<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cross-Modal Attention Guided Unlearning in Vision-Language Models](https://arxiv.org/abs/2510.07567)
*Karuna Bhaila,Aneesh Komanduri,Minh-Hao Van,Xintao Wu*

Main category: cs.CV

TL;DR: 提出CAGUL框架，一种轻量级的视觉语言模型遗忘方法，通过跨模态注意力引导来防止敏感信息泄露，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在训练过程中可能记忆并泄露隐私敏感信息，而现有的遗忘方法主要针对文本模型，视觉模态增加了遗忘的复杂性。

Method: 利用跨模态注意力分析视觉token对输出的贡献，通过外部模块在低重要性视觉token中编码遗忘信息，不改变预训练模型参数。

Result: 实验表明该方法性能与微调基线相当或更好，能有效防止信息泄露，同时保持参考模型行为。

Conclusion: CAGUL是一种实用有效的视觉语言模型遗忘解决方案，无需重新训练成本，不改变预训练参数。

Abstract: Vision-Language Models (VLMs) have demonstrated immense capabilities in
multi-modal understanding and inference tasks such as Visual Question Answering
(VQA), which requires models to infer outputs based on visual and textual
context simultaneously. Such inference abilities of large-scale pretrained
models are often attributed to the massive scale of pre-training data collected
across several domains. However, the models may memorize private and/or
sensitive information during training and regurgitate it in inference.
Recently, machine unlearning has been leveraged to address the leakage of
private data in LLMs. VLMs add a layer of complexity to this process, as the
visual context in the query may also contain sensitive information in addition
to the text. To address this issue, we explore unlearning for vision-language
models, specifically for the VQA task. We explore the role of visual tokens for
output generation in VLMs using cross-modal attention and utilize it to
formulate Cross-Modal Attention Guided Unlearning (CAGUL), a lightweight and
efficient VLM unlearning framework. In contrast to computationally expensive
model finetuning methods, CAGUL utilizes external modules to encode unlearning
information in visual tokens of low importance for relevant queries. We find
that the transformed visual tokens not only prevent leakage but also retain
reference model behavior. Experimental results show that our method performs
better or on par with finetuning-based baselines without altering the
pre-trained model parameters or incurring retraining costs, making it a
practical and effective unlearning solution for VLMs.

</details>


### [2] [DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream](https://arxiv.org/abs/2510.07752)
*Junhao He,Jiaxu Wang,Jia Li,Mingyuan Sun,Qiang Zhang,Jiahang Cao,Ziyi Zhang,Yi Gu,Jingkai Sun,Renjing Xu*

Main category: cs.CV

TL;DR: 提出了一种结合低帧率RGB视频和事件相机数据来重建动态3D高斯溅射的新框架，通过事件运动先验指导变形场优化，解决大帧间运动带来的不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 从低帧率RGB视频重建动态3D高斯溅射具有挑战性，因为大帧间运动会增加解空间的不确定性。事件相机能异步捕捉快速视觉变化且对运动模糊鲁棒，但缺乏颜色信息，将两者结合可以解决这一挑战。

Method: 采用事件运动先验指导变形场优化：1）使用LoCM无监督微调框架提取事件流中的运动先验；2）提出几何感知数据关联方法建立事件-高斯运动对应关系；3）使用运动分解和帧间伪标签策略。

Result: 在合成和真实场景上的广泛实验表明，该方法优于现有的基于图像和事件的方法，证明事件数据能有效优化动态3D高斯溅射。

Conclusion: 通过结合低帧率RGB图像和高帧率事件流，利用事件运动先验指导变形场优化，能够有效解决动态3D高斯溅射重建中的大帧间运动不确定性挑战。

Abstract: Reconstructing Dynamic 3D Gaussian Splatting (3DGS) from low-framerate RGB
videos is challenging. This is because large inter-frame motions will increase
the uncertainty of the solution space. For example, one pixel in the first
frame might have more choices to reach the corresponding pixel in the second
frame. Event cameras can asynchronously capture rapid visual changes and are
robust to motion blur, but they do not provide color information. Intuitively,
the event stream can provide deterministic constraints for the inter-frame
large motion by the event trajectories. Hence, combining
low-temporal-resolution images with high-framerate event streams can address
this challenge. However, it is challenging to jointly optimize Dynamic 3DGS
using both RGB and event modalities due to the significant discrepancy between
these two data modalities. This paper introduces a novel framework that jointly
optimizes dynamic 3DGS from the two modalities. The key idea is to adopt event
motion priors to guide the optimization of the deformation fields. First, we
extract the motion priors encoded in event streams by using the proposed LoCM
unsupervised fine-tuning framework to adapt an event flow estimator to a
certain unseen scene. Then, we present the geometry-aware data association
method to build the event-Gaussian motion correspondence, which is the primary
foundation of the pipeline, accompanied by two useful strategies, namely motion
decomposition and inter-frame pseudo-label. Extensive experiments show that our
method outperforms existing image and event-based approaches across synthetic
and real scenes and prove that our method can effectively optimize dynamic 3DGS
with the help of event data.

</details>


### [3] [PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting](https://arxiv.org/abs/2510.07830)
*Houqiang Zhong,Zhenglong Wu,Sihua Fu,Zihan Zheng,Xin Jin,Xiaoyun Zhang,Li Song,Qiang Hu*

Main category: cs.CV

TL;DR: PrismGS提出了一种基于物理的3D高斯泼溅正则化框架，通过金字塔多尺度监督和显式尺寸正则化，解决了大场景渲染中的锯齿伪影和优化不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在大型城市场景中会出现严重的锯齿伪影和优化不稳定问题，特别是在4K高分辨率渲染下，表现为闪烁纹理和锯齿边缘。现有方法虽然解决了可扩展性，但未能解决保真度差距。

Method: PrismGS集成了两个协同正则化器：金字塔多尺度监督（通过预滤波图像金字塔强制渲染一致性）和显式尺寸正则化（对3D高斯尺寸施加物理基础的下界约束）。

Result: 在MatrixCity、Mill-19和UrbanScene3D数据集上的实验表明，PrismGS实现了最先进的性能，相比CityGaussian获得了约1.5 dB的PSNR增益，在4K渲染下保持了优越的质量和鲁棒性。

Conclusion: PrismGS是一个即插即用的框架，能够显著改善3D高斯的固有渲染行为，有效缓解闪烁纹理和锯齿边缘问题，同时与现有管道兼容。

Abstract: 3D Gaussian Splatting (3DGS) has recently enabled real-time photorealistic
rendering in compact scenes, but scaling to large urban environments introduces
severe aliasing artifacts and optimization instability, especially under
high-resolution (e.g., 4K) rendering. These artifacts, manifesting as
flickering textures and jagged edges, arise from the mismatch between Gaussian
primitives and the multi-scale nature of urban geometry. While existing
``divide-and-conquer'' pipelines address scalability, they fail to resolve this
fidelity gap. In this paper, we propose PrismGS, a physically-grounded
regularization framework that improves the intrinsic rendering behavior of 3D
Gaussians. PrismGS integrates two synergistic regularizers. The first is
pyramidal multi-scale supervision, which enforces consistency by supervising
the rendering against a pre-filtered image pyramid. This compels the model to
learn an inherently anti-aliased representation that remains coherent across
different viewing scales, directly mitigating flickering textures. This is
complemented by an explicit size regularization that imposes a
physically-grounded lower bound on the dimensions of the 3D Gaussians. This
prevents the formation of degenerate, view-dependent primitives, leading to
more stable and plausible geometric surfaces and reducing jagged edges. Our
method is plug-and-play and compatible with existing pipelines. Extensive
experiments on MatrixCity, Mill-19, and UrbanScene3D demonstrate that PrismGS
achieves state-of-the-art performance, yielding significant PSNR gains around
1.5 dB against CityGaussian, while maintaining its superior quality and
robustness under demanding 4K rendering.

</details>


### [4] [ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving](https://arxiv.org/abs/2510.08562)
*Zhiyu Zheng,Shaoyu Chen,Haoran Yin,Xinbang Zhang,Jialv Zou,Xinggang Wang,Qian Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 提出ResAD框架解决端到端自动驾驶中的轨迹数据时空不平衡问题，通过预测与惯性参考的残差偏差来改进模型性能


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统面临轨迹数据固有的时空不平衡问题，这导致模型学习虚假相关性而非因果推理，同时优先考虑不确定的远距离预测而损害即时安全性

Method: ResAD框架采用归一化残差轨迹建模，预测与确定性惯性参考的残差偏差，并使用逐点归一化处理优化不平衡问题

Result: 在NAVSIM基准测试中，ResAD使用仅有两个去噪步骤的普通扩散策略实现了88.6的最优PDMS分数

Conclusion: ResAD方法显著简化了学习任务并提高了模型性能，通过重新定义学习目标为预测与惯性参考的残差偏差来解决轨迹数据不平衡问题

Abstract: End-to-end autonomous driving (E2EAD) systems, which learn to predict future
trajectories directly from sensor data, are fundamentally challenged by the
inherent spatio-temporal imbalance of trajectory data. This imbalance creates a
significant optimization burden, causing models to learn spurious correlations
instead of causal inference, while also prioritizing uncertain, distant
predictions, thereby compromising immediate safety. To address these issues, we
propose ResAD, a novel Normalized Residual Trajectory Modeling framework.
Instead of predicting the future trajectory directly, our approach reframes the
learning task to predict the residual deviation from a deterministic inertial
reference. The inertial reference serves as a counterfactual, forcing the model
to move beyond simple pattern recognition and instead identify the underlying
causal factors (e.g., traffic rules, obstacles) that necessitate deviations
from a default, inertially-guided path. To deal with the optimization imbalance
caused by uncertain, long-term horizons, ResAD further incorporates Point-wise
Normalization of the predicted residual. It re-weights the optimization
objective, preventing large-magnitude errors associated with distant, uncertain
waypoints from dominating the learning signal. Extensive experiments validate
the effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a
state-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two
denoising steps, demonstrating that our approach significantly simplifies the
learning task and improves model performance. The code will be released to
facilitate further research.

</details>


### [5] [GraphEnet: Event-driven Human Pose Estimation with a Graph Neural Network](https://arxiv.org/abs/2510.07990)
*Gaurvi Goyal,Pham Cong Thuong,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi*

Main category: cs.CV

TL;DR: 提出GraphEnet，一种基于图神经网络的2D人体姿态估计方法，专门针对事件相机数据，利用其稀疏特性实现高频姿态估计。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有低延迟、低能耗优势，适合便携设备和移动机器人应用，但现有方法未能充分利用其稀疏特性进行人体姿态估计。

Method: 使用图神经网络处理事件相机输出，采用基于线的中间事件表示，结合新颖的偏移向量学习范式和基于置信度的池化方法。

Result: 这是首个将图神经网络应用于事件数据的人体姿态估计工作，实现了高频单人体姿态估计。

Conclusion: GraphEnet成功展示了图神经网络在事件相机人体姿态估计中的有效性，为资源受限环境提供了高效解决方案。

Abstract: Human Pose Estimation is a crucial module in human-machine interaction
applications and, especially since the rise in deep learning technology, robust
methods are available to consumers using RGB cameras and commercial GPUs. On
the other hand, event-based cameras have gained popularity in the vision
research community for their low latency and low energy advantages that make
them ideal for applications where those resources are constrained like portable
electronics and mobile robots. In this work we propose a Graph Neural Network,
GraphEnet, that leverages the sparse nature of event camera output, with an
intermediate line based event representation, to estimate 2D Human Pose of a
single person at a high frequency. The architecture incorporates a novel offset
vector learning paradigm with confidence based pooling to estimate the human
pose. This is the first work that applies Graph Neural Networks to event data
for Human Pose Estimation. The code is open-source at
https://github.com/event-driven-robotics/GraphEnet-NeVi-ICCV2025.

</details>


### [6] [CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.08003)
*Weihuang Lin,Yiwei Ma,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: CIR-CoT是首个集成显式思维链推理的端到端检索导向多模态大语言模型，通过生成可解释的推理链来提高跨模态交互理解，实现更准确和透明的图像检索。


<details>
  <summary>Details</summary>
Motivation: 解决现有组合图像检索方法作为"黑盒"的局限性，这些方法缺乏可解释性且难以处理复杂的细粒度指令。

Method: 提出CIR-CoT模型，采用三阶段过程生成结构化思维链注释（描述、推理、结论），然后微调模型生成结构化输出，最后将检索意图编码到专用嵌入中。

Result: 在领域内数据集（FashionIQ、CIRR）上获得高度竞争力表现，在领域外CIRCO数据集上展现出显著泛化能力。

Conclusion: CIR-CoT为构建更有效和可信赖的检索系统开辟了新路径，通过显式推理链增强了模型的准确性和透明度。

Abstract: Composed Image Retrieval (CIR), which aims to find a target image from a
reference image and a modification text, presents the core challenge of
performing unified reasoning across visual and semantic modalities. While
current approaches based on Vision-Language Models (VLMs, e.g., CLIP) and more
recent Multimodal Large Language Models (MLLMs, e.g., Qwen-VL) have shown
progress, they predominantly function as ``black boxes." This inherent opacity
not only prevents users from understanding the retrieval rationale but also
restricts the models' ability to follow complex, fine-grained instructions. To
overcome these limitations, we introduce CIR-CoT, the first end-to-end
retrieval-oriented MLLM designed to integrate explicit Chain-of-Thought (CoT)
reasoning. By compelling the model to first generate an interpretable reasoning
chain, CIR-CoT enhances its ability to capture crucial cross-modal
interactions, leading to more accurate retrieval while making its decision
process transparent. Since existing datasets like FashionIQ and CIRR lack the
necessary reasoning data, a key contribution of our work is the creation of
structured CoT annotations using a three-stage process involving a caption,
reasoning, and conclusion. Our model is then fine-tuned to produce this
structured output before encoding its final retrieval intent into a dedicated
embedding. Comprehensive experiments show that CIR-CoT achieves highly
competitive performance on in-domain datasets (FashionIQ, CIRR) and
demonstrates remarkable generalization on the out-of-domain CIRCO dataset,
establishing a new path toward more effective and trustworthy retrieval
systems.

</details>


### [7] [VideoVerse: How Far is Your T2V Generator from a World Model?](https://arxiv.org/abs/2510.08398)
*Zeqing Wang,Xinyu Wei,Bairui Li,Zhen Guo,Jinrui Zhang,Hongyang Wei,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: VideoVerse是一个新的文本到视频生成基准测试，专注于评估T2V模型对复杂时间因果关系和世界知识的理解能力，填补现有基准在事件级时间因果性和世界知识评估方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有T2V基准测试在评估维度上已无法区分最先进模型，严重缺乏对事件级时间因果关系的评估，且缺乏对世界知识的系统性评估，而这些能力对于构建世界模型至关重要。

Method: 收集跨领域代表性视频，提取具有内在时间因果关系的事件级描述，由独立标注者重写为文本到视频提示，设计包含10个维度的二元评估问题，开发基于现代视觉语言模型的人类偏好对齐QA评估流程。

Result: VideoVerse包含300个精心策划的提示，涉及815个事件和793个二元评估问题，对开源和闭源T2V模型进行了系统性评估。

Conclusion: 该基准测试为评估T2V模型是否接近世界模型提供了深入分析框架，揭示了当前T2V生成器与世界模型之间的差距。

Abstract: The recent rapid advancement of Text-to-Video (T2V) generation technologies,
which are critical to build ``world models'', makes the existing benchmarks
increasingly insufficient to evaluate state-of-the-art T2V models. First,
current evaluation dimensions, such as per-frame aesthetic quality and temporal
consistency, are no longer able to differentiate state-of-the-art T2V models.
Second, event-level temporal causality, which not only distinguishes video from
other modalities but also constitutes a crucial component of world models, is
severely underexplored in existing benchmarks. Third, existing benchmarks lack
a systematic assessment of world knowledge, which are essential capabilities
for building world models. To address these issues, we introduce VideoVerse, a
comprehensive benchmark that focuses on evaluating whether a T2V model could
understand complex temporal causality and world knowledge in the real world. We
collect representative videos across diverse domains (e.g., natural landscapes,
sports, indoor scenes, science fiction, chemical and physical experiments) and
extract their event-level descriptions with inherent temporal causality, which
are then rewritten into text-to-video prompts by independent annotators. For
each prompt, we design a suite of binary evaluation questions from the
perspective of dynamic and static properties, with a total of ten carefully
defined evaluation dimensions. In total, our VideoVerse comprises 300 carefully
curated prompts, involving 815 events and 793 binary evaluation questions.
Consequently, a human preference aligned QA-based evaluation pipeline is
developed by using modern vision-language models. Finally, we perform a
systematic evaluation of state-of-the-art open-source and closed-source T2V
models on VideoVerse, providing in-depth analysis on how far the current T2V
generators are from world models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [ConCuR: Conciseness Makes State-of-the-Art Kernel Generation](https://arxiv.org/abs/2510.07356)
*Lingcheng Kong,Jiateng Wei,Hanzhang Shen,Huan Wang*

Main category: cs.LG

TL;DR: 该论文提出了一个生成和筛选高质量CUDA内核的流程，构建了ConCuR数据集和KernelCoder模型，在KernelBench中显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决内核生成任务中高质量数据稀缺的问题，因为大多数高质量内核是专有且不开源的，这阻碍了使用监督微调来对齐LLMs进行内核生成。

Method: 开发了一个生成和筛选带有推理轨迹的高质量CUDA内核的流程，构建ConCuR数据集，并训练KernelCoder模型。

Result: 在KernelBench设置中，模型显著优于现有最佳模型QwQ-32B，超越了所有开源内核生成微调模型以及前沿模型如DeepSeek-V3.1-Think和Claude-4-sonnet。

Conclusion: 平均推理长度可以作为评估内核生成任务难度的指标，该研究的数据收集和筛选流程有助于未来获得更好的内核生成数据。

Abstract: GPU kernel generation by LLMs has recently experienced rapid development,
leveraging test-time scaling and reinforcement learning techniques. However, a
key challenge for kernel generation is the scarcity of high-quality data, as
most high-quality kernels are proprietary and not open-source. This challenge
prevents us from leveraging supervised fine-tuning to align LLMs to the kernel
generation task. To address this challenge, we develop a pipeline that
generates and curates high-quality CUDA kernels with reasoning traces,
motivated by a critical observation that concise yet informative reasoning
traces result in robust generation of high-performance kernels. Using this
pipeline, we construct our dataset ConCuR and introduce our model KernelCoder,
which is the first model trained on a curated dataset consisting of PyTorch,
reasoning, and CUDA kernel pairs, to our knowledge. In the KernelBench setup,
our model achieves significant improvements over the existing top-performing
model, QwQ-32B, and outperforms all open-source models fine-tuned for kernel
generation, as well as frontier models such as DeepSeek-V3.1-Think and
Claude-4-sonnet. Finally, we show that the average reasoning length can serve
as a metric to assess the difficulty of kernel generation tasks. The
observations, metrics, and our data collection and curation pipeline can help
obtain better data in the kernel generation task in the future.

</details>


### [9] [Continual Learning for Adaptive AI Systems](https://arxiv.org/abs/2510.07648)
*Md Hasibul Amin,Tamzid Tanvi Alam*

Main category: cs.LG

TL;DR: 提出了一种基于簇间分离(ICS)的正则化方法来解决持续学习中的灾难性遗忘问题，通过在损失函数中惩罚远离先前任务簇中心的输出来改善任务分离。


<details>
  <summary>Details</summary>
Motivation: 持续学习是神经网络在不丢失先前知识的情况下学习多个顺序任务的能力，但深度学习中灾难性遗忘问题严重阻碍了真正自适应人工智能的发展。

Method: 引入基于簇间分离(ICS)的正则化技术，在损失函数中惩罚模型产生远离先前任务数据形成的簇中心的输出，并进行超参数调优以找到最佳正则化权重。

Result: 在标准5任务Split CIFAR-10基准测试和ResNet-18架构上，ICS在保持初始任务性能方面表现有效，但在长期知识保留方面存在局限性，特别是当任务数量增加时。

Conclusion: ICS方法在缓解灾难性遗忘方面有效，但持续学习中的复杂性和权衡仍然存在，特别是在长期知识保留方面需要进一步研究。

Abstract: Continual learning the ability of a neural network to learn multiple
sequential tasks without losing previously acquired knowledge remains a
significant obstacle to developing truly adaptive artificial intelligence. Deep
learning models have achieved remarkable results in various applications, but
overfitting remains a common issue. Regularization techniques can help prevent
overfitting by adding constraints to the model's parameters. To prevent
catastrophic forgetting, in this paper we introduce a novel regularization
technique based on inter-cluster separation (ICS) in the loss function, which
penalizes the model for producing outputs that are far away from the centroids
of the clusters formed by the data from previous tasks. We also performed
hyperparameter tuning to find the optimal weighting of the proposed
regularization term. This ensures clearer separation between tasks in the
neural network's internal representation, reducing overlap and mitigating
forgetting. Using the standard 5-task Split CIFAR-10 benchmark and a ResNet-18
architecture, we demonstrate ICS's effectiveness in maintaining strong
performance on initial tasks. However, our results also highlight limitations
in long-term knowledge retention, particularly when the number of tasks
increases. This underscores the complexity and trade-offs inherent in continual
learning and points toward avenues for further research.

</details>


### [10] [GeoGen: A Two-stage Coarse-to-Fine Framework for Fine-grained Synthetic Location-based Social Network Trajectory Generation](https://arxiv.org/abs/2510.07735)
*Rongchao Xu,Kunlin Cai,Lin Jiang,Dahai Yu,Zhiqing Hong,Yuan Tian,Guang Wang*

Main category: cs.LG

TL;DR: GeoGen是一个两阶段粗到细的框架，用于生成大规模的基于位置的社交网络签到轨迹数据，解决了现有方法在处理空间离散、时间不规则轨迹时的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于高收集成本和日益增长的隐私担忧，获取大规模LBSN轨迹数据变得困难。合成数据生成提供了一种新机会，但现有方法难以处理LBSN签到轨迹的空间离散、时间不规则特性以及复杂时空模式。

Method: 提出两阶段框架：第一阶段使用稀疏感知时空扩散模型(S²TDiff)从原始轨迹重建连续规则的运动序列；第二阶段使用Transformer-based Seq2Seq架构Coarse2FineNet，通过动态上下文融合和多任务混合头解码器生成细粒度轨迹。

Result: 在四个真实世界数据集上的实验表明，GeoGen在保真度和实用性评估上都优于现有最先进模型，在FS-TKY数据集上距离和半径指标分别提高了69%和55%以上。

Conclusion: GeoGen框架能够有效生成高质量的LBSN签到轨迹数据，在保护隐私的同时保持了数据的统计特征和实用性，为POI推荐、广告投放等应用提供了可行的数据解决方案。

Abstract: Location-Based Social Network (LBSN) check-in trajectory data are important
for many practical applications, like POI recommendation, advertising, and
pandemic intervention. However, the high collection costs and ever-increasing
privacy concerns prevent us from accessing large-scale LBSN trajectory data.
The recent advances in synthetic data generation provide us with a new
opportunity to achieve this, which utilizes generative AI to generate synthetic
data that preserves the characteristics of real data while ensuring privacy
protection. However, generating synthetic LBSN check-in trajectories remains
challenging due to their spatially discrete, temporally irregular nature and
the complex spatio-temporal patterns caused by sparse activities and uncertain
human mobility. To address this challenge, we propose GeoGen, a two-stage
coarse-to-fine framework for large-scale LBSN check-in trajectory generation.
In the first stage, we reconstruct spatially continuous, temporally regular
latent movement sequences from the original LBSN check-in trajectories and then
design a Sparsity-aware Spatio-temporal Diffusion model (S$^2$TDiff) with an
efficient denosing network to learn their underlying behavioral patterns. In
the second stage, we design Coarse2FineNet, a Transformer-based Seq2Seq
architecture equipped with a dynamic context fusion mechanism in the encoder
and a multi-task hybrid-head decoder, which generates fine-grained LBSN
trajectories based on coarse-grained latent movement sequences by modeling
semantic relevance and behavioral uncertainty. Extensive experiments on four
real-world datasets show that GeoGen excels state-of-the-art models for both
fidelity and utility evaluation, e.g., it increases over 69% and 55% in
distance and radius metrics on the FS-TKY dataset.

</details>


### [11] [MetaDefense: Defending Finetuning-based Jailbreak Attack Before and During Generation](https://arxiv.org/abs/2510.07835)
*Weisen Jiang,Sinno Jialin Pan*

Main category: cs.LG

TL;DR: MetaDefense是一个防御LLM微调越狱攻击的新框架，通过两阶段防御方法在生成前和生成中检测有害内容，显著优于现有防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制无法泛化到未见攻击模板伪装的有害查询，尽管LLM在嵌入空间能够区分这些查询。

Method: 提出两阶段防御：生成前防御检测有害查询，生成中防御监控部分响应；使用专门提示训练LLM预测查询和部分响应的有害性。

Result: 在多个LLM架构上的实验表明，MetaDefense显著优于现有防御机制，对可见和未见攻击模板的有害查询都能实现鲁棒防御，同时在良性任务上保持竞争力。

Conclusion: MetaDefense为LLM安全提供了一种有效的防御框架，能够早期终止潜在有害交互，提高模型安全性。

Abstract: This paper introduces MetaDefense, a novel framework for defending against
finetuning-based jailbreak attacks in large language models (LLMs). We observe
that existing defense mechanisms fail to generalize to harmful queries
disguised by unseen attack templates, despite LLMs being capable of
distinguishing disguised harmful queries in the embedding space. Based on these
insights, we propose a two-stage defense approach: (i) pre-generation defense
that detects harmful queries before response generation begins, and (ii)
mid-generation defense that monitors partial responses during generation to
prevent outputting more harmful content. Our MetaDefense trains the LLM to
predict the harmfulness of both queries and partial responses using specialized
prompts, enabling early termination of potentially harmful interactions.
Extensive experiments across multiple LLM architectures (LLaMA-2-7B,
Qwen-2.5-3B-Instruct, and LLaMA-3.2-3B-Instruct) demonstrate that MetaDefense
significantly outperforms existing defense mechanisms, achieving robust defense
against harmful queries with seen and unseen attack templates while maintaining
competitive performance on benign tasks. Code is available at
https://github.com/ws-jiang/MetaDefense.

</details>


### [12] [SketchGuard: Scaling Byzantine-Robust Decentralized Federated Learning via Sketch-Based Screening](https://arxiv.org/abs/2510.07922)
*Murtaza Rangwala,Farag Azzedin,Richard O. Sinnott,Rajkumar Buyya*

Main category: cs.LG

TL;DR: SketchGuard是一个通过草图压缩技术降低去中心化联邦学习中拜占庭攻击防御成本的新框架，将通信复杂度从O(d|N_i|)降低到O(k|N_i| + d|S_i|)，同时保持相同的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的拜占庭鲁棒DFL防御方法需要每个客户端在每轮训练中与所有邻居交换和比较完整的高维模型向量，产生了过高的通信和计算成本，阻碍了在Web规模上的部署。

Method: 使用Count Sketch将d维模型压缩到k维草图(k≪d)进行相似性比较，然后仅从被接受的邻居处选择性获取完整模型，将拜占庭过滤与模型聚合解耦。

Result: 在多个数据集、网络拓扑和攻击场景下的实验表明，SketchGuard保持与最先进方法相同的鲁棒性，同时将计算时间减少高达82%，通信开销减少50-70%。

Conclusion: 基于草图压缩的技术是实现Web规模鲁棒DFL的基本推动者，其优势随着模型维度和网络连接性的增加而倍增。

Abstract: Decentralized Federated Learning (DFL) enables privacy-preserving
collaborative training without centralized servers, but remains vulnerable to
Byzantine attacks where malicious clients submit corrupted model updates.
Existing Byzantine-robust DFL defenses rely on similarity-based neighbor
screening that requires every client to exchange and compare complete
high-dimensional model vectors with all neighbors in each training round,
creating prohibitive communication and computational costs that prevent
deployment at web scale. We propose SketchGuard, a general framework that
decouples Byzantine filtering from model aggregation through sketch-based
neighbor screening. SketchGuard compresses $d$-dimensional models to
$k$-dimensional sketches ($k \ll d$) using Count Sketch for similarity
comparisons, then selectively fetches full models only from accepted neighbors,
reducing per-round communication complexity from $O(d|N_i|)$ to $O(k|N_i| +
d|S_i|)$, where $|N_i|$ is the neighbor count and $|S_i| \le |N_i|$ is the
accepted neighbor count. We establish rigorous convergence guarantees in both
strongly convex and non-convex settings, proving that Count Sketch compression
preserves Byzantine resilience with controlled degradation bounds where
approximation errors introduce only a $(1+O(\epsilon))$ factor in the effective
threshold parameter. Comprehensive experiments across multiple datasets,
network topologies, and attack scenarios demonstrate that SketchGuard maintains
identical robustness to state-of-the-art methods while reducing computation
time by up to 82% and communication overhead by 50-70% depending on filtering
effectiveness, with benefits scaling multiplicatively with model dimensionality
and network connectivity. These results establish the viability of sketch-based
compression as a fundamental enabler of robust DFL at web scale.

</details>


### [13] [Long-tailed Recognition with Model Rebalancing](https://arxiv.org/abs/2510.08177)
*Jiaan Luo,Feng Hong,Qiang Hu,Xiaofeng Cao,Feng Liu,Jiangchao Yao*

Main category: cs.LG

TL;DR: 提出MORE框架，通过直接重新平衡模型参数空间来缓解长尾分布问题，使用低秩参数组件和正弦重加权调度，不增加模型复杂度或推理成本


<details>
  <summary>Details</summary>
Motivation: 长尾识别在深度学习和基础模型微调中普遍存在且具有挑战性，类别分布偏斜阻碍模型对尾部类别的泛化能力

Method: 引入低秩参数组件来调节参数空间分配，采用定制损失和正弦重加权调度，不增加整体模型复杂度

Result: 在多样化的长尾基准测试中显著改善泛化能力，特别是对尾部类别，有效补充现有不平衡缓解方法

Conclusion: MORE作为长尾设置中的稳健即插即用模块具有潜力

Abstract: Long-tailed recognition is ubiquitous and challenging in deep learning and
even in the downstream finetuning of foundation models, since the skew class
distribution generally prevents the model generalization to the tail classes.
Despite the promise of previous methods from the perspectives of data
augmentation, loss rebalancing and decoupled training etc., consistent
improvement in the broad scenarios like multi-label long-tailed recognition is
difficult. In this study, we dive into the essential model capacity impact
under long-tailed context, and propose a novel framework, Model Rebalancing
(MORE), which mitigates imbalance by directly rebalancing the model's parameter
space. Specifically, MORE introduces a low-rank parameter component to mediate
the parameter space allocation guided by a tailored loss and sinusoidal
reweighting schedule, but without increasing the overall model complexity or
inference costs. Extensive experiments on diverse long-tailed benchmarks,
spanning multi-class and multi-label tasks, demonstrate that MORE significantly
improves generalization, particularly for tail classes, and effectively
complements existing imbalance mitigation methods. These results highlight
MORE's potential as a robust plug-and-play module in long-tailed settings.

</details>


### [14] [The Hidden Bias: A Study on Explicit and Implicit Political Stereotypes in Large Language Models](https://arxiv.org/abs/2510.08236)
*Konrad Löhr,Shuzhou Yuan,Michael Färber*

Main category: cs.LG

TL;DR: 该研究使用政治罗盘测试评估了8个主流大语言模型的政治偏见和刻板印象传播，发现所有模型都呈现一致的左倾政治倾向，且通过语言变化引发的隐性刻板印象比显性刻板印象更为明显。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在社会信息传播和决策过程中的作用日益重要，理解其在政治领域的潜在偏见对于防止对公众舆论和民主进程产生不当影响至关重要。

Method: 采用二维政治罗盘测试评估模型固有政治倾向，使用角色提示探索显性刻板印象，并通过多语言版本测试揭示隐性刻板印象。

Result: 所有被调查模型均显示一致的左倾政治倾向；不同模型的刻板印象性质和程度差异很大；隐性刻板印象比显性刻板印象更明显；大多数模型的隐性和显性刻板印象存在显著一致性。

Conclusion: 该研究揭示了大语言模型中政治偏见与刻板印象的复杂相互作用，表明模型对其固有偏见具有一定程度的透明度或"意识"。

Abstract: Large Language Models (LLMs) are increasingly integral to information
dissemination and decision-making processes. Given their growing societal
influence, understanding potential biases, particularly within the political
domain, is crucial to prevent undue influence on public opinion and democratic
processes. This work investigates political bias and stereotype propagation
across eight prominent LLMs using the two-dimensional Political Compass Test
(PCT). Initially, the PCT is employed to assess the inherent political leanings
of these models. Subsequently, persona prompting with the PCT is used to
explore explicit stereotypes across various social dimensions. In a final step,
implicit stereotypes are uncovered by evaluating models with multilingual
versions of the PCT. Key findings reveal a consistent left-leaning political
alignment across all investigated models. Furthermore, while the nature and
extent of stereotypes vary considerably between models, implicit stereotypes
elicited through language variation are more pronounced than those identified
via explicit persona prompting. Interestingly, for most models, implicit and
explicit stereotypes show a notable alignment, suggesting a degree of
transparency or "awareness" regarding their inherent biases. This study
underscores the complex interplay of political bias and stereotypes in LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines](https://arxiv.org/abs/2510.07614)
*Amine Barrak*

Main category: cs.AI

TL;DR: 该论文研究了基于大语言模型的可追溯和问责的多智能体系统，通过Planner->Executor->Critic流水线结构，分析了错误传播机制并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的顺序多智能体系统虽然能自动化复杂软件任务，但由于错误会在各阶段间静默传递，导致系统难以信任。需要建立可追溯和问责的流水线来追踪错误来源。

Method: 采用Planner->Executor->Critic流水线结构，评估了8种配置的三种最先进LLM在三个基准测试上的表现，分析错误起始、传播和修复机制。

Result: 研究发现：(1)在智能体间添加结构化、可问责的交接显著提高准确性；(2)不同模型在特定角色中表现出明显优势和风险；(3)准确性-成本-延迟权衡是任务依赖的，异构流水线通常最有效。

Conclusion: 提供了一种实用的、数据驱动的方法，用于设计、追踪和调试可靠、可预测和可问责的多智能体系统。

Abstract: Sequential multi-agent systems built with large language models (LLMs) can
automate complex software tasks, but they are hard to trust because errors
quietly pass from one stage to the next. We study a traceable and accountable
pipeline, meaning a system with clear roles, structured handoffs, and saved
records that let us trace who did what at each step and assign blame when
things go wrong. Our setting is a Planner -> Executor -> Critic pipeline. We
evaluate eight configurations of three state-of-the-art LLMs on three
benchmarks and analyze where errors start, how they spread, and how they can be
fixed. Our results show: (1) adding a structured, accountable handoff between
agents markedly improves accuracy and prevents the failures common in simple
pipelines; (2) models have clear role-specific strengths and risks (e.g.,
steady planning vs. high-variance critiquing), which we quantify with repair
and harm rates; and (3) accuracy-cost-latency trade-offs are task-dependent,
with heterogeneous pipelines often the most efficient. Overall, we provide a
practical, data-driven method for designing, tracing, and debugging reliable,
predictable, and accountable multi-agent systems.

</details>


### [16] [GCPO: When Contrast Fails, Go Gold](https://arxiv.org/abs/2510.07790)
*Hao Wu,Wei Liu*

Main category: cs.AI

TL;DR: 提出了Group Contrastive Policy Optimization (GCPO)方法，通过引入外部标准参考答案来解决GRPO算法在强化学习中的局限性，提升小模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法如GRPO存在明显缺陷：模型rollout响应的上限完全由模型自身决定，无法从全错或全对样本中获取知识。需要一种能利用外部参考答案来引导模型学习的方法。

Method: GCPO方法引入外部标准参考答案，当模型无法解决问题时，参考答案提供正确响应，引导模型向明确正确的更新方向学习。这种方法充分利用每个样本，并让模型在训练中模仿参考答案的解题策略。

Result: GCPO在多个基准数据集上取得了优异结果，相比基线模型有显著提升。

Conclusion: GCPO通过引入外部参考答案有效解决了GRPO的局限性，提高了训练效率和模型在推理任务中的泛化能力。

Abstract: Reinforcement learning has been widely applied to enhance the reasoning
capabilities of large language models. Extending the inference limits of
smaller models has become a prominent research focus. However, algorithms such
as Group Relative Policy Optimization (GRPO) suffer from a clear drawback: the
upper bound of a model's rollout responses is entirely determined by the model
itself, preventing the acquisition of knowledge from samples that are either
all incorrect or all correct. In this paper, we introduce Group Contrastive
Policy Optimization (GCPO), a method that incorporates external standard
reference answers. When the model cannot solve a problem, the reference answer
supplies the correct response, steering the model toward an unequivocally
accurate update direction. This approach offers two main advantages: (1) it
improves training efficiency by fully utilizing every sample; (2) it enables
the model to emulate the problem solving strategy of the reference answer
during training, thereby enhancing generalization in reasoning. GCPO achieves
outstanding results across multiple benchmark datasets, yielding substantial
improvements over the baseline model. Our code is available at:
https://github.com/AchoWu/GCPO.

</details>


### [17] [Can Risk-taking AI-Assistants suitably represent entities](https://arxiv.org/abs/2510.08114)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Amirhossein Farshi Sotoudeh*

Main category: cs.AI

TL;DR: 该研究调查语言模型在风险厌恶可操纵性方面的表现，发现虽然一些模型与人类行为有一定对齐，但仍存在显著差异，需要改进生物中心的可操纵性测量方法。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地集成到AI驱动的决策支持系统中，理解它们的风险行为对于负责任部署至关重要，需要防止系统无意中引导用户做出风险决策或嵌入隐藏偏见。

Method: 研究考察语言模型在不同经济场景下复制人类风险偏好的能力，重点关注性别特定态度、不确定性、基于角色的决策制定以及风险厌恶的可操纵性。

Result: DeepSeek Reasoner和Gemini-2.0-flash-lite等语言模型与人类行为有一定对齐，但存在显著差异，突显了改进生物中心可操纵性测量的必要性。

Conclusion: 研究呼吁在模型设计方面进一步改进，确保AI系统更准确地复制人类风险偏好，从而提高在风险管理环境中的有效性，增强AI助手在风险管理中的适用性。

Abstract: Responsible AI demands systems whose behavioral tendencies can be effectively
measured, audited, and adjusted to prevent inadvertently nudging users toward
risky decisions or embedding hidden biases in risk aversion. As language models
(LMs) are increasingly incorporated into AI-driven decision support systems,
understanding their risk behaviors is crucial for their responsible deployment.
This study investigates the manipulability of risk aversion (MoRA) in LMs,
examining their ability to replicate human risk preferences across diverse
economic scenarios, with a focus on gender-specific attitudes, uncertainty,
role-based decision-making, and the manipulability of risk aversion. The
results indicate that while LMs such as DeepSeek Reasoner and
Gemini-2.0-flash-lite exhibit some alignment with human behaviors, notable
discrepancies highlight the need to refine bio-centric measures of
manipulability. These findings suggest directions for refining AI design to
better align human and AI risk preferences and enhance ethical decision-making.
The study calls for further advancements in model design to ensure that AI
systems more accurately replicate human risk preferences, thereby improving
their effectiveness in risk management contexts. This approach could enhance
the applicability of AI assistants in managing risk.

</details>


### [18] [Co-TAP: Three-Layer Agent Interaction Protocol Technical Report](https://arxiv.org/abs/2510.08263)
*Shunyu An,Miao Wang,Yongchao Li,Dong Wan,Lina Wang,Ling Qin,Liqin Gao,Congyao Fan,Zhiyong Mao,Jiange Pu,Wenji Xia,Dong Zhao,Rui Hu,Ji Lu,Guiyue Zhou,Baoyu Tang,Yanqin Gao,Yongsheng Du,Daigang Xu,Lingjun Huang,Baoli Wang,Xiwen Zhang,Luyao Wang,Shilong Liu*

Main category: cs.AI

TL;DR: Co-TAP是一个三层智能体交互协议，通过HAI、UAP和MEK三个核心协议解决多智能体系统在互操作性、交互协作和知识共享方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在三个核心维度面临的挑战：互操作性、交互协作和知识共享，为构建下一代高效、可扩展和智能的多智能体应用提供基础。

Method: 设计了三层协议：HAI（人机交互协议）标准化信息流，UAP（统一智能体协议）实现异构智能体互联，MEK（记忆-提取-知识协议）建立认知链实现知识共享。

Result: 提出了一个完整的协议框架，能够确保实时性能、可靠性、协同性，打破通信障碍，实现底层网络无缝互联，并支持集体智能的实现。

Conclusion: Co-TAP协议框架为构建下一代高效、可扩展和智能的多智能体应用提供了坚实的工程基础和理论指导。

Abstract: This paper proposes Co-TAP (T: Triple, A: Agent, P: Protocol), a three-layer
agent interaction protocol designed to address the challenges faced by
multi-agent systems across the three core dimensions of Interoperability,
Interaction and Collaboration, and Knowledge Sharing. We have designed and
proposed a layered solution composed of three core protocols: the Human-Agent
Interaction Protocol (HAI), the Unified Agent Protocol (UAP), and the
Memory-Extraction-Knowledge Protocol (MEK). HAI focuses on the interaction
layer, standardizing the flow of information between users, interfaces, and
agents by defining a standardized, event-driven communication paradigm. This
ensures the real-time performance, reliability, and synergy of interactions. As
the core of the infrastructure layer, UAP is designed to break down
communication barriers among heterogeneous agents through unified service
discovery and protocol conversion mechanisms, thereby enabling seamless
interconnection and interoperability of the underlying network. MEK, in turn,
operates at the cognitive layer. By establishing a standardized ''Memory (M) -
Extraction (E) - Knowledge (K)'' cognitive chain, it empowers agents with the
ability to learn from individual experiences and form shareable knowledge,
thereby laying the foundation for the realization of true collective
intelligence. We believe this protocol framework will provide a solid
engineering foundation and theoretical guidance for building the next
generation of efficient, scalable, and intelligent multi-agent applications.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 提出新的波斯语-塔吉克语双向音译模型，在多个数据集上训练，在跨领域文本上取得最佳性能，为实际应用提供更全面的基准。


<details>
  <summary>Details</summary>
Motivation: 波斯语使用两种书写标准（波斯-阿拉伯字母和塔吉克-西里尔字母），阻碍了塔吉克斯坦与其他波斯语国家的书面交流。现有音译模型局限于特定领域文本，缺乏实际应用的通用性。

Method: 使用序列到序列模型，在所有可用数据集上进行训练，并贡献了两个新数据集，实现塔吉克语和波斯语之间的双向音译。

Result: 模型在Farsi到Tajik方向获得chrF++ 87.91和标准化CER 0.05，Tajik到Farsi方向获得chrF++ 92.28和标准化CER 0.04，在所有领域都表现出色。

Conclusion: 该研究提供了更清晰的任务难度理解，建立了全面的可比基准，模型、数据和代码已开源，为实际跨文化交流提供了可行的技术解决方案。

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [20] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 论文研究发现提升LLMs真实性会削弱安全对齐能力，提出通过稀疏自编码器分离拒绝相关特征与幻觉特征的方法来平衡真实性与安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs研究中，增强真实性往往以牺牲安全对齐为代价，这种权衡关系尚未被充分研究。

Method: 使用稀疏自编码器分离拒绝相关特征与幻觉特征，并通过子空间正交化在微调过程中保持拒绝行为。

Result: 在常识推理任务和有害基准测试中，该方法有效保持了拒绝行为和任务效用，缓解了真实性与安全性之间的权衡。

Conclusion: 提出的特征分离方法能够在不增加幻觉的情况下维持安全对齐，解决了真实性与安全性之间的冲突。

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [21] [Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning](https://arxiv.org/abs/2510.07974)
*Jialu Du,Guiyang Hou,Yihui Fu,Chen Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu*

Main category: cs.CL

TL;DR: 提出自适应世界模型增强推理机制，通过构建动态文本世界模型来跟踪实体状态和时间序列，解决LLM在社会推理任务中混淆客观现实与主观信念的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和代码推理方面表现出色，但在社会推理任务中表现不佳，存在认知混淆、逻辑不一致以及客观世界状态与主观信念状态的混淆问题。

Method: 构建动态文本世界模型来跟踪实体状态和时间序列，动态监控推理轨迹中的混淆指标，及时提供清晰的世界状态描述来帮助模型应对认知困境。

Result: 在三个社会基准测试中显示出显著改进，准确率提升（如Hi-ToM中+10%），同时计算成本降低（最多减少33.8%的token使用）。

Conclusion: 该机制为在社交场景中部署LLM提供了一个简单而有效的解决方案，模仿人类使用隐式世界模型来区分外部事件和内部信念的方式。

Abstract: While large language models (LLMs) excel in mathematical and code reasoning,
we observe they struggle with social reasoning tasks, exhibiting cognitive
confusion, logical inconsistencies, and conflation between objective world
states and subjective belief states. Through deteiled analysis of DeepSeek-R1's
reasoning trajectories, we find that LLMs frequently encounter reasoning
impasses and tend to output contradictory terms like "tricky" and "confused"
when processing scenarios with multiple participants and timelines, leading to
erroneous reasoning or infinite loops. The core issue is their inability to
disentangle objective reality from agents' subjective beliefs. To address this,
we propose an adaptive world model-enhanced reasoning mechanism that constructs
a dynamic textual world model to track entity states and temporal sequences. It
dynamically monitors reasoning trajectories for confusion indicators and
promptly intervenes by providing clear world state descriptions, helping models
navigate through cognitive dilemmas. The mechanism mimics how humans use
implicit world models to distinguish between external events and internal
beliefs. Evaluations on three social benchmarks demonstrate significant
improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational
costs (up to 33.8% token reduction), offering a simple yet effective solution
for deploying LLMs in social contexts.

</details>


### [22] [SenWave: A Fine-Grained Multi-Language Sentiment Analysis Dataset Sourced from COVID-19 Tweets](https://arxiv.org/abs/2510.08214)
*Qiang Yang,Xiuying Chen,Changsheng Ma,Rui Yin,Xin Gao,Xiangliang Zhang*

Main category: cs.CL

TL;DR: SenWave是一个针对COVID-19推文的多语言细粒度情感分析数据集，包含10个情感类别，覆盖英语、阿拉伯语、西班牙语、法语和意大利语，并提供了基于预训练transformer模型的分类方法和ChatGPT兼容性评估。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行期间，虽然有大量公开数据集，但存在标注数据不足、情感标签粒度粗或不恰当的问题，需要更精细的情感分析来理解公众情绪变化。

Method: 构建了包含10,000条英语和阿拉伯语标注推文、30,000条翻译推文（西班牙语、法语、意大利语）以及1.05亿条未标注推文的SenWave数据集，使用预训练transformer模型进行细粒度情感分类。

Result: 实现了准确的情感分类，深入分析了不同语言、国家和主题的情绪演变，并验证了数据集与ChatGPT的兼容性，展示了其鲁棒性和多功能性。

Conclusion: SenWave数据集和代码已公开，将促进NLP社区对复杂事件的细粒度情感分析研究，推动更细致理解和研究创新。

Abstract: The global impact of the COVID-19 pandemic has highlighted the need for a
comprehensive understanding of public sentiment and reactions. Despite the
availability of numerous public datasets on COVID-19, some reaching volumes of
up to 100 billion data points, challenges persist regarding the availability of
labeled data and the presence of coarse-grained or inappropriate sentiment
labels. In this paper, we introduce SenWave, a novel fine-grained
multi-language sentiment analysis dataset specifically designed for analyzing
COVID-19 tweets, featuring ten sentiment categories across five languages. The
dataset comprises 10,000 annotated tweets each in English and Arabic, along
with 30,000 translated tweets in Spanish, French, and Italian, derived from
English tweets. Additionally, it includes over 105 million unlabeled tweets
collected during various COVID-19 waves. To enable accurate fine-grained
sentiment classification, we fine-tuned pre-trained transformer-based language
models using the labeled tweets. Our study provides an in-depth analysis of the
evolving emotional landscape across languages, countries, and topics, revealing
significant insights over time. Furthermore, we assess the compatibility of our
dataset with ChatGPT, demonstrating its robustness and versatility in various
applications. Our dataset and accompanying code are publicly accessible on the
repository\footnote{https://github.com/gitdevqiang/SenWave}. We anticipate that
this work will foster further exploration into fine-grained sentiment analysis
for complex events within the NLP community, promoting more nuanced
understanding and research innovations.

</details>


### [23] [Two-Stage Voting for Robust and Efficient Suicide Risk Detection on Social Media](https://arxiv.org/abs/2510.08365)
*Yukai Song,Pengfei Zhou,César Escobar-Viera,Candice Biernesser,Wei Huang,Jingtong Hu*

Main category: cs.CL

TL;DR: 提出两阶段投票架构用于自杀风险检测，第一阶段用轻量BERT处理明确案例，第二阶段用LLM投票或基于心理特征的ML集成处理隐晦案例，平衡效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 自杀率上升需要主动预防策略，社交媒体提供有价值信号，但检测隐晦自杀意念（通过隐喻、讽刺等间接表达）极具挑战，现有轻量模型无法处理隐晦信号，而大语言模型计算成本过高。

Method: 两阶段架构：第一阶段BERT分类器快速处理高置信度明确案例；第二阶段将模糊输入升级到多视角LLM投票框架或基于LLM提取心理特征指导的ML集成。

Result: 在两个互补数据集上表现优异：明确案例F1达98.0%，隐晦案例F1达99.7%，跨域差距低于2%，同时显著降低LLM成本。

Conclusion: 该框架在自杀风险检测中平衡了效率与鲁棒性，是首批将LLM提取的心理特征作为结构化向量用于自杀风险检测的工作之一。

Abstract: Suicide rates have risen worldwide in recent years, underscoring the urgent
need for proactive prevention strategies. Social media provides valuable
signals, as many at-risk individuals - who often avoid formal help due to
stigma - choose instead to share their distress online. Yet detecting implicit
suicidal ideation, conveyed indirectly through metaphor, sarcasm, or subtle
emotional cues, remains highly challenging. Lightweight models like BERT handle
explicit signals but fail on subtle implicit ones, while large language models
(LLMs) capture nuance at prohibitive computational cost. To address this gap,
we propose a two-stage voting architecture that balances efficiency and
robustness. In Stage 1, a lightweight BERT classifier rapidly resolves
high-confidence explicit cases. In Stage 2, ambiguous inputs are escalated to
either (i) a multi-perspective LLM voting framework to maximize recall on
implicit ideation, or (ii) a feature-based ML ensemble guided by
psychologically grounded indicators extracted via prompt-engineered LLMs for
efficiency and interpretability. To the best of our knowledge, this is among
the first works to operationalize LLM-extracted psychological features as
structured vectors for suicide risk detection. On two complementary datasets -
explicit-dominant Reddit and implicit-only DeepSuiMind - our framework
outperforms single-model baselines, achieving 98.0% F1 on explicit cases, 99.7%
on implicit ones, and reducing the cross-domain gap below 2%, while
significantly lowering LLM cost.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Differentiable Particle Optimization for Fast Sequential Manipulation](https://arxiv.org/abs/2510.07674)
*Lucas Chen,Shrutheesh Raman Iyer,Zachary Kingston*

Main category: cs.RO

TL;DR: SPaSM是一个完全GPU并行化的框架，通过将约束评估、采样和梯度优化编译为优化的CUDA内核，实现端到端的轨迹优化，无需CPU协调，在具有挑战性的基准测试中实现了毫秒级的求解时间和100%的成功率。


<details>
  <summary>Details</summary>
Motivation: 顺序机器人操作任务需要在可能的高维配置空间中找到满足多个物体交互几何约束的无碰撞轨迹。由于计算需求，实时和大规模解决这些问题一直难以实现。现有的GPU加速方法由于CPU-GPU数据传输开销和复杂逻辑导致性能有限。

Method: SPaSM采用两阶段粒子优化策略：首先通过大规模并行采样解决放置约束，然后将解决方案提升到关节空间中的完整轨迹优化。该方法将约束评估、采样和梯度优化编译为优化的CUDA内核，实现完全GPU并行化。

Result: 在具有挑战性的基准测试中，SPaSM实现了毫秒级的求解时间和100%的成功率，相比现有方法实现了4000倍的加速。

Conclusion: SPaSM通过完全GPU并行化和优化的CUDA内核，成功解决了顺序机器人操作任务的实时计算挑战，显著提升了求解速度和成功率。

Abstract: Sequential robot manipulation tasks require finding collision-free
trajectories that satisfy geometric constraints across multiple object
interactions in potentially high-dimensional configuration spaces. Solving
these problems in real-time and at large scales has remained out of reach due
to computational requirements. Recently, GPU-based acceleration has shown
promising results, but prior methods achieve limited performance due to CPU-GPU
data transfer overhead and complex logic that prevents full hardware
utilization. To this end, we present SPaSM (Sampling Particle optimization for
Sequential Manipulation), a fully GPU-parallelized framework that compiles
constraint evaluation, sampling, and gradient-based optimization into optimized
CUDA kernels for end-to-end trajectory optimization without CPU coordination.
The method consists of a two-stage particle optimization strategy: first
solving placement constraints through massively parallel sampling, then lifting
solutions to full trajectory optimization in joint space. Unlike hierarchical
approaches, SPaSM jointly optimizes object placements and robot trajectories to
handle scenarios where motion feasibility constrains placement options.
Experimental evaluation on challenging benchmarks demonstrates solution times
in the realm of $\textbf{milliseconds}$ with a 100% success rate; a
$4000\times$ speedup compared to existing approaches.

</details>


### [25] [DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation](https://arxiv.org/abs/2510.07865)
*Guowei Zou,Haitao Wang,Hejun Wu,Yukun Qian,Yuhang Wang,Weibing Li*

Main category: cs.RO

TL;DR: DM1提出了一种结合分散正则化的流匹配框架，解决流基策略中的表示崩溃问题，在保持一步生成效率的同时显著提升机器人操作性能


<details>
  <summary>Details</summary>
Motivation: 流基生成模型在机器人操作策略中具有采样效率优势，但存在表示崩溃问题，无法区分相似的视觉表示，导致精确操作任务失败

Method: 在MeanFlow中集成多种分散正则化变体，在不同中间嵌入层鼓励训练批次内的表示多样性，无需额外网络模块或专门训练过程

Result: 在RoboMimic基准测试中实现20-40倍推理加速(0.07s vs 2-3.5s)，成功率提升10-20个百分点，Lift任务达到99%成功率，真实机器人部署验证了从仿真到物理世界的有效迁移

Conclusion: 这是首个利用表示正则化使流基策略在机器人操作中实现强性能的工作，为高效鲁棒操作建立了简单而强大的方法

Abstract: The ability to learn multi-modal action distributions is indispensable for
robotic manipulation policies to perform precise and robust control. Flow-based
generative models have recently emerged as a promising solution to learning
distributions of actions, offering one-step action generation and thus
achieving much higher sampling efficiency compared to diffusion-based methods.
However, existing flow-based policies suffer from representation collapse, the
inability to distinguish similar visual representations, leading to failures in
precise manipulation tasks. We propose DM1 (MeanFlow with Dispersive
Regularization for One-Step Robotic Manipulation), a novel flow matching
framework that integrates dispersive regularization into MeanFlow to prevent
collapse while maintaining one-step efficiency. DM1 employs multiple dispersive
regularization variants across different intermediate embedding layers,
encouraging diverse representations across training batches without introducing
additional network modules or specialized training procedures. Experiments on
RoboMimic benchmarks show that DM1 achieves 20-40 times faster inference (0.07s
vs. 2-3.5s) and improves success rates by 10-20 percentage points, with the
Lift task reaching 99% success over 85% of the baseline. Real-robot deployment
on a Franka Panda further validates that DM1 transfers effectively from
simulation to the physical world. To the best of our knowledge, this is the
first work to leverage representation regularization to enable flow-based
policies to achieve strong performance in robotic manipulation, establishing a
simple yet powerful approach for efficient and robust manipulation.

</details>


### [26] [Scalable Offline Metrics for Autonomous Driving](https://arxiv.org/abs/2510.08571)
*Animikh Aich,Adwait Kulkarni,Eshed Ohn-Bar*

Main category: cs.RO

TL;DR: 该论文研究了感知规划模型在离线与在线评估之间的相关性，发现现有离线评估指标与在线性能相关性较差，提出基于认知不确定性的离线指标，显著提升了相关性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶等机器人系统的感知规划模型主要通过离线评估验证，但离线性能与在线实际表现之间的关联性研究不足，难以准确预测系统在真实环境中的表现。

Method: 通过大量仿真实验分析离线与在线评估的相关性，提出基于认知不确定性的离线评估指标，并在仿真和真实环境中验证其有效性。

Result: 发现离线与在线评估相关性比先前研究报道的更差，提出的新离线指标相比现有指标相关性提升超过13%，在真实环境中效果更显著。

Conclusion: 当前驾驶策略评估实践存在局限性，基于认知不确定性的离线指标能更好地桥接离线与在线评估的差距，为更可靠的政策评估提供新方法。

Abstract: Real-World evaluation of perception-based planning models for robotic
systems, such as autonomous vehicles, can be safely and inexpensively conducted
offline, i.e., by computing model prediction error over a pre-collected
validation dataset with ground-truth annotations. However, extrapolating from
offline model performance to online settings remains a challenge. In these
settings, seemingly minor errors can compound and result in test-time
infractions or collisions. This relationship is understudied, particularly
across diverse closed-loop metrics and complex urban maneuvers. In this work,
we revisit this undervalued question in policy evaluation through an extensive
set of experiments across diverse conditions and metrics. Based on analysis in
simulation, we find an even worse correlation between offline and online
settings than reported by prior studies, casting doubts on the validity of
current evaluation practices and metrics for driving policies. Next, we bridge
the gap between offline and online evaluation. We investigate an offline metric
based on epistemic uncertainty, which aims to capture events that are likely to
cause errors in closed-loop settings. The resulting metric achieves over 13%
improvement in correlation compared to previous offline metrics. We further
validate the generalization of our findings beyond the simulation environment
in real-world settings, where even greater gains are observed.

</details>
