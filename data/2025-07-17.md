<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 论文通过元分析和大规模实验，评估了步态识别年龄的技术，发现卷积神经网络误差最低（3.4年），并分析了步态特征与年龄的相关性。


<details>
  <summary>Details</summary>
Motivation: 步态识别年龄在医疗、安全和人机交互中有重要应用，但现有技术误差较大，需建立更准确的基线和方法。

Method: 结合元分析（59项研究）、大规模数据集（OU-ISIR和VersatileGait）和多种模型（CNN、SVM等），量化步态特征与年龄的关系。

Result: CNN误差最低（3.4年），步态特征与年龄相关性显著（相关系数≥0.27），深度学习模型准确率达96%。

Conclusion: 通过多传感器融合和深度学习，可将步态年龄误差降至3年以下，为实际应用提供可靠基线。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [2] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 论文提出了一种基于姿势的心理状态推断方法，通过板球运动验证其有效性，F1分数超过75%，AUC-ROC超过80%。


<details>
  <summary>Details</summary>
Motivation: 姿势推断在疲劳诊断、伤害预防和性能提升方面潜力巨大，但面临数据敏感性挑战。体育场景为多样化情绪数据提供了替代方案。

Method: 通过板球比赛中的姿势分析，结合运动视频识别击球意图，并利用现有数据统计作为弱监督验证。

Result: 方法在区分攻击性和防守性击球意图时表现优异，F1分数和AUC-ROC分别超过75%和80%。

Conclusion: 姿势分析为意图推断提供了强信号，弱监督方法可解决数据标注限制，为体育分析和行为分析开辟了新途径。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [3] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose是一个合成的基于事件的人体姿态估计数据集，用于固定行人感知，填补了真实数据不足的空白。


<details>
  <summary>Details</summary>
Motivation: 解决事件传感器在行人监测系统中数据不足的问题，尤其是在复杂条件下（如分心行走或异常运动）。

Method: 使用CARLA模拟器和动态视觉传感器生成SEPose数据集，包含近350K带注释的行人姿态关键点。

Result: SEPose数据集覆盖多种环境和条件，训练现有模型（如RVT和YOLOv8）并验证其从模拟到现实的泛化能力。

Conclusion: SEPose为事件传感器在行人监测中的应用提供了有效的数据支持，展示了模拟数据的实用性。

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [4] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 论文提出Dark-EvGS框架，利用事件相机和3D高斯泼溅技术，在低光环境下重建多视角明亮帧，解决了噪声、帧质量差和色调不一致问题。


<details>
  <summary>Details</summary>
Motivation: 传统相机在低光环境下难以捕捉清晰多视角图像，事件相机的高动态范围和高速度特性可解决这一问题。3D高斯泼溅技术虽有助于重建辐射场，但仍面临噪声、帧质量差和色调不一致的挑战。

Method: 提出Dark-EvGS框架，通过三重监督学习获取整体知识和细节，引入色调匹配模块保证帧间颜色一致性，并创建首个真实数据集用于实验验证。

Result: 实验表明，Dark-EvGS在低光条件下优于现有方法，成功重建辐射场并生成高质量明亮帧。

Conclusion: Dark-EvGS为低光环境下的多视角图像重建提供了一种有效解决方案，具有实际应用潜力。

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [5] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入OoD数据监督，解决了医学图像分割中前景与背景误分类的问题，无需外部数据、特征正则化或额外标注。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割网络在有限和不完美的数据集上容易发生前景与背景的误分类，需要一种无需额外资源的方法来提升性能。

Method: 提出Med-OoD框架，将OoD数据监督引入全监督医学图像分割，无需外部数据、特征正则化或额外标注，且可直接集成到现有网络架构中。

Result: 实验表明，Med-OoD显著减少了像素误分类，并在Lizard数据集上实现了显著性能提升。此外，仅使用OoD数据训练的网络达到了76.1%的mIoU。

Conclusion: Med-OoD为医学图像分割提供了一种高效的数据中心化解决方案，并展示了OoD数据在分割任务中的潜力。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [6] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 论文提出了三种创新技术（分形卷积、自敏感瓷砖填充和超分辨率）用于印度古迹的保护与修复，结合计算机视觉和机器学习，实现了高效且经济的自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代数字化方法改变了文化遗产保护的范式，但印度古迹的特殊性需要更高效且创新的技术来平衡传统与创新。

Method: 1. 分形卷积方法用于图像分割；2. 自敏感瓷砖填充（SSTF）结合数据增强技术MosaicSlice；3. 超分辨率技术提升图像质量。

Result: 提出的方法实现了无缝区域填充和高细节瓷砖生成，同时保持真实性和低成本自动化。

Conclusion: 这些技术为文化遗产保护提供了高效且美观的解决方案，推动了传统与创新的平衡发展。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [7] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 该研究开发了一种基于深度学习的模型，利用出生24小时内的胸部X光片预测极低出生体重婴儿的支气管肺发育不良（BPD）结局。


<details>
  <summary>Details</summary>
Motivation: BPD是一种慢性肺病，影响35%的极低出生体重婴儿，且预防措施可能带来严重风险。早期预测BPD结局可避免不必要的毒性干预。

Method: 研究使用163名极低出生体重婴儿的胸部X光片，微调了预训练的ResNet-50模型，采用渐进层冻结、CutMix增强和线性探测技术。

Result: 最佳模型在预测中度/重度BPD时，AUROC为0.78，平衡准确率为0.69，F1分数为0.67。域内预训练显著优于ImageNet初始化。

Conclusion: 研究表明，域特异性预训练结合渐进冻结和线性探测，可从常规X光片中准确预测BPD，且计算效率高，适合临床部署。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery](https://arxiv.org/abs/2507.11570)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.LG

TL;DR: 开发并评估了用于预测脊柱手术住院时间的机器学习模型，重点研究了时间建模和模型可解释性的优势。


<details>
  <summary>Details</summary>
Motivation: 提高脊柱手术住院时间预测的准确性和可解释性，以支持临床决策和医院规划。

Method: 比较了传统机器学习模型（如线性回归、随机森林、SVM和XGBoost）与开发的SurgeryLSTM模型（带注意力机制的BiLSTM），使用结构化电子健康记录数据。

Result: SurgeryLSTM预测准确率最高（R2=0.86），优于XGBoost（R2=0.85）和其他基线模型。注意力机制提高了可解释性，动态识别术前临床序列中的关键时间片段。

Conclusion: SurgeryLSTM是一种高效且可解释的AI解决方案，支持将时间建模和可解释性方法整合到临床决策支持系统中。

Abstract: Objective: To develop and evaluate machine learning (ML) models for
predicting length of stay (LOS) in elective spine surgery, with a focus on the
benefits of temporal modeling and model interpretability. Materials and
Methods: We compared traditional ML models (e.g., linear regression, random
forest, support vector machine (SVM), and XGBoost) with our developed model,
SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an
attention, using structured perioperative electronic health records (EHR) data.
Performance was evaluated using the coefficient of determination (R2), and key
predictors were identified using explainable AI. Results: SurgeryLSTM achieved
the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)
and baseline models. The attention mechanism improved interpretability by
dynamically identifying influential temporal segments within preoperative
clinical sequences, allowing clinicians to trace which events or features most
contributed to each LOS prediction. Key predictors of LOS included bone
disorder, chronic kidney disease, and lumbar fusion identified as the most
impactful predictors of LOS. Discussion: Temporal modeling with attention
mechanisms significantly improves LOS prediction by capturing the sequential
nature of patient data. Unlike static models, SurgeryLSTM provides both higher
accuracy and greater interpretability, which are critical for clinical
adoption. These results highlight the potential of integrating attention-based
temporal models into hospital planning workflows. Conclusion: SurgeryLSTM
presents an effective and interpretable AI solution for LOS prediction in
elective spine surgery. Our findings support the integration of temporal,
explainable ML approaches into clinical decision support systems to enhance
discharge readiness and individualized patient care.

</details>


### [9] [Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification](https://arxiv.org/abs/2507.11620)
*Steven Dillmann,Juan Rafael Martínez-Galarza*

Main category: cs.LG

TL;DR: 论文提出了一种基于张量表示和稀疏自编码器的方法，用于处理不规则事件时间序列，并在X射线天文学数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 事件时间序列在多个领域中普遍存在，但其不规则性使得传统方法难以提取有意义模式。

Method: 采用二维和三维张量表示事件时间序列，结合稀疏自编码器学习物理意义的潜在表示。

Result: 方法成功捕获了X射线瞬变的时间和频谱特征，支持多种下游任务。

Conclusion: 该框架为跨领域的不规则事件时间序列分析提供了灵活、可扩展的解决方案。

Abstract: Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.

</details>


### [10] [HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction](https://arxiv.org/abs/2507.11836)
*Jian Gao,Jianshe Wu,JingYi Ding*

Main category: cs.LG

TL;DR: 论文提出HyperEvent框架，将动态链接预测重构为超事件识别，通过事件相关性向量动态构建关联序列，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法捕捉复合超事件的结构凝聚力，限制了动态图建模能力。

Method: 提出HyperEvent框架，利用事件相关性向量动态构建关联序列，评估查询事件与历史事件是否形成有效超事件。

Result: 在5个数据集中4个表现最佳，大规模Flight数据集上MRR提升6.95%，训练时间仅需10.17%。

Conclusion: HyperEvent在准确性和效率上均优于现有方法，适用于大规模动态图建模。

Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental
task for modeling evolving complex systems. Existing node-centric and
event-centric methods focus on individual interactions or atomic states,
failing to capture the structural cohesion of composite hyper-events, groups of
causally related events. To address this, we propose HyperEvent, a framework
reframing dynamic link prediction as hyper-event recognition. Central to
HyperEvent is the dynamic construction of an association sequence using event
correlation vectors. These vectors quantify pairwise dependencies between the
query event and relevant historical events, thereby characterizing the
structural cohesion of a potential hyper-event. The framework predicts the
occurrence of the query event by evaluating whether it collectively forms a
valid hyper-event with these historical events. Notably, HyperEvent outperforms
state-of-the-art methods on 4 out of 5 datasets in the official leaderboard.
For scalability, we further introduce an efficient parallel training algorithm
that segments large event streams to enable concurrent training. Experiments
validate HyperEvent's superior accuracy and efficiency on large-scale graphs.
Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank
over state-of-the-art baseline on the large-scale Flight dataset while
utilizing only 10.17% of the training time.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways](https://arxiv.org/abs/2507.11621)
*Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 本文提出了一种分层协作式匝道合流控制（HCOMC）框架，用于解决混合交通流中的合流问题，结合纵向跟驰模型和横向换道模型，并通过仿真验证了其安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道合流区是交通拥堵和事故的常见瓶颈，而联网自动驾驶车辆（CAVs）尚未普及，因此需要一种适用于混合交通流的协作控制策略。

Method: 扩展了基于智能驾驶员模型的纵向跟驰模型和基于五次多项式曲线的横向换道模型，提出了HCOMC框架，包括分层协作规划模型、基于博弈论的自由换道模型和多目标优化模型。

Result: 仿真结果表明，HCOMC在提升车辆群安全性、稳定和加速合流过程、优化交通效率和节约燃油消耗方面具有显著优势。

Conclusion: HCOMC框架为混合交通流中的匝道合流问题提供了一种高效、安全的解决方案，尤其在CAV普及率较低的情况下表现突出。

Abstract: Highway on-ramp merging areas are common bottlenecks to traffic congestion
and accidents. Currently, a cooperative control strategy based on connected and
automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs
are not fully widespread, it is necessary to propose a hierarchical cooperative
on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on
two-lane highways to address this gap. This paper extends longitudinal
car-following models based on the intelligent driver model and lateral
lane-changing models using the quintic polynomial curve to account for
human-driven vehicles (HDVs) and CAVs, comprehensively considering human
factors and cooperative adaptive cruise control. Besides, this paper proposes a
HCOMC framework, consisting of a hierarchical cooperative planning model based
on the modified virtual vehicle model, a discretionary lane-changing model
based on game theory, and a multi-objective optimization model using the
elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and
efficient merging process. Then, the performance of our HCOMC is analyzed under
different traffic densities and CAV penetration rates through simulation. The
findings underscore our HCOMC's pronounced comprehensive advantages in
enhancing the safety of group vehicles, stabilizing and expediting merging
process, optimizing traffic efficiency, and economizing fuel consumption
compared with benchmarks.

</details>
