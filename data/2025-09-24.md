<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization on the Kvasir Dataset](https://arxiv.org/abs/2509.18159)
*Akwasi Asare,Ulas Bagci*

Main category: cs.CV

TL;DR: 本文提出PolypSeg-GradCAM框架，结合U-Net和Grad-CAM实现可解释的息肉分割，在Kvasir-SEG数据集上取得优异性能（IoU 0.9257），增强AI辅助结肠镜检查的可信度。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌是全球主要癌症死因，胃肠道息肉是关键前兆。现有深度学习分割方法准确性高但可解释性差，阻碍临床应用。

Method: 集成U-Net架构和梯度加权类激活映射(Grad-CAM)，在1000张标注内镜图像的Kvasir-SEG数据集上训练评估。

Result: 测试集平均IoU达0.9257，训练和验证集Dice系数均高于0.96，Grad-CAM可视化确认预测基于临床相关区域。

Conclusion: PolypSeg-GradCAM将高分割精度与可解释性结合，是迈向可靠AI辅助结肠镜检查和早期结直肠癌预防的重要一步。

Abstract: Colorectal cancer (CRC) remains one of the leading causes of cancer-related
morbidity and mortality worldwide, with gastrointestinal (GI) polyps serving as
critical precursors according to the World Health Organization (WHO). Early and
accurate segmentation of polyps during colonoscopy is essential for reducing
CRC progression, yet manual delineation is labor-intensive and prone to
observer variability. Deep learning methods have demonstrated strong potential
for automated polyp analysis, but their limited interpretability remains a
barrier to clinical adoption. In this study, we present PolypSeg-GradCAM, an
explainable deep learning framework that integrates the U-Net architecture with
Gradient-weighted Class Activation Mapping (Grad-CAM) for transparent polyp
segmentation. The model was trained and evaluated on the Kvasir-SEG dataset of
1000 annotated endoscopic images. Experimental results demonstrate robust
segmentation performance, achieving a mean Intersection over Union (IoU) of
0.9257 on the test set and consistently high Dice coefficients (F-score > 0.96)
on training and validation sets. Grad-CAM visualizations further confirmed that
predictions were guided by clinically relevant regions, enhancing transparency
and trust in the model's decisions. By coupling high segmentation accuracy with
interpretability, PolypSeg-GradCAM represents a step toward reliable,
trustworthy AI-assisted colonoscopy and improved early colorectal cancer
prevention.

</details>


### [2] [AI-Derived Structural Building Intelligence for Urban Resilience: An Application in Saint Vincent and the Grenadines](https://arxiv.org/abs/2509.18182)
*Isabelle Tingzon,Yoji Toriumi,Caroline Gevaert*

Main category: cs.CV

TL;DR: AI驱动的工作流，利用高分辨率卫星影像自动推断屋顶属性，为小岛屿发展中国家提供建筑结构信息以支持灾害风险评估


<details>
  <summary>Details</summary>
Motivation: 解决小岛屿发展中国家缺乏详细建筑结构信息的问题，这些信息对于评估飓风、洪水等灾害风险至关重要

Method: 比较地理空间基础模型结合浅层分类器与微调深度学习模型在屋顶分类中的效果，并评估加入邻近岛屿训练数据对模型性能的影响

Result: 最佳模型在屋顶坡度和屋顶材料分类上分别达到0.88和0.83的F1分数

Conclusion: 结合本地能力建设，该工作为小岛屿发展中国家提供了利用AI和地球观测数据实现更高效、基于证据的城市治理的新能力

Abstract: Detailed structural building information is used to estimate potential damage
from hazard events like cyclones, floods, and landslides, making them critical
for urban resilience planning and disaster risk reduction. However, such
information is often unavailable in many small island developing states (SIDS)
in climate-vulnerable regions like the Caribbean. To address this data gap, we
present an AI-driven workflow to automatically infer rooftop attributes from
high-resolution satellite imagery, with Saint Vincent and the Grenadines as our
case study. Here, we compare the utility of geospatial foundation models
combined with shallow classifiers against fine-tuned deep learning models for
rooftop classification. Furthermore, we assess the impact of incorporating
additional training data from neighboring SIDS to improve model performance.
Our best models achieve F1 scores of 0.88 and 0.83 for roof pitch and roof
material classification, respectively. Combined with local capacity building,
our work aims to provide SIDS with novel capabilities to harness AI and Earth
Observation (EO) data to enable more efficient, evidence-based urban
governance.

</details>


### [3] [URNet: Uncertainty-aware Refinement Network for Event-based Stereo Depth Estimation](https://arxiv.org/abs/2509.18184)
*Yifeng Cheng,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: 本文提出了一种基于事件相机的立体深度估计方法URNet，通过局部-全局精炼模块和KL散度不确定性建模，在DSEC数据集上超越了现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率、高动态范围和低延迟的优势，但现有的立体深度估计方法在细节捕捉和预测可靠性方面仍有改进空间。

Method: 提出了URNet不确定性感知精炼网络，包含局部-全局精炼模块来捕捉细粒度局部细节和长距离全局上下文，以及基于KL散度的不确定性建模方法。

Result: 在DSEC数据集上的大量实验表明，URNet在定性和定量评估中都一致优于最先进的方法。

Conclusion: URNet通过有效的精炼机制和不确定性建模，显著提升了事件相机立体深度估计的性能和可靠性。

Abstract: Event cameras provide high temporal resolution, high dynamic range, and low
latency, offering significant advantages over conventional frame-based cameras.
In this work, we introduce an uncertainty-aware refinement network called URNet
for event-based stereo depth estimation. Our approach features a local-global
refinement module that effectively captures fine-grained local details and
long-range global context. Additionally, we introduce a Kullback-Leibler (KL)
divergence-based uncertainty modeling method to enhance prediction reliability.
Extensive experiments on the DSEC dataset demonstrate that URNet consistently
outperforms state-of-the-art (SOTA) methods in both qualitative and
quantitative evaluations.

</details>


### [4] [Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction](https://arxiv.org/abs/2509.18566)
*Xiaoting Yin,Hao Shi,Kailun Yang,Jiajun Zhai,Shangwei Guo,Lin Wang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种基于事件相机和3D高斯泼溅的单目视频动态人体与静态场景联合重建框架，通过事件引导的损失函数解决快速运动下的运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 从单目视频中重建动态人体和静态场景存在困难，特别是在快速运动时RGB帧会出现运动模糊。事件相机具有微秒级时间分辨率的优势，更适合动态人体重建。

Method: 使用统一的3D高斯集合，其中包含可学习的语义属性；只有被分类为人体的高斯会进行形变动画，场景高斯保持静态。提出事件引导损失函数，匹配连续渲染之间的模拟亮度变化与事件流。

Result: 在两个基准数据集ZJU-MoCap-Blur和MMHPSD-Blur上实现了最先进的人体-场景重建效果，在PSNR/SSIM指标上显著优于强基线，LPIPS指标降低，特别是对高速运动主体效果更佳。

Conclusion: 该方法无需外部人体掩码，简化了单独高斯集合的管理，在快速运动场景下能够有效提升重建质量。

Abstract: Reconstructing dynamic humans together with static scenes from monocular
videos remains difficult, especially under fast motion, where RGB frames suffer
from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond
temporal resolution, making them a superior sensing choice for dynamic human
reconstruction. Accordingly, we present a novel event-guided human-scene
reconstruction framework that jointly models human and scene from a single
monocular event camera via 3D Gaussian Splatting. Specifically, a unified set
of 3D Gaussians carries a learnable semantic attribute; only Gaussians
classified as human undergo deformation for animation, while scene Gaussians
stay static. To combat blur, we propose an event-guided loss that matches
simulated brightness changes between consecutive renderings with the event
stream, improving local fidelity in fast-moving regions. Our approach removes
the need for external human masks and simplifies managing separate Gaussian
sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers
state-of-the-art human-scene reconstruction, with notable gains over strong
baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

</details>


### [5] [Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought](https://arxiv.org/abs/2509.18571)
*Yuhan Wang,Cheng Liu,Zihan Zhao,Weichao Wu*

Main category: cs.CV

TL;DR: Live-E2T是一个实时威胁监控框架，通过结构化语义元组、在线事件去重和基于大语言模型的推理机制，同时实现了实时性能和决策可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时满足实时性能和决策可解释性的要求，需要一种能够统一这两个目标的新框架。

Method: 1. 将视频帧解构为结构化的人-物-交互-地点语义元组；2. 提出高效的在线事件去重和更新机制；3. 使用思维链策略微调大语言模型进行透明推理。

Result: 在XD-Violence和UCF-Crime等基准数据集上的实验表明，Live-E2T在威胁检测准确性、实时效率和可解释性方面显著优于现有最优方法。

Conclusion: Live-E2T成功解决了实时威胁监控中实时性能与可解释性之间的权衡问题，为实际应用提供了有效的解决方案。

Abstract: Real-time threat monitoring identifies threatening behaviors in video streams
and provides reasoning and assessment of threat events through explanatory
text. However, prevailing methodologies, whether based on supervised learning
or generative models, struggle to concurrently satisfy the demanding
requirements of real-time performance and decision explainability. To bridge
this gap, we introduce Live-E2T, a novel framework that unifies these two
objectives through three synergistic mechanisms. First, we deconstruct video
frames into structured Human-Object-Interaction-Place semantic tuples. This
approach creates a compact, semantically focused representation, circumventing
the information degradation common in conventional feature compression. Second,
an efficient online event deduplication and updating mechanism is proposed to
filter spatio-temporal redundancies, ensuring the system's real time
responsiveness. Finally, we fine-tune a Large Language Model using a
Chain-of-Thought strategy, endow it with the capability for transparent and
logical reasoning over event sequences to produce coherent threat assessment
reports. Extensive experiments on benchmark datasets, including XD-Violence and
UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art
methods in terms of threat detection accuracy, real-time efficiency, and the
crucial dimension of explainability.

</details>


### [6] [Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network](https://arxiv.org/abs/2509.18591)
*Pengchao Deng,Shengqi Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于XMem模型的实时MRI引导放疗肿瘤分割框架，用于TrackRAD2025挑战赛，能够在长序列cine-MRI中实时跟踪肿瘤运动。


<details>
  <summary>Details</summary>
Motivation: 提高MRI引导放疗中肿瘤跟踪的精度，这对于提升癌症治疗的准确性和安全性至关重要。

Method: 利用XMem模型的内存增强架构，在长序列cine-MRI中分割肿瘤，通过高效集成内存机制实现实时肿瘤运动跟踪。

Result: 由于实验记录丢失，无法报告精确的定量结果，但初步开发印象显示XMem框架表现出合理的分割性能并满足临床实时要求。

Conclusion: 该工作有助于改善MRI引导放疗中的肿瘤跟踪精度，为癌症治疗的安全性和准确性做出贡献。

Abstract: This paper presents an advanced tumor segmentation framework for real-time
MRI-guided radiotherapy, designed for the TrackRAD2025 challenge. Our method
leverages the XMem model, a memory-augmented architecture, to segment tumors
across long cine-MRI sequences. The proposed system efficiently integrates
memory mechanisms to track tumor motion in real-time, achieving high
segmentation accuracy even under challenging conditions with limited annotated
data. Unfortunately, the detailed experimental records have been lost,
preventing us from reporting precise quantitative results at this stage.
Nevertheless, From our preliminary impressions during development, the
XMem-based framework demonstrated reasonable segmentation performance and
satisfied the clinical real-time requirement. Our work contributes to improving
the precision of tumor tracking during MRI-guided radiotherapy, which is
crucial for enhancing the accuracy and safety of cancer treatments.

</details>


### [7] [Prompt-Guided Dual Latent Steering for Inversion Problems](https://arxiv.org/abs/2509.18619)
*Yichen Wu,Xu Liu,Chenxuan Zhao,Xinyu Wu*

Main category: cs.CV

TL;DR: PDLS是一种基于Rectified Flow模型的训练免费框架，通过双潜在空间引导解决扩散模型图像反演中的语义漂移问题，在保持结构完整性的同时提升语义准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于单潜在向量的图像反演方法难以平衡结构保真度和语义准确性，导致重建图像出现语义漂移问题，如细节模糊或属性错误。

Method: PDLS将反演过程分解为结构路径和语义路径，通过线性二次调节器(LQR)形成最优控制问题的闭式解，在生成轨迹的每一步动态引导，避免语义漂移。

Result: 在FFHQ-1K和ImageNet-1K数据集上的多种反演任务实验表明，PDLS相比单潜在基线方法能产生更忠实于原图且语义信息更准确的重建结果。

Conclusion: PDLS框架通过双潜在空间引导机制有效解决了扩散模型图像反演中的语义漂移问题，无需昂贵的逐图像优化即可实现高质量重建。

Abstract: Inverting corrupted images into the latent space of diffusion models is
challenging. Current methods, which encode an image into a single latent
vector, struggle to balance structural fidelity with semantic accuracy, leading
to reconstructions with semantic drift, such as blurred details or incorrect
attributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering
(PDLS), a novel, training-free framework built upon Rectified Flow models for
their stable inversion paths. PDLS decomposes the inversion process into two
complementary streams: a structural path to preserve source integrity and a
semantic path guided by a prompt. We formulate this dual guidance as an optimal
control problem and derive a closed-form solution via a Linear Quadratic
Regulator (LQR). This controller dynamically steers the generative trajectory
at each step, preventing semantic drift while ensuring the preservation of fine
detail without costly, per-image optimization. Extensive experiments on FFHQ-1K
and ImageNet-1K under various inversion tasks, including Gaussian deblurring,
motion deblurring, super-resolution and freeform inpainting, demonstrate that
PDLS produces reconstructions that are both more faithful to the original image
and better aligned with the semantic information than single-latent baselines.

</details>


### [8] [DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring](https://arxiv.org/abs/2509.18898)
*Pengteng Li,Yunfan Lu,Pinhao Song,Weiyu Guo,Huizai Yao,F. Richard Yu,Hui Xiong*

Main category: cs.CV

TL;DR: 提出首个无需Structure-from-Motion的运动去模糊3D高斯泼溅方法DeblurSplat，利用事件相机解决运动模糊问题


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖SfM计算相机位姿，但运动模糊会导致位姿估计不准确，进而影响点云质量。事件相机对动态变化高度敏感，能提供更好的去模糊监督信号

Method: 1) 使用预训练的稠密立体模块(DUSt3R)直接从模糊图像获取准确初始点云，避免相机位姿累积误差；2) 引入事件流到去模糊流程，通过解码事件流和模糊图像的潜在清晰图像，为场景重建优化提供细粒度监督

Result: 在多种场景下的广泛实验表明，DeblurSplat不仅能生成高保真度的新视角，而且在去模糊3D-GS方面相比现有技术实现了显著的渲染效率提升

Conclusion: 该方法成功解决了运动模糊问题，无需SfM流程，结合事件相机的优势，在渲染质量和效率方面都优于现有技术

Abstract: In this paper, we propose the first Structure-from-Motion (SfM)-free
deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.
We address the motion-deblurring problem in two ways. First, we leverage the
pretrained capability of the dense stereo module (DUSt3R) to directly obtain
accurate initial point clouds from blurred images. Without calculating camera
poses as an intermediate result, we avoid the cumulative errors transfer from
inaccurate camera poses to the initial point clouds' positions. Second, we
introduce the event stream into the deblur pipeline for its high sensitivity to
dynamic change. By decoding the latent sharp images from the event stream and
blurred images, we can provide a fine-grained supervision signal for scene
reconstruction optimization. Extensive experiments across a range of scenes
demonstrate that DeblurSplat not only excels in generating high-fidelity novel
views but also achieves significant rendering efficiency compared to the SOTAs
in deblur 3D-GS.

</details>


### [9] [NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit](https://arxiv.org/abs/2509.19156)
*Maurf Hassan,Steven Davy,Muhammad Zawish,Owais Bin Zuber,Nouman Ashraf*

Main category: cs.CV

TL;DR: NeuCODEX是一种神经形态协同推理架构，通过联合优化空间和时间冗余，显著减少数据传输和边缘能耗，同时降低端到端延迟，实现资源受限环境中的高效SNN部署。


<details>
  <summary>Details</summary>
Motivation: 解决脉冲神经网络在边缘设备上推理时因固定高时间步开销导致的延迟和能耗问题，以及边缘-云协同推理系统中高延迟和特征传输成本的问题。

Method: 引入学习型脉冲驱动压缩模块减少数据传输，采用动态提前退出机制根据输出置信度自适应终止推理，在真实边缘到云测试平台上基于ResNet-18和VGG-16骨干网络进行原型验证。

Result: 数据传输减少高达2048倍，边缘能耗降低超过90%，端到端延迟相比仅边缘推理降低3倍，准确率下降小于2%。

Conclusion: NeuCODEX能够在资源受限环境中实现实用、高性能的SNN部署。

Abstract: Spiking Neural Networks (SNNs) offer significant potential for enabling
energy-efficient intelligence at the edge. However, performing full SNN
inference at the edge can be challenging due to the latency and energy
constraints arising from fixed and high timestep overheads. Edge-cloud
co-inference systems present a promising solution, but their deployment is
often hindered by high latency and feature transmission costs. To address these
issues, we introduce NeuCODEX, a neuromorphic co-inference architecture that
jointly optimizes both spatial and temporal redundancy. NeuCODEX incorporates a
learned spike-driven compression module to reduce data transmission and employs
a dynamic early-exit mechanism to adaptively terminate inference based on
output confidence. We evaluated NeuCODEX on both static images (CIFAR10 and
Caltech) and neuromorphic event streams (CIFAR10-DVS and N-Caltech). To
demonstrate practicality, we prototyped NeuCODEX on ResNet-18 and VGG-16
backbones in a real edge-to-cloud testbed. Our proposed system reduces data
transfer by up to 2048x and edge energy consumption by over 90%, while reducing
end-to-end latency by up to 3x compared to edge-only inference, all with a
negligible accuracy drop of less than 2%. In doing so, NeuCODEX enables
practical, high-performance SNN deployment in resource-constrained
environments.

</details>


### [10] [DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces](https://arxiv.org/abs/2509.19230)
*Tianshuo Zhang,Li Gao,Siran Peng,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 该论文提出了一种基于持续学习的面部伪造检测方法，通过开发性专家混合架构来应对不断演变的伪造技术，使用LoRA模型作为专家来学习真实面部和不同伪造类型。


<details>
  <summary>Details</summary>
Motivation: 随着数字面部生成和操纵技术的快速发展，现有的检测模型难以跟上不断演变的伪造技术。需要一种能够快速适应新领域、避免遗忘已学知识的检测方法。

Method: 采用开发性专家混合架构，使用LoRA模型作为个体专家。专家分为两组：Real-LoRA学习真实面部知识，多个Fake-LoRA捕获不同伪造类型的增量信息。通过正交学习方向和正交梯度来防止灾难性遗忘。

Result: 在数据集和操纵类型增量协议下的实验结果表明该方法有效，能够持续学习新伪造类型而不遗忘旧知识。

Conclusion: 该方法成功地将面部伪造检测构建为持续学习问题，通过开发性MoE架构实现了对新伪造类型的快速适应和对已学知识的保持。

Abstract: The rise of realistic digital face generation and manipulation poses
significant social risks. The primary challenge lies in the rapid and diverse
evolution of generation techniques, which often outstrip the detection
capabilities of existing models. To defend against the ever-evolving new types
of forgery, we need to enable our model to quickly adapt to new domains with
limited computation and data while avoiding forgetting previously learned
forgery types. In this work, we posit that genuine facial samples are abundant
and relatively stable in acquisition methods, while forgery faces continuously
evolve with the iteration of manipulation techniques. Given the practical
infeasibility of exhaustively collecting all forgery variants, we frame face
forgery detection as a continual learning problem and allow the model to
develop as new forgery types emerge. Specifically, we employ a Developmental
Mixture of Experts (MoE) architecture that uses LoRA models as its individual
experts. These experts are organized into two groups: a Real-LoRA to learn and
refine knowledge of real faces, and multiple Fake-LoRAs to capture incremental
information from different forgery types. To prevent catastrophic forgetting,
we ensure that the learning direction of Fake-LoRAs is orthogonal to the
established subspace. Moreover, we integrate orthogonal gradients into the
orthogonal loss of Fake-LoRAs, preventing gradient interference throughout the
training process of each task. Experimental results under both the datasets and
manipulation types incremental protocols demonstrate the effectiveness of our
method.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [BULL-ODE: Bullwhip Learning with Neural ODEs and Universal Differential Equations under Stochastic Demand](https://arxiv.org/abs/2509.18105)
*Nachiket N. Naik,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.LG

TL;DR: 该研究比较了完全学习的神经ODE与物理信息通用微分方程在连续时间库存动力学预测中的表现，发现在结构化需求机制下UDE泛化更好，而在重尾分布下NODE更灵活。


<details>
  <summary>Details</summary>
Motivation: 研究结构约束在牛鞭效应预测中何时有帮助或有害，解决在混合建模中是否应该强制执行已知结构的问题。

Method: 使用单级测试平台，比较完全学习的NODE和保留守恒结构的UDE，在三种需求机制（AR(1)、高斯i.i.d.、重尾对数正态）下训练和评估多步预测。

Result: 在结构化机制下，UDE表现更好（库存RMSE从4.92降至0.26）；在重尾机制下，NODE更灵活。训练数据减少时，NODE出现相位漂移，UDE保持稳定但对罕见峰值反应不足。

Conclusion: 当噪声轻尾或时间相关时强制执行结构约束；当极端事件主导时放松结构约束。这为科学和工程系统中的混合建模提供了具体指导。

Abstract: We study learning of continuous-time inventory dynamics under stochastic
demand and quantify when structure helps or hurts forecasting of the bullwhip
effect. BULL-ODE compares a fully learned Neural ODE (NODE) that models the
entire right-hand side against a physics-informed Universal Differential
Equation (UDE) that preserves conservation and order-up-to structure while
learning a small residual policy term. Classical supply chain models explain
the bullwhip through control/forecasting choices and information sharing, while
recent physics-informed and neural differential equation methods blend domain
constraints with learned components. It is unclear whether structural bias
helps or hinders forecasting under different demand regimes. We address this by
using a single-echelon testbed with three demand regimes - AR(1)
(autocorrelated), i.i.d. Gaussian, and heavy-tailed lognormal. Training is done
on varying fractions of each trajectory, followed by evaluation of multi-step
forecasts for inventory I, order rate O, and demand D. Across the structured
regimes, UDE consistently generalizes better: with 90% of the training horizon,
inventory RMSE drops from 4.92 (NODE) to 0.26 (UDE) under AR(1) and from 5.96
to 0.95 under Gaussian demand. Under heavy-tailed lognormal shocks, the
flexibility of NODE is better. These trends persist as train18 ing data
shrinks, with NODE exhibiting phase drift in extrapolation while UDE remains
stable but underreacts to rare spikes. Our results provide concrete guidance:
enforce structure when noise is light-tailed or temporally correlated; relax
structure when extreme events dominate. Beyond inventory control, the results
offer guidance for hybrid modeling in scientific and engineering systems:
enforce known structure when conservation laws and modest noise dominate, and
relax structure to capture extremes in settings where rare events drive
dynamics.

</details>


### [12] [Self-Evolving LLMs via Continual Instruction Tuning](https://arxiv.org/abs/2509.18133)
*Le Huang,Jiazheng Kang,Cheng Hou,Zhe Zhao,Zhenxiang Yan,Chuan Shi,Ting Bai*

Main category: cs.LG

TL;DR: MoE-CL是一个参数高效的对抗性专家混合框架，用于工业规模的大语言模型持续指令调优，通过双专家设计和GAN鉴别器来平衡知识保留和跨任务泛化。


<details>
  <summary>Details</summary>
Motivation: 解决工业环境中大语言模型持续学习时的灾难性遗忘问题，现有方法在新任务训练时会过度拟合新分布并削弱泛化能力。

Method: 采用双LoRA专家设计：专用专家保留任务特定知识，共享专家实现跨任务迁移；集成任务感知鉴别器通过对抗学习确保共享专家只传递任务相关信息。

Result: 在MTL5基准和腾讯工业基准上的实验验证了有效性，在腾讯视频平台的内容合规审查A/B测试中减少了15.3%的人工审核成本。

Conclusion: MoE-CL适用于需要持续适应和稳定迁移的大规模工业部署场景，具有实际应用价值。

Abstract: In real-world industrial settings, large language models (LLMs) must learn
continually to keep pace with diverse and evolving tasks, requiring
self-evolution to refine knowledge under dynamic data distributions. However,
existing continual learning (CL) approaches, such as replay and parameter
isolation, often suffer from catastrophic forgetting: training on new tasks
degrades performance on earlier ones by overfitting to the new distribution and
weakening generalization.We propose MoE-CL, a parameter-efficient adversarial
mixture-of-experts framework for industrial-scale, self-evolving continual
instruction tuning of LLMs. MoE-CL uses a dual-expert design: (1) a dedicated
LoRA expert per task to preserve task-specific knowledge via parameter
independence, mitigating forgetting; and (2) a shared LoRA expert to enable
cross-task transfer. To prevent transferring task-irrelevant noise through the
shared pathway, we integrate a task-aware discriminator within a GAN. The
discriminator encourages the shared expert to pass only task-aligned
information during sequential training. Through adversarial learning, the
shared expert acquires generalized representations that mimic the
discriminator, while dedicated experts retain task-specific details, balancing
knowledge retention and cross-task generalization and thereby supporting
self-evolution.Extensive experiments on the public MTL5 benchmark and an
industrial Tencent3 benchmark validate the effectiveness of MoE-CL for
continual instruction tuning. In real-world A/B testing for content compliance
review on the Tencent Video platform, MoE-CL reduced manual review costs by
15.3%. These results demonstrate that MoE-CL is practical for large-scale
industrial deployment where continual adaptation and stable transfer are
critical.

</details>


### [13] [Graph Enhanced Trajectory Anomaly Detection](https://arxiv.org/abs/2509.18386)
*Jonathan Kabala Mbuya,Dieter Pfoser,Antonios Anastasopoulos*

Main category: cs.LG

TL;DR: 提出GETAD框架，通过图注意力网络和Transformer解码器结合道路网络拓扑、语义和历史模式进行轨迹异常检测，引入CW NLL评分函数提高检测鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有轨迹异常检测方法仅考虑轨迹的采样位置序列，忽略了底层移动网络（如道路网络）的约束和连通性信息，导致在道路约束环境中检测效果不佳

Method: 使用图注意力网络学习道路感知嵌入，结合图基位置编码；采用Transformer解码器建模序列移动；设计多目标损失函数结合自回归预测和监督链接预测；引入CW NLL异常评分函数

Result: 在真实世界和合成数据集上的实验表明，GETAD相比现有方法取得一致改进，特别是在道路约束环境中检测细微异常方面表现优异

Conclusion: 将图结构和上下文语义融入轨迹建模能够实现更精确和上下文感知的异常检测，证明了结合道路网络信息的重要性

Abstract: Trajectory anomaly detection is essential for identifying unusual and
unexpected movement patterns in applications ranging from intelligent
transportation systems to urban safety and fraud prevention.
  Existing methods only consider limited aspects of the trajectory nature and
its movement space by treating trajectories as sequences of sampled locations,
with sampling determined by positioning technology, e.g., GPS, or by high-level
abstractions such as staypoints. Trajectories are analyzed in Euclidean space,
neglecting the constraints and connectivity information of the underlying
movement network, e.g., road or transit networks.
  The proposed Graph Enhanced Trajectory Anomaly Detection (GETAD) framework
tightly integrates road network topology, segment semantics, and historical
travel patterns to model trajectory data. GETAD uses a Graph Attention Network
to learn road-aware embeddings that capture both physical attributes and
transition behavior, and augments these with graph-based positional encodings
that reflect the spatial layout of the road network.
  A Transformer-based decoder models sequential movement, while a
multiobjective loss function combining autoregressive prediction and supervised
link prediction ensures realistic and structurally coherent representations.
  To improve the robustness of anomaly detection, we introduce Confidence
Weighted Negative Log Likelihood (CW NLL), an anomaly scoring function that
emphasizes high-confidence deviations.
  Experiments on real-world and synthetic datasets demonstrate that GETAD
achieves consistent improvements over existing methods, particularly in
detecting subtle anomalies in road-constrained environments. These results
highlight the benefits of incorporating graph structure and contextual
semantics into trajectory modeling, enabling more precise and context-aware
anomaly detection.

</details>


### [14] [Shared-Weights Extender and Gradient Voting for Neural Network Expansion](https://arxiv.org/abs/2509.18842)
*Nikolas Chatzis,Ioannis Kordonis,Manos Theodosis,Petros Maragos*

Main category: cs.LG

TL;DR: 提出Shared-Weights Extender（SWE）和Steepest Voting Distributor（SVoD）两种方法，用于在训练过程中扩展神经网络，防止新增神经元失效，提高扩展效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络扩展方法中，新增神经元往往无法有效融入已训练网络而变得不活跃，无法真正提升网络容量。

Method: SWE通过将新增神经元与现有神经元耦合实现平滑集成；SVoD使用基于梯度的神经元分配方法在深层网络扩展中分配神经元。

Result: 在四个数据集上的广泛测试表明，该方法能有效抑制神经元不活跃现象，性能优于其他扩展方法和基线。

Conclusion: 该方法为神经网络动态扩展提供了有效解决方案，能够在不重新训练大模型的情况下实现容量增长。

Abstract: Expanding neural networks during training is a promising way to augment
capacity without retraining larger models from scratch. However, newly added
neurons often fail to adjust to a trained network and become inactive,
providing no contribution to capacity growth. We propose the Shared-Weights
Extender (SWE), a novel method explicitly designed to prevent inactivity of new
neurons by coupling them with existing ones for smooth integration. In
parallel, we introduce the Steepest Voting Distributor (SVoD), a gradient-based
method for allocating neurons across layers during deep network expansion. Our
extensive benchmarking on four datasets shows that our method can effectively
suppress neuron inactivity and achieve better performance compared to other
expanding methods and baselines.

</details>


### [15] [Towards Privacy-Aware Bayesian Networks: A Credal Approach](https://arxiv.org/abs/2509.18949)
*Niccolò Rocchi,Fabio Stella,Cassio de Campos*

Main category: cs.LG

TL;DR: 本文提出使用置信网络（CN）作为贝叶斯网络（BN）的隐私保护替代方案，通过模糊化而非添加噪声的方式，在保护隐私的同时保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 随着隐私问题日益严重，公开发布的贝叶斯网络模型需要保护训练数据中的敏感信息。现有的噪声添加方法虽然提供强大的隐私保护，但显著降低了模型的实用性。

Method: 将贝叶斯网络转换为置信网络，通过模糊化模型参数来减少追踪攻击的成功概率，同时识别需要隐藏的关键学习信息以防止攻击者恢复原始BN。

Result: 数值实验表明，通过调整CN超参数可以调节隐私增益，CN能够在保护隐私的同时实现有意义的推理。

Conclusion: 置信网络为开发隐私感知的概率图模型提供了一种原则性、实用且有效的方法，能够在隐私保护和模型效用之间取得良好平衡。

Abstract: Bayesian networks (BN) are probabilistic graphical models that enable
efficient knowledge representation and inference. These have proven effective
across diverse domains, including healthcare, bioinformatics and economics. The
structure and parameters of a BN can be obtained by domain experts or directly
learned from available data. However, as privacy concerns escalate, it becomes
increasingly critical for publicly released models to safeguard sensitive
information in training data. Typically, released models do not prioritize
privacy by design. In particular, tracing attacks from adversaries can combine
the released BN with auxiliary data to determine whether specific individuals
belong to the data from which the BN was learned. State-of-the-art protection
tecniques involve introducing noise into the learned parameters. While this
offers robust protection against tracing attacks, it significantly impacts the
model's utility, in terms of both the significance and accuracy of the
resulting inferences. Hence, high privacy may be attained at the cost of
releasing a possibly ineffective model. This paper introduces credal networks
(CN) as a novel solution for balancing the model's privacy and utility. After
adapting the notion of tracing attacks, we demonstrate that a CN enables the
masking of the learned BN, thereby reducing the probability of successful
attacks. As CNs are obfuscated but not noisy versions of BNs, they can achieve
meaningful inferences while safeguarding privacy. Moreover, we identify key
learning information that must be concealed to prevent attackers from
recovering the underlying BN. Finally, we conduct a set of numerical
experiments to analyze how privacy gains can be modulated by tuning the CN
hyperparameters. Our results confirm that CNs provide a principled, practical,
and effective approach towards the development of privacy-aware probabilistic
graphical models.

</details>


### [16] [Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation](https://arxiv.org/abs/2509.19112)
*Hugo Math,Rainer Lienhart*

Main category: cs.LG

TL;DR: CARGO是一种可扩展的多标签因果发现方法，用于处理稀疏高维事件序列，通过预训练的因果Transformer和自适应频率融合来推断因果图。


<details>
  <summary>Details</summary>
Motivation: 理解事件序列中的因果关系对于医疗保健、车辆诊断等领域至关重要，但目前仍是一个未解决的挑战。

Method: 使用两个预训练的因果Transformer作为领域特定的基础模型，并行推断每个序列的因果图，并通过自适应频率融合聚合来重建标签的全局马尔可夫边界。

Result: 在包含29,100个唯一事件类型和474个不平衡标签的真实世界汽车故障预测数据集上，CARGO展现出结构化推理能力。

Conclusion: CARGO的两阶段方法能够在规模上实现高效的概率推理，同时避免了全数据集条件独立性测试的不可行成本。

Abstract: Understanding causality in event sequences where outcome labels such as
diseases or system failures arise from preceding events like symptoms or error
codes is critical. Yet remains an unsolved challenge across domains like
healthcare or vehicle diagnostics. We introduce CARGO, a scalable multi-label
causal discovery method for sparse, high-dimensional event sequences comprising
of thousands of unique event types. Using two pretrained causal Transformers as
domain-specific foundation models for event sequences. CARGO infers in
parallel, per sequence one-shot causal graphs and aggregates them using an
adaptive frequency fusion to reconstruct the global Markov boundaries of
labels. This two-stage approach enables efficient probabilistic reasoning at
scale while bypassing the intractable cost of full-dataset conditional
independence testing. Our results on a challenging real-world automotive fault
prediction dataset with over 29,100 unique event types and 474 imbalanced
labels demonstrate CARGO's ability to perform structured reasoning.

</details>


### [17] [GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding](https://arxiv.org/abs/2509.19135)
*Wenying Luo,Zhiyuan Lin,Wenhao Xu,Minghao Liu,Zhi Li*

Main category: cs.LG

TL;DR: GSTM-HMU是一个生成式时空框架，通过显式建模人类移动的语义和时间复杂性来推进移动性分析。该框架包含四个关键创新：时空概念编码器、认知轨迹记忆、生活方式概念库和任务导向生成头。在四个真实数据集上的实验表明，该模型在三个基准任务上均取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 人类移动轨迹记录了短期访问模式和持久生活方式规律，但现有方法难以有效捕捉移动数据中的语义和时间复杂性。本文旨在开发一个能够更好地理解人类移动意图和偏好的生成式框架。

Method: 提出GSTM-HMU框架，包含四个核心组件：1）STCE编码器整合地理位置、POI类别语义和周期性时间节奏；2）CTM记忆模块自适应过滤历史访问，强调近期和行为显著事件；3）LCB概念库提供结构化人类偏好线索；4）任务导向生成头将学习表示转化为多任务预测。

Result: 在Gowalla、WeePlace、Brightkite和FourSquare四个数据集上的实验显示，GSTM-HMU在下一个位置预测、轨迹用户识别和时间估计三个任务上均优于强基线模型，取得了持续且显著的性能提升。

Conclusion: 生成式建模为构建更鲁棒、可解释和可泛化的人类移动智能系统提供了有前景的基础。GSTM-HMU框架能够有效从复杂移动数据中提取语义规律性，展示了在移动分析领域的应用潜力。

Abstract: Human mobility traces, often recorded as sequences of check-ins, provide a
unique window into both short-term visiting patterns and persistent lifestyle
regularities. In this work we introduce GSTM-HMU, a generative spatio-temporal
framework designed to advance mobility analysis by explicitly modeling the
semantic and temporal complexity of human movement. The framework consists of
four key innovations. First, a Spatio-Temporal Concept Encoder (STCE)
integrates geographic location, POI category semantics, and periodic temporal
rhythms into unified vector representations. Second, a Cognitive Trajectory
Memory (CTM) adaptively filters historical visits, emphasizing recent and
behaviorally salient events in order to capture user intent more effectively.
Third, a Lifestyle Concept Bank (LCB) contributes structured human preference
cues, such as activity types and lifestyle patterns, to enhance
interpretability and personalization. Finally, task-oriented generative heads
transform the learned representations into predictions for multiple downstream
tasks. We conduct extensive experiments on four widely used real-world
datasets, including Gowalla, WeePlace, Brightkite, and FourSquare, and evaluate
performance on three benchmark tasks: next-location prediction, trajectory-user
identification, and time estimation. The results demonstrate consistent and
substantial improvements over strong baselines, confirming the effectiveness of
GSTM-HMU in extracting semantic regularities from complex mobility data. Beyond
raw performance gains, our findings also suggest that generative modeling
provides a promising foundation for building more robust, interpretable, and
generalizable systems for human mobility intelligence.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: SPADE是一个基于大语言模型的土壤湿度时间序列分析框架，能够联合检测灌溉模式和异常，无需特定任务标注或微调即可实现零样本分析。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度时间序列分析方法要么依赖基于阈值的规则，要么需要大量数据的机器学习模型，存在适应性和可解释性不足的问题。

Method: 利用ChatGPT-4.1的推理能力，将时间序列数据转换为文本表示，设计领域知识提示模板，识别灌溉事件、估计净灌溉增益、检测和分类异常，并生成结构化可解释报告。

Result: 在美国多个商业和实验农场的真实土壤湿度传感器数据上测试，SPADE在异常检测方面优于现有方法，召回率和F1分数更高，灌溉事件检测精度和召回率也很高。

Conclusion: 该研究展示了LLMs作为精准农业可扩展、适应性强的工具的潜力，能够整合定性知识和数据驱动推理，为准确的土壤湿度监测和改进的灌溉调度提供可行见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [19] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: HSGM是一种分层段图记忆框架，通过将长文档分解为有意义段落后构建局部语义图和全局图记忆，显著降低长文档语义解析的计算复杂度和内存需求。


<details>
  <summary>Details</summary>
Motivation: 解决长文档语义解析中因成对组合和内存需求呈二次方增长而面临的挑战，实现可扩展、准确的超长文本语义建模。

Method: 将输入文档分解为M个段落，为每个段落构建局部语义图，提取紧凑的摘要节点形成全局图记忆，支持增量更新和分层查询处理。

Result: 在三个基准测试中，HSGM实现了2-4倍推理加速、超过60%的峰值内存减少，并保持基线准确率的95%以上。

Conclusion: HSGM为超长文本的语义建模提供了可扩展且准确的解决方案，支持实时和资源受限的NLP应用。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [20] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了相似性场理论，这是一个数学框架，用于形式化实体间相似性关系及其演化的原则。该理论定义了相似性场、系统演化、概念纤维和生成算子，并基于此形式化地定义了智能的概念。


<details>
  <summary>Details</summary>
Motivation: 作者认为持久化和转换相似性关系是任何可理解动态系统的结构基础，需要建立一个数学框架来形式化相似性值及其演化的原则。

Method: 定义了相似性场S: U×U→[0,1]，满足自反性；系统演化序列Z_p=(X_p,S^(p))；概念K诱导的纤维F_α(K)；生成算子G。基于此框架形式化智能的定义。

Result: 证明了两个定理：(i)不对称性阻止相互包含；(ii)稳定性需要锚坐标或最终限制在f的水平集中。这些结果确保相似性场演化既受约束又可解释。

Conclusion: 相似性场理论为表征、比较和构建智能系统提供了基础语言，可用于解释大语言模型并将其作为社会认知的实验探针。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [21] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: ComputerAgent是一个轻量级分层强化学习框架，用于桌面应用程序控制，通过两级选项过程（管理器和子策略）实现OS控制，比大型多模态语言模型更高效。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在桌面应用控制中存在推理延迟高、长视野稀疏奖励任务样本效率差、无法在设备上部署等问题，需要更实用的解决方案。

Method: 采用分层强化学习框架，包含三级模态状态编码器（截图、任务ID、数值状态），集成元动作和早停机制，使用紧凑视觉骨干网络和小型策略网络（1500万参数）。

Result: 在135个真实桌面任务测试中，简单任务（<8步）成功率92.1%，困难任务（≥8步）成功率58.8%，模型大小减少4个数量级，推理时间减半。

Conclusion: 分层强化学习为计算机控制提供了一个实用、可扩展的替代方案，优于基于单体大语言模型的自动化方法。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [22] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: 本文提出了Gödel测试，用于评估大语言模型是否能解决数学领域的新简单猜想，并在组合优化问题上测试了GPT-5的性能。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在高级数学领域解决新简单猜想的能力，而不仅仅是已知数学竞赛问题。

Method: 选择五个组合优化中的未解决猜想，提供相关源论文但不告知具体猜想，详细评估GPT-5的推理过程。

Result: GPT-5在三个较简单问题上产生近乎正确的解，甚至在一个问题上推翻了原猜想；但在需要跨论文综合的问题上失败，在无验证猜想的难题上算法正确但分析失败。

Conclusion: GPT-5在常规推理上有显著进步，偶尔展现原创性，但在跨论文综合方面仍有明显局限，可能是通过Gödel测试的早期步骤。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [23] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: 本文提出LLMZ+方法，通过提示白名单机制保护智能AI代理免受越狱攻击，确保只有上下文适当的安全消息能与LLM交互。


<details>
  <summary>Details</summary>
Motivation: 智能AI代理相比传统模型具有更高的安全风险，因为它们拥有对数据源和API工具的特权访问，且依赖AI的非确定性行为。现有防御机制主要依赖恶意意图检测，但这种方法存在局限性。

Method: 采用提示白名单方法，仅允许上下文适当且安全的消息与智能LLM代理交互。通过利用上下文特异性，确保所有外部用户与LLM的交换都符合预定义用例和操作边界。

Result: 实证评估表明LLMZ+对最常见的越狱提示具有强大韧性，同时不干扰合法业务通信。在实验设置中，误报率和漏报率均可降至0。

Conclusion: LLMZ+方法简化了安全框架，增强了长期韧性，减少了维持LLM信息安全所需的资源，为智能AI代理提供了有效的安全保护。

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [24] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的方法，通过分解数学应用题、生成方程、使用外部符号求解器，并结合估算验证和迭代修正过程，显著提高了大语言模型在数学应用题上的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在解决数学应用题方面存在困难，因为需要复杂的推理和数学能力。现有的提示方法虽然有所改进，但仍需更有效的解决方案。

Method: 首先提示LLM从问题分解中创建方程，使用外部符号方程求解器生成答案。然后让LLM估算正确答案并与生成答案比较验证，如果验证失败则进行迭代修正。

Result: 该方法在数值和代数数学应用题数据集上达到了新的最先进结果，平均比之前最佳结果提高了近2%。在三角函数应用题上也取得了满意结果。

Conclusion: 该方法有效提升了LLM解决数学应用题的能力，并引入了两个新数据集SVAMPClean和Trig300来进一步测试LLM的推理能力。

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [25] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出自主数据代理（DataAgents）的概念，通过集成LLM推理与任务分解、行动推理和工具调用，实现从复杂数据到知识的自动化转换。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性的增长，数据准备、转换和分析工作仍然劳动密集、重复且难以扩展。数据与AI的对齐至关重要，但数据通常未以最优方式结构化以支持AI利用。

Method: DataAgents通过动态规划工作流、调用强大工具和适应多样化数据任务，能够处理数据收集、集成、预处理、选择、转换、重新加权、增强、重编程、修复和检索等操作。

Result: DataAgents能够将复杂和非结构化数据转换为连贯且可操作的知识，代表了向自主数据到知识系统的范式转变。

Conclusion: 本文呼吁在行动工作流优化、建立开放数据集和基准生态系统、保护隐私、平衡效率与可扩展性以及开发可信赖的DataAgent防护措施方面做出协同努力。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [26] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: 本文比较了四种剩余时间预测方法在物流公司出库仓库流程中的表现，发现深度学习模型准确率最高，但浅层方法如传统提升技术在计算资源需求上更优。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测正在进行的流程执行的未来，剩余时间预测是常见目标。本文旨在在真实物流公司出库流程中比较不同方法的性能。

Method: 在物流公司提供的包含169,523条轨迹的新事件日志上，比较了四种剩余时间预测方法，包括深度学习模型和浅层方法如传统提升技术。

Result: 深度学习模型达到最高准确率，但浅层方法如传统提升技术获得竞争性准确率且计算资源需求显著减少。

Conclusion: 虽然深度学习在准确率上表现最佳，但浅层方法在准确率和计算效率之间提供了更好的平衡，适用于资源受限的环境。

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [27] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过将事件视为治疗和结果，利用合成控制方法生成虚拟双胞胎来估计因果效应。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果关系识别方法主要依赖语言模式和多跳关系推理，容易因因果关系的非正式使用和虚假图形推理而导致错误识别。需要更稳健的方法来区分因果关系和相关关系。

Method: 采用Rubin因果模型框架，将第一个事件视为治疗，第二个事件视为结果。使用合成控制方法从相关历史数据中生成虚拟双胞胎，利用文本嵌入合成和反演技术来估计治疗对结果的影响。

Result: 该方法在因果关系基准测试COPES-hard上表现出色，识别效果优于包括GPT-4在内的先前方法，能够更稳健地识别事件间的因果关系。

Conclusion: 基于Rubin因果模型的合成控制方法为事件因果关系识别提供了新的有效途径，通过概念性操作和虚拟对照组的构建，显著提高了因果关系识别的准确性和可靠性。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [28] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无需训练的即插即用方法，通过生成低比特量化替代层来加速参数卸载，在内存受限的GPU上实现无损的LLM推理加速。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在内存受限消费级GPU上部署的挑战，现有方法要么牺牲质量（压缩），要么推理速度慢（参数卸载），而推测解码方法通常需要额外训练且加速效果有限。

Method: 构建高度对齐的草稿模型：从卸载的目标LLM部分生成低比特量化替代层，共享剩余的GPU驻留层和KV-Cache，减少内存开销并增强对齐性。

Result: 在8GB VRAM限制下，Qwen2.5 7B在MT-Bench上实现9.1倍加速；在24GB VRAM限制下，Qwen2.5 32B在流行生成基准测试中平均实现12.5倍加速。

Conclusion: SubSpec通过量化替代层和共享策略，实现了高平均接受长度和显著的速度提升，为内存受限环境下的LLM部署提供了有效的解决方案。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [29] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出了一种LLM辅助的说话人日志校正系统，通过实时用户反馈来修正说话人归属错误，显著降低了说话人日志错误率。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统以"开环"模式运行，缺乏用户反馈，而人机协作工作流程可以显著提高准确性。

Method: 系统执行流式ASR和说话人日志，使用LLM生成简洁摘要，接受简短语音反馈并立即整合。开发了SWM技术检测和分割多说话人段，以及基于用户校正的在线说话人注册。

Result: 在AMI测试集上的LLM驱动模拟显示，系统显著降低了DER 9.92%和说话人混淆错误44.23%。

Conclusion: 该系统通过人机协作有效提升了说话人日志的准确性，分析了不同设置下的校正效果。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [30] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出了一种基于10-K文件的无监督方法，用于提取企业间风险关系，通过自然语言处理技术捕捉隐含风险联系，并生成可量化的风险关系评分。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断和手动分析评估企业间风险关系的方法存在主观性强、劳动密集且难以扩展的问题，需要一种系统化、可扩展的解决方案。

Method: 利用10-K文件作为数据源，通过无监督微调方法基于时间顺序和词汇模式捕捉隐含风险联系，开发领域特定的金融编码器。

Result: 大量实验表明，该方法在多个评估设置中优于强基线模型。

Conclusion: 该方法为企业间风险关系识别提供了一种系统化、可扩展的解决方案，在投资组合管理和投资策略等应用中具有重要价值。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [31] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 本研究比较了多种预训练注意力模型在电子健康记录信息提取任务上的性能，发现临床数据预训练的模型在药物和药物事件检测方面更有效，而通用领域预训练的Bert Base在药物相关事件上下文分类方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的模型已成为临床笔记自然语言处理的主要方法，本研究旨在比较不同预训练注意力模型在EHR信息提取任务上的性能，特别是针对哈佛医学院2022年n2c2挑战赛Track 1的药物事件上下文数据集。

Method: 研究比较了Bert Base、BioBert、两种Bio+Clinical Bert变体、RoBerta和Clinical Longformer等预训练模型，在CMED数据集上进行微调，执行药物提取、医疗事件检测和多维药物事件上下文分类任务，并详细描述了EHR处理方法和基于召回率、精确率和F1分数的性能评估。

Result: 结果显示，在临床数据上预训练的模型在检测药物和药物事件方面更有效，但Bert Base（在通用领域数据上预训练）在分类与药物相关事件的上下文方面表现最佳。

Conclusion: 临床数据预训练的模型在药物事件检测方面具有优势，而通用领域预训练的模型在复杂上下文分类任务中可能表现更好，这为医疗NLP任务中模型选择提供了重要指导。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [32] [Number Adaptive Formation Flight Planning via Affine Deformable Guidance in Narrow Environments](https://arxiv.org/abs/2509.18636)
*Yuan Zhou,Jialiang Hou,Guangtong Xu,Fei Gao*

Main category: cs.RO

TL;DR: 提出了一种基于可变形虚拟结构（DVS）的无人机编队规划方法，能够在狭窄环境中处理无人机数量变化，实现快速编队恢复和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 解决在狭窄环境中无人机数量变化时编队维护的挑战，传统方法难以收敛到期望配置。

Method: 采用Lloyd算法进行均匀分区和匈牙利算法进行分配（PAAS），结合基于基元的路径搜索和非线性轨迹优化来规划DVS的时空轨迹，实现自适应转换。

Result: 在模拟环境中支持最多15%的无人机加入或离开编队，同时快速恢复期望编队形状，相比现有方法展现出更好的编队恢复能力和环境适应性。

Conclusion: 真实世界实验验证了该编队规划方法的有效性和鲁棒性，为动态无人机编队控制提供了实用解决方案。

Abstract: Formation maintenance with varying number of drones in narrow environments
hinders the convergence of planning to the desired configurations. To address
this challenge, this paper proposes a formation planning method guided by
Deformable Virtual Structures (DVS) with continuous spatiotemporal
transformation. Firstly, to satisfy swarm safety distance and preserve
formation shape filling integrity for irregular formation geometries, we employ
Lloyd algorithm for uniform $\underline{PA}$rtitioning and Hungarian algorithm
for $\underline{AS}$signment (PAAS) in DVS. Subsequently, a spatiotemporal
trajectory involving DVS is planned using primitive-based path search and
nonlinear trajectory optimization. The DVS trajectory achieves adaptive
transitions with respect to a varying number of drones while ensuring
adaptability to narrow environments through affine transformation. Finally,
each agent conducts distributed trajectory planning guided by desired
spatiotemporal positions within the DVS, while incorporating collision
avoidance and dynamic feasibility requirements. Our method enables up to 15\%
of swarm numbers to join or leave in cluttered environments while rapidly
restoring the desired formation shape in simulation. Compared to cutting-edge
formation planning method, we demonstrate rapid formation recovery capacity and
environmental adaptability. Real-world experiments validate the effectiveness
and resilience of our formation planning method.

</details>


### [33] [DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation](https://arxiv.org/abs/2509.18830)
*Suzannah Wistreich,Baiyu Shi,Stephen Tian,Samuel Clarke,Michael Nath,Chengyi Xu,Zhenan Bao,Jiajun Wu*

Main category: cs.RO

TL;DR: DexSkin是一种柔软、可适应的电容式电子皮肤，能够实现敏感、局部化和可校准的触觉感知，可定制到不同几何形状的机器人手指上，用于学习接触丰富的操作任务。


<details>
  <summary>Details</summary>
Motivation: 人类皮肤提供丰富的触觉感知流，能够在大的曲面区域定位有意和无意的接触事件。为灵巧机器人操作系统复制这些触觉感知能力仍然是一个长期挑战。

Method: 开发了DexSkin电子皮肤，将其安装在平行夹爪手指上，覆盖几乎整个手指表面。在从示范学习和在线强化学习框架中评估其在挑战性操作任务中的能力。

Result: DexSkin在需要整个手指表面传感覆盖的任务中表现出色，如手中重新定向物体和将弹性带缠绕在盒子上。关键的是，DexSkin可以校准以实现模型在不同传感器实例间的转移。

Conclusion: DexSkin展示了其在学习真实世界、接触丰富的操作任务中的适用性和实用性，为机器人触觉感知提供了可行的解决方案。

Abstract: Human skin provides a rich tactile sensing stream, localizing intentional and
unintentional contact events over a large and contoured region. Replicating
these tactile sensing capabilities for dexterous robotic manipulation systems
remains a longstanding challenge. In this work, we take a step towards this
goal by introducing DexSkin. DexSkin is a soft, conformable capacitive
electronic skin that enables sensitive, localized, and calibratable tactile
sensing, and can be tailored to varying geometries. We demonstrate its efficacy
for learning downstream robotic manipulation by sensorizing a pair of parallel
jaw gripper fingers, providing tactile coverage across almost the entire finger
surfaces. We empirically evaluate DexSkin's capabilities in learning
challenging manipulation tasks that require sensing coverage across the entire
surface of the fingers, such as reorienting objects in hand and wrapping
elastic bands around boxes, in a learning-from-demonstration framework. We then
show that, critically for data-driven approaches, DexSkin can be calibrated to
enable model transfer across sensor instances, and demonstrate its
applicability to online reinforcement learning on real robots. Our results
highlight DexSkin's suitability and practicality for learning real-world,
contact-rich manipulation. Please see our project webpage for videos and
visualizations: https://dex-skin.github.io/.

</details>


### [34] [Proactive-reactive detection and mitigation of intermittent faults in robot swarms](https://arxiv.org/abs/2509.19246)
*Sinan Oğuz,Emanuele Garone,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 本文提出了一种针对具有持久网络的机器人群体中间歇性故障的主动-被动检测与缓解策略，基于自组织备份层和多路网络中的分布式共识。


<details>
  <summary>Details</summary>
Motivation: 间歇性故障在机器人群体中具有挑战性，但现有研究主要关注永久性故障。自组织神经系统（SoNS）方法使机器人群体能够首次自组织持久网络结构，为检测间歇性故障提供了可能。

Method: 采用主动-被动策略：主动方面，机器人在故障发生前自组织动态备份路径；被动方面，机器人使用一次性似然比检验比较多路网络中不同路径的信息，实现早期故障检测。检测到故障后，通信以自组织方式临时重路由。

Result: 在形成控制中故障位置数据的代表性场景中验证了该方法，证明间歇性故障不会破坏向期望形成的收敛，具有高故障检测准确性和低误报率。

Conclusion: 该方法有效解决了机器人群体中的间歇性故障问题，通过自组织备份层和分布式共识实现了可靠的故障检测和缓解。

Abstract: Intermittent faults are transient errors that sporadically appear and
disappear. Although intermittent faults pose substantial challenges to
reliability and coordination, existing studies of fault tolerance in robot
swarms focus instead on permanent faults. One reason for this is that
intermittent faults are prohibitively difficult to detect in the fully
self-organized ad-hoc networks typical of robot swarms, as their network
topologies are transient and often unpredictable. However, in the recently
introduced self-organizing nervous systems (SoNS) approach, robot swarms are
able to self-organize persistent network structures for the first time, easing
the problem of detecting intermittent faults. To address intermittent faults in
robot swarms that have persistent networks, we propose a novel
proactive-reactive strategy to detection and mitigation, based on
self-organized backup layers and distributed consensus in a multiplex network.
Proactively, the robots self-organize dynamic backup paths before faults occur,
adapting to changes in the primary network topology and the robots' relative
positions. Reactively, robots use one-shot likelihood ratio tests to compare
information received along different paths in the multiplex network, enabling
early fault detection. Upon detection, communication is temporarily rerouted in
a self-organized way, until the detected fault resolves. We validate the
approach in representative scenarios of faulty positional data occurring during
formation control, demonstrating that intermittent faults are prevented from
disrupting convergence to desired formations, with high fault detection
accuracy and low rates of false positives.

</details>
