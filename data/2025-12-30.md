<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 13]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Signal-SGN++: Topology-Enhanced Time-Frequency Spiking Graph Network for Skeleton-Based Action Recognition](https://arxiv.org/abs/2512.22214)
*Naichuan Zheng,Xiahai Lun,Weiyi Li,Yuchen Du*

Main category: cs.CV

TL;DR: 提出Signal-SGN++框架，结合拓扑感知的脉冲图神经网络，通过1D脉冲图卷积和频率脉冲卷积提取时空-频谱特征，嵌入拓扑转移自注意力机制，并利用多尺度小波变换融合分支，在保持高能效的同时提升动作识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统图卷积网络(GCNs)在骨骼动作识别中表现良好但计算能耗高，而脉冲神经网络(SNNs)虽然能效高但难以捕捉人体运动的时空-频率耦合依赖和拓扑结构。需要结合两者优势，开发既能高效处理拓扑结构又具有低能耗的框架。

Method: 1. 使用1D脉冲图卷积(1D-SGC)和频率脉冲卷积(FSC)作为主干网络，联合提取时空和频谱特征；2. 嵌入拓扑转移自注意力(TSSA)机制，自适应地在学习到的骨骼拓扑上路由注意力；3. 引入多尺度小波变换融合(MWTF)分支，将脉冲特征分解为多分辨率时频表示；4. 使用拓扑感知时频融合(TATF)单元，结合结构先验保持拓扑一致的频谱融合。

Result: 在大规模基准测试中，Signal-SGN++实现了优越的精度-效率权衡，超越了现有的基于SNN的方法，并在显著降低能耗的情况下达到了与最先进GCNs竞争的结果。

Conclusion: Signal-SGN++成功地将拓扑感知与脉冲动态相结合，为骨骼动作识别提供了一个高效且高性能的解决方案，在保持低能耗的同时实现了与复杂GCNs相媲美的性能。

Abstract: Graph Convolutional Networks (GCNs) demonstrate strong capability in modeling skeletal topology for action recognition, yet their dense floating-point computations incur high energy costs. Spiking Neural Networks (SNNs), characterized by event-driven and sparse activation, offer energy efficiency but remain limited in capturing coupled temporal-frequency and topological dependencies of human motion. To bridge this gap, this article proposes Signal-SGN++, a topology-aware spiking graph framework that integrates structural adaptivity with time-frequency spiking dynamics. The network employs a backbone composed of 1D Spiking Graph Convolution (1D-SGC) and Frequency Spiking Convolution (FSC) for joint spatiotemporal and spectral feature extraction. Within this backbone, a Topology-Shift Self-Attention (TSSA) mechanism is embedded to adaptively route attention across learned skeletal topologies, enhancing graph-level sensitivity without increasing computational complexity. Moreover, an auxiliary Multi-Scale Wavelet Transform Fusion (MWTF) branch decomposes spiking features into multi-resolution temporal-frequency representations, wherein a Topology-Aware Time-Frequency Fusion (TATF) unit incorporates structural priors to preserve topology-consistent spectral fusion. Comprehensive experiments on large-scale benchmarks validate that Signal-SGN++ achieves superior accuracy-efficiency trade-offs, outperforming existing SNN-based methods and achieving competitive results against state-of-the-art GCNs under substantially reduced energy consumption.

</details>


### [2] [VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs](https://arxiv.org/abs/2512.22226)
*Naishan Zheng,Jie Huang,Qingpei Guo,Feng Zhao*

Main category: cs.CV

TL;DR: VideoScaffold是一个用于流式视频理解的动态表示框架，通过自适应调整事件粒度来提升多模态大语言模型对长视频的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有静态策略（如稀疏采样、帧压缩和聚类）在处理连续视频流时存在局限性，会产生碎片化或过度压缩的输出，无法满足流式视频理解的需求。

Method: 提出VideoScaffold框架，包含两个核心组件：弹性尺度事件分割（EES）进行预测引导的动态边界细化，以及分层事件整合（HEC）将语义相关片段逐步聚合为多层次抽象表示。

Result: 在离线和流式视频理解基准测试中达到最先进性能，框架模块化且即插即用，能够无缝扩展现有的基于图像的MLLMs到连续视频理解。

Conclusion: VideoScaffold通过动态调整事件粒度，在保持细粒度视觉语义的同时，实现了从帧级理解到事件级推理的平滑过渡，有效解决了长视频理解中的冗余和时序连贯性问题。

Abstract: Understanding long videos with multimodal large language models (MLLMs) remains challenging due to the heavy redundancy across frames and the need for temporally coherent representations. Existing static strategies, such as sparse sampling, frame compression, and clustering, are optimized for offline settings and often produce fragmented or over-compressed outputs when applied to continuous video streams. We present VideoScaffold, a dynamic representation framework designed for streaming video understanding. It adaptively adjusts event granularity according to video duration while preserving fine-grained visual semantics. VideoScaffold introduces two key components: Elastic-Scale Event Segmentation (EES), which performs prediction-guided segmentation to dynamically refine event boundaries, and Hierarchical Event Consolidation (HEC), which progressively aggregates semantically related segments into multi-level abstractions. Working in concert, EES and HEC enable VideoScaffold to transition smoothly from fine-grained frame understanding to abstract event reasoning as the video stream unfolds. Extensive experiments across both offline and streaming video understanding benchmarks demonstrate that VideoScaffold achieves state-of-the-art performance. The framework is modular and plug-and-play, seamlessly extending existing image-based MLLMs to continuous video comprehension. The code is available at https://github.com/zheng980629/VideoScaffold.

</details>


### [3] [LECalib: Line-Based Event Camera Calibration](https://arxiv.org/abs/2512.22441)
*Zibin Liu,Banglei Guana,Yang Shanga,Zhenbao Yu,Yifei Bian,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于直线的事件相机标定框架，利用人造环境中常见物体的几何直线进行标定，无需专用标定板


<details>
  <summary>Details</summary>
Motivation: 现有事件相机标定方法通常需要闪烁图案、重建强度图像或手动放置标定物，耗时且无法适应快速变化场景

Method: 直接从事件流中检测直线，利用事件-直线标定模型生成相机参数初始估计，然后进行非线性优化精修，适用于平面和非平面直线

Result: 仿真和真实世界实验验证了方法的可行性和准确性，在单目和双目事件相机上均进行了验证

Conclusion: 提出的基于直线的标定框架能够有效解决事件相机标定问题，无需专用标定板，适应快速变化场景

Abstract: Camera calibration is an essential prerequisite for event-based vision applications. Current event camera calibration methods typically involve using flashing patterns, reconstructing intensity images, and utilizing the features extracted from events. Existing methods are generally time-consuming and require manually placed calibration objects, which cannot meet the needs of rapidly changing scenarios. In this paper, we propose a line-based event camera calibration framework exploiting the geometric lines of commonly-encountered objects in man-made environments, e.g., doors, windows, boxes, etc. Different from previous methods, our method detects lines directly from event streams and leverages an event-line calibration model to generate the initial guess of camera parameters, which is suitable for both planar and non-planar lines. Then, a non-linear optimization is adopted to refine camera parameters. Both simulation and real-world experiments have demonstrated the feasibility and accuracy of our method, with validation performed on monocular and stereo event cameras. The source code is released at https://github.com/Zibin6/line_based_event_camera_calib.

</details>


### [4] [Comparing Object Detection Models for Electrical Substation Component Mapping](https://arxiv.org/abs/2512.22454)
*Haley Mody,Namish Bansal,Dennies Kiprono Bor,Edward J. Oughton*

Main category: cs.CV

TL;DR: 该研究比较了三种计算机视觉模型（YOLOv8、YOLOv11、RF-DETR）在电力变电站组件自动检测中的性能，旨在替代传统人工标注方法，实现大规模变电站基础设施的高效映射。


<details>
  <summary>Details</summary>
Motivation: 电力变电站是电网的关键组成部分，其资产（如变压器）容易受到飓风、洪水、地震和地磁感应电流等多种灾害的破坏。电网作为关键国家基础设施，任何故障都可能带来重大的经济和公共安全影响。传统的人工变电站基础设施映射方法耗时耗力，因此需要开发自主的计算机视觉解决方案来提高效率和便利性。

Method: 研究使用手动标注的美国变电站图像数据集，训练并比较了三种计算机视觉模型：YOLOv8、YOLOv11和RF-DETR。评估指标包括检测准确率、精确度和效率。研究还利用这些模型对美国各地的变电站组件进行了有效映射。

Result: 研究展示了三种模型在变电站组件检测中的性能表现，分析了各自的关键优势和局限性，并确定了哪种模型能够提供可靠且可扩展的大规模变电站组件映射解决方案。

Conclusion: 该研究证明了机器学习在变电站映射中的应用价值，通过比较不同计算机视觉模型的性能，为电力基础设施的自动化监测和维护提供了有效的技术方案，有助于预防和减轻变电站故障带来的风险。

Abstract: Electrical substations are a significant component of an electrical grid. Indeed, the assets at these substations (e.g., transformers) are prone to disruption from many hazards, including hurricanes, flooding, earthquakes, and geomagnetically induced currents (GICs). As electrical grids are considered critical national infrastructure, any failure can have significant economic and public safety implications. To help prevent and mitigate these failures, it is thus essential that we identify key substation components to quantify vulnerability. Unfortunately, traditional manual mapping of substation infrastructure is time-consuming and labor-intensive. Therefore, an autonomous solution utilizing computer vision models is preferable, as it allows for greater convenience and efficiency. In this research paper, we train and compare the outputs of 3 models (YOLOv8, YOLOv11, RF-DETR) on a manually labeled dataset of US substation images. Each model is evaluated for detection accuracy, precision, and efficiency. We present the key strengths and limitations of each model, identifying which provides reliable and large-scale substation component mapping. Additionally, we utilize these models to effectively map the various substation components in the United States, showcasing a use case for machine learning in substation mapping.

</details>


### [5] [Event-based high temporal resolution measurement of shock wave motion field](https://arxiv.org/abs/2512.22474)
*Taihang Lei,Banglei Guan,Minzu Liang,Pengju Sun,Jing Tao,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于多事件相机的高时空分辨率冲击波运动参数测量框架，通过极坐标编码、自适应ROI提取和迭代斜率分析实现冲击波前提取，最终实现3D重建和爆炸当量反演，测量误差最小0.06%，最大5.20%。


<details>
  <summary>Details</summary>
Motivation: 冲击波在电力场测试和损伤评估等应用中需要高时空分辨率的精确测量，但冲击波快速不均匀传播和不稳定测试条件带来重大挑战。

Method: 1) 建立极坐标系编码事件以揭示冲击波传播模式，通过事件偏移计算进行自适应ROI提取；2) 利用速度变化连续性，通过迭代斜率分析提取冲击波前事件；3) 基于事件光学成像模型推导事件几何模型和冲击波运动参数，结合3D重建模型。

Result: 实现了多角度冲击波测量、运动场重建和爆炸当量反演。速度测量结果与压力传感器和经验公式对比，最大误差5.20%，最小误差0.06%，实现了高时空分辨率的高精度测量。

Conclusion: 该方法利用事件相机的高速和高动态范围能力，成功解决了冲击波快速不均匀传播的测量挑战，实现了高精度的冲击波运动场测量，代表了该领域的显著进展。

Abstract: Accurate measurement of shock wave motion parameters with high spatiotemporal resolution is essential for applications such as power field testing and damage assessment. However, significant challenges are posed by the fast, uneven propagation of shock waves and unstable testing conditions. To address these challenges, a novel framework is proposed that utilizes multiple event cameras to estimate the asymmetry of shock waves, leveraging its high-speed and high-dynamic range capabilities. Initially, a polar coordinate system is established, which encodes events to reveal shock wave propagation patterns, with adaptive region-of-interest (ROI) extraction through event offset calculations. Subsequently, shock wave front events are extracted using iterative slope analysis, exploiting the continuity of velocity changes. Finally, the geometric model of events and shock wave motion parameters is derived according to event-based optical imaging model, along with the 3D reconstruction model. Through the above process, multi-angle shock wave measurement, motion field reconstruction, and explosive equivalence inversion are achieved. The results of the speed measurement are compared with those of the pressure sensors and the empirical formula, revealing a maximum error of 5.20% and a minimum error of 0.06%. The experimental results demonstrate that our method achieves high-precision measurement of the shock wave motion field with both high spatial and temporal resolution, representing significant progress.

</details>


### [6] [PoseStreamer: A Multi-modal Framework for 6DoF Pose Estimation of Unseen Moving Objects](https://arxiv.org/abs/2512.22979)
*Huiming Yang,Linglin Liao,Fei Ding,Sibo Wang,Zijian Zeng*

Main category: cs.CV

TL;DR: PoseStreamer：用于高速运动场景的鲁棒多模态6DoF姿态估计框架，通过自适应姿态记忆队列、物体中心2D跟踪器和射线姿态滤波器提升性能，并在新数据集MoCapCube6D上验证效果。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在高速和低光场景下存在运动模糊问题，而现有6DoF姿态估计方法在高速物体运动场景中表现不佳。事件相机具有高时间分辨率优势，但需要专门针对高速运动场景设计的姿态估计框架。

Method: 提出PoseStreamer框架，包含三个核心组件：1) 自适应姿态记忆队列，利用历史方向线索保持时间一致性；2) 物体中心2D跟踪器，提供强2D先验以提升3D中心召回；3) 射线姿态滤波器，沿相机射线进行几何细化。同时构建了多模态数据集MoCapCube6D用于快速运动下的性能评估。

Result: 大量实验表明，PoseStreamer在高速运动场景中实现了卓越的准确性，同时作为无模板框架对未见过的运动物体表现出强大的泛化能力。

Conclusion: PoseStreamer为解决高速运动场景下的6DoF姿态估计问题提供了有效的多模态解决方案，通过时间一致性、2D先验和几何细化相结合的方法显著提升了性能，并为该领域提供了新的基准数据集。

Abstract: Six degree of freedom (6DoF) pose estimation for novel objects is a critical task in computer vision, yet it faces significant challenges in high-speed and low-light scenarios where standard RGB cameras suffer from motion blur. While event cameras offer a promising solution due to their high temporal resolution, current 6DoF pose estimation methods typically yield suboptimal performance in high-speed object moving scenarios. To address this gap, we propose PoseStreamer, a robust multi-modal 6DoF pose estimation framework designed specifically on high-speed moving scenarios. Our approach integrates three core components: an Adaptive Pose Memory Queue that utilizes historical orientation cues for temporal consistency, an Object-centric 2D Tracker that provides strong 2D priors to boost 3D center recall, and a Ray Pose Filter for geometric refinement along camera rays. Furthermore, we introduce MoCapCube6D, a novel multi-modal dataset constructed to benchmark performance under rapid motion. Extensive experiments demonstrate that PoseStreamer not only achieves superior accuracy in high-speed moving scenarios, but also exhibits strong generalizability as a template-free framework for unseen moving objects.

</details>


### [7] [RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models](https://arxiv.org/abs/2512.23239)
*Fan Wei,Runmin Dong,Yushan Lai,Yixiang Yang,Zhaoyang Luo,Jinxiao Zhang,Miao Yang,Shuai Yuan,Jiyao Zhao,Bin Luo,Haohuan Fu*

Main category: cs.CV

TL;DR: 提出一种无需训练的两阶段数据剪枝方法，通过熵值筛选和场景感知聚类，在高剪枝率下选择高质量遥感数据子集，显著提升扩散基础模型的收敛速度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前遥感扩散基础模型依赖大量全局代表性数据，但这些数据存在冗余、噪声和类别不平衡问题，降低训练效率并阻碍收敛。现有方法通常简单聚合多个分类数据集或应用简单去重，忽视了生成模型的分布需求和遥感图像的异质性。

Method: 提出无需训练的两阶段数据剪枝方法：1) 基于熵的准则高效去除低信息样本；2) 利用遥感场景分类数据集作为参考基准，进行场景感知聚类和分层采样，平衡聚类级均匀性和样本代表性，在高剪枝率下实现细粒度选择。

Result: 即使剪枝85%的训练数据，该方法仍能显著改善收敛性和生成质量。使用该方法训练的扩散基础模型在下游任务（如超分辨率和语义图像合成）中持续达到最先进性能。

Conclusion: 该数据剪枝范式为开发遥感生成基础模型提供了实用指导，能够在高剪枝率下选择高质量数据子集，使初步基础模型快速收敛并作为多功能骨干网络。

Abstract: Diffusion-based remote sensing (RS) generative foundation models are cruial for downstream tasks. However, these models rely on large amounts of globally representative data, which often contain redundancy, noise, and class imbalance, reducing training efficiency and preventing convergence. Existing RS diffusion foundation models typically aggregate multiple classification datasets or apply simplistic deduplication, overlooking the distributional requirements of generation modeling and the heterogeneity of RS imagery. To address these limitations, we propose a training-free, two-stage data pruning approach that quickly select a high-quality subset under high pruning ratios, enabling a preliminary foundation model to converge rapidly and serve as a versatile backbone for generation, downstream fine-tuning, and other applications. Our method jointly considers local information content with global scene-level diversity and representativeness. First, an entropy-based criterion efficiently removes low-information samples. Next, leveraging RS scene classification datasets as reference benchmarks, we perform scene-aware clustering with stratified sampling to improve clustering effectiveness while reducing computational costs on large-scale unlabeled data. Finally, by balancing cluster-level uniformity and sample representativeness, the method enables fine-grained selection under high pruning ratios while preserving overall diversity and representativeness. Experiments show that, even after pruning 85\% of the training data, our method significantly improves convergence and generation quality. Furthermore, diffusion foundation models trained with our method consistently achieve state-of-the-art performance across downstream tasks, including super-resolution and semantic image synthesis. This data pruning paradigm offers practical guidance for developing RS generative foundation models.

</details>


### [8] [Contour Information Aware 2D Gaussian Splatting for Image Representation](https://arxiv.org/abs/2512.23255)
*Masaya Takabe,Hiroshi Watanabe,Sujun Hong,Tomohiro Ikai,Zheming Fan,Ryo Ishimoto,Kakeru Sugimoto,Ruri Imichi*

Main category: cs.CV

TL;DR: 提出了一种结合轮廓信息的2D高斯泼溅框架，通过引入物体分割先验来改善图像压缩时的边缘质量


<details>
  <summary>Details</summary>
Motivation: 现有的2D高斯泼溅方法在Gaussian数量较少时会产生模糊或不清晰的边界，缺乏轮廓感知能力

Method: 提出轮廓信息感知的2D高斯泼溅框架，将物体分割先验融入高斯表示，通过约束每个Gaussian在特定分割区域内进行光栅化，防止跨边界混合，并引入预热方案稳定训练

Result: 在合成色卡和DAVIS数据集上的实验表明，该方法在物体边缘区域实现了比现有2DGS方法更高的重建质量，特别是在Gaussian数量很少的情况下，同时保持快速渲染和低内存使用

Conclusion: 通过结合分割先验和轮廓感知，提出的方法有效解决了2D高斯泼溅在压缩时的边缘模糊问题，实现了更好的边缘保持性能

Abstract: Image representation is a fundamental task in computer vision. Recently, Gaussian Splatting has emerged as an efficient representation framework, and its extension to 2D image representation enables lightweight, yet expressive modeling of visual content. While recent 2D Gaussian Splatting (2DGS) approaches provide compact storage and real-time decoding, they often produce blurry or indistinct boundaries when the number of Gaussians is small due to the lack of contour awareness. In this work, we propose a Contour Information-Aware 2D Gaussian Splatting framework that incorporates object segmentation priors into Gaussian-based image representation. By constraining each Gaussian to a specific segmentation region during rasterization, our method prevents cross-boundary blending and preserves edge structures under high compression. We also introduce a warm-up scheme to stabilize training and improve convergence. Experiments on synthetic color charts and the DAVIS dataset demonstrate that our approach achieves higher reconstruction quality around object edges compared to existing 2DGS methods. The improvement is particularly evident in scenarios with very few Gaussians, while our method still maintains fast rendering and low memory usage.

</details>


### [9] [SoulX-LiveTalk Technical Report](https://arxiv.org/abs/2512.23379)
*Le Shen,Qiao Qian,Tan Yu,Ke Zhou,Tianhang Yu,Yu Zhan,Zhenjie Wang,Ming Tao,Shunshun Yin,Siyuan Liu*

Main category: cs.CV

TL;DR: SoulX-LiveTalk是一个14B参数的实时音频驱动虚拟人生成框架，通过双向注意力蒸馏和自校正机制，在保持高视觉质量的同时实现亚秒级启动延迟和32FPS实时吞吐。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模扩散模型在实时、无限时长、音频驱动的虚拟人生成中存在计算负载与严格延迟约束的冲突，通常需要牺牲视觉质量（强制单向注意力或减少模型容量）。

Method: 采用14B参数框架，使用自我校正双向蒸馏策略保留视频块内的双向注意力，保持时空相关性；引入多步回顾自校正机制防止累积错误；开发全栈推理加速套件，包括混合序列并行、并行VAE和内核级优化。

Result: 首次在14B规模系统中实现亚秒级启动延迟（0.87秒）和32FPS实时吞吐，为高保真交互式数字人合成设定了新标准。

Conclusion: SoulX-LiveTalk通过创新的双向注意力蒸馏和自校正机制，成功解决了大规模扩散模型在实时虚拟人生成中的计算-延迟权衡问题，实现了高质量、低延迟的实时生成。

Abstract: Deploying massive diffusion models for real-time, infinite-duration, audio-driven avatar generation presents a significant engineering challenge, primarily due to the conflict between computational load and strict latency constraints. Existing approaches often compromise visual fidelity by enforcing strictly unidirectional attention mechanisms or reducing model capacity. To address this problem, we introduce \textbf{SoulX-LiveTalk}, a 14B-parameter framework optimized for high-fidelity real-time streaming. Diverging from conventional unidirectional paradigms, we use a \textbf{Self-correcting Bidirectional Distillation} strategy that retains bidirectional attention within video chunks. This design preserves critical spatiotemporal correlations, significantly enhancing motion coherence and visual detail. To ensure stability during infinite generation, we incorporate a \textbf{Multi-step Retrospective Self-Correction Mechanism}, enabling the model to autonomously recover from accumulated errors and preventing collapse. Furthermore, we engineered a full-stack inference acceleration suite incorporating hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations. Extensive evaluations confirm that SoulX-LiveTalk is the first 14B-scale system to achieve a \textbf{sub-second start-up latency (0.87s)} while reaching a real-time throughput of \textbf{32 FPS}, setting a new standard for high-fidelity interactive digital human synthesis.

</details>


### [10] [AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization](https://arxiv.org/abs/2512.23537)
*Binhe Yu,Zhen Wang,Kexin Li,Yuqian Yuan,Wenqiao Zhang,Long Chen,Juncheng Li,Jun Xiao,Yueting Zhuang*

Main category: cs.CV

TL;DR: AnyMS是一个无需训练的多主体定制框架，通过双级注意力解耦机制，在生成过程中协调文本提示、主体图像和布局约束，实现文本对齐、主体身份保持和布局控制的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有多主体定制方法在平衡文本对齐、主体身份保持和布局控制三个关键目标方面存在困难，且依赖额外训练限制了方法的可扩展性和效率。

Method: 提出AnyMS训练免费框架，采用自底向上的双级注意力解耦机制：全局解耦分离文本和视觉条件的交叉注意力确保文本对齐；局部解耦将每个主体的注意力限制在其指定区域防止冲突。使用预训练图像适配器提取主体特定特征，无需主体学习或适配器调优。

Result: 大量实验表明AnyMS达到最先进性能，支持复杂组合并扩展到更多主体数量。

Conclusion: AnyMS通过创新的注意力解耦机制和预训练适配器，有效解决了多主体定制中的平衡问题，实现了无需训练的高效可扩展解决方案。

Abstract: Multi-subject customization aims to synthesize multiple user-specified subjects into a coherent image. To address issues such as subjects missing or conflicts, recent works incorporate layout guidance to provide explicit spatial constraints. However, existing methods still struggle to balance three critical objectives: text alignment, subject identity preservation, and layout control, while the reliance on additional training further limits their scalability and efficiency. In this paper, we present AnyMS, a novel training-free framework for layout-guided multi-subject customization. AnyMS leverages three input conditions: text prompt, subject images, and layout constraints, and introduces a bottom-up dual-level attention decoupling mechanism to harmonize their integration during generation. Specifically, global decoupling separates cross-attention between textual and visual conditions to ensure text alignment. Local decoupling confines each subject's attention to its designated area, which prevents subject conflicts and thus guarantees identity preservation and layout control. Moreover, AnyMS employs pre-trained image adapters to extract subject-specific features aligned with the diffusion model, removing the need for subject learning or adapter tuning. Extensive experiments demonstrate that AnyMS achieves state-of-the-art performance, supporting complex compositions and scaling to a larger number of subjects.

</details>


### [11] [LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation](https://arxiv.org/abs/2512.23576)
*Ethan Chern,Zhulin Hu,Bohao Tang,Jiadi Su,Steffi Chern,Zhijie Deng,Pengfei Liu*

Main category: cs.CV

TL;DR: 本文提出了一种实时交互式视频扩散模型，通过改进蒸馏方法实现20倍推理加速，并构建了LiveTalk系统实现实时多模态人机交互。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型通过双向注意力的迭代去噪过程无法实现实时交互，而现有蒸馏方法主要针对文本到视频生成，在多模态条件下存在视觉伪影和质量下降问题，限制了自然高效的人机交互。

Method: 提出改进的蒸馏配方，重点关注条件输入质量以及在线策略优化的初始化和调度策略，将模型从双向去噪蒸馏为自回归模型，显著减少采样步骤。

Result: 在HDTF、AVSpeech和CelebV-HQ等多模态条件化头像视频生成基准测试中，蒸馏模型以20倍更低的推理成本和延迟匹配了完整步骤双向基线的视觉质量。构建的LiveTalk系统在响应延迟上从1-2分钟降低到实时生成，在多轮视频连贯性和内容质量上优于Sora2、Veo3等最先进模型。

Conclusion: 通过改进的蒸馏方法实现了实时多模态交互视频生成，显著降低了推理延迟，使无缝的人机多模态交互成为可能，为构建通用多模态交互AI系统奠定了基础。

Abstract: Real-time video generation via diffusion is essential for building general-purpose multimodal interactive AI systems. However, the simultaneous denoising of all video frames with bidirectional attention via an iterative process in diffusion models prevents real-time interaction. While existing distillation methods can make the model autoregressive and reduce sampling steps to mitigate this, they focus primarily on text-to-video generation, leaving the human-AI interaction unnatural and less efficient. This paper targets real-time interactive video diffusion conditioned on a multimodal context, including text, image, and audio, to bridge the gap. Given the observation that the leading on-policy distillation approach Self Forcing encounters challenges (visual artifacts like flickering, black frames, and quality degradation) with multimodal conditioning, we investigate an improved distillation recipe with emphasis on the quality of condition inputs as well as the initialization and schedule for the on-policy optimization. On benchmarks for multimodal-conditioned (audio, image, and text) avatar video generation including HDTF, AVSpeech, and CelebV-HQ, our distilled model matches the visual quality of the full-step, bidirectional baselines of similar or larger size with 20x less inference cost and latency. Further, we integrate our model with audio language models and long-form video inference technique Anchor-Heavy Identity Sinks to build LiveTalk, a real-time multimodal interactive avatar system. System-level evaluation on our curated multi-turn interaction benchmark shows LiveTalk outperforms state-of-the-art models (Sora2, Veo3) in multi-turn video coherence and content quality, while reducing response latency from 1 to 2 minutes to real-time generation, enabling seamless human-AI multimodal interaction.

</details>


### [12] [Memorization in 3D Shape Generation: An Empirical Study](https://arxiv.org/abs/2512.23628)
*Shu Pu,Boya Zeng,Kaichen Zhou,Mengyu Wang,Zhuang Liu*

Main category: cs.CV

TL;DR: 本文提出了一个评估框架来量化3D生成模型中的记忆化现象，并通过实验发现数据模态、多样性和建模设计对记忆化的影响，同时提出了减少记忆化的有效策略。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在3D视觉中用于合成新形状，但尚不清楚其生成是否依赖于记忆训练形状。理解记忆化有助于防止训练数据泄露并提高生成结果的多样性。

Method: 设计了一个评估框架来量化3D生成模型中的记忆化，首先应用于现有方法，然后通过潜在向量集扩散模型进行控制实验，研究数据和建模设计对记忆化的影响。

Result: 发现记忆化取决于数据模态，随数据多样性和更细粒度条件而增加；在建模方面，记忆化在中等引导尺度达到峰值，可通过更长的向量集和简单的旋转增强来缓解。

Conclusion: 该框架和分析提供了对3D生成模型中记忆化的实证理解，并提出了简单有效的策略来减少记忆化而不降低生成质量。

Abstract: Generative models are increasingly used in 3D vision to synthesize novel shapes, yet it remains unclear whether their generation relies on memorizing training shapes. Understanding their memorization could help prevent training data leakage and improve the diversity of generated results. In this paper, we design an evaluation framework to quantify memorization in 3D generative models and study the influence of different data and modeling designs on memorization. We first apply our framework to quantify memorization in existing methods. Next, through controlled experiments with a latent vector-set (Vecset) diffusion model, we find that, on the data side, memorization depends on data modality, and increases with data diversity and finer-grained conditioning; on the modeling side, it peaks at a moderate guidance scale and can be mitigated by longer Vecsets and simple rotation augmentation. Together, our framework and analysis provide an empirical understanding of memorization in 3D generative models and suggest simple yet effective strategies to reduce it without degrading generation quality. Our code is available at https://github.com/zlab-princeton/3d_mem.

</details>


### [13] [OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding](https://arxiv.org/abs/2512.23646)
*Keda Tao,Wenjie Du,Bohan Yu,Weiqiang Wang,Jian Liu,Huan Wang*

Main category: cs.CV

TL;DR: OmniAgent：一种完全音频引导的主动感知代理，通过动态编排专用工具实现细粒度音频-视觉推理，在三个音频-视频理解基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有的全模态大语言模型在统一音频和视觉模态方面取得进展，但缺乏细粒度跨模态理解能力，难以实现多模态对齐。需要从被动响应生成转向主动多模态查询的新范式。

Method: 提出OmniAgent，采用动态规划自主按需编排工具调用，战略性地将感知注意力集中在任务相关线索上。核心是新颖的粗到细音频引导感知范式，利用音频线索定位时间事件并指导后续推理。

Result: 在三个音频-视频理解基准测试上进行广泛实证评估，OmniAgent实现了最先进的性能，超越领先的开源和专有模型10%-20%的准确率。

Conclusion: OmniAgent展示了从被动响应生成到主动多模态查询的范式转变，通过动态工具编排和音频引导感知实现了更精细的音频-视觉推理能力。

Abstract: Omnimodal large language models have made significant strides in unifying audio and visual modalities; however, they often lack the fine-grained cross-modal understanding and have difficulty with multimodal alignment. To address these limitations, we introduce OmniAgent, a fully audio-guided active perception agent that dynamically orchestrates specialized tools to achieve more fine-grained audio-visual reasoning. Unlike previous works that rely on rigid, static workflows and dense frame-captioning, this paper demonstrates a paradigm shift from passive response generation to active multimodal inquiry. OmniAgent employs dynamic planning to autonomously orchestrate tool invocation on demand, strategically concentrating perceptual attention on task-relevant cues. Central to our approach is a novel coarse-to-fine audio-guided perception paradigm, which leverages audio cues to localize temporal events and guide subsequent reasoning. Extensive empirical evaluations on three audio-video understanding benchmarks demonstrate that OmniAgent achieves state-of-the-art performance, surpassing leading open-source and proprietary models by substantial margins of 10% - 20% accuracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents](https://arxiv.org/abs/2512.22200)
*Dhruv Tiwari*

Main category: cs.LG

TL;DR: 提出情感启发学习信号（EILS）框架，用生物启发的内部稳态控制机制替代传统外部奖励函数，以提升AI在开放环境中的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前AI依赖外部定义的静态奖励函数，在封闭环境中表现优异但在开放、非平稳的真实世界中脆弱。标准智能体缺乏内部自主性，难以在没有密集反馈时探索，无法适应分布变化，需要大量手动调参。

Method: 引入情感启发学习信号（EILS）框架，将情感建模为连续的稳态评估信号（如好奇心、压力、信心），这些信号从交互历史中推导为向量值内部状态，实时动态调节智能体的优化景观。

Result: 假设这种闭环稳态调节能使EILS智能体在样本效率和非平稳适应性方面优于标准基线方法。

Conclusion: 通过模拟生物情感作为高级稳态控制机制，EILS框架为构建在开放世界中更鲁棒、自适应的智能体提供了新途径。

Abstract: The ruling method in modern Artificial Intelligence spanning from Deep Reinforcement Learning (DRL) to Large Language Models (LLMs) relies on a surge of static, externally defined reward functions. While this "extrinsic maximization" approach has rendered superhuman performance in closed, stationary fields, it produces agents that are fragile in open-ended, real-world environments. Standard agents lack internal autonomy: they struggle to explore without dense feedback, fail to adapt to distribution shifts (non-stationarity), and require extensive manual tuning of static hyperparameters. This paper proposes that the unaddressed factor in robust autonomy is a functional analog to biological emotion, serving as a high-level homeostatic control mechanism. We introduce Emotion-Inspired Learning Signals (EILS), a unified framework that replaces scattered optimization heuristics with a coherent, bio-inspired internal feedback engine. Unlike traditional methods that treat emotions as semantic labels, EILS models them as continuous, homeostatic appraisal signals such as Curiosity, Stress, and Confidence. We formalize these signals as vector-valued internal states derived from interaction history. These states dynamically modulate the agent's optimization landscape in real time: curiosity regulates entropy to prevent mode collapse, stress modulates plasticity to overcome inactivity, and confidence adapts trust regions to stabilize convergence. We hypothesize that this closed-loop homeostatic regulation can enable EILS agents to outperform standard baselines in terms of sample efficiency and non-stationary adaptation.

</details>


### [15] [Valori: A Deterministic Memory Substrate for AI Systems](https://arxiv.org/abs/2512.22280)
*Varshith Gudur*

Main category: cs.LG

TL;DR: Valori提出确定性AI内存基板，用定点算术(Q16.16)替代浮点运算，保证跨平台比特一致性，解决AI系统中因硬件差异导致的非确定性问题。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统依赖浮点运算的向量嵌入存储和搜索，但相同模型、输入和代码在不同硬件架构（如x86 vs ARM）上会产生不同的内存状态和检索结果。这种非确定性破坏了可重现性和安全部署，导致数据静默分歧，影响受监管行业的审计追踪。

Method: Valori采用定点算术(Q16.16)替代浮点内存操作，将内存建模为可重放状态机，在内存边界强制执行确定性，保证比特一致的内存状态、快照和搜索结果。

Result: Valori能够保证跨平台的比特一致性内存状态和检索结果，证明非确定性在索引或检索之前就已产生，并展示了如何在内存边界强制执行确定性。

Conclusion: 确定性内存是可信AI系统的必要基础组件，Valori为解决AI系统中的非确定性问题提供了有效方案，其参考实现已开源。

Abstract: Modern AI systems rely on vector embeddings stored and searched using floating-point arithmetic. While effective for approximate similarity search, this design introduces fundamental non-determinism: identical models, inputs, and code can produce different memory states and retrieval results across hardware architectures (e.g., x86 vs. ARM). This prevents replayability and safe deployment, leading to silent data divergence that prevents post-hoc verification and compromises audit trails in regulated sectors. We present Valori, a deterministic AI memory substrate that replaces floating-point memory operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. Valori guarantees bit-identical memory states, snapshots, and search results across platforms. We demonstrate that non-determinism arises before indexing or retrieval and show how Valori enforces determinism at the memory boundary. Our results suggest that deterministic memory is a necessary primitive for trustworthy AI systems. The reference implementation is open-source and available at https://github.com/varshith-Git/Valori-Kernel (archived at https://zenodo.org/records/18022660).

</details>


### [16] [Multi-Head Spectral-Adaptive Graph Anomaly Detection](https://arxiv.org/abs/2512.22291)
*Qingyue Cao,Bo Jin,Changwei Gong,Xin Tong,Wenzheng Li,Xiaodong Zhou*

Main category: cs.LG

TL;DR: 提出MHSA-GNN，通过轻量级超网络动态生成Chebyshev滤波器参数，结合双正则化策略解决图异常检测中异常节点伪装和异质性共存的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法在处理复杂异常模式时面临挑战：异常节点常伪装成正常节点，导致图中同质性和异质性共存。现有谱图神经网络使用固定全局滤波器，容易导致过度平滑，丢失异常检测所需的高频信号，且缺乏对不同图实例的自适应能力。

Method: 提出多头谱自适应图神经网络(MHSA-GNN)：1) 设计轻量级超网络，基于包含结构统计和Rayleigh商特征的"谱指纹"，为每个实例动态生成Chebyshev滤波器参数；2) 引入双正则化策略防止多头机制模式崩溃：结合师生对比学习(TSC)确保表示准确性，使用Barlow Twins多样性损失(BTD)强制头间正交性。

Result: 在四个真实世界数据集上的实验表明，该方法能有效保留高频异常信号，显著优于现有最先进方法，在高度异质性数据集上表现出优秀的鲁棒性。

Conclusion: MHSA-GNN通过实例特定的自适应滤波策略解决了图异常检测中的关键挑战，在保留高频异常信号和适应图异质性方面表现出色，为金融欺诈和风险控制等应用提供了有效解决方案。

Abstract: Graph anomaly detection technology has broad applications in financial fraud and risk control. However, existing graph anomaly detection methods often face significant challenges when dealing with complex and variable abnormal patterns, as anomalous nodes are often disguised and mixed with normal nodes, leading to the coexistence of homophily and heterophily in the graph domain. Recent spectral graph neural networks have made notable progress in addressing this issue; however, current techniques typically employ fixed, globally shared filters. This 'one-size-fits-all' approach can easily cause over-smoothing, erasing critical high-frequency signals needed for fraud detection, and lacks adaptive capabilities for different graph instances. To solve this problem, we propose a Multi-Head Spectral-Adaptive Graph Neural Network (MHSA-GNN). The core innovation is the design of a lightweight hypernetwork that, conditioned on a 'spectral fingerprint' containing structural statistics and Rayleigh quotient features, dynamically generates Chebyshev filter parameters tailored to each instance. This enables a customized filtering strategy for each node and its local subgraph. Additionally, to prevent mode collapse in the multi-head mechanism, we introduce a novel dual regularization strategy that combines teacher-student contrastive learning (TSC) to ensure representation accuracy and Barlow Twins diversity loss (BTD) to enforce orthogonality among heads. Extensive experiments on four real-world datasets demonstrate that our method effectively preserves high-frequency abnormal signals and significantly outperforms existing state-of-the-art methods, especially showing excellent robustness on highly heterogeneous datasets.

</details>


### [17] [LangPrecip: Language-Aware Multimodal Precipitation Nowcasting](https://arxiv.org/abs/2512.22317)
*Xudong Ling,Tianxi Huang,Qian Dong,Tao He,Chaorong Li,Guiduo Duan*

Main category: cs.LG

TL;DR: LangPrecip：一个语言感知的多模态降水临近预报框架，通过将气象文本作为降水演变的语义运动约束，在Rectified Flow范式下将文本和雷达信息高效集成，显著提升极端降水预报性能。


<details>
  <summary>Details</summary>
Motivation: 短期降水临近预报具有高度不确定性和约束不足的特点，现有生成方法主要依赖视觉条件，导致未来运动约束弱且模糊。需要更强的语义约束来改善预报准确性。

Method: 提出语言感知多模态预报框架(LangPrecip)，将气象文本作为降水演变的语义运动约束，在Rectified Flow范式下将临近预报构建为语义约束的轨迹生成问题，在潜在空间中高效集成文本和雷达信息。

Result: 在瑞典和MRMS数据集上实验显示，相比现有最佳方法，在80分钟预报时效上，强降水CSI分别提升超过60%和19%。同时构建了包含16万对雷达序列和运动描述的大规模多模态数据集LangPrecip-160k。

Conclusion: 将语言作为语义运动约束能显著改善降水临近预报性能，特别是在极端天气事件中。多模态方法为气象预报提供了新的有效途径。

Abstract: Short-term precipitation nowcasting is an inherently uncertain and under-constrained spatiotemporal forecasting problem, especially for rapidly evolving and extreme weather events. Existing generative approaches rely primarily on visual conditioning, leaving future motion weakly constrained and ambiguous. We propose a language-aware multimodal nowcasting framework(LangPrecip) that treats meteorological text as a semantic motion constraint on precipitation evolution. By formulating nowcasting as a semantically constrained trajectory generation problem under the Rectified Flow paradigm, our method enables efficient and physically consistent integration of textual and radar information in latent space.We further introduce LangPrecip-160k, a large-scale multimodal dataset with 160k paired radar sequences and motion descriptions. Experiments on Swedish and MRMS datasets show consistent improvements over state-of-the-art methods, achieving over 60 \% and 19\% gains in heavy-rainfall CSI at an 80-minute lead time.

</details>


### [18] [Causality-Inspired Safe Residual Correction for Multivariate Time Series](https://arxiv.org/abs/2512.22428)
*Jianxiang Xie,Yuncheng Hua*

Main category: cs.LG

TL;DR: CRC是一个因果启发的安全残差校正框架，通过解耦自变量和交叉变量动态来确保预测性能不退化，具有严格的安全机制防止有害更新。


<details>
  <summary>Details</summary>
Motivation: 现代多元预测器（如Transformers和GNNs）虽然性能强大，但存在特定变量或时间范围的系统性误差，且缺乏部署时性能不退化的保证。现有残差校正方法虽然可能提高平均准确率，但可能"以错误的方式帮助"，在未见场景中导致局部失败。

Method: CRC采用分而治之策略：1）使用因果启发的编码器通过解耦自变量和交叉变量动态来暴露方向感知结构；2）使用混合校正器建模残差误差；3）通过严格的四重安全机制控制校正过程，防止有害更新。

Result: 在多个数据集和预测骨干网络上的实验表明，CRC能持续提高准确性，消融研究确认其核心安全机制能确保极高的非退化率（NDR），使其成为适合安全可靠部署的校正框架。

Conclusion: CRC是一个即插即用的安全残差校正框架，通过因果启发的结构和严格的安全机制，解决了现有方法在部署时可能导致的性能退化问题，为预测系统提供了可靠的安全保障。

Abstract: While modern multivariate forecasters such as Transformers and GNNs achieve strong benchmark performance, they often suffer from systematic errors at specific variables or horizons and, critically, lack guarantees against performance degradation in deployment. Existing post-hoc residual correction methods attempt to fix these errors, but are inherently greedy: although they may improve average accuracy, they can also "help in the wrong way" by overcorrecting reliable predictions and causing local failures in unseen scenarios.
  To address this critical "safety gap," we propose CRC (Causality-inspired Safe Residual Correction), a plug-and-play framework explicitly designed to ensure non-degradation. CRC follows a divide-and-conquer philosophy: it employs a causality-inspired encoder to expose direction-aware structure by decoupling self- and cross-variable dynamics, and a hybrid corrector to model residual errors. Crucially, the correction process is governed by a strict four-fold safety mechanism that prevents harmful updates.
  Experiments across multiple datasets and forecasting backbones show that CRC consistently improves accuracy, while an in-depth ablation study confirms that its core safety mechanisms ensure exceptionally high non-degradation rates (NDR), making CRC a correction framework suited for safe and reliable deployment.

</details>


### [19] [Predictive Modeling of Power Outages during Extreme Events: Integrating Weather and Socio-Economic Factors](https://arxiv.org/abs/2512.22699)
*Antar Kumar Biswas,Masoud H. Nazari*

Main category: cs.LG

TL;DR: 提出基于机器学习预测极端事件导致停电的框架，整合多源数据，在密歇根州验证中LSTM表现最佳，发现经济条件和基础设施发展与停电发生率负相关。


<details>
  <summary>Details</summary>
Motivation: 针对低概率高后果的停电场景，现有预测方法可能不够全面。需要整合天气、社会经济、基础设施等多维度数据，并考虑社区脆弱性因素，以更准确预测极端事件下的停电风险。

Method: 整合EAGLE-I停电记录（2014-2024）与天气、社会经济、基础设施和季节性事件数据，加入社会人口指标分析社区脆弱性。评估四种机器学习模型：随机森林、支持向量机、自适应提升和长短期记忆网络。在密歇根州下半岛县区的大规模数据集上进行实验验证。

Result: 在所有测试模型中，LSTM网络取得了最低的预测误差。结果还表明，更强的经济条件和更发达的基础设施与更低的停电发生率相关。

Conclusion: 提出的学习框架能有效预测极端事件导致的停电，LSTM模型表现最佳。社会经济和基础设施因素对停电风险有显著影响，为电力系统规划和应急响应提供了重要见解。

Abstract: This paper presents a novel learning-based framework for predicting power outages caused by extreme events. The proposed approach specifically targets low-probability, high-consequence outage scenarios and leverages a comprehensive set of features derived from publicly available data sources. We integrate EAGLE-I outage records (2014-2024) with weather, socio-economic, infrastructure, and seasonal event data. Incorporating social and demographic indicators reveals underlying patterns of community vulnerability and provides a clearer understanding of outage risk during extreme conditions. Four machine learning models (Random Forest (RF), Support Vector Machine (SVM), Adaptive Boosting (AdaBoost), and Long Short-Term Memory (LSTM)) are evaluated. Experimental validation is performed on a large-scale dataset covering counties in the lower peninsula of Michigan. Among all models tested, the LSTM network achieves the lowest prediction error. Additionally, the results demonstrate that stronger economic conditions and more developed infrastructure are associated with lower outage occurrence.

</details>


### [20] [Debugging Tabular Log as Dynamic Graphs](https://arxiv.org/abs/2512.22903)
*Chumeng Liang,Zhanyang Jin,Zahaib Akhtar,Mona Pereira,Haofei Yu,Jiaxuan You*

Main category: cs.LG

TL;DR: 提出GraphLogDebugger框架，基于动态图来调试表格日志，通过构建对象和事件的异质节点连接，将系统恢复为演化动态图，使用简单的动态GNN即可超越LLMs的调试效果。


<details>
  <summary>Details</summary>
Motivation: 当前处理文本丰富的表格日志数据过度依赖大语言模型和其他重型模型，导致灵活性和可扩展性受限，需要更高效的方法来调试表格日志。

Method: 提出GraphLogDebugger框架：1) 为对象和事件构建异质节点；2) 连接节点间边；3) 将系统恢复为演化动态图；4) 使用简单的动态图神经网络进行调试。

Result: 在计算机系统和学术论文的真实日志数据集上验证，简单的动态GNN在调试表格日志方面能够超越大语言模型。

Conclusion: 通过动态图建模，GraphLogDebugger框架能够有效调试表格日志，相比依赖大语言模型的方法具有更好的灵活性和可扩展性。

Abstract: Tabular log abstracts objects and events in the real-world system and reports their updates to reflect the change of the system, where one can detect real-world inconsistencies efficiently by debugging corresponding log entries. However, recent advances in processing text-enriched tabular log data overly depend on large language models (LLMs) and other heavy-load models, thus suffering from limited flexibility and scalability. This paper proposes a new framework, GraphLogDebugger, to debug tabular log based on dynamic graphs. By constructing heterogeneous nodes for objects and events and connecting node-wise edges, the framework recovers the system behind the tabular log as an evolving dynamic graph. With the help of our dynamic graph modeling, a simple dynamic Graph Neural Network (GNN) is representative enough to outperform LLMs in debugging tabular log, which is validated by experimental results on real-world log datasets of computer systems and academic papers.

</details>


### [21] [GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks](https://arxiv.org/abs/2512.22772)
*Xuyan Li,Jie Wang,Zheng Yan*

Main category: cs.LG

TL;DR: GRExplainer：首个通用、高效且用户友好的TGNN解释方法，通过节点序列统一特征表示，适用于快照式和事件式TGNN，利用BFS和时序信息提高效率，基于RNN自动生成解释。


<details>
  <summary>Details</summary>
Motivation: TGNN在动态图处理中表现出色，但缺乏透明度和可解释性限制了实际应用。现有TGNN解释方法存在三个主要问题：1）针对特定TGNN类型，缺乏通用性；2）计算成本高，不适用于大规模网络；3）忽视解释的结构连通性且需要先验知识，用户友好性差。

Method: 提出GRExplainer方法：1）提取节点序列作为统一特征表示，使其独立于特定输入格式，适用于快照式和事件式TGNN；2）利用广度优先搜索（BFS）和时序信息构建输入节点序列，减少冗余计算；3）设计基于循环神经网络（RNN）的生成模型，实现自动化连续解释生成。

Result: 在6个真实世界数据集和3个目标TGNN上的实验表明，GRExplainer在通用性、效率和用户友好性方面优于现有基线方法。

Conclusion: GRExplainer是首个通用、高效且用户友好的TGNN解释方法，解决了现有方法的局限性，通过统一的节点序列表示、优化的计算策略和自动化生成机制，为TGNN的透明化应用提供了有效解决方案。

Abstract: Dynamic graphs are widely used to represent evolving real-world networks. Temporal Graph Neural Networks (TGNNs) have emerged as a powerful tool for processing such graphs, but the lack of transparency and explainability limits their practical adoption. Research on TGNN explainability is still in its early stages and faces several key issues: (i) Current methods are tailored to specific TGNN types, restricting generality. (ii) They suffer from high computational costs, making them unsuitable for large-scale networks. (iii) They often overlook the structural connectivity of explanations and require prior knowledge, reducing user-friendliness. To address these issues, we propose GRExplainer, the first universal, efficient, and user-friendly explanation method for TGNNs. GRExplainer extracts node sequences as a unified feature representation, making it independent of specific input formats and thus applicable to both snapshot-based and event-based TGNNs (the major types of TGNNs). By utilizing breadth-first search and temporal information to construct input node sequences, GRExplainer reduces redundant computation and improves efficiency. To enhance user-friendliness, we design a generative model based on Recurrent Neural Networks (RNNs), enabling automated and continuous explanation generation. Experiments on six real-world datasets with three target TGNNs show that GRExplainer outperforms existing baseline methods in generality, efficiency, and user-friendliness.

</details>


### [22] [PFed-Signal: An ADR Prediction Model based on Federated Learning](https://arxiv.org/abs/2512.23262)
*Tao Li,Peilin Li,Kui Lu,Yilei Wang,Junliang Shang,Guangshun Li,Huiyu Zhou*

Main category: cs.LG

TL;DR: PFed-signal：基于联邦学习的药物不良反应信号预测模型，通过欧氏距离消除FAERS数据中的偏差，提高预测准确性


<details>
  <summary>Details</summary>
Motivation: FAERS系统中存在偏差记录，基于这些数据预测药物不良反应可能误导在线诊断。传统方法如ROR和PRR依赖统计方法无法消除偏差数据，导致信号预测不准确

Method: 提出PFed-signal联邦学习模型：1) Pfed-Split方法按ADR分割原始数据集；2) ADR-signal模型包括基于联邦学习的偏差数据识别（使用欧氏距离）和基于Transformer的ADR预测模型

Result: 在清洗后的数据集上，ROR和PRR优于传统方法。PFed-Signal的准确率0.887、F1分数0.890、召回率0.913、AUC 0.957，均高于基线模型

Conclusion: PFed-signal通过联邦学习和欧氏距离有效消除FAERS数据偏差，显著提高了ADR信号预测的准确性，优于传统统计方法

Abstract: The adverse drug reactions (ADRs) predicted based on the biased records in FAERS (U.S. Food and Drug Administration Adverse Event Reporting System) may mislead diagnosis online. Generally, such problems are solved by optimizing reporting odds ratio (ROR) or proportional reporting ratio (PRR). However, these methods that rely on statistical methods cannot eliminate the biased data, leading to inaccurate signal prediction. In this paper, we propose PFed-signal, a federated learning-based signal prediction model of ADR, which utilizes the Euclidean distance to eliminate the biased data from FAERS, thereby improving the accuracy of ADR prediction. Specifically, we first propose Pfed-Split, a method to split the original dataset into a split dataset based on ADR. Then we propose ADR-signal, an ADR prediction model, including a biased data identification method based on federated learning and an ADR prediction model based on Transformer. The former identifies the biased data according to the Euclidean distance and generates a clean dataset by deleting the biased data. The latter is an ADR prediction model based on Transformer trained on the clean data set. The results show that the ROR and PRR on the clean dataset are better than those of the traditional methods. Furthermore, the accuracy rate, F1 score, recall rate and AUC of PFed-Signal are 0.887, 0.890, 0.913 and 0.957 respectively, which are higher than the baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Bidirectional RAG: Safe Self-Improving Retrieval-Augmented Generation Through Multi-Stage Validation](https://arxiv.org/abs/2512.22199)
*Teja Chinthala*

Main category: cs.AI

TL;DR: Bidirectional RAG 是一种新型检索增强生成架构，通过验证高质量生成响应的写回机制实现安全语料库扩展，相比标准RAG将平均覆盖率从20.33%提升至40.58%，同时比朴素写回方法减少72%的文档添加。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用静态知识库，无法从用户交互中学习和进化。需要一种能够安全扩展语料库的RAG架构，既能积累知识又避免幻觉污染。

Method: 提出Bidirectional RAG架构，采用多阶段接受层，结合基于NLI的蕴含验证、归因检查和新颖性检测，确保高质量生成响应的安全写回，实现语料库的验证扩展。

Result: 在四个数据集（Natural Questions、TriviaQA、HotpotQA、Stack Overflow）上的实验显示，Bidirectional RAG平均覆盖率达到40.58%，几乎是标准RAG（20.33%）的两倍，同时比朴素写回方法少添加72%的文档（140 vs 500）。

Conclusion: 研究表明，在严格验证机制管理下，自我改进的RAG系统是可行且安全的，为从部署中学习的RAG系统提供了实用路径。

Abstract: Retrieval-Augmented Generation RAG systems enhance large language models by grounding responses in external knowledge bases, but conventional RAG architectures operate with static corpora that cannot evolve from user interactions. We introduce Bidirectional RAG, a novel RAG architecture that enables safe corpus expansion through validated write back of high quality generated responses. Our system employs a multi stage acceptance layer combining grounding verification (NLI based entailment, attribution checking, and novelty detection to prevent hallucination pollution while enabling knowledge accumulation. Across four datasets Natural Questions, TriviaQA, HotpotQA, Stack Overflow with three random seeds 12 experiments per system, Bidirectional RAG achieves 40.58% average coverage nearly doubling Standard RAG 20.33% while adding 72% fewer documents than naive write back 140 vs 500. Our work demonstrates that self improving RAG is feasible and safe when governed by rigorous validation, offering a practical path toward RAG systems that learn from deployment.

</details>


### [24] [Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities](https://arxiv.org/abs/2512.23508)
*Alessio Benavoli,Alessandro Facchini,Marco Zaffalon*

Main category: cs.AI

TL;DR: 论文探讨AI对齐与安全，提出通过AI协助游戏和关机游戏框架研究如何确保AI系统符合人类价值观并保持安全，强调需要处理不确定性和非阿基米德偏好


<details>
  <summary>Details</summary>
Motivation: 确保AI系统与人类价值观对齐并保持安全是重要挑战。现有框架如AI协助问题和关机问题揭示了AI设计中的核心困难：AI需要学习未知的人类效用函数，同时要正确处理关机指令而不试图干预关机过程

Method: 采用AI协助游戏和AI关机游戏作为分析框架。AI协助问题关注设计能帮助人类最大化其效用函数的AI代理，但AI不知道这些函数必须学习。关机问题要求AI在按下关机按钮时关机，不干预按钮按下过程，同时保持任务能力

Result: 分析表明解决这些挑战需要AI代理能够处理不确定性，并同时处理不完全偏好和非阿基米德偏好。这意味着AI需要能够推理未知的人类效用函数，并在面对关机指令时做出适当响应

Conclusion: 确保AI安全对齐需要开发能够处理不确定性和复杂偏好的AI系统。AI协助和关机游戏框架为分析这些挑战提供了有用的理论工具，强调了对鲁棒AI推理能力的需求

Abstract: How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [25] [NepEMO: A Multi-Label Emotion and Sentiment Analysis on Nepali Reddit with Linguistic Insights and Temporal Trends](https://arxiv.org/abs/2512.22823)
*Sameer Sitoula,Tej Bahadur Shahi,Laxmi Prasad Bhatt,Anisha Pokhrel,Arjun Neupane*

Main category: cs.CL

TL;DR: 本文提出了NepEMO数据集，用于尼泊尔语Reddit帖子的多标签情感和情感分类，包含4,462个帖子，涵盖5种情绪和3种情感类别，并比较了多种机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台如Reddit为用户提供了匿名表达敏感话题（如健康和生活）的空间。尼泊尔语Reddit帖子中的情感分析缺乏专门数据集，因此需要构建尼泊尔语多标签情感分类数据集。

Method: 构建了NepEMO数据集，包含4,462个帖子（2019年1月-2025年6月），使用英语、罗马化尼泊尔语和天城体文字，标注了5种情绪（恐惧、愤怒、悲伤、喜悦、抑郁）和3种情感类别（积极、消极、中性）。进行了详细的语言分析，包括情感趋势、情感共现、情感特定n-gram，以及使用LDA和TF-IDF的主题建模。比较了传统机器学习、深度学习和Transformer模型。

Result: Transformer模型在多标签情感分类和情感分类任务中始终优于传统机器学习和深度学习模型。

Conclusion: NepEMO数据集填补了尼泊尔语社交媒体情感分析的空白，为相关研究提供了有价值的资源。Transformer模型在尼泊尔语情感分析任务中表现出最佳性能。

Abstract: Social media (SM) platforms (e.g. Facebook, Twitter, and Reddit) are increasingly leveraged to share opinions and emotions, specifically during challenging events, such as natural disasters, pandemics, and political elections, and joyful occasions like festivals and celebrations. Among the SM platforms, Reddit provides a unique space for its users to anonymously express their experiences and thoughts on sensitive issues such as health and daily life. In this work, we present a novel dataset, called NepEMO, for multi-label emotion (MLE) and sentiment classification (SC) on the Nepali subreddit post. We curate and build a manually annotated dataset of 4,462 posts (January 2019- June 2025) written in English, Romanised Nepali and Devanagari script for five emotions (fear, anger, sadness, joy, and depression) and three sentiment classes (positive, negative, and neutral). We perform a detailed analysis of posts to capture linguistic insights, including emotion trends, co-occurrence of emotions, sentiment-specific n-grams, and topic modelling using Latent Dirichlet Allocation and TF-IDF keyword extraction. Finally, we compare various traditional machine learning (ML), deep learning (DL), and transformer models for MLE and SC tasks. The result shows that transformer models consistently outperform the ML and DL models for both tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [26] [ParaMaP: Parallel Mapping and Collision-free Motion Planning for Reactive Robot Manipulation](https://arxiv.org/abs/2512.22575)
*Xuewei Zhang,Bailing Tian,Kai Zheng,Yulin Hui,Junjie Lu,Zhiyu Li*

Main category: cs.RO

TL;DR: 提出并行建图与运动规划框架，通过GPU加速的欧几里得距离变换和采样模型预测控制，实现未知环境下机械臂实时无碰撞运动规划


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，由于持续感知更新和频繁在线重规划的需求，实时无碰撞运动规划对机器人操作仍然具有挑战性

Method: 1) 建图端：使用GPU加速的欧几里得距离变换构建密集距离场表示，并加入机器人掩码更新机制防止错误自碰撞检测
2) 规划端：将运动生成建模为随机优化问题，在SE(3)上定义几何一致的姿态跟踪度量，通过采样模型预测控制框架并行评估大量候选轨迹

Result: 整个建图与规划流程在GPU上实现以支持高频重规划，通过大量仿真和7自由度机械臂真实实验验证了框架的有效性

Conclusion: 提出的并行建图与运动规划框架能够有效解决未知环境下机器人操作的实时无碰撞运动规划挑战

Abstract: Real-time and collision-free motion planning remains challenging for robotic manipulation in unknown environments due to continuous perception updates and the need for frequent online replanning. To address these challenges, we propose a parallel mapping and motion planning framework that tightly integrates Euclidean Distance Transform (EDT)-based environment representation with a sampling-based model predictive control (SMPC) planner. On the mapping side, a dense distance-field-based representation is constructed using a GPU-based EDT and augmented with a robot-masked update mechanism to prevent false self-collision detections during online perception. On the planning side, motion generation is formulated as a stochastic optimization problem with a unified objective function and efficiently solved by evaluating large batches of candidate rollouts in parallel within a SMPC framework, in which a geometrically consistent pose tracking metric defined on SE(3) is incorporated to ensure fast and accurate convergence to the target pose. The entire mapping and planning pipeline is implemented on the GPU to support high-frequency replanning. The effectiveness of the proposed framework is validated through extensive simulations and real-world experiments on a 7-DoF robotic manipulator. More details are available at: https://zxw610.github.io/ParaMaP.

</details>


### [27] [Sistema de navegación de cobertura para vehículos no holonómicos en ambientes de exterior](https://arxiv.org/abs/2512.22734)
*Michelle Valenzuela,Francisco Leiva,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出一种用于非完整机器人的覆盖导航系统，旨在实现矿区清洁、筑坝等覆盖任务的自动化，系统包含路径规划与异常恢复功能，在模拟和真实环境中达到约90%的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 移动机器人覆盖导航在矿业等工业领域有重要应用价值，如清洁、筑坝等任务。自动化这些过程对提升作业安全性至关重要，但目前缺乏针对非完整机器人的覆盖导航系统。

Method: 开发了包含路径计算和恢复行为的覆盖导航系统。系统能为移动平台计算覆盖特定区域的路径，并能处理动态障碍、未映射障碍等突发情况，执行规避和恢复操作以确保完整覆盖。

Result: 在多种模拟和真实室外环境中测试，大多数实验获得接近90%的覆盖率。系统展示了在真实环境中处理动态障碍和恢复覆盖的能力。

Conclusion: 该系统作为概念验证，展示了覆盖导航在矿业等工业过程中自动化的潜力。下一步将扩展到真实采矿机械上，在真实环境中验证其操作性能。

Abstract: In mobile robotics, coverage navigation refers to the deliberate movement of a robot with the purpose of covering a certain area or volume. Performing this task properly is fundamental for the execution of several activities, for instance, cleaning a facility with a robotic vacuum cleaner. In the mining industry, it is required to perform coverage in several unit processes related with material movement using industrial machinery, for example, in cleaning tasks, in dumps, and in the construction of tailings dam walls. The automation of these processes is fundamental to enhance the security associated with their execution. In this work, a coverage navigation system for a non-holonomic robot is presented. This work is intended to be a proof of concept for the potential automation of various unit processes that require coverage navigation like the ones mentioned before. The developed system includes the calculation of routes that allow a mobile platform to cover a specific area, and incorporates recovery behaviors in case that an unforeseen event occurs, such as the arising of dynamic or previously unmapped obstacles in the terrain to be covered, e.g., other machines or pedestrians passing through the area, being able to perform evasive maneuvers and post-recovery to ensure a complete coverage of the terrain. The system was tested in different simulated and real outdoor environments, obtaining results near 90% of coverage in the majority of experiments. The next step of development is to scale up the utilized robot to a mining machine/vehicle whose operation will be validated in a real environment. The result of one of the tests performed in the real world can be seen in the video available in https://youtu.be/gK7_3bK1P5g.

</details>


### [28] [SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling](https://arxiv.org/abs/2512.23162)
*Yufan He,Pengfei Guo,Mengya Xu,Zhaoshuo Li,Andriy Myronenko,Dillan Imans,Bingjie Liu,Dongren Yang,Mingxue Gu,Yongnan Ji,Yueming Jin,Ren Zhao,Baiyong Shen,Daguang Xu*

Main category: cs.RO

TL;DR: 利用SurgWorld世界模型生成合成手术视频，通过逆动力学模型推断伪运动学数据，解决了手术机器人数据稀缺问题，显著提升了VLA策略性能。


<details>
  <summary>Details</summary>
Motivation: 手术机器人面临数据稀缺的根本障碍，虽然有大量手术视频但缺乏对应的动作标签，无法直接应用模仿学习或VLA训练。

Method: 1. 构建SATA数据集（手术动作文本对齐）；2. 基于最先进的物理AI世界模型和SATA构建SurgWorld，生成多样化、可泛化的真实手术视频；3. 首次使用逆动力学模型从合成手术视频推断伪运动学数据，生成合成的配对视频-动作数据。

Result: 使用这些增强数据训练的手术VLA策略在真实手术机器人平台上显著优于仅使用真实演示训练的模型。

Conclusion: 该方法通过利用未标记手术视频的丰富性和生成式世界建模，为自主手术技能获取提供了可扩展的路径，打开了通向可泛化且数据高效的手术机器人策略的大门。

Abstract: Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.

</details>
