<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Colors See Colors Ignore: Clothes Changing ReID with Color Disentanglement](https://arxiv.org/abs/2507.07230)
*Priyank Pathak,Yogesh S. Rawat*

Main category: cs.CV

TL;DR: 论文提出了一种名为CSCI的轻量级方法，利用颜色信息解决衣物更换重识别问题，无需额外标注或模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖额外模型或标注学习衣物不变特征，资源消耗大。本文探索颜色作为轻量级代理，减少外观偏差。

Method: 提出CSCI方法，利用RGB信息，通过S2A自注意力机制分离颜色与身份特征。

Result: 在四个CC-ReID数据集上显著提升性能，图像重识别Top-1提升2.9%-5.0%，视频重识别提升1.0%-2.5%。

Conclusion: 颜色是解决衣物更换重识别外观偏差的高效低成本方案。

Abstract: Clothes-Changing Re-Identification (CC-ReID) aims to recognize individuals
across different locations and times, irrespective of clothing. Existing
methods often rely on additional models or annotations to learn robust,
clothing-invariant features, making them resource-intensive. In contrast, we
explore the use of color - specifically foreground and background colors - as a
lightweight, annotation-free proxy for mitigating appearance bias in ReID
models. We propose Colors See, Colors Ignore (CSCI), an RGB-only method that
leverages color information directly from raw images or video frames. CSCI
efficiently captures color-related appearance bias ('Color See') while
disentangling it from identity-relevant ReID features ('Color Ignore'). To
achieve this, we introduce S2A self-attention, a novel self-attention to
prevent information leak between color and identity cues within the feature
space. Our analysis shows a strong correspondence between learned color
embeddings and clothing attributes, validating color as an effective proxy when
explicit clothing labels are unavailable. We demonstrate the effectiveness of
CSCI on both image and video ReID with extensive experiments on four CC-ReID
datasets. We improve the baseline by Top-1 2.9% on LTCC and 5.0% on PRCC for
image-based ReID, and 1.0% on CCVID and 2.5% on MeVID for video-based ReID
without relying on additional supervision. Our results highlight the potential
of color as a cost-effective solution for addressing appearance bias in
CC-ReID. Github: https://github.com/ppriyank/ICCV-CSCI-Person-ReID.

</details>


### [2] [DisenQ: Disentangling Q-Former for Activity-Biometrics](https://arxiv.org/abs/2507.07262)
*Shehreen Azad,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 提出了一种多模态语言引导框架DisenQ，用于解决活动生物识别中身份特征与运动动态和外观变化纠缠的问题，并在多个基准测试中取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 传统身份识别在多样化活动中面临身份特征与运动动态和外观变化纠缠的挑战，现有方法依赖额外视觉数据但存在提取不准确的问题。

Method: 提出DisenQ框架，利用结构化文本指导分离生物特征、运动和非生物特征，避免身份特征受外观和运动变化影响。

Result: 在三个活动视频基准测试中达到最优性能，并在传统视频识别基准测试中表现出色。

Conclusion: DisenQ框架通过语言指导有效解决了活动生物识别中的特征纠缠问题，具有广泛适用性。

Abstract: In this work, we address activity-biometrics, which involves identifying
individuals across diverse set of activities. Unlike traditional person
identification, this setting introduces additional challenges as identity cues
become entangled with motion dynamics and appearance variations, making
biometrics feature learning more complex. While additional visual data like
pose and/or silhouette help, they often struggle from extraction inaccuracies.
To overcome this, we propose a multimodal language-guided framework that
replaces reliance on additional visual data with structured textual
supervision. At its core, we introduce \textbf{DisenQ} (\textbf{Disen}tangling
\textbf{Q}-Former), a unified querying transformer that disentangles
biometrics, motion, and non-biometrics features by leveraging structured
language guidance. This ensures identity cues remain independent of appearance
and motion variations, preventing misidentifications. We evaluate our approach
on three activity-based video benchmarks, achieving state-of-the-art
performance. Additionally, we demonstrate strong generalization to complex
real-world scenario with competitive performance on a traditional video-based
identification benchmark, showing the effectiveness of our framework.

</details>


### [3] [Multi-Scale Attention and Gated Shifting for Fine-Grained Event Spotting in Videos](https://arxiv.org/abs/2507.07381)
*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal*

Main category: cs.CV

TL;DR: 提出了一种多尺度注意力门移位模块（MSAGSM），用于增强体育视频中精确事件点检测（PES）的性能，并通过新数据集TTA验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有PES模型的时空模块在时间感受野和空间适应性上存在局限，需要改进。

Method: 提出MSAGSM模块，结合多尺度时间扩张和多头空间注意力，提升时空建模能力。

Result: 在五个PES基准测试中表现优异，性能显著提升，计算开销小。

Conclusion: MSAGSM是一种轻量级即插即用模块，能有效提升PES任务性能，并引入新数据集TTA推动领域发展。

Abstract: Precise Event Spotting (PES) in sports videos requires frame-level
recognition of fine-grained actions from single-camera footage. Existing PES
models typically incorporate lightweight temporal modules such as Gate Shift
Module (GSM) or Gate Shift Fuse (GSF) to enrich 2D CNN feature extractors with
temporal context. However, these modules are limited in both temporal receptive
field and spatial adaptability. We propose a Multi-Scale Attention Gate Shift
Module (MSAGSM) that enhances GSM with multi-scale temporal dilations and
multi-head spatial attention, enabling efficient modeling of both short- and
long-term dependencies while focusing on salient regions. MSAGSM is a
lightweight plug-and-play module that can be easily integrated with various 2D
backbones. To further advance the field, we introduce the Table Tennis
Australia (TTA) dataset-the first PES benchmark for table tennis-containing
over 4800 precisely annotated events. Extensive experiments across five PES
benchmarks demonstrate that MSAGSM consistently improves performance with
minimal overhead, setting new state-of-the-art results.

</details>


### [4] [Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking](https://arxiv.org/abs/2507.07483)
*Qiangqiang Wu,Yi Yu,Chenqi Kong,Ziquan Liu,Jia Wan,Haoliang Li,Alex C. Kot,Antoni B. Chan*

Main category: cs.CV

TL;DR: 本文提出了一种生成时间不可学习示例（TUEs）的新框架，以保护视频数据隐私，防止未经授权的视觉对象跟踪（VOT）模型训练。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体的兴起，大量用户上传的视频被用于VOT训练，但数据隐私问题被忽视，许多私人视频未经授权被用于商业模型训练。

Method: 提出了一种生成TUEs的生成框架，并引入时间对比损失以增强效果，确保训练视频数据隐私。

Result: 实验表明，该方法在视频数据隐私保护方面表现优异，具有强大的跨模型、数据集和时间匹配任务的迁移能力。

Conclusion: 该框架为视频数据隐私保护提供了高效、可扩展的解决方案，填补了现有方法的不足。

Abstract: With the rise of social media, vast amounts of user-uploaded videos (e.g.,
YouTube) are utilized as training data for Visual Object Tracking (VOT).
However, the VOT community has largely overlooked video data-privacy issues, as
many private videos have been collected and used for training commercial models
without authorization. To alleviate these issues, this paper presents the first
investigation on preventing personal video data from unauthorized exploitation
by deep trackers. Existing methods for preventing unauthorized data use
primarily focus on image-based tasks (e.g., image classification), directly
applying them to videos reveals several limitations, including inefficiency,
limited effectiveness, and poor generalizability. To address these issues, we
propose a novel generative framework for generating Temporal Unlearnable
Examples (TUEs), and whose efficient computation makes it scalable for usage on
large-scale video datasets. The trackers trained w/ TUEs heavily rely on
unlearnable noises for temporal matching, ignoring the original data structure
and thus ensuring training video data-privacy. To enhance the effectiveness of
TUEs, we introduce a temporal contrastive loss, which further corrupts the
learning of existing trackers when using our TUEs for training. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
in video data-privacy protection, with strong transferability across VOT
models, datasets, and temporal matching tasks.

</details>


### [5] [EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream Spiking Neural Networks](https://arxiv.org/abs/2507.07734)
*Michael Neumeier,Jules Lecomte,Nils Kazinski,Soubarna Banik,Bing Li,Axel von Arnim*

Main category: cs.CV

TL;DR: 提出了一种高频率的双流脉冲神经网络（SNN），用于早期人类活动识别，在THU EACT-50数据集上准确率提升2%。


<details>
  <summary>Details</summary>
Motivation: 早期识别人类活动对安全性和响应性至关重要，事件视觉传感器的高时间分辨率和低延迟适合这一需求，但现有方法限制了早期预测能力。

Method: 采用高频率双流SNN处理事件数据，避免传统方法的低速率限制。

Result: 在THU EACT-50数据集上准确率提升2%，并在早期识别框架中评估了Top-1和Top-5得分。

Conclusion: 该方法在早期动作触发（如运动捕捉）中具有实际应用价值。

Abstract: Recognizing human activities early is crucial for the safety and
responsiveness of human-robot and human-machine interfaces. Due to their high
temporal resolution and low latency, event-based vision sensors are a perfect
match for this early recognition demand. However, most existing processing
approaches accumulate events to low-rate frames or space-time voxels which
limits the early prediction capabilities. In contrast, spiking neural networks
(SNNs) can process the events at a high-rate for early predictions, but most
works still fall short on final accuracy. In this work, we introduce a
high-rate two-stream SNN which closes this gap by outperforming previous work
by 2% in final accuracy on the large-scale THU EACT-50 dataset. We benchmark
the SNNs within a novel early event-based recognition framework by reporting
Top-1 and Top-5 recognition scores for growing observation time. Finally, we
exemplify the impact of these methods on a real-world task of early action
triggering for human motion capture in sports.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Optimizing Model Splitting and Device Task Assignment for Deceptive Signal Assisted Private Multi-hop Split Learning](https://arxiv.org/abs/2507.07323)
*Dongyu Wei,Xiaoren Xu,Yuchen Liu,H. Vincent Poor,Mingzhe Chen*

Main category: cs.LG

TL;DR: 论文研究了通过欺骗信号辅助的私有分割学习，提出了一种优化方法以减少信息泄露，同时满足能耗和延迟约束。


<details>
  <summary>Details</summary>
Motivation: 防止窃听者从边缘设备收集模型和数据信息，确保协作训练的安全性。

Method: 提出了一种基于软演员-评论家深度强化学习的框架（ICM-CA），结合内在好奇心模块和交叉注意力模块，动态选择设备分配和功率控制。

Result: 仿真结果表明，该方法比传统SAC算法收敛速度快3倍，信息泄露减少13%。

Conclusion: ICM-CA框架有效提升了训练效率和安全性，适用于隐私保护的分布式学习场景。

Abstract: In this paper, deceptive signal-assisted private split learning is
investigated. In our model, several edge devices jointly perform collaborative
training, and some eavesdroppers aim to collect the model and data information
from devices. To prevent the eavesdroppers from collecting model and data
information, a subset of devices can transmit deceptive signals. Therefore, it
is necessary to determine the subset of devices used for deceptive signal
transmission, the subset of model training devices, and the models assigned to
each model training device. This problem is formulated as an optimization
problem whose goal is to minimize the information leaked to eavesdroppers while
meeting the model training energy consumption and delay constraints. To solve
this problem, we propose a soft actor-critic deep reinforcement learning
framework with intrinsic curiosity module and cross-attention (ICM-CA) that
enables a centralized agent to determine the model training devices, the
deceptive signal transmission devices, the transmit power, and sub-models
assigned to each model training device without knowing the position and
monitoring probability of eavesdroppers. The proposed method uses an ICM module
to encourage the server to explore novel actions and states and a CA module to
determine the importance of each historical state-action pair thus improving
training efficiency. Simulation results demonstrate that the proposed method
improves the convergence rate by up to 3x and reduces the information leaked to
eavesdroppers by up to 13% compared to the traditional SAC algorithm.

</details>


### [7] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
*Deepak Kumar Panda,Weisi Guo*

Main category: cs.LG

TL;DR: 提出了一种基于cGAN的框架，用于生成能够逃避无人机入侵检测系统（IDS）的隐蔽对抗攻击，并通过CVAE检测这些攻击。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法难以识别新型威胁，且常规OOD检测器无法区分隐蔽对抗攻击与真实OOD事件。

Method: 设计了一个多类IDS分类器，利用cGAN生成对抗样本，并通过CVAE检测这些样本。

Result: CVAE在检测隐蔽对抗攻击方面显著优于传统方法。

Conclusion: 强调高级概率建模对提升IDS对抗生成模型攻击能力的重要性。

Abstract: The growing integration of UAVs into civilian airspace underscores the need
for resilient and intelligent intrusion detection systems (IDS), as traditional
anomaly detection methods often fail to identify novel threats. A common
approach treats unfamiliar attacks as out-of-distribution (OOD) samples;
however, this leaves systems vulnerable when mitigation is inadequate.
Moreover, conventional OOD detectors struggle to distinguish stealthy
adversarial attacks from genuine OOD events. This paper introduces a
conditional generative adversarial network (cGAN)-based framework for crafting
stealthy adversarial attacks that evade IDS mechanisms. We first design a
robust multi-class IDS classifier trained on benign UAV telemetry and known
cyber-attacks, including Denial of Service (DoS), false data injection (FDI),
man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN
perturbs known attacks to generate adversarial samples that misclassify as
benign while retaining statistical resemblance to OOD distributions. These
adversarial samples are iteratively refined to achieve high stealth and success
rates. To detect such perturbations, we implement a conditional variational
autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial
inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based
regret scores significantly outperform traditional Mahalanobis distance-based
detectors in identifying stealthy adversarial threats. Our findings emphasize
the importance of advanced probabilistic modeling to strengthen IDS
capabilities against adaptive, generative-model-based cyber intrusions.

</details>


### [8] [Learning Collective Variables from Time-lagged Generation](https://arxiv.org/abs/2507.07390)
*Seonghyun Park,Kiyoung Seong,Soojung Yang,Rafael Gómez-Bombarelli,Sungsoo Ahn*

Main category: cs.LG

TL;DR: TLC框架通过从生成模型的时间滞后条件中学习集体变量（CVs），以更准确地捕捉慢动态行为，在Alanine Dipeptide系统中验证了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于分子动力学模拟难以直接观测罕见事件（如状态转变），现有机器学习方法通常仅关注区分稳态而忽略动态细节，TLC旨在解决这一问题。

Method: TLC通过建模时间滞后条件分布而非静态Boltzmann分布，学习CVs以捕捉慢动态行为，并在Alanine Dipeptide系统中验证其性能。

Result: 在SMD和OPES任务中，TLC在路径采样和状态区分方面表现优于或等同于现有MLCV方法。

Conclusion: TLC通过直接学习动态行为，提供了一种更有效的CV发现方法，适用于增强采样任务。

Abstract: Rare events such as state transitions are difficult to observe directly with
molecular dynamics simulations due to long timescales. Enhanced sampling
techniques overcome this by introducing biases along carefully chosen
low-dimensional features, known as collective variables (CVs), which capture
the slow degrees of freedom. Machine learning approaches (MLCVs) have automated
CV discovery, but existing methods typically focus on discriminating
meta-stable states without fully encoding the detailed dynamics essential for
accurate sampling. We propose TLC, a framework that learns CVs directly from
time-lagged conditions of a generative model. Instead of modeling the static
Boltzmann distribution, TLC models a time-lagged conditional distribution
yielding CVs to capture the slow dynamic behavior. We validate TLC on the
Alanine Dipeptide system using two CV-based enhanced sampling tasks: (i)
steered molecular dynamics (SMD) and (ii) on-the-fly probability enhanced
sampling (OPES), demonstrating equal or superior performance compared to
existing MLCV methods in both transition path sampling and state
discrimination.

</details>


### [9] [Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series](https://arxiv.org/abs/2507.07559)
*Amirhossein Sadough,Mahyar Shahsavari,Mark Wijtvliet,Marcel van Gerven*

Main category: cs.LG

TL;DR: DAD是一种基于在线去相关学习的实时异常检测方法，适用于高维多变量时间序列数据，具有高效性和内存友好性。


<details>
  <summary>Details</summary>
Motivation: 随着工业物联网的发展，实时异常检测需求激增，需要处理高维流数据且无需存储历史实例的方法。

Method: DAD通过单次遍历动态学习数据的相关结构，与传统基于邻近或重构的方法不同。

Result: 实验表明，DAD在多种异常类型上表现优于现有方法，尤其适合高维实时数据流。

Conclusion: DAD在检测效果和计算效率间取得平衡，为实时内存受限的异常检测设定了新标准。

Abstract: Anomaly detection (AD) plays a vital role across a wide range of real-world
domains by identifying data instances that deviate from expected patterns,
potentially signaling critical events such as system failures, fraudulent
activities, or rare medical conditions. The demand for real-time AD has surged
with the rise of the (Industrial) Internet of Things, where massive volumes of
multivariate sensor data must be processed instantaneously. Real-time AD
requires methods that not only handle high-dimensional streaming data but also
operate in a single-pass manner, without the burden of storing historical
instances, thereby ensuring minimal memory usage and fast decision-making. We
propose DAD, a novel real-time decorrelation-based anomaly detection method for
multivariate time series, based on an online decorrelation learning approach.
Unlike traditional proximity-based or reconstruction-based detectors that
process entire data or windowed instances, DAD dynamically learns and monitors
the correlation structure of data sample by sample in a single pass, enabling
efficient and effective detection. To support more realistic benchmarking
practices, we also introduce a practical hyperparameter tuning strategy
tailored for real-time anomaly detection scenarios. Extensive experiments on
widely used benchmark datasets demonstrate that DAD achieves the most
consistent and superior performance across diverse anomaly types compared to
state-of-the-art methods. Crucially, its robustness to increasing
dimensionality makes it particularly well-suited for real-time,
high-dimensional data streams. Ultimately, DAD not only strikes an optimal
balance between detection efficacy and computational efficiency but also sets a
new standard for real-time, memory-constrained anomaly detection.

</details>


### [10] [COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation](https://arxiv.org/abs/2507.07580)
*Uliana Parkina,Maxim Rakhuba*

Main category: cs.LG

TL;DR: 提出了一种基于稳定分解的无逆正则化框架，解决了现有方法因依赖显式Gram矩阵计算和逆运算导致的数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在神经网络中因依赖显式Gram矩阵计算和逆运算，导致数值不稳定，影响近似质量或产生数值奇异矩阵。

Method: 提出了一种基于稳定分解的无逆正则化框架，能够处理校准矩阵超出GPU内存容量、输入激活矩阵接近奇异或数据不足的情况。

Result: 该方法在数值稳定性上优于现有方法，并证明了在数据不足时收敛到期望近似，且推导了显式误差界。

Conclusion: 新方法有效解决了现有技术的数值不稳定问题，适用于多种挑战性场景。

Abstract: Recent studies suggest that context-aware low-rank approximation is a useful
tool for compression and fine-tuning of modern large-scale neural networks. In
this type of approximation, a norm is weighted by a matrix of input
activations, significantly improving metrics over the unweighted case.
Nevertheless, existing methods for neural networks suffer from numerical
instabilities due to their reliance on classical formulas involving explicit
Gram matrix computation and their subsequent inversion. We demonstrate that
this can degrade the approximation quality or cause numerically singular
matrices.
  To address these limitations, we propose a novel inversion-free regularized
framework that is based entirely on stable decompositions and overcomes the
numerical pitfalls of prior art. Our method can handle possible challenging
scenarios: (1) when calibration matrices exceed GPU memory capacity, (2) when
input activation matrices are nearly singular, and even (3) when insufficient
data prevents unique approximation. For the latter, we prove that our solution
converges to a desired approximation and derive explicit error bounds.

</details>


### [11] [GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing](https://arxiv.org/abs/2507.07735)
*Peiyan Zhang,Haibo Jin,Liying Kang,Haohan Wang*

Main category: cs.LG

TL;DR: 本文提出GuardVal协议，动态生成和优化越狱提示，以更准确评估LLM的安全漏洞，并揭示不同模型的行为模式。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以全面捕捉LLM的漏洞，亟需更有效的评估协议。

Method: 引入GuardVal协议，动态生成和优化越狱提示，结合新优化方法防止停滞。

Result: 应用于多种模型（如Mistral-7b、GPT-4），揭示了不同模型的行为模式和漏洞。

Conclusion: GuardVal提供了更全面的LLM安全性评估，为未来研究及安全模型开发提供参考。

Abstract: Jailbreak attacks reveal critical vulnerabilities in Large Language Models
(LLMs) by causing them to generate harmful or unethical content. Evaluating
these threats is particularly challenging due to the evolving nature of LLMs
and the sophistication required in effectively probing their vulnerabilities.
Current benchmarks and evaluation methods struggle to fully address these
challenges, leaving gaps in the assessment of LLM vulnerabilities. In this
paper, we review existing jailbreak evaluation practices and identify three
assumed desiderata for an effective jailbreak evaluation protocol. To address
these challenges, we introduce GuardVal, a new evaluation protocol that
dynamically generates and refines jailbreak prompts based on the defender LLM's
state, providing a more accurate assessment of defender LLMs' capacity to
handle safety-critical situations. Moreover, we propose a new optimization
method that prevents stagnation during prompt refinement, ensuring the
generation of increasingly effective jailbreak prompts that expose deeper
weaknesses in the defender LLMs. We apply this protocol to a diverse set of
models, from Mistral-7b to GPT-4, across 10 safety domains. Our findings
highlight distinct behavioral patterns among the models, offering a
comprehensive view of their robustness. Furthermore, our evaluation process
deepens the understanding of LLM behavior, leading to insights that can inform
future research and drive the development of more secure models.

</details>


### [12] [Deep Survival Analysis in Multimodal Medical Data: A Parametric and Probabilistic Approach with Competing Risks](https://arxiv.org/abs/2507.07804)
*Alba Garrido,Alejandro Almodóvar,Patricia A. Apellániz,Juan Parras,Santiago Zazo*

Main category: cs.LG

TL;DR: 提出了一种名为SAMVAE的多模态深度学习框架，用于生存分析，整合六种数据模态，并在乳腺癌和低级别胶质瘤中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 传统生存预测方法依赖单一数据模态，难以捕捉肿瘤生物学的复杂性，因此需要一种能整合多模态数据的方法。

Method: 提出SAMVAE架构，利用模态特定编码器将输入映射到共享潜在空间，支持生存预测和竞争风险场景。

Result: 在乳腺癌和低级别胶质瘤数据上验证，性能优于现有方法，首次实现多模态竞争风险建模。

Conclusion: SAMVAE为肿瘤学提供了可解释的数据驱动生存分析框架，支持临床决策。

Abstract: Accurate survival prediction is critical in oncology for prognosis and
treatment planning. Traditional approaches often rely on a single data
modality, limiting their ability to capture the complexity of tumor biology. To
address this challenge, we introduce a multimodal deep learning framework for
survival analysis capable of modeling both single and competing risks
scenarios, evaluating the impact of integrating multiple medical data sources
on survival predictions. We propose SAMVAE (Survival Analysis Multimodal
Variational Autoencoder), a novel deep learning architecture designed for
survival prediction that integrates six data modalities: clinical variables,
four molecular profiles, and histopathological images. SAMVAE leverages
modality specific encoders to project inputs into a shared latent space,
enabling robust survival prediction while preserving modality specific
information. Its parametric formulation enables the derivation of clinically
meaningful statistics from the output distributions, providing patient-specific
insights through interactive multimedia that contribute to more informed
clinical decision-making and establish a foundation for interpretable,
data-driven survival analysis in oncology. We evaluate SAMVAE on two cancer
cohorts breast cancer and lower grade glioma applying tailored preprocessing,
dimensionality reduction, and hyperparameter optimization. The results
demonstrate the successful integration of multimodal data for both standard
survival analysis and competing risks scenarios across different datasets. Our
model achieves competitive performance compared to state-of-the-art multimodal
survival models. Notably, this is the first parametric multimodal deep learning
architecture to incorporate competing risks while modeling continuous time to a
specific event, using both tabular and image data.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLMs）生成有害内容的过滤问题，发现输入和输出过滤均存在计算上的挑战，并指出外部过滤器无法完全确保安全性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，防止其生成有害内容的需求日益迫切，论文旨在探讨过滤技术的有效性及其计算限制。

Method: 通过理论分析，研究输入提示和输出内容的过滤效率，并基于密码学假设证明其计算不可行性。

Result: 发现对抗性提示可绕过高效过滤器，且输出过滤在特定场景下计算不可行，表明外部过滤器无法完全解决安全问题。

Conclusion: 安全需内置于LLMs的设计中，无法仅依赖外部过滤器，智能与判断需紧密结合。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [14] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 研究评估了微调的Llama 3.2模型从急诊分诊笔记中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。微调模型在提取疫苗名称的准确性上优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 支持高效的疫苗安全监测和早期发现免疫后不良事件。

Method: 使用提示工程创建标注数据集，并由人工确认。比较了提示工程模型、微调模型和基于规则的方法。

Result: 微调的Llama 3亿参数模型在提取疫苗名称的准确性上表现最佳，模型量化使其在资源受限环境中高效部署。

Conclusion: 大型语言模型在自动化急诊笔记数据提取中具有潜力，可提升疫苗安全监测效率。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [15] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 本文提出了一种基于轮廓线分类小提琴是否为缩小尺寸的方法，通过几何特征分析，发现区分缩小与非缩小小提琴是可行的。


<details>
  <summary>Details</summary>
Motivation: 研究小提琴制作中尺寸缩小对轮廓线的影响，填补专家观察未定量研究的空白。

Method: 使用摄影测量获取25把小提琴的3D几何网格，提取并拟合轮廓线参数，通过回归和分类方法分析。

Result: 发现几何特征可以一定程度区分缩小与非缩小小提琴，其中开口参数beta最具预测性。

Conclusion: 几何分析可用于小提琴分类，但需考虑尺寸缩小程度的连续性。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [16] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: FAI Benchmark评估AI在七个维度上对人类繁荣的贡献，发现现有模型在信仰与灵性、品格与美德、意义与目的方面表现不足。


<details>
  <summary>Details</summary>
Motivation: 传统基准关注技术能力或避免危害，而FAI Benchmark旨在衡量AI对人类全面繁荣的贡献。

Method: 通过1,229个主客观问题，结合专家LLM和几何平均评分，评估28个领先语言模型。

Result: 最高分模型得72/100，但无模型在所有维度上表现良好，尤其在信仰与灵性等领域。

Conclusion: FAI Benchmark为开发支持人类繁荣的AI系统提供了框架，对AI伦理和评估有重要意义。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [17] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 论文指出，随着计算资源投入的边际效益递减，AI模型性能将趋于收敛，即使资源有限的模型也能接近最佳模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨AI模型性能不平等问题，并挑战当前关于计算资源投入越多性能越好的直觉。

Method: 通过固定分布的下一个词预测目标模型，分析计算资源的边际效益递减现象，并结合基准数据和理论模型验证。

Result: 计算资源的边际效益显著下降，资源有限的模型性能将接近最佳模型。

Conclusion: AI战略和政策需重新审视，以应对模型性能收敛的趋势。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>
