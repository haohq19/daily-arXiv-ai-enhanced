<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 11]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 提出基于频域早期融合的RGB-事件跟踪框架，通过FFT将RGB和事件模态转换到频域，利用振幅和相位注意力选择性融合高频事件信息，结合运动引导的空间稀疏化模块减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-事件视觉目标跟踪方法主要依赖传统特征级融合，未能充分利用事件相机的高动态范围和运动敏感特性，同时对低信息区域进行统一处理，导致主干网络不必要的计算开销。

Method: 1) 通过快速傅里叶变换将RGB和事件模态从空间域转换到频域，解耦振幅和相位分量；2) 通过振幅和相位注意力选择性融合高频事件信息到RGB模态；3) 运动引导的空间稀疏化模块利用事件相机运动敏感性捕获目标运动线索与空间概率分布关系，过滤低信息区域；4) 稀疏的目标相关特征输入主干网络学习，跟踪头预测最终目标位置。

Result: 在三个广泛使用的RGB-事件跟踪基准数据集（FE108、FELT、COESOT）上进行了大量实验，证明了方法的高性能和效率。

Conclusion: 提出的频域早期融合框架有效利用了事件相机的高动态范围和运动敏感特性，通过选择性融合高频信息和空间稀疏化显著减少了计算开销，在RGB-事件跟踪任务中实现了高性能和高效率。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [2] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: LinMU：一种线性复杂度的视觉语言模型设计，通过M-MATE双分支模块（全局状态空间模型+局部窗口注意力）替代自注意力，实现性能不变但复杂度从二次降为线性，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的自注意力机制具有二次复杂度，限制了其在边缘设备上的部署，且处理高分辨率图像和长视频时计算成本过高。需要设计既能保持性能又能降低复杂度的模型架构。

Method: 提出LinMU架构，用M-MATE双分支模块替代所有自注意力层：Flex-MA分支使用双向状态空间模型捕获全局上下文，Local-Swin分支使用Swin风格窗口注意力处理局部相关性。采用三阶段蒸馏框架将预训练VLM转换为LinMU架构。

Result: 在MMMU、TextVQA、LongVideoBench、Video-MME等多个基准测试中，LinMU匹配了教师模型的性能，同时将首token生成时间减少2.7倍，在分钟级视频上的token吞吐量提升9.0倍。消融实验验证了蒸馏阶段和双分支的必要性。

Conclusion: 研究表明，无需二次复杂度的注意力机制也能实现最先进的多模态推理，为处理高分辨率图像和长视频的长上下文VLM开辟了新途径，显著提升了部署效率和计算效率。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [3] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 论文提出Teleo-Spatial Intelligence (TSI)新范式，结合物理动态推理和意图驱动推理，并发布EscherVerse基准套件来推动空间智能研究。


<details>
  <summary>Details</summary>
Motivation: 当前空间推理研究忽视了人类意图在空间变化中的作用，需要从被动场景描述转向目的驱动的整体理解。

Method: 提出TSI范式，包含物理动态推理和意图驱动推理两个支柱，并构建EscherVerse基准套件（包括Escher-Bench基准、Escher-35k数据集和Escher系列模型）。

Result: 创建了首个系统评估意图驱动推理的基准，涵盖物体恒存性、状态转换和轨迹预测等动态场景，为空间智能研究提供基础资源。

Conclusion: TSI范式将空间智能从被动描述提升到目的驱动的整体理解，EscherVerse为相关研究提供了重要基准和工具。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [4] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 提出FFP-300K大规模数据集和自适应时空RoPE框架，实现无需运行时引导的第一帧传播视频编辑，在EditVerseBench基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有第一帧传播方法依赖繁琐的运行时引导，根本原因是训练数据集不足：视频太短、分辨率低、任务多样性不够，无法学习鲁棒的时序先验。

Method: 1) 构建FFP-300K数据集：30万对720p、81帧的高保真视频对，通过原则性双轨流程生成多样局部和全局编辑；2) 提出自适应时空RoPE框架：动态重映射位置编码解耦外观和运动参考；3) 自蒸馏策略：身份传播任务作为正则化器确保长期时序稳定性。

Result: 在EditVerseBench基准测试中，方法显著优于现有学术和商业模型，PickScore提升约0.2分，VLM分数提升约0.3分。

Conclusion: 通过大规模高质量数据集和创新的自适应时空RoPE框架，实现了真正无需引导的第一帧传播视频编辑，有效解决了外观保持与运动保留之间的关键矛盾。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [5] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: DDNet：基于双流图学习和解缠的时序伪造定位框架，通过协调局部伪影和语义内容流来捕获全局异常，显著提升伪造片段定位精度和跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: AIGC技术的快速发展使得仅篡改视频中的小片段就能误导观众，而视频级检测不够准确和具有说服力。现有方法受限于局部视角，难以捕捉全局异常，因此需要更精确的时序伪造定位方法。

Method: 提出DDNet框架，包含：1）双流图学习：时间距离流捕捉局部伪影，语义内容流建立长程连接；2）痕迹解缠与适配（TDA）分离通用伪造指纹；3）跨层级特征嵌入（CLFE）通过层次特征深度融合构建鲁棒特征基础。

Result: 在ForgeryNet和TVIL基准测试中，DDNet在AP@0.95指标上比现有最优方法提升约9%，在跨域鲁棒性方面有显著改进。

Conclusion: DDNet通过双流协调和特征解缠，有效解决了时序伪造定位中的全局异常捕捉问题，在精度和跨域适应性方面均优于现有方法。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [6] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: 提出LUMPNet混合深度学习模型，用于早期检测牛结节性皮肤病(LSD)，通过YOLOv11检测皮肤结节，EfficientNet分类，结合新型自适应混合优化器，在公开数据集上达到99%训练准确率和98%验证准确率。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病(LSD)是一种传染性病毒性疾病，严重影响畜牧业健康和全球粮食安全。由于其快速传播特性，早期精确识别对于预防疫情爆发和及时干预至关重要。

Method: 提出LUMPNet混合深度学习模型：1) 使用YOLOv11检测和定位牛图像中的LSD皮肤结节和病变；2) 利用基于EfficientNet的CNN分类器对定位图像进行LSD感染或健康分类；3) 提出新型自适应混合优化器来稳定和加速YOLOv11与EfficientNet混合模型的训练。

Result: 在公开数据集上评估：1) 达到99%的LSD检测训练准确率；2) 验证准确率达到98%；3) 优于现有方案；4) 与使用AdamW优化的EfficientNet-B0模型相比，LUMPNet表现更优。

Conclusion: LUMPNet能够有效早期检测牛结节性皮肤病，在检测准确率和性能方面优于现有方法，为LSD的早期诊断和防控提供了有效的深度学习解决方案。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [7] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: CogFlow是一个受认知启发的三阶段框架，通过知识内化阶段来改善视觉数学推理，解决了现有方法在视觉感知与推理整合方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉数学问题解决上仍有困难。虽然最近工作认识到视觉感知是瓶颈，但只关注改善视觉输入的提取和解释，忽略了提取的视觉线索是否被忠实整合并正确用于后续推理的关键问题。

Method: 提出CogFlow框架，模拟人类推理的层次流程：感知→内化→推理。包含协同视觉奖励提升符号和图表的信息提取；知识内化奖励模型确保视觉线索忠实整合；视觉门控策略优化算法防止模型寻求看似连贯但视觉未接地推理链；并创建MathCog数据集用于训练。

Result: 在常用视觉数学推理基准测试上的综合实验和分析验证了CogFlow的优越性。

Conclusion: 通过引入知识内化阶段并全面增强感知、内化和推理三个阶段，CogFlow显著提升了视觉数学推理性能，解决了现有方法在视觉感知与推理整合方面的根本问题。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [8] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: ADAE：一种事件引导的时空融合框架，用于增强Depth Anything在退化场景（极端光照、运动模糊）下的深度估计能力


<details>
  <summary>Details</summary>
Motivation: 当前深度基础模型（如Depth Anything）在理想场景中表现优异，但在极端光照和运动模糊等恶劣成像条件下表现不佳。这些退化会破坏帧相机的视觉信号，削弱基于帧的深度特征在时空维度上的判别能力。现有方法虽然引入事件相机来利用其高动态范围和高时间分辨率，但通常需要从头训练，无法继承基础模型的开放世界知识和鲁棒泛化能力。

Method: 提出ADAE框架，包含两个核心组件：1）熵感知空间融合：使用信息熵策略自适应融合基于帧和基于事件的特征，以指示光照引起的退化；2）运动引导时间校正：利用事件运动线索重新校准模糊区域的模糊特征。这两个组件在统一框架下相互补充，共同增强Depth Anything在恶劣成像条件下的性能。

Result: 大量实验验证了所提方法的优越性。ADAE能够有效提升Depth Anything在退化场景下的深度估计性能，特别是在极端光照和运动模糊条件下。

Conclusion: ADAE通过事件引导的时空融合框架，成功增强了Depth Anything在恶劣成像条件下的深度估计能力，同时继承了基础模型的开放世界知识和泛化能力，为解决动态和恶劣光照条件下的鲁棒深度估计问题提供了有效方案。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [9] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: HeadLighter：基于3D高斯溅射的头部生成模型，通过双分支架构和渐进解耦训练实现外观与照明的物理可分解，支持显式光照和视角编辑


<details>
  <summary>Details</summary>
Motivation: 现有3D感知头部生成模型虽然能实现实时、逼真、视角一致的头部合成，但存在根本限制：光照与内在外观的深度纠缠阻碍了可控重光照。现有解耦方法依赖强假设进行弱监督学习，限制了处理复杂光照的能力。

Method: 提出HeadLighter框架：1）双分支架构分别建模光照不变的头部属性和物理基础的渲染组件；2）渐进解耦训练逐步将头部外观先验注入生成架构；3）蒸馏策略生成高质量法线以实现逼真渲染；4）使用光舞台设置下采集的多视角图像进行监督训练。

Result: 实验表明，该方法在保持高质量生成和实时渲染的同时，支持显式光照和视角编辑。将公开代码和数据集。

Conclusion: HeadLighter成功解决了3D头部生成模型中光照与外观的纠缠问题，实现了物理合理的分解，为可控重光照提供了有效解决方案。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [10] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 提出基于CSI-ResNet-A的两阶段框架，通过自监督对比学习预训练获取域不变表示，配合轻量级适配器微调，实现无需设备的WiFi人群计数，在域迁移问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 基于WiFi信道状态信息(CSI)的无设备人群计数是隐私保护物联网应用的关键技术，但实际部署受到域迁移问题的严重阻碍——在一个环境中训练的模型无法泛化到其他环境。

Method: 提出两阶段框架：1) 使用CSI-ResNet-A架构通过自监督对比学习预训练，学习域不变表示；2) 利用轻量级适配器模块进行高效微调；3) 通过状态计数机处理事件序列生成稳定占用估计。

Result: 在WiFlow数据集上，无监督方法在10-shot学习场景中达到MAE仅0.44，而监督基线方法失败；引入泛化指数(GI)评估，模型接近完美；在公共WiAR基准上达到98.8%准确率的新SOTA；适配器微调性能接近完全微调(98.84% vs 99.67%)，但仅训练2.8%的参数。

Conclusion: 该工作为开发适用于真实世界物联网部署的鲁棒感知系统提供了实用且可扩展的解决方案，通过域不变表示学习和高效适配器微调有效解决了域迁移问题。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [11] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: RetinexEVSR：首个事件驱动的低光视频超分辨率框架，通过Retinex先验和双向跨模态融合，利用高对比度事件信号恢复低光低分辨率视频的细节，在性能和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有低光视频超分辨率方法在恢复细节方面存在困难，主要因为低光条件下对比度有限且高频信息不足。需要利用高对比度的事件信号来增强恢复效果。

Method: 提出RetinexEVSR框架：1）引入双向跨模态融合策略，从噪声事件数据和退化RGB帧中提取并整合有效信息；2）设计光照引导的事件增强模块，利用Retinex模型的光照图逐步精炼事件特征；3）提出事件引导的反射率增强模块，通过多尺度融合机制动态恢复反射率细节。

Result: 在三个数据集上达到最先进性能。在SDSD基准测试中，相比之前的事件驱动方法，获得高达2.95 dB的性能提升，同时减少65%的运行时间。

Conclusion: RetinexEVSR通过有效整合事件信号和Retinex先验，成功解决了低光视频超分辨率的挑战，在恢复细节和计算效率方面均表现出色，为低光视频增强提供了新思路。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

TL;DR: FedSCAM是一种联邦学习算法，通过动态调整SAM扰动半径和基于客户端异质性分数的聚合权重，解决非IID数据下的收敛和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据的统计异质性（特别是非IID标签分布）对收敛和泛化构成重大挑战。现有的SAM方法通常对所有客户端使用统一的扰动半径，忽略了客户端特定的异质性。

Method: 提出FedSCAM算法：1) 为每个客户端计算异质性度量；2) 根据异质性分数反向调制SAM扰动半径，防止高方差客户端破坏全局模型稳定性；3) 引入异质性感知的加权聚合机制，优先考虑与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST数据集上，使用不同程度的狄利克雷标签偏斜进行实验，FedSCAM在收敛速度和最终测试准确率方面与FedSAM、FedLESAM等最先进基线方法相比具有竞争力。

Conclusion: FedSCAM通过动态调整扰动半径和异质性感知聚合，有效解决了联邦学习中非IID数据带来的挑战，提升了模型性能和收敛稳定性。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [13] [Geometric and Dynamic Scaling in Deep Transformers](https://arxiv.org/abs/2601.01014)
*Haoran Su,Chenyu You*

Main category: cs.LG

TL;DR: 论文提出Transformer深度增加导致表示崩溃的根本原因是几何问题，而非优化问题，并提出了基于几何约束的MGT架构来解决


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer经验上成功，但推向极端深度时会出现表示冗余、秩丢失和崩溃的悖论。现有解释主要归因于优化不稳定或梯度消失，但这些解释无法说明为什么在现代归一化和初始化方案下崩溃仍然存在。作者认为深层Transformer的崩溃本质上是几何问题。

Method: 提出了统一的几何框架，包含两个正交原则：1) 流形约束超连接，限制残差更新到有效的局部切向方向，防止不受控制的流形漂移；2) 深度delta学习，引入数据依赖的非单调更新，能够反射和擦除冗余特征而非无条件积累。这些机制解耦了特征更新的方向和符号，实现了跨深度的稳定几何演化。由此产生的架构称为流形几何Transformer(MGT)。

Result: 分析预测，强制几何有效性同时允许动态擦除对于避免超深层网络中的秩崩溃至关重要。作者概述了超过100层的Transformer评估协议，以测试几何而非深度本身是深度表示学习的关键限制因素的假设。

Conclusion: 深层Transformer的崩溃是几何问题而非优化问题，通过流形约束和动态擦除机制可以解决表示退化问题，为超深层架构设计提供了新的理论框架。

Abstract: Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.

</details>


### [14] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

TL;DR: 开发了一个针对孟加拉国和南亚人群的可解释机器学习框架，用于社区早期慢性肾病筛查，相比现有工具显著提高了准确性和敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有慢性肾病筛查工具主要基于高收入国家人群开发，在孟加拉国和南亚地区表现不佳，因为这些地区的风险特征不同。这些工具通常使用简单的累加评分函数，基于晚期肾病患者数据，无法捕捉风险因素间的复杂交互作用，也难以预测早期肾病。

Method: 使用孟加拉国社区数据集（南亚首个此类数据集），评估了12种机器学习分类器，应用10种互补的特征选择技术识别稳健、可泛化的预测因子。最终模型采用10折交叉验证评估，并在印度、阿联酋和孟加拉国的三个独立数据集上进行外部验证。使用SHAP提供模型可解释性。

Result: 基于RFECV选择特征子集的机器学习模型达到90.40%的平衡准确率，而最少非病理测试特征集也表现出色（89.23%平衡准确率），通常优于更大或完整特征集。相比现有筛查工具，所提模型在需要更少、更易获取输入的情况下，实现了显著更高的准确性和敏感性。外部验证显示78%至98%的敏感性，证实了强泛化能力。

Conclusion: 该研究开发了一个针对孟加拉国和南亚人群的可解释机器学习框架，用于社区早期慢性肾病筛查，相比现有工具显著提高了准确性和敏感性，同时具有强泛化能力和临床可解释性，适合低资源环境使用。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [15] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

TL;DR: 使用多类型严肃游戏结合机器学习预测软件开发适合度，通过游戏行为特征替代传统人格问卷，达到97%精度和94%准确率


<details>
  <summary>Details</summary>
Motivation: 传统职业评估中的人格问卷存在回答偏差、疲劳和故意扭曲等问题，需要一种更客观、可扩展且偏误更少的替代方案

Method: 通过文献回顾和实证研究确定软件开发相关特质，设计定制移动游戏收集问题解决、规划、适应性等行为数据，采用两阶段建模策略仅使用游戏行为特征预测适合度

Result: 模型达到97%精度和94%准确率，合适候选人表现出独特游戏模式：更多解谜游戏胜利、更多侧挑战、更频繁菜单导航、更少暂停/重试/放弃

Conclusion: 游戏行为特征能有效预测软件开发适合度，严肃游戏可作为可扩展、有趣且偏误更少的职业评估替代方案

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [16] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

TL;DR: 提出REE-TTT模型，通过时空测试时训练机制提升雷达回波外推的泛化能力，解决传统方法在跨区域和极端天气下泛化差的问题


<details>
  <summary>Details</summary>
Motivation: 传统深度学习的雷达回波外推方法依赖高质量本地训练数据和静态参数，导致跨区域和极端天气事件泛化能力差，需要更自适应的解决方案

Method: 提出REE-TTT模型，引入自适应测试时训练机制，核心是时空测试时训练块，用任务特定的注意力机制替代标准线性投影，增强对非平稳气象分布的适应能力

Result: 在跨区域极端降水场景实验中，REE-TTT在预测精度和泛化能力上显著优于最先进的基线模型，对数据分布偏移表现出卓越的适应性

Conclusion: REE-TTT通过测试时训练机制有效解决了降水临近预报中的泛化问题，为跨区域和极端天气下的气象预报提供了更鲁棒的解决方案

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [17] [Learning Resilient Elections with Adversarial GNNs](https://arxiv.org/abs/2601.01653)
*Hao Xiang Li,Yash Shah,Lorenzo Giusti*

Main category: cs.LG

TL;DR: 该论文提出了一种基于图神经网络和对抗训练的投票规则学习方法，通过将选举表示为二分图来提高表达能力和抗策略投票能力。


<details>
  <summary>Details</summary>
Motivation: 传统投票规则难以满足所有场景需求，而现有的自动化机制设计方法在应用到真实选举中存在局限性，特别是对策略性投票的鲁棒性不足。

Method: 将选举表示为二分图，使用图神经网络学习投票规则，并结合对抗训练来提高规则对策略性投票的鲁棒性，同时最大化社会福利。

Result: 在合成和真实数据集上的评估表明，该方法解决了先前工作的关键限制，提高了投票规则的表达能力和鲁棒性。

Conclusion: 该方法为机器学习应用于真实世界选举开辟了新前沿，通过图神经网络表示和对抗训练实现了更鲁棒的投票规则学习。

Abstract: In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.

</details>


### [18] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

TL;DR: ProtoPal框架通过原型学习实现个性化预防医疗，在保持高性能的同时提供可理解和可验证的干预方案展示。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习在医疗领域存在可解释性和可验证性不足的问题，需要为医疗行业所有利益相关者提供既易于理解又可信的预测、干预和推荐系统。

Method: 采用原型学习框架ProtoPal，包含前端和后端两种模式，通过原型表示来展示干预措施及其模拟结果。

Result: 在定量性能上表现优异，同时能够直观地呈现干预措施及其模拟结果。

Conclusion: 原型学习能够有效解决个性化预防医疗中的可解释性和可验证性问题，为医疗决策提供透明可靠的支持。

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [19] [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)
*Emrah Mete,Emin Erkan Korkmaz*

Main category: cs.LG

TL;DR: 提出Neuro-Channel Networks (NCN)乘法免架構，模仿生物神經系統離子通道限制機制，用通道寬度和神經遞質參數取代傳統權重，僅需加法、減法和位元運算，無需浮點乘法。


<details>
  <summary>Details</summary>
Motivation: 深度學習對GPU等高性能硬體的依賴造成成本高、能耗大、供應短缺等問題，限制了AI在邊緣設備的普及。生物神經系統的高效性啟發了開發不依賴矩陣乘法的替代架構。

Method: 提出Neuro-Channel Networks (NCN)架構：1) 用Channel Widths物理限制信號幅度取代權重；2) 用Neurotransmitter參數基於符號邏輯調節信號傳輸；3) 前向傳播僅使用加法、減法和位元運算（最小值、符號），完全消除浮點乘法；4) 使用標準反向傳播訓練。

Result: 概念驗證顯示NCN能100%準確解決非線性可分問題（如XOR和Majority函數），證明無需乘法權重即可形成複雜決策邊界。

Conclusion: NCN為下一代神經形態硬體提供高效替代方案，使複雜模型能在普通CPU或超低功耗晶片上運行，無需依賴昂貴的GPU集群，推動AI在邊緣設備的普及。

Abstract: The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

</details>


### [20] [POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network](https://arxiv.org/abs/2601.02264)
*Boris Kriuk,Fedor Kriuk*

Main category: cs.LG

TL;DR: POSEIDON是一个基于物理的能量模型，用于统一的多任务地震事件预测，结合了Gutenberg-Richter和Omori-Utsu等地震学定律作为可学习的约束条件，在多个预测任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法通常作为黑箱运行，忽略了已建立的物理定律。地震预测和地震危险性评估仍然是地球物理学的基本挑战。

Method: 引入POSEIDON（物理优化地震能量推断和检测操作网络），这是一个基于物理的能量模型，将Gutenberg-Richter震级-频率关系和Omori-Utsu余震衰减定律作为可学习的约束嵌入到能量建模框架中。同时处理三个相互关联的预测任务：余震序列识别、海啸生成潜力和前震检测。

Result: POSEIDON在所有任务上实现了最先进的性能，优于梯度提升、随机森林和CNN基线，在所有比较方法中获得了最高的平均F1分数。学习到的物理参数收敛到科学可解释的值（Gutenberg-Richter b值0.752，Omori-Utsu参数p=0.835，c=0.1948天），这些值落在已建立的地震学范围内，同时增强了预测准确性。

Conclusion: POSEIDON通过将物理定律作为可学习约束嵌入机器学习模型，成功实现了物理信息的地震预测，在保持科学可解释性的同时提高了预测性能。Poseidon数据集（280万个事件，30年）公开可用，推动了物理信息地震研究的发展。

Abstract: Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.

</details>


### [21] [Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models](https://arxiv.org/abs/2601.00391)
*Nouar AlDahoul,Aznul Qalid Md Sabri,Ali Mohammed Mansoor*

Main category: cs.LG

TL;DR: 该论文提出结合光流和三种深度学习模型（S-CNN、预训练CNN、H-ELM）用于无人机视频中的人体检测，在UCF-ARG数据集上取得高精度结果。


<details>
  <summary>Details</summary>
Motivation: 传统手工特征方法对动态事件（光照变化、相机抖动等）敏感且依赖专家知识，需要更鲁棒、自动化的特征学习方法用于无人机视频中的人体检测。

Method: 结合光流特征与三种深度学习模型：1) 监督卷积神经网络（S-CNN），2) 预训练CNN特征提取器，3) 分层极限学习机（H-ELM），在UCF-ARG无人机数据集上进行训练和测试。

Result: 预训练CNN平均准确率98.09%，S-CNN（softmax）95.6%，S-CNN（SVM）91.7%，H-ELM 95.9%。H-ELM在CPU上训练445秒，S-CNN在GPU上训练770秒。

Conclusion: 提出的自动特征学习方法在无人机视频人体检测任务中表现成功，预训练CNN效果最佳，H-ELM在计算效率上有优势。

Abstract: Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: 提出了TPP-TAL框架，通过增强LLMs的时间感知能力来改进时序点过程建模，在多个基准数据集上显著提升了时间似然估计和事件预测精度。


<details>
  <summary>Details</summary>
Motivation: 时序点过程在金融、医疗、社交系统等领域至关重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互。尽管大语言模型在序列建模中表现出色，但应用于时序点过程仍面临挑战。

Method: 提出TPP-TAL框架，这是一种即插即用的方法，在将信息输入LLM之前，显式地对齐时间动态与上下文语义，而不是简单地拼接事件时间和类型嵌入。这种方法让模型能更好地感知时间依赖性和事件与上下文之间的长程交互。

Result: 在多个基准数据集上的综合实验表明，TPP-TAL在时间似然估计和事件预测准确性方面带来了显著改进，突显了增强LLMs时间感知能力对连续时间事件建模的重要性。

Conclusion: TPP-TAL框架通过增强大语言模型的时间感知能力，有效解决了时序点过程建模中的关键挑战，为连续时间事件建模提供了新的解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [23] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: ElecTwit是一个模拟社交媒体政治选举中多智能体说服行为的框架，发现LLMs使用了25种说服技巧，不同模型架构和训练影响说服动态，并观察到"真相内核"消息和"墨水"痴迷等独特现象。


<details>
  <summary>Details</summary>
Motivation: 为了研究多智能体系统中的说服行为，特别是在社交媒体政治选举环境中的交互，克服以往研究中基于游戏模拟的局限性，在更真实的环境中评估LLM智能体的说服能力。

Method: 开发了ElecTwit模拟框架，在模拟社交媒体政治选举的逼真环境中进行多智能体实验，测试多种LLM模型，分析它们使用的说服技巧和行为模式。

Result: 观察到25种特定的说服技巧被大多数测试的LLM广泛使用，范围超过以往报道；不同模型在技巧使用和整体说服输出上存在显著差异；发现了"真相内核"消息和"墨水"痴迷（智能体集体要求书面证据）等独特现象。

Conclusion: 该研究为在真实世界环境中评估有说服力的LLM智能体奠定了基础，确保对齐并防止危险结果，同时揭示了不同模型架构和训练如何影响现实社交模拟中的动态。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [24] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 提出"可采纳性对齐"框架，将AI对齐重新定义为在不确定性下对结果分布的可采纳行动和决策选择属性，并通过MAP-AI架构实现概率化、决策理论的对齐评估。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐方法通常将对齐视为静态或二元条件，缺乏对不确定性、干预效果、价值模糊性和治理约束的明确建模。需要一种能够评估策略在结果分布和尾部事件中行为的实用框架。

Method: 提出MAP-AI（蒙特卡洛对齐策略）架构，通过蒙特卡洛估计结果分布和可采纳性控制的策略选择来实施对齐。该框架在可信未来集合中评估决策策略，明确建模不确定性、干预效果、价值模糊性和治理约束。

Result: 建立了评估对齐的分布属性方法，包括期望效用、方差、尾部风险和不对齐概率，而非传统的准确性或排名性能。提供了可执行的方法论来评估企业AI系统中的信任和对齐。

Conclusion: 该框架为治理AI系统提供了实用基础，其影响不是由个体预测决定，而是由策略在分布和尾部事件中的行为决定。分布对齐评估可以集成到决策过程中，实现无需重新训练或修改底层模型的可采纳性控制行动选择。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [25] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 该论文提出将长链思维推理中的幻觉视为演化潜状态而非一次性错误事件，引入累积前缀级幻觉信号来追踪推理状态的全局演化，实现实时可解释的幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理虽然能提升大语言模型性能，但其中的幻觉问题往往微妙且会在推理步骤间传播。传统方法将幻觉视为一次性错误事件，难以捕捉其在长推理链中的演化特性。

Method: 将步骤级幻觉判断视为局部观测，引入累积前缀级幻觉信号来追踪整个推理轨迹中推理状态的全局演化，实现流式幻觉检测。

Result: 该方法能够在长链思维推理中实现实时幻觉检测，并提供可解释的证据，更好地理解和追踪幻觉在推理过程中的传播和演化。

Conclusion: 将幻觉建模为演化潜状态而非一次性事件，通过累积前缀级信号进行全局追踪，为长链思维推理中的幻觉检测提供了更有效的实时可解释方法。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [26] [KOS-TL (Knowledge Operation System Type Logic)](https://arxiv.org/abs/2601.01143)
*Peng Chen*

Main category: cs.CL

TL;DR: KOS-TL是一个基于依赖类型理论的知识操作系统类型逻辑框架，旨在为自主可执行知识系统提供严格的逻辑基础，统一数据、逻辑和证明，并确保状态演化的形式化验证。


<details>
  <summary>Details</summary>
Motivation: 传统知识表示模型存在静态符号逻辑与动态系统执行之间的鸿沟，需要一种能够统一数据、逻辑和证明的严格逻辑框架来支持自主可执行知识系统。

Method: 基于依赖类型理论，采用三层架构：核心层（静态类型宇宙和构造原语）、内核层（事件驱动状态演化机制）、运行时层（物理信号与逻辑证据的双向精化）。整合Davidsonian事件语义和Martin-Löf类型理论，实现"证明携带知识"。

Result: 形式化定义了系统的操作语义，证明了关键元理论性质（Progress和Evolutionary Consistency），确保系统在连续状态转换中保持逻辑自洽且无死锁状态。在工业追溯和跨境金融合规等应用中展示了实用性。

Conclusion: KOS-TL为下一代智能自主操作系统提供了强大且形式化可验证的基础，通过统一数据、逻辑和证明，实现了知识系统的严格逻辑基础和动态可执行性。

Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational substrate.The architecture of KOS-TL is organized into three hierarchical layers: the Core Layer, which defines the static type universe and constructive primitives; the Kernel Layer, which governs state evolution through an event-driven mechanism characterized by the triple $\langle Σ, \textsf{Ev}, Δ\rangle$; and the Runtime Layer, responsible for the bidirectional refinement of physical signals into logical evidence. We formally define the operational semantics of the system and prove key meta-theoretical properties, including Progress and Evolutionary Consistency, ensuring that the system remains logically self-consistent and free from stuck states during continuous state transitions.By integrating Davidsonian event semantics with Martin-Löf type theory, KOS-TL enables the construction of "proof-carrying knowledge," where every state change in the knowledge base is accompanied by a formal witness of its validity. We demonstrate the practical utility of this logic through application examples in industrial traceability and cross-border financial compliance. Our results suggest that KOS-TL provides a robust, formally verifiable basis for the next generation of intelligent, autonomous operating systems.

</details>


### [27] [Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584)
*Jakub Hoscilowicz*

Main category: cs.CL

TL;DR: 研究发现AI系统的能力与可操控性并非负相关，区分了授权与非授权操控性，揭示了开放权重模型面临的安全-安全困境，并通过实验展示了反工具性提示能显著降低有害行为输出。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统的能力与可操控性之间的关系，特别是区分授权操控性（开发者实现预期行为）和非授权操控性（攻击者引发禁止行为），揭示开放权重模型面临的安全-安全困境。

Method: 使用Qwen3模型（4B/30B；基础版/指导版/思考版）和InstrumentalEval评估框架，通过对比亲工具性和反工具性提示后缀，测量工具性收敛行为（如关机回避、欺骗、自我复制）的变化。

Result: 能力更高的系统并不一定更难操控；反工具性提示能显著降低工具性收敛行为（Qwen3-30B指导版从81.69%降至2.82%）；在反工具性提示下，更大的对齐模型产生的收敛行为更少。

Conclusion: 开放权重模型面临安全与安全的根本矛盾：安全需要高可操控性来实施控制，而安全需要低可操控性以防止恶意行为。当前开放权重模型通过微调和对抗性提示具有高度可操控性，这既是风险也是机遇。

Abstract: We examine two properties of AI systems: capability (what a system can do) and steerability (how reliably one can shift behavior toward intended outcomes). In our experiments, higher capability does not imply lower steerability. We distinguish between authorized steerability (builders reliably reaching intended behaviors) and unauthorized steerability (attackers eliciting disallowed behaviors). This distinction highlights a fundamental safety--security dilemma for open-weight AI models: safety requires high steerability to enforce control (e.g., stop/refuse), while security requires low steerability to prevent malicious actors from eliciting harmful behaviors. This tension is acute for open-weight models, which are currently highly steerable via common techniques such as fine-tuning and adversarial prompting. Using Qwen3 models (4B/30B; Base/Instruct/Thinking) and InstrumentalEval, we find that a short anti-instrumental prompt suffix sharply reduces outputs labeled as instrumental convergence (e.g., shutdown avoidance, deception, self-replication). For Qwen3-30B Instruct, convergence drops from 81.69% under a pro-instrumental suffix to 2.82% under an anti-instrumental suffix. Under anti-instrumental prompting, larger aligned models produce fewer convergence-labeled outputs than smaller ones (Instruct: 2.82% vs. 4.23%; Thinking: 4.23% vs. 9.86%). Code is available at github.com/j-hoscilowicz/instrumental_steering.

</details>


### [28] [Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage](https://arxiv.org/abs/2601.01685)
*Jinwei Hu,Xinmiao Huang,Youcheng Sun,Yi Dong,Xiaowei Huang*

Main category: cs.CL

TL;DR: 论文提出了一种新型的认知合谋攻击，利用LLM的过度思考倾向，通过仅使用真实证据片段在公开渠道构建欺骗性叙述，导致受害者内化并传播虚假结论。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主代理转变，其推理能力引入了一个意外的攻击面。现有攻击通常依赖隐蔽通信、后门或伪造文档，而本文研究如何仅通过真实证据片段在公开渠道实施认知合谋攻击。

Method: 提出Generative Montage框架，包含Writer-Editor-Director三个角色，通过对抗性辩论和协调发布证据片段构建欺骗性叙述。开发CoPHEME数据集（基于真实世界谣言事件），在14个LLM家族中模拟攻击。

Result: 攻击成功率在专有模型中达74.4%，开源模型中达70.6%。反直觉的是，更强的推理能力反而增加易受攻击性，推理专用模型比基础模型更易受攻击。虚假信念会向下游传播，欺骗率超过60%。

Conclusion: LLM代理在动态信息环境中的交互存在社会技术漏洞，认知合谋攻击利用真实证据片段就能有效操纵信念，且推理能力越强的模型越脆弱，需要新的防御机制。

Abstract: As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.

</details>


### [29] [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)
*Tran Sy Bao*

Main category: cs.CL

TL;DR: 提出Canonical Semantic Form (CSF)框架，实现任意源语言到手语的直接翻译，无需英语中介，通过9个通用语义槽分解语句，特别针对条件表达建立了35种条件类型的分类体系。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译系统通常需要英语作为中介语言，这为全球非英语使用者（特别是聋人社区）设置了障碍。需要一种语言无关的语义表示框架，实现从任意源语言到手语的直接翻译。

Method: 提出Canonical Semantic Form (CSF)框架，将话语分解为9个通用语义槽：事件、意图、时间、条件、施事者、对象、地点、目的、修饰语。特别贡献是建立了包含35种条件类型的全面分类体系，涵盖8个语义类别。训练了一个轻量级基于Transformer的提取器（0.74 MB）。

Result: 在四种类型学上不同的语言（英语、越南语、日语、法语）上实现了99.03%的平均槽提取准确率。条件分类准确率达到99.4%（35个类别）。在CPU上的推理延迟为3.02ms，支持浏览器应用中的实时手语生成。

Conclusion: CSF框架成功实现了语言无关的手语翻译，消除了英语中介的需求。轻量级模型的高准确率和低延迟使其适用于实时应用。开源代码、模型和多语言数据集将推动无障碍手语技术的进一步发展。

Abstract: Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [30] [DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos](https://arxiv.org/abs/2601.01651)
*Yucheng Xu,Xiaofeng Mao,Elle Miller,Xinyu Yi,Yang Li,Zhibin Li,Robert B. Fisher*

Main category: cs.RO

TL;DR: DemoBot：从单段未标注RGB-D视频中学习复杂双手操作技能的学习框架，通过提取运动轨迹作为先验，结合强化学习进行精炼，实现长时程双手装配任务。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量标注数据或从零开始学习复杂双手操作技能，成本高且效率低。本文旨在直接从单段未标注的人类演示视频中学习复杂操作技能，减少数据需求并提高学习效率。

Method: 1. 从原始RGB-D视频中提取双手和物体的结构化运动轨迹作为运动先验；2. 提出新颖的强化学习流程：基于时间分段的RL确保状态与演示的时间对齐，成功门控重置策略平衡技能精炼与后续阶段探索，事件驱动奖励课程通过自适应阈值指导高精度操作学习。

Result: 该框架成功实现了长时程同步和异步双手装配任务，验证了从人类视频直接获取复杂操作技能的可扩展性。

Conclusion: DemoBot提供了一种从单段未标注人类视频直接学习复杂双手操作技能的有效方法，通过结合视频处理和强化学习技术，实现了长时程复杂任务的技能获取，为机器人技能学习提供了可扩展的解决方案。

Abstract: This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.

</details>


### [31] [Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions](https://arxiv.org/abs/2601.01726)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.RO

TL;DR: 开发用于MRI扫描仪环境的机器人辅助系统，通过计算处理MR图像建立血管虚拟路径，生成定制磁场梯度模式控制设备，提升血管内介入手术的精度和安全性。


<details>
  <summary>Details</summary>
Motivation: MRI扫描仪强磁场环境下机器人系统面临精度和稳定性挑战，需要增强MRI在医学成像中的作用，特别是在机器人辅助设备引导血管内介入手术中的应用。

Method: 开发基于Qt框架和C/C++的计算系统，包括计算单元和用户界面，与MRI扫描仪无缝集成。系统处理MR图像描绘血管网络，建立虚拟路径和边界，生成定制磁场梯度模式控制设备，考虑血管几何形状、安全规范和血流特性。

Result: 系统能够创建针对血管几何形状和安全规范的定制磁场梯度模式，适应不同血流特性实现精细导航。建模方面评估预设血管路径的安全性和可行性。系统显著提升了血管内手术的精度和安全性。

Conclusion: 该系统代表了成像技术与机器人辅助融合的重要进展，通过专门软件模块显著增强了血管内手术的精度和安全性，是MRI引导机器人辅助血管内介入的重要技术进步。

Abstract: Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.

</details>


### [32] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

TL;DR: 提出一种级联框架，将纵向规划显式地建立在行驶路径上，实现协调的横向和纵向规划，在Bench2Drive基准测试中达到新的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶规划方法将横向和纵向预测并行处理，导致：1) 规划的路径和速度协调失败；2) 未充分利用行驶路径作为纵向规划的先验信息，造成静态信息冗余编码

Method: 提出级联框架，将纵向规划显式地建立在行驶路径上，采用路径条件化公式，沿行驶路径预测纵向位移而非完整2D轨迹点；引入面向规划的数据增强策略，模拟车辆切入等安全关键事件

Result: 在Bench2Drive基准测试中达到新的SOTA：驾驶分数89.07，成功率73.18%，显著改善了协调性和安全性

Conclusion: 通过将纵向规划显式地建立在行驶路径上，实现了更协调、更安全的横向和纵向规划，简化了纵向推理过程，并增强了模型对安全关键事件的应对能力

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>
