<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MOSCARD -- Causal Reasoning and De-confounding for Multimodal Opportunistic Screening of Cardiovascular Adverse Events](https://arxiv.org/abs/2506.19174)
*Jialu Pi,Juan Maria Farina,Rimita Lahiri,Jiwoong Jeong,Archana Gurudu,Hyung-Bok Park,Chieh-Ju Chao,Chadi Ayoub,Reza Arsanjani,Imon Banerjee*

Main category: cs.CV

TL;DR: 论文提出了一种多模态预测模型MOSCARD，结合胸片（CXR）和心电图（ECG）数据，通过因果推理和共注意力机制提升心血管事件（MACE）风险评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 心血管事件（MACE）是全球主要死因，现有风险评估方法受限于单模态数据和采样偏差。多模态数据整合可提供更全面的风险预测。

Method: 提出MOSCARD框架，结合CXR和ECG数据，采用多模态对齐、因果推理和双反向传播图去混杂。

Result: 在内部和外部数据集上，模型表现优于单模态和现有基准模型（AUC: 0.75, 0.83, 0.71）。

Conclusion: MOSCARD为低成本机会性筛查提供了有效工具，有助于早期干预和改善患者预后。

Abstract: Major Adverse Cardiovascular Events (MACE) remain the leading cause of
mortality globally, as reported in the Global Disease Burden Study 2021.
Opportunistic screening leverages data collected from routine health check-ups
and multimodal data can play a key role to identify at-risk individuals. Chest
X-rays (CXR) provide insights into chronic conditions contributing to major
adverse cardiovascular events (MACE), while 12-lead electrocardiogram (ECG)
directly assesses cardiac electrical activity and structural abnormalities.
Integrating CXR and ECG could offer a more comprehensive risk assessment than
conventional models, which rely on clinical scores, computed tomography (CT)
measurements, or biomarkers, which may be limited by sampling bias and single
modality constraints. We propose a novel predictive modeling framework -
MOSCARD, multimodal causal reasoning with co-attention to align two distinct
modalities and simultaneously mitigate bias and confounders in opportunistic
risk estimation. Primary technical contributions are - (i) multimodal alignment
of CXR with ECG guidance; (ii) integration of causal reasoning; (iii) dual
back-propagation graph for de-confounding. Evaluated on internal, shift data
from emergency department (ED) and external MIMIC datasets, our model
outperformed single modality and state-of-the-art foundational models - AUC:
0.75, 0.83, 0.71 respectively. Proposed cost-effective opportunistic screening
enables early intervention, improving patient outcomes and reducing
disparities.

</details>


### [2] [HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis](https://arxiv.org/abs/2506.19291)
*Xiaoyuan Wang,Yizhou Zhao,Botao Ye,Xiaojun Shan,Weijie Lyu,Lu Qi,Kelvin C. K. Chan,Yinxiao Li,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: HoliGS是一种新颖的可变形高斯泼溅框架，用于从长单目RGB视频中实现视图合成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有4D高斯泼溅和动态NeRF方法在长时间捕获中训练开销大的问题。

Method: 将场景分解为静态背景和时间变化对象，通过可逆高斯泼溅变形网络实现全局刚性变换、骨架驱动关节和非刚性变形。

Result: 在挑战性数据集上实现更高质量的重建，显著减少训练和渲染时间。

Conclusion: HoliGS为真实场景中的EVS提供了实用且可扩展的解决方案。

Abstract: We propose HoliGS, a novel deformable Gaussian splatting framework that
addresses embodied view synthesis from long monocular RGB videos. Unlike prior
4D Gaussian splatting and dynamic NeRF pipelines, which struggle with training
overhead in minute-long captures, our method leverages invertible Gaussian
Splatting deformation networks to reconstruct large-scale, dynamic environments
accurately. Specifically, we decompose each scene into a static background plus
time-varying objects, each represented by learned Gaussian primitives
undergoing global rigid transformations, skeleton-driven articulation, and
subtle non-rigid deformations via an invertible neural flow. This hierarchical
warping strategy enables robust free-viewpoint novel-view rendering from
various embodied camera trajectories by attaching Gaussians to a complete
canonical foreground shape (\eg, egocentric or third-person follow), which may
involve substantial viewpoint changes and interactions between multiple actors.
Our experiments demonstrate that \ourmethod~ achieves superior reconstruction
quality on challenging datasets while significantly reducing both training and
rendering time compared to state-of-the-art monocular deformable NeRFs. These
results highlight a practical and scalable solution for EVS in real-world
scenarios. The source code will be released.

</details>


### [3] [EvDetMAV: Generalized MAV Detection from Moving Event Cameras](https://arxiv.org/abs/2506.19416)
*Yin Zhang,Zian Ning,Xiaoyu Zhang,Shiliang Guo,Peidong Liu,Shiyu Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一种基于事件相机的MAV检测方法，通过利用螺旋桨在事件流中的特征，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有MAV检测方法依赖RGB图像的外观特征，难以实现泛化检测。事件相机捕捉到的高速旋转螺旋桨特征为解决这一问题提供了新思路。

Method: 提出三个模块，从原始事件流中提取螺旋桨的显著时空特征，同时过滤背景噪声和相机运动干扰。

Result: 在未训练的情况下，方法显著优于现有技术，精确率和召回率分别达到83.0%和81.5%。

Conclusion: 该方法在挑战性场景中表现优异，并发布了首个事件相机MAV数据集，为社区提供了新资源。

Abstract: Existing micro aerial vehicle (MAV) detection methods mainly rely on the
target's appearance features in RGB images, whose diversity makes it difficult
to achieve generalized MAV detection. We notice that different types of MAVs
share the same distinctive features in event streams due to their high-speed
rotating propellers, which are hard to see in RGB images. This paper studies
how to detect different types of MAVs from an event camera by fully exploiting
the features of propellers in the original event stream. The proposed method
consists of three modules to extract the salient and spatio-temporal features
of the propellers while filtering out noise from background objects and camera
motion. Since there are no existing event-based MAV datasets, we introduce a
novel MAV dataset for the community. This is the first event-based MAV dataset
comprising multiple scenarios and different types of MAVs. Without training,
our method significantly outperforms state-of-the-art methods and can deal with
challenging scenarios, achieving a precision rate of 83.0\% (+30.3\%) and a
recall rate of 81.5\% (+36.4\%) on the proposed testing dataset. The dataset
and code are available at: https://github.com/WindyLab/EvDetMAV.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [From Tiny Machine Learning to Tiny Deep Learning: A Survey](https://arxiv.org/abs/2506.18927)
*Shriyank Somvanshi,Md Monzurul Islam,Gaurab Chhetri,Rohit Chakraborty,Mahmuda Sultana Mimi,Swagat Ahmed Shuvo,Kazi Sifatul Islam,Syed Aaqib Javed,Sharif Ahmed Rafat,Anandi Dutta,Subasish Das*

Main category: cs.LG

TL;DR: 本文综述了从TinyML到TinyDL的演变，涵盖架构创新、硬件平台、模型优化技术和软件工具链，并探讨了应用领域和未来方向。


<details>
  <summary>Details</summary>
Motivation: 边缘设备的快速增长推动了在边缘部署AI的需求，尤其是资源受限的硬件上部署深度学习模型。

Method: 通过分析量化、剪枝、神经架构搜索等方法，以及硬件和软件工具链的发展，全面概述TinyDL的进展。

Result: 总结了TinyDL在计算机视觉、音频识别等领域的应用，并提出了未来研究方向。

Conclusion: 本文为研究者和从业者提供了TinyDL生态系统的全面视角，为边缘AI的未来发展奠定了基础。

Abstract: The rapid growth of edge devices has driven the demand for deploying
artificial intelligence (AI) at the edge, giving rise to Tiny Machine Learning
(TinyML) and its evolving counterpart, Tiny Deep Learning (TinyDL). While
TinyML initially focused on enabling simple inference tasks on
microcontrollers, the emergence of TinyDL marks a paradigm shift toward
deploying deep learning models on severely resource-constrained hardware. This
survey presents a comprehensive overview of the transition from TinyML to
TinyDL, encompassing architectural innovations, hardware platforms, model
optimization techniques, and software toolchains. We analyze state-of-the-art
methods in quantization, pruning, and neural architecture search (NAS), and
examine hardware trends from MCUs to dedicated neural accelerators.
Furthermore, we categorize software deployment frameworks, compilers, and
AutoML tools enabling practical on-device learning. Applications across domains
such as computer vision, audio recognition, healthcare, and industrial
monitoring are reviewed to illustrate the real-world impact of TinyDL. Finally,
we identify emerging directions including neuromorphic computing, federated
TinyDL, edge-native foundation models, and domain-specific co-design
approaches. This survey aims to serve as a foundational resource for
researchers and practitioners, offering a holistic view of the ecosystem and
laying the groundwork for future advancements in edge AI.

</details>


### [5] [A Batch-Insensitive Dynamic GNN Approach to Address Temporal Discontinuity in Graph Streams](https://arxiv.org/abs/2506.19282)
*Yang Zhou,Xiaoning Ren*

Main category: cs.LG

TL;DR: BADGNN是一种批处理无关的动态图神经网络框架，通过Temporal Lipschitz Regularization和Adaptive Attention Adjustment解决大批次训练导致的时间信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 动态图中保持时间连续性至关重要，但大批次训练的MDGNNs会破坏事件序列，导致时间信息丢失和参数收敛困难。

Method: 提出BADGNN框架，包含Temporal Lipschitz Regularization（TLR）控制参数搜索空间扩展，以及Adaptive Attention Adjustment（A3）缓解注意力失真。

Result: 在三个基准数据集上，BADGNN在保持高性能的同时支持更大的批次和更快的训练速度。

Conclusion: BADGNN有效解决了大批次训练中的时间信息丢失问题，提升了动态图神经网络的训练效率和性能。

Abstract: In dynamic graphs, preserving temporal continuity is critical. However,
Memory-based Dynamic Graph Neural Networks (MDGNNs) trained with large batches
often disrupt event sequences, leading to temporal information loss. This
discontinuity not only deteriorates temporal modeling but also hinders
optimization by increasing the difficulty of parameter convergence. Our
theoretical study quantifies this through a Lipschitz upper bound, showing that
large batch sizes enlarge the parameter search space. In response, we propose
BADGNN, a novel batch-agnostic framework consisting of two core components: (1)
Temporal Lipschitz Regularization (TLR) to control parameter search space
expansion, and (2) Adaptive Attention Adjustment (A3) to alleviate attention
distortion induced by both regularization and batching. Empirical results on
three benchmark datasets show that BADGNN maintains strong performance while
enabling significantly larger batch sizes and faster training compared to TGN.
Our code is available at Code:
https://anonymous.4open.science/r/TGN_Lipichitz-C033/.

</details>


### [6] [Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment](https://arxiv.org/abs/2506.19342)
*Sudesh Bhagat,Raghupathi Kandiboina,Ibne Farabi Shihab,Skylar Knickerbocker,Neal Hawkins,Anuj Sharma*

Main category: cs.LG

TL;DR: 研究通过BERT模型分析爱荷华州2016-2022年的371,062条车祸记录，发现24.03%的酒精推断不匹配（AIM），并提出改进数据质量和针对性培训的建议。


<details>
  <summary>Details</summary>
Motivation: 全球道路交通事故致死率高，需准确数据支持预防策略和政策制定。

Method: 使用BERT模型分析车祸记录，结合Probit Logit模型统计工具，开发框架减少AIM。

Result: 发现2,767起AIM事件，酒精相关致命事故和夜间事故AIM比例较低，未知车型和老年司机事故更易出现AIM。

Conclusion: 需针对性培训和优化数据管理以提高报告准确性，支持政策制定。

Abstract: Road traffic crashes are a significant global cause of fatalities,
emphasizing the urgent need for accurate crash data to enhance prevention
strategies and inform policy development. This study addresses the challenge of
alcohol inference mismatch (AIM) by employing database narrative alignment to
identify AIM in crash data. A framework was developed to improve data quality
in crash management systems and reduce the percentage of AIM crashes. Utilizing
the BERT model, the analysis of 371,062 crash records from Iowa (2016-2022)
revealed 2,767 AIM incidents, resulting in an overall AIM percentage of 24.03%.
Statistical tools, including the Probit Logit model, were used to explore the
crash characteristics affecting AIM patterns. The findings indicate that
alcohol-related fatal crashes and nighttime incidents have a lower percentage
of the mismatch, while crashes involving unknown vehicle types and older
drivers are more susceptible to mismatch. The geospatial cluster as part of
this study can identify the regions which have an increased need for education
and training. These insights highlight the necessity for targeted training
programs and data management teams to improve the accuracy of crash reporting
and support evidence-based policymaking.

</details>


### [7] [Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models](https://arxiv.org/abs/2506.19697)
*Jungwoo Park,Taewhoo Lee,Chanwoong Yoon,Hyeon Hwang,Jaewoo Kang*

Main category: cs.LG

TL;DR: 论文提出Outlier-Safe Pre-Training (OSP)，通过预防极端激活异常值，提升大型语言模型（LLMs）的量化性能。


<details>
  <summary>Details</summary>
Motivation: 极端激活异常值严重影响LLMs的量化性能，阻碍高效部署。现有方法难以有效缓解这一问题。

Method: OSP结合三项创新：Muon优化器、Single-Scale RMSNorm和可学习嵌入投影，从训练阶段预防异常值形成。

Result: 在1.4B参数模型上验证，OSP模型在4位量化下表现优异（平均得分35.7 vs 26.5），且训练开销仅增加2%。

Conclusion: 异常值并非LLMs固有特性，而是训练策略的结果。OSP为高效LLM部署提供了新途径。

Abstract: Extreme activation outliers in Large Language Models (LLMs) critically
degrade quantization performance, hindering efficient on-device deployment.
While channel-wise operations and adaptive gradient scaling are recognized
causes, practical mitigation remains challenging. We introduce Outlier-Safe
Pre-Training (OSP), a practical guideline that proactively prevents outlier
formation rather than relying on post-hoc mitigation. OSP combines three key
innovations: (1) the Muon optimizer, eliminating privileged bases while
maintaining training efficiency; (2) Single-Scale RMSNorm, preventing
channel-wise amplification; and (3) a learnable embedding projection,
redistributing activation magnitudes originating from embedding matrices. We
validate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is
the first production-scale LLM trained without such outliers. Under aggressive
4-bit quantization, our OSP model achieves a 35.7 average score across 10
benchmarks (compared to 26.5 for an Adam-trained model), with only a 2%
training overhead. Remarkably, OSP models exhibit near-zero excess kurtosis
(0.04) compared to extreme values (1818.56) in standard models, fundamentally
altering LLM quantization behavior. Our work demonstrates that outliers are not
inherent to LLMs but are consequences of training strategies, paving the way
for more efficient LLM deployment. The source code and pretrained checkpoints
are available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.

</details>


### [8] [Model Guidance via Robust Feature Attribution](https://arxiv.org/abs/2506.19680)
*Mihnea Ghitu,Matthew Wicker,Vihari Piratla*

Main category: cs.LG

TL;DR: 提出一种新方法，通过优化解释鲁棒性和减少捷径学习，显著降低测试错误率。


<details>
  <summary>Details</summary>
Motivation: 防止模型依赖无关或误导性特征（捷径特征），避免现实危害。

Method: 提出简化目标函数，同时优化解释鲁棒性和捷径学习缓解，理论证明其有效性。

Result: 实验显示，测试错误率降低20%，并扩展至自然语言处理任务。

Conclusion: 方法优于现有技术，提供实用洞见（如标注质量的重要性）。

Abstract: Controlling the patterns a model learns is essential to preventing reliance
on irrelevant or misleading features. Such reliance on irrelevant features,
often called shortcut features, has been observed across domains, including
medical imaging and natural language processing, where it may lead to
real-world harms. A common mitigation strategy leverages annotations (provided
by humans or machines) indicating which features are relevant or irrelevant.
These annotations are compared to model explanations, typically in the form of
feature salience, and used to guide the loss function during training.
Unfortunately, recent works have demonstrated that feature salience methods are
unreliable and therefore offer a poor signal to optimize. In this work, we
propose a simplified objective that simultaneously optimizes for explanation
robustness and mitigation of shortcut learning. Unlike prior objectives with
similar aims, we demonstrate theoretically why our approach ought to be more
effective. Across a comprehensive series of experiments, we show that our
approach consistently reduces test-time misclassifications by 20% compared to
state-of-the-art methods. We also extend prior experimental settings to include
natural language processing tasks. Additionally, we conduct novel ablations
that yield practical insights, including the relative importance of annotation
quality over quantity. Code for our method and experiments is available at:
https://github.com/Mihneaghitu/ModelGuidanceViaRobustFeatureAttribution.

</details>


### [9] [Orthogonal Finetuning Made Scalable](https://arxiv.org/abs/2506.19847)
*Zeju Qiu,Weiyang Liu,Adrian Weller,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: OFTv2通过输入中心重构和Cayley-Neumann参数化，显著降低了OFT的计算和内存需求，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: OFT的高运行时和内存需求限制了其实际应用，需要更高效的实现。

Method: 提出OFTv2，采用输入中心重构（矩阵-向量乘法）和Cayley-Neumann参数化（近似矩阵逆）。

Result: OFTv2训练速度提升10倍，GPU内存使用降低3倍，且支持量化基础模型调优。

Conclusion: OFTv2在效率、内存和稳定性上优于现有方法，适用于实际部署。

Abstract: Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation
while preventing catastrophic forgetting, but its high runtime and memory
demands limit practical deployment. We identify the core computational
bottleneck in OFT as its weight-centric implementation, which relies on costly
matrix-matrix multiplications with cubic complexity. To overcome this, we
propose OFTv2, an input-centric reformulation that instead uses matrix-vector
multiplications (i.e., matrix-free computation), reducing the computational
cost to quadratic. We further introduce the Cayley-Neumann parameterization, an
efficient orthogonal parameterization that approximates the matrix inversion in
Cayley transform via a truncated Neumann series. These modifications allow
OFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage
without compromising performance. In addition, we extend OFTv2 to support
finetuning quantized foundation models and show that it outperforms the popular
QLoRA in training stability, efficiency, and memory usage.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [10] [Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting](https://arxiv.org/abs/2506.19089)
*Nathaniel Getachew,Abulhair Saparov*

Main category: cs.CL

TL;DR: 介绍了一个名为StorySim的可编程框架，用于生成合成故事以评估大语言模型（LLMs）的心理理论（ToM）和世界建模（WM）能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准可能存在预训练数据污染问题，StorySim通过可控的故事板生成新颖、组合的故事提示，以精确操控角色视角和事件。

Method: 设计了第一和第二阶ToM任务及WM任务，控制对心理状态的追踪和建模能力。

Result: 实验表明，大多数LLMs在WM任务上表现优于ToM任务，且对人类推理优于对无生命物体推理。还发现启发式行为如近因偏差和对早期事件的过度依赖。

Conclusion: StorySim为评估LLMs的ToM和WM能力提供了有效工具，并揭示了模型行为中的潜在偏差。

Abstract: We introduce $\texttt{StorySim}$, a programmable framework for synthetically
generating stories to evaluate the theory of mind (ToM) and world modeling (WM)
capabilities of large language models (LLMs). Unlike prior benchmarks that may
suffer from contamination in pretraining data, $\texttt{StorySim}$ produces
novel, compositional story prompts anchored by a highly controllable
$\texttt{Storyboard}$, enabling precise manipulation of character perspectives
and events. We use this framework to design first- and second-order ToM tasks
alongside WM tasks that control for the ability to track and model mental
states. Our experiments across a suite of state-of-the-art LLMs reveal that
most models perform better on WM tasks than ToM tasks, and that models tend to
perform better reasoning with humans compared to inanimate objects.
Additionally, our framework enabled us to find evidence of heuristic behavior
such as recency bias and an over-reliance on earlier events in the story. All
code for generating data and evaluations is freely available.

</details>


### [11] [EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition](https://arxiv.org/abs/2506.19279)
*Zhiyang Qi,Keiko Takamizo,Mariko Ukiyo,Michimasa Inaba*

Main category: cs.CL

TL;DR: EmoStage是一个基于开源LLM的框架，通过视角推断和阶段识别提升AI心理咨询的共情响应质量，无需额外训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决当前AI心理咨询系统在理解用户心理状态、依赖高质量数据及隐私问题上的局限性。

Method: 利用开源LLM的推理能力，结合视角推断（理解用户心理）和阶段识别（匹配咨询流程），生成共情响应。

Result: 在日文和中文心理咨询场景中，EmoStage提升了基础模型的响应质量，与数据驱动方法表现相当。

Conclusion: EmoStage为AI心理咨询提供了一种高效、隐私友好的解决方案，展现了开源LLM的潜力。

Abstract: The rising demand for mental health care has fueled interest in AI-driven
counseling systems. While large language models (LLMs) offer significant
potential, current approaches face challenges, including limited understanding
of clients' psychological states and counseling stages, reliance on
high-quality training data, and privacy concerns associated with commercial
deployment. To address these issues, we propose EmoStage, a framework that
enhances empathetic response generation by leveraging the inference
capabilities of open-source LLMs without additional training data. Our
framework introduces perspective-taking to infer clients' psychological states
and support needs, enabling the generation of emotionally resonant responses.
In addition, phase recognition is incorporated to ensure alignment with the
counseling process and to prevent contextually inappropriate or inopportune
responses. Experiments conducted in both Japanese and Chinese counseling
settings demonstrate that EmoStage improves the quality of responses generated
by base models and performs competitively with data-driven methods.

</details>


### [12] [Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models](https://arxiv.org/abs/2506.19483)
*Marcos Estecha-Garitagoitia,Chen Zhang,Mario Rodríguez-Cantelar,Luis Fernando D'Haro*

Main category: cs.CL

TL;DR: 论文探索了基于常识关系的对话系统数据增强任务，并自动评估生成的合成对话。利用预训练大语言模型（LLMs）的扩展知识和零样本能力，结合Chain-of-Thought（CoT）方法，生成条件化于常识属性的对话，并提出了自动评估框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用LLMs的常识推理能力，为对话系统生成多样化的数据增强，并自动评估其质量。

Method: 方法包括：1）从5个知名对话数据集中提取200个部分对话，生成基于事件常识属性的替代响应；2）提出基于指令的提示框架，利用LLMs自动评估生成对话的质量。

Result: 初步结果表明，该方法能有效利用LLMs的常识推理能力，生成高质量的对话数据增强。

Conclusion: 结论是该方法为对话系统的数据增强和自动评估提供了有效途径，展示了LLMs在常识推理任务中的潜力。

Abstract: This paper provides preliminary results on exploring the task of performing
turn-level data augmentation for dialogue system based on different types of
commonsense relationships, and the automatic evaluation of the generated
synthetic turns. The proposed methodology takes advantage of the extended
knowledge and zero-shot capabilities of pretrained Large Language Models (LLMs)
to follow instructions, understand contextual information, and their
commonsense reasoning capabilities. The approach draws inspiration from
methodologies like Chain-of-Thought (CoT), applied more explicitly to the task
of prompt-based generation for dialogue-based data augmentation conditioned on
commonsense attributes, and the automatic evaluation of the generated
dialogues.
  To assess the effectiveness of the proposed approach, first we extracted 200
randomly selected partial dialogues, from 5 different well-known dialogue
datasets, and generate alternative responses conditioned on different event
commonsense attributes. This novel dataset allows us to measure the proficiency
of LLMs in generating contextually relevant commonsense knowledge, particularly
up to 12 different specific ATOMIC [10] database relations. Secondly, we
propose an evaluation framework to automatically detect the quality of the
generated dataset inspired by the ACCENT [26] metric, which offers a nuanced
approach to assess event commonsense. However, our method does not follow
ACCENT's complex eventrelation tuple extraction process. Instead, we propose an
instruction-based prompt for each commonsense attribute and use
state-of-the-art LLMs to automatically detect the original attributes used when
creating each augmented turn in the previous step.
  Preliminary results suggest that our approach effectively harnesses LLMs
capabilities for commonsense reasoning and evaluation in dialogue systems.

</details>


### [13] [Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection](https://arxiv.org/abs/2506.19548)
*Devesh Pant,Rishi Raj Grandhe,Vipin Samaria,Mukul Paul,Sudhir Kumar,Saransh Khanna,Jatin Agrawal,Jushaan Singh Kalra,Akhil VSSG,Satish V Khalikar,Vipin Garg,Himanshu Chauhan,Pranay Verma,Neha Khandelwal,Soma S Dhavala,Minesh Mathew*

Main category: cs.CL

TL;DR: Health Sentinel是一个多阶段信息提取管道，结合机器学习和非机器学习方法，从在线文章中提取疾病爆发事件，以支持早期检测和干预。


<details>
  <summary>Details</summary>
Motivation: 传统基于指标的疾病监测方法存在挑战，而在线媒体监测成为流行但手动筛选不切实际。

Method: 使用多阶段信息提取管道，结合ML和非ML方法，从在线文章中提取结构化事件信息。

Result: 处理了3亿多篇新闻文章，识别了9.5万多个独特健康事件，其中3500多个被专家列为潜在爆发。

Conclusion: Health Sentinel有效支持了疾病爆发的早期检测和公共卫生干预。

Abstract: Early detection of disease outbreaks is crucial to ensure timely intervention
by the health authorities. Due to the challenges associated with traditional
indicator-based surveillance, monitoring informal sources such as online media
has become increasingly popular. However, owing to the number of online
articles getting published everyday, manual screening of the articles is
impractical. To address this, we propose Health Sentinel. It is a multi-stage
information extraction pipeline that uses a combination of ML and non-ML
methods to extract events-structured information concerning disease outbreaks
or other unusual health events-from online articles. The extracted events are
made available to the Media Scanning and Verification Cell (MSVC) at the
National Centre for Disease Control (NCDC), Delhi for analysis, interpretation
and further dissemination to local agencies for timely intervention. From April
2022 till date, Health Sentinel has processed over 300 million news articles
and identified over 95,000 unique health events across India of which over
3,500 events were shortlisted by the public health experts at NCDC as potential
outbreaks.

</details>


### [14] [Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach](https://arxiv.org/abs/2506.19750)
*Takashi Nishibayashi,Seiji Kanazawa,Kumpei Yamada*

Main category: cs.CL

TL;DR: 提出了一种基于合成病例模拟的方法，用于评估症状检查器算法更新对罕见疾病诊断性能的影响。


<details>
  <summary>Details</summary>
Motivation: 解决罕见疾病评估数据不足和人工创建临床病例成本高的问题。

Method: 利用人类表型本体（HPO）生成合成病例，模拟症状检查器访谈，并通过R²验证方法有效性。

Result: 对于有频率信息的疾病，R²显示预测性能良好（召回@8为0.831，精确@8为0.78），而无频率信息的疾病预测误差较大。

Conclusion: 该方法透明且低成本，可用于罕见疾病算法更新的预部署评估，支持早期诊断。

Abstract: Background: Symptom Checkers (SCs) provide users with personalized medical
information. To prevent performance degradation from algorithm updates, SC
developers must evaluate diagnostic performance changes for individual diseases
before deployment. However, acquiring sufficient evaluation data for rare
diseases is difficult, and manually creating numerous clinical vignettes is
costly and impractical. Objective: This study proposes and validates a novel
Synthetic Vignette Simulation Approach to evaluate diagnostic performance
changes for individual rare diseases following SC algorithm updates. Methods:
We used disease-phenotype annotations from the Human Phenotype Ontology (HPO),
a knowledge database for rare diseases, to generate synthetic vignettes. With
these, we simulated SC interviews to estimate the impact of algorithm updates
on real-world diagnostic performance. The method's effectiveness was evaluated
retrospectively by comparing estimated values with actual metric changes using
the R 2(R-squared) coefficient. Results: The experiment included eight past SC
algorithm updates. For updates on diseases with frequency information in HPO
(n=5), the R^2 for recall@8 change was 0.831 (p=0.031), and for precision@8
change, it was 0.78 (p=0.047), indicating the method can predict
post-deployment performance. In contrast, large prediction errors occurred for
diseases without frequency information (n=3), highlighting its importance. The
manual effort to map HPO phenotypes to SC symptoms was approximately 2 hours
per disease. Conclusions: Our method enables pre-deployment evaluation of SC
algorithm changes for individual rare diseases using a publicly available,
expert-created knowledge base. This transparent and low-cost approach allows
developers to efficiently improve diagnostic performance for rare diseases,
potentially enhancing support for early diagnosis.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [15] [FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation](https://arxiv.org/abs/2506.18960)
*Siqi Shang,Mingyo Seo,Yuke Zhu,Lilly Chin*

Main category: cs.RO

TL;DR: FORTE是一种嵌入柔性夹爪的触觉传感系统，通过3D打印的鳍状夹爪和内部空气通道提供低延迟的力和滑动反馈，成功抓取易碎物体。


<details>
  <summary>Details</summary>
Motivation: 刚性平行夹爪在抓取易碎物体时依赖视觉反馈，触觉传感和软机器人技术可提供响应性和顺应性，但现有方法集成复杂或响应慢。

Method: FORTE采用3D打印的鳍状夹爪和内部空气通道，实现低延迟的力和滑动反馈，确保抓取力度适中且不损坏物体。

Result: FORTE能准确估计0-8N的抓取力（平均误差0.2N），并在100ms内检测滑动事件，抓取易碎物体成功率达98.6%，滑动检测准确率93%。

Conclusion: FORTE为易碎物体的机器人抓取提供了一种实用且高效的解决方案。

Abstract: Handling delicate and fragile objects remains a major challenge for robotic
manipulation, especially for rigid parallel grippers. While the simplicity and
versatility of parallel grippers have led to widespread adoption, these
grippers are limited by their heavy reliance on visual feedback. Tactile
sensing and soft robotics can add responsiveness and compliance. However,
existing methods typically involve high integration complexity or suffer from
slow response times. In this work, we introduce FORTE, a tactile sensing system
embedded in compliant gripper fingers. FORTE uses 3D-printed fin-ray grippers
with internal air channels to provide low-latency force and slip feedback.
FORTE applies just enough force to grasp objects without damaging them, while
remaining easy to fabricate and integrate. We find that FORTE can accurately
estimate grasping forces from 0-8 N with an average error of 0.2 N, and detect
slip events within 100 ms of occurring. We demonstrate FORTE's ability to grasp
a wide range of slippery, fragile, and deformable objects. In particular, FORTE
grasps fragile objects like raspberries and potato chips with a 98.6% success
rate, and achieves 93% accuracy in detecting slip events. These results
highlight FORTE's potential as a robust and practical solution for enabling
delicate robotic manipulation. Project page: https://merge-lab.github.io/FORTE

</details>
