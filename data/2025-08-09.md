<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
*Chirag Seth,Divya Naiken,Keyan Lin*

Main category: cs.CV

TL;DR: 利用事件相机和深度学习技术，开发了一种成本效益高且可解释的算法，用于精确追踪人眼中心位置，CNN_LSTM模型达到81%准确率。


<details>
  <summary>Details</summary>
Motivation: 人眼运动速度快（可达300度/秒），传统高精度追踪设备昂贵，研究旨在通过事件相机和深度学习提供低成本解决方案，提升VR/AR设备的用户体验。

Method: 采用CNN_LSTM深度学习模型，结合事件相机的输入数据，预测人眼中心位置（x, y）。

Result: CNN_LSTM模型表现最佳，准确率约为81%。

Conclusion: 研究成功开发了一种高效且成本低的眼动追踪算法，未来计划通过LRP进一步提升模型可解释性和性能。

Abstract: This research project addresses the challenge of accurately tracking eye
movements during specific events by leveraging previous research. Given the
rapid movements of human eyes, which can reach speeds of 300{\deg}/s, precise
eye tracking typically requires expensive and high-speed cameras. Our primary
objective is to locate the eye center position (x, y) using inputs from an
event camera. Eye movement analysis has extensive applications in consumer
electronics, especially in VR and AR product development. Therefore, our
ultimate goal is to develop an interpretable and cost-effective algorithm using
deep learning methods to predict human attention, thereby improving device
comfort and enhancing overall user experience. To achieve this goal, we
explored various approaches, with the CNN\_LSTM model proving most effective,
achieving approximately 81\% accuracy. Additionally, we propose future work
focusing on Layer-wise Relevance Propagation (LRP) to further enhance the
model's interpretability and predictive performance.

</details>


### [2] [FedGIN: Federated Learning with Dynamic Global Intensity Non-linear Augmentation for Organ Segmentation using Multi-modal Images](https://arxiv.org/abs/2508.05137)
*Sachin Dudda Nagaraju,Ashkan Moradi,Bendik Skarre Abrahamsen,Mattijs Elschot*

Main category: cs.CV

TL;DR: FedGIN是一个联邦学习框架，用于多模态医学图像分割，通过GIN模块增强跨模态性能，无需共享原始数据。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中数据稀缺、模态间域偏移和隐私限制的问题。

Method: 提出FedGIN框架，结合GIN模块在本地训练中协调模态强度分布。

Result: 在有限数据场景下提升12-18% Dice分数，完整数据场景下接近集中式性能。

Conclusion: FedGIN在多模态分割中表现优异，同时保护隐私。

Abstract: Medical image segmentation plays a crucial role in AI-assisted diagnostics,
surgical planning, and treatment monitoring. Accurate and robust segmentation
models are essential for enabling reliable, data-driven clinical decision
making across diverse imaging modalities. Given the inherent variability in
image characteristics across modalities, developing a unified model capable of
generalizing effectively to multiple modalities would be highly beneficial.
This model could streamline clinical workflows and reduce the need for
modality-specific training. However, real-world deployment faces major
challenges, including data scarcity, domain shift between modalities (e.g., CT
vs. MRI), and privacy restrictions that prevent data sharing. To address these
issues, we propose FedGIN, a Federated Learning (FL) framework that enables
multimodal organ segmentation without sharing raw patient data. Our method
integrates a lightweight Global Intensity Non-linear (GIN) augmentation module
that harmonizes modality-specific intensity distributions during local
training. We evaluated FedGIN using two types of datasets: an imputed dataset
and a complete dataset. In the limited dataset scenario, the model was
initially trained using only MRI data, and CT data was added to assess its
performance improvements. In the complete dataset scenario, both MRI and CT
data were fully utilized for training on all clients. In the limited-data
scenario, FedGIN achieved a 12 to 18% improvement in 3D Dice scores on MRI test
cases compared to FL without GIN and consistently outperformed local baselines.
In the complete dataset scenario, FedGIN demonstrated near-centralized
performance, with a 30% Dice score improvement over the MRI-only baseline and a
10% improvement over the CT-only baseline, highlighting its strong
cross-modality generalization under privacy constraints.

</details>


### [3] [ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking](https://arxiv.org/abs/2508.05221)
*Xiao Wang,Liye Jin,Xufeng Lou,Shiao Wang,Lan Chen,Bo Jiang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于推理的视觉语言跟踪框架ReasoningTrack，结合预训练模型Qwen2.5-VL，通过SFT和GRPO优化推理与语言生成，并构建了大规模数据集TNLLT。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉语言跟踪中性能有限，未能充分利用大模型优势或提供推理过程洞察。

Method: 结合SFT和GRPO优化推理与语言生成，嵌入更新的语言描述与视觉特征，通过跟踪头预测目标位置。

Result: 在多个基准数据集上验证了方法的有效性，并发布了TNLLT数据集。

Conclusion: 提出的推理策略显著提升了视觉语言跟踪性能，为任务提供了新基准。

Abstract: Vision-language tracking has received increasing attention in recent years,
as textual information can effectively address the inflexibility and inaccuracy
associated with specifying the target object to be tracked. Existing works
either directly fuse the fixed language with vision features or simply modify
using attention, however, their performance is still limited. Recently, some
researchers have explored using text generation to adapt to the variations in
the target during tracking, however, these works fail to provide insights into
the model's reasoning process and do not fully leverage the advantages of large
models, which further limits their overall performance. To address the
aforementioned issues, this paper proposes a novel reasoning-based
vision-language tracking framework, named ReasoningTrack, based on a
pre-trained vision-language model Qwen2.5-VL. Both SFT (Supervised Fine-Tuning)
and reinforcement learning GRPO are used for the optimization of reasoning and
language generation. We embed the updated language descriptions and feed them
into a unified tracking backbone network together with vision features. Then,
we adopt a tracking head to predict the specific location of the target object.
In addition, we propose a large-scale long-term vision-language tracking
benchmark dataset, termed TNLLT, which contains 200 video sequences. 20
baseline visual trackers are re-trained and evaluated on this dataset, which
builds a solid foundation for the vision-language visual tracking task.
Extensive experiments on multiple vision-language tracking benchmark datasets
fully validated the effectiveness of our proposed reasoning-based natural
language generation strategy. The source code of this paper will be released on
https://github.com/Event-AHU/Open_VLTrack

</details>


### [4] [Revealing Latent Information: A Physics-inspired Self-supervised Pre-training Framework for Noisy and Sparse Events](https://arxiv.org/abs/2508.05507)
*Lin Zhu,Ruonan Liu,Xiao Wang,Lizhi Wang,Hua Huang*

Main category: cs.CV

TL;DR: 提出了一种自监督预训练框架，用于从稀疏且嘈杂的事件数据中提取潜在信息，包括边缘和纹理线索。该框架通过三个阶段（差异引导掩码建模、主干固定特征转换和聚焦对比学习）显著提升了多种下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据具有高时间分辨率和宽动态范围，但数据稀疏且噪声多，难以有效提取特征。

Method: 框架分为三个阶段：差异引导掩码建模重建时间强度差异图；主干固定特征转换对比事件和图像特征；聚焦对比学习更新整个模型以提高语义区分能力。

Result: 实验表明，该框架在物体识别、语义分割和光流估计等任务中优于现有方法。

Conclusion: 提出的自监督预训练框架能够有效提取事件数据中的潜在信息，并在多种任务中表现优异。

Abstract: Event camera, a novel neuromorphic vision sensor, records data with high
temporal resolution and wide dynamic range, offering new possibilities for
accurate visual representation in challenging scenarios. However, event data is
inherently sparse and noisy, mainly reflecting brightness changes, which
complicates effective feature extraction. To address this, we propose a
self-supervised pre-training framework to fully reveal latent information in
event data, including edge information and texture cues. Our framework consists
of three stages: Difference-guided Masked Modeling, inspired by the event
physical sampling process, reconstructs temporal intensity difference maps to
extract enhanced information from raw event data. Backbone-fixed Feature
Transition contrasts event and image features without updating the backbone to
preserve representations learned from masked modeling and stabilizing their
effect on contrastive learning. Focus-aimed Contrastive Learning updates the
entire model to improve semantic discrimination by focusing on high-value
regions. Extensive experiments show our framework is robust and consistently
outperforms state-of-the-art methods on various downstream tasks, including
object recognition, semantic segmentation, and optical flow estimation. The
code and dataset are available at https://github.com/BIT-Vision/EventPretrain.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 论文提出了一种公平感知的电力恢复策略EPOPR，通过预测和优化框架解决现有恢复方案中的不公平问题，显著减少了停电时间和社区间的不平等。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件频发，现有电力恢复方案因请求量差异导致不公平，弱势社区恢复较慢。

Method: 设计了EPOPR框架，包含公平一致性分位数回归和时空注意力强化学习，以平衡效率和公平。

Result: 实验显示EPOPR平均减少停电时间3.60%，降低社区间不平等14.19%。

Conclusion: EPOPR有效解决了电力恢复中的效率和公平问题，为未来研究提供了新方向。

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [6] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: 提出了一种统一的流匹配框架，用于标记时间点过程，通过连续和离散流匹配实现非自回归建模，显著提升了长范围预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经时间点过程模型通常是自回归的，导致长范围预测效率低且误差累积。

Method: 采用连续和离散流匹配框架，联合建模事件间隔时间和事件类型，实现非自回归生成。

Result: 在六个真实世界基准测试中，模型在准确性和生成效率上显著优于自回归和基于扩散的基线方法。

Conclusion: 提出的流匹配框架为长范围标记事件序列建模提供了高效且准确的解决方案。

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [7] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
*Zhehan Qu,Tianyi Hu,Christian Fronk,Maria Gorlatova*

Main category: cs.LG

TL;DR: 研究探讨了AR系统在CPR任务中如何影响情境感知（SA），开发了AR应用并通过眼动追踪分析SA，提出了一种预测SA的图神经网络模型。


<details>
  <summary>Details</summary>
Motivation: AR系统在提升任务表现的同时可能导致认知隧道效应，影响安全关键场景中的SA，特别是在CPR等紧急任务中。

Method: 开发了AR应用提供实时CPR反馈，通过用户研究模拟意外事件，结合眼动追踪和问卷收集SA数据，提出FixGraphPool模型预测SA。

Result: 眼动分析显示高SA与更大的扫视幅度和速度相关，FixGraphPool模型预测SA准确率达83.0%，优于其他方法。

Conclusion: 眼动追踪可用于AR中的SA建模，为设计兼顾安全性和SA的AR系统提供了新思路。

Abstract: Augmented Reality (AR) systems, while enhancing task performance through
real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on
virtual content that compromises situational awareness (SA) in safety-critical
scenarios. This paper investigates SA in AR-guided cardiopulmonary
resuscitation (CPR), where responders must balance effective compressions with
vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR
app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth
and rate) and conducted a user study with simulated unexpected incidents (e.g.,
bleeding) to evaluate SA, in which SA metrics were collected via observation
and questionnaires administered during freeze-probe events. Eye tracking
analysis revealed that higher SA levels were associated with greater saccadic
amplitude and velocity, and with reduced proportion and frequency of fixations
on virtual content. To predict SA, we propose FixGraphPool, a graph neural
network that structures gaze events (fixations, saccades) into spatiotemporal
graphs, effectively capturing dynamic attentional patterns. Our model achieved
83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and
state-of-the-art time-series models by leveraging domain knowledge and
spatial-temporal information encoded in ET data. These findings demonstrate the
potential of eye tracking for SA modeling in AR and highlight its utility in
designing AR systems that ensure user safety and situational awareness.

</details>


### [8] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
*Yue Duan,Taicai Chen,Lei Qi,Yinghuan Shi*

Main category: cs.LG

TL;DR: USP框架通过分而治之策略同时优化半监督持续学习中的学习可塑性、无标签学习和记忆稳定性，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 解决半监督持续学习中无标签学习、记忆稳定性和学习可塑性的协同优化问题。

Method: 采用分而治之框架USP，包括特征空间保留策略（FSR）、分而治之伪标签方法（DCP）和类均值锚定无标签蒸馏（CUD）。

Result: USP在最终准确率上比现有方法提升高达5.94%。

Conclusion: USP有效协同优化了半监督持续学习中的关键挑战，性能显著提升。

Abstract: Semi-supervised continual learning (SSCL) seeks to leverage both labeled and
unlabeled data in a sequential learning setup, aiming to reduce annotation
costs while managing continual data arrival. SSCL introduces complex
challenges, including ensuring effective unlabeled learning (UL), while
balancing memory stability (MS) and learning plasticity (LP). Previous SSCL
efforts have typically focused on isolated aspects of the three, while this
work presents USP, a divide-and-conquer framework designed to synergistically
enhance these three aspects: (1) Feature Space Reservation (FSR) strategy for
LP, which constructs reserved feature locations for future classes by shaping
old classes into an equiangular tight frame; (2) Divide-and-Conquer
Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels
across both high- and low-confidence unlabeled data; and (3)
Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's
outputs to anchor unlabeled data to stable class means for distillation to
prevent forgetting. Comprehensive evaluations show USP outperforms prior SSCL
methods, with gains up to 5.94% in the last accuracy, validating its
effectiveness. The code is available at https://github.com/NJUyued/USP4SSCL.

</details>


### [9] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
*Vincent Jeanselme,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 论文探讨了将竞争风险误分类为截尾数据对生存估计的偏差影响，并量化了这种误差及其对预测性能和算法公平性的影响。


<details>
  <summary>Details</summary>
Motivation: 准确的时间到事件预测对决策至关重要，但竞争风险常被误处理为截尾数据，导致生存估计偏差和加剧不公平。

Method: 开发了一个框架，量化将竞争风险误分类为截尾数据导致的误差，并分析其对预测性能和公平性的影响。

Result: 研究发现，忽视竞争风险会显著高估风险并加剧群体间的不公平，尤其是在高风险个体中。

Conclusion: 生存模型必须考虑竞争风险以提高准确性、减少评估偏差，并更好地支持决策。

Abstract: Accurate time-to-event prediction is integral to decision-making, informing
medical guidelines, hiring decisions, and resource allocation. Survival
analysis, the quantitative framework used to model time-to-event data, accounts
for patients who do not experience the event of interest during the study
period, known as censored patients. However, many patients experience events
that prevent the observation of the outcome of interest. These competing risks
are often treated as censoring, a practice frequently overlooked due to a
limited understanding of its consequences. Our work theoretically demonstrates
why treating competing risks as censoring introduces substantial bias in
survival estimates, leading to systematic overestimation of risk and,
critically, amplifying disparities. First, we formalize the problem of
misclassifying competing risks as censoring and quantify the resulting error in
survival estimates. Specifically, we develop a framework to estimate this error
and demonstrate the associated implications for predictive performance and
algorithmic fairness. Furthermore, we examine how differing risk profiles
across demographic groups lead to group-specific errors, potentially
exacerbating existing disparities. Our findings, supported by an empirical
analysis of cardiovascular management, demonstrate that ignoring competing
risks disproportionately impacts the individuals most at risk of these events,
potentially accentuating inequity. By quantifying the error and highlighting
the fairness implications of the common practice of considering competing risks
as censoring, our work provides a critical insight into the development of
survival models: practitioners must account for competing risks to improve
accuracy, reduce disparities in risk assessment, and better inform downstream
decisions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以避免灾难性故障并优化运行效率，传统方法仅能检测异常，无法提供具体维护建议。

Method: 系统将轴承振动数据（BPFO、BPFI、BSF、FTF频率）转化为自然语言供LLM处理，结合多代理组件分析维护手册和网络搜索，生成结构化维护建议。

Result: 实验验证表明，系统能有效检测异常并提供上下文相关的维护指导，成功填补了状态监测与可操作维护计划之间的空白。

Conclusion: 该研究推动了LLM在工业维护中的应用，为跨机械组件和工业领域的预测性维护提供了可扩展的框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [11] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 论文提出了一种基于异构图神经网络的模型，用于修复流程挖掘中事件日志的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的事件日志常因数据采集问题导致信息缺失，传统方法依赖流程模型或机器学习，但效果有限。

Method: 开发了一种异构图神经网络模型，能够处理不完整事件并修复缺失属性。

Result: 在两个合成日志和四个真实日志上评估，模型在修复所有事件属性方面表现优异。

Conclusion: 异构图神经网络为流程挖掘中的日志修复提供了更高效和全面的解决方案。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [12] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: LLMs正在改变有机合成化学的方式，通过结合其他技术加速发现周期，但仍存在数据偏见和安全问题。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何从理论工具发展为实际实验室助手，以推动更快、更绿色的化学研究。

Method: 结合图神经网络、量子计算和实时光谱技术，优化LLMs在合成化学中的应用。

Result: LLMs能够提出合成路线、预测反应结果并指导实验机器人，但需解决数据偏见和安全性问题。

Conclusion: 通过开放基准和可解释界面，LLMs有望实现快速、可靠且包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出了一种基于视觉语言聚类的框架，用于更全面地评估视觉活动识别系统，解决了动词语义和图像解释的模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 标准精确匹配评估无法捕捉动词语义和图像解释的模糊性，导致模型性能评估不完整。

Method: 提出视觉语言聚类框架，构建动词意义簇，用于评估活动识别模型。

Result: 在imSitu数据集中，每张图像平均映射到2.8个意义簇，簇基评估更符合人类判断。

Conclusion: 簇基评估方法能更全面地反映模型性能，优于标准评估方法。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [14] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 提出了一种多阶段大语言模型框架，用于从非结构化文本中提取社会健康决定因素（SDoH），提升自杀事件的早期干预能力。


<details>
  <summary>Details</summary>
Motivation: 解决SDoH因素分布不均、关键压力源分析困难及模型可解释性不足的挑战。

Method: 采用多阶段大语言模型框架，对比BioBERT、GPT-3.5-turbo和DeepSeek-R1，并通过用户研究评估解释效果。

Result: 框架在SDoH提取和相关上下文检索任务中表现更优，且小模型微调可降低成本。多阶段设计提升了可解释性。

Conclusion: 该方法提高了从非结构化文本中提取自杀相关SDoH的准确性和透明度，有助于早期风险识别和预防策略。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [15] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: 论文提出CGRS方法，通过动态抑制高置信度时的反思行为，减少LRLMs的冗余推理步骤，降低token使用和推理成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: LRLMs的复杂反思行为可能导致过度思考问题，增加token使用和推理成本，降低实用性。

Method: 提出CGRS方法，动态抑制高置信度时的反思触发词生成，无需重新训练或修改架构。

Result: 在四个基准测试中，CGRS平均减少18.5%至41.9%的token使用，同时保持准确性。

Conclusion: CGRS在多种模型和规模下均有效，实现了推理效率与性能的最优平衡。

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [16] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: 论文提出了一种名为LAG的新方法，通过逻辑分解和依赖感知推理增强语言模型在知识密集型任务中的表现，显著减少了幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型任务中存在幻觉问题，现有检索增强生成方法在复杂推理场景中表现不足。

Method: LAG将复杂问题分解为原子子问题，按逻辑依赖顺序解决，并引入逻辑终止机制防止错误传播。

Result: 在四个基准数据集上的实验表明，LAG显著提升了推理鲁棒性，减少了幻觉，并更贴近人类认知。

Conclusion: LAG为现有RAG系统提供了一种基于逻辑的替代方案，有效提升了语言模型的问题解决能力。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [17] [On the causality between affective impact and coordinated human-robot reactions](https://arxiv.org/abs/2508.04834)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 研究机器人主动分享反应对人类感知其情感影响的效果，发现共享事件反应和特定延迟时间显著影响感知。


<details>
  <summary>Details</summary>
Motivation: 改善机器人在社交环境中的功能，探讨机器人反应对人类感知的影响。

Method: 设计两组实验：一组隔离反应元素，另一组测试不同延迟时间对物理互动的影响。

Result: 共享事件反应显著提升感知情感影响；物理互动中，接近人类的反应时间（200ms）效果最佳。

Conclusion: 200ms延迟对小型非人形机器人最有效；100ms延迟能最大化人类对机器人影响的感知。

Abstract: In an effort to improve how robots function in social contexts, this paper
investigates if a robot that actively shares a reaction to an event with a
human alters how the human perceives the robot's affective impact. To verify
this, we created two different test setups. One to highlight and isolate the
reaction element of affective robot expressions, and one to investigate the
effects of applying specific timing delays to a robot reacting to a physical
encounter with a human. The first test was conducted with two different groups
(n=84) of human observers, a test group and a control group both interacting
with the robot. The second test was performed with 110 participants using
increasingly longer reaction delays for the robot with every ten participants.
The results show a statistically significant change (p$<$.05) in perceived
affective impact for the robots when they react to an event shared with a human
observer rather than reacting at random. The result also shows for shared
physical interaction, the near-human reaction times from the robot are most
appropriate for the scenario. The paper concludes that a delay time around
200ms may render the biggest impact on human observers for small-sized
non-humanoid robots. It further concludes that a slightly shorter reaction time
around 100ms is most effective when the goal is to make the human observers
feel they made the biggest impact on the robot.

</details>
