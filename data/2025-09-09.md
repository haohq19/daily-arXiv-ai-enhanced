<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory](https://arxiv.org/abs/2509.05337)
*Younggeol Cho,Gokhan Solak,Olivia Nocentini,Marta Lorenzini,Andrea Fortuna,Arash Ajoudani*

Main category: cs.CV

TL;DR: 提出了一种结合动态图神经网络和LSTM的混合模型，用于预测性跌倒检测，通过解耦运动预测和步态分类任务，实现了高精度的跌倒预警。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在跌倒检测，但在跌倒发生前的预测以及稳定状态与即将跌倒之间的瞬态状态分析方面仍未被探索，这对于辅助机器人系统至关重要。

Method: 使用从视频序列中提取的实时骨骼特征作为输入，采用DGNN作为分类器区分稳定、瞬态和跌倒三种步态状态，LSTM网络预测后续时间步的人类运动，实现早期跌倒检测。

Result: 在OUMVLP-Pose和URFD数据集上训练验证，相比仅使用DGNN的模型和文献中的模型，在预测误差和识别准确率方面表现出优越性能。

Conclusion: 解耦预测和分类相比使用单一DGNN解决统一问题能提高性能，同时该方法允许监测瞬态状态，为高级辅助系统功能增强提供有价值见解。

Abstract: Detecting and preventing falls in humans is a critical component of assistive
robotic systems. While significant progress has been made in detecting falls,
the prediction of falls before they happen, and analysis of the transient state
between stability and an impending fall remain unexplored. In this paper, we
propose a anticipatory fall detection method that utilizes a hybrid model
combining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory
(LSTM) networks that decoupled the motion prediction and gait classification
tasks to anticipate falls with high accuracy. Our approach employs real-time
skeletal features extracted from video sequences as input for the proposed
model. The DGNN acts as a classifier, distinguishing between three gait states:
stable, transient, and fall. The LSTM-based network then predicts human
movement in subsequent time steps, enabling early detection of falls. The
proposed model was trained and validated using the OUMVLP-Pose and URFD
datasets, demonstrating superior performance in terms of prediction error and
recognition accuracy compared to models relying solely on DGNN and models from
literature. The results indicate that decoupling prediction and classification
improves performance compared to addressing the unified problem using only the
DGNN. Furthermore, our method allows for the monitoring of the transient state,
offering valuable insights that could enhance the functionality of advanced
assistance systems.

</details>


### [2] [Handling imbalance and few-sample size in ML based Onion disease classification](https://arxiv.org/abs/2509.05341)
*Abhijeet Manoj Pal,Rajbabu Velmurugan*

Main category: cs.CV

TL;DR: 基于深度学习的多类别洋葱疾虫分类模型，统合注意力机制和数据增帽，在实际田间图像数据集上达到96.90%的总体准确率和0.96 F1分数


<details>
  <summary>Details</summary>
Motivation: 当前疾虫分类方法主要集中于二元分类，导致实际应用受限，特别是在需要准确识别具体疾虫类型的场景中

Method: 增强预训练卷积神经网络(CNN)模型，集成注意力模块，使用综合数据增帽流程来缓解类别不平衡问题

Result: 在实际田间图像数据集上达到96.90%的总体准确率和0.96 F1分数，效果优于其他使用同样数据集的方法

Conclusion: 该模型能够有效地进行洋葱疾虫的多类别分类，为精准农业提供了一种实用的解决方案

Abstract: Accurate classification of pests and diseases plays a vital role in precision
agriculture, enabling efficient identification, targeted interventions, and
preventing their further spread. However, current methods primarily focus on
binary classification, which limits their practical applications, especially in
scenarios where accurately identifying the specific type of disease or pest is
essential. We propose a robust deep learning based model for multi-class
classification of onion crop diseases and pests. We enhance a pre-trained
Convolutional Neural Network (CNN) model by integrating attention based modules
and employing comprehensive data augmentation pipeline to mitigate class
imbalance. We propose a model which gives 96.90% overall accuracy and 0.96 F1
score on real-world field image dataset. This model gives better results than
other approaches using the same datasets.

</details>


### [3] [Augmented Structure Preserving Neural Networks for cell biomechanics](https://arxiv.org/abs/2509.05388)
*Juan Olalla-Pombo,Alberto Badías,Miguel Ángel Sanz-Gómez,José María Benítez,Francisco Javier Montáns*

Main category: cs.CV

TL;DR: 提出了一种结合结构保持神经网络和人工神经网络的新方法，用于预测细胞迁移轨迹和有丝分裂事件，在模拟和真实细胞迁移案例中表现出高精度。


<details>
  <summary>Details</summary>
Motivation: 细胞生物力学涉及从胚胎发生到肿瘤生长等众多重要生命过程，但细胞间相互作用及其对集体决策的影响仍不清楚，需要新的研究方法来理解这些复杂现象。

Method: 结合结构保持神经网络（研究细胞运动作为纯机械系统）和人工神经网络（考虑通过计算机视觉技术从实验中直接推导的环境因素），并开发了基于神经网络架构的有丝分裂事件预测模型。

Result: 新模型在模拟和真实细胞迁移案例中测试，通过roll-out策略预测完整细胞轨迹，达到了高精度水平。

Conclusion: 该研究成功开发了一个能够准确预测细胞迁移轨迹和有丝分裂事件的综合模型，为理解细胞集体行为提供了新的计算工具。

Abstract: Cell biomechanics involve a great number of complex phenomena that are
fundamental to the evolution of life itself and other associated processes,
ranging from the very early stages of embryo-genesis to the maintenance of
damaged structures or the growth of tumors. Given the importance of such
phenomena, increasing research has been dedicated to their understanding, but
the many interactions between them and their influence on the decisions of
cells as a collective network or cluster remain unclear. We present a new
approach that combines Structure Preserving Neural Networks, which study cell
movements as a purely mechanical system, with other Machine Learning tools
(Artificial Neural Networks), which allow taking into consideration
environmental factors that can be directly deduced from an experiment with
Computer Vision techniques. This new model, tested on simulated and real cell
migration cases, predicts complete cell trajectories following a roll-out
policy with a high level of accuracy. This work also includes a mitosis event
prediction model based on Neural Networks architectures which makes use of the
same observed features.

</details>


### [4] [RED: Robust Event-Guided Motion Deblurring with Modality-Specific Disentangled Representation](https://arxiv.org/abs/2509.05554)
*Yihong Leng,Siming Zheng,Jinwei Chen,Bo Li,Jiaojiao Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 事件相机在运动去模糊中展现潜力，但现有方法忽视事件流的本质不完整性。本文提出RED网络，通过随机投影策略和解耦注意力机制，在合成和真实数据集上达到独创的准确性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有事件导向去模糊方法忽视了事件流的内在不完整性问题，这种退化影响运动先验知识的完整性和事件导向去模糊的效果。

Method: 提出RED网络：1)稳健性导向的随机投影策略(RPS)，通过随机隐藏事件来培养网络对不完整模式的稳健性；2)解耦的OmniAttention机制，显式建模内部运动、运动间和跨模态相关性；3)两个交互模块增强模糊图像中的运动敏感区域并向事件表征注入语义上下文。

Result: 在合成和真实数据集上的大量实验证明，RED网络在准确性和稳健性方面均达到了独创的性能。

Conclusion: 通过重视事件流的不完整性问题并提出相应的稳健性策略，RED网络有效提升了事件导向去模糊的效果和实际应用价值。

Abstract: Event cameras provide sparse yet temporally high-temporal-resolution motion
information, demonstrating great potential for motion deblurring. Existing
methods focus on cross-modal interaction, overlooking the inherent
incompleteness of event streams, which arises from the trade-off between
sensitivity and noise introduced by the thresholding mechanism of Dynamic
Vision Sensors (DVS). Such degradation compromises the integrity of motion
priors and limits the effectiveness of event-guided deblurring. To tackle these
challenges, we propose a Robust Event-guided Deblurring (RED) network with
modality-specific disentangled representation. First, we introduce a
Robustness-Oriented Perturbation Strategy (RPS) that applies random masking to
events, which exposes RED to incomplete patterns and then foster robustness
against various unknown scenario conditions.Next, a disentangled OmniAttention
is presented to explicitly model intra-motion, inter-motion, and cross-modality
correlations from two inherently distinct but complementary sources: blurry
images and partially disrupted events. Building on these reliable features, two
interactive modules are designed to enhance motion-sensitive areas in blurry
images and inject semantic context into incomplete event representations.
Extensive experiments on synthetic and real-world datasets demonstrate RED
consistently achieves state-of-the-art performance in both accuracy and
robustness.

</details>


### [5] [Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization](https://arxiv.org/abs/2509.05604)
*Jungin Park,Jiyoung Lee,Kwanghoon Sohn*

Main category: cs.CV

TL;DR: VideoGraph：基于语言引导的时空图建模的视频摘要方法，通过将对象和帧建模为图节点，利用语义关系进行关键帧选择，在多个基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 传统视频摘要方法主要关注帧间的时间建模，但忽略了细粒度视觉实体（如对象）与视频主要内容的关系。语言引导的视频摘要需要全面理解复杂真实世界视频的语义内容

Method: 提出递归时空图网络VideoGraph，将对象和帧分别建模为空间图和时间图的节点，通过图边表示节点间的语义关系。引入语言查询来增强节点表示的语义知识，避免仅基于视觉相似性配置边。采用递归策略优化初始图并正确分类关键帧

Result: 在多个通用和查询聚焦视频摘要基准测试中，在监督和无监督设置下均达到了最先进的性能

Conclusion: VideoGraph通过语言引导的时空图建模有效解决了视频摘要问题，证明了考虑对象语义关系和语言引导的重要性

Abstract: Video summarization aims to select keyframes that are visually diverse and
can represent the whole story of a given video. Previous approaches have
focused on global interlinkability between frames in a video by temporal
modeling. However, fine-grained visual entities, such as objects, are also
highly related to the main content of the video. Moreover, language-guided
video summarization, which has recently been studied, requires a comprehensive
linguistic understanding of complex real-world videos. To consider how all the
objects are semantically related to each other, this paper regards video
summarization as a language-guided spatiotemporal graph modeling problem. We
present recursive spatiotemporal graph networks, called VideoGraph, which
formulate the objects and frames as nodes of the spatial and temporal graphs,
respectively. The nodes in each graph are connected and aggregated with graph
edges, representing the semantic relationships between the nodes. To prevent
the edges from being configured with visual similarity, we incorporate language
queries derived from the video into the graph node representations, enabling
them to contain semantic knowledge. In addition, we adopt a recursive strategy
to refine initial graphs and correctly classify each frame node as a keyframe.
In our experiments, VideoGraph achieves state-of-the-art performance on several
benchmarks for generic and query-focused video summarization in both supervised
and unsupervised manners. The code is available at
https://github.com/park-jungin/videograph.

</details>


### [6] [Depth-Aware Super-Resolution via Distance-Adaptive Variational Formulation](https://arxiv.org/abs/2509.05746)
*Tianhao Guo,Bingjie Lu,Feng Wang,Zhengyang Lu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于水动力学框架的距离自适应超分辨率方法，通过深度条件卷积内核和学习的距离适应性正则化项来处理实际影像中的空间变化降级模型，在多个标准数据集上达到了独创性能。


<details>
  <summary>Details</summary>
Motivation: 传统的单影像超分辨率方法假设空间不变的降级模型，但真实影像系统存在复杂的距离依赖效应，如大气散射、景深变化和透视扭曲等，需要空间适应性重建策略。

Method: 提出一种严格的变分框架，将超分辨率形式化为空间变化的逆问题，通过深度条件卷积内核的级联殊余块实现离散梯度流动力学，并包含学习的距离适应性正则化项。

Result: 在5个标准数据集上达到了最先进性能，在KITTI户外场景中在2倍和4倍缩放下分别获得36.89/0.9516和30.54/0.8721的PSNR/SSIM值，超过现有方法0.44dB和0.36dB。

Conclusion: 这项工作建立了第一个理论基础坚实的距离自适应超分辨率框架，在深度变化场景中实现了显著改进，同时在传统标准测试中保持了竞争力。

Abstract: Single image super-resolution traditionally assumes spatially-invariant
degradation models, yet real-world imaging systems exhibit complex
distance-dependent effects including atmospheric scattering, depth-of-field
variations, and perspective distortions. This fundamental limitation
necessitates spatially-adaptive reconstruction strategies that explicitly
incorporate geometric scene understanding for optimal performance. We propose a
rigorous variational framework that characterizes super-resolution as a
spatially-varying inverse problem, formulating the degradation operator as a
pseudodifferential operator with distance-dependent spectral characteristics
that enable theoretical analysis of reconstruction limits across depth ranges.
Our neural architecture implements discrete gradient flow dynamics through
cascaded residual blocks with depth-conditional convolution kernels, ensuring
convergence to stationary points of the theoretical energy functional while
incorporating learned distance-adaptive regularization terms that dynamically
adjust smoothness constraints based on local geometric structure. Spectral
constraints derived from atmospheric scattering theory prevent bandwidth
violations and noise amplification in far-field regions, while adaptive kernel
generation networks learn continuous mappings from depth to reconstruction
filters. Comprehensive evaluation across five benchmark datasets demonstrates
state-of-the-art performance, achieving 36.89/0.9516 and 30.54/0.8721 PSNR/SSIM
at 2 and 4 scales on KITTI outdoor scenes, outperforming existing methods by
0.44dB and 0.36dB respectively. This work establishes the first
theoretically-grounded distance-adaptive super-resolution framework and
demonstrates significant improvements on depth-variant scenarios while
maintaining competitive performance across traditional benchmarks.

</details>


### [7] [Event Spectroscopy: Event-based Multispectral and Depth Sensing using Structured Light](https://arxiv.org/abs/2509.06741)
*Christian Geckeler,Niklas Neugebauer,Manasi Muglikar,Davide Scaramuzza,Stefano Mintchev*

Main category: cs.CV

TL;DR: 一种新型事件光谱系统，通过单个传感器同时实现高分辨率深度重建和多光谱成像，在森林环境中显著提升无人机感知能力


<details>
  <summary>Details</summary>
Motivation: 传统感知方法在森林环境中存在延迟、深度分辨率低、光照依赖性强等问题，无法满足无人机在密林中安全导航和精确数据采集的需求

Method: 设计了事件光谱系统，利用结构光进行深度重建，通过调制投射结构光的波长来获取650-850nm范围内的光谱信息，开发了仅支持RGB的笼版系统

Result: 与商业深度传感器相比RMSE提升60%，光谱准确性与参考光谱仪和商业多光谱相机相当，在马索拉雨林获得真实数据，结合深度和光谱数据识别叶子和树枝的准确性比仅使用颜色的方法提升30%

Conclusion: 该系统在实验室和真实雨林环境中都表现出艰固的深度估计、RGB重建和材料区分能力，为轻量化、集成化的无人机感知和数据采集在复杂自然环境中的应用探索了新路径

Abstract: Uncrewed aerial vehicles (UAVs) are increasingly deployed in forest
environments for tasks such as environmental monitoring and search and rescue,
which require safe navigation through dense foliage and precise data
collection. Traditional sensing approaches, including passive multispectral and
RGB imaging, suffer from latency, poor depth resolution, and strong dependence
on ambient light - especially under forest canopies. In this work, we present a
novel event spectroscopy system that simultaneously enables high-resolution,
low-latency depth reconstruction and multispectral imaging using a single
sensor. Depth is reconstructed using structured light, and by modulating the
wavelength of the projected structured light, our system captures spectral
information in controlled bands between 650 nm and 850 nm. We demonstrate up to
$60\%$ improvement in RMSE over commercial depth sensors and validate the
spectral accuracy against a reference spectrometer and commercial multispectral
cameras, demonstrating comparable performance. A portable version limited to
RGB (3 wavelengths) is used to collect real-world depth and spectral data from
a Masoala Rainforest. We demonstrate the use of this prototype for color image
reconstruction and material differentiation between leaves and branches using
spectral and depth data. Our results show that adding depth (available at no
extra effort with our setup) to material differentiation improves the accuracy
by over $30\%$ compared to color-only method. Our system, tested in both lab
and real-world rainforest environments, shows strong performance in depth
estimation, RGB reconstruction, and material differentiation - paving the way
for lightweight, integrated, and robust UAV perception and data collection in
complex natural environments.

</details>


### [8] [A Fine-Grained Attention and Geometric Correspondence Model for Musculoskeletal Risk Classification in Athletes Using Multimodal Visual and Skeletal Features](https://arxiv.org/abs/2509.05913)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Tamanna Shermin,Md Rafiqul Islam,Mukhtar Hussain,Sami Azam*

Main category: cs.CV

TL;DR: ViSK-GAT是一种新颖的多模态深度学习框架，结合视觉和骨骼坐标特征，用于肌肉骨骼风险分类，在复杂环境中实现了93%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的肌肉骨骼风险评估方法大多设计用于受控环境，依赖单一数据类型，无法在复杂环境中可靠评估风险。

Method: 提出ViSK-GAT框架，结合残差块和轻量级Transformer块，包含细粒度注意力模块(FGAM)和多模态几何对应模块(MGCM)，使用视觉和骨骼坐标多模态数据进行训练。

Result: 验证准确率93.55%，测试准确率93.89%，精确度93.86%，F1分数93.85%，均优于9种流行的迁移学习骨干网络。

Conclusion: ViSK-GAT模型推进了人工智能在肌肉骨骼风险分类中的应用，能够实现有效的早期干预。

Abstract: Musculoskeletal disorders pose significant risks to athletes, and assessing
risk early is important for prevention. However, most existing methods are
designed for controlled settings and fail to reliably assess risk in complex
environments due to their reliance on a single type of data. This research
proposes ViSK-GAT (Visual-Skeletal Geometric Attention Transformer), a novel
multimodal deep learning framework designed to classify musculoskeletal risk
using visual and skeletal coordinate-based features. In addition, a custom
multimodal dataset is constructed by combining visual data and skeletal
coordinates for risk assessment. Each sample is labeled into eight risk
categories based on the Rapid Entire Body Assessment system. ViSK-GAT combines
a Residual Block with a Lightweight Transformer Block to learn spatial and
temporal dependencies jointly. It incorporates two novel modules: the
Fine-Grained Attention Module (FGAM), which enables precise inter-modal feature
refinement through cross-attention between visual and skeletal inputs, and the
Multimodal Geometric Correspondence Module (MGCM), which enhances cross-modal
coherence by aligning image features with coordinate-based representations.
ViSK-GAT achieved strong performance with validation and test accuracies of
93.55\% and 93.89\%, respectively; a precision of 93.86\%; an F1 score of
93.85\%; and Cohen's Kappa and Matthews Correlation Coefficient of 93\%. The
regression results also indicated a low Root Mean Square Error of the predicted
probability distribution of 0.1205 and a corresponding Mean Absolute Error of
0.0156. Compared to nine popular transfer learning backbones, ViSK-GAT
consistently outperformed previous methods. The ViSK-GAT model advances
artificial intelligence implementation and application, transforming
musculoskeletal risk classification and enabling impactful early interventions
in sports.

</details>


### [9] [AttriPrompt: Dynamic Prompt Composition Learning for CLIP](https://arxiv.org/abs/2509.05949)
*Qiqi Zhan,Shiwei Li,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: AttriPrompt是一个新颖的深度提示学习框架，通过利用CLIP视觉编码器的中间层特征来增强文本语义表示，解决了现有深度文本提示方法的两个关键限制：过度依赖对比学习目标和静态提示问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度文本提示方法存在两个关键问题：1）过度依赖对比学习目标，只关注高层语义对齐而忽略细粒度特征优化；2）所有输入类别使用静态提示，缺乏内容感知适应能力。

Method: 提出AttriPrompt框架，包含属性检索模块（聚类视觉特征并检索语义相似的提示）、双流对比学习（实现细粒度对齐）和自正则化机制（防止过拟合）。通过将检索到的提示连接到文本编码器的每一层输入。

Result: 在三个基准测试上的广泛实验表明，AttriPrompt优于最先进的方法，在base-to-novel设置中实现了高达7.37%的改进，在跨域知识转移方面表现出色。

Conclusion: 该方法使视觉语言预训练模型成为现实世界应用中更可行的解决方案，通过分层视觉信息和细粒度对齐显著提升了模型性能。

Abstract: The evolution of prompt learning methodologies has driven exploration of
deeper prompt designs to enhance model performance. However, current deep text
prompting approaches suffer from two critical limitations: Over-reliance on
constrastive learning objectives that prioritize high-level semantic alignment,
neglecting fine-grained feature optimization; Static prompts across all input
categories, preventing content-aware adaptation. To address these limitations,
we propose AttriPrompt-a novel framework that enhances and refines textual
semantic representations by leveraging the intermediate-layer features of
CLIP's vision encoder. We designed an Attribute Retrieval module that first
clusters visual features from each layer. The aggregated visual features
retrieve semantically similar prompts from a prompt pool, which are then
concatenated to the input of every layer in the text encoder. Leveraging
hierarchical visual information embedded in prompted text features, we
introduce Dual-stream Contrastive Learning to realize fine-grained alignment.
Furthermore, we introduce a Self-Regularization mechanism by applying explicit
regularization constraints between the prompted and non-prompted text features
to prevent overfitting on limited training data. Extensive experiments across
three benchmarks demonstrate AttriPrompt's superiority over state-of-the-art
methods, achieving up to 7.37\% improvement in the base-to-novel setting. The
observed strength of our method in cross-domain knowledge transfer positions
vision-language pre-trained models as more viable solutions for real-world
implementation.

</details>


### [10] [Raw2Event: Converting Raw Frame Camera into Event Camera](https://arxiv.org/abs/2509.06767)
*Zijie Ning,Enmin Lin,Sudarshan R. Iyengar,Patrick Vandewalle*

Main category: cs.CV

TL;DR: Raw2Event是一个硬件-软件系统，能够从低成本原始帧相机实时生成事件流，提供比RGB帧转换器更高的动态范围、分辨率和保真度输出。


<details>
  <summary>Details</summary>
Motivation: 事件相机虽然具有高时间分辨率、低延迟和高动态范围等优势，但高成本、有限分辨率以及缺乏自动对焦等功能限制了其广泛应用，特别是在早期开发和原型设计阶段。

Method: 通过直接访问原始Bayer数据并绕过传统图像信号处理器(ISP)，基于DVS-Voltmeter模型构建可配置的仿真框架，并设计支持原始数据、RGB和事件流同步记录的数据采集管道。

Result: 实验结果表明Raw2Event能够生成与真实事件相机非常相似的事件流，同时受益于更高分辨率和自动对焦能力，系统还支持用户直观的参数调优，并可在树莓派上实时运行。

Conclusion: 该系统提供了一个可扩展且经济高效的事件视觉研究和早期系统开发解决方案，代码已在线开源。

Abstract: Event cameras offer unique advantages such as high temporal resolution, low
latency, and high dynamic range, making them more and more popular for vision
tasks under challenging light conditions. However, their high cost, limited
resolution, and lack of features such as autofocus hinder their broad adoption,
particularly for early-stage development and prototyping. In this work, we
present Raw2Event, a complete hardware-software system that enables real-time
event generation from low-cost raw frame-based cameras. By leveraging direct
access to raw Bayer data and bypassing traditional image signal processors
(ISP), our system is able to utilize the full potential of camera hardware,
delivering higher dynamic range, higher resolution, and more faithful output
than RGB-based frame-to-event converters.
  Built upon the DVS-Voltmeter model, Raw2Event features a configurable
simulation framework optimized for deployment on embedded platforms. We further
design a data acquisition pipeline that supports synchronized recording of raw,
RGB, and event streams, facilitating downstream evaluation and dataset
creation. Experimental results show that Raw2Event can generate event streams
closely resembling those from real event cameras, while benefiting from higher
resolution and autofocus capabilities. The system also supports user-intuitive
parameter tuning, enabling flexible adaptation to various application
requirements. Finally, we deploy the system on a Raspberry Pi for real-time
operation, providing a scalable and cost-effective solution for event-based
vision research and early-stage system development.
  The codes are available online:
https://anonymous.4open.science/r/raw2event-BFF2/README.md.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [Reinforcement Learning with Anticipation: A Hierarchical Approach for Long-Horizon Tasks](https://arxiv.org/abs/2509.05545)
*Yang Yu*

Main category: cs.LG

TL;DR: RLA（强化学习与预期）是一个分层强化学习框架，通过低层目标导向策略和高层预期模型协同工作，解决长时域目标导向任务中的规划问题，具有理论保证和收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决长时域目标导向任务中分层强化学习的不稳定性和缺乏理论保证的问题，提供一种原则性的可扩展框架。

Method: 学习两个协同模型：低层目标导向策略（学习到达指定子目标）和高层预期模型（作为规划器，提出到达最终目标的最优路径中的中间子目标），通过价值几何一致性原则训练预期模型。

Result: RLA在各种条件下能够逼近全局最优策略，为长时域目标导向任务中的分层规划和执行提供了原则性和收敛性的方法。

Conclusion: RLA框架通过预期模型和价值几何一致性原则，有效解决了分层强化学习中的不稳定性和理论保证缺失问题，为长时域目标导向任务提供了可靠的解决方案。

Abstract: Solving long-horizon goal-conditioned tasks remains a significant challenge
in reinforcement learning (RL). Hierarchical reinforcement learning (HRL)
addresses this by decomposing tasks into more manageable sub-tasks, but the
automatic discovery of the hierarchy and the joint training of multi-level
policies often suffer from instability and can lack theoretical guarantees. In
this paper, we introduce Reinforcement Learning with Anticipation (RLA), a
principled and potentially scalable framework designed to address these
limitations. The RLA agent learns two synergistic models: a low-level,
goal-conditioned policy that learns to reach specified subgoals, and a
high-level anticipation model that functions as a planner, proposing
intermediate subgoals on the optimal path to a final goal. The key feature of
RLA is the training of the anticipation model, which is guided by a principle
of value geometric consistency, regularized to prevent degenerate solutions. We
present proofs that RLA approaches the globally optimal policy under various
conditions, establishing a principled and convergent method for hierarchical
planning and execution in long-horizon goal-conditioned tasks.

</details>


### [12] [Ensemble of Precision-Recall Curve (PRC) Classification Trees with Autoencoders](https://arxiv.org/abs/2509.05766)
*Jiaju Miao,Wei Zhu*

Main category: cs.LG

TL;DR: 提出了一种结合PRC随机森林和自编码器的混合框架，用于解决异常检测中的类别不平衡和高维问题，在多个基准数据集上表现出优越性能


<details>
  <summary>Details</summary>
Motivation: 异常检测在网络安全、入侵检测和欺诈预防等关键应用中至关重要，但面临极端类别不平衡和维度诅咒两大障碍

Method: 将之前提出的PRC随机森林(PRC-RF)与自编码器结合，自编码器学习紧凑的潜在表示来处理高维问题，PRC-RF处理类别不平衡

Result: 在多个基准数据集上的广泛实验表明，Autoencoder-PRC-RF模型相比先前方法在准确性、可扩展性和可解释性方面都更优越

Conclusion: 该混合框架在高风险异常检测任务中展现出巨大潜力，能够同时有效应对类别不平衡和高维挑战

Abstract: Anomaly detection underpins critical applications from network security and
intrusion detection to fraud prevention, where recognizing aberrant patterns
rapidly is indispensable. Progress in this area is routinely impeded by two
obstacles: extreme class imbalance and the curse of dimensionality. To combat
the former, we previously introduced Precision-Recall Curve (PRC)
classification trees and their ensemble extension, the PRC Random Forest
(PRC-RF). Building on that foundation, we now propose a hybrid framework that
integrates PRC-RF with autoencoders, unsupervised machine learning methods that
learn compact latent representations, to confront both challenges
simultaneously. Extensive experiments across diverse benchmark datasets
demonstrate that the resulting Autoencoder-PRC-RF model achieves superior
accuracy, scalability, and interpretability relative to prior methods,
affirming its potential for high-stakes anomaly-detection tasks.

</details>


### [13] [DCV-ROOD Evaluation Framework: Dual Cross-Validation for Robust Out-of-Distribution Detection](https://arxiv.org/abs/2509.05778)
*Arantxa Urrea-Castaño,Nicolás Segura-Kunsagi,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.LG

TL;DR: 本文提出了一种双重交叉验证框架DCV-ROOD，用于更稳健地评估分布外检测模型的性能，通过分别处理分布内和分布外数据的特性，并考虑类别层次结构来获得公平的数据分割。


<details>
  <summary>Details</summary>
Motivation: 分布外(OOD)检测对于提高AI系统稳健性至关重要，但现有评估方法在处理ID和OOD数据特性差异时存在不足。需要一种更稳健的评估框架来准确估计OOD检测模型的真实性能。

Method: 提出双重交叉验证(DCV-ROOD)框架：1)分布内(ID)数据采用标准分割方式；2)分布外(OOD)数据按类别分组分割；3)在类别层次数据中，考虑整个类别层次结构来获得公平的ID-OOD分割。

Result: 通过对多个独立OOD检测方法的实验验证，证明该评估框架能够快速收敛到模型的真实性能估计值。

Conclusion: DCV-ROOD框架为OOD检测模型提供了一种稳健、可靠的评估方法，能够更准确地估计模型在实际应用中的性能表现，为该领域的研究提供了有效的评测工具。

Abstract: Out-of-distribution (OOD) detection plays a key role in enhancing the
robustness of artificial intelligence systems by identifying inputs that differ
significantly from the training distribution, thereby preventing unreliable
predictions and enabling appropriate fallback mechanisms. Developing reliable
OOD detection methods is a significant challenge, and rigorous evaluation of
these techniques is essential for ensuring their effectiveness, as it allows
researchers to assess their performance under diverse conditions and to
identify potential limitations or failure modes. Cross-validation (CV) has
proven to be a highly effective tool for providing a reasonable estimate of the
performance of a learning algorithm. Although OOD scenarios exhibit particular
characteristics, an appropriate adaptation of CV can lead to a suitable
evaluation framework for this setting. This work proposes a dual CV framework
for robust evaluation of OOD detection models, aimed at improving the
reliability of their assessment. The proposed evaluation framework aims to
effectively integrate in-distribution (ID) and OOD data while accounting for
their differing characteristics. To achieve this, ID data are partitioned using
a conventional approach, whereas OOD data are divided by grouping samples based
on their classes. Furthermore, we analyze the context of data with class
hierarchy to propose a data splitting that considers the entire class hierarchy
to obtain fair ID-OOD partitions to apply the proposed evaluation framework.
This framework is called Dual Cross-Validation for Robust Out-of-Distribution
Detection (DCV-ROOD). To test the validity of the evaluation framework, we
selected a set of state-of-the-art OOD detection methods, both with and without
outlier exposure. The results show that the method achieves very fast
convergence to the true performance.

</details>


### [14] [time2time: Causal Intervention in Hidden States to Simulate Rare Events in Time Series Foundation Models](https://arxiv.org/abs/2509.05801)
*Debdeep Sanyal,Aaryan Nagpal,Dhruv Kumar,Murari Mandal,Saurabh Deshpande*

Main category: cs.LG

TL;DR: 研究发现大型时间序列Transformer模型内部编码了语义概念，通过激活移植技术可以因果干预模型预测，实现市场状态的语义控制


<details>
  <summary>Details</summary>
Motivation: 探究基于Transformer的基础模型是否真正内化了语义概念（如市场状态），而不仅仅是曲线拟合，以及能否利用其内部表示来模拟罕见的高风险事件（如市场崩盘）

Method: 引入激活移植技术，通过在正向传播过程中将一个事件（如历史崩盘）的统计矩强加到另一个事件（如平静期）上来操纵隐藏状态

Result: 注入崩盘语义会诱导下跌预测，注入平静语义则抑制崩盘并恢复稳定性；模型编码了事件严重程度的梯度概念，潜在向量范数与系统性冲击幅度直接相关

Conclusion: 大型时间序列Transformer具有可操控的、基于语义的表征能力，存在一个控制模型预测的潜在概念空间，实现了从后验归因到直接因果干预的转变

Abstract: While transformer-based foundation models excel at forecasting routine
patterns, two questions remain: do they internalize semantic concepts such as
market regimes, or merely fit curves? And can their internal representations be
leveraged to simulate rare, high-stakes events such as market crashes? To
investigate this, we introduce activation transplantation, a causal
intervention that manipulates hidden states by imposing the statistical moments
of one event (e.g., a historical crash) onto another (e.g., a calm period)
during the forward pass. This procedure deterministically steers forecasts:
injecting crash semantics induces downturn predictions, while injecting calm
semantics suppresses crashes and restores stability. Beyond binary control, we
find that models encode a graded notion of event severity, with the latent
vector norm directly correlating with the magnitude of systemic shocks.
Validated across two architecturally distinct TSFMs, Toto (decoder only) and
Chronos (encoder-decoder), our results demonstrate that steerable, semantically
grounded representations are a robust property of large time series
transformers. Our findings provide evidence for a latent concept space that
governs model predictions, shifting interpretability from post-hoc attribution
to direct causal intervention, and enabling semantic "what-if" analysis for
strategic stress-testing.

</details>


### [15] [Data-Driven Stochastic Modeling Using Autoregressive Sequence Models: Translating Event Tables to Queueing Dynamics](https://arxiv.org/abs/2509.05839)
*Daksh Mittal,Shunri Zheng,Jing Dong,Hongseok Namkoong*

Main category: cs.LG

TL;DR: 基于自回序列模型的队列网络建模框架，通过Transformer学习事件流数据的条件分布，实现了队列网络模型的自动化构建和高保真模拟。


<details>
  <summary>Details</summary>
Motivation: 传统队列网络模型需要大量人工努力和领域专业知识，为了使此建模方法更具可扩展性和易访问性。

Method: 使用自回序列模型训练于事件流数据，学习事件类型和事件时间的条件分布，重构建模任务为序列分布学习问题，采用Transformer结构进行参数化。

Result: 在多样化队列网络事件表上验证框架有效性，展示了其在模拟、不确定性量化和反事实评估方面的应用价值。

Conclusion: 利用人工智能进步和数据可用性的提升，该框架向更自动化的数据驱动建模流程进行了插译，支持队列网络模型在服务领域的更广泛采用。

Abstract: While queueing network models are powerful tools for analyzing service
systems, they traditionally require substantial human effort and domain
expertise to construct. To make this modeling approach more scalable and
accessible, we propose a data-driven framework for queueing network modeling
and simulation based on autoregressive sequence models trained on event-stream
data. Instead of explicitly specifying arrival processes, service mechanisms,
or routing logic, our approach learns the conditional distributions of event
types and event times, recasting the modeling task as a problem of sequence
distribution learning. We show that Transformer-style architectures can
effectively parameterize these distributions, enabling automated construction
of high-fidelity simulators. As a proof of concept, we validate our framework
on event tables generated from diverse queueing networks, showcasing its
utility in simulation, uncertainty quantification, and counterfactual
evaluation. Leveraging advances in artificial intelligence and the growing
availability of data, our framework takes a step toward more automated,
data-driven modeling pipelines to support broader adoption of queueing network
models across service domains.

</details>


### [16] [Unified Interaction Foundational Model (UIFM) for Predicting Complex User and System Behavior](https://arxiv.org/abs/2509.06025)
*Vignesh Ethiraj,Subhash Talluri*

Main category: cs.LG

TL;DR: 提出了统一交互基础模型(UIFM)，采用复合标记化方法将多属性事件作为语义连贯单元处理，解决了传统模型在序列化事件时丢失关键上下文的问题


<details>
  <summary>Details</summary>
Motivation: 当前基于自然语言的基础模型无法理解电信、电商和金融等领域中结构化交互的整体性质，通过将事件序列化为文本会破坏语义完整性

Method: 采用复合标记化原则，将每个多属性事件视为单个语义连贯单元，学习用户行为的底层"语法"

Result: 该架构不仅更准确，而且代表了创建更适应和智能预测系统的根本性进步

Conclusion: UIFM模型能够感知完整的交互而非断开的数据流，是实现真正行为理解的重要步骤

Abstract: A central goal of artificial intelligence is to build systems that can
understand and predict complex, evolving sequences of events. However, current
foundation models, designed for natural language, fail to grasp the holistic
nature of structured interactions found in domains like telecommunications,
e-commerce and finance. By serializing events into text, they disassemble them
into semantically fragmented parts, losing critical context. In this work, we
introduce the Unified Interaction Foundation Model (UIFM), a foundation model
engineered for genuine behavioral understanding. At its core is the principle
of composite tokenization, where each multi-attribute event is treated as a
single, semantically coherent unit. This allows UIFM to learn the underlying
"grammar" of user behavior, perceiving entire interactions rather than a
disconnected stream of data points. We demonstrate that this architecture is
not just more accurate, but represents a fundamental step towards creating more
adaptable and intelligent predictive systems.

</details>


### [17] [DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT](https://arxiv.org/abs/2509.06483)
*Guanjie Cheng,Boyi Li,Peihan Wu,Feiyi Chen,Xinkui Zhao,Mengying Zhu,Shuiguang Deng*

Main category: cs.LG

TL;DR: DyC-STG是一个用于物联网数据可信度分析的动态因果时空图网络，通过事件驱动的动态图模块和因果推理模块，解决了传统STG模型在静态拓扑和伪相关性问题上的局限性


<details>
  <summary>Details</summary>
Motivation: 物联网传感器产生大量时空数据流，但数据可信度是未解决的关键挑战。传统时空图模型在动态人本环境中存在两个根本局限：静态图拓扑无法捕捉物理事件驱动的动态性，以及容易混淆伪相关性和真实因果关系

Method: 提出DyC-STG框架，包含两个协同贡献：事件驱动的动态图模块实时调整图拓扑以反映物理状态变化，以及因果推理模块通过严格强制执行时间优先原则来提取因果感知表示

Result: 综合实验显示DyC-STG建立了新的最先进水平，比最强基线高出1.4个百分点，F1分数最高达到0.930。同时发布了两个新的真实世界数据集

Conclusion: DyC-STG通过动态图拓扑和因果推理的有效结合，显著提升了物联网时空数据可信度分析的性能，为人本环境中的实时数据可信度验证提供了有效解决方案

Abstract: The wide spreading of Internet of Things (IoT) sensors generates vast
spatio-temporal data streams, but ensuring data credibility is a critical yet
unsolved challenge for applications like smart homes. While spatio-temporal
graph (STG) models are a leading paradigm for such data, they often fall short
in dynamic, human-centric environments due to two fundamental limitations: (1)
their reliance on static graph topologies, which fail to capture physical,
event-driven dynamics, and (2) their tendency to confuse spurious correlations
with true causality, undermining robustness in human-centric environments. To
address these gaps, we propose the Dynamic Causal Spatio-Temporal Graph Network
(DyC-STG), a novel framework designed for real-time data credibility analysis
in IoT. Our framework features two synergistic contributions: an event-driven
dynamic graph module that adapts the graph topology in real-time to reflect
physical state changes, and a causal reasoning module to distill causally-aware
representations by strictly enforcing temporal precedence. To facilitate the
research in this domain we release two new real-world datasets. Comprehensive
experiments show that DyC-STG establishes a new state-of-the-art, outperforming
the strongest baselines by 1.4 percentage points and achieving an F1-Score of
up to 0.930.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents](https://arxiv.org/abs/2509.06269)
*Vishal Raman,Vijai Aravindh R,Abhijith Ragav*

Main category: cs.AI

TL;DR: REMI是一个基于因果模式记忆的多模态生活方式助手架构，通过整合个人因果知识图谱、因果推理引擎和基于模式的规划模块，提供可解释的个性化推荐


<details>
  <summary>Details</summary>
Motivation: 现有的个性化AI助手难以整合复杂的个人数据和因果知识，导致建议过于通用且缺乏解释性

Method: 使用个人因果图谱记录用户生活事件和习惯，进行目标导向的因果遍历（结合外部知识和假设推理），检索可适应的计划模式来生成定制化行动方案，由大语言模型协调各组件

Result: 基于CSM的智能体相比基线LLM智能体能够提供更符合上下文、更贴合用户的推荐

Conclusion: 这项工作展示了在个性化智能体中实现记忆增强和因果推理的新方法，推动了透明可信AI生活方式助手的发展

Abstract: Personalized AI assistants often struggle to incorporate complex personal
data and causal knowledge, leading to generic advice that lacks explanatory
power. We propose REMI, a Causal Schema Memory architecture for a multimodal
lifestyle agent that integrates a personal causal knowledge graph, a causal
reasoning engine, and a schema based planning module. The idea is to deliver
explainable, personalized recommendations in domains like fashion, personal
wellness, and lifestyle planning. Our architecture uses a personal causal graph
of the user's life events and habits, performs goal directed causal traversals
enriched with external knowledge and hypothetical reasoning, and retrieves
adaptable plan schemas to generate tailored action plans. A Large Language
Model orchestrates these components, producing answers with transparent causal
explanations. We outline the CSM system design and introduce new evaluation
metrics for personalization and explainability, including Personalization
Salience Score and Causal Reasoning Accuracy, to rigorously assess its
performance. Results indicate that CSM based agents can provide more context
aware, user aligned recommendations compared to baseline LLM agents. This work
demonstrates a novel approach to memory augmented, causal reasoning in
personalized agents, advancing the development of transparent and trustworthy
AI lifestyle assistants.

</details>


### [19] [A data-driven discretized CS:GO simulation environment to facilitate strategic multi-agent planning research](https://arxiv.org/abs/2509.06355)
*Yunzhe Wang,Volkan Ustun,Chris McGroarty*

Main category: cs.AI

TL;DR: DECOY是一个新颖的多智能体模拟器，通过将3D地形中的战略长期规划抽象为高级离散化模拟，同时保持底层环境保真度，在计算效率和细节真实性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现代复杂多智能体交互的模拟环境需要在计算效率和细节保真度之间取得平衡，传统方法往往难以同时满足这两个需求。

Method: 使用路径点系统简化和离散化连续状态和动作，配合基于真实CS:GO比赛数据训练的神经预测和生成模型来重建事件结果。仅使用移动决策作为战术定位，无需显式建模瞄准和射击等低级机制。

Result: 广泛评估表明，从人类数据生成的DECOY回放与原始游戏中观察到的回放高度匹配。

Conclusion: DECOY提供了一个有价值的工具，可用于推进战略多智能体规划和行为生成的研究，其公开可用的模拟环境为相关领域研究提供了重要支持。

Abstract: Modern simulation environments for complex multi-agent interactions must
balance high-fidelity detail with computational efficiency. We present DECOY, a
novel multi-agent simulator that abstracts strategic, long-horizon planning in
3D terrains into high-level discretized simulation while preserving low-level
environmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a
testbed, our framework accurately simulates gameplay using only movement
decisions as tactical positioning -- without explicitly modeling low-level
mechanics such as aiming and shooting. Central to our approach is a waypoint
system that simplifies and discretizes continuous states and actions, paired
with neural predictive and generative models trained on real CS:GO tournament
data to reconstruct event outcomes. Extensive evaluations show that replays
generated from human data in DECOY closely match those observed in the original
game. Our publicly available simulation environment provides a valuable tool
for advancing research in strategic multi-agent planning and behavior
generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: Llama-GENBA-10B是一个10B参数的三语基础模型，基于Llama 3.1-8B构建，在164B tokens（英语82B、德语82B、巴伐利亚语80M）上持续预训练，解决了英语中心偏见问题，特别针对德语NLP社区并推广低资源巴伐利亚语。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型中的英语中心偏见问题，为德语NLP社区提供支持，并促进低资源语言巴伐利亚语的发展。

Method: 基于Llama 3.1-8B扩展到10B参数，在平衡的多语言语料库上持续预训练，创建统一的分词器，优化架构和语言比例超参数，建立首个标准化三语评估套件。

Result: 模型在三语性能上表现强劲，微调版本在巴伐利亚语上超越Apertus-8B-2509和gemma-2-9b，成为该语言类别最佳模型，同时在英语上优于EuroLLM，德语表现相当。

Conclusion: 该研究为包容性基础模型提供了蓝图，展示了如何有效整合低资源语言，并在Cerebras CS-2上实现了高效的大规模多语言预训练。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [21] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: 本文探讨了在文本到音乐生成模型中应用机器忘印技术来避免使用版权创作内容的初步研究成果。


<details>
  <summary>Details</summary>
Motivation: 人工智能音乐生成系统在创造性行业中快速发展，但存在利用版权创作的风险，引发了道德和法律问题。

Method: 研究将现有的机器忘印技术应用于预训练的文本到音乐基线模型，分析在不损害模型性能的情况下忘印预训练数据集的效果。

Result: 实验结果提供了在音乐生成中应用忘印技术的挑战和见解，为未来研究奠定了基础。

Conclusion: 这项研究为音乐生成模型的机器忘印应用提供了初步分析和基础性研究，有助于解决版权使用的道德风险。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [22] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: Proof-Carrying Numbers (PCN) 是一种展示层协议，通过机械验证来确保大语言模型生成数字的保真度，将验证放在渲染器而非模型中，防止数字幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为随机系统可能生成偏离可用数据的数字，即数字幻觉问题。现有的安全措施（检索增强生成、引用和不确定性估计）提高了透明度但无法保证保真度。

Method: PCN协议将数字跨度作为与结构化声明绑定的声明绑定令牌发出，验证器根据声明的策略（如精确相等、舍入、别名或带限定符的容差）检查每个令牌。验证在渲染器中进行，只有经过声明检查的数字才被标记为已验证。

Result: PCN被形式化并证明了声音性、诚实令牌下的完备性、故障关闭行为和策略细化下的单调性。PCN轻量且模型无关，可无缝集成到现有应用中，并可扩展加密承诺。

Conclusion: 通过在显示前强制进行验证，PCN为数字敏感环境建立了一个简单契约：信任只能通过证明获得，而缺少标记则传达不确定性，从而有效防止数字幻觉问题。

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [23] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: eKalibr-Inertial是一个用于事件相机-惯性测量单元系统的精确时空标定工具，使用圆形网格板进行校准，通过严格的初始化和连续时间批量优化实现高精度标定。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动估计中需要与惯性测量单元融合，但需要准确的时空（外参和时间）校准才能实现最优融合效果。

Method: 基于eKalibr和eKalibr-Stereo的网格模式识别和跟踪方法，采用严格的初始化过程恢复所有参数，然后进行连续时间批量优化来细化参数。

Result: 广泛的真实世界实验结果表明，eKalibr-Inertial能够实现准确的事件相机-惯性测量单元时空校准。

Conclusion: 该方法为事件视觉-惯性系统提供了有效的标定解决方案，并开源实现以促进研究社区发展。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [24] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 通过事件驱动通信机制改进CBBA算法，在保持性能的同时大幅减少信息传输量


<details>
  <summary>Details</summary>
Motivation: 多机器人任务分配中，传统CBBA算法需要连续通信，容易造成网络塞塞和数据包丢失，影响系统性能

Method: 提出事件驱动通信机制，只在需要时候才进行通信，保持了CBBA的收敛性和性能上界

Result: 理论证明解的质量与CBBA相同，模拟实验显示可将消息传输量减少达52%

Conclusion: ED-CBBA算法有效解决了多机器任务分配中的通信挑战，在保持算法性能的同时显著提升了通信效率

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [25] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: LiHRA是一个新颖的多模态数据集，用于人机交互风险监控研究，包含3D LiDAR点云、人体关键点和机器人关节状态数据，覆盖6种HRI场景的4431个标记点云。


<details>
  <summary>Details</summary>
Motivation: 工业环境中协作机器人日益普及，但缺乏高质量的人机交互数据集（包括危险事件）阻碍了可靠安全系统的发展。

Method: 提供包含3D LiDAR点云、人体关键点和机器人关节状态的多模态数据集，捕捉人机协作的完整空间和动态上下文，覆盖6种代表性HRI场景的安全和危险版本。

Result: 数据集包含4431个以10Hz记录的标记点云，为传统和AI驱动的风险监控算法提供了丰富的训练和基准测试资源。

Conclusion: LiHRA通过高分辨率LiDAR数据、精确人体追踪、机器人状态数据和真实碰撞事件，为实时风险监控和自适应安全策略研究提供了重要基础。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>
