<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SynSpill: Improved Industrial Spill Detection With Synthetic Data](https://arxiv.org/abs/2508.10171)
*Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas*

Main category: cs.CV

TL;DR: 论文提出了一种基于高质量合成数据的框架，用于提升视觉语言模型（VLMs）在工业泄漏检测等安全关键领域的性能。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、数据敏感性和事件罕见性，真实数据稀缺，传统微调方法在工业泄漏检测等安全关键领域效果不佳。

Method: 通过合成数据生成管道（SynSpill数据集）进行参数高效微调（PEFT），提升YOLO和DETR等目标检测器的性能。

Result: 合成数据显著提升了VLMs和检测器的性能，使其在未见泄漏场景中表现接近。

Conclusion: 高保真合成数据是解决安全关键领域数据稀缺问题的有效手段，结合轻量级适配为工业环境提供了一种经济高效的解决方案。

Abstract: Large-scale Vision-Language Models (VLMs) have transformed general-purpose
visual recognition through strong zero-shot capabilities. However, their
performance degrades significantly in niche, safety-critical domains such as
industrial spill detection, where hazardous events are rare, sensitive, and
difficult to annotate. This scarcity -- driven by privacy concerns, data
sensitivity, and the infrequency of real incidents -- renders conventional
fine-tuning of detectors infeasible for most industrial settings.
  We address this challenge by introducing a scalable framework centered on a
high-quality synthetic data generation pipeline. We demonstrate that this
synthetic corpus enables effective Parameter-Efficient Fine-Tuning (PEFT) of
VLMs and substantially boosts the performance of state-of-the-art object
detectors such as YOLO and DETR. Notably, in the absence of synthetic data
(SynSpill dataset), VLMs still generalize better to unseen spill scenarios than
these detectors. When SynSpill is used, both VLMs and detectors achieve marked
improvements, with their performance becoming comparable.
  Our results underscore that high-fidelity synthetic data is a powerful means
to bridge the domain gap in safety-critical applications. The combination of
synthetic generation and lightweight adaptation offers a cost-effective,
scalable pathway for deploying vision systems in industrial environments where
real data is scarce/impractical to obtain.
  Project Page: https://synspill.vercel.app

</details>


### [2] [STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images](https://arxiv.org/abs/2508.10473)
*Liangrui Pan,xiaoyu Li,Guang Zhu,Guanting Li,Ruixin Wang,Jiadi Luo,Yaning Yang,Liang qingchun,Shaoliang Peng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为STAMP的多模式注意力感知多实例学习框架，用于通过深度学习模型诊断肺腺癌中的空气传播（STAS），在多中心数据集上取得了优于临床水平的诊断结果。


<details>
  <summary>Details</summary>
Motivation: STAS与肺腺癌的复发和生存率降低相关，但大规模诊断存在劳动密集和误诊风险，因此需要利用深度学习模型提高诊断效率。

Method: 研究收集了多中心病理图像数据集，提出STAMP框架，采用双分支架构和Transformer编码，结合多模式注意力模块动态选择STAS相关区域。

Result: STAMP在三个数据集上的AUC分别为0.8058、0.8017和0.7928，表现优于临床水平。

Conclusion: STAMP框架能有效提升STAS诊断的准确性和效率，具有临床应用潜力。

Abstract: Spread through air spaces (STAS) constitutes a novel invasive pattern in lung
adenocarcinoma (LUAD), associated with tumor recurrence and diminished survival
rates. However, large-scale STAS diagnosis in LUAD remains a labor-intensive
endeavor, compounded by the propensity for oversight and misdiagnosis due to
its distinctive pathological characteristics and morphological features.
Consequently, there is a pressing clinical imperative to leverage deep learning
models for STAS diagnosis. This study initially assembled histopathological
images from STAS patients at the Second Xiangya Hospital and the Third Xiangya
Hospital of Central South University, alongside the TCGA-LUAD cohort. Three
senior pathologists conducted cross-verification annotations to construct the
STAS-SXY, STAS-TXY, and STAS-TCGA datasets. We then propose a multi-pattern
attention-aware multiple instance learning framework, named STAMP, to analyze
and diagnose the presence of STAS across multi-center histopathology images.
Specifically, the dual-branch architecture guides the model to learn
STAS-associated pathological features from distinct semantic spaces.
Transformer-based instance encoding and a multi-pattern attention aggregation
modules dynamically selects regions closely associated with STAS pathology,
suppressing irrelevant noise and enhancing the discriminative power of global
representations. Moreover, a similarity regularization constraint prevents
feature redundancy across branches, thereby improving overall diagnostic
accuracy. Extensive experiments demonstrated that STAMP achieved competitive
diagnostic results on STAS-SXY, STAS-TXY and STAS-TCGA, with AUCs of 0.8058,
0.8017, and 0.7928, respectively, surpassing the clinical level.

</details>


### [3] [GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images](https://arxiv.org/abs/2508.10542)
*Mengyu Ren,Yutong Li,Hua Li,Runmin Cong,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了一种基于Mamba架构的GCRPNet模型，通过图增强的上下文和区域感知网络解决光学遥感图像中显著目标检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 光学遥感图像中显著目标检测面临目标尺度变化大和目标与背景对比度低的挑战，现有方法难以有效整合全局和局部特征。

Method: 采用视觉状态空间编码器提取多尺度特征，设计了差异-相似性引导的层次图注意力模块（DS-HGAM）和LEVSS解码器模块。

Result: 实验结果表明，GCRPNet模型在显著目标检测任务中达到了最先进的性能。

Conclusion: GCRPNet通过增强长程依赖和区域特征表示，有效提升了显著目标检测的性能。

Abstract: Salient object detection (SOD) in optical remote sensing images (ORSIs) faces
numerous challenges, including significant variations in target scales and low
contrast between targets and the background. Existing methods based on vision
transformers (ViTs) and convolutional neural networks (CNNs) architectures aim
to leverage both global and local features, but the difficulty in effectively
integrating these heterogeneous features limits their overall performance. To
overcome these limitations, we propose a graph-enhanced contextual and regional
perception network (GCRPNet), which builds upon the Mamba architecture to
simultaneously capture long-range dependencies and enhance regional feature
representation. Specifically, we employ the visual state space (VSS) encoder to
extract multi-scale features. To further achieve deep guidance and enhancement
of these features, we first design a difference-similarity guided hierarchical
graph attention module (DS-HGAM). This module strengthens cross-layer
interaction capabilities between features of different scales while enhancing
the model's structural perception,allowing it to distinguish between foreground
and background more effectively. Then, we design the LEVSS block as the decoder
of GCRPNet. This module integrates our proposed adaptive scanning strategy and
multi-granularity collaborative attention enhancement module (MCAEM). It
performs adaptive patch scanning on feature maps processed via multi-scale
convolutions, thereby capturing rich local region information and enhancing
Mamba's local modeling capability. Extensive experimental results demonstrate
that the proposed model achieves state-of-the-art performance, validating its
effectiveness and superiority.

</details>


### [4] [EvTurb: Event Camera Guided Turbulence Removal](https://arxiv.org/abs/2508.10582)
*Yixing Liu,Minggui Teng,Yifei Xia,Peiqi Duan,Boxin Shi*

Main category: cs.CV

TL;DR: EvTurb提出了一种基于事件流的湍流去除框架，通过事件积分和方差图两步网络解耦模糊和倾斜失真，并在真实数据集TurbEvent上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 大气湍流导致图像模糊和几何倾斜失真，现有方法难以解决这一高度不适定问题。

Method: EvTurb通过事件流建模湍流形成，采用两步网络：事件积分减少模糊，方差图消除倾斜失真。

Result: 实验表明EvTurb在性能和计算效率上优于现有方法。

Conclusion: EvTurb有效解决了湍流失真问题，并通过真实数据集验证了其优越性。

Abstract: Atmospheric turbulence degrades image quality by introducing blur and
geometric tilt distortions, posing significant challenges to downstream
computer vision tasks. Existing single-image and multi-frame methods struggle
with the highly ill-posed nature of this problem due to the compositional
complexity of turbulence-induced distortions. To address this, we propose
EvTurb, an event guided turbulence removal framework that leverages high-speed
event streams to decouple blur and tilt effects. EvTurb decouples blur and tilt
effects by modeling event-based turbulence formation, specifically through a
novel two-step event-guided network: event integrals are first employed to
reduce blur in the coarse outputs. This is followed by employing a variance
map, derived from raw event streams, to eliminate the tilt distortion for the
refined outputs. Additionally, we present TurbEvent, the first real-captured
dataset featuring diverse turbulence scenarios. Experimental results
demonstrate that EvTurb surpasses state-of-the-art methods while maintaining
computational efficiency.

</details>


### [5] [Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios](https://arxiv.org/abs/2508.10704)
*Zhanwen Liu,Yujing Sun,Yang Wang,Nan Yang,Shengbo Eben Li,Xiangmo Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种结合事件相机和RGB相机的方法（MCFNet），通过动态范围增强和跨模态特征融合，显著提升了复杂交通场景下的目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在复杂交通环境（如夜间驾驶、隧道）中动态范围有限，导致全局对比度降低和高频细节丢失，影响目标检测性能。

Method: 提出MCFNet，包括事件校正模块（ECM）、事件动态上采样模块（EDUM）和跨模态融合模块（CMM），实现时空对齐和自适应特征融合。

Result: 在DSEC-Det和PKU-DAVIS-SOD数据集上，MCFNet显著优于现有方法，mAP50提升7.4%，mAP提升1.7%。

Conclusion: MCFNet通过融合事件相机和RGB相机信息，有效解决了复杂光照下的目标检测问题，性能显著提升。

Abstract: The dynamic range limitation of conventional RGB cameras reduces global
contrast and causes loss of high-frequency details such as textures and edges
in complex traffic environments (e.g., nighttime driving, tunnels), hindering
discriminative feature extraction and degrading frame-based object detection.
To address this, we integrate a bio-inspired event camera with an RGB camera to
provide high dynamic range information and propose a motion cue fusion network
(MCFNet), which achieves optimal spatiotemporal alignment and adaptive
cross-modal feature fusion under challenging lighting. Specifically, an event
correction module (ECM) temporally aligns asynchronous event streams with image
frames via optical-flow-based warping, jointly optimized with the detection
network to learn task-aware event representations. The event dynamic upsampling
module (EDUM) enhances spatial resolution of event frames to match image
structures, ensuring precise spatiotemporal alignment. The cross-modal mamba
fusion module (CMM) uses adaptive feature fusion with a novel interlaced
scanning mechanism, effectively integrating complementary information for
robust detection. Experiments conducted on the DSEC-Det and PKU-DAVIS-SOD
datasets demonstrate that MCFNet significantly outperforms existing methods in
various poor lighting and fast moving traffic scenarios. Notably, on the
DSEC-Det dataset, MCFNet achieves a remarkable improvement, surpassing the best
existing methods by 7.4% in mAP50 and 1.7% in mAP metrics, respectively. The
code is available at https://github.com/Charm11492/MCFNet.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study](https://arxiv.org/abs/2508.10233)
*Li Sun,Shuheng Chen,Junyi Fan,Yong Si,Minoo Ahmadi,Elham Pishgar,Kamiar Alaei,Maryam Pishgar*

Main category: cs.LG

TL;DR: 该研究开发了一种可解释的机器学习模型，用于早期预测肝硬化重症患者的急性肾损伤（AKI），LightGBM模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 肝硬化患者中AKI发生率高且预后差，现有预测工具准确性不足且难以融入ICU工作流程。

Method: 回顾性分析MIMIC-IV数据库，提取48小时内实验室和生理数据，使用多种算法训练并评估模型。

Result: LightGBM模型表现最优（AUROC 0.808），关键预测因子与肝硬化-AKI机制一致。

Conclusion: 该模型能准确早期预测AKI风险，高阴性预测值支持低风险患者降级治疗，需进一步外部验证和系统集成。

Abstract: Background: Cirrhosis is a progressive liver disease with high mortality and
frequent complications, notably acute kidney injury (AKI), which occurs in up
to 50% of hospitalized patients and worsens outcomes. AKI stems from complex
hemodynamic, inflammatory, and metabolic changes, making early detection
essential. Many predictive tools lack accuracy, interpretability, and alignment
with intensive care unit (ICU) workflows. This study developed an interpretable
machine learning model for early AKI prediction in critically ill patients with
cirrhosis.
  Methods: We conducted a retrospective analysis of the MIMIC-IV v2.2 database,
identifying 1240 adult ICU patients with cirrhosis and excluding those with ICU
stays under 48 hours or missing key data. Laboratory and physiological
variables from the first 48 hours were extracted. The pipeline included
preprocessing, missingness filtering, LASSO feature selection, and SMOTE class
balancing. Six algorithms-LightGBM, CatBoost, XGBoost, logistic regression,
naive Bayes, and neural networks-were trained and evaluated using AUROC,
accuracy, F1-score, sensitivity, specificity, and predictive values.
  Results: LightGBM achieved the best performance (AUROC 0.808, 95% CI
0.741-0.856; accuracy 0.704; NPV 0.911). Key predictors included prolonged
partial thromboplastin time, absence of outside-facility 20G placement, low pH,
and altered pO2, consistent with known cirrhosis-AKI mechanisms and suggesting
actionable targets.
  Conclusion: The LightGBM-based model enables accurate early AKI risk
stratification in ICU patients with cirrhosis using routine clinical variables.
Its high negative predictive value supports safe de-escalation for low-risk
patients, and interpretability fosters clinician trust and targeted prevention.
External validation and integration into electronic health record systems are
warranted.

</details>


### [7] [GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation](https://arxiv.org/abs/2508.10471)
*Xinrui Li,Qilin Fan,Tianfu Wang,Kaiwen Wei,Ke Yu,Xu Zhang*

Main category: cs.LG

TL;DR: GraphFedMIG是一个联邦图学习框架，通过生成对抗网络和数据增强解决类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 联邦图学习（FGL）中，非独立同分布数据和类别不平衡会导致模型偏向多数类，影响性能。

Method: 提出GraphFedMIG，利用分层生成对抗网络和互信息引导机制生成少数类特征。

Result: 在四个真实数据集上实验，GraphFedMIG表现优于基线方法。

Conclusion: GraphFedMIG有效解决了FGL中的类别不平衡问题，提升了模型性能。

Abstract: Federated graph learning (FGL) enables multiple clients to collaboratively
train powerful graph neural networks without sharing their private,
decentralized graph data. Inherited from generic federated learning, FGL is
critically challenged by statistical heterogeneity, where non-IID data
distributions across clients can severely impair model performance. A
particularly destructive form of this is class imbalance, which causes the
global model to become biased towards majority classes and fail at identifying
rare but critical events. This issue is exacerbated in FGL, as nodes from a
minority class are often surrounded by biased neighborhood information,
hindering the learning of expressive embeddings. To grapple with this
challenge, we propose GraphFedMIG, a novel FGL framework that reframes the
problem as a federated generative data augmentation task. GraphFedMIG employs a
hierarchical generative adversarial network where each client trains a local
generator to synthesize high-fidelity feature representations. To provide
tailored supervision, clients are grouped into clusters, each sharing a
dedicated discriminator. Crucially, the framework designs a mutual
information-guided mechanism to steer the evolution of these client generators.
By calculating each client's unique informational value, this mechanism
corrects the local generator parameters, ensuring that subsequent rounds of
mutual information-guided generation are focused on producing high-value,
minority-class features. We conduct extensive experiments on four real-world
datasets, and the results demonstrate the superiority of the proposed
GraphFedMIG compared with other baselines.

</details>


### [8] [REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations](https://arxiv.org/abs/2508.10701)
*Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang*

Main category: cs.LG

TL;DR: REFN利用强化学习训练大型语言模型（LLM），自动生成网络过滤器以防御1天或n天漏洞攻击，解决了现有防御方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法（如主机补丁和网络过滤）在可扩展性、兼容性和部署过程中存在问题，无法有效应对大规模漏洞威胁。

Method: REFN通过强化学习（RL）驱动在线网络奖励训练LLM，结合Agentic RAG知识蒸馏和在线验证，生成兼容且稳健的网络过滤器。

Result: 在22类漏洞攻击测试中，REFN表现优异（准确率提高21.1%，平均补丁时间为3.65小时），并具备高可扩展性。

Conclusion: REFN为利用LLM快速防御大规模漏洞攻击提供了初步解决方案。

Abstract: The exploitation of 1 day or n day vulnerabilities poses severe threats to
networked devices due to massive deployment scales and delayed patching
(average Mean Time To Patch exceeds 60 days). Existing defenses, including host
based patching and network based filtering, are inadequate due to limited
scalability across diverse devices, compatibility issues especially with
embedded or legacy systems, and error prone deployment process (manual patch
validation). To address these issues, we introduce REFN (Reinforcement Learning
From Network), a novel framework that trains Large Language Models (LLMs) to
autonomously generate network filters to prevent 1 day or n day exploitations.
REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven
by online network rewards instead of traditional Human Feedback (RLHF). REFN
guarantees compatibility via unified deployment on edge security gateways
(Amazon Eero). REFN provides robustness via online validation using real
network traffic. Crucially, REFN addresses three core challenges in training
LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability
fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging
current LLMs language to network gaps through an RL From VNF Pipeline that
translates language context (vulnerability description) into network
enforcement, 3) addressing the LLM hallucination and non determinism via the
Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22
families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1
percent higher accuracy than alternatives), efficiency (Mean Time To Patch of
3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an
initial step toward training LLMs to rapidly prevent massive scale 1 day or n
day exploitations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence](https://arxiv.org/abs/2508.10241)
*Mark Zilberman*

Main category: cs.AI

TL;DR: 本文提出了一种基于事件熵势的概念，用于增强AI中的不确定性量化、决策和可解释性，并探讨了其在多个领域的应用。


<details>
  <summary>Details</summary>
Motivation: 通过量化离散事件对系统未来熵的影响，提升AI系统在不确定性建模中的表现。

Method: 将物理学中的熵势概念调整并形式化为AI框架，强调条件期望以考虑反事实场景。

Result: 熵势框架在策略评估、内在奖励设计、可解释AI和异常检测中展现出潜力。

Conclusion: 熵势框架为AI中的不确定性管理提供了理论基础强、可解释且多功能的解决方案。

Abstract: This work demonstrates how the concept of the entropic potential of events --
a parameter quantifying the influence of discrete events on the expected future
entropy of a system -- can enhance uncertainty quantification, decision-making,
and interpretability in artificial intelligence (AI). Building on its original
formulation in physics, the framework is adapted for AI by introducing an
event-centric measure that captures how actions, observations, or other
discrete occurrences impact uncertainty at future time horizons. Both the
original and AI-adjusted definitions of entropic potential are formalized, with
the latter emphasizing conditional expectations to account for counterfactual
scenarios. Applications are explored in policy evaluation, intrinsic reward
design, explainable AI, and anomaly detection, highlighting the metric's
potential to unify and strengthen uncertainty modeling in intelligent systems.
Conceptual examples illustrate its use in reinforcement learning, Bayesian
inference, and anomaly detection, while practical considerations for
computation in complex AI models are discussed. The entropic potential
framework offers a theoretically grounded, interpretable, and versatile
approach to managing uncertainty in AI, bridging principles from
thermodynamics, information theory, and machine learning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [10] [XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs](https://arxiv.org/abs/2508.09999)
*Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang*

Main category: cs.CL

TL;DR: 该论文提出XFacta数据集，用于评估基于多模态大语言模型（MLLM）的虚假信息检测方法，并分析了现有方法的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有虚假信息检测方法在多模态数据上的效果有限，且数据集存在过时或合成问题，阻碍了领域发展。

Method: 引入XFacta数据集，系统评估多种MLLM检测策略，并提出半自动更新框架。

Result: 通过实验验证了XFacta的适用性，并提供了模型设计和评估的实践建议。

Conclusion: XFacta和半自动框架为多模态虚假信息检测领域提供了重要工具和见解。

Abstract: The rapid spread of multimodal misinformation on social media calls for more
effective and robust detection methods. Recent advances leveraging multimodal
large language models (MLLMs) have shown the potential in addressing this
challenge. However, it remains unclear exactly where the bottleneck of existing
approaches lies (evidence retrieval v.s. reasoning), hindering the further
advances in this field. On the dataset side, existing benchmarks either contain
outdated events, leading to evaluation bias due to discrepancies with
contemporary social media scenarios as MLLMs can simply memorize these events,
or artificially synthetic, failing to reflect real-world misinformation
patterns. Additionally, it lacks comprehensive analyses of MLLM-based model
design strategies. To address these issues, we introduce XFacta, a
contemporary, real-world dataset that is better suited for evaluating
MLLM-based detectors. We systematically evaluate various MLLM-based
misinformation detection strategies, assessing models across different
architectures and scales, as well as benchmarking against existing detection
methods. Building on these analyses, we further enable a semi-automatic
detection-in-the-loop framework that continuously updates XFacta with new
content to maintain its contemporary relevance. Our analysis provides valuable
insights and practices for advancing the field of multimodal misinformation
detection. The code and data have been released.

</details>


### [11] [An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs](https://arxiv.org/abs/2508.10010)
*Ayana Hussain,Patrick Zhao,Nicholas Vincent*

Main category: cs.CL

TL;DR: 论文研究了LLM生成的越狱攻击对医疗错误信息的影响，并探讨了LLM在检测错误信息中的潜力。


<details>
  <summary>Details</summary>
Motivation: LLM可能被用于生成或检测错误信息，研究其越狱攻击的特性和效果有助于理解其双刃剑性质。

Method: 分析了109种针对三种目标LLM的越狱攻击，比较了生成的错误信息与Reddit上的医疗错误信息。

Result: LLM能有效检测来自其他LLM和人类的错误信息，支持其在健康信息生态系统中的积极作用。

Conclusion: 通过精心设计，LLM可以为信息生态系统的健康发展做出贡献。

Abstract: Large Language Models (LLMs) are a double-edged sword capable of generating
harmful misinformation -- inadvertently, or when prompted by "jailbreak"
attacks that attempt to produce malicious outputs. LLMs could, with additional
research, be used to detect and prevent the spread of misinformation. In this
paper, we investigate the efficacy and characteristics of LLM-produced
jailbreak attacks that cause other models to produce harmful medical
misinformation. We also study how misinformation generated by jailbroken LLMs
compares to typical misinformation found on social media, and how effectively
it can be detected using standard machine learning approaches. Specifically, we
closely examine 109 distinct attacks against three target LLMs and compare the
attack prompts to in-the-wild health-related LLM queries. We also examine the
resulting jailbreak responses, comparing the generated misinformation to
health-related misinformation on Reddit. Our findings add more evidence that
LLMs can be effectively used to detect misinformation from both other LLMs and
from people, and support a body of work suggesting that with careful design,
LLMs can contribute to a healthier overall information ecosystem.

</details>


### [12] [LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients](https://arxiv.org/abs/2508.10021)
*Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko*

Main category: cs.CL

TL;DR: 提出LATTE框架，通过对比学习将原始事件嵌入与冻结LLM的语义嵌入对齐，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 金融应用中需要从客户历史通信序列学习嵌入，但直接使用LLM处理长序列计算成本高且不实用。

Method: 使用对比学习框架LATTE，将行为特征总结为短提示，通过LLM嵌入并作为监督信号。

Result: 在真实金融数据集上优于现有技术，同时降低推理成本和输入大小。

Conclusion: LATTE在延迟敏感环境中仍可部署，优于传统LLM处理长序列的方法。

Abstract: Learning clients embeddings from sequences of their historic communications
is central to financial applications. While large language models (LLMs) offer
general world knowledge, their direct use on long event sequences is
computationally expensive and impractical in real-world pipelines. In this
paper, we propose LATTE, a contrastive learning framework that aligns raw event
embeddings with semantic embeddings from frozen LLMs. Behavioral features are
summarized into short prompts, embedded by the LLM, and used as supervision via
contrastive loss. The proposed approach significantly reduces inference cost
and input size compared to conventional processing of complete sequence by LLM.
We experimentally show that our method outperforms state-of-the-art techniques
for learning event sequence representations on real-world financial datasets
while remaining deployable in latency-sensitive environments.

</details>


### [13] [Detecting and explaining postpartum depression in real-time with generative artificial intelligence](https://arxiv.org/abs/2508.10025)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.CL

TL;DR: 论文提出了一种结合NLP、ML和LLMs的智能产后抑郁筛查系统，实现实时、低成本、非侵入性的语音分析，检测准确率达90%。


<details>
  <summary>Details</summary>
Motivation: 产后抑郁（PPD）严重影响母亲身心健康，需快速检测及干预。

Method: 结合自然语言处理、机器学习和大型语言模型，使用可解释的树模型和特征重要性分析。

Result: PPD检测准确率达90%，优于现有方法。

Conclusion: 该系统能快速检测PPD及其风险因素，为及时干预提供支持。

Abstract: Among the many challenges mothers undergo after childbirth, postpartum
depression (PPD) is a severe condition that significantly impacts their mental
and physical well-being. Consequently, the rapid detection of ppd and their
associated risk factors is critical for in-time assessment and intervention
through specialized prevention procedures. Accordingly, this work addresses the
need to help practitioners make decisions with the latest technological
advancements to enable real-time screening and treatment recommendations.
Mainly, our work contributes to an intelligent PPD screening system that
combines Natural Language Processing, Machine Learning (ML), and Large Language
Models (LLMs) towards an affordable, real-time, and non-invasive free speech
analysis. Moreover, it addresses the black box problem since the predictions
are described to the end users thanks to the combination of LLMs with
interpretable ml models (i.e., tree-based algorithms) using feature importance
and natural language. The results obtained are 90 % on ppd detection for all
evaluation metrics, outperforming the competing solutions in the literature.
Ultimately, our solution contributes to the rapid detection of PPD and their
associated risk factors, critical for in-time and proper assessment and
intervention.

</details>


### [14] [Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models](https://arxiv.org/abs/2508.10192)
*Igor Halperin*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The proliferation of Large Language Models (LLMs) is challenged by
hallucinations, critical failure modes where models generate non-factual,
nonsensical or unfaithful text. This paper introduces Semantic Divergence
Metrics (SDM), a novel lightweight framework for detecting Faithfulness
Hallucinations -- events of severe deviations of LLMs responses from input
contexts. We focus on a specific implementation of these LLM errors,
{confabulations, defined as responses that are arbitrary and semantically
misaligned with the user's query. Existing methods like Semantic Entropy test
for arbitrariness by measuring the diversity of answers to a single, fixed
prompt. Our SDM framework improves upon this by being more prompt-aware: we
test for a deeper form of arbitrariness by measuring response consistency not
only across multiple answers but also across multiple, semantically-equivalent
paraphrases of the original prompt. Methodologically, our approach uses joint
clustering on sentence embeddings to create a shared topic space for prompts
and answers. A heatmap of topic co-occurances between prompts and responses can
be viewed as a quantified two-dimensional visualization of the user-machine
dialogue. We then compute a suite of information-theoretic metrics to measure
the semantic divergence between prompts and responses. Our practical score,
$\mathcal{S}_H$, combines the Jensen-Shannon divergence and Wasserstein
distance to quantify this divergence, with a high score indicating a
Faithfulness hallucination. Furthermore, we identify the KL divergence
KL(Answer $||$ Prompt) as a powerful indicator of \textbf{Semantic
Exploration}, a key signal for distinguishing different generative behaviors.
These metrics are further combined into the Semantic Box, a diagnostic
framework for classifying LLM response types, including the dangerous,
confident confabulation.

</details>
