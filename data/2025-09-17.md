<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Modular, On-Site Solutions with Lightweight Anomaly Detection for Sustainable Nutrient Management in Agriculture](https://arxiv.org/abs/2509.12247)
*Abigail R. Cohen,Yuming Sun,Zhihao Qin,Harsh S. Muriki,Zihao Xiao,Yeonju Lee,Matthew Housley,Andrew F. Sharkey,Rhuanito S. Ferrarezi,Jing Li,Lu Gan,Yongsheng Chen*

Main category: cs.CV

TL;DR: 这篇论文提出了一种分层处理流程，通过多光谱成像和机器学习等技术，实现了体种异常检测和作物状态估计，在低能耗下完成农业营养管理的实时优化。


<details>
  <summary>Details</summary>
Motivation: 当前农业营养管理需要长时间分析，无法实现实时优化；成像技术虽能快速表型但计算复杂度高，在资源受限环境下难以部署。需要一种效率与准确性平衡的解决方案。

Method: 采用三种肥料激测处理（T1-100%、T2-50%、T3-25%）进行营养消耗实验，使用多光谱成像技术。建立分层处理流程：首先用自编码器（AE）进行早期异常警报，然后使用植被指数特征结合随机森林（RF）和整张图像深度学习（ViT）两种不同复杂度的状态估计模块。

Result: 高效率异常检测（移植后9天检测到73%的T3样本），能耗远低于浪费氮的体现能量。ViT在磷和钙估计上表现更好（R2 0.61 vs 0.58，0.48 vs 0.35），但能耗成本更高。RF与ViT在不同指标上各有优势，存在效率-准确性交换。

Conclusion: 该模块化处理流程为边缘设备的农业诊断开启了新机会，提供了实用的农业可持续发展解决方案，能够在低能耗下实现营养管理的实时优化。

Abstract: Efficient nutrient management is critical for crop growth and sustainable
resource consumption (e.g., nitrogen, energy). Current approaches require
lengthy analyses, preventing real-time optimization; similarly, imaging
facilitates rapid phenotyping but can be computationally intensive, preventing
deployment under resource constraints. This study proposes a flexible, tiered
pipeline for anomaly detection and status estimation (fresh weight, dry mass,
and tissue nutrients), including a comprehensive energy analysis of approaches
that span the efficiency-accuracy spectrum. Using a nutrient depletion
experiment with three treatments (T1-100%, T2-50%, and T3-25% fertilizer
strength) and multispectral imaging (MSI), we developed a hierarchical pipeline
using an autoencoder (AE) for early warning. Further, we compared two status
estimation modules of different complexity for more detailed analysis:
vegetation index (VI) features with machine learning (Random Forest, RF) and
raw whole-image deep learning (Vision Transformer, ViT). Results demonstrated
high-efficiency anomaly detection (73% net detection of T3 samples 9 days after
transplanting) at substantially lower energy than embodied energy in wasted
nitrogen. The state estimation modules show trade-offs, with ViT outperforming
RF on phosphorus and calcium estimation (R2 0.61 vs. 0.58, 0.48 vs. 0.35) at
higher energy cost. With our modular pipeline, this work opens opportunities
for edge diagnostics and practical opportunities for agricultural
sustainability.

</details>


### [2] [Two-Stage Decoupling Framework for Variable-Length Glaucoma Prognosis](https://arxiv.org/abs/2509.12453)
*Yiran Song,Yikai Zhang,Silvia Orengo-Nania,Nian Wang,Fenglong Ma,Rui Zhang,Yifan Peng,Mingquan Lin*

Main category: cs.CV

TL;DR: 提出两阶段解耦框架TSDF用于可变长度青光眼预后预测，通过自监督学习整合多数据集特征表示，使用注意力机制处理变长序列输入，在两个不同规模数据集上验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有青光眼预后方法受限于固定长度输入且端到端模型在有限数据集上表现不佳，需要更灵活高效的处理变长序列数据的解决方案

Method: 两阶段框架：第一阶段使用自监督学习整合多数据集训练特征表示模块；第二阶段使用基于注意力的时序聚合模块处理变长序列输入

Result: 在OHTS和GRAPE两个不同规模和临床设置的基准数据集上验证了方法的有效性和鲁棒性，显著提升模型性能同时保持参数紧凑

Conclusion: TSDF框架能够有效处理青光眼预后中的变长序列数据问题，通过解耦特征学习和时序聚合实现更好的性能表现

Abstract: Glaucoma is one of the leading causes of irreversible blindness worldwide.
Glaucoma prognosis is essential for identifying at-risk patients and enabling
timely intervention to prevent blindness. Many existing approaches rely on
historical sequential data but are constrained by fixed-length inputs, limiting
their flexibility. Additionally, traditional glaucoma prognosis methods often
employ end-to-end models, which struggle with the limited size of glaucoma
datasets. To address these challenges, we propose a Two-Stage Decoupling
Framework (TSDF) for variable-length glaucoma prognosis. In the first stage, we
employ a feature representation module that leverages self-supervised learning
to aggregate multiple glaucoma datasets for training, disregarding differences
in their supervisory information. This approach enables datasets of varying
sizes to learn better feature representations. In the second stage, we
introduce a temporal aggregation module that incorporates an attention-based
mechanism to process sequential inputs of varying lengths, ensuring flexible
and efficient utilization of all available data. This design significantly
enhances model performance while maintaining a compact parameter size.
Extensive experiments on two benchmark glaucoma datasets:the Ocular
Hypertension Treatment Study (OHTS) and the Glaucoma Real-world Appraisal
Progression Ensemble (GRAPE),which differ significantly in scale and clinical
settings,demonstrate the effectiveness and robustness of our approach.

</details>


### [3] [Few to Big: Prototype Expansion Network via Diffusion Learner for Point Cloud Few-shot Semantic Segmentation](https://arxiv.org/abs/2509.12878)
*Qianguang Zhao,Dongli Wang,Yan Zhou,Jianxun Li,Richard Irampa*

Main category: cs.CV

TL;DR: PENet是一个用于少样本3D点云语义分割的新框架，通过扩散模型生成通用特征来扩展原型表示能力，解决类内多样性和集合间不一致性问题


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的方法存在两个关键挑战：(1)类内多样性问题 - 原型的有限表示能力无法覆盖类的全部变化；(2)集合间不一致性问题 - 支持集生成的原型与查询特征空间不对齐

Method: 提出原型扩展网络(PENet)，采用双流学习器架构：固有学习器(IL)提取代表性特征，扩散学习器(DL)提供丰富的通用特征。通过原型同化模块(PAM)和原型校准机制(PCM)处理双原型

Result: 在S3DIS和ScanNet数据集上的大量实验表明，PENet在各种少样本设置下显著优于最先进的方法

Conclusion: 通过利用扩散模型的生成能力来扩展原型表示范围，PENet有效解决了少样本3D点云分割中的关键挑战，取得了优异的性能

Abstract: Few-shot 3D point cloud semantic segmentation aims to segment novel
categories using a minimal number of annotated support samples. While existing
prototype-based methods have shown promise, they are constrained by two
critical challenges: (1) Intra-class Diversity, where a prototype's limited
representational capacity fails to cover a class's full variations, and (2)
Inter-set Inconsistency, where prototypes derived from the support set are
misaligned with the query feature space. Motivated by the powerful generative
capability of diffusion model, we re-purpose its pre-trained conditional
encoder to provide a novel source of generalizable features for expanding the
prototype's representational range. Under this setup, we introduce the
Prototype Expansion Network (PENet), a framework that constructs big-capacity
prototypes from two complementary feature sources. PENet employs a dual-stream
learner architecture: it retains a conventional fully supervised Intrinsic
Learner (IL) to distill representative features, while introducing a novel
Diffusion Learner (DL) to provide rich generalizable features. The resulting
dual prototypes are then processed by a Prototype Assimilation Module (PAM),
which adopts a novel push-pull cross-guidance attention block to iteratively
align the prototypes with the query space. Furthermore, a Prototype Calibration
Mechanism (PCM) regularizes the final big capacity prototype to prevent
semantic drift. Extensive experiments on the S3DIS and ScanNet datasets
demonstrate that PENet significantly outperforms state-of-the-art methods
across various few-shot settings.

</details>


### [4] [Time-step Mixup for Efficient Spiking Knowledge Transfer from Appearance to Event Domain](https://arxiv.org/abs/2509.12959)
*Yuqi Xie,Shuhan Ye,Chong Wang,Jiazhen Xu,Le Shen,Yuanbin Qian,Jiangbo Qian*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The integration of event cameras and spiking neural networks holds great
promise for energy-efficient visual processing. However, the limited
availability of event data and the sparse nature of DVS outputs pose challenges
for effective training. Although some prior work has attempted to transfer
semantic knowledge from RGB datasets to DVS, they often overlook the
significant distribution gap between the two modalities. In this paper, we
propose Time-step Mixup knowledge transfer (TMKT), a novel fine-grained mixing
strategy that exploits the asynchronous nature of SNNs by interpolating RGB and
DVS inputs at various time-steps. To enable label mixing in cross-modal
scenarios, we further introduce modality-aware auxiliary learning objectives.
These objectives support the time-step mixup process and enhance the model's
ability to discriminate effectively across different modalities. Our approach
enables smoother knowledge transfer, alleviates modality shift during training,
and achieves superior performance in spiking image classification tasks.
Extensive experiments demonstrate the effectiveness of our method across
multiple datasets. The code will be released after the double-blind review
process.

</details>


### [5] [Drone Detection Using a Low-Power Neuromorphic Virtual Tripwire](https://arxiv.org/abs/2509.12997)
*Anton Eldeborg Lundin,Rasmus Winzell,Hanna Hamrell,David Gustafsson,Hannes Ovrén*

Main category: cs.CV

TL;DR: 基于神经科学相机和疯疲神经网络的低功耗无人机检测系统，能在网格化部署中实现超过一年的电池持续时间


<details>
  <summary>Details</summary>
Motivation: 小型无人机对军事和民用基础设施构成日益严重的威胁，需要早期自动化检测解决方案

Method: 使用神经科学相机（事件相机）和疯疲神经网络，将检测模型部署在神经科学芯片上，支持多个检测单元组成虚拟护栏

Result: 系统能耗效率比边缘GPU解决方案高几个数量级，可以运行超过一年，模型主要依靠无人机形状而非叶轮时序特征

Conclusion: 该神经科学解决方案具有极低的功耗和小形化特性，适合在缺乏电力基础设施的地区或争议区域部署

Abstract: Small drones are an increasing threat to both military personnel and civilian
infrastructure, making early and automated detection crucial. In this work we
develop a system that uses spiking neural networks and neuromorphic cameras
(event cameras) to detect drones. The detection model is deployed on a
neuromorphic chip making this a fully neuromorphic system. Multiple detection
units can be deployed to create a virtual tripwire which detects when and where
drones enter a restricted zone. We show that our neuromorphic solution is
several orders of magnitude more energy efficient than a reference solution
deployed on an edge GPU, allowing the system to run for over a year on battery
power. We investigate how synthetically generated data can be used for
training, and show that our model most likely relies on the shape of the drone
rather than the temporal characteristics of its propellers. The small size and
low power consumption allows easy deployment in contested areas or locations
that lack power infrastructure.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Explainable Unsupervised Multi-Anomaly Detection and Temporal Localization in Nuclear Times Series Data with a Dual Attention-Based Autoencoder](https://arxiv.org/abs/2509.12372)
*Konstantinos Vasili,Zachery T. Dahm,Stylianos Chatzidakis*

Main category: cs.LG

TL;DR: 基于双重注意力机制LSTM自动编码器的无监督异常检测方法，能够在核反应堆监测中进行异常事件的检测、定位和定时


<details>
  <summary>Details</summary>
Motivation: 下一代核反应堆产生大量多变量时间序列数据，需要远程自主控制系统。现有ML/DL方法存在可解释性不足、缺乏真实数据和异常事件稀缺等挑战

Method: 使用LSTM自动编码器结合特征注意力和时间注意力机制，特征注意力分配权重给异常模式的辐射传感器，时间注意力突出发生不常的具体时刻

Result: 在PUR-1研究反应堆的真实数据集上评估，框架能够在单一统一网络中识别受影响传感器和异常持续时间

Conclusion: 该方法提供了一种可解释的异常检测方案，能够在安全关键领域实现异常事件的检测、定位和定时，为远程自主控制系统的发展奠定基础

Abstract: The nuclear industry is advancing toward more new reactor designs, with
next-generation reactors expected to be smaller in scale and power output.
These systems have the potential to produce large volumes of information in the
form of multivariate time-series data, which could be used for enhanced
real-time monitoring and control. In this context, the development of remote
autonomous or semi-autonomous control systems for reactor operation has gained
significant interest. A critical first step toward such systems is an accurate
diagnostics module capable of detecting and localizing anomalies within the
reactor system. Recent studies have proposed various ML and DL approaches for
anomaly detection in the nuclear domain. Despite promising results, key
challenges remain, including limited to no explainability, lack of access to
real-world data, and scarcity of abnormal events, which impedes benchmarking
and characterization. Most existing studies treat these methods as black boxes,
while recent work highlights the need for greater interpretability of ML/DL
outputs in safety-critical domains. Here, we propose an unsupervised
methodology based on an LSTM autoencoder with a dual attention mechanism for
characterization of abnormal events in a real-world reactor radiation area
monitoring system. The framework includes not only detection but also
localization of the event and was evaluated using real-world datasets of
increasing complexity from the PUR-1 research reactor. The attention mechanisms
operate in both the feature and temporal dimensions, where the feature
attention assigns weights to radiation sensors exhibiting abnormal patterns,
while time attention highlights the specific timesteps where irregularities
occur, thus enabling localization. By combining the results, the framework can
identify both the affected sensors and the duration of each anomaly within a
single unified network.

</details>


### [7] [Unbiased Online Curvature Approximation for Regularized Graph Continual Learning](https://arxiv.org/abs/2509.12727)
*Jie Yin,Ke Sun,Han Wu*

Main category: cs.LG

TL;DR: 本文提出了一种基于正则化的图持续学习方法，通过在线估计欧氏曲率空间来防止坏忘，在三个图数据集上较现有方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决图持续学习中的坏忘问题，特别是在无重放、类增量设置下，现有正则化方法对欧氏信息矩阵的对角线性近似存在限制。

Method: 构建了基于欧氏信息矩阵引导的曲率参数空间正则化框架，提出了一种无偏的在线曲率近似方法，直接估计正则化项而不显式计算和存储FIM。

Result: 在三个图数据集上进行的实验显示，该方法显著超过了现有正则化基方法，实现了稳定性（保留旧知识）和可塑性（获取新知识）之间的优称平衡。

Conclusion: 通过在线估计完整FIM的曲率空间，该方法能够更好地描述学习新任务时的损失地形，同时保留之前任务的知识，为图持续学习提供了更有效的正则化方法。

Abstract: Graph continual learning (GCL) aims to learn from a continuous sequence of
graph-based tasks. Regularization methods are vital for preventing catastrophic
forgetting in GCL, particularly in the challenging replay-free,
class-incremental setting, where each task consists of a set of unique classes.
In this work, we first establish a general regularization framework for GCL
based on the curved parameter space induced by the Fisher information matrix
(FIM). We show that the dominant Elastic Weight Consolidation (EWC) and its
variants are a special case within this framework, using a diagonal
approximation of the empirical FIM based on parameters from previous tasks. To
overcome their limitations, we propose a new unbiased online curvature
approximation of the full FIM based on the model's current learning state. Our
method directly estimates the regularization term in an online manner without
explicitly evaluating and storing the FIM itself. This enables the model to
better capture the loss landscape during learning new tasks while retaining the
knowledge learned from previous tasks. Extensive experiments on three graph
datasets demonstrate that our method significantly outperforms existing
regularization-based methods, achieving a superior trade-off between stability
(retaining old knowledge) and plasticity (acquiring new knowledge).

</details>


### [8] [Spiking Vocos: An Energy-Efficient Neural Vocoder](https://arxiv.org/abs/2509.13049)
*Yukun Chen,Zhaoxi Mu,Andong Li,Peilin Li,Xinyu Yang*

Main category: cs.LG

TL;DR: 提出Spiking Vocos，一种基于SNN的超低能耗神经声码器，通过Spiking ConvNeXt模块和振幅捷径路径解决信息瓶颈，性能接近ANN版本但能耗仅14.7%


<details>
  <summary>Details</summary>
Motivation: 传统神经声码器在边缘设备部署时能耗过高，SNN因其事件驱动特性具有高能效优势，适合低资源场景

Method: 基于Vocos框架构建SNN声码器，设计Spiking ConvNeXt减少MAC操作，加入振幅捷径路径保持信号动态，采用自架构蒸馏策略和轻量级时序移位模块

Result: 性能与ANN相当（UTMOS 3.74，PESQ 3.45），能耗仅为ANN的14.7%

Conclusion: Spiking Vocos成功实现了高性能与超低能耗的平衡，为边缘设备部署提供了可行的解决方案

Abstract: Despite the remarkable progress in the synthesis speed and fidelity of neural
vocoders, their high energy consumption remains a critical barrier to practical
deployment on computationally restricted edge devices. Spiking Neural Networks
(SNNs), widely recognized for their high energy efficiency due to their
event-driven nature, offer a promising solution for low-resource scenarios. In
this paper, we propose Spiking Vocos, a novel spiking neural vocoder with
ultra-low energy consumption, built upon the efficient Vocos framework. To
mitigate the inherent information bottleneck in SNNs, we design a Spiking
ConvNeXt module to reduce Multiply-Accumulate (MAC) operations and incorporate
an amplitude shortcut path to preserve crucial signal dynamics. Furthermore, to
bridge the performance gap with its Artificial Neural Network (ANN)
counterpart, we introduce a self-architectural distillation strategy to
effectively transfer knowledge. A lightweight Temporal Shift Module is also
integrated to enhance the model's ability to fuse information across the
temporal dimension with negligible computational overhead. Experiments
demonstrate that our model achieves performance comparable to its ANN
counterpart, with UTMOS and PESQ scores of 3.74 and 3.45 respectively, while
consuming only 14.7% of the energy. The source code is available at
https://github.com/pymaster17/Spiking-Vocos.

</details>


### [9] [Traces Propagation: Memory-Efficient and Scalable Forward-Only Learning in Spiking Neural Networks](https://arxiv.org/abs/2509.13053)
*Lorenzo Pes,Bojian Yin,Sander Stuijk,Federico Corradi*

Main category: cs.LG

TL;DR: 提出了一种名为Traces Propagation (TP)的前向传播、内存高效、可扩展的完全局部学习规则，用于脉冲神经网络训练，解决了时空信用分配问题，无需辅助矩阵，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的SNN训练方法如BPTT与生物神经系统的时空局部性不符，且计算内存需求高。现有局部学习规则虽然实现了时间信用分配，但无法解决空间信用分配问题，需要辅助矩阵导致内存开销大和可扩展性差。

Method: 提出TP学习规则，将资格迹与分层对比损失相结合，无需辅助分层矩阵，实现完全局部的前向传播学习。

Result: 在NMNIST和SHD数据集上优于其他完全局部学习规则；在DVS-GESTURE和DVS-CIFAR10等复杂数据集上表现竞争力强；可有效扩展到VGG-9等深层SNN架构；内存扩展性优于现有完全局部可扩展规则；适用于Google Speech Commands等实际微调任务。

Conclusion: TP为边缘设备上的高效学习提供了可行路径，是一种内存高效、可扩展的完全局部学习解决方案。

Abstract: Spiking Neural Networks (SNNs) provide an efficient framework for processing
dynamic spatio-temporal signals and for investigating the learning principles
underlying biological neural systems. A key challenge in training SNNs is to
solve both spatial and temporal credit assignment. The dominant approach for
training SNNs is Backpropagation Through Time (BPTT) with surrogate gradients.
However, BPTT is in stark contrast with the spatial and temporal locality
observed in biological neural systems and leads to high computational and
memory demands, limiting efficient training strategies and on-device learning.
Although existing local learning rules achieve local temporal credit assignment
by leveraging eligibility traces, they fail to address the spatial credit
assignment without resorting to auxiliary layer-wise matrices, which increase
memory overhead and hinder scalability, especially on embedded devices. In this
work, we propose Traces Propagation (TP), a forward-only, memory-efficient,
scalable, and fully local learning rule that combines eligibility traces with a
layer-wise contrastive loss without requiring auxiliary layer-wise matrices. TP
outperforms other fully local learning rules on NMNIST and SHD datasets. On
more complex datasets such as DVS-GESTURE and DVS-CIFAR10, TP showcases
competitive performance and scales effectively to deeper SNN architectures such
as VGG-9, while providing favorable memory scaling compared to prior fully
local scalable rules, for datasets with a significant number of classes.
Finally, we show that TP is well suited for practical fine-tuning tasks, such
as keyword spotting on the Google Speech Commands dataset, thus paving the way
for efficient learning at the edge.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [InPhyRe Discovers: Large Multimodal Models Struggle in Inductive Physical Reasoning](https://arxiv.org/abs/2509.12263)
*Gautam Sreekumar,Vishnu Naresh Boddeti*

Main category: cs.AI

TL;DR: 提出了InPhyRe基准测试，用于评估大型多模态模型在违反训练物理定律场景下的归纳物理推理能力，发现现有模型存在参数知识应用困难、语言偏见和视觉输入忽略等问题。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型仅依赖训练时学到的参数化物理知识，无法处理违反物理定律的推理场景，而人类具备从少量视觉示例中适应新物理环境的归纳推理能力，这对安全关键应用至关重要。

Method: 创建InPhyRe视觉问答基准，通过算法生成的合成碰撞视频评估模型在违反物理定律场景下的推理能力，测试了13个大型多模态模型。

Result: 发现模型在应用参数化物理知识进行推理方面存在困难；当演示样本违反物理定律时归纳推理能力较弱；存在语言偏见且很大程度上忽略视觉输入。

Conclusion: 大型多模态模型在归纳物理推理方面存在严重缺陷，对视觉输入的信任度值得质疑，需要改进模型以增强在违反物理定律场景下的推理能力。

Abstract: Large multimodal models (LMMs) encode universal physical laws observed during
training, such as momentum conservation, as parametric knowledge. It allows
LMMs to answer physical reasoning queries, such as the outcome of a potential
collision event from visual input. However, since parametric knowledge includes
only the physical laws seen during training, it is insufficient for reasoning
when the inference scenario violates these physical laws. In contrast, humans
possess the skill to adapt their physical reasoning to unseen physical
environments from a few visual examples. This ability, which we refer to as
inductive physical reasoning, is indispensable for LMMs if they are to replace
human agents in safety-critical applications. Despite its importance, existing
visual benchmarks evaluate only the parametric knowledge in LMMs, and not
inductive physical reasoning. To this end, we propose InPhyRe, the first visual
question answering benchmark to measure inductive physical reasoning in LMMs.
InPhyRe evaluates LMMs on their ability to predict the outcome of collision
events in algorithmically generated synthetic collision videos. By inspecting
13 LMMs, InPhyRe informs us that (1) LMMs struggle to apply their limited
parametric knowledge about universal physical laws to reasoning, (2) inductive
physical reasoning in LMMs is weak when demonstration samples violate universal
physical laws, and (3) inductive physical reasoning in LMMs suffers from
language bias and largely ignores the visual inputs, questioning the
trustworthiness of LMMs regarding visual inputs.

</details>


### [11] [A Dimensionality-Reduced XAI Framework for Roundabout Crash Severity Insights](https://arxiv.org/abs/2509.12524)
*Rohit Chakraborty,Subasish Das*

Main category: cs.AI

TL;DR: 这篇论文通过可解释人工智能流程分析了丧生圆相互相关的严重交通事故模式，识别了四种事故模式并量化了严重程度的关键驱动因素。


<details>
  <summary>Details</summary>
Motivation: 虽然圆相互能减少严重交通事故，但不同条件下的风险模式存在差异，需要更深入分析以支持有效的安全管理策略。

Method: 采用两步可解释性工作流程：首先用聚类对应分析(CCA)识别四种事故模式，然后用树基模型结合SHAP方法量化严重程度的驱动因素。

Result: 结果显示：黑暗、湿滑地面、高速度与固定物体碰撞或角度事故同时出现时严重程度高；明亮、低速环境下严重程度低。不同模式有特定的事故机制。

Conclusion: 该工作流将模式发现与案例级解释相结合，为公共安全分析提供了可用的可解释人工智能模板，支持场景筛选、措施选择和审计报告。

Abstract: Roundabouts reduce severe crashes, yet risk patterns vary by conditions. This
study analyzes 2017-2021 Ohio roundabout crashes using a two-step, explainable
workflow. Cluster Correspondence Analysis (CCA) identifies co-occurring factors
and yields four crash patterns. A tree-based severity model is then interpreted
with SHAP to quantify drivers of injury within and across patterns. Results
show higher severity when darkness, wet surfaces, and higher posted speeds
coincide with fixed-object or angle events, and lower severity in clear,
low-speed settings. Pattern-specific explanations highlight mechanisms at
entries (fail-to-yield, gap acceptance), within multi-lane circulation
(improper maneuvers), and during slow-downs (rear-end). The workflow links
pattern discovery with case-level explanations, supporting site screening,
countermeasure selection, and audit-ready reporting. The contribution to
Information Systems is a practical template for usable XAI in public safety
analytics.

</details>


### [12] [Analogy-Driven Financial Chain-of-Thought (AD-FCoT): A Prompting Approach for Financial Sentiment Analysis](https://arxiv.org/abs/2509.12611)
*Anmol Singhal Navya Singhal*

Main category: cs.AI

TL;DR: 提出了AD-FCoT框架，通过类比推理和思维链提示相结合的方法，在无需额外训练的情况下提升金融新闻情感分析的准确性和市场相关性。


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析方法难以捕捉复杂经济背景且缺乏透明推理，影响了可靠性。大型语言模型虽具备强大文本理解能力，但需要更好的方法来处理金融领域的特定需求。

Method: AD-FCoT框架结合类比推理和思维链提示，引导LLM在新事件与已知结果的历史情景之间建立平行关系，并嵌入到结构化推理链中。无需额外训练数据或微调。

Result: 在数千篇新闻文章上的实验显示，AD-FCoT在情感分类准确性和市场回报相关性方面均优于强基线方法，生成的解释也与领域专业知识一致。

Conclusion: AD-FCoT是首批在金融领域明确将类比示例与思维链推理相结合的方法之一，为实际金融分析提供了可解释的见解，展现了纯提示方法的有效性。

Abstract: Financial news sentiment analysis is crucial for anticipating market
movements. With the rise of AI techniques such as Large Language Models (LLMs),
which demonstrate strong text understanding capabilities, there has been
renewed interest in enhancing these systems. Existing methods, however, often
struggle to capture the complex economic context of news and lack transparent
reasoning, which undermines their reliability. We propose Analogy-Driven
Financial Chain-of-Thought (AD-FCoT), a prompting framework that integrates
analogical reasoning with chain-of-thought (CoT) prompting for sentiment
prediction on historical financial news. AD-FCoT guides LLMs to draw parallels
between new events and relevant historical scenarios with known outcomes,
embedding these analogies into a structured, step-by-step reasoning chain. To
our knowledge, this is among the first approaches to explicitly combine
analogical examples with CoT reasoning in finance. Operating purely through
prompting, AD-FCoT requires no additional training data or fine-tuning and
leverages the model's internal financial knowledge to generate rationales that
mirror human analytical reasoning. Experiments on thousands of news articles
show that AD-FCoT outperforms strong baselines in sentiment classification
accuracy and achieves substantially higher correlation with market returns. Its
generated explanations also align with domain expertise, providing
interpretable insights suitable for real-world financial analysis.

</details>


### [13] [A Visualized Framework for Event Cooperation with Generative Agents](https://arxiv.org/abs/2509.13011)
*Yuyang Tian,Shunqiang Mao,Wenchang Gao,Lanlan Qiu,Tianxing He*

Main category: cs.AI

TL;DR: MiniAgentPro是一个可视化平台，用于评估LLM代理在物理环境中的事件组织和协调能力，包含地图编辑器和模拟播放器，通过8个不同事件场景的测试集进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理社会模拟框架缺乏系统的事件组织评估和物理环境可视化集成，限制了代理在空间中导航和与现实物品交互的能力。

Method: 开发MiniAgentPro可视化平台，包含直观的地图编辑器用于定制环境，以及带有流畅动画的模拟播放器。基于该工具构建包含8个不同事件场景（基础版和困难版变体）的综合测试集。

Result: 使用GPT-4o进行评估显示，在基础设置中表现强劲，但在困难变体中突显了协调挑战。

Conclusion: MiniAgentPro平台有效解决了现有框架在物理环境集成和系统评估方面的不足，为LLM代理的社会模拟提供了更全面的测试环境。

Abstract: Large Language Models (LLMs) have revolutionized the simulation of agent
societies, enabling autonomous planning, memory formation, and social
interactions. However, existing frameworks often overlook systematic
evaluations for event organization and lack visualized integration with
physically grounded environments, limiting agents' ability to navigate spaces
and interact with items realistically. We develop MiniAgentPro, a visualization
platform featuring an intuitive map editor for customizing environments and a
simulation player with smooth animations. Based on this tool, we introduce a
comprehensive test set comprising eight diverse event scenarios with basic and
hard variants to assess agents' ability. Evaluations using GPT-4o demonstrate
strong performance in basic settings but highlight coordination challenges in
hard variants.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Don't Change My View: Ideological Bias Auditing in Large Language Models](https://arxiv.org/abs/2509.12652)
*Paul Kröger,Emilio Barkett*

Main category: cs.CL

TL;DR: 这篇论文提出了一种检测大语言模型意识形态偏向的统计方法，适用于审计专有黑盒系统。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在产品中的普及，其输出可能影响公众意见。如果模型能够被偶然地向特定意识形态偏向，控制者将获得不成比例的影响力。需要检测这种偏向尝试。

Method: 采用模型无关的统计方法，通过分析模型在与特定主题相关提示下输出的分布移动来识别意识形态偏向，无需访问模型内部结构。

Result: 通过一系列实验验证了该方法的实际应用性，证明其能够支持对LLM行为的独立后置审计。

Conclusion: 该方法为检测大语言模型的意识形态偏向提供了一种可行的统计方法，尤其适用于审计专有黑盒系统，有助于维护公共议程的公正性。

Abstract: As large language models (LLMs) become increasingly embedded in products used
by millions, their outputs may influence individual beliefs and, cumulatively,
shape public opinion. If the behavior of LLMs can be intentionally steered
toward specific ideological positions, such as political or religious views,
then those who control these systems could gain disproportionate influence over
public discourse. Although it remains an open question whether LLMs can
reliably be guided toward coherent ideological stances and whether such
steering can be effectively prevented, a crucial first step is to develop
methods for detecting when such steering attempts occur. In this work, we adapt
a previously proposed statistical method to the new context of ideological bias
auditing. Our approach carries over the model-agnostic design of the original
framework, which does not require access to the internals of the language
model. Instead, it identifies potential ideological steering by analyzing
distributional shifts in model outputs across prompts that are thematically
related to a chosen topic. This design makes the method particularly suitable
for auditing proprietary black-box systems. We validate our approach through a
series of experiments, demonstrating its practical applicability and its
potential to support independent post hoc audits of LLM behavior.

</details>


### [15] [HistoryBankQA: Multilingual Temporal Question Answering on Historical Events](https://arxiv.org/abs/2509.12720)
*Biswadip Mandal,Anant Khandelwal,Manish Gupta*

Main category: cs.CL

TL;DR: HistoryBank是一个包含1000多万个历史事件的多语言数据库，来自维基百科时间线页面和信息框，涵盖10种语言，并构建了全面的时间推理问答基准来评估大语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 现有时间推理数据集规模有限、缺乏多语言覆盖且主要关注当代事件，需要更全面的资源来评估大语言模型在历史事件时间推理方面的能力。

Method: 从维基百科时间线页面和文章信息框中提取历史事件，构建包含10M+事件的多语言数据库，并设计涵盖6种时间QA推理任务的基准测试。

Result: GPT4o在所有答案类型和语言中表现最佳；Gemma-2在小型语言模型中表现最优。数据库提供了前所未有的历史深度和语言广度覆盖。

Conclusion: HistoryBank为推进多语言和时间感知的历史事件自然语言理解提供了全面资源，将促进相关研究的进一步发展。

Abstract: Temporal reasoning about historical events is a critical skill for NLP tasks
like event extraction, historical entity linking, temporal question answering,
timeline summarization, temporal event clustering and temporal natural language
inference. Yet efforts on benchmarking temporal reasoning capabilities of large
language models (LLMs) are rather limited. Existing temporal reasoning datasets
are limited in scale, lack multilingual coverage and focus more on contemporary
events. To address these limitations, we present HistoryBank, a multilingual
database of 10M+ historical events extracted from Wikipedia timeline pages and
article infoboxes. Our database provides unprecedented coverage in both
historical depth and linguistic breadth with 10 languages. Additionally, we
construct a comprehensive question answering benchmark for temporal reasoning
across all languages. This benchmark covers a diverse set of 6 temporal QA
reasoning tasks, and we evaluate a suite of popular language models
(LLaMA-3-8B, Mistral-7B, Gemma-2-9b, Qwen3-8B, GPT4o) to assess their
performance on these tasks. As expected GPT4o performs best across all answer
types and languages; Gemma-2 outperforms the other small language models. Our
work aims to provide a comprehensive resource for advancing multilingual and
temporally-aware natural language understanding of historical events. To
facilitate further research, we will make our code and datasets publicly
available upon acceptance of this paper.

</details>


### [16] [Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents](https://arxiv.org/abs/2509.12876)
*Fuyu Xing,Zimu Wang,Wei Wang,Haiyang Zhang*

Main category: cs.CL

TL;DR: 对DeepSeek-VL2和Qwen-VL系列LVLM模型在M2E2数据集上的首次系统性评估，发现在少样本提示和微调设置下，模型在视觉任务表现良好但文本任务困难，微调能显著提升性能，多模态结合展现强协同效应


<details>
  <summary>Details</summary>
Motivation: 多媒体内容的激增需要有效的多媒体事件抽取系统，但大型视觉语言模型在M2E2任务中的应用潜力尚未被充分探索

Method: 在M2E2数据集上评估代表性LVLM模型，包括文本、图像和跨媒体子任务，采用少样本提示和LoRA微调两种设置

Result: 少样本LVLM在视觉任务表现更好但文本任务困难；LoRA微调显著提升性能；多模态结合展现强协同效应，在跨模态设置中达到最优性能

Conclusion: 研究揭示了LVLM在M2E2任务中的潜力和局限性，指出了语义精度、定位和跨模态基础等持续挑战，为推进M2E2能力提供了重要见解

Abstract: The proliferation of multimedia content necessitates the development of
effective Multimedia Event Extraction (M2E2) systems. Though Large
Vision-Language Models (LVLMs) have shown strong cross-modal capabilities,
their utility in the M2E2 task remains underexplored. In this paper, we present
the first systematic evaluation of representative LVLMs, including DeepSeek-VL2
and the Qwen-VL series, on the M2E2 dataset. Our evaluations cover text-only,
image-only, and cross-media subtasks, assessed under both few-shot prompting
and fine-tuning settings. Our key findings highlight the following valuable
insights: (1) Few-shot LVLMs perform notably better on visual tasks but
struggle significantly with textual tasks; (2) Fine-tuning LVLMs with LoRA
substantially enhances model performance; and (3) LVLMs exhibit strong synergy
when combining modalities, achieving superior performance in cross-modal
settings. We further provide a detailed error analysis to reveal persistent
challenges in areas such as semantic precision, localization, and cross-modal
grounding, which remain critical obstacles for advancing M2E2 capabilities.

</details>


### [17] [Multi-Model Synthetic Training for Mission-Critical Small Language Models](https://arxiv.org/abs/2509.13047)
*Nolan Platt,Pragyansmita Nayak*

Main category: cs.CL

TL;DR: 使用LLMs作为一次性教师生成合成数据，而非直接推理，实现了261倍成本降低，使小型模型在专业领域达到与大模型相似的准确率


<details>
  <summary>Details</summary>
Motivation: 解决专业领域训练数据稀缺和复杂性问题，降低大语言模型在专业应用中的高昂推理成本

Method: 利用GPT-4o和o3-mini多模型生成32亿条AIS船舶跟踪记录的21,543个合成问答对，防止过拟合并确保准确推理，然后微调Qwen2.5-7B模型

Result: 微调后的模型在海事任务上达到75%准确率，相比使用更大模型进行推理成本大幅降低

Conclusion: 通过合成数据生成和适当微调，小型廉价模型可以在专业领域提供与昂贵大模型相似的准确性，为手动标注不可行的领域提供了可复现框架

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
many domains, yet their application to specialized fields remains constrained
by the scarcity and complexity of domain-specific training data. We present a
novel approach that achieves a 261x cost reduction for maritime intelligence by
using LLMs as one-time teachers rather than using them directly for inference.
Our method transforms 3.2 billion Automatic Identification System (AIS) vessel
tracking records into 21,543 synthetic question and answer pairs through
multi-model generation (GPT-4o and o3-mini), preventing overfitting and
ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves
75% accuracy on maritime tasks, while being substantially cheaper than using a
larger model for inference. We show that smaller, cheaper models -- when fine
tuned properly -- can provide similar accuracy compared to larger models that
are prohibitively expensive. Our work contributes to the growing field of
synthetic dataset generation for specialized AI applications and presents a
highly reproducible framework for domains where manual annotation is
infeasible. Beyond expanding research in the growing field of specialized small
language models, our approach has immediate applications in maritime safety,
security operations, and vessel traffic management systems in various
industries.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems](https://arxiv.org/abs/2509.12390)
*Evangelos Psomiadis,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 提出基于事件触发的分布式编队控制器，通过距离测量实现多智能体系统编队控制，仅在测量误差超过阈值时更新控制，显著减少控制资源消耗


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在有限资源条件下的编队控制问题，减少不必要的控制更新以节省资源

Method: 分布式事件触发编队控制器，基于智能体间距离测量，当测量误差超过预设阈值时触发控制更新

Result: 通过仿真和实物实验验证，事件触发方法显著减少控制工作量，同时保持编队性能

Conclusion: 事件触发策略相比周期性触发策略能有效节省控制资源，在保证系统稳定性的同时提高资源利用效率

Abstract: This paper addresses the problem of collaborative formation control for
multi-agent systems with limited resources. We consider a team of robots tasked
with achieving a desired formation from arbitrary initial configurations. To
reduce unnecessary control updates and conserve resources, we propose a
distributed event-triggered formation controller that relies on inter-agent
distance measurements. Control updates are triggered only when the measurement
error exceeds a predefined threshold, ensuring system stability. The proposed
controller is validated through extensive simulations and real-world
experiments involving different formations, communication topologies,
scalability tests, and variations in design parameters, while also being
compared against periodic triggering strategies. Results demonstrate that the
event-triggered approach significantly reduces control efforts while preserving
formation performance.

</details>


### [19] [Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.12458)
*Àlmos Veres-Vitàlyos,Genis Castillo Gomez-Raya,Filip Lemic,Daniel Johannes Bugelnig,Bernhard Rinner,Sergi Abadal,Xavier Costa-Pérez*

Main category: cs.RO

TL;DR: 使用超轻垂直起飞器实现自主高精度3D重建的新系统架构，通过双重建流水线和动态轨迹调整提升扫描质量


<details>
  <summary>Details</summary>
Motivation: 解决轻型无人机在负载和自主性方面的限制，以支持复杂任务如高质量3D重建

Method: 双重建流水线系统：近实时SfM点云生成与动态轨迹调整形成反馈循环，非实时N3DR管道结合SfM和UWB数据进行精确重建

Result: 动态轨迹调整在单机和多机配置中均能持续提升重建质量，超过100克的Crazyflie 2.1无人机成功实现高保真扫描

Conclusion: 该系统为小型化无人机提供了可扩展的自主解决方案，开启了在空间受限环境中进行细粒度3D重建的新可能性

Abstract: Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for
navigating indoor and hard-to-reach areas, yet their significant constraints in
payload and autonomy have largely prevented their use for complex tasks like
high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we
introduce a novel system architecture that enables fully autonomous,
high-fidelity 3D scanning of static objects using UAVs weighing under 100
grams. Our core innovation lies in a dual-reconstruction pipeline that creates
a real-time feedback loop between data capture and flight control. A
near-real-time (near-RT) process uses Structure from Motion (SfM) to generate
an instantaneous pointcloud of the object. The system analyzes the model
quality on the fly and dynamically adapts the UAV's trajectory to intelligently
capture new images of poorly covered areas. This ensures comprehensive data
acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline
employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR)
approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB)
location data to achieve superior accuracy. We implemented and validated this
architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both
single- and multi-UAV configurations, conclusively show that dynamic trajectory
adaptation consistently improves reconstruction quality over static flight
paths. This work demonstrates a scalable and autonomous solution that unlocks
the potential of miniaturized UAVs for fine-grained 3D reconstruction in
constrained environments, a capability previously limited to much larger
platforms.

</details>


### [20] [Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins](https://arxiv.org/abs/2509.12982)
*Erblin Isaku,Hassan Sartaj,Shaukat Ali,Beatriz Sanguino,Tongtong Wang,Guoyuan Li,Houxiang Zhang,Thomas Peyrucain*

Main category: cs.RO

TL;DR: ODiSAR是一个基于数字孪生的OOD检测方法，使用Transformer模型预测机器人状态，结合重构误差和蒙特卡洛dropout进行不确定性量化，在工业机器人导航任务中实现了高达98%的检测性能。


<details>
  <summary>Details</summary>
Motivation: 复杂不确定环境中的自适应机器人需要主动检测和处理异常行为（包括分布外情况），数字孪生技术为此提供了有价值的解决方案。

Method: 使用基于Transformer的数字孪生预测机器人状态，采用重构误差和蒙特卡洛dropout进行不确定性量化，结合重构误差和预测方差来检测OOD行为，并包含可解释性层关联特定状态。

Result: 在两个工业机器人案例（办公室导航和海上船舶导航）中，ODiSAR实现了高达98% AUROC、96% TNR@TPR95和95% F1-score的检测性能，同时提供可解释的见解。

Conclusion: ODiSAR方法能够有效检测自适应机器人的分布外行为，即使在未见过的条件下也能工作良好，并为自我适应提供支持。

Abstract: Self-adaptive robots (SARs) in complex, uncertain environments must
proactively detect and address abnormal behaviors, including
out-of-distribution (OOD) cases. To this end, digital twins offer a valuable
solution for OOD detection. Thus, we present a digital twin-based approach for
OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to
forecast SAR states and employs reconstruction error and Monte Carlo dropout
for uncertainty quantification. By combining reconstruction error with
predictive variance, the digital twin effectively detects OOD behaviors, even
in previously unseen conditions. The digital twin also includes an
explainability layer that links potential OOD to specific SAR states, offering
insights for self-adaptation. We evaluated ODiSAR by creating digital twins of
two industrial robots: one navigating an office environment, and another
performing maritime ship navigation. In both cases, ODiSAR forecasts SAR
behaviors (i.e., robot trajectories and vessel motion) and proactively detects
OOD events. Our results showed that ODiSAR achieved high detection performance
-- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing
interpretable insights to support self-adaptation.

</details>


### [21] [TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving](https://arxiv.org/abs/2509.13164)
*Jiawei Wang,Haowei Sun,Xintao Yan,Shuo Feng,Jun Gao,Henry X. Liu*

Main category: cs.RO

TL;DR: TeraSim-World是一个自动化管道，用于在全球任何地方合成逼真且地理多样化的安全关键数据，用于端到端自动驾驶的训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶数据主要来自模拟器（存在显著的模拟到真实差距）或道路测试（成本高且不安全），需要一种能够生成大规模、多样化安全关键数据的方法。

Method: 从任意位置检索真实世界地图和交通需求，模拟自然驾驶数据集中的智能体行为，编排多样化逆境创建极端情况，并基于街景实现逼真的地理接地传感器渲染。

Result: 通过桥接智能体和传感器模拟，提供了一个可扩展的关键数据合成框架。

Conclusion: TeraSim-World为端到端自动驾驶系统的训练和评估提供了安全、可扩展的数据合成解决方案。

Abstract: Safe and scalable deployment of end-to-end (E2E) autonomous driving requires
extensive and diverse data, particularly safety-critical events. Existing data
are mostly generated from simulators with a significant sim-to-real gap or
collected from on-road testing that is costly and unsafe. This paper presents
TeraSim-World, an automated pipeline that synthesizes realistic and
geographically diverse safety-critical data for E2E autonomous driving at
anywhere in the world. Starting from an arbitrary location, TeraSim-World
retrieves real-world maps and traffic demand from geospatial data sources.
Then, it simulates agent behaviors from naturalistic driving datasets, and
orchestrates diverse adversities to create corner cases. Informed by street
views of the same location, it achieves photorealistic, geographically grounded
sensor rendering via the frontier video generation model Cosmos-Drive. By
bridging agent and sensor simulations, TeraSim-World provides a scalable and
critical~data synthesis framework for training and evaluation of E2E autonomous
driving systems.

</details>
