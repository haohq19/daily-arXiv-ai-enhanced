<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Density Estimation and Crowd Counting](https://arxiv.org/abs/2511.09723)
*Balachandra Devarangadi Sunil,Rakshith Venkatesh,Shantanu Todmal*

Main category: cs.CV

TL;DR: 将图像人群密度估计算法改进为视频版本，通过扩散模型生成高质量密度图，结合事件驱动采样减少计算量，在密集和稀疏场景下都能有效捕捉人群动态。


<details>
  <summary>Details</summary>
Motivation: 解决视频分析中特有的时序挑战，为公共安全、灾害响应和事件管理等实时人群监控应用提供可扩展的高效框架。

Method: 集成去噪概率模型使用扩散过程生成密度图，采用窄高斯核和多密度图输出，结合回归分支进行特征提取，通过相似度评分整合结果，引入基于Farneback光流算法的事件驱动采样技术。

Result: 通过定性和定量评估（包括叠加图和平均绝对误差），模型在密集和稀疏场景下都能有效捕捉人群动态，采样方法能显著减少帧数同时保持关键人群事件。

Conclusion: 该工作成功解决了视频分析中的时序挑战，为实时人群监控提供了可扩展且高效的解决方案。

Abstract: This study enhances a crowd density estimation algorithm originally designed for image-based analysis by adapting it for video-based scenarios. The proposed method integrates a denoising probabilistic model that utilizes diffusion processes to generate high-quality crowd density maps. To improve accuracy, narrow Gaussian kernels are employed, and multiple density map outputs are generated. A regression branch is incorporated into the model for precise feature extraction, while a consolidation mechanism combines these maps based on similarity scores to produce a robust final result. An event-driven sampling technique, utilizing the Farneback optical flow algorithm, is introduced to selectively capture frames showing significant crowd movements, reducing computational load and storage by focusing on critical crowd dynamics. Through qualitative and quantitative evaluations, including overlay plots and Mean Absolute Error (MAE), the model demonstrates its ability to effectively capture crowd dynamics in both dense and sparse settings. The efficiency of the sampling method is further assessed, showcasing its capability to decrease frame counts while maintaining essential crowd events. By addressing the temporal challenges unique to video analysis, this work offers a scalable and efficient framework for real-time crowd monitoring in applications such as public safety, disaster response, and event management.

</details>


### [2] [Explicit Temporal-Semantic Modeling for Dense Video Captioning via Context-Aware Cross-Modal Interaction](https://arxiv.org/abs/2511.10134)
*Mingda Jia,Weiliang Meng,Zenghuang Fu,Yiheng Li,Qi Zeng,Yifan Zhang,Ju Xin,Rongtao Xu,Jiguang Zhang,Xiaopeng Zhang*

Main category: cs.CV

TL;DR: 提出了CACMI框架，通过显式建模视频的时序连贯性和语义上下文，解决密集视频描述中事件序列时序一致性和视觉上下文语义理解不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集视频描述方法依赖隐式建模，使用帧级或碎片化视频特征，无法捕捉事件序列的时序连贯性和视觉上下文的全面语义。

Method: CACMI框架包含两个核心组件：跨模态帧聚合通过跨模态检索聚合相关帧提取时序连贯的事件对齐文本特征；上下文感知特征增强利用查询引导注意力整合视觉动态与伪事件语义。

Result: 在ActivityNet Captions和YouCook2数据集上的实验表明，CACMI在密集视频描述任务上达到了最先进的性能。

Conclusion: CACMI通过显式建模时序语义特征，有效提升了密集视频描述的性能，证明了利用视频潜在时序特性和文本语料库语言语义的重要性。

Abstract: Dense video captioning jointly localizes and captions salient events in untrimmed videos. Recent methods primarily focus on leveraging additional prior knowledge and advanced multi-task architectures to achieve competitive performance. However, these pipelines rely on implicit modeling that uses frame-level or fragmented video features, failing to capture the temporal coherence across event sequences and comprehensive semantics within visual contexts. To address this, we propose an explicit temporal-semantic modeling framework called Context-Aware Cross-Modal Interaction (CACMI), which leverages both latent temporal characteristics within videos and linguistic semantics from text corpus. Specifically, our model consists of two core components: Cross-modal Frame Aggregation aggregates relevant frames to extract temporally coherent, event-aligned textual features through cross-modal retrieval; and Context-aware Feature Enhancement utilizes query-guided attention to integrate visual dynamics with pseudo-event semantics. Extensive experiments on the ActivityNet Captions and YouCook2 datasets demonstrate that CACMI achieves the state-of-the-art performance on dense video captioning task.

</details>


### [3] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 本文研究了不同参数规模（500M和2.2B）的SmolVLM2模型在盲人和低视力用户视频描述任务中的性能表现，提出了专门的可访问性评估框架，并在智能手机上测试了不同精度变体的实际性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然能生成高质量视频描述，但其高内存、计算和部署需求限制了实际应用，特别是对依赖详细上下文感知描述的盲人和低视力用户群体。

Method: 在两个多样化数据集（AVCaps户外和Charades室内）上评估SmolVLM2变体；引入两个新颖的BLV可访问性评估框架：多上下文BLV框架和导航辅助框架；系统评估四种提示设计策略；在智能手机上部署FP32和INT8精度变体。

Result: 通过专门的评估框架对模型在空间定位、社交互动、动作事件、环境氛围等上下文信息生成能力进行量化评估，并测试了在资源受限移动设备上的实际性能约束。

Conclusion: 研究表明较小参数规模的模型在保持描述质量的同时，能够更好地满足盲人和低视力用户在移动设备上的实际使用需求，为可访问性AI应用提供了实用解决方案。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [4] [Learning to Tell Apart: Weakly Supervised Video Anomaly Detection via Disentangled Semantic Alignment](https://arxiv.org/abs/2511.10334)
*Wenti Yin,Huaxin Zhang,Xiang Wang,Yuqing Lu,Yicheng Zhang,Bingquan Gong,Jialong Zuo,Li Yu,Changxin Gao,Nong Sang*

Main category: cs.CV

TL;DR: 提出DSANet网络，通过粗粒度和细粒度特征分离来改进弱监督视频异常检测，在XD-Violence和UCF-Crime基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法倾向于检测最显著响应片段，忽视挖掘与异常分离的多样正常模式，且由于相似外观容易产生类别混淆，导致细粒度分类结果不理想。

Method: 粗粒度：自引导正常性建模分支，在学习的正常原型指导下重构输入视频特征；细粒度：解耦对比语义对齐机制，将视频分解为事件中心和背景中心组件，应用视觉语言对比学习。

Result: 在XD-Violence和UCF-Crime两个标准基准上的综合实验表明，DSANet优于现有最先进方法。

Conclusion: DSANet通过显式分离异常和正常特征，从粗粒度和细粒度层面增强可区分性，有效解决了现有方法的局限性。

Abstract: Recent advancements in weakly-supervised video anomaly detection have achieved remarkable performance by applying the multiple instance learning paradigm based on multimodal foundation models such as CLIP to highlight anomalous instances and classify categories. However, their objectives may tend to detect the most salient response segments, while neglecting to mine diverse normal patterns separated from anomalies, and are prone to category confusion due to similar appearance, leading to unsatisfactory fine-grained classification results. Therefore, we propose a novel Disentangled Semantic Alignment Network (DSANet) to explicitly separate abnormal and normal features from coarse-grained and fine-grained aspects, enhancing the distinguishability. Specifically, at the coarse-grained level, we introduce a self-guided normality modeling branch that reconstructs input video features under the guidance of learned normal prototypes, encouraging the model to exploit normality cues inherent in the video, thereby improving the temporal separation of normal patterns and anomalous events. At the fine-grained level, we present a decoupled contrastive semantic alignment mechanism, which first temporally decomposes each video into event-centric and background-centric components using frame-level anomaly scores and then applies visual-language contrastive learning to enhance class-discriminative representations. Comprehensive experiments on two standard benchmarks, namely XD-Violence and UCF-Crime, demonstrate that DSANet outperforms existing state-of-the-art methods.

</details>


### [5] [Fragile by Design: On the Limits of Adversarial Defenses in Personalized Generation](https://arxiv.org/abs/2511.10382)
*Zhen Chen,Yi Zhang,Xiangyu Yin,Chengxuan Qin,Xingyu Zhao,Xiaowei Huang,Wenjie Ruan*

Main category: cs.CV

TL;DR: 现有防御方法（如Anti-DreamBooth）存在两个关键缺陷：对抗样本有明显可见的人工痕迹，且易被简单图像过滤去除，导致用户身份泄露风险依然存在。


<details>
  <summary>Details</summary>
Motivation: 个性化AI应用如DreamBooth存在面部身份泄露的隐私风险，现有防御方法效果有限，需要更有效的保护机制。

Method: 提出了AntiDB_Purify评估框架，系统评估现有防御方法在传统图像过滤和对抗净化威胁下的有效性。

Result: 结果显示当前所有防御方法在净化威胁下都失去了保护效果，无法有效防止用户身份泄露。

Conclusion: 当前防御方法提供的是虚假安全感，迫切需要开发更隐蔽和鲁棒的保护机制来保障个性化生成中的用户身份安全。

Abstract: Personalized AI applications such as DreamBooth enable the generation of customized content from user images, but also raise significant privacy concerns, particularly the risk of facial identity leakage. Recent defense mechanisms like Anti-DreamBooth attempt to mitigate this risk by injecting adversarial perturbations into user photos to prevent successful personalization. However, we identify two critical yet overlooked limitations of these methods. First, the adversarial examples often exhibit perceptible artifacts such as conspicuous patterns or stripes, making them easily detectable as manipulated content. Second, the perturbations are highly fragile, as even a simple, non-learned filter can effectively remove them, thereby restoring the model's ability to memorize and reproduce user identity. To investigate this vulnerability, we propose a novel evaluation framework, AntiDB_Purify, to systematically evaluate existing defenses under realistic purification threats, including both traditional image filters and adversarial purification. Results reveal that none of the current methods maintains their protective effectiveness under such threats. These findings highlight that current defenses offer a false sense of security and underscore the urgent need for more imperceptible and robust protections to safeguard user identity in personalized generation.

</details>


### [6] [RodEpil: A Video Dataset of Laboratory Rodents for Seizure Detection and Benchmark Evaluation](https://arxiv.org/abs/2511.10431)
*Daniele Perlo,Vladimir Despotovic,Selma Boudissa,Sang-Yoon Kim,Petr Nazarov,Yanrong Zhang,Max Wintermark,Olivier Keunen*

Main category: cs.CV

TL;DR: 本文介绍了RodEpil数据集，这是一个用于自动检测啮齿类动物惊厥发作的精选视频数据集，包含10,101个阴性样本和2,952个阳性样本，使用TimeSformer架构实现了97%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 为临床前癫痫研究开发非侵入性、基于视频的监测方法，需要高质量的标注数据集来支持自动惊厥事件检测算法的开发。

Method: 收集了实验室啮齿类动物的俯视图和侧视图短视频片段，采用严格的受试者划分五折交叉验证，使用基于Transformer的视频分类器TimeSformer进行基线实验。

Result: TimeSformer架构能够区分惊厥发作和正常活动，平均F1分数达到97%，数据集和基线代码已公开发布。

Conclusion: RodEpil数据集为临床前癫痫研究的可重复研究提供了支持，证明了基于视频的非侵入性监测在惊厥检测中的有效性。

Abstract: We introduce a curated video dataset of laboratory rodents for automatic detection of convulsive events. The dataset contains short (10~s) top-down and side-view video clips of individual rodents, labeled at clip level as normal activity or seizure. It includes 10,101 negative samples and 2,952 positive samples collected from 19 subjects. We describe the data curation, annotation protocol and preprocessing pipeline, and report baseline experiments using a transformer-based video classifier (TimeSformer). Experiments employ five-fold cross-validation with strict subject-wise partitioning to prevent data leakage (no subject appears in more than one fold). Results show that the TimeSformer architecture enables discrimination between seizure and normal activity with an average F1-score of 97%. The dataset and baseline code are publicly released to support reproducible research on non-invasive, video-based monitoring in preclinical epilepsy research. RodEpil Dataset access - DOI: 10.5281/zenodo.17601357

</details>


### [7] [Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes](https://arxiv.org/abs/2511.10484)
*Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T. S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers*

Main category: cs.CV

TL;DR: 本文提出了一种全自动方法，使用深度学习模型分割胰腺并检测胰腺表面分叶度(PSL)，发现PSL在糖尿病患者中显著增高，可用于2型糖尿病筛查和早期预测。


<details>
  <summary>Details</summary>
Motivation: 2型糖尿病早期检测很重要，但胰腺表面分叶度在糖尿病患者中的作用尚未充分研究。本文旨在开发自动化方法来检测PSL并用于糖尿病筛查。

Method: 使用四种深度学习模型在584名患者数据集上分割胰腺，自动检测PSL，并建立多变量模型使用CT生物标志物预测2型糖尿病。

Result: 糖尿病患者PSL显著高于非糖尿病患者(4.26±8.32 vs 3.19±3.62, p=0.01)。PancAP模型达到最高Dice分数0.79±0.17和最低ASSD误差1.94±2.63mm。预测模型获得0.90 AUC、66.7%敏感性和91.9%特异性。

Conclusion: PSL对2型糖尿病筛查有用，可能有助于预测2型糖尿病的早期发病。

Abstract: Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that affects millions of people worldwide. Early detection is crucial as it can alter pancreas function through morphological changes and increased deposition of ectopic fat, eventually leading to organ damage. While studies have shown an association between T2DM and pancreas volume and fat content, the role of increased pancreatic surface lobularity (PSL) in patients with T2DM has not been fully investigated. In this pilot work, we propose a fully automated approach to delineate the pancreas and other abdominal structures, derive CT imaging biomarkers, and opportunistically screen for T2DM. Four deep learning-based models were used to segment the pancreas in an internal dataset of 584 patients (297 males, 437 non-diabetic, age: 45$\pm$15 years). PSL was automatically detected and it was higher for diabetic patients (p=0.01) at 4.26 $\pm$ 8.32 compared to 3.19 $\pm$ 3.62 for non-diabetic patients. The PancAP model achieved the highest Dice score of 0.79 $\pm$ 0.17 and lowest ASSD error of 1.94 $\pm$ 2.63 mm (p$<$0.05). For predicting T2DM, a multivariate model trained with CT biomarkers attained 0.90 AUC, 66.7\% sensitivity, and 91.9\% specificity. Our results suggest that PSL is useful for T2DM screening and could potentially help predict the early onset of T2DM.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization](https://arxiv.org/abs/2511.09578)
*Hadi Keramati,Morteza Sadeghi,Rajeev K. Jaiman*

Main category: cs.LG

TL;DR: 提出基于引导去噪扩散概率模型的生成优化框架，利用代理梯度生成最小化压降且保持表面温度低于阈值的热沉设计。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒优化方法（如CMA-ES）在热沉设计中效率有限，且拓扑优化方法在新约束下需要重新训练。需要开发可扩展、计算高效的热沉生成方法。

Method: 使用边界表示法表示多翅片几何结构，采用多保真度方法生成训练数据。训练DDPM生成热沉几何，并训练两个残差神经网络预测压降和表面温度。利用代理梯度引导几何生成过程满足约束条件。

Result: 引导扩散模型生成的热沉样本比传统黑盒优化方法获得的最低压降还要低10%。

Conclusion: 该方法为构建电子冷却基础生成模型迈出了重要一步，具有可扩展性和计算效率优势。

Abstract: This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.

</details>


### [9] [History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754)
*Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa*

Main category: cs.LG

TL;DR: 提出了一种基于宏观情境检索的金融预测框架，通过在历史相似宏观经济情境中检索类比来增强预测的鲁棒性，解决金融市场的非平稳性问题。


<details>
  <summary>Details</summary>
Motivation: 金融市场具有内在非平稳性，结构断裂和宏观经济体制转变常导致预测模型在分布外部署时失效。传统多模态方法简单融合数值指标和文本情感，难以适应这种变化。

Method: 引入宏观情境检索框架，将宏观指标（CPI、失业率、收益率利差、GDP增长等）和金融新闻情感共同嵌入共享相似性空间，在推理过程中因果检索历史相似经济体制作为预测依据，无需重新训练。

Result: 在17年标普500数据上训练，并在AAPL和XOM上分布外评估，显著缩小了CV到OOD性能差距。宏观条件检索实现了唯一正收益的交易结果（AAPL：PF=1.18，夏普比率=0.95；XOM：PF=1.16，夏普比率=0.61），而静态数值、纯文本和朴素多模态基线在体制转变下均失效。

Conclusion: 通过操作化"金融历史不会重演但常押韵"的原则，证明宏观感知检索能在分布变化下产生稳健、可解释的预测，检索到的邻居形成可解释的证据链，对应可识别的宏观情境（如通胀或收益率曲线倒挂阶段），支持因果可解释性和透明度。

Abstract: Financial markets are inherently non-stationary: structural breaks and macroeconomic regime shifts often cause forecasting models to fail when deployed out of distribution (OOD). Conventional multimodal approaches that simply fuse numerical indicators and textual sentiment rarely adapt to such shifts. We introduce macro-contextual retrieval, a retrieval-augmented forecasting framework that grounds each prediction in historically analogous macroeconomic regimes. The method jointly embeds macro indicators (e.g., CPI, unemployment, yield spread, GDP growth) and financial news sentiment in a shared similarity space, enabling causal retrieval of precedent periods during inference without retraining.
  Trained on seventeen years of S&P 500 data (2007-2023) and evaluated OOD on AAPL (2024) and XOM (2024), the framework consistently narrows the CV to OOD performance gap. Macro-conditioned retrieval achieves the only positive out-of-sample trading outcomes (AAPL: PF=1.18, Sharpe=0.95; XOM: PF=1.16, Sharpe=0.61), while static numeric, text-only, and naive multimodal baselines collapse under regime shifts. Beyond metric gains, retrieved neighbors form interpretable evidence chains that correspond to recognizable macro contexts, such as inflationary or yield-curve inversion phases, supporting causal interpretability and transparency. By operationalizing the principle that "financial history may not repeat, but it often rhymes," this work demonstrates that macro-aware retrieval yields robust, explainable forecasts under distributional change.
  All datasets, models, and source code are publicly available.

</details>


### [10] [NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG](https://arxiv.org/abs/2511.09773)
*Mahdi Samaee,Mehran Yazdi,Daniel Massicotte*

Main category: cs.LG

TL;DR: NeuroLingua是一个受语言启发的睡眠分期框架，将睡眠视为结构化生理语言，通过CNN分词器和双级Transformer实现层次化时序建模，结合GCN进行多模态EEG/EOG融合，在Sleep-EDF和ISRUC数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有自动睡眠分期方法缺乏表达性时序层次结构、多模态EEG和EOG融合困难以及深度学习模型可解释性有限的问题。

Method: 将30秒epoch分解为3秒重叠子窗口作为"token"，使用CNN分词器和双级Transformer（段内编码和跨7个epoch的段间集成），通过图卷积网络融合EEG和EOG模态特征。

Result: 在Sleep-EDF数据集上达到85.3%准确率、0.800宏F1和0.796 Cohen's kappa；在ISRUC数据集上达到81.9%准确率、0.802宏F1和0.755 kappa，匹配或超越现有基准。

Conclusion: 通过将睡眠框架化为组合语言，NeuroLingua统一了层次序列建模和多模态融合，为睡眠研究中的可解释性、可解释性和因果推理提供了基础，推动自动睡眠分期向更透明和临床有意义的应用发展。

Abstract: Automated sleep stage classification from polysomnography remains limited by the lack of expressive temporal hierarchies, challenges in multimodal EEG and EOG fusion, and the limited interpretability of deep learning models. We propose NeuroLingua, a language-inspired framework that conceptualizes sleep as a structured physiological language. Each 30-second epoch is decomposed into overlapping 3-second subwindows ("tokens") using a CNN-based tokenizer, enabling hierarchical temporal modeling through dual-level Transformers: intra-segment encoding of local dependencies and inter-segment integration across seven consecutive epochs (3.5 minutes) for extended context. Modality-specific embeddings from EEG and EOG channels are fused via a Graph Convolutional Network, facilitating robust multimodal integration. NeuroLingua is evaluated on the Sleep-EDF Expanded and ISRUC-Sleep datasets, achieving state-of-the-art results on Sleep-EDF (85.3% accuracy, 0.800 macro F1, and 0.796 Cohen's kappa) and competitive performance on ISRUC (81.9% accuracy, 0.802 macro F1, and 0.755 kappa), matching or exceeding published baselines in overall and per-class metrics. The architecture's attention mechanisms enhance the detection of clinically relevant sleep microevents, providing a principled foundation for future interpretability, explainability, and causal inference in sleep research. By framing sleep as a compositional language, NeuroLingua unifies hierarchical sequence modeling and multimodal fusion, advancing automated sleep staging toward more transparent and clinically meaningful applications.

</details>


### [11] [Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning](https://arxiv.org/abs/2511.09871)
*Hyung-Jun Moon,Sung-Bae Cho*

Main category: cs.LG

TL;DR: 提出了一种可扩展的双记忆网络方法，通过共享记忆和特定记忆的组合来解决持续学习中的任务隔离问题，实现了知识的高效整合和利用。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法强制神经网络孤立处理顺序任务，无法利用任务间有用关系，导致重复学习相似特征或过度差异化特征。

Method: 使用两个互补的可微分记忆：一个学习跨任务通用特征，另一个结合共享特征学习每个样本的判别性特征。通过记忆调整模块自适应修剪关键槽位并最小化扩展容量，使用正交正则化防止干扰。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上优于14种最先进方法，分别达到55.13%、37.24%和30.11%的最终准确率。

Conclusion: 该方法通过有效整合和利用知识，能够提高顺序任务的平均性能，产生的特征提取结果最接近上限，为持续学习设立了新的里程碑。

Abstract: Continual learning methods used to force neural networks to process sequential tasks in isolation, preventing them from leveraging useful inter-task relationships and causing them to repeatedly relearn similar features or overly differentiate them. To address this problem, we propose a fully differentiable, exemplar-free expandable method composed of two complementary memories: One learns common features that can be used across all tasks, and the other combines the shared features to learn discriminative characteristics unique to each sample. Both memories are differentiable so that the network can autonomously learn latent representations for each sample. For each task, the memory adjustment module adaptively prunes critical slots and minimally expands capacity to accommodate new concepts, and orthogonal regularization enforces geometric separation between preserved and newly learned memory components to prevent interference. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that the proposed method outperforms 14 state-of-the-art methods for class-incremental learning, achieving final accuracies of 55.13\%, 37.24\%, and 30.11\%, respectively. Additional analysis confirms that, through effective integration and utilization of knowledge, the proposed method can increase average performance across sequential tasks, and it produces feature extraction results closest to the upper bound, thus establishing a new milestone in continual learning.

</details>


### [12] [Towards Multiple Missing Values-resistant Unsupervised Graph Anomaly Detection](https://arxiv.org/abs/2511.09917)
*Jiazhen Chen,Xiuqin Liang,Sichao Fu,Zheng Ma,Weihua Ou*

Main category: cs.LG

TL;DR: 提出了M²V-UGAD框架，用于处理图数据中节点属性和结构同时缺失的无监督异常检测问题，通过双路径编码器防止跨视图干扰，并利用硬负样本缓解插补偏差。


<details>
  <summary>Details</summary>
Motivation: 现实图数据常存在节点属性和结构信息同时缺失的问题，传统插补方法会修复异常节点使其看起来正常，产生插补偏差，且缺失视图间的错误会相互传播，影响检测性能。

Method: 使用双路径编码器独立重构缺失的节点属性和图结构，在联合潜在空间中融合和正则化，使正常节点占据紧凑内流形，异常节点位于外表面，并通过采样潜在空间生成硬负样本来锐化决策边界。

Result: 在七个公共基准测试中，M²V-UGAD在不同缺失率下始终优于现有的无监督图异常检测方法。

Conclusion: 该框架有效解决了图数据多重缺失值下的异常检测问题，通过防止跨视图干扰和缓解插补偏差，显著提升了检测性能。

Abstract: Unsupervised graph anomaly detection (GAD) has received increasing attention in recent years, which aims to identify data anomalous patterns utilizing only unlabeled node information from graph-structured data. However, prevailing unsupervised GAD methods typically presuppose complete node attributes and structure information, a condition hardly satisfied in real-world scenarios owing to privacy, collection errors or dynamic node arrivals. Existing standard imputation schemes risk "repairing" rare anomalous nodes so that they appear normal, thereby introducing imputation bias into the detection process. In addition, when both node attributes and edges are missing simultaneously, estimation errors in one view can contaminate the other, causing cross-view interference that further undermines the detection performance. To overcome these challenges, we propose M$^2$V-UGAD, a multiple missing values-resistant unsupervised GAD framework on incomplete graphs. Specifically, a dual-pathway encoder is first proposed to independently reconstruct missing node attributes and graph structure, thereby preventing errors in one view from propagating to the other. The two pathways are then fused and regularized in a joint latent space so that normals occupy a compact inner manifold while anomalies reside on an outer shell. Lastly, to mitigate imputation bias, we sample latent codes just outside the normal region and decode them into realistic node features and subgraphs, providing hard negative examples that sharpen the decision boundary. Experiments on seven public benchmarks demonstrate that M$^2$V-UGAD consistently outperforms existing unsupervised GAD methods across varying missing rates.

</details>


### [13] [EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models](https://arxiv.org/abs/2511.09947)
*Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EEGAgent是一个基于大语言模型的通用EEG分析框架，能够调度多种工具自动完成脑电图相关任务，支持多任务和连续推理的脑电分析。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG模型通常针对特定任务设计，限制了在现实场景中的实用性，因为EEG分析往往涉及多任务和连续推理。

Method: 利用大语言模型来调度和规划多个工具，构建包含EEG预处理、特征提取、事件检测等功能的工具箱。

Result: 在公共数据集上评估了EEGAgent的能力，证明其能够支持灵活且可解释的EEG分析。

Conclusion: EEGAgent具有在现实世界临床应用中使用的潜力，为脑电分析提供了通用且可扩展的解决方案。

Abstract: Scalable and generalizable analysis of brain activity is essential for advancing both clinical diagnostics and cognitive research. Electroencephalography (EEG), a non-invasive modality with high temporal resolution, has been widely used for brain states analysis. However, most existing EEG models are usually tailored for individual specific tasks, limiting their utility in realistic scenarios where EEG analysis often involves multi-task and continuous reasoning. In this work, we introduce EEGAgent, a general-purpose framework that leverages large language models (LLMs) to schedule and plan multiple tools to automatically complete EEG-related tasks. EEGAgent is capable of performing the key functions: EEG basic information perception, spatiotemporal EEG exploration, EEG event detection, interaction with users, and EEG report generation. To realize these capabilities, we design a toolbox composed of different tools for EEG preprocessing, feature extraction, event detection, etc. These capabilities were evaluated on public datasets, and our EEGAgent can support flexible and interpretable EEG analysis, highlighting its potential for real-world clinical applications.

</details>


### [14] [BuddyMoE: Exploiting Expert Redundancy to Accelerate Memory-Constrained Mixture-of-Experts Inference](https://arxiv.org/abs/2511.10054)
*Yun Wang,Lingyun Yang,Senhao Yu,Yixiao Wang,Ruixing Li,Zhixiang Wei,James Yen,Zhengwei Qi*

Main category: cs.LG

TL;DR: MoE模型通过仅激活部分专家网络来减少计算量，但全参数集超出GPU内存容量。现有系统将非活跃专家卸载到CPU内存，但PCIe传输延迟高。预取启发式方法旨在隐藏延迟，但预取失败会导致显著延迟或模型精度下降。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型中因预取失败导致的推理延迟和模型精度下降问题，需要在保持高推理速度的同时维护模型准确性。

Method: 通过将非活跃专家卸载到CPU内存，并使用预取启发式方法来预测所需专家，但面临预取失败时的挑战。

Result: 预取失败时，现有方法要么导致PCIe传输延迟造成的长停滞，要么因跳过专家计算而显著降低模型精度。

Conclusion: 关键挑战是在预取失败时同时保持高推理速度和模型精度。

Abstract: Mixture-of-Experts (MoE) architectures scale language models by activating only a subset of specialized expert networks for each input token, thereby reducing the number of floating-point operations. However, the growing size of modern MoE models causes their full parameter sets to exceed GPU memory capacity; for example, Mixtral-8x7B has 45 billion parameters and requires 87 GB of memory even though only 14 billion parameters are used per token. Existing systems alleviate this limitation by offloading inactive experts to CPU memory, but transferring experts across the PCIe interconnect incurs significant latency (about 10 ms). Prefetching heuristics aim to hide this latency by predicting which experts are needed, but prefetch failures introduce significant stalls and amplify inference latency. In the event of a prefetch failure, prior work offers two primary solutions: either fetch the expert on demand, which incurs a long stall due to the PCIe bottleneck, or drop the expert from the computation, which significantly degrades model accuracy. The critical challenge, therefore, is to maintain both high inference speed and model accuracy when prefetching fails.

</details>


### [15] [How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders](https://arxiv.org/abs/2511.10094)
*Yiming Tang,Abhijeet Sinha,Dianbo Liu*

Main category: cs.LG

TL;DR: 提出Matryoshka Transcoders框架，用于自动发现和解释生成模型中的物理合理性特征，通过分层稀疏特征学习和多模态模型解释，识别物理相关的失败模式，并建立评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型虽然能产生逼真输出，但容易出现物理合理性错误，且现有评估方法难以检测这些错误，缺乏自动识别和解释物理错误模式的框架。

Method: 扩展Matryoshka表示学习范式到转码器架构，在物理合理性分类器的中间表示上进行训练，利用多模态模型进行解释，实现多粒度层次稀疏特征学习。

Result: 相比现有方法，实现了更好的特征相关性和准确性，识别出多样化的物理相关失败模式，无需手动特征工程，为八个先进生成模型提供了物理约束遵循失败的分析。

Conclusion: 该框架为生成模型的物理合理性评估提供了新基准，揭示了模型未能遵循物理约束的具体方式，为模型改进铺平了道路。

Abstract: Although recent generative models are remarkably capable of producing instruction-following and realistic outputs, they remain prone to notable physical plausibility failures. Though critical in applications, these physical plausibility errors often escape detection by existing evaluation methods. Furthermore, no framework exists for automatically identifying and interpreting specific physical error patterns in natural language, preventing targeted model improvements. We introduce Matryoshka Transcoders, a novel framework for the automatic discovery and interpretation of physical plausibility features in generative models. Our approach extends the Matryoshka representation learning paradigm to transcoder architectures, enabling hierarchical sparse feature learning at multiple granularity levels. By training on intermediate representations from a physical plausibility classifier and leveraging large multimodal models for interpretation, our method identifies diverse physics-related failure modes without manual feature engineering, achieving superior feature relevance and feature accuracy compared to existing approaches. We utilize the discovered visual patterns to establish a benchmark for evaluating physical plausibility in generative models. Our analysis of eight state-of-the-art generative models provides valuable insights into how these models fail to follow physical constraints, paving the way for further model improvements.

</details>


### [16] [Holonorm](https://arxiv.org/abs/2511.10504)
*Daryl Noupa Yongueng,Hamidou Tembine*

Main category: cs.LG

TL;DR: 提出了Holonorm作为Transformer中Tanh归一化的替代方案，解决了Tanh的正交性、线性和失真问题，具有残差连接和非线性特性，适合高维张量和向量。


<details>
  <summary>Details</summary>
Motivation: Tanh作为层归一化替代方案存在正交性、线性和失真问题，无法可靠使用，需要一种更好的归一化方法。

Method: 提出Holonorm，具有残差连接和非线性特性，保持信号的正交性、方向和可逆性，将向量映射到开放单位球内防止激活爆炸。

Result: Holonorm作为softsign函数的广义形式，适合作为归一化函数，在0到1之间定义，便于模型评估理解。

Conclusion: Holonorm是Transformer中有效的归一化方法，解决了Tanh的问题，提高了深度Transformer模型的稳定性。

Abstract: Normalization is a key point in transformer training . In Dynamic Tanh (DyT), the author demonstrated that Tanh can be used as an alternative layer normalization (LN) and confirmed the effectiveness of the idea. But Tanh itself faces orthogonality, linearity and distortion problems. Due to that, his proposition cannot be reliable. So we propose a Holonorm (hn) which has residual connections and nonlinearity. Holonorm is suitable for replacing Tanh in the context of normalization. Although the HoloNorm expression could be similar to the softsign function in dimension one, softsign is a componentwise function which is not good for tensors and vectors of great dimension. Holonorm preserves the orthogonality, the direction, the invertibility of the signal. Holonorm is also a suitable metric, maps all vectors into the open unit ball. This prevents exploding activations and improves stability in deep Transformer models. In this work, we have meticulously examined the normalization in transformers and say that Holonorm, a generalized form of softsign function suited as a normalization function first.Second, defined between 0 and 1 hn serves as a percentage, and $1 - \text{Holonorm}$ is its complement, making it better understandable in evaluating a model.

</details>


### [17] [Oya: Deep Learning for Accurate Global Precipitation Estimation](https://arxiv.org/abs/2511.10562)
*Emmanuel Asiedu Brempong,Mohammed Alewi Hassen,MohamedElfatih MohamedKhair,Vusumuzi Dube,Santiago Hincapie Potes,Olivia Graham,Amanie Brik,Amy McGovern,George Huffman,Jason Hickey*

Main category: cs.LG

TL;DR: Oya是一种新型实时降水反演算法，利用地球静止卫星的可见光和红外全光谱观测，采用两阶段深度学习方法，结合两个U-Net模型分别进行降水检测和定量降水估计，在准全球范围内优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 全球南方地区地面观测网络稀疏且预报能力有限，现有卫星降水产品仅依赖长波红外通道或使用可能引入显著误差的校准数据，特别是在次日时间尺度上。

Method: 采用两阶段深度学习架构：一个U-Net用于降水检测，另一个用于定量降水估计；使用GPM CORRA v07数据作为地面真值，并在IMERG-Final检索上进行预训练以增强鲁棒性；利用多颗地球静止卫星实现准全球覆盖。

Result: Oya在准全球范围内表现出优于现有竞争性区域和全球降水基线的性能，为改进降水监测和预报提供了有前景的途径。

Conclusion: Oya算法通过充分利用地球静止卫星的可见光和红外全光谱观测，结合深度学习技术，能够提供更准确的实时降水估计，特别适用于地面观测稀疏的地区。

Abstract: Accurate precipitation estimation is critical for hydrological applications, especially in the Global South where ground-based observation networks are sparse and forecasting skill is limited. Existing satellite-based precipitation products often rely on the longwave infrared channel alone or are calibrated with data that can introduce significant errors, particularly at sub-daily timescales. This study introduces Oya, a novel real-time precipitation retrieval algorithm utilizing the full spectrum of visible and infrared (VIS-IR) observations from geostationary (GEO) satellites. Oya employs a two-stage deep learning approach, combining two U-Net models: one for precipitation detection and another for quantitative precipitation estimation (QPE), to address the inherent data imbalance between rain and no-rain events. The models are trained using high-resolution GPM Combined Radar-Radiometer Algorithm (CORRA) v07 data as ground truth and pre-trained on IMERG-Final retrievals to enhance robustness and mitigate overfitting due to the limited temporal sampling of CORRA. By leveraging multiple GEO satellites, Oya achieves quasi-global coverage and demonstrates superior performance compared to existing competitive regional and global precipitation baselines, offering a promising pathway to improved precipitation monitoring and forecasting.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [Temporal Properties of Conditional Independence in Dynamic Bayesian Networks](https://arxiv.org/abs/2511.10266)
*Rajab Aghamov,Christel Baier,Joel Ouaknine,Jakob Piribauer,Mihir Vahanwala,Isa Vialard*

Main category: cs.AI

TL;DR: 本文研究了动态贝叶斯网络中条件独立性命题演化的验证问题，分析了随机性和结构性两种CI属性的验证复杂度，并识别了使结构CI属性验证可处理的图结构限制。


<details>
  <summary>Details</summary>
Motivation: 动态贝叶斯网络是建模概率系统的重要工具，但对其条件独立性命题随时间的演化验证问题尚未得到充分研究，需要开发有效的验证方法。

Method: 采用线性时序逻辑和非确定性Büchi自动机作为规范形式化方法，分别分析随机性和结构性CI属性的验证问题，并通过复杂度分析识别可处理的情况。

Result: 验证随机CI命题最终成立至少与线性递推序列的Skolem问题一样困难；而验证结构CI命题对LTL和NBA规范在PSPACE内，且是NP-和coNP-难的；发现某些图结构限制可使结构CI属性验证变得可处理。

Conclusion: 动态贝叶斯网络中CI命题的验证复杂度取决于属性类型和网络结构，结构CI属性在某些限制下可有效验证，而随机CI属性的验证则面临理论困难。

Abstract: Dynamic Bayesian networks (DBNs) are compact graphical representations used to model probabilistic systems where interdependent random variables and their distributions evolve over time. In this paper, we study the verification of the evolution of conditional-independence (CI) propositions against temporal logic specifications. To this end, we consider two specification formalisms over CI propositions: linear temporal logic (LTL), and non-deterministic Büchi automata (NBAs). This problem has two variants. Stochastic CI properties take the given concrete probability distributions into account, while structural CI properties are viewed purely in terms of the graphical structure of the DBN. We show that deciding if a stochastic CI proposition eventually holds is at least as hard as the Skolem problem for linear recurrence sequences, a long-standing open problem in number theory. On the other hand, we show that verifying the evolution of structural CI propositions against LTL and NBA specifications is in PSPACE, and is NP- and coNP-hard. We also identify natural restrictions on the graphical structure of DBNs that make the verification of structural CI properties tractable.

</details>


### [19] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: FactGuard是一个利用大语言模型提取事件中心内容来减少写作风格影响的假新闻检测框架，通过动态可用性机制和知识蒸馏实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 随着攻击者模仿真实新闻写作风格，基于写作风格的假新闻检测方法效果逐渐下降，而现有LLM方法存在功能探索浅、可用性模糊、推理成本高等问题。

Method: 使用LLM提取事件中心内容，引入动态可用性机制识别事实推理中的矛盾和模糊案例，通过知识蒸馏获得轻量级版本FactGuard-D。

Result: 在两个基准数据集上的综合实验表明，该方法在鲁棒性和准确性上均优于现有方法，有效解决了风格敏感性和LLM可用性问题。

Conclusion: FactGuard框架通过事件内容提取和动态可用性机制，显著提升了假新闻检测的性能和实用性，为LLM在假新闻检测中的实际应用提供了可行方案。

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


### [20] [Regular Games -- an Automata-Based General Game Playing Language](https://arxiv.org/abs/2511.10593)
*Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik*

Main category: cs.AI

TL;DR: 提出了一个名为Regular Games (RG)的新型通用游戏系统，通过有限自动机定义游戏规则，在计算效率和游戏设计便利性方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有通用游戏系统在计算效率和游戏设计便利性方面存在不足，RG旨在同时解决这两个问题。

Method: 采用分层语言设计：底层是有限自动机定义规则的核心语言，上层提供面向游戏设计的高级语言，最终编译到底层语言。

Result: RG生成的前向模型比其他GGP系统（如Regular Boardgames、Ludii）更快，在效率方面表现更优。

Conclusion: RG系统成功实现了计算效率和设计便利性的平衡，其生态系统提供了完整的开发工具链。

Abstract: We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based games with imperfect information. Higher-level languages are introduced for game design (by humans or Procedural Content Generation), which are eventually translated to a low-level language. RG generates faster forward models than the current state of the art, beating other GGP systems (Regular Boardgames, Ludii) in terms of efficiency. Additionally, RG's ecosystem includes an editor with LSP, automaton visualization, benchmarking tools, and a debugger of game description transformations.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出一种基于因果视角的偏差缓解方法，用于改善社交媒体灾难事件分类的泛化能力，在三个灾难分类任务中显著提升PLM分类器性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体已成为监测灾难事件的重要工具，但现有系统面临事件相关偏差问题，影响对新兴事件的泛化能力。虽然去偏差和因果学习有进展，但在灾难事件领域仍未被充分探索。

Method: 通过因果视角处理偏差缓解，提出减少事件和领域相关偏差的方法，以增强对未来事件的泛化能力。

Result: 方法在多个基线模型上表现最佳，F1分数提升高达+1.9%，在三个灾难分类任务中显著改善了基于预训练语言模型的分类器性能。

Conclusion: 基于因果视角的偏差缓解方法能有效提高社交媒体灾难事件分类系统的泛化能力，为处理新兴灾难事件提供了更好的解决方案。

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [22] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: LocalBench是首个系统评估LLMs在美国县级本地知识能力的基准，包含14,782个验证问答对，涵盖526个县。评估显示现有模型在本地知识方面存在严重不足，最佳模型在叙事类问题准确率仅56.8%，数值推理低于15.5%。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法捕捉超本地知识的复杂性，而现实应用（如公民平台、社区新闻）需要AI系统能够理解社区特定动态、文化叙事和本地治理。

Method: 基于Localness概念框架构建LocalBench基准，整合人口普查数据、本地subreddit讨论和区域新闻，涵盖物理、认知和关系维度。评估13个最先进LLMs在闭卷和网络增强设置下的表现。

Result: 模型表现严重不足：最佳模型在叙事类问题准确率56.8%，数值推理低于15.5%。更大的模型规模和网络增强不保证更好性能，搜索使Gemini准确率提升+13.6%，但降低GPT系列性能-11.4%。

Conclusion: 迫切需要能够支持公平、位置感知AI系统的语言模型，能够参与不同地理和文化背景下本地社区的多样化、细粒度现实。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [23] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: URaG是一个统一检索与生成的多模态大语言模型框架，通过利用模型早期层的证据定位能力进行页面级检索，在保持精度的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在长文档理解中的两个核心挑战：大量无关内容的信息干扰，以及Transformer架构的二次计算成本。现有方法要么牺牲细节，要么增加系统复杂性。

Method: 提出URaG框架，引入轻量级跨模态检索模块，将早期Transformer层转换为高效的证据选择器，识别并保留最相关页面，丢弃无关内容，让深层层专注于相关信息。

Result: 在广泛实验中，URaG实现了最先进的性能，同时将计算开销降低了44-56%。

Conclusion: URaG证明了多模态大语言模型固有的证据定位能力可以显式利用，在推理过程中执行检索，实现高效的长文档理解，为统一检索与生成提供了简单而有效的解决方案。

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2511.09958)
*Xiangyi Wei,Haotian Zhang,Xinyi Cao,Siyu Xie,Weifeng Ge,Yang Li,Changbo Wang*

Main category: cs.RO

TL;DR: Audio-VLA是一个多模态机器人操作策略，利用接触音频来感知接触事件和动态过程反馈，克服了纯视觉VLA模型的限制。


<details>
  <summary>Details</summary>
Motivation: 纯视觉VLA模型在感知交互和操作动态过程方面存在根本性限制，需要引入音频模态来增强感知能力。

Method: 使用预训练的DINOv2和SigLIP作为视觉编码器，AudioCLIP作为音频编码器，Llama2作为大语言模型主干，通过LoRA微调和多模态投影层实现跨模态理解。

Result: 在LIBERO、RLBench和两个真实世界任务上的实验表明，Audio-VLA优于纯视觉对比方法，TCR指标有效量化了动态过程感知能力。

Conclusion: Audio-VLA通过引入音频模态显著提升了机器人操作性能，TCR指标为动态操作过程评估提供了系统化方法。

Abstract: The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

</details>


### [25] [Robot Crash Course: Learning Soft and Stylized Falling](https://arxiv.org/abs/2511.10635)
*Pascal Strauch,David Müller,Sammy Christen,Agon Serifi,Ruben Grandia,Espen Knoop,Moritz Bächer*

Main category: cs.RO

TL;DR: 提出一种机器人无关的奖励函数，通过强化学习实现双足机器人的受控软着陆，平衡期望最终姿态与冲击最小化，保护关键部件。


<details>
  <summary>Details</summary>
Motivation: 双足机器人在现实世界中仍有摔倒风险，现有研究主要关注防止摔倒，而本文专注于摔倒现象本身，旨在减少物理损伤并让用户控制机器人最终姿态。

Method: 使用机器人无关的奖励函数进行强化学习，平衡期望最终姿态、冲击最小化和关键部件保护；引入基于仿真的初始和最终姿态采样策略，使策略对广泛的初始摔倒条件和任意未见最终姿态具有鲁棒性。

Result: 通过仿真和真实世界实验证明，双足机器人能够执行受控的软着陆。

Conclusion: 即使双足机器人也能实现受控的软着陆，为机器人摔倒管理提供了新方法。

Abstract: Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.

</details>
