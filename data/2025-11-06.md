<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [EvtSlowTV -- A Large and Diverse Dataset for Event-Based Depth Estimation](https://arxiv.org/abs/2511.02953)
*Sadiq Layi Macaulay,Nimet Kaygusuz,Simon Hadfield*

Main category: cs.CV

TL;DR: 提出了EvtSlowTV，一个从YouTube视频构建的大规模事件相机数据集，包含超过130亿个事件，用于解决事件相机深度估计中标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高动态范围和低延迟特性，但现有事件深度估计方法受限于小规模标注数据集，难以泛化到真实场景。

Method: 从YouTube公开视频构建EvtSlowTV数据集，采用自监督学习框架利用原始事件流的高动态范围潜力，无需基于帧的标注。

Result: EvtSlowTV比现有事件数据集大一个数量级，训练后模型在复杂场景和运动中的泛化能力得到提升。

Conclusion: EvtSlowTV为事件相机深度学习提供了无约束的自然环境设置，保留了事件数据的异步特性，解决了标注数据稀缺问题。

Abstract: Event cameras, with their high dynamic range (HDR) and low latency, offer a
promising alternative for robust depth estimation in challenging environments.
However, many event-based depth estimation approaches are constrained by
small-scale annotated datasets, limiting their generalizability to real-world
scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event
camera dataset curated from publicly available YouTube footage, which contains
more than 13B events across various environmental conditions and motions,
including seasonal hiking, flying, scenic driving, and underwater exploration.
EvtSlowTV is an order of magnitude larger than existing event datasets,
providing an unconstrained, naturalistic setting for event-based depth
learning. This work shows the suitability of EvtSlowTV for a self-supervised
learning framework to capitalise on the HDR potential of raw event streams. We
further demonstrate that training with EvtSlowTV enhances the model's ability
to generalise to complex scenes and motions. Our approach removes the need for
frame-based annotations and preserves the asynchronous nature of event data.

</details>


### [2] [SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention](https://arxiv.org/abs/2511.03178)
*Shreyas C. Dhake,Jiayuan Huang,Runlong He,Danyal Z. Khan,Evangelos B. Mazomenos,Sophia Bano,Hani J. Marcus,Danail Stoyanov,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 提出了首个面向手术前瞻性推理的视觉问答数据集PitVQA-Anticipation，并开发了SurgAnt-ViVQA模型，通过时间感知编码和门控交叉注意力实现从回顾性描述到前瞻性预测的转变。


<details>
  <summary>Details</summary>
Motivation: 在鼻内镜下经蝶垂体手术中，能预见即将发生的手术事件对实时辅助至关重要，现有VQA系统主要关注当前场景而非未来预测。

Method: 提出SurgAnt-ViVQA模型，采用GRU门控时间交叉注意力模块，双向GRU编码帧间动态，自适应门控在token级别注入视觉上下文，参数高效微调定制语言骨干网络。

Result: 在PitVQA-Anticipation和EndoVis数据集上测试，超越强图像和视频基线，消融实验显示时间循环和门控融合带来主要增益。

Conclusion: 通过时间感知编码器和细粒度门控交叉注意力的结合，SurgAnt-ViVQA将手术VQA从回顾性描述推进到前瞻性预测，PitVQA-Anticipation为该领域提供了全面基准。

Abstract: Anticipating forthcoming surgical events is vital for real-time assistance in
endonasal transsphenoidal pituitary surgery, where visibility is limited and
workflow changes rapidly. Most visual question answering (VQA) systems reason
on isolated frames with static vision language alignment, providing little
support for forecasting next steps or instrument needs. Existing surgical VQA
datasets likewise center on the current scene rather than the near future. We
introduce PitVQA-Anticipation, the first VQA dataset designed for forward
looking surgical reasoning. It comprises 33.5 hours of operative video and
734,769 question answer pairs built from temporally grouped clips and expert
annotations across four tasks: predicting the future phase, next step, upcoming
instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video
language model that adapts a large language model using a GRU Gated Temporal
Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics,
while an adaptive gate injects visual context into the language stream at the
token level. Parameter efficient fine tuning customizes the language backbone
to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and
EndoVis datasets, surpassing strong image and video based baselines. Ablations
show that temporal recurrence and gated fusion drive most of the gains. A frame
budget study indicates a trade-off: 8 frames maximize fluency, whereas 32
frames slightly reduce BLEU but improve numeric time estimation. By pairing a
temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA
advances surgical VQA from retrospective description to proactive anticipation.
PitVQA-Anticipation offers a comprehensive benchmark for this setting and
highlights the importance of targeted temporal modeling for reliable, future
aware surgical assistance.

</details>


### [3] [SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding](https://arxiv.org/abs/2511.03325)
*Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: SurgViVQA是一个外科视频问答模型，通过融合视频和问题特征来捕捉时间线索，在结肠镜视频问答任务中优于现有图像基准模型，特别是在关键词准确率上提升了9-11%。


<details>
  <summary>Details</summary>
Motivation: 当前外科视频问答方法局限于静态图像特征，缺乏对时间动态的建模，而手术过程中的运动和组织-工具交互等时间线索对于准确理解手术过程至关重要。

Method: 提出SurgViVQA模型，使用掩码视频-文本编码器融合视频和问题特征，捕捉运动和组织-工具交互等时间线索，然后通过微调的大型语言模型解码为连贯答案。

Result: 在REAL-Colon-VQA和EndoVis18-VQA数据集上的实验表明，SurgViVQA在关键词准确率上比PitVQA分别提升11%和9%，扰动研究进一步证实了模型对问题表述变化的鲁棒性。

Conclusion: SurgViVQA和REAL-Colon-VQA数据集为外科视频问答提供了时间感知理解的框架，使AI模型能够更有效地解释动态手术场景。

Abstract: Video Question Answering (VideoQA) in the surgical domain aims to enhance
intraoperative understanding by enabling AI models to reason over temporally
coherent events rather than isolated frames. Current approaches are limited to
static image features, and available datasets often lack temporal annotations,
ignoring the dynamics critical for accurate procedural interpretation. We
propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from
static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder
to fuse video and question features, capturing temporal cues such as motion and
tool--tissue interactions, which a fine-tuned large language model (LLM) then
decodes into coherent answers. To evaluate its performance, we curated
REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related
questions and diagnostic attributes, as well as out-of-template questions with
rephrased or semantically altered formulations to assess model robustness.
Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset
shows that SurgViVQA outperforms existing image-based VQA benchmark models,
particularly in keyword accuracy, improving over PitVQA by +11\% on
REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions
further confirms improved generalizability and robustness to variations in
question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework
for temporally-aware understanding in surgical VideoQA, enabling AI models to
interpret dynamic procedural contexts more effectively. Code and dataset
available at https://github.com/madratak/SurgViVQA.

</details>


### [4] [Generalizing Shape-from-Template to Topological Changes](https://arxiv.org/abs/2511.03459)
*Kevin Manogue,Tomasz M Schang,Dilara Kuş,Jonas Müller,Stefan Zachow,Agniva Sengupta*

Main category: cs.CV

TL;DR: 提出了一个能够处理拓扑变化的形状模板重建方法，通过迭代分割模板空间域来最小化能量函数，实现了在撕裂、切割等拓扑变化情况下的鲁棒重建。


<details>
  <summary>Details</summary>
Motivation: 现有的形状模板重建方法在遇到拓扑变化时会失效，需要扩展SfT方法来处理这类情况。

Method: 基于经典SfT解初始化，通过迭代分割模板空间域来最小化同时编码物理合理性和重投影一致性的能量函数。

Result: 方法能够鲁棒地捕捉各种实际相关的拓扑事件，包括有界2D表面的撕裂和切割，在合成和真实数据实验中均优于基线方法。

Conclusion: 建立了第一个通用的拓扑变化感知SfT框架，为处理拓扑变化的表面重建提供了有效解决方案。

Abstract: Reconstructing the surfaces of deformable objects from correspondences
between a 3D template and a 2D image is well studied under Shape-from-Template
(SfT) methods; however, existing approaches break down when topological changes
accompany the deformation. We propose a principled extension of SfT that
enables reconstruction in the presence of such changes. Our approach is
initialized with a classical SfT solution and iteratively adapts the template
by partitioning its spatial domain so as to minimize an energy functional that
jointly encodes physical plausibility and reprojection consistency. We
demonstrate that the method robustly captures a wide range of practically
relevant topological events including tears and cuts on bounded 2D surfaces,
thereby establishing the first general framework for topological-change-aware
SfT. Experiments on both synthetic and real data confirm that our approach
consistently outperforms baseline methods.

</details>


### [5] [A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential](https://arxiv.org/abs/2511.03665)
*Mehdi Sefidgar Dilmaghani,Francis Fowley,Peter Corcoran*

Main category: cs.CV

TL;DR: 提出一种轻量级3DCNN用于基于事件视觉的人类活动识别，通过事件相机实现隐私保护，在复合数据集上达到94.17%准确率，优于现有基准模型。


<details>
  <summary>Details</summary>
Motivation: 传统帧相机在人类监控系统中会捕捉可识别个人信息，存在隐私问题。事件相机仅记录像素强度变化，提供固有的隐私保护感知方式。

Method: 使用轻量级3DCNN建模时空动态，采用焦点损失和类别重加权处理类别不平衡，结合针对性数据增强策略提升泛化能力。

Result: 在Toyota Smart Home和ETRI复合数据集上获得0.9415的F1分数和94.17%的总体准确率，比C3D、ResNet3D和MC3_18等基准模型高出最多3%。

Conclusion: 基于事件的深度学习方法具有开发准确、高效且隐私感知的人类动作识别系统的潜力，适用于现实世界边缘应用。

Abstract: This paper presents a lightweight three-dimensional convolutional neural
network (3DCNN) for human activity recognition (HAR) using event-based vision
data. Privacy preservation is a key challenge in human monitoring systems, as
conventional frame-based cameras capture identifiable personal information. In
contrast, event cameras record only changes in pixel intensity, providing an
inherently privacy-preserving sensing modality. The proposed network
effectively models both spatial and temporal dynamics while maintaining a
compact design suitable for edge deployment. To address class imbalance and
enhance generalization, focal loss with class reweighting and targeted data
augmentation strategies are employed. The model is trained and evaluated on a
composite dataset derived from the Toyota Smart Home and ETRI datasets.
Experimental results demonstrate an F1-score of 0.9415 and an overall accuracy
of 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D,
and MC3_18 by up to 3%. These results highlight the potential of event-based
deep learning for developing accurate, efficient, and privacy-aware human
action recognition systems suitable for real-world edge applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Digital Twin-Driven Pavement Health Monitoring and Maintenance Optimization Using Graph Neural Networks](https://arxiv.org/abs/2511.02957)
*Mohsin Mahmud Topu,Mahfuz Ahmed Anik,Azmine Toushik Wasi,Md Manjurul Ahsan*

Main category: cs.LG

TL;DR: 提出了一种结合数字孪生和图神经网络的道路健康监测框架，通过图结构建模道路段和空间关系，实现数据驱动的预测性维护。


<details>
  <summary>Details</summary>
Motivation: 传统道路管理系统缺乏实时智能，无法有效预防故障和优化维护规划，需要解决复杂空间依赖、环境变化和非线性劣化等挑战。

Method: 将道路段和空间关系建模为图节点和边，利用无人机、传感器和激光雷达实时数据，采用归纳式图神经网络学习劣化模式进行预测。

Result: 在真实数据集上R2达到0.3798，优于基线回归器，有效捕捉非线性退化，并开发了交互式仪表板和强化学习模块。

Conclusion: DT-GNN集成提高了预测精度，建立了持续改进的闭环反馈，为主动、智能和可持续的道路管理奠定了基础。

Abstract: Pavement infrastructure monitoring is challenged by complex spatial
dependencies, changing environmental conditions, and non-linear deterioration
across road networks. Traditional Pavement Management Systems (PMS) remain
largely reactive, lacking real-time intelligence for failure prevention and
optimal maintenance planning. To address this, we propose a unified Digital
Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven
pavement health monitoring and predictive maintenance. Pavement segments and
spatial relations are modeled as graph nodes and edges, while real-time UAV,
sensor, and LiDAR data stream into the DT. The inductive GNN learns
deterioration patterns from graph-structured inputs to forecast distress and
enable proactive interventions. Trained on a real-world-inspired dataset with
segment attributes and dynamic connectivity, our model achieves an R2 of
0.3798, outperforming baseline regressors and effectively capturing non-linear
degradation. We also develop an interactive dashboard and reinforcement
learning module for simulation, visualization, and adaptive maintenance
planning. This DT-GNN integration enhances forecasting precision and
establishes a closed feedback loop for continuous improvement, positioning the
approach as a foundation for proactive, intelligent, and sustainable pavement
management, with future extensions toward real-world deployment, multi-agent
coordination, and smart-city integration.

</details>


### [7] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 提出了一种自适应无传感器监测方法，通过残差校正框架修正无传感器模型的系统偏差，在集装箱温湿度监测中显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统无传感器监测方法不包含遥测信息且无法校正系统误差，导致预测结果与实时数据差异显著，给用户带来困惑。

Method: 引入残差校正方法，在观测到实时遥测数据后校正无传感器模型的系统偏差，形成自适应无传感器监测框架。

Result: 在348万数据点上评估，自适应无传感器模型相比基线模型，温度MAE从2.43°C降至2.24~2.31°C，湿度MAE从7.99%降至5.72~7.09%；温度RMSE从3.38°C降至3.19~3.26°C，湿度RMSE从10.0%降至7.70~9.12%。

Conclusion: 自适应无传感器模型实现了更准确的货物监测、早期风险检测，并减少了对全球航运中完全连接的依赖。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [8] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: FCDC将数据收集建模为闭环控制问题，通过在线概率模型和反馈机制动态调节样本保留，实现更平衡的数据集和显著减少存储需求。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统受限于数据质量和多样性而非模型容量，传统开环数据收集方式积累冗余样本，导致存储效率低、标注成本高和泛化能力有限。

Method: FCDC使用在线概率模型近似已收集数据分布状态，基于似然和马哈拉诺比斯距离等反馈信号自适应调节样本保留，动态平衡探索与利用。

Result: 在真实数据流实验中，FCDC产生更平衡的数据集（提升25.9%），同时减少数据存储39.8%。

Conclusion: 数据收集本身可以主动控制，将收集从被动管道阶段转变为数据中心AI核心的自调节、反馈驱动过程。

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [9] [Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life Adaptation Pathways](https://arxiv.org/abs/2511.03243)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 本文提出使用强化学习来识别气候变化下的适应路径，并明确建模不同的适应优先级（经济vs福祉），通过综合评估模型分析洪水影响。


<details>
  <summary>Details</summary>
Motivation: 气候变化将增加洪水事件的频率和严重性，需要有效的适应政策制定，但长期气候影响的不确定性和政策中的规范性选择往往未明确考虑。

Method: 使用强化学习（RL）结合综合评估模型（IAM），将降雨和洪水模型联系起来，计算洪水对生活质量、交通和基础设施的影响。

Result: 优先考虑生活质量而非经济影响的模型会导致更多的适应支出，并在研究区域内更均匀地分配支出，表明规范性假设会显著改变适应政策。

Conclusion: 强化学习是识别不确定条件下适应路径的有用工具，同时允许明确建模和比较不同的适应优先级，框架已公开可用。

Abstract: Climate change will cause an increase in the frequency and severity of flood
events, prompting the need for cohesive adaptation policymaking. Designing
effective adaptation policies, however, depends on managing the uncertainty of
long-term climate impacts. Meanwhile, such policies can feature important
normative choices that are not always made explicit. We propose that
Reinforcement Learning (RL) can be a useful tool to both identify adaptation
pathways under uncertain conditions while it also allows for the explicit
modelling (and consequent comparison) of different adaptation priorities (e.g.
economic vs. wellbeing). We use an Integrated Assessment Model (IAM) to link
together a rainfall and flood model, and compute the impacts of flooding in
terms of quality of life (QoL), transportation, and infrastructure damage. Our
results show that models prioritising QoL over economic impacts results in more
adaptation spending as well as a more even distribution of spending over the
study area, highlighting the extent to which such normative assumptions can
alter adaptation policy. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [10] [GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models](https://arxiv.org/abs/2511.03251)
*Zhibin Wang,Zhixing Zhang,Shuqi Wang,Xuanting Xie,Zhao Kang*

Main category: cs.LG

TL;DR: GMoPE是一个结合混合专家架构和提示学习的图神经网络框架，通过专家特定提示向量和结构感知路由实现跨领域泛化，显著降低迁移成本。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在跨领域和任务泛化方面存在负迁移、可扩展性差和适应成本高的问题，需要开发更通用和高效的图基础模型。

Method: 提出GMoPE框架，集成混合专家架构与图提示学习，使用专家特定提示向量和结构感知路由，引入软正交约束促进专家多样性，采用仅提示微调策略。

Result: 在各种预训练策略和下游任务上的实验表明，GMoPE持续优于最先进基线，性能接近全参数微调，同时仅需少量适应开销。

Conclusion: GMoPE为推进通用化和高效的图基础模型提供了一个原则性和可扩展的框架。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive performance on
task-specific benchmarks, yet their ability to generalize across diverse
domains and tasks remains limited. Existing approaches often struggle with
negative transfer, scalability issues, and high adaptation costs. To address
these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel
framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture
with prompt-based learning for graphs. GMoPE leverages expert-specific prompt
vectors and structure-aware MoE routing to enable each expert to specialize in
distinct subdomains and dynamically contribute to predictions. To promote
diversity and prevent expert collapse, we introduce a soft orthogonality
constraint across prompt vectors, encouraging expert specialization and
facilitating a more balanced expert utilization. Additionally, we adopt a
prompt-only fine-tuning strategy that significantly reduces spatiotemporal
complexity during transfer. We validate GMoPE through extensive experiments
under various pretraining strategies and multiple downstream tasks. Results
show that GMoPE consistently outperforms state-of-the-art baselines and
achieves performance comparable to full parameter fine-tuning-while requiring
only a fraction of the adaptation overhead. Our work provides a principled and
scalable framework for advancing generalizable and efficient graph foundation
models.

</details>


### [11] [SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection](https://arxiv.org/abs/2511.03661)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.LG

TL;DR: 本研究提出基于机器学习的框架，用于检测医疗物联网设备的恶意网络攻击和设备故障异常，评估了8种机器学习模型在监督、半监督和无监督学习中的表现。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网设备面临严重的安全性和可靠性挑战，容易受到网络威胁和操作异常的影响，需要有效的异常检测策略来保障医疗设备的安全运行。

Method: 使用包含20万条记录的数据集，评估了三种学习方法的8种模型：监督学习（XGBoost、KNN）、半监督学习（GAN、VAE）和无监督学习（One-Class SVM、Isolation Forest、GNN、LSTM Autoencoders）。

Result: XGBoost在异常检测中达到99%准确率且计算开销最小（0.04秒），Isolation Forest在精度和召回率间取得良好平衡。KNN在攻击检测中实现近乎完美的精度、召回率和F1分数，计算成本最低（0.05秒）。LSTM Autoencoders表现较差，GAN计算成本最高且准确率最低。

Conclusion: 该框架通过有效的异常检测策略增强了医疗物联网安全性，能够早期检测网络威胁和设备故障，预防数据泄露，减少系统停机时间，确保医疗设备持续安全运行，保护患者健康和信任。

Abstract: The integration of IoT devices in healthcare introduces significant security
and reliability challenges, increasing susceptibility to cyber threats and
operational anomalies. This study proposes a machine learning-driven framework
for (1) detecting malicious cyberattacks and (2) identifying faulty device
anomalies, leveraging a dataset of 200,000 records. Eight machine learning
models are evaluated across three learning approaches: supervised learning
(XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative
Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised
learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph
Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The
comprehensive evaluation was conducted across multiple metrics like F1-score,
precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost
achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly
detection, while Isolation Forest balanced precision and recall effectively.
LSTM Autoencoders underperformed with lower accuracy and higher latency. For
attack detection, KNN achieved near-perfect precision, recall, and F1-score
with the lowest computational cost (0.05s), followed by VAE at 97% accuracy.
GAN showed the highest computational cost with lowest accuracy and ROC-AUC.
These findings enhance IoT-enabled healthcare security through effective
anomaly detection strategies. By improving early detection of cyber threats and
device failures, this framework has the potential to prevent data breaches,
minimize system downtime, and ensure the continuous and safe operation of
medical devices, ultimately safeguarding patient health and trust in IoT-driven
healthcare solutions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 开发了Summit Concierge，一个针对Adobe Summit的领域特定AI助手，采用人在回路开发流程，结合提示工程、检索增强和轻量级人工验证，在数据稀疏等现实约束下实现可靠部署。


<details>
  <summary>Details</summary>
Motivation: 利用生成式AI助手提升企业环境中的生产力、简化信息访问并改善用户体验，特别是在Adobe Summit这样的企业活动中。

Method: 采用人在回路开发工作流程，结合提示工程、检索增强和轻量级人工验证，构建能够处理各种活动相关查询的系统架构。

Result: 成功开发并部署了Summit Concierge助手，能够处理广泛的活动相关查询，在现实约束下实现可靠运行。

Conclusion: 敏捷、反馈驱动的开发方法即使在冷启动场景下也能实现可扩展且可靠的AI助手部署。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: QuestionRAG是一个解决QA系统中输入错误问题的框架，通过外部知识增强和强化学习对齐来改善LLM对错误问题的理解和修正能力。


<details>
  <summary>Details</summary>
Motivation: QA系统中的输入错误经常导致错误回答，LLM在处理这类任务时存在误解用户意图或过度修正问题结构的问题。

Method: 使用外部知识（如搜索结果、相关实体）增强输入以解决误解问题；采用强化学习对齐模型目标，确保精确修正而非简单改写。

Result: 知识增强对于理解错误问题至关重要；基于RL的对齐方法比传统监督微调更有效，显著提升了模型的指令遵循和泛化能力。

Conclusion: 通过整合知识增强和强化学习对齐，QuestionRAG充分释放了LLM在问题修正任务中的潜力。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control](https://arxiv.org/abs/2511.03481)
*Jianbo Yuan,Haohua Zhu,Jing Dai,Sheng Yi*

Main category: cs.RO

TL;DR: Dex-Hand 021是一款高性能电缆驱动五指机械手，具有12个主动和7个被动自由度，重量仅1kg，采用本体感知力传感导纳控制方法，在抓取能力和精度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 人类手在日常生活中和工业应用中至关重要，但复制其多功能能力（包括运动、感知和协调操作）对机器人系统仍然是一个巨大挑战。需要平衡类人敏捷性与工程约束（如复杂性、尺寸重量比、耐久性和力传感性能）。

Method: 提出基于本体感知力传感的导纳控制方法，采用电缆驱动设计，具有12个主动和7个被动自由度，总共19个自由度。

Result: 单指负载能力超过10N，指尖重复性低于0.001m，力估计误差小于0.2N。与PID控制相比，多物体抓取时关节扭矩减少31.19%，显著提高力传感能力并防止碰撞过载。成功执行33种GRASP分类动作和复杂操作任务。

Conclusion: 这项工作推进了轻量级工业级灵巧手的设计，增强了本体感知控制，为机器人操作和智能制造做出贡献。

Abstract: The human hand plays a vital role in daily life and industrial applications,
yet replicating its multifunctional capabilities-including motion, sensing, and
coordinated manipulation-with robotic systems remains a formidable challenge.
Developing a dexterous robotic hand requires balancing human-like agility with
engineering constraints such as complexity, size-to-weight ratio, durability,
and force-sensing performance. This letter presents Dex-Hand 021, a
high-performance, cable-driven five-finger robotic hand with 12 active and 7
passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight
1 kg design. We propose a proprioceptive force-sensing-based admittance control
method to enhance manipulation. Experimental results demonstrate its superior
performance: a single-finger load capacity exceeding 10 N, fingertip
repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared
to PID control, joint torques in multi-object grasping are reduced by 31.19%,
significantly improves force-sensing capability while preventing overload
during collisions. The hand excels in both power and precision grasps,
successfully executing 33 GRASP taxonomy motions and complex manipulation
tasks. This work advances the design of lightweight, industrial-grade dexterous
hands and enhances proprioceptive control, contributing to robotic manipulation
and intelligent manufacturing.

</details>
