<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 13]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Unbiased Gradient Estimation for Event Binning via Functional Backpropagation](https://arxiv.org/abs/2602.12590)
*Jinze Chen,Wei Zhai,Han Han,Tiankai Ma,Yang Cao,Bin Li,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出一种无偏梯度估计框架，通过合成弱导数解决事件视觉中binning函数不连续导致的梯度截断问题


<details>
  <summary>Details</summary>
Motivation: 事件视觉将动态场景编码为异步时空脉冲（事件）。传统方法将事件分箱成帧，但分箱函数不连续导致梯度截断，迫使算法依赖帧级特征。直接学习原始事件则因分箱操作的不连续性导致梯度估计偏差，限制了学习效率。

Method: 提出无偏梯度估计框架：在前向传播保持输出不变的同时，在反向传播中合成弱导数。核心思想是利用分部积分：将目标函数提升为泛函，在反向传播中得到分箱函数导数的积分形式，其中余切函数自然出现。通过从采样的余切向量重构余切函数，计算弱导数，可证明匹配平滑和非平滑目标的长期有限差分。

Result: 实验表明：在简单优化型自运动估计中，RMS误差降低3.2%，收敛速度加快1.57倍；在复杂下游任务中，自监督光流估计的EPE降低9.4%，SLAM的RMS误差降低5.1%，显著提升事件视觉感知性能。

Conclusion: 该方法通过合成弱导数解决了事件视觉中分箱函数不连续导致的梯度估计问题，为事件视觉感知提供了有效的无偏梯度估计框架，在多个任务上展示了广泛的应用价值。

Abstract: Event-based vision encodes dynamic scenes as asynchronous spatio-temporal spikes called events. To leverage conventional image processing pipelines, events are typically binned into frames. However, binning functions are discontinuous, which truncates gradients at the frame level and forces most event-based algorithms to rely solely on frame-based features. Attempts to directly learn from raw events avoid this restriction but instead suffer from biased gradient estimation due to the discontinuities of the binning operation, ultimately limiting their learning efficiency. To address this challenge, we propose a novel framework for unbiased gradient estimation of arbitrary binning functions by synthesizing weak derivatives during backpropagation while keeping the forward output unchanged. The key idea is to exploit integration by parts: lifting the target functions to functionals yields an integral form of the derivative of the binning function during backpropagation, where the cotangent function naturally arises. By reconstructing this cotangent function from the sampled cotangent vector, we compute weak derivatives that provably match long-range finite differences of both smooth and non-smooth targets. Experimentally, our method improves simple optimization-based egomotion estimation with 3.2\% lower RMS error and 1.57$\times$ faster convergence. On complex downstream tasks, we achieve 9.4\% lower EPE in self-supervised optical flow, and 5.1\% lower RMS error in SLAM, demonstrating broad benefits for event-based visual perception. Source code can be found at https://github.com/chjz1024/EventFBP.

</details>


### [2] [Channel-Aware Probing for Multi-Channel Imaging](https://arxiv.org/abs/2602.12696)
*Umar Marikkar,Syed Sameed Husain,Muhammad Awais,Sara Atito*

Main category: cs.CV

TL;DR: 提出Channel-Aware Probing (CAP)方法，通过独立特征编码和分离池化来利用多通道成像数据的通道间多样性，提升冻结预训练编码器的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 多通道成像数据中通道配置在不同数据集间变化，阻碍了固定通道训练和预训练编码器的重用。现有方法主要关注全微调，而冻结编码器的探测方法研究不足，且现有策略在多通道成像领域效果不佳。

Method: 提出Channel-Aware Probing (CAP)方法，包含两个核心组件：1) Independent Feature Encoding (IFE) - 独立编码每个通道；2) Decoupled Pooling (DCP) - 先在通道内池化，再跨通道聚合。

Result: 在三个多通道成像基准测试中，CAP一致提升探测性能，匹配从头开始训练的效果，并大幅缩小与全微调之间的性能差距。

Conclusion: CAP通过利用多通道成像数据的内在通道间多样性，有效解决了冻结预训练编码器在下游任务中的性能问题，为多通道成像领域提供了有效的探测方法。

Abstract: Training and evaluating vision encoders on Multi-Channel Imaging (MCI) data remains challenging as channel configurations vary across datasets, preventing fixed-channel training and limiting reuse of pre-trained encoders on new channel settings. Prior work trains MCI encoders but typically evaluates them via full fine-tuning, leaving probing with frozen pre-trained encoders comparatively underexplored. Existing studies that perform probing largely focus on improving representations, rather than how to best leverage fixed representations for downstream tasks. Although the latter problem has been studied in other domains, directly transferring those strategies to MCI yields weak results, even worse than training from scratch. We therefore propose Channel-Aware Probing (CAP), which exploits the intrinsic inter-channel diversity in MCI datasets by controlling feature flow at both the encoder and probe levels. CAP uses Independent Feature Encoding (IFE) to encode each channel separately, and Decoupled Pooling (DCP) to pool within channels before aggregating across channels. Across three MCI benchmarks, CAP consistently improves probing performance over the default probing protocol, matches fine-tuning from scratch, and largely reduces the gap to full fine-tuning from the same MCI pre-trained checkpoints. Code can be found in https://github.com/umarikkar/CAP.

</details>


### [3] [Reliable Thinking with Images](https://arxiv.org/abs/2602.12916)
*Haobin Li,Yutong Yang,Yijie Lin,Dai Xiang,Mouxing Yang,Xi Peng*

Main category: cs.CV

TL;DR: RTWI方法通过统一文本中心的方式评估视觉线索和文本推理链的可靠性，使用鲁棒过滤和投票模块解决多模态推理中的噪声思维问题


<details>
  <summary>Details</summary>
Motivation: 现有的"Thinking with Images"方法假设图像-文本推理链是完美的，但现实场景中由于多模态理解的复杂性，这种假设容易被违反，导致错误累积和性能下降

Method: 提出Reliable Thinking with Images方法：1）以统一文本中心的方式评估视觉线索和文本推理链的可靠性；2）使用鲁棒过滤模块防止噪声思维污染最终答案；3）采用投票机制确保答案的可靠性

Result: 在七个基准测试上的广泛实验验证了RTWI方法在解决噪声思维问题上的有效性

Conclusion: RTWI通过可靠性评估和鲁棒过滤机制，有效解决了多模态推理中的噪声思维问题，提升了MLLMs在现实场景中的性能

Abstract: As a multimodal extension of Chain-of-Thought (CoT), Thinking with Images (TWI) has recently emerged as a promising avenue to enhance the reasoning capability of Multi-modal Large Language Models (MLLMs), which generates interleaved CoT by incorporating visual cues into the textual reasoning process. However, the success of existing TWI methods heavily relies on the assumption that interleaved image-text CoTs are faultless, which is easily violated in real-world scenarios due to the complexity of multimodal understanding. In this paper, we reveal and study a highly-practical yet under-explored problem in TWI, termed Noisy Thinking (NT). Specifically, NT refers to the imperfect visual cues mining and answer reasoning process. As the saying goes, ``One mistake leads to another'', erroneous interleaved CoT would cause error accumulation, thus significantly degrading the performance of MLLMs. To solve the NT problem, we propose a novel method dubbed Reliable Thinking with Images (RTWI). In brief, RTWI estimates the reliability of visual cues and textual CoT in a unified text-centric manner and accordingly employs robust filtering and voting modules to prevent NT from contaminating the final answer. Extensive experiments on seven benchmarks verify the effectiveness of RTWI against NT.

</details>


### [4] [EPRBench: A High-Quality Benchmark Dataset for Event Stream Based Visual Place Recognition](https://arxiv.org/abs/2602.12919)
*Xiao Wang,Xingxing Xiong,Jinfeng Gao,Xufeng Lou,Bo Jiang,Si-bao Chen,Yaowei Wang,Yonghong Tian*

Main category: cs.CV

TL;DR: 提出EPRBench事件流视觉地点识别基准数据集，包含10K事件序列和65K事件帧，并基于LLM生成场景描述，提出多模态融合框架提升识别准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统可见光相机在低光照、过曝、高速运动等挑战条件下不稳定，而事件流视觉地点识别（VPR）能解决这些问题。目前该领域缺乏专用数据集，需要高质量基准来推动研究。

Method: 1) 构建EPRBench数据集，使用手持和车载设备采集10K事件序列和65K事件帧，涵盖多样化视角、天气和光照条件；2) 通过LLM生成场景描述并人工标注；3) 提出多模态融合框架：利用LLM从原始事件流生成文本描述，指导空间注意力token选择、跨模态特征融合和多尺度表示学习。

Result: 1) 发布高质量EPRBench数据集；2) 在数据集上评估了15种最先进的VPR算法，为未来比较提供基线；3) 提出的多模态融合框架不仅实现高精度地点识别，还产生可解释的推理过程，显著提升模型透明度和可解释性。

Conclusion: EPRBench填补了事件流VPR领域的数据集空白，提出的多模态融合框架通过结合LLM生成文本描述，实现了准确且可解释的地点识别，为未来事件感知研究提供了重要基础。

Abstract: Event stream-based Visual Place Recognition (VPR) is an emerging research direction that offers a compelling solution to the instability of conventional visible-light cameras under challenging conditions such as low illumination, overexposure, and high-speed motion. Recognizing the current scarcity of dedicated datasets in this domain, we introduce EPRBench, a high-quality benchmark specifically designed for event stream-based VPR. EPRBench comprises 10K event sequences and 65K event frames, collected using both handheld and vehicle-mounted setups to comprehensively capture real-world challenges across diverse viewpoints, weather conditions, and lighting scenarios. To support semantic-aware and language-integrated VPR research, we provide LLM-generated scene descriptions, subsequently refined through human annotation, establishing a solid foundation for integrating LLMs into event-based perception pipelines. To facilitate systematic evaluation, we implement and benchmark 15 state-of-the-art VPR algorithms on EPRBench, offering a strong baseline for future algorithmic comparisons. Furthermore, we propose a novel multi-modal fusion paradigm for VPR: leveraging LLMs to generate textual scene descriptions from raw event streams, which then guide spatially attentive token selection, cross-modal feature fusion, and multi-scale representation learning. This framework not only achieves highly accurate place recognition but also produces interpretable reasoning processes alongside its predictions, significantly enhancing model transparency and explainability. The dataset and source code will be released on https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [5] [CoPE-VideoLM: Codec Primitives For Efficient Video Language Models](https://arxiv.org/abs/2602.13191)
*Sayan Deb Sarkar,Rémi Pautrat,Ondrej Miksik,Marc Pollefeys,Iro Armeni,Mahdi Rad,Mihai Dusmanu*

Main category: cs.CV

TL;DR: 提出利用视频编解码原语（运动向量和残差）的VideoLM方法，显著降低计算开销并提升视频理解性能


<details>
  <summary>Details</summary>
Motivation: 现有VideoLM方法使用关键帧采样会遗漏宏观事件和微观细节，且处理完整图像帧带来巨大计算开销

Method: 利用视频编解码原语（运动向量和残差）编码视频冗余和稀疏性，设计轻量级Transformer编码器聚合这些原语，并通过预训练策略对齐图像编码器表示

Result: 相比标准VideoLM，首token生成时间减少86%，token使用量减少93%，在14个视频理解基准上保持或超越性能

Conclusion: 利用视频编解码原语是高效视频语言建模的有效方法，能显著降低计算成本同时维持或提升多任务性能

Abstract: Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\%$ and token usage by up to $93\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications](https://arxiv.org/abs/2602.12338)
*Farshad Zeinali,Mahdi Boloursaz Mashhadi,Dusit Niyato,Rahim Tafazolli*

Main category: cs.LG

TL;DR: 提出混合强化学习框架解决多用户无线TokenCom中的Tokenizer协议问题，结合DQN进行tokenizer选择和子信道分配，DDPG进行波束成形，显著提升语义质量和资源效率。


<details>
  <summary>Details</summary>
Motivation: TokenCom作为新兴通信范式，需要收发双方就tokenizer模型和码本达成一致。在多用户下行无线TokenCom场景中，如何高效进行Tokenizer协议（TA）过程，联合优化tokenizer选择、子信道分配和波束成形，以提升语义质量和资源效率，是本文的研究动机。

Method: 提出混合强化学习框架：1）使用深度Q网络（DQN）联合优化tokenizer协议和子信道分配；2）使用深度确定性策略梯度（DDPG）优化波束成形。将混合整数非凸问题分解为两个子问题，通过RL方法协同求解。

Result: 仿真结果表明，所提框架在语义质量和资源效率方面优于基线方法，与传统H.265方案相比，视频传输中的冻结事件减少了68%。

Conclusion: 混合强化学习框架能有效解决多用户无线TokenCom中的Tokenizer协议问题，通过联合优化tokenizer选择、子信道分配和波束成形，显著提升系统性能，为未来语义和目标导向通信提供有效解决方案。

Abstract: Token Communications (TokenCom) has recently emerged as an effective new paradigm, where tokens are the unified units of multimodal communications and computations, enabling efficient digital semantic- and goal-oriented communications in future wireless networks. To establish a shared semantic latent space, the transmitters/receivers in TokenCom need to agree on an identical tokenizer model and codebook. To this end, an initial Tokenizer Agreement (TA) process is carried out in each communication episode, where the transmitter/receiver cooperate to choose from a set of pre-trained tokenizer models/ codebooks available to them both for efficient TokenCom. In this correspondence, we investigate TA in a multi-user downlink wireless TokenCom scenario, where the base station equipped with multiple antennas transmits video token streams to multiple users. We formulate the corresponding mixed-integer non-convex problem, and propose a hybrid reinforcement learning (RL) framework that integrates a deep Q-network (DQN) for joint tokenizer agreement and sub-channel assignment, with a deep deterministic policy gradient (DDPG) for beamforming. Simulation results show that the proposed framework outperforms baseline methods in terms of semantic quality and resource efficiency, while reducing the freezing events in video transmission by 68% compared to the conventional H.265-based scheme.

</details>


### [7] [On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs](https://arxiv.org/abs/2602.12506)
*Rosie Zhao,Anshul Shah,Xiaoyu Zhu,Xinke Deng,Zhongyu Jiang,Yang Yang,Joerg Liebelt,Arnab Mondal*

Main category: cs.LG

TL;DR: RL微调视觉语言模型在视觉推理基准上表现提升，但对文本扰动敏感，存在准确性-忠实性权衡，需要同时关注正确性、鲁棒性和视觉推理的忠实性。


<details>
  <summary>Details</summary>
Motivation: RL微调已成为增强大语言模型在推理密集型任务上的关键技术，但扩展到视觉语言模型时，这些模型仍存在视觉基础薄弱、幻觉和过度依赖文本线索等脆弱性。需要理解这些脆弱性并开发更全面的评估方法。

Method: 使用简单的受控文本扰动（误导性标题或错误的思维链轨迹）来测试模型鲁棒性，分析RL微调动态，探索对抗性增强和忠实性感知奖励的效果，使用熵基指标评估模型不确定性和校准。

Result: 文本扰动导致鲁棒性和置信度显著下降，特别是在考虑思维链一致性时。RL微调存在准确性-忠实性权衡：提高基准准确性但降低思维链可靠性和对上下文变化的鲁棒性。对抗性增强提高鲁棒性但不能防止忠实性漂移，忠实性感知奖励可以恢复答案与推理的对齐，但与增强结合时训练可能崩溃到捷径策略。

Conclusion: 仅基于准确性的评估存在局限性，需要开发和采用同时强调正确性、鲁棒性和视觉基础推理忠实性的训练和评估协议。

Abstract: Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.

</details>


### [8] [Constraint-Rectified Training for Efficient Chain-of-Thought](https://arxiv.org/abs/2602.12526)
*Qinhang Wu,Sen Lin,Ming Zhang,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: CRT是一个基于约束优化的后训练框架，通过交替最小化推理长度和仅在性能低于参考时修正准确率，实现稳定有效的冗余推理剪枝，显著减少token使用同时保持答案质量。


<details>
  <summary>Details</summary>
Motivation: 虽然长推理链能提升LLM的答案质量和自校正能力，但会导致高推理成本和冗余步骤（过度思考）。现有基于启发式的方法存在准确率下降严重和对超参数敏感的问题，需要更稳定、可解释的高效推理方案。

Method: 提出CRT（约束修正训练）框架，基于参考保护的约束优化，交替最小化推理长度和仅在性能低于参考时修正准确率。采用两阶段训练方案：首先发现最短可靠推理模式，然后在学习到的长度预算下优化准确率。

Result: CRT能持续减少token使用，同时将答案质量维持在稳健可靠的水平。不仅缩短响应长度，还减少内部语言冗余，产生新的评估指标。训练过程自然产生一系列中间检查点，可在不同解释长度下保持正确性。

Conclusion: CRT提供了一个原则性的后训练框架，通过约束优化实现高效推理，在减少推理成本的同时保持答案质量，并能实现细粒度的推理冗长度控制。

Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.

</details>


### [9] [Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference](https://arxiv.org/abs/2602.12542)
*Pengfei Hu,Chang Lu,Feifan Liu,Yue Ning*

Main category: cs.LG

TL;DR: ExtraCare是一个用于临床事件预测的领域自适应框架，通过将患者表征分解为不变和协变组件，在提高预测准确性的同时提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）的深度学习模型在不同数据分布下部署时性能会下降。现有的领域自适应方法虽然可以缓解这种偏移，但其"黑盒"特性阻碍了在临床实践中的广泛应用，因为临床实践需要透明性来建立信任和确保安全。

Method: ExtraCare将患者表征分解为不变组件和协变组件。通过监督这两个组件并在训练中强制它们正交，模型在保留标签信息的同时暴露领域特定的变化。此外，通过将稀疏潜在维度映射到医学概念，并通过有针对性的消融量化它们的贡献，提供人类可理解的解释。

Result: 在两个真实世界的EHR数据集上的多个领域划分设置中评估，ExtraCare表现出优越的性能和增强的透明性。广泛的案例研究证明了其准确的预测和可解释性。

Conclusion: ExtraCare通过分解患者表征为不变和协变组件，不仅提高了临床事件预测的准确性，还提供了可解释性，解决了领域自适应方法在临床实践中因"黑盒"特性而难以广泛应用的问题。

Abstract: Deep learning models for clinical event prediction on electronic health records (EHR) often suffer performance degradation when deployed under different data distributions. While domain adaptation (DA) methods can mitigate such shifts, its "black-box" nature prevents widespread adoption in clinical practice where transparency is essential for trust and safety. We propose ExtraCare to decompose patient representations into invariant and covariant components. By supervising these two components and enforcing their orthogonality during training, our model preserves label information while exposing domain-specific variation at the same time for more accurate predictions than most feature alignment models. More importantly, it offers human-understandable explanations by mapping sparse latent dimensions to medical concepts and quantifying their contributions via targeted ablations. ExtraCare is evaluated on two real-world EHR datasets across multiple domain partition settings, demonstrating superior performance along with enhanced transparency, as evidenced by its accurate predictions and explanations from extensive case studies.

</details>


### [10] [Fractional Order Federated Learning for Battery Electric Vehicle Energy Consumption Modeling](https://arxiv.org/abs/2602.12567)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出FO-RI-FedAvg方法，通过粗糙度感知正则化和分数阶优化改进联邦学习在电动汽车场景下的稳定性


<details>
  <summary>Details</summary>
Motivation: 电动汽车联邦学习面临连接不稳定、客户端参与变化大、数据分布差异显著等挑战，传统FedAvg方法在这些现实约束下容易产生过度漂移和收敛退化

Method: FO-RI-FedAvg方法包含两个客户端机制：1) 自适应粗糙度感知近端正则化，根据局部损失函数粗糙度动态调整向全局模型的拉力；2) 分数阶局部优化，引入短期记忆平滑冲突的更新方向。该方法保持标准FedAvg服务器聚合，仅增加可分摊的元素级操作

Result: 在VED和eVED两个真实世界电动汽车能耗预测数据集上的实验表明，FO-RI-FedAvg相比强基线联邦学习方法获得了更高的准确性和更稳定的收敛，特别是在客户端参与减少的情况下

Conclusion: FO-RI-FedAvg是一个轻量级、模块化的FedAvg扩展，通过客户端侧机制有效提升了电动汽车联邦学习在现实约束下的稳定性，同时保持了计算效率

Abstract: Federated learning on connected electric vehicles (BEVs) faces severe instability due to intermittent connectivity, time-varying client participation, and pronounced client-to-client variation induced by diverse operating conditions. Conventional FedAvg and many advanced methods can suffer from excessive drift and degraded convergence under these realistic constraints. This work introduces Fractional-Order Roughness-Informed Federated Averaging (FO-RI-FedAvg), a lightweight and modular extension of FedAvg that improves stability through two complementary client-side mechanisms: (i) adaptive roughness-informed proximal regularization, which dynamically tunes the pull toward the global model based on local loss-landscape roughness, and (ii) non-integer-order local optimization, which incorporates short-term memory to smooth conflicting update directions. The approach preserves standard FedAvg server aggregation, adds only element-wise operations with amortizable overhead, and allows independent toggling of each component. Experiments on two real-world BEV energy prediction datasets, VED and its extended version eVED, show that FO-RI-FedAvg achieves improved accuracy and more stable convergence compared to strong federated baselines, particularly under reduced client participation.

</details>


### [11] [Vehicle behaviour estimation for abnormal event detection using distributed fiber optic sensing](https://arxiv.org/abs/2602.12591)
*Hemant Prasad,Daisuke Ikefuji,Shin Tominaga,Hitoshi Sakurai,Manabu Otani*

Main category: cs.LG

TL;DR: 提出一种基于分布式光纤传感的交通监测方法，通过追踪车辆路径和检测车道变换来识别单车道异常


<details>
  <summary>Details</summary>
Motivation: 分布式光纤传感系统虽然能有效监测交通拥堵，但难以检测导致拥堵的单车道异常。这些异常可以通过监测车辆为避免拥堵而进行的车道变换行为来识别。

Method: 通过聚类技术估计车辆在所有时间点的位置并拟合路径，通过追踪参考车辆并监测其振动频谱质心的变化来检测车道变换

Result: 使用真实交通数据评估，车道变换检测准确率达到80%，能够有效代表异常存在

Conclusion: 该方法能够有效检测单车道异常，为分布式光纤传感系统的交通监测提供了新的能力

Abstract: The distributed fiber-optic sensing (DFOS) system is a cost-effective wide-area traffic monitoring technology that utilizes existing fiber infrastructure to effectively detect traffic congestions. However, detecting single-lane abnormalities, that lead to congestions, is still a challenge. These single-lane abnormalities can be detected by monitoring lane change behaviour of vehicles, performed to avoid congestion along the monitoring section of a road. This paper presents a method to detect single-lane abnormalities by tracking individual vehicle paths and detecting vehicle lane changes along a section of a road. We propose a method to estimate the vehicle position at all time instances and fit a path using clustering techniques. We detect vehicle lane change by monitoring any change in spectral centroid of vehicle vibrations by tracking a reference vehicle along a highway. The evaluation of our proposed method with real traffic data showed 80% accuracy for lane change detection events that represent presence of abnormalities.

</details>


### [12] [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)
*Justin Gu,Rishabh Ranjan,Charilaos Kanatsoulis,Haiming Tang,Martin Jurkovic,Valter Hudovernik,Mark Znidar,Pranshu Chaturvedi,Parth Shroff,Fengyu Li,Jure Leskovec*

Main category: cs.LG

TL;DR: RelBench v2 是一个扩展的关系深度学习基准测试，新增了4个大规模数据集和自动补全任务，整合了外部基准，包含11个数据集、29个表、2200万行数据，实验显示关系模型优于单表基线。


<details>
  <summary>Details</summary>
Motivation: 随着关系深度学习向更大模型和关系基础模型发展，需要可扩展且真实的基准测试来进行系统性评估和推动进展。现有的基准测试在规模、任务多样性和外部整合方面存在不足。

Method: 1) 新增4个大规模关系数据集（学术出版物、企业资源规划、消费者平台、临床记录）；2) 引入自动补全任务，要求模型在关系表中推断缺失属性值；3) 整合外部基准：将Temporal Graph Benchmark转换为关系模式，与ReDeLEx接口连接70+真实数据库，纳入4DBInfer数据集；4) 扩展至11个数据集、29个表、2200万行数据。

Result: 实验结果表明，关系深度学习模型在自动补全、预测和推荐任务上持续优于单表基线，验证了显式建模关系结构的重要性。基准测试规模显著扩大，任务类型更加丰富。

Conclusion: RelBench v2 为关系深度学习提供了一个更全面、可扩展的基准测试框架，支持更广泛的评估场景，促进了关系深度学习领域的系统性进展。

Abstract: Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic benchmarks are essential for enabling systematic evaluation and progress. In this paper, we introduce RelBench v2, a major expansion of the RelBench benchmark for RDL. RelBench v2 adds four large-scale relational datasets spanning scholarly publications, enterprise resource planning, consumer platforms, and clinical records, increasing the benchmark to 11 datasets comprising over 22 million rows across 29 tables. We further introduce autocomplete tasks, a new class of predictive objectives that require models to infer missing attribute values directly within relational tables while respecting temporal constraints, expanding beyond traditional forecasting tasks constructed via SQL queries. In addition, RelBench v2 expands beyond its native datasets by integrating external benchmarks and evaluation frameworks: we translate event streams from the Temporal Graph Benchmark into relational schemas for unified relational-temporal evaluation, interface with ReDeLEx to provide uniform access to 70+ real-world databases suitable for pretraining, and incorporate 4DBInfer datasets and tasks to broaden multi-table prediction coverage. Experimental results demonstrate that RDL models consistently outperform single-table baselines across autocomplete, forecasting, and recommendation tasks, highlighting the importance of modeling relational structure explicitly.

</details>


### [13] [Can Neural Networks Provide Latent Embeddings for Telemetry-Aware Greedy Routing?](https://arxiv.org/abs/2602.12798)
*Andreas Boltres,Niklas Freymuth,Gerhard Neumann*

Main category: cs.LG

TL;DR: Placer使用消息传递网络将网络状态转换为节点嵌入，实现快速贪婪下一跳路由，同时提供路由决策的可视化解释


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的遥测感知路由方法牺牲了路由决策的可解释性，因为神经网络模块是黑盒。需要一种既能利用机器学习处理复杂网络状态依赖，又能保持路由决策可解释性的方法。

Method: 使用消息传递网络将网络状态转换为潜在节点嵌入，这些嵌入支持快速贪婪下一跳路由，无需直接解决全对最短路径问题，并能可视化网络事件如何影响路由决策。

Result: Placer算法能够高效处理网络状态与路由之间的复杂依赖关系，同时提供路由决策的可视化解释，增强了遥测感知路由的可解释性。

Conclusion: Placer通过消息传递网络和节点嵌入技术，在保持机器学习优势的同时解决了路由决策可解释性问题，为网络管理提供了更好的可视化和理解能力。

Abstract: Telemetry-Aware routing promises to increase efficacy and responsiveness to traffic surges in computer networks. Recent research leverages Machine Learning to deal with the complex dependency between network state and routing, but sacrifices explainability of routing decisions due to the black-box nature of the proposed neural routing modules. We propose \emph{Placer}, a novel algorithm using Message Passing Networks to transform network states into latent node embeddings. These embeddings facilitate quick greedy next-hop routing without directly solving the all-pairs shortest paths problem, and let us visualize how certain network events shape routing decisions.

</details>


### [14] [GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories](https://arxiv.org/abs/2602.12828)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: GRAIL框架通过结构化几何表示和结构感知检索预测临床事件，结合确定性编码层次和数据驱动关联，在双曲空间嵌入临床图，利用LLM作为推理时重排器提升预测效果。


<details>
  <summary>Details</summary>
Motivation: 从纵向电子健康记录预测未来临床事件面临挑战：稀疏的多类型临床事件、层次化医学词汇表、以及大语言模型在处理长结构化历史时容易产生幻觉。需要解决这些限制来准确预测患者下一次就诊的临床事件。

Method: GRAIL框架：1) 构建统一临床图，结合确定性编码系统层次和数据驱动的跨事件类型时间关联；2) 在双曲空间中嵌入该图；3) 将每次就诊总结为概率性中心事件以去噪稀疏观测；4) 推理时检索结构化的临床合理未来事件集合，与层次和时间进展对齐；5) 可选使用LLM作为约束推理时重排器优化排名。

Result: 在MIMIC-IV数据集上的实验表明，GRAIL持续改进多类型下次就诊预测，并产生更符合层次一致性的预测结果。

Conclusion: GRAIL通过结构化几何表示和结构感知检索有效解决了从稀疏纵向EHR预测临床事件的挑战，结合图表示、双曲嵌入和LLM重排，实现了更准确和层次一致的预测。

Abstract: Predicting future clinical events from longitudinal electronic health records (EHRs) is challenging due to sparse multi-type clinical events, hierarchical medical vocabularies, and the tendency of large language models (LLMs) to hallucinate when reasoning over long structured histories. We study next-visit event prediction, which aims to forecast a patient's upcoming clinical events based on prior visits. We propose GRAIL, a framework that models longitudinal EHRs using structured geometric representations and structure-aware retrieval. GRAIL constructs a unified clinical graph by combining deterministic coding-system hierarchies with data-driven temporal associations across event types, embeds this graph in hyperbolic space, and summarizes each visit as a probabilistic Central Event that denoises sparse observations. At inference time, GRAIL retrieves a structured set of clinically plausible future events aligned with hierarchical and temporal progression, and optionally refines their ranking using an LLM as a constrained inference-time reranker. Experiments on MIMIC-IV show that GRAIL consistently improves multi-type next-visit prediction and yields more hierarchy-consistent forecasts.

</details>


### [15] [TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)](https://arxiv.org/abs/2602.12833)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: TRACE框架通过双记忆架构和四个智能体组件，使冻结的大型语言模型能够在纵向患者轨迹中进行时间临床推理，无需扩展上下文窗口或更新参数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然编码了丰富的医学知识，但在处理纵向患者轨迹时表现不佳，因为临床状态演变、不规则时间安排和异质事件会随时间降低性能。现有方法依赖微调或检索增强，但存在计算开销、隐私限制或长上下文不稳定等问题。

Method: TRACE框架采用双记忆架构：静态的全局协议编码机构临床规则，动态的个体协议跟踪患者特定状态。四个智能体组件（路由器、推理器、审计员、管理员）在此结构化记忆上协调工作，支持时间推理和状态演变。通过结构化状态压缩保持有限推理成本，并选择性审计安全关键的临床决策。

Result: 在MIMIC-IV的纵向临床事件流上评估，TRACE显著提高了下一事件预测准确性、协议遵从性和临床安全性，优于长上下文和检索增强基线，同时产生可解释和可审计的推理轨迹。

Conclusion: TRACE框架通过结构化记忆和智能体协调，使冻结的LLM能够有效处理纵向临床推理任务，在保持有限计算成本的同时提高性能、安全性和可解释性。

Abstract: Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a framework that enables temporal clinical reasoning with frozen LLMs by explicitly structuring and maintaining context rather than extending context windows or updating parameters. TRACE operates over a dual-memory architecture consisting of a static Global Protocol encoding institutional clinical rules and a dynamic Individual Protocol tracking patient-specific state. Four agentic components, Router, Reasoner, Auditor, and Steward, coordinate over this structured memory to support temporal inference and state evolution. The framework maintains bounded inference cost via structured state compression and selectively audits safety-critical clinical decisions. Evaluated on longitudinal clinical event streams from MIMIC-IV, TRACE significantly improves next-event prediction accuracy, protocol adherence, and clinical safety over long-context and retrieval-augmented baselines, while producing interpretable and auditable reasoning traces.

</details>


### [16] [X-VORTEX: Spatio-Temporal Contrastive Learning for Wake Vortex Trajectory Forecasting](https://arxiv.org/abs/2602.12869)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: X-VORTEX是一个基于增强重叠理论的时空对比学习框架，用于从无标签的LiDAR点云序列中学习物理感知的尾涡表示，解决了传感器稀疏性和时变涡流动力学两大核心挑战。


<details>
  <summary>Details</summary>
Motivation: 飞机尾涡是强烈的空气湍流，对空中交通管理构成安全和容量挑战。现有方法将每次扫描视为独立的监督分割问题，忽略了时间结构，且无法扩展到实践中收集的大量无标签数据。

Method: 提出X-VORTEX框架，通过结合弱扰动序列和强增强对应序列构建配对输入（使用时间子采样和空间掩码），采用时间分布几何编码器提取每帧特征，序列聚合器建模可变长度序列中的涡流状态演化。

Result: 在超过100万次LiDAR扫描的真实数据集上，X-VORTEX实现了优越的涡流中心定位，仅使用监督基线所需标记数据的1%，且学习到的表示支持准确的轨迹预测。

Conclusion: X-VORTEX通过时空对比学习有效解决了尾涡跟踪中的传感器稀疏性和时变动态问题，显著减少了标记数据需求，为实际空中交通管理提供了可扩展的解决方案。

Abstract: Wake vortices are strong, coherent air turbulences created by aircraft, and they pose a major safety and capacity challenge for air traffic management. Tracking how vortices move, weaken, and dissipate over time from LiDAR measurements is still difficult because scans are sparse, vortex signatures fade as the flow breaks down under atmospheric turbulence and instabilities, and point-wise annotation is prohibitively expensive. Existing approaches largely treat each scan as an independent, fully supervised segmentation problem, which overlooks temporal structure and does not scale to the vast unlabeled archives collected in practice. We present X-VORTEX, a spatio-temporal contrastive learning framework grounded in Augmentation Overlap Theory that learns physics-aware representations from unlabeled LiDAR point cloud sequences. X-VORTEX addresses two core challenges: sensor sparsity and time-varying vortex dynamics. It constructs paired inputs from the same underlying flight event by combining a weakly perturbed sequence with a strongly augmented counterpart produced via temporal subsampling and spatial masking, encouraging the model to align representations across missing frames and partial observations. Architecturally, a time-distributed geometric encoder extracts per-scan features and a sequential aggregator models the evolving vortex state across variable-length sequences. We evaluate on a real-world dataset of over one million LiDAR scans. X-VORTEX achieves superior vortex center localization while using only 1% of the labeled data required by supervised baselines, and the learned representations support accurate trajectory forecasting.

</details>


### [17] [Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling](https://arxiv.org/abs/2602.12976)
*Jin Li,Kleanthis Malialis,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.LG

TL;DR: VAE++ESDD：一种结合增量学习和双层集成（VAE集成用于异常检测，概念漂移检测器集成）的方法，用于处理非平稳环境中的无标签流数据异常检测。


<details>
  <summary>Details</summary>
Motivation: 数字世界中大量流数据无标签，难以检测异常，特别是在非平稳环境下存在概念漂移问题，导致模型性能随时间下降。

Method: 提出VAE++ESDD方法，采用增量学习和双层集成：1）变分自编码器（VAE）集成用于异常预测；2）概念漂移检测器集成，每个检测器使用基于统计的概念漂移机制。

Result: 在具有极低异常率和各种漂移特征的真实世界和合成数据集上进行实验，结果显示该方法显著优于强基线和最先进方法。

Conclusion: VAE++ESDD有效解决了非平稳环境中无标签流数据的异常检测问题，通过集成学习和概念漂移检测机制提升了性能。

Abstract: In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.

</details>


### [18] [Eventizing Traditionally Opaque Binary Neural Networks as 1-safe Petri net Models](https://arxiv.org/abs/2602.13128)
*Mohamed Tarraf,Alex Chan,Alex Yakovlev,Rishad Shafik*

Main category: cs.LG

TL;DR: 提出基于Petri网的框架，将二值神经网络的事件驱动过程建模，实现因果透明度和形式化验证


<details>
  <summary>Details</summary>
Motivation: 二值神经网络虽然低复杂度、高能效，但其离散非线性行为难以解释、验证和形式化验证，限制了在安全关键领域的应用

Method: 引入Petri网框架，将BNN内部操作建模为事件驱动过程，构建核心组件（激活、梯度计算、权重更新）的模块化PN蓝图，并组合成系统级模型

Result: 验证了PN模型与参考软件BNN的一致性，通过可达性和结构检查验证了1-安全性、无死锁、互斥和正确因果序列，使用Workcraft工具评估了可扩展性和复杂性

Conclusion: 该框架实现了事件驱动BNN的因果内省，使其适合形式化推理和验证，提高了BNN在安全关键领域的适用性

Abstract: Binary Neural Networks (BNNs) offer a low-complexity and energy-efficient alternative to traditional full-precision neural networks by constraining their weights and activations to binary values. However, their discrete, highly non-linear behavior makes them difficult to explain, validate and formally verify. As a result, BNNs remain largely opaque, limiting their suitability in safety-critical domains, where causal transparency and behavioral guarantees are essential. In this work, we introduce a Petri net (PN)-based framework that captures the BNN's internal operations as event-driven processes. By "eventizing" their operations, we expose their causal relationships and dependencies for a fine-grained analysis of concurrency, ordering, and state evolution. Here, we construct modular PN blueprints for core BNN components including activation, gradient computation and weight updates, and compose them into a complete system-level model. We then validate the composed PN against a reference software-based BNN, verify it against reachability and structural checks to establish 1-safeness, deadlock-freeness, mutual exclusion and correct-by-construction causal sequencing, before we assess its scalability and complexity at segment, component, and system levels using the automated measurement tools in Workcraft. Overall, this framework enables causal introspection of transparent and event-driven BNNs that are amenable to formal reasoning and verification.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting](https://arxiv.org/abs/2602.12389)
*Siyuan Li,Yunjia Wu,Yiyong Xiao,Pingyang Huang,Peize Li,Ruitong Liu,Yan Wen,Te Sun,Fangyi Pei*

Main category: cs.AI

TL;DR: 提出Entity State Tuning (EST)框架，通过维护持久且持续演化的实体状态来解决TKG预测中的长期依赖问题，显著提升了多种骨干模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有TKG预测方法大多是无状态的，每次时间戳都从有限查询窗口重新计算实体表示，导致"情景性遗忘"和长期依赖快速衰减，限制了长期预测能力。

Method: EST框架包含：1) 全局状态缓冲区存储持久实体状态；2) 拓扑感知状态感知器将实体状态先验注入结构编码；3) 统一时序上下文模块聚合状态增强事件；4) 双轨演化机制平衡可塑性与稳定性，将更新上下文写回全局状态内存。

Result: 在多个基准测试中，EST框架一致性地提升了多种骨干模型的性能，并取得了最先进的预测结果，证明了状态持久性对长期TKG预测的重要性。

Conclusion: EST通过维护持续演化的实体状态有效解决了TKG预测中的长期依赖问题，为TKG预测器提供了持久记忆能力，显著提升了长期预测性能。

Abstract: Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity representations at each timestamp from a limited query window, leading to episodic amnesia and rapid decay of long-term dependencies. To address this limitation, we propose Entity State Tuning (EST), an encoder-agnostic framework that endows TKG forecasters with persistent and continuously evolving entity states. EST maintains a global state buffer and progressively aligns structural evidence with sequential signals via a closed-loop design. Specifically, a topology-aware state perceiver first injects entity-state priors into structural encoding. Then, a unified temporal context module aggregates the state-enhanced events with a pluggable sequence backbone. Subsequently, a dual-track evolution mechanism writes the updated context back to the global entity state memory, balancing plasticity against stability. Experiments on multiple benchmarks show that EST consistently improves diverse backbones and achieves state-of-the-art performance, highlighting the importance of state persistence for long-horizon TKG forecasting. The code is published at https://github.com/yuanwuyuan9/Evolving-Beyond-Snapshots

</details>


### [20] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 提出混合障碍物规避架构，结合最优控制与模糊规则系统，实现无人机自适应约束处理，但发现FALCON和IPOPT软件存在兼容性问题导致约束无法执行。


<details>
  <summary>Details</summary>
Motivation: 经典最优控制在不确定性下的局限性，以及航空安全关键系统需要可解释决策，促使开发能自适应处理约束的混合架构。

Method: 采用三层Takagi-Sugeno-Kang模糊系统，基于FAA和EASA法规调整约束半径、紧急程度和激活决策，将模糊生成的间隙作为软约束纳入最优控制问题，使用FALCON工具箱和IPOPT求解。

Result: 概念验证显示每次迭代计算时间2-3秒，适合近实时应用，但发现FALCON和IPOPT最新版本存在软件不兼容问题，拉格朗日惩罚项始终为零，导致约束无法执行。

Conclusion: 混合架构有潜力，但需解决软件兼容性问题。未来工作包括验证早期软件版本、优化模糊隶属函数、扩展到高保真飞机模型和随机障碍环境。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [A Lightweight LLM Framework for Disaster Humanitarian Information Classification](https://arxiv.org/abs/2602.12284)
*Han Jinzhen,Kim Jisung,Yang Jong Soo,Yun Hong Sik*

Main category: cs.CL

TL;DR: 本文开发了一个轻量级、成本效益高的灾害推文分类框架，使用参数高效微调，在Llama 3.1 8B上通过LoRA和QLoRA实现了高效部署，发现RAG策略会降低微调模型性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的人道主义信息及时分类对有效的灾害响应至关重要，但在资源受限的紧急环境中部署大型语言模型面临挑战，需要开发轻量级、成本效益高的解决方案。

Method: 通过整合和标准化HumAID数据集构建统一实验语料库，形成双任务基准：人道主义信息分类和事件类型识别。系统评估提示策略、LoRA微调和检索增强生成(RAG)在Llama 3.1 8B上的表现。

Result: LoRA实现了79.62%的人道主义分类准确率（比零样本学习提高37.79%），仅训练约2%的参数；QLoRA以50%内存成本实现LoRA性能的99.4%；RAG策略会因检索示例的标签噪声而降低微调模型性能。

Conclusion: 这些发现为在有限计算资源下构建可靠危机情报系统建立了一个实用、可复现的流程，证明了参数高效微调在资源受限环境中的有效性。

Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper develops a lightweight, cost-effective framework for disaster tweet classification using parameter-efficient fine-tuning. We construct a unified experimental corpus by integrating and normalizing the HumAID dataset (76,484 tweets across 19 disaster events) into a dual-task benchmark: humanitarian information categorization and event type identification. Through systematic evaluation of prompting strategies, LoRA fine-tuning, and retrieval-augmented generation (RAG) on Llama 3.1 8B, we demonstrate that: (1) LoRA achieves 79.62% humanitarian classification accuracy (+37.79% over zero-shot) while training only ~2% of parameters; (2) QLoRA enables efficient deployment with 99.4% of LoRA performance at 50% memory cost; (3) contrary to common assumptions, RAG strategies degrade fine-tuned model performance due to label noise from retrieved examples. These findings establish a practical, reproducible pipeline for building reliable crisis intelligence systems with limited computational resources.

</details>


### [22] [propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale](https://arxiv.org/abs/2602.12414)
*Maximilian Idahl,Benedikt Droste,Björn Plüster,Jan Philipp Harries*

Main category: cs.CL

TL;DR: 提出propella-1系列小型多语言LLM，用于文本文档的多维度质量标注，替代传统单一评分方法，并发布包含30亿文档标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前LLM预训练数据筛选主要依赖小型分类器产生的单一质量分数，这种方法存在三个问题：1）将多个质量维度混为一谈；2）无法灵活过滤；3）缺乏可解释性。需要更精细的多维度标注方法。

Method: 开发propella-1系列小型多语言LLM（0.6B、1.7B、4B参数），支持57种语言，按照预定义模式生成结构化JSON标注，涵盖18个属性，分为六个类别：核心内容、分类、质量与价值、受众与目的、安全合规、地理相关性。

Result: 4B模型在标注一致性上优于更大的通用模型；发布了propella-annotations数据集，包含超过30亿文档标注，覆盖FineWeb-2、FinePDFs、HPLT 3.0、Nemotron-CC等主要预训练语料；多维度分析揭示了传统单一评分方法无法捕捉的质量、推理深度和内容构成差异。

Conclusion: propella-1模型提供了比单一评分更精细、灵活、可解释的数据标注方法，有助于改进LLM预训练数据筛选，所有模型权重和标注数据都采用商业友好的许可协议发布。

Abstract: Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no interpretability. We introduce propella-1, a family of small multilingual LLMs (0.6B, 1.7B, 4B parameters) that annotate text documents across 18 properties organized into six categories: core content, classification, quality and value, audience and purpose, safety and compliance, and geographic relevance. The models support 57 languages and produce structured JSON annotations conforming to a predefined schema. Evaluated against a frontier commercial LLM as a reference annotator, the 4B model achieves higher agreement than much larger general-purpose models. We release propella-annotations, a dataset of over three billion document annotations covering major pretraining corpora including data from FineWeb-2, FinePDFs, HPLT 3.0, and Nemotron-CC. Using these annotations, we present a multi-dimensional compositional analysis of widely used pretraining datasets, revealing substantial differences in quality, reasoning depth, and content composition that single-score approaches cannot capture. All model weights and annotations are released under permissive, commercial-use licenses.

</details>


### [23] [Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats](https://arxiv.org/abs/2602.12635)
*Pengxiang Zhao,Hui-Ling Zhen,Xing Li,Han Bao,Weizhe Lin,Zhiyuan Yang,Ziwei Yu,Xin Wang,Mingxuan Yuan,Xianzhi Yu,Zhenhua Dong*

Main category: cs.CL

TL;DR: HiFloat浮点格式（HiF8和HiF4）专为Ascend NPU设计，在4位量化中通过分层缩放避免精度崩溃，兼容现有PTQ框架，为NPU上的高效LLM推理提供解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，低比特浮点格式（如MXFP和NVFP4）为精度和效率提供了新机会。需要评估专为Ascend NPU设计的HiFloat格式家族的性能表现。

Method: 通过严格的比较评估HiFloat格式（HiF8和HiF4），涵盖权重-激活和KV缓存任务，分析不同格式在不同数据分布下的表现。

Result: 获得三个关键发现：1) INT8适合窄范围数据，浮点格式在高方差数据中表现更佳；2) 在4位量化中，HiF4的分层缩放避免了整数格式的精度崩溃；3) HiFloat完全兼容最先进的训练后量化框架。

Conclusion: HiFloat为NPU上的高效大语言模型推理提供了一个有效的解决方案，特别是在4位量化场景中表现出色。

Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.

</details>


### [24] [RAT-Bench: A Comprehensive Benchmark for Text Anonymization](https://arxiv.org/abs/2602.12806)
*Nataša Krčo,Zexi Yao,Matthieu Meeus,Yves-Alexandre de Montjoye*

Main category: cs.CL

TL;DR: RAT-Bench是一个基于再识别风险的文本匿名化工具基准测试，使用美国人口统计生成合成文本，评估发现现有工具在非标准直接标识符和间接标识符方面存在不足，LLM匿名化工具提供更好的隐私-效用权衡但计算成本更高。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化工具（如Microsoft Presidio、Anthropic PII purifier）通常只评估其移除特定标识符（如姓名）的能力，但它们在防止再识别方面的实际效果尚不清楚，需要建立基于再识别风险的全面评估基准。

Method: 提出RAT-Bench基准测试：1）使用美国人口统计数据生成包含各种直接和间接标识符的合成文本；2）涵盖不同领域、语言和难度级别；3）评估基于NER和LLM的文本匿名化工具；4）基于LLM攻击者能从匿名化文本中正确推断的属性，计算在美国人口中的再识别风险；5）适当考虑标识符的不同影响。

Result: 1）不同工具能力差异很大；2）即使最好的工具也远非完美，特别是在直接标识符非标准书写和间接标识符能实现再识别的情况下；3）基于LLM的匿名化工具（包括新的迭代匿名化器）提供更好的隐私-效用权衡，但计算成本更高；4）LLM工具在不同语言中表现良好。

Conclusion: 需要开发更有效的文本匿名化工具，特别是要处理非标准标识符和间接标识符。将发布RAT-Bench基准并鼓励社区扩展，特别是扩展到其他地理区域。

Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio or Anthropic's PII purifier. These tools have traditionally been evaluated on their ability to remove specific identifiers (e.g., names), yet their effectiveness at preventing re-identification remains unclear. We introduce RAT-Bench, a comprehensive benchmark for text anonymization tools based on re-identification risk. Using U.S. demographic statistics, we generate synthetic text containing various direct and indirect identifiers across domains, languages, and difficulty levels. We evaluate a range of NER- and LLM-based text anonymization tools and, based on the attributes an LLM-based attacker is able to correctly infer from the anonymized text, we report the risk of re-identification in the U.S. population, while properly accounting for the disparate impact of identifiers. We find that, while capabilities vary widely, even the best tools are far from perfect in particular when direct identifiers are not written in standard ways and when indirect identifiers enable re-identification. Overall we find LLM-based anonymizers, including new iterative anonymizers, to provide a better privacy-utility trade-off albeit at a higher computational cost. Importantly, we also find them to work well across languages. We conclude with recommendations for future anonymization tools and will release the benchmark and encourage community efforts to expand it, in particular to other geographies.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [25] [An Autonomous, End-to-End, Convex-Based Framework for Close-Range Rendezvous Trajectory Design and Guidance with Hardware Testbed Validation](https://arxiv.org/abs/2602.12421)
*Minduli C. Wijayatunga,Julian Guinane,Nathan D. Wallace,Xiaofeng Wu*

Main category: cs.RO

TL;DR: CORTEX是一个用于近距离交会对接的自主感知-优化轨迹设计与制导框架，结合深度学习感知与凸优化，具备实时重规划和安全轨道中止能力，在仿真和硬件测试中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 自主卫星服务任务需要在严格的安全和操作约束下执行近距离交会对接，同时保持计算可行性以适应机载使用，并应对感知、执行和动力学的不确定性。

Method: CORTEX框架整合了深度学习感知管道与基于凸优化的轨迹设计和制导，包括参考轨迹重新生成和安全轨道中止逻辑，以应对传感器故障和发动机故障导致的大偏差。

Result: 在高保真软件仿真中，蒙特卡洛测试在最严苛情况下达到终端对接误差：位置36.85±44.46毫米，速度1.25±2.26毫米/秒。在平面气浮测试台上，18个测试案例（10个标称，8个非标称）达到位置误差8.09±5.29毫米，速度误差2.23±1.72毫米/秒。

Conclusion: CORTEX框架成功实现了自主、感知启用的实时轨迹设计与制导，在仿真和硬件测试中展示了鲁棒性能，能够处理传感器故障和发动机故障等非标称情况。

Abstract: Autonomous satellite servicing missions must execute close-range rendezvous under stringent safety and operational constraints while remaining computationally tractable for onboard use and robust to uncertainty in sensing, actuation, and dynamics. This paper presents CORTEX (Convex Optimization for Rendezvous Trajectory Execution), an autonomous, perception-enabled, real-time trajectory design and guidance framework for close-range rendezvous. CORTEX integrates a deep-learning perception pipeline with convex-optimisation-based trajectory design and guidance, including reference regeneration and abort-to-safe-orbit logic to recover from large deviations caused by sensor faults and engine failures.
  CORTEX is validated in high-fidelity software simulation and hardware-in-the-loop experiments. The software pipeline (Basilisk) models high-fidelity relative dynamics, realistic thruster execution, perception, and attitude control. Hardware testing uses (i) an optical navigation testbed to assess perception-to-estimation performance and (ii) a planar air-bearing testbed to evaluate the end-to-end guidance loop under representative actuation and subsystem effects. A Monte-Carlo campaign in simulation includes initial-state uncertainty, thrust-magnitude errors, and missed-thrust events; under the strongest case investigated, CORTEX achieves terminal docking errors of $36.85 \pm 44.46$ mm in relative position and $1.25 \pm 2.26$ mm/s in relative velocity. On the planar air-bearing testbed, 18 cases are executed (10 nominal; 8 off-nominal requiring recomputation and/or abort due to simulated engine failure and sensor malfunctions), yielding terminal errors of $8.09 \pm 5.29$ mm in position and $2.23 \pm 1.72$ mm/s in velocity.

</details>


### [26] [Eva-Tracker: ESDF-update-free, Visibility-aware Planning with Target Reacquisition for Robust Aerial Tracking](https://arxiv.org/abs/2602.12549)
*Yue Lin,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: Eva-Tracker：一种用于空中跟踪的可见性感知轨迹规划框架，通过预计算的FoV-ESDF消除ESDF更新开销，并集成目标重获恢复能力


<details>
  <summary>Details</summary>
Motivation: 传统ESDF在可见性评估中广泛使用，但频繁更新带来巨大计算开销，影响跟踪系统的实时性和效率

Method: 1) 目标轨迹预测和可见性感知初始路径生成算法；2) 预计算的FoV-ESDF（视野ESDF）实现快速可见性评估；3) 基于可微分FoV-ESDF目标的轨迹优化

Result: 在大量仿真和真实世界实验中，该方法相比现有最先进方法提供了更鲁棒的跟踪结果，同时计算开销更低

Conclusion: Eva-Tracker通过消除ESDF更新需求，实现了高效、鲁棒的空中跟踪，在保持连续可见性的同时显著降低了计算负担

Abstract: The Euclidean Signed Distance Field (ESDF) is widely used in visibility evaluation to prevent occlusions and collisions during tracking. However, frequent ESDF updates introduce considerable computational overhead. To address this issue, we propose Eva-Tracker, a visibility-aware trajectory planning framework for aerial tracking that eliminates ESDF updates and incorporates a recovery-capable path generation method for target reacquisition. First, we design a target trajectory prediction method and a visibility-aware initial path generation algorithm that maintain an appropriate observation distance, avoid occlusions, and enable rapid replanning to reacquire the target when it is lost. Then, we propose the Field of View ESDF (FoV-ESDF), a precomputed ESDF tailored to the tracker's field of view, enabling rapid visibility evaluation without requiring updates. Finally, we optimize the trajectory using differentiable FoV-ESDF-based objectives to ensure continuous visibility throughout the tracking process. Extensive simulations and real-world experiments demonstrate that our approach delivers more robust tracking results with lower computational effort than existing state-of-the-art methods. The source code is available at https://github.com/Yue-0/Eva-Tracker.

</details>


### [27] [INHerit-SG: Incremental Hierarchical Semantic Scene Graphs with RAG-Style Retrieval](https://arxiv.org/abs/2602.12971)
*YukTungSamuel Fang,Zhikang Shi,Jiabin Qiu,Zixuan Chen,Jieqi Shi,Hao Xu,Jing Huo,Yang Gao*

Main category: cs.RO

TL;DR: INHerit-SG 是一个用于机器人导航的语义场景图系统，通过结构化知识库和显式语义锚点来更好地对齐人类意图，采用异步双进程架构和事件触发更新机制，在复杂查询中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义场景图方法依赖于离线批处理或隐式特征嵌入，难以支持复杂环境中可解释的人类意图推理，与具身任务需求存在根本性不匹配。

Method: 1) 将地图重新定义为结构化、RAG就绪的知识库，引入自然语言描述作为显式语义锚点；2) 采用异步双进程架构和Floor-Room-Area-Object层次结构，解耦几何分割与语义推理；3) 事件触发的地图更新机制仅在发生有意义语义事件时重组图；4) 使用多角色LLM分解查询并处理逻辑否定，采用硬到软过滤策略确保鲁棒推理。

Result: 在HM3DSem-SQR新构建的数据集和真实环境中评估，系统在复杂查询上达到最先进性能，并展示了下游导航任务的可扩展性。

Conclusion: INHerit-SG通过显式可解释性提高了复杂检索的成功率和可靠性，使系统能够适应更广泛的人类交互任务，同时以相对较低的计算开销保持长期一致性。

Abstract: Driven by advancements in foundation models, semantic scene graphs have emerged as a prominent paradigm for high-level 3D environmental abstraction in robot navigation. However, existing approaches are fundamentally misaligned with the needs of embodied tasks. As they rely on either offline batch processing or implicit feature embeddings, the maps can hardly support interpretable human-intent reasoning in complex environments. To address these limitations, we present INHerit-SG. We redefine the map as a structured, RAG-ready knowledge base where natural-language descriptions are introduced as explicit semantic anchors to better align with human intent. An asynchronous dual-process architecture, together with a Floor-Room-Area-Object hierarchy, decouples geometric segmentation from time-consuming semantic reasoning. An event-triggered map update mechanism reorganizes the graph only when meaningful semantic events occur. This strategy enables our graph to maintain long-term consistency with relatively low computational overhead. For retrieval, we deploy multi-role Large Language Models (LLMs) to decompose queries into atomic constraints and handle logical negations, and employ a hard-to-soft filtering strategy to ensure robust reasoning. This explicit interpretability improves the success rate and reliability of complex retrievals, enabling the system to adapt to a broader spectrum of human interaction tasks. We evaluate INHerit-SG on a newly constructed dataset, HM3DSem-SQR, and in real-world environments. Experiments demonstrate that our system achieves state-of-the-art performance on complex queries, and reveal its scalability for downstream navigation tasks. Project Page: https://fangyuktung.github.io/INHeritSG.github.io/

</details>


### [28] [Agentic AI for Robot Control: Flexible but still Fragile](https://arxiv.org/abs/2602.13081)
*Oscar Lima,Marc Vinci,Martin Günther,Marian Renz,Alexander Sung,Sebastian Stock,Johannes Brust,Lennart Niecksch,Zongyao Yi,Felix Igelbrink,Benjamin Kisliuk,Martin Atzmueller,Joachim Hertzberg*

Main category: cs.RO

TL;DR: 论文提出一个基于推理能力语言模型的机器人控制系统，通过迭代规划-执行循环选择和调用机器人技能，在移动操作和农业导航两个平台上进行了概念验证实验。


<details>
  <summary>Details</summary>
Motivation: 利用生成式模型的能力和常识先验进行机器人控制，解决不确定性、部分可观测性、传感器噪声和模糊自然语言指令等挑战。

Method: 构建基于语言模型的智能控制系统，采用迭代规划-执行循环，支持结构化内省、显式事件检查和操作员干预，通过更新系统提示和工具接口绑定实现跨平台迁移。

Result: 在两个物理机器人平台上成功部署：室内移动操作（Mobipick）和自主农业导航（Valdemar），系统表现出灵活性但存在显著脆弱性，包括非确定性次优行为、指令跟随错误和对提示规范的高敏感性。

Conclusion: 基于语言模型的机器人控制系统具有架构灵活性，能够适应不同平台和任务领域，但当前存在脆弱性问题，需要在鲁棒性和可靠性方面进一步改进。

Abstract: Recent work leverages the capabilities and commonsense priors of generative models for robot control. In this paper, we present an agentic control system in which a reasoning-capable language model plans and executes tasks by selecting and invoking robot skills within an iterative planner and executor loop. We deploy the system on two physical robot platforms in two settings: (i) tabletop grasping, placement, and box insertion in indoor mobile manipulation (Mobipick) and (ii) autonomous agricultural navigation and sensing (Valdemar). Both settings involve uncertainty, partial observability, sensor noise, and ambiguous natural-language commands. The system exposes structured introspection of its planning and decision process, reacts to exogenous events via explicit event checks, and supports operator interventions that modify or redirect ongoing execution. Across both platforms, our proof-of-concept experiments reveal substantial fragility, including non-deterministic suboptimal behavior, instruction-following errors, and high sensitivity to prompt specification. At the same time, the architecture is flexible: transfer to a different robot and task domain largely required updating the system prompt (domain model, affordances, and action catalogue) and re-binding the same tool interface to the platform-specific skill API.

</details>
