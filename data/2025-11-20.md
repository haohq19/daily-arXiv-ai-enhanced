<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [InstructMix2Mix: Consistent Sparse-View Editing Through Multi-View Model Personalization](https://arxiv.org/abs/2511.14899)
*Daniel Gilo,Or Litany*

Main category: cs.CV

TL;DR: 提出InstructMix2Mix框架，将2D扩散模型的编辑能力蒸馏到预训练的多视图扩散模型中，用于从稀疏输入视图进行多视图图像编辑，保持跨视图一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于逐场景神经场或时序注意力机制的方法在多视图编辑中容易产生伪影和不一致编辑，需要改进跨视图一致性。

Method: 用多视图扩散学生替换SDS中的传统神经场整合器，采用增量学生更新、专用教师噪声调度器和注意力修改来增强跨视图一致性。

Result: 实验表明I-Mix2Mix显著提高了多视图一致性，同时保持了高单帧编辑质量。

Conclusion: 该方法成功将2D编辑能力蒸馏到多视图扩散模型中，解决了多视图编辑中的一致性问题。

Abstract: We address the task of multi-view image editing from sparse input views, where the inputs can be seen as a mix of images capturing the scene from different viewpoints. The goal is to modify the scene according to a textual instruction while preserving consistency across all views. Existing methods, based on per-scene neural fields or temporal attention mechanisms, struggle in this setting, often producing artifacts and incoherent edits. We propose InstructMix2Mix (I-Mix2Mix), a framework that distills the editing capabilities of a 2D diffusion model into a pretrained multi-view diffusion model, leveraging its data-driven 3D prior for cross-view consistency. A key contribution is replacing the conventional neural field consolidator in Score Distillation Sampling (SDS) with a multi-view diffusion student, which requires novel adaptations: incremental student updates across timesteps, a specialized teacher noise scheduler to prevent degeneration, and an attention modification that enhances cross-view coherence without additional cost. Experiments demonstrate that I-Mix2Mix significantly improves multi-view consistency while maintaining high per-frame edit quality.

</details>


### [2] [An Event-triggered System for Social Persuasion and Danger Alert in Elder Home Monitoring](https://arxiv.org/abs/2511.15117)
*Jun-Yi Liu,Chung-Hao Chen,Ya-Chi Tsao,Ssu-Yao Wu,Yu-Ting Tsao,Lyn Chao-ling Chen*

Main category: cs.CV

TL;DR: 开发了一个事件触发系统来监测老年人的身心健康状态，通过GMM背景建模检测访客和老人的运动行为，使用SVM分析图像，并设计了直观的操作方式让老人通过社交媒体与亲属沟通。


<details>
  <summary>Details</summary>
Motivation: 同时考虑老年人的身体和心理状态，为缺乏技术经验的老年人设计直观的沟通方式。

Method: 采用GMM背景建模检测运动行为，使用SVM机器学习分析图像，设计事件触发系统（看门狗、危险通知和照片链接事件）。

Result: 在家庭场景中进行实验，5个家庭参与，成功检测和记录了三种类型的事件。

Conclusion: 该系统能够有效监测老年人的身心健康，并通过直观的操作方式促进老人与亲属的沟通。

Abstract: In the study, the physical state and mental state of elders are both considered, and an event-triggered system has developed to detect events: watch dog, danger notice and photo link. By adopting GMM background modeling, the motion behavior of visitors and elders can be detected in the watch dog event and danger notice event respectively. Experiments set in home scenarios and 5 families participated in the experiments for detecting and recording three types of events from their life activities. In addition, the captured images were analyzed using SVM machine learning. For lack of technical experiences of elders, an intuitive operation as normal life activity was designed to create communication between elder and relatives via social media.

</details>


### [3] [Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition](https://arxiv.org/abs/2511.15197)
*Raghu Vamsi Chittersu,Yuvraj Singh Rathore,Pranav Adlinge,Kunal Swami*

Main category: cs.CV

TL;DR: Insert In Style是一个零样本生成框架，能够在风格化域中插入真实世界对象，无需在线微调，在身份和风格指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于参考的对象组合方法在将真实世界对象插入风格化域时失败，现有方法要么缺乏生成保真度，要么需要不切实际的在线微调。

Method: 提出统一框架，包含多阶段训练协议来解耦身份、风格和组合表示，以及专门的掩码注意力架构来在生成过程中强制实施这种解耦。

Result: 在新建的公共基准测试中展示了最先进的性能，在身份和风格指标上显著优于现有方法，用户研究也强烈证实了这一结果。

Conclusion: Insert In Style是第一个既实用又高保真的零样本生成框架，解决了风格化域中对象插入的挑战。

Abstract: Reference-based object composition methods fail when inserting real-world objects into stylized domains. This under-explored problem is currently split between practical "blenders" that lack generative fidelity and "generators" that require impractical, per-subject online finetuning. In this work, we introduce Insert In Style, the first zero-shot generative framework that is both practical and high-fidelity. Our core contribution is a unified framework with two key innovations: (i) a novel multi-stage training protocol that disentangles representations for identity, style, and composition, and (ii) a specialized masked-attention architecture that surgically enforces this disentanglement during generation. This approach prevents the concept interference common in general-purpose, unified-attention models. Our framework is trained on a new 100k sample dataset, curated from a novel data pipeline. This pipeline couples large-scale generation with a rigorous, two-stage filtering process to ensure both high-fidelity semantic identity and style coherence. Unlike prior work, our model is truly zero-shot and requires no text prompts. We also introduce a new public benchmark for stylized composition. We demonstrate state-of-the-art performance, significantly outperforming existing methods on both identity and style metrics, a result strongly corroborated by user studies.

</details>


### [4] [SplitFlux: Learning to Decouple Content and Style from a Single Image](https://arxiv.org/abs/2511.15258)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Yongjun Zhang,Ziyang Chen,Shuting He*

Main category: cs.CV

TL;DR: 提出SplitFlux方法，通过分析Flux模型的特性，发现早期单流块控制内容、后期块控制风格，利用LoRA微调实现内容和风格的解耦，并通过秩约束适应和视觉门控LoRA提升内容保持和风格化质量。


<details>
  <summary>Details</summary>
Motivation: 现有SDXL方法难以实现高质量定制化图像生成，而Flux模型由于特性未被充分探索，无法有效分离内容和风格。

Method: 基于对Flux模型的分析，提出SplitFlux方法：1）秩约束适应：压缩特定块的秩并放大更新幅度，防止内容泄漏到风格块；2）视觉门控LoRA：将内容LoRA分为高秩和低秩分支，分别保留主体信息和残差细节。

Result: 大量实验表明SplitFlux在多样化场景中持续优于最先进方法，实现了优越的内容保持和风格化质量。

Conclusion: SplitFlux通过系统分析Flux模型特性，成功实现了内容和风格的有效解耦，为定制化图像生成提供了高质量解决方案。

Abstract: Disentangling image content and style is essential for customized image generation. Existing SDXL-based methods struggle to achieve high-quality results, while the recently proposed Flux model fails to achieve effective content-style separation due to its underexplored characteristics. To address these challenges, we conduct a systematic analysis of Flux and make two key observations: (1) Single Dream Blocks are essential for image generation; and (2) Early single stream blocks mainly control content, whereas later blocks govern style. Based on these insights, we propose SplitFlux, which disentangles content and style by fine-tuning the single dream blocks via LoRA, enabling the disentangled content to be re-embedded into new contexts. It includes two key components: (1) Rank-Constrained Adaptation. To preserve content identity and structure, we compress the rank and amplify the magnitude of updates within specific blocks, preventing content leakage into style blocks. (2) Visual-Gated LoRA. We split the content LoRA into two branches with different ranks, guided by image saliency. The high-rank branch preserves primary subject information, while the low-rank branch encodes residual details, mitigating content overfitting and enabling seamless re-embedding. Extensive experiments demonstrate that SplitFlux consistently outperforms state-of-the-art methods, achieving superior content preservation and stylization quality across diverse scenarios.

</details>


### [5] [Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning](https://arxiv.org/abs/2511.15633)
*Tao Hu,Lan Li,Zhen-Hao Xie,Da-Wei Zhou*

Main category: cs.CV

TL;DR: HASTEN是一种基于CLIP的类增量学习方法，通过将层次语义信息嵌入双曲空间来减少灾难性遗忘，在保持层次结构的同时防止特征漂移。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP类增量学习方法未能显式捕捉视觉和语言概念固有的层次结构（如'狗'包含'拉布拉多'和'金毛'等细粒度类别），导致细粒度类别特征在增量更新时漂移和灾难性遗忘。

Method: 1. 使用外部知识图谱作为监督，在双曲空间中嵌入视觉和文本特征以保持层次结构；2. 将梯度投影到共享双曲映射器的零空间，防止对先前任务的干扰。

Result: 大量实验表明HASTEN持续优于现有方法，并提供统一的结构化表示。

Conclusion: HASTEN通过层次语义树锚定技术，在类增量学习中有效减少灾难性遗忘，同时保持层次关系。

Abstract: Class-Incremental Learning (CIL) enables models to learn new classes continually while preserving past knowledge. Recently, vision-language models like CLIP offer transferable features via multi-modal pre-training, making them well-suited for CIL. However, real-world visual and linguistic concepts are inherently hierarchical: a textual concept like "dog" subsumes fine-grained categories such as "Labrador" and "Golden Retriever," and each category entails its images. But existing CLIP-based CIL methods fail to explicitly capture this inherent hierarchy, leading to fine-grained class features drift during incremental updates and ultimately to catastrophic forgetting. To address this challenge, we propose HASTEN (Hierarchical Semantic Tree Anchoring) that anchors hierarchical information into CIL to reduce catastrophic forgetting. First, we employ an external knowledge graph as supervision to embed visual and textual features in hyperbolic space, effectively preserving hierarchical structure as data evolves. Second, to mitigate catastrophic forgetting, we project gradients onto the null space of the shared hyperbolic mapper, preventing interference with prior tasks. These two steps work synergistically to enable the model to resist forgetting by maintaining hierarchical relationships. Extensive experiments show that HASTEN consistently outperforms existing methods while providing a unified structured representation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Semiconductor Industry Trend Prediction with Event Intervention Based on LSTM Model in Sentiment-Enhanced Time Series Data](https://arxiv.org/abs/2511.15112)
*Wei-hsiang Yen,Lyn Chao-ling Chen*

Main category: cs.LG

TL;DR: 该研究将深度学习方法与情感分析整合到传统商业模式分析中，以台积电为研究对象预测台湾半导体行业趋势。通过分析台积电季度报告中的文本和时间序列数据，结合内外部事件干预的情感分析，使用LSTM模型进行行业趋势预测。


<details>
  <summary>Details</summary>
Motivation: 半导体行业市场变化快速，传统数据分析方法在处理高变化性和时间序列数据时表现不佳，需要更先进的预测方法。

Method: 收集台积电季度报告中的文本和时间序列数据，通过情感分析考虑公司内部事件和外部全球事件的干预，使用情感增强的时间序列数据训练LSTM模型进行预测。

Result: 预测结果揭示了台积电晶圆技术的显著发展和全球市场的潜在威胁，与台积电产品发布新闻和国际新闻相符。

Conclusion: 该研究通过考虑内外部事件干预，在半导体行业趋势预测方面表现准确，为研究和商业领域提供了有价值的半导体行业信息。

Abstract: The innovation of the study is that the deep learning method and sentiment analysis are integrated in traditional business model analysis and forecasting, and the research subject is TSMC for industry trend prediction of semiconductor industry in Taiwan. For the rapid market changes and development of wafer technologies of semiconductor industry, traditional data analysis methods not perform well in the high variety and time series data. Textual data and time series data were collected from seasonal reports of TSMC including financial information. Textual data through sentiment analysis by considering the event intervention both from internal events of the company and the external global events. Using the sentiment-enhanced time series data, the LSTM model was adopted for predicting industry trend of TSMC. The prediction results reveal significant development of wafer technology of TSMC and the potential threatens in the global market, and matches the product released news of TSMC and the international news. The contribution of the work performed accurately in industry trend prediction of the semiconductor industry by considering both the internal and external event intervention, and the prediction results provide valuable information of semiconductor industry both in research and business aspects.

</details>


### [7] [FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model](https://arxiv.org/abs/2511.15174)
*Yi Xu,Zhigang Chen,Rui Wang,Yangfan Li,Fengxiao Tang,Ming Zhao,Jiaqi Liu*

Main category: cs.LG

TL;DR: 提出基于扩散模型的少样本故障时间序列生成框架，通过正负差异适配器和多样性损失解决故障数据稀缺问题，在真实性和多样性方面显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 工业设备监测中故障数据稀缺，现有时间序列生成模型在少样本场景下难以捕捉故障分布，生成的样本缺乏真实性和多样性。

Method: 使用扩散模型，采用正负差异适配器利用预训练的正常数据分布建模正常与故障域的差异，并引入多样性损失防止模式崩溃。

Result: 实验结果表明，该模型在真实性和多样性方面显著优于传统方法，在关键基准测试中达到最先进性能。

Conclusion: 提出的框架有效解决了少样本故障时间序列生成问题，为工业设备故障诊断提供了高质量的数据增强方案。

Abstract: In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.

</details>


### [8] [EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control](https://arxiv.org/abs/2511.15248)
*Kai Yang,Xin Xu,Yangkun Chen,Weijie Liu,Jiafei Lyu,Zichuan Lin,Deheng Ye,Saiyong Yang*

Main category: cs.LG

TL;DR: 提出EntroPIC方法，通过比例-积分控制动态调整正负样本的损失系数，稳定大语言模型强化学习训练中的熵值，防止过早收敛到次优解。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法难以在训练过程中维持适当的熵水平，因为正负样本在不同步骤中对熵的影响方式不同，导致探索不稳定。

Method: EntroPIC方法使用比例-积分控制机制，自适应地调整正负样本的损失系数，从而稳定训练过程中的熵值。

Result: 实验结果表明该方法能成功维持期望的熵水平，实现大语言模型的稳定最优强化学习训练。

Conclusion: EntroPIC方法通过熵稳定化机制，有效解决了大语言模型长期训练中的探索稳定性问题，为大规模LLM训练提供了理论保证和实践验证。

Abstract: Long-term training of large language models (LLMs) requires maintaining stable exploration to prevent the model from collapsing into sub-optimal behaviors. Entropy is crucial in this context, as it controls exploration and helps avoid premature convergence to sub-optimal solutions. However, existing reinforcement learning methods struggle to maintain an appropriate level of entropy, as the training process involves a mix of positive and negative samples, each affecting entropy in different ways across steps. To address this, we propose Entropy stablilization via Proportional-Integral Control (EntroPIC), a novel method that adaptively adjusts the influence of positive and negative samples by dynamically tuning their loss coefficients. This approach stabilizes entropy throughout training, ensuring efficient exploration and steady progress. We provide a comprehensive theoretical analysis for both on-policy and off-policy learning settings, demonstrating that EntroPIC is effective at controlling entropy in large-scale LLM training. Experimental results show that our method successfully maintains desired entropy levels, enabling stable and optimal RL training for LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents](https://arxiv.org/abs/2511.14780)
*Keith Moore,Jun W. Kim,David Lyu,Jeffrey Heo,Ehsan Adeli*

Main category: cs.AI

TL;DR: Ask WhAI是一个用于检查和扰动多智能体交互中信念状态的系统级框架，通过记录回放交互、查询信念和注入反事实证据来测试信念结构对新信息的响应。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体科学推理中的信念形成和认知孤岛，提供一种可重现的方法来观察和测试这些动态过程，这在人类专家中是不可能的。

Method: 使用具有角色特定先验的LLM智能体在医疗案例模拟器中交互，通过共享医疗记录和与调解员互动，在关键诊断时刻设置断点进行信念查询和反事实证据注入。

Result: 智能体信念往往反映现实世界学科立场，包括过度依赖经典研究和抵制反证据，这些信念可以被追踪和质询。

Conclusion: Ask WhAI通过使信念动态可见和可测试，为研究多智能体科学推理中的信念形成和认知孤岛提供了可重现的方法。

Abstract: We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors ("act like a neurologist", "act like an infectious disease specialist"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.

</details>


### [10] [Subnational Geocoding of Global Disasters Using Large Language Models](https://arxiv.org/abs/2511.14788)
*Michele Ronco,Damien Delforge,Wiebke S. Jäger,Christina Corbane*

Main category: cs.AI

TL;DR: 开发了一个基于LLM的自动化工作流，用于处理灾害数据库中的非结构化位置信息，通过GPT-4o清理文本并使用三个地理信息库进行交叉验证，为EM-DAT数据集中的14,215个事件生成子国家级几何数据。


<details>
  <summary>Details</summary>
Motivation: 灾害数据库中的位置信息通常以非结构化文本形式存在，具有不一致的粒度和拼写，难以与空间数据集集成，这阻碍了风险评估和灾害风险减少工作。

Method: 使用GPT-4o处理清理文本位置信息，通过交叉验证GADM、OpenStreetMap和Wikidata三个独立地理信息库来分配几何数据，并为每个位置分配可靠性评分。

Result: 应用于2000-2024年EM-DAT数据集，成功地理编码14,215个事件，覆盖17,948个独特位置，无需人工干预，涵盖所有灾害类型。

Conclusion: 该方法展示了LLMs从非结构化文本中提取和结构化地理信息的潜力，为相关分析提供了可扩展且可靠的方法。

Abstract: Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Temporal Predictors of Outcome in Reasoning Language Models](https://arxiv.org/abs/2511.14773)
*Joey David*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型在推理过程的早期阶段就能预测最终答案的正确性，即使需要更多步骤才能得出明确结论。


<details>
  <summary>Details</summary>
Motivation: 探索链式思维推理中，语言模型在何时内部确定最终答案，以及这种早期预测能力对模型解释性和推理控制的意义。

Method: 通过在推理过程的前t个token处训练线性分类器来预测隐藏状态，分析模型对最终正确性的早期预测能力。

Result: 模型在仅经过几个推理token后就能高度预测最终答案的正确性，且难度较高的问题在长链式思维中占比过高。

Conclusion: 推理模型在早期阶段就具备内部自我评估成功的能力，这对模型解释性和推理时控制具有重要启示。

Abstract: The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) internally commits to an eventual outcome. We probe this by training linear classifiers on hidden states after the first t reasoning tokens, showing that eventual correctness is highly predictable after only a few tokens, even when longer outputs are needed to reach a definite answer. We show that, for harder questions, a drop in predictive accuracy highlights a selection artifact: hard items are disproportionately represented in long CoTs. Overall, our results imply that for reasoning models, internal self-assessment of success tends to emerge after only a few tokens, with implications for interpretability and for inference-time control.

</details>


### [12] [Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs](https://arxiv.org/abs/2511.15163)
*Yang Wu,Rujing Yao,Tong Zhang,Yufei Shi,Zhuoren Jiang,Zhushan Li,Xiaozhong Liu*

Main category: cs.CL

TL;DR: TASA是一个基于大语言模型的智能数学辅导框架，通过整合学生画像、记忆和遗忘动态来实现个性化教学。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型辅导系统未能有效捕捉学生知识随时间的动态演变，包括熟练度、概念差距和遗忘模式，这在需要精细校准的数学辅导中尤为关键。

Method: TASA维护结构化的学生画像（记录熟练度档案）和事件记忆（记录先前学习互动），结合连续遗忘曲线和知识追踪来动态更新学生掌握状态，并生成情境适当、难度校准的问题和解释。

Result: 实证结果表明，TASA相比代表性基线方法取得了更优的学习效果和更自适应的辅导行为。

Conclusion: 在大语言模型辅导系统中建模时间遗忘和学习者画像具有重要意义，TASA框架展示了这种整合的有效性。

Abstract: Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.

</details>


### [13] [Multimodal Evaluation of Russian-language Architectures](https://arxiv.org/abs/2511.15552)
*Artem Chervyakov,Ulyana Isaeva,Anton Emelyanov,Artem Safin,Maria Tikhonova,Alexander Kharitonov,Yulia Lyakh,Petr Surovtsev,Denis Shevelev Vildan Saburov,Vasily Konovalov,Elisei Rykov,Ivan Sviridov,Amina Miftakhova,Ilseyar Alimova,Alexander Panchenko,Alexander Kapitanov,Alena Fenogenova*

Main category: cs.CL

TL;DR: Mera Multi是一个针对俄语的多模态评估框架，包含18个新构建的评估任务，涵盖文本、图像、音频和视频模态，为俄语多模态大语言模型提供标准化评估。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对俄语的多模态基准测试，无法充分理解多模态大语言模型在俄语环境下的智能、局限性和风险。

Method: 构建了18个全新的评估数据集，关注俄语文化和语言特性，采用统一的提示和指标，并设计了防止基准泄漏的方法（水印和私有集许可）。

Result: 为闭源和开源模型提供了基线结果，建立了通用的多模态能力分类体系。

Conclusion: 该基准为构建斯拉夫语系等类型多样语言的多模态基准提供了可复现的方法论，填补了俄语多模态评估的空白。

Abstract: Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms](https://arxiv.org/abs/2511.15274)
*Alexander Boldachev*

Main category: cs.RO

TL;DR: 对比了指令式行为树(BT)和声明式可执行本体(EO)两种机器人行为建模方法，发现EO通过事件驱动的状态传播实现了与BT相当的响应性和模块性，同时支持运行时模型修改和完整时间可追溯性。


<details>
  <summary>Details</summary>
Motivation: 解决传统机器人控制中的语义-过程鸿沟问题，探索从过程式编程向语义领域建模的转变，为动态演进的机器人系统提供替代框架。

Method: 通过boldsea框架实现两种方法：BT使用层次化控制流结构，EO使用基于数据流规则的时态事件语义图。在移动操作任务中进行实际对比。

Result: EO实现了与BT相当的响应性和模块性，但通过完全不同的架构（事件驱动vs轮询执行）。EO支持运行时模型修改、完整时间可追溯性以及数据、逻辑和接口的统一表示。

Conclusion: EO为机器人控制提供了从过程式编程向语义领域建模的替代框架，特别适合动态演进系统，而BT在既定可预测场景中表现优异。两种方法各有优势，适用于不同场景。

Abstract: This paper compares two distinct approaches to modeling robotic behavior: imperative Behavior Trees (BTs) and declarative Executable Ontologies (EO), implemented through the boldsea framework. BTs structure behavior hierarchically using control-flow, whereas EO represents the domain as a temporal, event-based semantic graph driven by dataflow rules. We demonstrate that EO achieves comparable reactivity and modularity to BTs through a fundamentally different architecture: replacing polling-based tick execution with event-driven state propagation. We propose that EO offers an alternative framework, moving from procedural programming to semantic domain modeling, to address the semantic-process gap in traditional robotic control. EO supports runtime model modification, full temporal traceability, and a unified representation of data, logic, and interface - features that are difficult or sometimes impossible to achieve with BTs, although BTs excel in established, predictable scenarios. The comparison is grounded in a practical mobile manipulation task. This comparison highlights the respective operational strengths of each approach in dynamic, evolving robotic systems.

</details>


### [15] [Decentralized Gaussian Process Classification and an Application in Subsea Robotics](https://arxiv.org/abs/2511.15529)
*Yifei Gao,Hans J. He,Daniel J. Stilwell,James McMahon*

Main category: cs.RO

TL;DR: 本文提出了一种用于自主水下航行器(AUV)团队实时构建通信成功概率地图的数据共享策略，通过选择性地共享通信测量数据来应对水下声学通信的不确定性。


<details>
  <summary>Details</summary>
Motivation: 水下声学通信存在距离有限、多径效应和低带宽等限制，导致通信不确定性。为了解决这一问题，需要实时学习通信环境，构建通信成功概率地图。

Method: 采用分散式分类方法，将通信事件分为成功或失败，AUVs选择性地共享部分通信测量数据来构建地图。主要贡献是严格推导的数据共享策略来选择要共享的测量数据。

Result: 使用弗吉尼亚理工大学690 AUVs团队收集的真实声学通信数据进行了实验验证，证明该策略在水下环境中的有效性。

Conclusion: 提出的数据共享策略能够有效帮助AUV团队在水下环境中实时构建通信成功概率地图，提高团队协作的可靠性。

Abstract: Teams of cooperating autonomous underwater vehicles (AUVs) rely on acoustic communication for coordination, yet this communication medium is constrained by limited range, multi-path effects, and low bandwidth. One way to address the uncertainty associated with acoustic communication is to learn the communication environment in real-time. We address the challenge of a team of robots building a map of the probability of communication success from one location to another in real-time. This is a decentralized classification problem -- communication events are either successful or unsuccessful -- where AUVs share a subset of their communication measurements to build the map. The main contribution of this work is a rigorously derived data sharing policy that selects measurements to be shared among AUVs. We experimentally validate our proposed sharing policy using real acoustic communication data collected from teams of Virginia Tech 690 AUVs, demonstrating its effectiveness in underwater environments.

</details>
