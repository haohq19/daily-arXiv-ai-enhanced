<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning](https://arxiv.org/abs/2506.21724)
*Remco F. Leijenaar,Hamidreza Kasaei*

Main category: cs.CV

TL;DR: AsymDSD是一种自监督3D学习框架，通过潜在空间预测结合掩码建模和不变性学习，显著提升了语义表示能力。


<details>
  <summary>Details</summary>
Motivation: 解决无标签3D点云数据中语义表示学习的挑战，避免传统掩码点建模（MPM）在高层次语义捕捉上的局限性。

Method: 提出AsymDSD框架，采用非对称双自蒸馏设计，结合潜在空间预测、多掩码采样和多裁剪点云适配。

Result: 在ScanObjectNN上达到90.53%的准确率，预训练后提升至93.72%，优于现有方法。

Conclusion: AsymDSD通过创新设计显著提升了3D点云的语义表示能力，为自监督学习提供了新思路。

Abstract: Learning semantically meaningful representations from unstructured 3D point
clouds remains a central challenge in computer vision, especially in the
absence of large-scale labeled datasets. While masked point modeling (MPM) is
widely used in self-supervised 3D learning, its reconstruction-based objective
can limit its ability to capture high-level semantics. We propose AsymDSD, an
Asymmetric Dual Self-Distillation framework that unifies masked modeling and
invariance learning through prediction in the latent space rather than the
input space. AsymDSD builds on a joint embedding architecture and introduces
several key design choices: an efficient asymmetric setup, disabling attention
between masked queries to prevent shape leakage, multi-mask sampling, and a
point cloud adaptation of multi-crop. AsymDSD achieves state-of-the-art results
on ScanObjectNN (90.53%) and further improves to 93.72% when pretrained on 930k
shapes, surpassing prior methods.

</details>


### [2] [ImplicitQA: Going beyond frames towards Implicit Video Reasoning](https://arxiv.org/abs/2506.21742)
*Sirnam Swetha,Rohit Gupta,Parth Parag Kulkarni,David G Shatwell,Jeffrey A Chan Santiago,Nyle Siddiqui,Joseph Fioresi,Mubarak Shah*

Main category: cs.CV

TL;DR: 论文提出了ImplicitQA，一个专注于测试视频问答中隐式推理能力的新基准，填补了现有系统在理解复杂叙事内容上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答基准主要关注可直接观察的视觉内容，而忽略了需要隐式推理的复杂叙事内容（如电影、电视剧）。

Method: 构建了包含1K高质量QA对的ImplicitQA基准，涵盖多种隐式推理维度，并对主流模型进行了评估。

Result: 评估显示现有模型在隐式推理任务上表现不佳，依赖表层视觉线索。

Conclusion: ImplicitQA为社区提供了新的研究方向，旨在推动视频问答系统在隐式推理能力上的进步。

Abstract: Video QA has made significant strides by leveraging multimodal learning to
align visual and textual modalities. However, current benchmarks overwhelmingly
focus on questions answerable through explicit visual content - actions,
objects & events directly observable within individual frames or short clips.
In contrast, creative and cinematic videos - such as movies, TV shows, and
narrative-driven content - employ storytelling techniques that deliberately
omit certain depictions, requiring viewers to infer motives, causality, and
relationships across discontinuous frames. Humans naturally excel at such
implicit reasoning, seamlessly integrating information across time and context
to construct coherent narratives. Current VideoQA systems and benchmarks fail
to capture this essential dimension of human-like understanding. To bridge this
gap, we present ImplicitQA, a novel benchmark specifically designed to test
models on implicit reasoning. It comprises 1K meticulously annotated QA pairs
derived from 320+ high-quality creative video clips, systematically categorized
into key reasoning dimensions: lateral and vertical spatial reasoning, depth
and proximity, viewpoint and visibility, motion and trajectory, causal and
motivational reasoning, social interactions, physical context, and inferred
counting. These annotations are deliberately challenging, crafted by authors
ensuring high-quality. Our extensive evaluations on leading VideoQA models
reveals performance degradation, underscoring their reliance on surface-level
visual cues and highlighting the difficulty of implicit reasoning. Performance
variations across models further illustrate the complexity and diversity of the
challenges presented by ImplicitQA. By releasing both the dataset and our data
collection framework, we aim to stimulate further research and development in
the community. https://huggingface.co/datasets/ucf-crcv/ImplicitQA.

</details>


### [3] [A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake](https://arxiv.org/abs/2506.22338)
*Luigi Russo,Deodato Tapete,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 提出了一种基于单日期高分辨率SAR图像和多源地理空间数据的深度学习框架，用于快速检测建筑物损坏，无需依赖灾前数据。


<details>
  <summary>Details</summary>
Motivation: 灾害后快速识别建筑物损坏对应急响应和恢复至关重要，但传统光学卫星图像常受云层或缺乏灾前数据的限制。

Method: 结合SAR图像、OSM建筑轮廓、DSM数据和GEM的结构与暴露属性，构建多模态深度学习模型，仅使用灾后数据。

Result: 在土耳其2023年地震数据集上验证，结果表明结合地理空间特征显著提升了检测性能和泛化能力。

Conclusion: 该方法无需灾前数据，能快速可靠地评估建筑物损坏，支持灾害管理和恢复工作。

Abstract: Building damage identification shortly after a disaster is crucial for
guiding emergency response and recovery efforts. Although optical satellite
imagery is commonly used for disaster mapping, its effectiveness is often
hampered by cloud cover or the absence of pre-event acquisitions. To overcome
these challenges, we introduce a novel multimodal deep learning (DL) framework
for detecting building damage using single-date very high resolution (VHR)
Synthetic Aperture Radar (SAR) imagery from the Italian Space Agency (ASI)
COSMO SkyMed (CSK) constellation, complemented by auxiliary geospatial data.
Our method integrates SAR image patches, OpenStreetMap (OSM) building
footprints, digital surface model (DSM) data, and structural and exposure
attributes from the Global Earthquake Model (GEM) to improve detection accuracy
and contextual interpretation. Unlike existing approaches that depend on pre
and post event imagery, our model utilizes only post event data, facilitating
rapid deployment in critical scenarios. The framework effectiveness is
demonstrated using a new dataset from the 2023 earthquake in Turkey, covering
multiple cities with diverse urban settings. Results highlight that
incorporating geospatial features significantly enhances detection performance
and generalizability to previously unseen areas. By combining SAR imagery with
detailed vulnerability and exposure information, our approach provides reliable
and rapid building damage assessments without the dependency from available
pre-event data. Moreover, the automated and scalable data generation process
ensures the framework's applicability across diverse disaster-affected regions,
underscoring its potential to support effective disaster management and
recovery efforts. Code and data will be made available upon acceptance of the
paper.

</details>


### [4] [From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications](https://arxiv.org/abs/2506.22360)
*Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 研究比较了CNN（ResNet34）和ViT（ViT B16）在事件相机数据上的性能，发现ResNet34在分类精度上略优，但ViT B16在鲁棒性上表现更好。


<details>
  <summary>Details</summary>
Motivation: 事件相机适用于动态环境（如无人机和自动驾驶车辆），但相关深度学习架构的性能尚未充分研究。

Method: 使用GEN1事件数据集对ResNet34和ViT B16进行微调，并在标准条件和模拟噪声下评估。

Result: ResNet34和ViT B16在干净数据上的准确率分别为88%和86%，ViT B16在噪声下表现更稳健。

Conclusion: 研究为无人机等动态环境中的事件视觉系统提供了有前景的方法和结果。

Abstract: This study investigates the performance of the two most relevant computer
vision deep learning architectures, Convolutional Neural Network and Vision
Transformer, for event-based cameras. These cameras capture scene changes,
unlike traditional frame-based cameras with capture static images, and are
particularly suited for dynamic environments such as UAVs and autonomous
vehicles. The deep learning models studied in this work are ResNet34 and ViT
B16, fine-tuned on the GEN1 event-based dataset. The research evaluates and
compares these models under both standard conditions and in the presence of
simulated noise. Initial evaluations on the clean GEN1 dataset reveal that
ResNet34 and ViT B16 achieve accuracies of 88% and 86%, respectively, with
ResNet34 showing a slight advantage in classification accuracy. However, the
ViT B16 model demonstrates notable robustness, particularly given its
pre-training on a smaller dataset. Although this study focuses on ground-based
vehicle classification, the methodologies and findings hold significant promise
for adaptation to UAV contexts, including aerial object classification and
event-based vision systems for aviation-related tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization](https://arxiv.org/abs/2506.21655)
*Minjie Hong,Zirun Guo,Yan Xia,Zehan Wang,Ziang Zhang,Tao Jin,Zhou Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种名为不对称策略优化（APO）的方法，通过动态调整KL散度权重和惩罚过长响应，解决了多模态大语言模型（MLLMs）在强化学习训练中的性能下降和过度推理问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在复杂推理任务中表现不佳，而强化学习（RL）虽然能提升推理能力，但直接应用于MLLMs会导致性能下降和过度推理问题。

Method: 提出APO方法，将样本分为正负两组：对正样本使用难度自适应散度塑形（DADS）动态调整KL散度权重；对负样本使用次优轨迹复杂度正则化（STCR）惩罚过长响应。

Result: 在Qwen2.5-VL-3B模型上应用该方法后，推理能力显著提升，平均性能提高7%，并在多个推理基准测试中优于更大的MLLMs（7-11B）。

Conclusion: APO方法有效解决了MLLMs在强化学习训练中的问题，提升了推理能力和泛化性能，同时保持了模型在通用任务上的表现。

Abstract: Multimodal Large Language Models (MLLMs) are powerful at integrating diverse
data, but they often struggle with complex reasoning. While Reinforcement
learning (RL) can boost reasoning in LLMs, applying it to MLLMs is tricky.
Common issues include a drop in performance on general tasks and the generation
of overly detailed or "overthinking" reasoning. Our work investigates how the
KL penalty and overthinking affect RL training in MLLMs. We propose Asymmetric
Policy Optimization (APO) to address these issues, which divides the sampled
responses into positive and negative groups. For positive samples,
Difficulty-Adaptive Divergence Shaping (DADS) is introduced to dynamically
adjust the KL divergence weight based on their difficulty. This method prevents
policy entropy from dropping sharply, improves training stability, utilizes
samples better, and preserves the model's existing knowledge. For negative
samples, Suboptimal Trajectory Complexity Regularization (STCR) is proposed to
penalize overly long responses. This helps mitigate overthinking and encourages
more concise reasoning while preserving the model's explorative capacity. We
apply our method to Qwen2.5-VL-3B, creating View-R1-3B. View-R1-3B
significantly enhances reasoning capabilities, showing an average 7\% gain over
the base model and outperforming larger MLLMs (7-11B) on various reasoning
benchmarks. Importantly, unlike other reasoning-tuned MLLMs that often degrade
on general tasks, View-R1-3B maintains consistent improvement, demonstrating
superior generalization. These results highlight the effectiveness and broad
applicability of our DADS and STCR techniques for advancing complex multimodal
reasoning in MLLMs. The code will be made available at
https://github.com/Indolent-Kawhi/View-R1.

</details>


### [6] [Physics-informed network paradigm with data generation and background noise removal for diverse distributed acoustic sensing applications](https://arxiv.org/abs/2506.21952)
*Yangyang Wan,Haotian Wang,Xuhui Yu,Jiageng Chen,Xinyu Fan,Zuyuan He*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息的DAS神经网络范式，无需真实事件数据进行训练，通过物理建模生成数据，并在去噪和事件识别中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决DAS应用中真实事件数据有限的问题，同时提升去噪和事件识别的性能。

Method: 通过物理建模生成DAS事件数据，训练生成网络和去背景噪声网络。

Result: 在事件识别和皮带输送机故障监测中表现优异，故障诊断准确率达91.8%。

Conclusion: 该范式为解决DAS数据获取和噪声问题提供了有效方案，具有广泛应用潜力。

Abstract: Distributed acoustic sensing (DAS) has attracted considerable attention
across various fields and artificial intelligence (AI) technology plays an
important role in DAS applications to realize event recognition and denoising.
Existing AI models require real-world data (RWD), whether labeled or not, for
training, which is contradictory to the fact of limited available event data in
real-world scenarios. Here, a physics-informed DAS neural network paradigm is
proposed, which does not need real-world events data for training. By
physically modeling target events and the constraints of real world and DAS
system, physical functions are derived to train a generative network for
generation of DAS events data. DAS debackground net is trained by using the
generated DAS events data to eliminate background noise in DAS data. The
effectiveness of the proposed paradigm is verified in event identification
application based on a public dataset of DAS spatiotemporal data and in belt
conveyor fault monitoring application based on DAS time-frequency data, and
achieved comparable or better performance than data-driven networks trained
with RWD. Owing to the introduction of physical information and capability of
background noise removal, the paradigm demonstrates generalization in same
application on different sites. A fault diagnosis accuracy of 91.8% is achieved
in belt conveyor field with networks which transferred from simulation test
site without any fault events data of test site and field for training. The
proposed paradigm is a prospective solution to address significant obstacles of
data acquisition and intense noise in practical DAS applications and explore
more potential fields for DAS.

</details>


### [7] [On the Necessity of Output Distribution Reweighting for Effective Class Unlearning](https://arxiv.org/abs/2506.20893)
*Yian Wang,Ali Ebrahimpour-Boroojeny,Hari Sundaram*

Main category: cs.LG

TL;DR: 提出了一种轻量级的输出重加权遗忘方法RWFT，无需完全重新训练即可从分类器中删除特定类别，解决了现有遗忘方法在预测未学习类别时的不足。


<details>
  <summary>Details</summary>
Motivation: 强制执行用户删除权和减少有害或偏见预测的需求，同时避免完全重新训练的高成本。

Method: 通过重新分配预测概率质量，设计了一种对MIA-NN攻击鲁棒的方法，并引入基于总变差距离的新度量标准。

Result: 实验表明，RWFT在现有评估指标和新提出的TV距离指标上均优于现有方法，分别提升了2.79%和111.45%。

Conclusion: RWFT是一种高效且安全的遗忘方法，能够在不完全重新训练的情况下达到与完全重新训练相当的效果。

Abstract: In this work, we introduce an output-reweighting unlearning method, RWFT, a
lightweight technique that erases an entire class from a trained classifier
without full retraining. Forgetting specific classes from trained models is
essential for enforcing user deletion rights and mitigating harmful or biased
predictions. The full retraining is costly and existing unlearning methods fail
to replicate the behavior of the retrained models when predicting samples from
the unlearned class. We prove this failure by designing a variant of membership
inference attacks, MIA-NN that successfully reveals the unlearned class for any
of these methods. We propose a simple redistribution of the probability mass
for the prediction on the samples in the forgotten class which is robust to
MIA-NN. We also introduce a new metric based on the total variation (TV)
distance of the prediction probabilities to quantify residual leakage to
prevent future methods from susceptibility to the new attack. Through extensive
experiments with state of the art baselines in machine unlearning, we show that
our approach matches the results of full retraining in both metrics used for
evaluation by prior work and the new metric we propose in this work. Compare to
state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45%
in our new TV-based metric over the best existing method.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个混合框架，结合轻量级领域特定生成器和LLMs，用于高效生成和动态调整人类移动模式，填补了大规模模拟平台的空白。


<details>
  <summary>Details</summary>
Motivation: 现有移动模拟平台在算法开发、政策实施和大规模评估方面存在不足，传统方法数据需求高且适应性差，LLMs则面临计算限制。

Method: 提出MobiVerse框架，结合轻量级生成器生成基础活动链和LLMs进行上下文感知调整，支持动态环境反馈。

Result: 在洛杉矶Westwood的案例研究中，成功为53,000个代理生成并动态调整日程，保持计算效率并提升行为真实性。

Conclusion: MobiVerse为移动系统规划和操作提供了可定制平台，填补了模拟领域的空白。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Bench to the Future: A Pastcasting Benchmark for Forecasting Agents](https://arxiv.org/abs/2506.21558)
*FutureSearch,:,Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips*

Main category: cs.CL

TL;DR: 论文提出了BTF基准，通过已知结果的“过去预测”问题评估LLM的预测能力，提供了一种可重复的测试环境。


<details>
  <summary>Details</summary>
Motivation: 现有预测基准缺乏真实、封闭且可重复的环境，难以评估LLM的预测能力。

Method: 使用已知结果的“过去预测”问题和相关网页语料库，模拟真实预测场景，测试LLM的表现。

Result: BTF环境能够产生与未解决问题预测相似的结果，并能追踪预测能力的进步。

Conclusion: BTF是一个动态基准，将持续更新问题，为研究提供工具支持。

Abstract: Forecasting is a challenging task that offers a clearly measurable way to
study AI systems. Forecasting requires a large amount of research on the
internet, and evaluations require time for events to happen, making the
development of forecasting benchmarks challenging. To date, no forecasting
benchmark provides a realistic, hermetic, and repeatable environment for LLM
forecasters. We introduce Bench To the Future (BTF), a "pastcasting" benchmark
with hundreds of high-quality questions for which the resolution is already
known. Each question is accompanied by a large offline corpus of tens of
thousands of relevant web pages, enabling a way to elicit realistic "forecasts"
on past events from LLMs. Results suggest that our pastcasting environment can
produce results comparable to those based on forecasts using the internet on
at-the-time unresolved questions. We show results benchmarking agent and
chain-of-thought forecasting approaches using several LLMs, including the
recently-released Claude 4 models, and demonstrate BTF's ability to track
steady forecasting capability progress over time. We intend this to be a living
benchmark, with new questions added continually to account for increasing
training data cutoff dates. We invite researchers to contact us at
hello@futuresearch.ai to utilize our benchmark or tooling for their own
research.

</details>


### [10] [MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark](https://arxiv.org/abs/2412.15194)
*Qihao Zhao,Yangyu Huang,Tengchao Lv,Lei Cui,Qinzheng Sun,Shaoguang Mao,Xin Zhang,Ying Xin,Qiufeng Yin,Scarlett Li,Furu Wei*

Main category: cs.CL

TL;DR: 论文提出了一个名为MMLU-CF的无污染多选问答基准，旨在解决现有基准因数据泄露导致的评估不可靠问题。


<details>
  <summary>Details</summary>
Motivation: 现有MCQ数据集（如MMLU）因开源性和LLM训练数据的广泛来源导致基准污染，评估结果不可靠。

Method: 通过从更广泛领域获取数据并设计三条去污染规则避免无意数据泄露；将基准分为验证集和测试集以防止恶意数据泄露。

Result: 主流LLM（如GPT-4）在测试集上的5-shot和0-shot得分分别为73.4%和71.9%，验证了MMLU-CF的严谨性。

Conclusion: MMLU-CF提供了一个更严格且无污染的评估标准，有效解决了基准污染问题。

Abstract: Multiple-choice question (MCQ) datasets like Massive Multitask Language
Understanding (MMLU) are widely used to evaluate the commonsense,
understanding, and problem-solving abilities of large language models (LLMs).
However, the open-source nature of these benchmarks and the broad sources of
training data for LLMs have inevitably led to benchmark contamination,
resulting in unreliable evaluation results. To alleviate this issue, we propose
a contamination-free and more challenging MCQ benchmark called MMLU-CF. This
benchmark reassesses LLMs' understanding of world knowledge by averting both
unintentional and malicious data leakage. To avoid unintentional data leakage,
we source data from a broader domain and design three decontamination rules. To
prevent malicious data leakage, we divide the benchmark into validation and
test sets with similar difficulty and subject distributions. The test set
remains closed-source to ensure reliable results, while the validation set is
publicly available to promote transparency and facilitate independent
verification. Our evaluation of mainstream LLMs reveals that the powerful
GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on
the test set, which indicates the effectiveness of our approach in creating a
more rigorous and contamination-free evaluation standard. The GitHub repository
is available at https://github.com/microsoft/MMLU-CF and the dataset refers to
https://huggingface.co/datasets/microsoft/MMLU-CF.

</details>


### [11] [Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions](https://arxiv.org/abs/2506.21574)
*Yicheng Mao,Yang Zhao*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（如GPT-3.5和GPT-4）在移民决策中的潜力，发现其能模拟人类决策策略，但也存在偏见。


<details>
  <summary>Details</summary>
Motivation: 全球化与移民增长使移民部门面临巨大工作量和公平决策的挑战，人工智能可能提供解决方案。

Method: 采用混合方法，包括离散选择实验和深度访谈，分析LLM的决策策略及其公平性。

Result: LLM能模拟人类决策策略，注重效用最大化和程序公平，但仍存在国籍偏见和特权群体偏好。

Conclusion: LLM在自动化移民决策中具有潜力，但也需注意其局限性，如偏见问题。

Abstract: With globalization and increasing immigrant populations, immigration
departments face significant work-loads and the challenge of ensuring fairness
in decision-making processes. Integrating artificial intelligence offers a
promising solution to these challenges. This study investigates the potential
of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting
immigration decision-making. Utilizing a mixed-methods approach,this paper
conducted discrete choice experiments and in-depth interviews to study LLM
decision-making strategies and whether they are fair. Our findings demonstrate
that LLMs can align their decision-making with human strategies, emphasizing
utility maximization and procedural fairness. Meanwhile, this paper also
reveals that while ChatGPT has safeguards to prevent unintentional
discrimination, it still exhibits stereotypes and biases concerning nationality
and shows preferences toward privileged group. This dual analysis highlights
both the potential and limitations of LLMs in automating and enhancing
immigration decisions.

</details>


### [12] [Understanding Verbatim Memorization in LLMs Through Circuit Discovery](https://arxiv.org/abs/2506.21588)
*Ilya Lasy,Peter Knees,Stefan Woltran*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）中记忆化的机制，通过变压器电路识别了触发和维持记忆化的不同子网络，并发现记忆化预防机制具有跨文本域的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs中记忆化的具体机制，包括哪些网络部分决定记忆化序列的开始，以及模型在生成记忆化和非记忆化内容时的行为差异。

Method: 从机制可解释性角度出发，利用变压器电路（特定功能的最小计算子图）和对比数据集，识别记忆化与非记忆化内容的分歧点，并分离出负责记忆化的特定电路。

Result: 发现触发记忆化的电路也能维持记忆化，而仅维持记忆化的电路无法触发其开始；记忆化预防机制具有跨域鲁棒性，而记忆化诱导则更依赖上下文。

Conclusion: 研究揭示了记忆化在LLMs中的具体机制，为理解和控制模型记忆化行为提供了新视角。

Abstract: Underlying mechanisms of memorization in LLMs -- the verbatim reproduction of
training data -- remain poorly understood. What exact part of the network
decides to retrieve a token that we would consider as start of memorization
sequence? How exactly is the models' behaviour different when producing
memorized sentence vs non-memorized? In this work we approach these questions
from mechanistic interpretability standpoint by utilizing transformer circuits
-- the minimal computational subgraphs that perform specific functions within
the model. Through carefully constructed contrastive datasets, we identify
points where model generation diverges from memorized content and isolate the
specific circuits responsible for two distinct aspects of memorization. We find
that circuits that initiate memorization can also maintain it once started,
while circuits that only maintain memorization cannot trigger its initiation.
Intriguingly, memorization prevention mechanisms transfer robustly across
different text domains, while memorization induction appears more
context-dependent.

</details>


### [13] [A General Method for Detecting Information Generated by Large Language Models](https://arxiv.org/abs/2506.21589)
*Minjia Mao,Dongjun Wei,Xiao Fang,Michael Chau*

Main category: cs.CL

TL;DR: 论文提出了一种通用LLM检测器（GLD），用于检测未见过的LLM和领域生成的内容，解决了现有方法泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，区分人类撰写和LLM生成的内容变得困难，这对数字平台的信任和防止虚假信息传播至关重要。

Method: GLD结合了双记忆网络设计和理论指导的检测泛化模块，以提升检测的泛化能力。

Result: 通过真实数据集验证，GLD在检测性能上优于现有最先进方法。

Conclusion: GLD为数字平台和LLM提供了重要的学术和实践价值。

Abstract: The proliferation of large language models (LLMs) has significantly
transformed the digital information landscape, making it increasingly
challenging to distinguish between human-written and LLM-generated content.
Detecting LLM-generated information is essential for preserving trust on
digital platforms (e.g., social media and e-commerce sites) and preventing the
spread of misinformation, a topic that has garnered significant attention in IS
research. However, current detection methods, which primarily focus on
identifying content generated by specific LLMs in known domains, face
challenges in generalizing to new (i.e., unseen) LLMs and domains. This
limitation reduces their effectiveness in real-world applications, where the
number of LLMs is rapidly multiplying and content spans a vast array of
domains. In response, we introduce a general LLM detector (GLD) that combines a
twin memory networks design and a theory-guided detection generalization module
to detect LLM-generated information across unseen LLMs and domains. Using
real-world datasets, we conduct extensive empirical evaluations and case
studies to demonstrate the superiority of GLD over state-of-the-art detection
methods. The study has important academic and practical implications for
digital platforms and LLMs.

</details>


### [14] [Evaluating List Construction and Temporal Understanding capabilities of Large Language Models](https://arxiv.org/abs/2506.21783)
*Alexandru Dumitru,V Venktesh,Adam Jatowt,Avishek Anand*

Main category: cs.CL

TL;DR: 论文提出了一个名为TLQA的基准测试，用于评估大语言模型在时间引用列表问答任务中的表现，揭示了当前模型在完整答案生成和时间对齐方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言任务中表现优异，但在涉及多实体和时间理解的问答任务中容易产生幻觉和错误，现有研究未充分评估此类能力。

Method: 提出TLQA基准测试，要求模型生成与时间周期对齐的结构化列表答案，并在闭卷和开放域设置下评估模型的性能。

Result: 研究发现当前模型在闭卷设置中难以提供完整答案和时间对齐，开放域设置中检索能力有待提升。

Conclusion: TLQA基准测试为未来研究提供了明确方向，代码和基准已开源。

Abstract: Large Language Models (LLMs) have demonstrated immense advances in a wide
range of natural language tasks. However, these models are susceptible to
hallucinations and errors on particularly temporal understanding tasks
involving multiple entities in answers. In such tasks, they fail to associate
entities with accurate time intervals, generate a complete list of entities in
answers or reason about events associated with specific temporal bounds.
Existing works do not extensively evaluate the abilities of the model to
perform implicit and explicit temporal understanding in a list answer
construction setup. To bridge this gap, we propose the Time referenced List
based Question Answering or TLQA benchmark that requires structured answers in
list format aligned with corresponding time periods. Our TLQA benchmark,
requires both list construction and temporal understanding simultaneously,
which to the best of our knowledge has not been explored in prior benchmarks.
We investigate the temporal understanding and list construction capabilities of
state-of-the-art generative models on TLQA in closed-book and open-domain
settings. Our findings reveal significant shortcomings in current models,
particularly their inability to provide complete answers and temporally align
facts in a closed-book setup and the need to improve retrieval in open-domain
setup, providing clear future directions for research on TLQA. The benchmark
and code at https://github.com/elixir-research-group/TLQA.

</details>


### [15] [PARSI: Persian Authorship Recognition via Stylometric Integration](https://arxiv.org/abs/2506.21840)
*Kourosh Shahnazari,Mohammadali Keshtparvar,Seyed Moein Ayyoubzadeh*

Main category: cs.CL

TL;DR: 提出了一种多输入神经网络框架，结合语义、风格和韵律特征，用于波斯古典诗歌的作者归属，取得了71%的准确率，高置信度预测时可达97%。


<details>
  <summary>Details</summary>
Motivation: 波斯古典诗歌的语言、风格和韵律复杂性对计算作者归属提出了挑战，需要一种综合方法来解决。

Method: 采用多输入神经网络框架，结合Transformer语言编码器、Word2Vec嵌入、风格特征和韵律编码，基于647,653节诗句进行训练和评估。

Result: 加权投票方案达到71%准确率，高置信度阈值（0.9）下准确率提升至97%，但覆盖率降低。

Conclusion: 该方法为波斯诗歌的作者归属和风格分析提供了有效工具，并支持多语言作者归属和生成建模的进一步研究。

Abstract: The intricate linguistic, stylistic, and metrical aspects of Persian
classical poetry pose a challenge for computational authorship attribution. In
this work, we present a versatile framework to determine authorship among 67
prominent poets. We employ a multi-input neural framework consisting of a
transformer-based language encoder complemented by features addressing the
semantic, stylometric, and metrical dimensions of Persian poetry. Our feature
set encompasses 100-dimensional Word2Vec embeddings, seven stylometric
measures, and categorical encodings of poetic form and meter. We compiled a
vast corpus of 647,653 verses of the Ganjoor digital collection, validating the
data through strict preprocessing and author verification while preserving
poem-level splitting to prevent overlap. This work employs verse-level
classification and majority and weighted voting schemes in evaluation,
revealing that weighted voting yields 71% accuracy. We further investigate
threshold-based decision filtering, allowing the model to generate highly
confident predictions, achieving 97% accuracy at a 0.9 threshold, though at
lower coverage. Our work focuses on the integration of deep representational
forms with domain-specific features for improved authorship attribution. The
results illustrate the potential of our approach for automated classification
and the contribution to stylistic analysis, authorship disputes, and general
computational literature research. This research will facilitate further
research on multilingual author attribution, style shift, and generative
modeling of Persian poetry.

</details>
