<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 12]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Food Portion Estimation: From Pixels to Calories](https://arxiv.org/abs/2602.05078)
*Gautham Vinod,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文综述了基于图像的饮食评估中食物分量估计的不同策略，重点探讨了如何从2D图像准确估计3D食物尺寸的各种方法。


<details>
  <summary>Details</summary>
Motivation: 基于图像的饮食评估对于准确便捷地监测个体健康、预防和管理慢性疾病及肥胖至关重要。然而，从2D图像估计3D食物尺寸是该方法面临的主要挑战。

Method: 论文探讨了多种策略：1）使用辅助输入如深度图；2）多视角输入；3）基于模型的方法如模板匹配；4）深度学习技术，包括使用单目图像或图像与辅助输入的组合。

Result: 论文对现有食物分量估计策略进行了系统性综述和分析，但没有报告具体的实验数据或性能指标。

Conclusion: 基于图像的饮食评估需要克服2D到3D的尺寸估计挑战，多种策略已被开发，深度学习技术正在帮助缩小这一差距，实现更准确的食物分量预测。

Abstract: Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.

</details>


### [2] [GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling](https://arxiv.org/abs/2602.05202)
*Shivanshu Shekhar,Uttaran Bhattacharya,Raghavendra Addanki,Mehrab Tanjim,Somdeb Sarkhel,Tong Zhang*

Main category: cs.CV

TL;DR: 提出Generative-Transformer-based Self-Supervised Video Judge (GTSVJ)，将视频生成模型重新用作奖励模型，通过对比学习训练能量模型来评估视频质量，仅需3万人工标注即达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型(VLMs)的视频奖励建模方法难以捕捉细微的时间动态，需要大量人工标注数据。视频生成模型本身具有建模时间结构的能力，但尚未被用于奖励建模。

Method: 将视频生成模型重新构建为能量模型(EBMs)，通过对比目标训练，使高质量视频获得低能量值，低质量视频获得高能量值。设计三种潜在空间扰动方法生成合成负样本：时间切片、特征交换和帧重排，迫使模型学习有意义的时空特征而非表面伪影。

Result: 在GenAI-Bench和MonteBench上达到最先进性能，仅使用3万人工标注数据，比现有VLM方法少6-65倍标注量。

Conclusion: 视频生成模型可以有效地重新用作时间感知的奖励模型，通过对比学习和精心设计的合成负样本，能够以极少的人工标注实现卓越的视频质量评估性能。

Abstract: Aligning video generative models with human preferences remains challenging: current approaches rely on Vision-Language Models (VLMs) for reward modeling, but these models struggle to capture subtle temporal dynamics. We propose a fundamentally different approach: repurposing video generative models, which are inherently designed to model temporal structure, as reward models. We present the Generative-Transformer-based Self-Supervised Video Judge (\modelname), a novel evaluation model that transforms state-of-the-art video generation models into powerful temporally-aware reward models. Our key insight is that generative models can be reformulated as energy-based models (EBMs) that assign low energy to high-quality videos and high energy to degraded ones, enabling them to discriminate video quality with remarkable precision when trained via contrastive objectives. To prevent the model from exploiting superficial differences between real and generated videos, we design challenging synthetic negative videos through controlled latent-space perturbations: temporal slicing, feature swapping, and frame shuffling, which simulate realistic but subtle visual degradations. This forces the model to learn meaningful spatiotemporal features rather than trivial artifacts. \modelname achieves state-of-the-art performance on GenAI-Bench and MonteBench using only 30K human-annotations: $6\times$ to $65\times$ fewer than existing VLM-based approaches.

</details>


### [3] [E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching](https://arxiv.org/abs/2602.05215)
*Jiahao Nie,Wenbin An,Gongjie Zhang,Yicheng Xu,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: E.M.Ground：一种用于时序视频定位的新型视频大语言模型，通过事件令牌、平滑处理和多粒度特征聚合来提升事件感知的完整性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在时序视频定位任务中，通常通过比较帧特征与两个独立令牌来匹配起止帧，严重依赖精确时间戳。这种方法无法捕捉事件的语义连续性和完整性，导致定位模糊。

Method: 提出E.M.Ground模型，包含三个关键创新：1) 引入特殊<event>令牌聚合查询事件所有帧的信息，保持语义连续性；2) 使用Savitzky-Golay平滑减少时间戳间令牌-帧相似度的噪声；3) 采用多粒度帧特征聚合增强匹配可靠性和时序理解，补偿压缩导致的信息损失。

Result: 在基准数据集上的大量实验表明，E.M.Ground始终显著优于最先进的视频大语言模型。

Conclusion: E.M.Ground通过关注整体和连贯的事件感知，有效解决了时序视频定位中的语义连续性问题，在多个数据集上取得了显著性能提升。

Abstract: Despite recent advances in Video Large Language Models (Vid-LLMs), Temporal Video Grounding (TVG), which aims to precisely localize time segments corresponding to query events, remains a significant challenge. Existing methods often match start and end frames by comparing frame features with two separate tokens, relying heavily on exact timestamps. However, this approach fails to capture the event's semantic continuity and integrity, leading to ambiguities. To address this, we propose E.M.Ground, a novel Vid-LLM for TVG that focuses on holistic and coherent event perception. E.M.Ground introduces three key innovations: (i) a special <event> token that aggregates information from all frames of a query event, preserving semantic continuity for accurate event matching; (ii) Savitzky-Golay smoothing to reduce noise in token-to-frame similarities across timestamps, improving prediction accuracy; (iii) multi-grained frame feature aggregation to enhance matching reliability and temporal understanding, compensating for compression-induced information loss. Extensive experiments on benchmark datasets show that E.M.Ground consistently outperforms state-of-the-art Vid-LLMs by significant margins.

</details>


### [4] [SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback](https://arxiv.org/abs/2602.05380)
*Xiaoxuan He,Siming Fu,Wanli Li,Zhiyuan Li,Dacheng Yin,Kang Rong,Fengyun Rao,Bo Zhang*

Main category: cs.CV

TL;DR: SAIL框架通过自增强迭代学习，让扩散模型作为自己的老师，仅需6%的人类偏好数据就能实现有效对齐，无需外部奖励模型。


<details>
  <summary>Details</summary>
Motivation: 当奖励模型不可用或获取成本过高，且大规模偏好数据集收集昂贵时，如何仅用最少的人类反馈实现扩散模型的有效对齐成为一个关键问题。

Method: 提出SAIL框架：从少量人类标注的偏好对开始，通过闭环方式让模型逐步生成多样样本，基于自身演化理解进行自标注偏好，并使用自增强数据集进行自我精炼。引入排名偏好混合策略平衡探索与初始人类先验。

Result: SAIL在多个基准测试中始终优于最先进方法，仅需现有方法6%的偏好数据，证明扩散模型具有显著的自改进能力。

Conclusion: 扩散模型拥有强大的自改进能力，当被适当利用时，可以有效替代大规模人类标注和外部奖励模型，实现高效对齐。

Abstract: Aligning diffusion models with human preferences remains challenging, particularly when reward models are unavailable or impractical to obtain, and collecting large-scale preference datasets is prohibitively expensive. \textit{This raises a fundamental question: can we achieve effective alignment using only minimal human feedback, without auxiliary reward models, by unlocking the latent capabilities within diffusion models themselves?} In this paper, we propose \textbf{SAIL} (\textbf{S}elf-\textbf{A}mplified \textbf{I}terative \textbf{L}earning), a novel framework that enables diffusion models to act as their own teachers through iterative self-improvement. Starting from a minimal seed set of human-annotated preference pairs, SAIL operates in a closed-loop manner where the model progressively generates diverse samples, self-annotates preferences based on its evolving understanding, and refines itself using this self-augmented dataset. To ensure robust learning and prevent catastrophic forgetting, we introduce a ranked preference mixup strategy that carefully balances exploration with adherence to initial human priors. Extensive experiments demonstrate that SAIL consistently outperforms state-of-the-art methods across multiple benchmarks while using merely 6\% of the preference data required by existing approaches, revealing that diffusion models possess remarkable self-improvement capabilities that, when properly harnessed, can effectively replace both large-scale human annotation and external reward models.

</details>


### [5] [TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions](https://arxiv.org/abs/2602.05414)
*Ngoc Doan-Minh Huynh,Duong Nguyen-Ngoc Tran,Long Hoang Pham,Tai Huu-Phuong Tran,Hyung-Joon Jeon,Huy-Hung Nguyen,Duong Khac Vu,Hyung-Min Jeon,Son Hong Phan,Quoc Pham-Nam Ho,Chi Dai Tran,Trinh Le Ba Khanh,Jae Wook Jeon*

Main category: cs.CV

TL;DR: 该研究提出了TSBOW数据集，这是一个针对极端天气条件下交通监控中遮挡车辆检测的综合性基准数据集，包含超过32小时的真实交通数据和数百万标注帧。


<details>
  <summary>Details</summary>
Motivation: 全球变暖加剧了极端天气事件的频率和严重性，这些天气会降低CCTV信号和视频质量，同时扰乱交通流，增加交通事故率。现有数据集通常只包含轻度雾霾、雨雪等条件，无法捕捉极端天气情况。

Method: 研究团队收集了来自人口密集城市地区的超过32小时真实世界交通数据，创建了TSBOW数据集。该数据集包含超过48,000个手动标注帧和320万个半标注帧，涵盖八个交通参与者类别，包括大型车辆、微型交通工具和行人等。

Result: 建立了TSBOW的对象检测基准，突出了遮挡和恶劣天气带来的挑战。数据集包含多样化的道路类型、尺度和视角，可作为智能交通系统研究的关键资源。

Conclusion: TSBOW数据集填补了极端天气条件下交通监控研究的空白，展示了基于CCTV的交通监控潜力，为新的研究和应用铺平了道路。数据集已公开可用。

Abstract: Global warming has intensified the frequency and severity of extreme weather events, which degrade CCTV signal and video quality while disrupting traffic flow, thereby increasing traffic accident rates. Existing datasets, often limited to light haze, rain, and snow, fail to capture extreme weather conditions. To address this gap, this study introduces the Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions (TSBOW), a comprehensive dataset designed to enhance occluded vehicle detection across diverse annual weather scenarios. Comprising over 32 hours of real-world traffic data from densely populated urban areas, TSBOW includes more than 48,000 manually annotated and 3.2 million semi-labeled frames; bounding boxes spanning eight traffic participant classes from large vehicles to micromobility devices and pedestrians. We establish an object detection benchmark for TSBOW, highlighting challenges posed by occlusions and adverse weather. With its varied road types, scales, and viewpoints, TSBOW serves as a critical resource for advancing Intelligent Transportation Systems. Our findings underscore the potential of CCTV-based traffic monitoring, pave the way for new research and applications. The TSBOW dataset is publicly available at: https://github.com/SKKUAutoLab/TSBOW.

</details>


### [6] [NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks](https://arxiv.org/abs/2602.05423)
*Pengcheng Chen,Yue Hu,Wenhao Li,Nicole M Gunderson,Andrew Feng,Zhenglong Sun,Peter Beerel,Eric J Seibel*

Main category: cs.CV

TL;DR: NeVStereo：一种结合NeRF渲染与立体视觉的联合框架，能够从多视角RGB输入中同时获得相机位姿、深度图、新视角合成和表面重建，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：前馈系统（如VGGT、pi3）专注于端到端匹配和几何预测但不输出新视角合成；基于神经渲染的方法能提供高质量新视角合成和详细几何，但通常假设固定相机位姿且对位姿误差敏感。因此，需要一个统一框架从随意拍摄的视图中同时获得准确的位姿、可靠的深度、高质量的渲染和精确的3D表面。

Method: NeVStereo结合了NeRF驱动的新视角合成与立体视觉架构，包括：1）基于NeRF的新视角合成生成适合立体匹配的渲染；2）置信度引导的多视角深度估计；3）NeRF耦合的束调整进行位姿优化；4）迭代优化阶段同时更新深度和辐射场以提高几何一致性。这种设计缓解了NeRF常见的表面堆叠、伪影和位姿-深度耦合问题。

Result: 在室内、室外、桌面和航拍基准测试中，NeVStereo实现了持续强大的零样本性能：深度误差降低达36%，位姿精度提升10.4%，新视角合成保真度提高4.5%，网格质量达到SOTA水平（F1 91.93%，Chamfer距离4.35 mm）。

Conclusion: NeVStereo成功构建了一个统一框架，能够从多视角RGB输入中联合提供相机位姿、多视角深度、新视角合成和表面重建，解决了现有方法的局限性，在多个任务上实现了优异的性能。

Abstract: In modern dense 3D reconstruction, feed-forward systems (e.g., VGGT, pi3) focus on end-to-end matching and geometry prediction but do not explicitly output the novel view synthesis (NVS). Neural rendering-based approaches offer high-fidelity NVS and detailed geometry from posed images, yet they typically assume fixed camera poses and can be sensitive to pose errors. As a result, it remains non-trivial to obtain a single framework that can offer accurate poses, reliable depth, high-quality rendering, and accurate 3D surfaces from casually captured views. We present NeVStereo, a NeRF-driven NVS-stereo architecture that aims to jointly deliver camera poses, multi-view depth, novel view synthesis, and surface reconstruction from multi-view RGB-only inputs. NeVStereo combines NeRF-based NVS for stereo-friendly renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and an iterative refinement stage that updates both depth and the radiance field to improve geometric consistency. This design mitigated the common NeRF-based issues such as surface stacking, artifacts, and pose-depth coupling. Across indoor, outdoor, tabletop, and aerial benchmarks, our experiments indicate that NeVStereo achieves consistently strong zero-shot performance, with up to 36% lower depth error, 10.4% improved pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm) compared to existing prestigious methods.

</details>


### [7] [Stable Velocity: A Variance Perspective on Flow Matching](https://arxiv.org/abs/2602.05435)
*Donglin Yang,Yongxing Zhang,Xin Yu,Liang Hou,Xin Tao,Pengfei Wan,Xiaojuan Qi,Renjie Liao*

Main category: cs.CV

TL;DR: 本文提出Stable Velocity框架，通过分析流匹配中条件速度的高方差问题，设计了方差降低的训练目标和采样加速方法，在多个大规模生成模型中实现了训练效率提升和2倍以上的采样加速。


<details>
  <summary>Details</summary>
Motivation: 流匹配方法虽然优雅，但其依赖单样本条件速度导致高方差训练目标，这会破坏优化稳定性并减慢收敛速度。作者通过显式分析这种方差，发现两个关键区域：1）靠近先验分布的高方差区域（优化困难），2）靠近数据分布的低方差区域（条件速度和边际速度几乎重合）。

Method: 提出Stable Velocity统一框架，包含：1）训练方面：Stable Velocity Matching（StableVM）- 无偏方差降低目标；Variance-Aware Representation Alignment（VA-REPA）- 在低方差区域自适应加强辅助监督；2）推理方面：Stable Velocity Sampling（StableVS）- 利用低方差区域动力学可闭式简化的特性，实现无需微调的采样加速。

Result: 在ImageNet 256×256以及大型预训练文本到图像和文本到视频模型（包括SD3.5、Flux、Qwen-Image、Wan2.2）上的广泛实验表明，该方法能一致提升训练效率，并在低方差区域内实现超过2倍的采样加速，同时不降低样本质量。

Conclusion: 通过显式分析流匹配中的方差问题，提出的Stable Velocity框架有效解决了训练不稳定和收敛慢的问题，同时实现了显著的采样加速，为大规模生成模型的训练和推理提供了实用解决方案。

Abstract: While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.

</details>


### [8] [Attention Retention for Continual Learning with Vision Transformers](https://arxiv.org/abs/2602.05454)
*Yue Lu,Xiangyu Zhou,Shizhou Zhang,Yinghui Xing,Guoqiang Liang,Wencong Zhang*

Main category: cs.CV

TL;DR: 提出基于注意力保留的持续学习方法，通过梯度掩码防止Vision Transformer中的注意力漂移，缓解灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 持续学习中灾难性遗忘是核心挑战，研究发现Vision Transformer中的注意力漂移是导致遗忘的主要原因，受人类视觉系统选择性注意机制启发

Method: 提出注意力保留框架：1) 使用层间展开机制提取前一任务的注意力图并生成实例自适应二进制掩码；2) 学习新任务时应用掩码将先前注意力区域的梯度置零，防止已学视觉概念被破坏；为兼容现代优化器，通过比例缩放参数更新保持相对幅度

Result: 实验和可视化表明该方法能有效缓解灾难性遗忘并保留视觉概念，在多种持续学习场景中取得最先进性能并展现强大泛化能力

Conclusion: 注意力漂移是Vision Transformer中灾难性遗忘的关键原因，提出的注意力保留框架通过梯度掩码机制能有效缓解遗忘，为持续学习提供了新思路

Abstract: Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the attention to previously learned visual concepts shifts significantly after learning new tasks. Inspired by neuroscientific insights into the selective attention in the human visual system, we propose a novel attention-retaining framework to mitigate forgetting in CL. Our method constrains attention drift by explicitly modifying gradients during backpropagation through a two-step process: 1) extracting attention maps of the previous task using a layer-wise rollout mechanism and generating instance-adaptive binary masks, and 2) when learning a new task, applying these masks to zero out gradients associated with previous attention regions, thereby preventing disruption of learned visual concepts. For compatibility with modern optimizers, the gradient masking process is further enhanced by scaling parameter updates proportionally to maintain their relative magnitudes. Experiments and visualizations demonstrate the effectiveness of our method in mitigating catastrophic forgetting and preserving visual concepts. It achieves state-of-the-art performance and exhibits robust generalizability across diverse CL scenarios.

</details>


### [9] [UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos](https://arxiv.org/abs/2602.05638)
*Jinlin Wu,Felix Holm,Chuxi Chen,An Wang,Yaxin Hu,Xiaofan Ye,Zelin Zang,Miao Xu,Lihua Zhou,Huai Liao,Danny T. M. Chan,Ming Feng,Wai S. Poon,Hongliang Ren,Dong Yi,Nassir Navab,Gaofeng Meng,Jiebo Luo,Hongbin Liu,Zhen Lei*

Main category: cs.CV

TL;DR: UniSurg是一个基于视频原生架构的手术视频基础模型，通过从像素级重建转向潜在运动预测，结合运动引导、时空亲和性自蒸馏和特征多样性正则化三大创新，在17个基准测试中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于基础模型的手术视频分析方法主要依赖像素级重建目标，浪费模型容量在烟雾、镜面反射、流体运动等低层次视觉细节上，而非关注手术理解所需的关键语义结构。

Method: 基于视频联合嵌入预测架构(V-JEPA)，提出三个针对手术视频的技术创新：1)运动引导潜在预测以关注语义重要区域；2)时空亲和性自蒸馏以增强关系一致性；3)特征多样性正则化以防止纹理稀疏手术场景中的表示坍缩。使用UniSurg-15M数据集(3,658小时视频，50个来源，13个解剖区域)进行大规模预训练。

Result: 在17个基准测试中显著优于最先进方法：手术工作流识别(EgoSurgery +14.6% F1，PitVis +10.3%)、动作三元组识别(CholecT50 39.54% mAP-IVT)、技能评估、息肉分割和深度估计。

Conclusion: UniSurg通过从像素级重建转向潜在运动预测的新范式，建立了通用、运动导向的手术视频理解新标准。

Abstract: While foundation models have advanced surgical video analysis, current approaches rely predominantly on pixel-level reconstruction objectives that waste model capacity on low-level visual details - such as smoke, specular reflections, and fluid motion - rather than semantic structures essential for surgical understanding. We present UniSurg, a video-native foundation model that shifts the learning paradigm from pixel-level reconstruction to latent motion prediction. Built on the Video Joint Embedding Predictive Architecture (V-JEPA), UniSurg introduces three key technical innovations tailored to surgical videos: 1) motion-guided latent prediction to prioritize semantically meaningful regions, 2) spatiotemporal affinity self-distillation to enforce relational consistency, and 3) feature diversity regularization to prevent representation collapse in texture-sparse surgical scenes. To enable large-scale pretraining, we curate UniSurg-15M, the largest surgical video dataset to date, comprising 3,658 hours of video from 50 sources across 13 anatomical regions. Extensive experiments across 17 benchmarks demonstrate that UniSurg significantly outperforms state-of-the-art methods on surgical workflow recognition (+14.6% F1 on EgoSurgery, +10.3% on PitVis), action triplet recognition (39.54% mAP-IVT on CholecT50), skill assessment, polyp segmentation, and depth estimation. These results establish UniSurg as a new standard for universal, motion-oriented surgical video understanding.

</details>


### [10] [Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing](https://arxiv.org/abs/2602.05737)
*Luca Ciampi,Ludovico Iannello,Fabrizio Tonelli,Gabriele Lagani,Angelo Di Garbo,Federico Cremisi,Giuseppe Amato*

Main category: cs.CV

TL;DR: 利用体外培养的皮层神经元网络作为物理储层，通过高密度微电极阵列进行刺激和读取，实现生物储层计算系统，成功完成从简单刺激到MNIST手写数字的视觉模式识别任务。


<details>
  <summary>Details</summary>
Motivation: 传统储层计算依赖人工循环模型近似神经动力学，而本研究旨在利用活体神经回路的自发和刺激诱发活动作为计算基质，将生物神经基质整合到神经形态计算框架中。

Method: 使用高密度多电极阵列同时刺激和读取数百个通道：通过选定电极传递输入模式，其余电极捕获高维神经响应，形成生物基础的特征表示，然后训练线性读出层（单层感知器）对这些储层状态进行分类。

Result: 尽管生物神经响应存在噪声、自发活动和会话间差异等固有变异性，系统始终能生成支持准确分类的高维表示，体外皮层网络能够作为静态视觉模式识别的有效储层。

Conclusion: 体外皮层网络可作为静态视觉模式识别的有效储层，为将活体神经基质整合到神经形态计算框架开辟了新途径，展示了活体神经系统如何为设计高效且生物基础的计算模型提供信息。

Abstract: In this paper, we present a neuro-inspired approach to reservoir computing (RC) in which a network of in vitro cultured cortical neurons serves as the physical reservoir. Rather than relying on artificial recurrent models to approximate neural dynamics, our biological reservoir computing (BRC) system leverages the spontaneous and stimulus-evoked activity of living neural circuits as its computational substrate. A high-density multi-electrode array (HD-MEA) provides simultaneous stimulation and readout across hundreds of channels: input patterns are delivered through selected electrodes, while the remaining ones capture the resulting high-dimensional neural responses, yielding a biologically grounded feature representation. A linear readout layer (single-layer perceptron) is then trained to classify these reservoir states, enabling the living neural network to perform static visual pattern-recognition tasks within a computer-vision framework. We evaluate the system across a sequence of tasks of increasing difficulty, ranging from pointwise stimuli to oriented bars, clock-digit-like shapes, and handwritten digits from the MNIST dataset. Despite the inherent variability of biological neural responses-arising from noise, spontaneous activity, and inter-session differences-the system consistently generates high-dimensional representations that support accurate classification. These results demonstrate that in vitro cortical networks can function as effective reservoirs for static visual pattern recognition, opening new avenues for integrating living neural substrates into neuromorphic computing frameworks. More broadly, this work contributes to the effort to incorporate biological principles into machine learning and supports the goals of neuro-inspired vision by illustrating how living neural systems can inform the design of efficient and biologically grounded computational models.

</details>


### [11] [EoCD: Encoder only Remote Sensing Change Detection](https://arxiv.org/abs/2602.05882)
*Mubashir Noman,Mustansar Fiaz,Hiyam Debary,Abdul Hannan,Shah Nawaz,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 提出了一种仅使用编码器的变化检测方法EoCD，通过早期融合时序数据并替换解码器为参数免费的多尺度特征融合模块，显著降低模型复杂度，在性能和速度间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有变化检测方法存在两个问题：1）基于孪生编码器的方法需要分别提取时序特征再进行融合，计算成本高且模型复杂；2）早期融合方法虽然避免了孪生编码器的开销，但仍依赖复杂解码器且性能不如后期融合方法。需要一种简单有效的方法来平衡性能和复杂度。

Method: 提出编码器仅变化检测（EoCD）方法：1）对时序数据进行早期融合；2）用参数免费的多尺度特征融合模块替代传统解码器；3）模型性能主要依赖编码器网络，解码器成为附加组件。

Result: 在四个具有挑战性的变化检测数据集上进行广泛实验，EoCD在变化检测性能和预测速度之间展现出最佳平衡。结果表明模型性能主要取决于编码器网络，解码器成为额外组件。

Conclusion: EoCD是一种简单有效的编码器仅变化检测方法，通过早期融合和参数免费特征融合模块显著降低模型复杂度，在多种编码器架构下都能实现性能与速度的最佳平衡。

Abstract: Being a cornerstone of temporal analysis, change detection has been playing a pivotal role in modern earth observation. Existing change detection methods rely on the Siamese encoder to individually extract temporal features followed by temporal fusion. Subsequently, these methods design sophisticated decoders to improve the change detection performance without taking into consideration the complexity of the model. These aforementioned issues intensify the overall computational cost as well as the network's complexity which is undesirable. Alternatively, few methods utilize the early fusion scheme to combine the temporal images. These methods prevent the extra overhead of Siamese encoder, however, they also rely on sophisticated decoders for better performance. In addition, these methods demonstrate inferior performance as compared to late fusion based methods. To bridge these gaps, we introduce encoder only change detection (EoCD) that is a simple and effective method for the change detection task. The proposed method performs the early fusion of the temporal data and replaces the decoder with a parameter-free multiscale feature fusion module thereby significantly reducing the overall complexity of the model. EoCD demonstrate the optimal balance between the change detection performance and the prediction speed across a variety of encoder architectures. Additionally, EoCD demonstrate that the performance of the model is predominantly dependent on the encoder network, making the decoder an additional component. Extensive experimentation on four challenging change detection datasets reveals the effectiveness of the proposed method.

</details>


### [12] [Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028)
*Shuo Chen,Cong Wei,Sun Sun,Ping Nie,Kai Zhou,Ge Zhang,Ming-Hsuan Yang,Wenhu Chen*

Main category: cs.CV

TL;DR: 提出Context Forcing框架，通过长上下文教师训练长上下文学生，解决现有实时长视频生成中的学生-教师不匹配问题，实现超过20秒的有效上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有实时长视频生成方法采用流式调优策略，使用短上下文（无记忆）教师训练长上下文学生。这种结构导致学生-教师不匹配：教师无法访问长期历史，无法指导学生处理全局时间依赖，限制了学生的上下文长度。

Method: 提出Context Forcing框架，通过长上下文教师训练长上下文学生，消除监督不匹配。为处理极端时长（如2分钟），引入上下文管理系统，将线性增长的上下文转换为慢-快记忆架构，显著减少视觉冗余。

Result: 方法实现超过20秒的有效上下文长度，比LongLive和Infinite-RoPE等最先进方法长2-10倍。利用扩展的上下文，Context Forcing在长时间内保持卓越的一致性，在各种长视频评估指标上超越现有基线。

Conclusion: Context Forcing通过消除学生-教师不匹配，实现了长上下文视频生成，显著提升了长视频的时序一致性，为实时长视频生成提供了有效的解决方案。

Abstract: Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Multi-Aspect Mining and Anomaly Detection for Heterogeneous Tensor Streams](https://arxiv.org/abs/2602.04917)
*Soshi Kakio,Yasuko Matsubara,Ren Fujiwara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: HeteroComp：一种用于异构张量流（包含分类和连续属性）的连续摘要和组异常检测方法，使用高斯过程先验直接建模数据分布和时序动态。


<details>
  <summary>Details</summary>
Motivation: 现有张量分解和异常检测方法存在两个主要局限：1) 无法处理包含分类属性（如IP地址）和连续属性（如数据包长度）的异构张量流，通常需要离散化连续属性或将分类属性视为连续，这会扭曲数据的统计特性；2) 离散化时间戳，无法跟踪流的时序动态（如趋势、异常事件），导致无法有效检测组级异常（如DoS攻击）。

Method: 提出HeteroComp方法：1) 使用高斯过程先验建模连续属性的未知分布和时序动态，直接从数据估计概率密度；2) 将异构张量流连续摘要为表示每个属性中潜在组及其时序动态的"组件"；3) 基于提取的组件进行组异常检测。

Result: 在真实数据集上的广泛实验表明：1) HeteroComp在组异常检测准确率上优于最先进算法；2) 计算时间不依赖于数据流长度，具有良好的可扩展性。

Conclusion: HeteroComp能够有效处理异构张量流，通过直接建模数据分布和时序动态，提供简洁但有效的摘要，实现准确的组异常检测，解决了现有方法在处理异构属性和时序动态方面的局限性。

Abstract: Analysis and anomaly detection in event tensor streams consisting of timestamps and multiple attributes - such as communication logs(time, IP address, packet length)- are essential tasks in data mining. While existing tensor decomposition and anomaly detection methods provide useful insights, they face the following two limitations. (i) They cannot handle heterogeneous tensor streams, which comprises both categorical attributes(e.g., IP address) and continuous attributes(e.g., packet length). They typically require either discretizing continuous attributes or treating categorical attributes as continuous, both of which distort the underlying statistical properties of the data.Furthermore, incorrect assumptions about the distribution family of continuous attributes often degrade the model's performance. (ii) They discretize timestamps, failing to track the temporal dynamics of streams(e.g., trends, abnormal events), which makes them ineffective for detecting anomalies at the group level, referred to as 'group anomalies' (e.g, DoS attacks). To address these challenges, we propose HeteroComp, a method for continuously summarizing heterogeneous tensor streams into 'components' representing latent groups in each attribute and their temporal dynamics, and detecting group anomalies. Our method employs Gaussian process priors to model unknown distributions of continuous attributes, and temporal dynamics, which directly estimate probability densities from data. Extracted components give concise but effective summarization, enabling accurate group anomaly detection. Extensive experiments on real datasets demonstrate that HeteroComp outperforms the state-of-the-art algorithms for group anomaly detection accuracy, and its computational time does not depend on the data stream length.

</details>


### [14] [ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation](https://arxiv.org/abs/2602.05051)
*Songyuan Zhang,Oswin So,H. M. Sabbir Ahmad,Eric Yang Yu,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: ReFORM是一种基于流策略的离线强化学习方法，通过构造强制执行较宽松的支持约束，解决了离线RL中的分布外误差问题，同时在OGBench基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中存在两个主要挑战：1）分布外（OOD）误差问题，当策略偏离训练分布时发生；2）最优策略分布可能是多模态且难以表示。现有方法通过惩罚统计距离项来保持策略接近行为策略，但这限制了策略改进且不能完全防止OOD动作。

Method: ReFORM基于流策略设计：1）首先学习一个有界源分布的行为克隆（BC）流策略来捕捉动作分布的支持；2）然后优化一个反射流，为BC流生成有界噪声同时保持支持，以最大化性能。这种方法通过构造强制执行支持约束，而不是惩罚统计距离。

Result: 在OGBench基准测试的40个挑战性任务中，使用不同质量的数据集，ReFORM在所有任务上使用恒定超参数，在性能曲线分析中显著优于所有经过手动调优超参数的基线方法。

Conclusion: ReFORM通过流策略的构造方式有效解决了离线RL中的OOD误差问题，同时保持了策略的表达能力，在多个基准测试中展现出优越的性能和鲁棒性。

Abstract: Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed dataset generated by behavior policies without additional environment interactions. One common challenge that arises in this setting is the out-of-distribution (OOD) error, which occurs when the policy leaves the training distribution. Prior methods penalize a statistical distance term to keep the policy close to the behavior policy, but this constrains policy improvement and may not completely prevent OOD actions. Another challenge is that the optimal policy distribution can be multimodal and difficult to represent. Recent works apply diffusion or flow policies to address this problem, but it is unclear how to avoid OOD errors while retaining policy expressiveness. We propose ReFORM, an offline RL method based on flow policies that enforces the less restrictive support constraint by construction. ReFORM learns a behavior cloning (BC) flow policy with a bounded source distribution to capture the support of the action distribution, then optimizes a reflected flow that generates bounded noise for the BC flow while keeping the support, to maximize the performance. Across 40 challenging tasks from the OGBench benchmark with datasets of varying quality and using a constant set of hyperparameters for all tasks, ReFORM dominates all baselines with hand-tuned hyperparameters on the performance profile curves.

</details>


### [15] [Constrained Group Relative Policy Optimization](https://arxiv.org/abs/2602.05863)
*Roger Girgis,Rodrigue de Schaetzen,Luke Rowe,Azalée Robitaille,Christopher Pal,Liam Paull*

Main category: cs.LG

TL;DR: 提出Constrained GRPO，一种基于拉格朗日方法的GRPO扩展，用于约束策略优化。通过标量化优势估计解决多组件优势估计中的优化问题，在机器人任务中实现更好的约束满足和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然GRPO已成为可扩展的无评论者策略学习框架，但在具有明确行为约束的场景中应用仍未被充分探索。需要将GRPO扩展到约束策略优化领域，特别是在依赖大型多模态基础模型的具身AI领域。

Method: 提出Constrained GRPO，基于拉格朗日松弛的GRPO扩展。使用指示器成本函数指定约束，通过拉格朗日松弛直接优化违反率。关键创新是标量化优势构造，避免多组件优势估计中因标准差不匹配导致的优化问题。

Result: 在玩具网格世界中验证了多组件优势估计的优化病理问题，标量化优势构造恢复了稳定的约束控制。在机器人任务中，Constrained GRPO提高了约束满足度，同时增加了任务成功率。

Conclusion: Constrained GRPO为具身AI领域的约束策略优化提供了一个简单有效的解决方案，特别是在依赖大型多模态基础模型的场景中，能够有效平衡奖励和约束之间的权衡。

Abstract: While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.

</details>


### [16] [StagePilot: A Deep Reinforcement Learning Agent for Stage-Controlled Cybergrooming Simulation](https://arxiv.org/abs/2602.05060)
*Heajun An,Qi Zhang,Minqian Liu,Xinyi Zhang,Sang Won Lee,Lifu Huang,Pamela J. Wisniewski,Jin-Hee Cho*

Main category: cs.LG

TL;DR: StagePilot是一个基于离线强化学习的对话代理，通过模拟网络诱骗行为的阶段性进展来进行预防培训，在LLM模拟中表现出色，IQL+AWAC代理在战略规划和情感一致性方面达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 网络诱骗对青少年构成持续威胁，需要主动的教育干预措施。传统方法可能无法有效模拟诱骗行为的动态发展过程，因此需要开发能够真实再现诱骗阶段性进展的训练工具。

Method: 提出StagePilot离线RL对话代理，使用复合奖励函数平衡用户情感和目标接近度来选择对话阶段，阶段转换限制在相邻阶段以保证真实性和可解释性。通过LLM模拟进行评估，测量阶段完成度、对话效率和情感参与度。

Result: StagePilot能生成与诱骗动态一致的现实且连贯的对话。在测试方法中，IQL+AWAC代理在战略规划和情感一致性方面达到最佳平衡，到达最终阶段的频率比基线高43%，同时保持超过70%的情感一致性。

Conclusion: StagePilot作为预防培训工具，能够有效模拟网络诱骗的阶段性行为，为青少年网络安全教育提供了一种创新的、基于AI的干预方法。

Abstract: Cybergrooming is an evolving threat to youth, necessitating proactive educational interventions. We propose StagePilot, an offline RL-based dialogue agent that simulates the stage-wise progression of grooming behaviors for prevention training. StagePilot selects conversational stages using a composite reward that balances user sentiment and goal proximity, with transitions constrained to adjacent stages for realism and interpretability. We evaluate StagePilot through LLM-based simulations, measuring stage completion, dialogue efficiency, and emotional engagement. Results show that StagePilot generates realistic and coherent conversations aligned with grooming dynamics. Among tested methods, the IQL+AWAC agent achieves the best balance between strategic planning and emotional coherence, reaching the final stage up to 43% more frequently than baselines while maintaining over 70% sentiment alignment.

</details>


### [17] [Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks](https://arxiv.org/abs/2602.05125)
*William F. Shen,Xinchi Qiu,Chenxi Whitehouse,Lisa Alazraki,Shashwat Goel,Francesco Barbieri,Timon Willi,Akhil Mathur,Ilias Leontiadis*

Main category: cs.LG

TL;DR: RRD框架通过递归分解-过滤循环优化评分标准，提升LLM评估准确性和强化微调效果


<details>
  <summary>Details</summary>
Motivation: 现有评分标准存在覆盖不全、维度混淆、偏好方向错位、冗余和高度相关等问题，影响LLM评估准确性和强化微调效果

Method: 提出RRD框架，采用递归分解-过滤循环：将粗粒度评分标准分解为细粒度判别性标准，过滤错位和冗余标准，并使用相关性感知加权方案

Result: 在JudgeBench和PPE上显著提升GPT-4o和Llama3.1-405B的评估准确性（最高+17.7分）；在WildChat上作为强化微调奖励信号，使Qwen3-4B奖励提升160%，Llama3.1-8B提升60%

Conclusion: RRD建立了可扩展、可解释的递归评分标准优化基础，显著提升LLM在开放领域中的评估和奖励建模能力

Abstract: Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.

</details>


### [18] [Cross-talk based multi-task learning for fault classification of physically coupled machine system](https://arxiv.org/abs/2602.05146)
*Wonjun Yi,Rismaya Kumar Mishra,Yong-Hwa Park*

Main category: cs.LG

TL;DR: 该论文提出了一种基于交叉对话结构的多任务学习框架，通过联合学习故障条件和相关物理变量来提升故障分类性能，在两个基准数据集上均优于单任务模型和多类模型。


<details>
  <summary>Details</summary>
Motivation: 机器系统产生的信号中，故障条件与各种物理变量存在物理耦合。现有故障分类研究通常只使用直接故障标签，但这些信号自然包含了由其他物理耦合信息塑造的附加信息。利用这种耦合关系可以提升故障分类性能。

Method: 采用多任务学习框架，通过交叉对话结构联合学习故障条件和相关物理变量。基于先前提出的残差神经降维模型，在交叉对话结构中通过交叉对话层实现任务间的受控信息交换，避免负迁移。在两个基准数据集上验证：无人机故障数据集和电机复合故障数据集。

Result: 在两个基准数据集上，残差神经降维模型均优于单任务模型、合并所有标签组合的多类模型以及共享主干多任务模型。对于无人机故障数据集，通过学习故障分类与物理属性（机器类型和操纵方向），交叉对话架构能更好地分类故障。对于电机复合故障数据集，测试了单通道和多通道数据作为输入的分类性能。

Conclusion: 通过利用信号中固有的物理耦合信息，采用交叉对话结构的多任务学习框架能有效提升故障分类性能，避免负迁移问题，在两个不同领域的基准数据集上都取得了优于传统方法的性能。

Abstract: Machine systems inherently generate signals in which fault conditions and various physical variables are physically coupled. Although many existing fault classification studies rely solely on direct fault labels, the aforementioned signals naturally embed additional information shaped by other physically coupled information. Herein, we leverage this coupling through a multi-task learning (MTL) framework that jointly learns fault conditions and the related physical variables. Among MTL architectures, crosstalk structures have distinct advantages because they allow for controlled information exchange between tasks through the cross-talk layer while preventing negative transfer, in contrast to shared trunk architectures that often mix incompatible features. We build on our previously introduced residual neural dimension reductor model, and extend its application to two benchmarks where physical coupling is prominent. The first benchmark is a drone fault dataset, in which machine type and maneuvering direction significantly alter the frequency components of measured signals even under the same nominal condition. By learning fault classification together with these physical attributes, the cross-talk architecture can better classify faults. The second benchmark dataset is the motor compound fault dataset. In this system, each fault component, inner race fault, outer race fault, misalignment, and unbalance is coupled to the other. For motor compound fault, we also test classification performance when we use single-channel data or multi-channel data as input to the classifier. Across both benchmarks, our residual neural dimension reductor, consistently outperformed single-task models, multi-class models that merge all label combinations, and shared trunk multi-task models.

</details>


### [19] [Extreme Weather Nowcasting via Local Precipitation Pattern Prediction](https://arxiv.org/abs/2602.05204)
*Changhoon Song,Teng Yuan Chang,Youngjoon Hong*

Main category: cs.LG

TL;DR: exPreCast：一种用于雷达降水临近预报的高效确定性框架，结合平衡数据集实现极端天气和普通降雨的准确预测


<details>
  <summary>Details</summary>
Motivation: 极端天气（如暴雨、风暴）的准确预报对风险管理和灾害缓解至关重要。现有方法存在以下问题：基于扩散的生成模型计算成本高，不适合实时应用；确定性模型计算高效但对极端降雨存在偏差；现有基准数据集本身存在偏差，要么以普通降雨为主，要么仅限于极端降雨事件，限制了实际应用。

Method: 提出exPreCast框架，包含局部时空注意力机制、纹理保持的立方双上采样解码器和时间提取器，可灵活调整预报时间范围。同时构建了来自韩国气象厅的平衡雷达数据集，包含普通降水和极端事件。

Result: 在SEVIR、MeteoNet基准数据集和新构建的平衡KMA数据集上的实验表明，该方法实现了最先进的性能，在普通和极端降雨情况下都能提供准确可靠的临近预报。

Conclusion: exPreCast框架通过高效确定性方法和平衡数据集，解决了降水临近预报中极端天气预测的挑战，为实际应用提供了准确可靠的解决方案。

Abstract: Accurate forecasting of extreme weather events such as heavy rainfall or storms is critical for risk management and disaster mitigation. Although high-resolution radar observations have spurred extensive research on nowcasting models, precipitation nowcasting remains particularly challenging due to pronounced spatial locality, intricate fine-scale rainfall structures, and variability in forecasting horizons. While recent diffusion-based generative ensembles show promising results, they are computationally expensive and unsuitable for real-time applications. In contrast, deterministic models are computationally efficient but remain biased toward normal rainfall. Furthermore, the benchmark datasets commonly used in prior studies are themselves skewed--either dominated by ordinary rainfall events or restricted to extreme rainfall episodes--thereby hindering general applicability in real-world settings. In this paper, we propose exPreCast, an efficient deterministic framework for generating finely detailed radar forecasts, and introduce a newly constructed balanced radar dataset from the Korea Meteorological Administration (KMA), which encompasses both ordinary precipitation and extreme events. Our model integrates local spatiotemporal attention, a texture-preserving cubic dual upsampling decoder, and a temporal extractor to flexibly adjust forecasting horizons. Experiments on established benchmarks (SEVIR and MeteoNet) as well as on the balanced KMA dataset demonstrate that our approach achieves state-of-the-art performance, delivering accurate and reliable nowcasts across both normal and extreme rainfall regimes.

</details>


### [20] [Joint Embedding Variational Bayes](https://arxiv.org/abs/2602.05639)
*Amin Oji,Paul Fieguth*

Main category: cs.LG

TL;DR: VJE是一个结合联合嵌入和变分推断的自监督学习框架，用于学习概率表示，无需重建和非对比训练，在多个数据集上达到与非对比基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于能量的预测目标优化点间差异，而VJE旨在通过变分推断学习概率表示，避免重建和非对比设置下的训练不稳定性。

Method: VJE最大化对称条件证据下界(ELBO)，使用重尾Student-t模型作为条件似然，通过极坐标分解解耦方向和径向因子，采用摊销推理网络参数化对角高斯变分后验。

Result: 在ImageNet-1K、CIFAR-10/100和STL-10上，VJE在线性和k-NN评估中达到与非对比基线相当的性能；在单类CIFAR-10异常检测中，基于似然的评分优于其他自监督基线。

Conclusion: VJE成功将变分推断与联合嵌入结合，实现了重建自由、非对比的自监督概率表示学习，在标准评估和异常检测任务中验证了其有效性。

Abstract: We introduce Variational Joint Embedding (VJE), a framework that synthesizes joint embedding and variational inference to enable self-supervised learning of probabilistic representations in a reconstruction-free, non-contrastive setting. Compared to energy-based predictive objectives that optimize pointwise discrepancies, VJE maximizes a symmetric conditional evidence lower bound (ELBO) for a latent-variable model defined directly on encoder embeddings. We instantiate the conditional likelihood with a heavy-tailed Student-$t$ model using a polar decomposition that explicitly decouples directional and radial factors to prevent norm-induced instabilities during training. VJE employs an amortized inference network to parameterize a diagonal Gaussian variational posterior whose feature-wise variances are shared with the likelihood scale to capture anisotropic uncertainty without auxiliary projection heads. Across ImageNet-1K, CIFAR-10/100, and STL-10, VJE achieves performance comparable to standard non-contrastive baselines under linear and k-NN evaluation. We further validate these probabilistic semantics through one-class CIFAR-10 anomaly detection, where likelihood-based scoring under the proposed model outperforms comparable self-supervised baselines.

</details>


### [21] [Accelerating Benchmarking of Functional Connectivity Modeling via Structure-aware Core-set Selection](https://arxiv.org/abs/2602.05667)
*Ling Zhan,Zhen Li,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: 提出SCLCS方法，通过自监督学习选择代表性核心集，仅用10%数据就能保持功能连接模型性能排名，解决大规模fMRI数据集基准测试的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 大规模fMRI数据集中功能连接建模方法的基准测试对可重复神经科学至关重要，但模型-数据组合的爆炸性增长使得穷举评估计算上不可行，需要打破这一瓶颈。

Method: 提出结构感知对比学习核心集选择框架：1) 使用自适应Transformer学习每个样本的独特功能连接结构；2) 引入结构扰动分数量化训练期间学习结构的稳定性；3) 采用密度平衡采样策略确保核心集的结构鲁棒性和分布代表性。

Result: 在REST-meta-MDD数据集上，SCLCS仅用10%数据就能保持地面真实模型排名，在排名一致性方面比现有最佳核心集选择方法提升达23.2%。

Conclusion: 这是首个将核心集选择形式化用于功能连接算子基准测试的工作，使大规模算子比较成为计算神经科学中可行且不可或缺的部分。

Abstract: Benchmarking the hundreds of functional connectivity (FC) modeling methods on large-scale fMRI datasets is critical for reproducible neuroscience. However, the combinatorial explosion of model-data pairings makes exhaustive evaluation computationally prohibitive, preventing such assessments from becoming a routine pre-analysis step. To break this bottleneck, we reframe the challenge of FC benchmarking by selecting a small, representative core-set whose sole purpose is to preserve the relative performance ranking of FC operators. We formalize this as a ranking-preserving subset selection problem and propose Structure-aware Contrastive Learning for Core-set Selection (SCLCS), a self-supervised framework to select these core-sets. SCLCS first uses an adaptive Transformer to learn each sample's unique FC structure. It then introduces a novel Structural Perturbation Score (SPS) to quantify the stability of these learned structures during training, identifying samples that represent foundational connectivity archetypes. Finally, while SCLCS identifies stable samples via a top-k ranking, we further introduce a density-balanced sampling strategy as a necessary correction to promote diversity, ensuring the final core-set is both structurally robust and distributionally representative. On the large-scale REST-meta-MDD dataset, SCLCS preserves the ground-truth model ranking with just 10% of the data, outperforming state-of-the-art (SOTA) core-set selection methods by up to 23.2% in ranking consistency (nDCG@k). To our knowledge, this is the first work to formalize core-set selection for FC operator benchmarking, thereby making large-scale operators comparisons a feasible and integral part of computational neuroscience. Code is publicly available on https://github.com/lzhan94swu/SCLCS

</details>


### [22] [Distributional Reinforcement Learning with Diffusion Bridge Critics](https://arxiv.org/abs/2602.05783)
*Shutong Ding,Yimiao Zhou,Ke Hu,Mokai Pan,Shan Zhong,Yanwei Fu,Jingya Wang,Ye Shi*

Main category: cs.LG

TL;DR: 提出DBC方法，首次将扩散桥模型用作分布强化学习中的评论家，通过建模Q值的逆累积分布函数来准确捕捉价值分布，避免坍缩为简单高斯分布。


<details>
  <summary>Details</summary>
Motivation: 现有扩散强化学习方法主要关注扩散策略，而忽略了扩散评论家。由于策略优化本质上依赖于评论家，准确的价值估计比策略表达能力更重要。此外，考虑到强化学习任务的随机性，评论家更适合用分布模型来刻画。

Method: 提出扩散桥评论家(DBC)方法，直接建模Q值的逆累积分布函数，利用扩散桥的强大分布匹配能力准确捕捉价值分布。还推导了解析积分公式来处理DBC中的离散化误差。

Result: 在MuJoCo机器人控制基准测试中，DBC相比之前的分布评论家模型表现出优越性能。

Conclusion: DBC是首个将扩散桥模型用作评论家的工作，是一个即插即用的组件，可以集成到大多数现有的强化学习框架中，在分布强化学习中实现了更准确的价值估计。

Abstract: Recent advances in diffusion-based reinforcement learning (RL) methods have demonstrated promising results in a wide range of continuous control tasks. However, existing works in this field focus on the application of diffusion policies while leaving the diffusion critics unexplored. In fact, since policy optimization fundamentally relies on the critic, accurate value estimation is far more important than policy expressiveness. Furthermore, given the stochasticity of most reinforcement learning tasks, it has been confirmed that the critic is more appropriately depicted with a distributional model. Motivated by these points, we propose a novel distributional RL method with Diffusion Bridge Critics (DBC). DBC directly models the inverse cumulative distribution function (CDF) of the Q value. This allows us to accurately capture the value distribution and prevents it from collapsing into a trivial Gaussian distribution owing to the strong distribution-matching capability of the diffusion bridge. Moreover, we further derive an analytic integral formula to address discretization errors in DBC, which is essential in value estimation. To our knowledge, DBC is the first work to employ the diffusion bridge model as the critic. Notably, DBC is also a plug-and-play component and can be integrated into most existing RL frameworks. Experimental results on MuJoCo robot control benchmarks demonstrate the superiority of DBC compared with previous distributional critic models.

</details>


### [23] [Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference](https://arxiv.org/abs/2602.06029)
*Yingke Li,Anjali Parashar,Enlu Zhou,Chuchu Fan*

Main category: cs.LG

TL;DR: 本文为主动推理中的期望自由能最小化提供了首个理论保证，证明"足够的好奇心"能同时确保贝叶斯后验一致性和无遗憾优化，连接了主动推理与经典贝叶斯实验设计和贝叶斯优化。


<details>
  <summary>Details</summary>
Motivation: 主动推理通过期望自由能统一探索与利用，平衡认知价值（信息增益）和实用价值（任务性能）。但现有研究不清楚这种平衡何时能同时实现连贯学习和高效决策：好奇心不足会导致短视利用和不确定性无法解决，而好奇心过强会引发不必要的探索和遗憾。

Method: 建立期望自由能最小化代理的首个理论保证，分析"足够好奇心"这一单一要求如何同时确保自洽学习（贝叶斯后验一致性）和无遗憾优化（有界累积遗憾）。分析该机制如何依赖于初始不确定性、可识别性和目标对齐，将主动推理与经典贝叶斯实验设计和贝叶斯优化连接在一个理论框架内。

Result: 证明了"足够的好奇心"能同时保证贝叶斯后验一致性和有界累积遗憾，建立了主动推理的理论基础。进一步将这些理论转化为实际设计指南，用于在混合学习优化问题中调整认知-实用权衡，并通过真实世界实验验证。

Conclusion: 本文为主动推理中的期望自由能最小化提供了首个理论保证，建立了"足够好奇心"的统一框架，连接了主动推理与经典贝叶斯方法，并为实际应用提供了设计指导。

Abstract: Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: DemPO框架通过算法抽签构建代表性评分者小组，在偏好对齐中实现人口统计学代表性，硬面板和软面板方案均能提升模型对代表性公众价值观的反映。


<details>
  <summary>Details</summary>
Motivation: 当前AI偏好对齐方法（如RLHF）依赖的评分者样本通常存在人口统计学偏差，不能代表全体公众的价值观。需要一种机制确保偏好数据来自代表性样本。

Method: 提出民主偏好优化（DemPO）框架，采用算法抽签（类似公民大会机制）构建代表性评分者小组。提供两种方案：硬面板（仅使用抽签选出的代表性小组数据）和软面板（保留所有数据但按抽签概率重新加权）。

Result: 在包含评分者人口统计信息的公共偏好数据集上评估，硬面板方案在六种聚合方法中始终排名第一，软面板方案始终优于未加权基线。随着模型容量增加，效果更加明显。

Conclusion: 在偏好收集阶段强制实施人口统计学代表性，而非事后修正，能够训练出更好反映代表性公众价值观的模型。DemPO框架为AI价值观对齐提供了更民主的方法。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [25] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE框架通过对抗学习和指导性语言反馈，让LLM内部化推理逻辑，无需人工监督即可实现专家级推理能力


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖标量奖励存在三大问题：扩展成本高、跨领域脆弱、无法理解解决方案的内在逻辑。这种对外部贫乏信号的依赖阻碍了模型发展对推理原则的深度、自包含理解。

Method: ALIVE框架基于"认知协同"原则，将问题提出、解决和评判统一在单一策略模型中。通过对抗学习结合指导性语言反馈，让模型能够从原始语料中直接内部化评估标准，将外部批评转化为内生的推理能力。

Result: 在数学推理、代码生成和一般逻辑推理基准测试中，ALIVE持续缓解了奖励信号限制。在相同数据和计算条件下，实现了准确率提升、跨领域泛化能力显著改善以及更高的自我纠正率。

Conclusion: ALIVE的推理三位一体（问题提出、解决、评判）促进了能力增长的自我维持轨迹，为无需人工监督的通用推理对齐提供了可扩展的基础。

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [26] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 开发数据驱动的离散事件模拟器，用于评估学校安全干预策略，特别是机器人应对枪击事件的方案，通过VR数据训练实现可扩展的策略学习。


<details>
  <summary>Details</summary>
Motivation: VR虽然能有效评估学校安全措施，但需要为每个条件招募新参与者，难以进行大规模或迭代评估，尤其是在需要大量训练场景的学习有效干预策略时。

Method: 开发数据驱动的离散事件模拟器，将枪手移动和区域内行为建模为从VR研究参与者行为中学习的随机过程，用于评估机器人干预策略。

Result: 模拟器能够重现关键经验模式，实现可扩展的干预策略评估和学习，这些策略直接使用人类受试者进行训练是不可行的。

Conclusion: 这项工作展示了一个高到中保真度的模拟工作流程，为开发和评估自主学校安全干预提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>


### [27] [Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach](https://arxiv.org/abs/2602.05533)
*Zhengyi Guo,Wenpin Tang,Renyuan Xu*

Main category: cs.AI

TL;DR: 提出基于Doob's h-transform的扩散模型条件生成框架，用于满足硬约束（概率为1），通过漂移修正实现而不修改预训练分数网络，提供两种离策略学习算法和理论保证。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用和罕见事件模拟中，需要确保生成样本以概率1满足硬约束，而现有的软约束或基于奖励的引导方法无法保证约束满足。

Method: 基于扩散模型的概率解释，利用Doob's h-transform、鞅表示和二次变差过程，提出条件扩散引导框架。通过引入包含条件函数对数梯度的显式漂移修正来增强预训练扩散模型，不修改预训练分数网络。提出基于鞅损失和鞅协变损失的两种离策略学习算法来估计h及其梯度。

Result: 在总变差距离和Wasserstein距离上为非条件采样器提供非渐近保证，明确刻画了分数近似和引导估计误差的影响。数值实验证明方法在强制执行硬约束和生成罕见事件样本方面的有效性。

Conclusion: 提出了一个理论严谨的条件扩散引导框架，能够保证硬约束的满足，为安全关键应用和罕见事件模拟提供了可靠的生成方法。

Abstract: We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.

</details>


### [28] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 提出Generative Ontology框架，结合传统本体论的结构严谨性与大语言模型的创造性，通过可执行的Pydantic模式约束LLM生成，实现既有结构有效性又有创造性的领域设计生成。


<details>
  <summary>Details</summary>
Motivation: 传统本体论擅长描述领域结构但无法生成新工件，而大语言模型能流畅生成但缺乏结构有效性，经常产生无组件的机制或无终止条件的目标。需要结合两者的互补优势。

Method: 将领域知识编码为可执行的Pydantic模式，通过DSPy签名约束LLM生成。采用多智能体管道，为不同本体领域分配专门角色（如机制架构师、主题编织者、平衡批评家），每个智能体带有防止浅层输出的"专业焦虑"。使用检索增强生成将新设计基于现有范例，并通过迭代验证确保机制与组件的一致性。

Result: 通过GameGrammar系统展示了该框架，能够根据主题提示生成结构完整、可玩的桌面游戏设计，包含机制、组件、胜利条件和设置说明。输出既满足本体约束又保持真正的创造性。

Conclusion: 该模式可推广到游戏以外的领域，任何具有专家词汇、有效性约束和积累范例的领域（如音乐创作、软件架构、烹饪艺术）都适合使用Generative Ontology。约束不是限制创造力，而是使其成为可能，就像语法使诗歌成为可能一样。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [29] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: APO提出了一种新的强化学习优化方法，通过支持覆盖而非形状匹配来避免递归空间收缩问题，在保持多样性的同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在递归空间收缩（RSC）的系统性病理问题，KL正则化虽然试图缓解但引入了形状匹配约束，导致梯度冲突。需要一种既能保持效率又能防止空间崩溃的新方法。

Method: 提出锚定策略优化（APO），将范式从全局形状匹配转向支持覆盖。基于参考模型高置信度支持定义安全流形，允许激进锐化以提高效率，同时在错误修正时选择性调用恢复力以防止崩溃。

Result: 在数学基准测试中，APO打破了准确性-多样性权衡，显著提高了Pass@1指标，同时恢复了标准策略梯度方法通常失去的Pass@K多样性。

Conclusion: APO作为一种梯度对齐机制，通过最大化支持覆盖实现弹性恢复，有效解决了RLVR中的递归空间收缩问题，为强化学习优化提供了新方向。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [30] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 提出RLFKV框架，通过细粒度知识验证和强化学习减少金融RAG系统中的幻觉问题，提高回答与检索文档的一致性。


<details>
  <summary>Details</summary>
Motivation: 金融RAG系统虽然依赖检索文档来生成准确回答，但由于金融领域的时间敏感性，模型生成的回答仍会出现与检索信息矛盾的幻觉问题，需要解决这种不一致性。

Method: 提出强化学习框架RLFKV，将金融回答分解为原子知识单元，评估每个单元的正确性来计算细粒度忠实度奖励；同时引入信息量奖励防止奖励攻击（如过于简洁的回答），鼓励策略模型保留至少与基础模型相同数量的知识单元。

Result: 在公开的Financial Data Description (FDD)任务和新提出的FDD-ANT数据集上的实验显示了一致的改进，证实了方法的有效性。

Conclusion: RLFKV框架通过细粒度知识验证和强化学习，有效减少了金融RAG系统中的幻觉问题，提高了回答与检索文档的一致性。

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories](https://arxiv.org/abs/2602.05085)
*Sidi Lu,Zhenwen Liang,Dongyang Ma,Yan Wang,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: Locas是一种局部支持的参数化记忆机制，可与Transformer的FFN块设计兼容，支持高效持续学习，通过参数重用初始化实现快速收敛和减少灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 本文旨在将测试时训练与新型参数化记忆相结合，这种记忆可以灵活地从模型参数中卸载或合并，以支持高效的持续学习。

Method: 提出Locas（局部支持参数化记忆），采用两种变体：传统两层MLP设计（理论保证更清晰）和与SOTA LLMs共享GLU-FFN结构的设计。关键是通过重用模型参数、激活和/或梯度进行原则性初始化。

Result: 在PG-19整书语言建模和LoCoMo长上下文对话问答任务上验证。Locas-GLU仅需0.02%额外参数即可存储过去上下文信息，同时保持较小上下文窗口。MMLU评估显示Locas能最小化灾难性遗忘。

Conclusion: Locas能够将过去上下文永久化为参数化知识，同时最小化对模型现有内部知识的灾难性遗忘，展示了在持续学习中的潜力。

Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.

</details>


### [32] [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220)
*Jinchuan Tian,Haoran Wang,Bo-Hao Su,Chien-yu Huang,Qingzheng Wang,Jiatong Shi,William Chen,Xun Gong,Siddhant Arora,Chin-Jou Li,Masao Someki,Takashi Maekaku,Yusuke Shinohara,Jin Sakuma,Chao-Han Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: Bagpiper是一个80亿参数的音频基础模型，通过丰富的自然语言描述来理解物理音频信号，实现了音频理解与生成的统一框架，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前音频基础模型通常依赖刚性的任务特定监督，处理孤立的音频因素而非整体。相比之下，人类智能以整体方式处理音频，无缝连接物理信号与抽象认知概念来执行复杂任务。需要一种能够统一理解与生成通用音频的模型。

Method: 引入Bagpiper模型，通过丰富的自然语言描述（包含转录、音频事件等关键认知概念）来解释物理音频。在6000亿token的大规模语料上进行预训练，建立原始音频与高级概念空间之间的稳健双向映射。微调时采用"描述-处理"工作流程，模拟中间认知推理步骤来解决多样化任务。

Result: Bagpiper在MMAU和AIRBench音频理解基准上优于Qwen-2.5-Omni，在生成质量上超越CosyVoice3和TangoFlux，能够合成语音、音乐和音效的任意组合。实现了通用音频的统一理解与生成。

Conclusion: Bagpiper是首批实现通用音频统一理解与生成的工作之一，通过丰富的自然语言描述建立音频信号与认知概念之间的映射，为音频AI提供了更接近人类智能的处理方式。模型、数据和代码已开源。

Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.

</details>


### [33] [CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs](https://arxiv.org/abs/2602.05258)
*Haoran Li,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CL

TL;DR: CoPE通过软截断RoPE低频分量，统一了OOD缓解和语义建模两种目标，在长上下文扩展中取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有RoPE适应长上下文的方法主要分为两类：OOD缓解（调整频率适应未见位置）和语义建模（注意力分数应优先语义相似token）。这两种看似不同的目标需要统一的理论框架。

Method: 提出CoPE（软截断RoPE低频分量），通过简单的软截断操作同时消除OOD异常值、优化语义信号，并避免硬截断导致的频谱泄漏。

Result: 实验表明，仅对RoPE应用软截断策略就能在长达256k的上下文长度上获得显著的性能提升，验证了理论分析并确立了CoPE在长度泛化上的SOTA地位。

Conclusion: CoPE通过统一的软截断方法成功融合了OOD缓解和语义建模两种目标，为LLM的长上下文扩展提供了简单有效的解决方案。

Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.

</details>


### [34] [Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions](https://arxiv.org/abs/2602.05932)
*Léo Labat,Etienne Ollion,François Yvon*

Main category: cs.CL

TL;DR: 该研究探讨多语言大语言模型在价值导向多选题上的跨语言一致性，发现即使经过指令微调的大型模型也存在语言特异性行为，但仅在某些问题上出现。


<details>
  <summary>Details</summary>
Motivation: 研究多语言大语言模型在价值导向多选题上的跨语言一致性，探究它们是否像理论上的多语者一样在不同语言中表现一致，还是像多个单语模型一样因语言不同而表达不同价值观。

Method: 创建多语言欧洲价值观调查（MEVS）语料库，包含8种欧洲语言的人工翻译对齐问题。对30多个多语言大语言模型进行测试，控制提示变量（答案顺序、符号类型、尾部字符等）。

Result: 大型指令微调模型整体一致性较高，但不同问题间差异显著：某些问题模型间完全一致，而其他问题则答案分裂。所有一致的指令微调模型都表现出语言特异性行为，但仅出现在特定问题上。

Conclusion: 多语言大语言模型在价值导向多选题上存在语言诱导的变异，偏好微调具有选择性效应，需要进一步研究语言对模型价值观表达的影响。

Abstract: Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [35] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: VLN-Pilot是一个基于大型视觉语言模型（VLLM）的室内无人机导航框架，让VLLM充当人类飞行员角色，通过自然语言指令和视觉感知实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则或几何路径规划的无人机导航方法需要大量任务特定工程，无法灵活理解语义指令。室内GPS受限环境需要更智能、语义感知的导航方案，以支持检查、搜救等复杂任务。

Method: 利用VLLM的多模态推理能力，将自由形式的自然语言指令与视觉观察相结合，进行空间关系推理、障碍物避让和动态反应，实现语言驱动的语义理解和视觉感知融合。

Result: 在自定义的逼真室内仿真基准测试中，VLLM驱动的智能体在复杂指令跟随任务上取得高成功率，包括具有多个语义目标的长期导航任务。

Conclusion: VLLM为基础的飞行员可以显著减少操作员工作量，提高室内受限环境中的安全性和任务灵活性，为可扩展、人性化的室内无人机控制开辟了新途径。

Abstract: This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.

</details>


### [36] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出一种神经形态控制框架，用于视觉引导导航和跟踪，通过动态神经元群体将视觉目标激励直接转化为自我中心运动指令，利用动态分岔机制解决目标对称性导致的决策困难。


<details>
  <summary>Details</summary>
Motivation: 机器人导航中，反应式传感器控制与基于模型的规划器之间存在矛盾。当多个目标选项对称时，反应式系统难以做出决策，而传统规划器计算成本高。需要一种既能实时响应又能在对称情况下做出决策的轻量级控制方法。

Method: 提出神经形态控制框架：1）将机载相机图像像素编码为动态神经元群体的输入；2）将视觉目标激励直接转化为自我中心运动指令；3）采用动态分岔机制，延迟决策直到环境几何诱导的临界点出现；4）受动物认知机制和意见动力学模型启发，设计具有可解释参数的系统。

Result: 在仿真环境和实验四旋翼平台上验证了该方法的有效性。系统能够实现实时自主导航，计算负担小，参数少且可解释，并能与特定应用的图像处理流程无缝集成。

Conclusion: 该神经形态控制框架成功弥合了反应式控制与模型规划之间的差距，通过动态分岔机制解决了对称目标下的决策问题，为视觉引导导航提供了轻量级、实时且可解释的解决方案。

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>
