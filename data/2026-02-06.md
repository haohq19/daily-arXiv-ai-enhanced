<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 12]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Food Portion Estimation: From Pixels to Calories](https://arxiv.org/abs/2602.05078)
*Gautham Vinod,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文综述了基于图像的饮食评估中食物三维尺寸估计的不同策略，包括深度图、多视角输入、模板匹配等辅助输入方法，以及深度学习在单目图像或组合输入中的应用。


<details>
  <summary>Details</summary>
Motivation: 基于图像的饮食评估对于准确便捷地监测个体健康至关重要，是预防和护理慢性疾病及肥胖的重要机制。然而，从2D图像输入估计食物的三维尺寸存在困难。

Method: 探索了多种策略来克服这一限制：1）使用辅助输入如深度图和多视角输入；2）基于模型的方法如模板匹配；3）深度学习方法，包括使用单目图像或图像与辅助输入的组合来精确预测食物分量。

Result: 论文主要对各种策略进行了综述分析，未报告具体实验结果，而是系统性地梳理了不同方法在解决食物三维尺寸估计问题上的应用。

Conclusion: 基于图像的饮食评估需要准确的食物分量估计，多种策略已被开发来解决从2D图像估计3D尺寸的挑战，深度学习等现代方法正在帮助缩小这一差距。

Abstract: Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.

</details>


### [2] [GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling](https://arxiv.org/abs/2602.05202)
*Shivanshu Shekhar,Uttaran Bhattacharya,Raghavendra Addanki,Mehrab Tanjim,Somdeb Sarkhel,Tong Zhang*

Main category: cs.CV

TL;DR: 提出Generative-Transformer-based Self-Supervised Video Judge (GTSVJ)，将视频生成模型重新用作奖励模型，通过对比学习使其能够精确评估视频质量，仅需3万个人工标注即可在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型(VLMs)的视频奖励建模方法难以捕捉细微的时间动态，需要大量人工标注数据。视频生成模型天生具备建模时间结构的能力，但尚未被用于奖励建模。

Method: 将视频生成模型重新构建为基于能量的模型(EBMs)，通过对比学习训练使其为高质量视频分配低能量、低质量视频分配高能量。设计三种潜在空间扰动方法生成合成负样本：时间切片、特征交换和帧重排，迫使模型学习有意义的时空特征而非表面差异。

Result: 在GenAI-Bench和MonteBench上达到最先进性能，仅使用3万个人工标注，比现有VLM方法少6-65倍数据量。

Conclusion: 视频生成模型可以有效地重新用作时间感知的奖励模型，通过对比学习和精心设计的负样本生成，能够以极少的人工标注实现卓越的视频质量评估性能。

Abstract: Aligning video generative models with human preferences remains challenging: current approaches rely on Vision-Language Models (VLMs) for reward modeling, but these models struggle to capture subtle temporal dynamics. We propose a fundamentally different approach: repurposing video generative models, which are inherently designed to model temporal structure, as reward models. We present the Generative-Transformer-based Self-Supervised Video Judge (\modelname), a novel evaluation model that transforms state-of-the-art video generation models into powerful temporally-aware reward models. Our key insight is that generative models can be reformulated as energy-based models (EBMs) that assign low energy to high-quality videos and high energy to degraded ones, enabling them to discriminate video quality with remarkable precision when trained via contrastive objectives. To prevent the model from exploiting superficial differences between real and generated videos, we design challenging synthetic negative videos through controlled latent-space perturbations: temporal slicing, feature swapping, and frame shuffling, which simulate realistic but subtle visual degradations. This forces the model to learn meaningful spatiotemporal features rather than trivial artifacts. \modelname achieves state-of-the-art performance on GenAI-Bench and MonteBench using only 30K human-annotations: $6\times$ to $65\times$ fewer than existing VLM-based approaches.

</details>


### [3] [E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching](https://arxiv.org/abs/2602.05215)
*Jiahao Nie,Wenbin An,Gongjie Zhang,Yicheng Xu,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: E.M.Ground：一种用于时序视频定位的新型视频大语言模型，通过事件令牌、平滑技术和多粒度特征聚合来提升事件感知的完整性和连续性。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在时序视频定位任务中主要依赖精确时间戳匹配起始和结束帧，但这种方法无法捕捉事件的语义连续性和完整性，导致定位模糊。

Method: 提出E.M.Ground模型，包含三个关键创新：1) 特殊<event>令牌聚合查询事件所有帧的信息；2) Savitzky-Golay平滑减少时间戳间令牌-帧相似度的噪声；3) 多粒度帧特征聚合增强匹配可靠性和时序理解。

Result: 在基准数据集上的大量实验表明，E.M.Ground始终显著优于最先进的视频大语言模型。

Conclusion: E.M.Ground通过关注整体和连贯的事件感知，有效解决了时序视频定位中的语义连续性问题，实现了更准确的事件匹配。

Abstract: Despite recent advances in Video Large Language Models (Vid-LLMs), Temporal Video Grounding (TVG), which aims to precisely localize time segments corresponding to query events, remains a significant challenge. Existing methods often match start and end frames by comparing frame features with two separate tokens, relying heavily on exact timestamps. However, this approach fails to capture the event's semantic continuity and integrity, leading to ambiguities. To address this, we propose E.M.Ground, a novel Vid-LLM for TVG that focuses on holistic and coherent event perception. E.M.Ground introduces three key innovations: (i) a special <event> token that aggregates information from all frames of a query event, preserving semantic continuity for accurate event matching; (ii) Savitzky-Golay smoothing to reduce noise in token-to-frame similarities across timestamps, improving prediction accuracy; (iii) multi-grained frame feature aggregation to enhance matching reliability and temporal understanding, compensating for compression-induced information loss. Extensive experiments on benchmark datasets show that E.M.Ground consistently outperforms state-of-the-art Vid-LLMs by significant margins.

</details>


### [4] [SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback](https://arxiv.org/abs/2602.05380)
*Xiaoxuan He,Siming Fu,Wanli Li,Zhiyuan Li,Dacheng Yin,Kang Rong,Fengyun Rao,Bo Zhang*

Main category: cs.CV

TL;DR: SAIL是一个自增强迭代学习框架，仅需少量人工标注偏好对，通过扩散模型自我生成样本、自我标注偏好、自我优化的闭环方式实现对齐，无需外部奖励模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型与人类偏好对齐面临挑战：奖励模型难以获取，大规模偏好数据集收集成本高昂。核心问题是能否仅用少量人工反馈，不依赖外部奖励模型，通过挖掘扩散模型自身潜力实现有效对齐。

Method: 提出SAIL框架：从少量人工标注偏好对开始，采用闭环迭代学习。模型逐步生成多样样本，基于自身演化理解自我标注偏好，利用自增强数据集进行优化。引入排序偏好混合策略，平衡探索与初始人类先验，防止灾难性遗忘。

Result: SAIL在多个基准测试中持续优于最先进方法，仅需现有方法6%的偏好数据。实验表明扩散模型具有显著的自增强能力，当被恰当利用时，可以有效替代大规模人工标注和外部奖励模型。

Conclusion: 扩散模型拥有强大的自我改进能力，通过SAIL框架可以仅用少量人工反馈实现有效对齐，无需外部奖励模型，为扩散模型对齐提供了高效且可扩展的解决方案。

Abstract: Aligning diffusion models with human preferences remains challenging, particularly when reward models are unavailable or impractical to obtain, and collecting large-scale preference datasets is prohibitively expensive. \textit{This raises a fundamental question: can we achieve effective alignment using only minimal human feedback, without auxiliary reward models, by unlocking the latent capabilities within diffusion models themselves?} In this paper, we propose \textbf{SAIL} (\textbf{S}elf-\textbf{A}mplified \textbf{I}terative \textbf{L}earning), a novel framework that enables diffusion models to act as their own teachers through iterative self-improvement. Starting from a minimal seed set of human-annotated preference pairs, SAIL operates in a closed-loop manner where the model progressively generates diverse samples, self-annotates preferences based on its evolving understanding, and refines itself using this self-augmented dataset. To ensure robust learning and prevent catastrophic forgetting, we introduce a ranked preference mixup strategy that carefully balances exploration with adherence to initial human priors. Extensive experiments demonstrate that SAIL consistently outperforms state-of-the-art methods across multiple benchmarks while using merely 6\% of the preference data required by existing approaches, revealing that diffusion models possess remarkable self-improvement capabilities that, when properly harnessed, can effectively replace both large-scale human annotation and external reward models.

</details>


### [5] [TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions](https://arxiv.org/abs/2602.05414)
*Ngoc Doan-Minh Huynh,Duong Nguyen-Ngoc Tran,Long Hoang Pham,Tai Huu-Phuong Tran,Hyung-Joon Jeon,Huy-Hung Nguyen,Duong Khac Vu,Hyung-Min Jeon,Son Hong Phan,Quoc Pham-Nam Ho,Chi Dai Tran,Trinh Le Ba Khanh,Jae Wook Jeon*

Main category: cs.CV

TL;DR: 该研究提出了TSBOW数据集，这是一个针对极端天气条件下交通监控中遮挡车辆检测的综合性基准数据集，包含超过32小时的真实交通数据和数百万标注帧。


<details>
  <summary>Details</summary>
Motivation: 全球变暖加剧了极端天气事件的频率和严重性，这会降低CCTV信号和视频质量，同时扰乱交通流，从而增加交通事故率。现有数据集通常仅限于轻度雾霾、雨雪等条件，无法捕捉极端天气情况。

Method: 研究引入了TSBOW（Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions）数据集，包含超过32小时来自人口密集城市地区的真实交通数据，包含48,000多个人工标注帧和320万半标注帧，涵盖8种交通参与者类别。

Result: 建立了TSBOW的目标检测基准，突出了遮挡和恶劣天气带来的挑战。数据集包含多样化的道路类型、尺度和视角，为智能交通系统的发展提供了关键资源。

Conclusion: TSBOW数据集公开可用，强调了基于CCTV的交通监控潜力，为新的研究和应用铺平了道路。

Abstract: Global warming has intensified the frequency and severity of extreme weather events, which degrade CCTV signal and video quality while disrupting traffic flow, thereby increasing traffic accident rates. Existing datasets, often limited to light haze, rain, and snow, fail to capture extreme weather conditions. To address this gap, this study introduces the Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions (TSBOW), a comprehensive dataset designed to enhance occluded vehicle detection across diverse annual weather scenarios. Comprising over 32 hours of real-world traffic data from densely populated urban areas, TSBOW includes more than 48,000 manually annotated and 3.2 million semi-labeled frames; bounding boxes spanning eight traffic participant classes from large vehicles to micromobility devices and pedestrians. We establish an object detection benchmark for TSBOW, highlighting challenges posed by occlusions and adverse weather. With its varied road types, scales, and viewpoints, TSBOW serves as a critical resource for advancing Intelligent Transportation Systems. Our findings underscore the potential of CCTV-based traffic monitoring, pave the way for new research and applications. The TSBOW dataset is publicly available at: https://github.com/SKKUAutoLab/TSBOW.

</details>


### [6] [NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks](https://arxiv.org/abs/2602.05423)
*Pengcheng Chen,Yue Hu,Wenhao Li,Nicole M Gunderson,Andrew Feng,Zhenglong Sun,Peter Beerel,Eric J Seibel*

Main category: cs.CV

TL;DR: NeVStereo：一个结合NeRF渲染与立体视觉的联合框架，能够从多视角RGB输入中同时估计相机位姿、多视角深度、新视角合成和表面重建，在多个基准测试中实现零样本的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：前馈系统（如VGGT、pi3）专注于端到端匹配和几何预测但不输出新视角合成；基于神经渲染的方法（如NeRF）能提供高质量渲染和详细几何，但通常假设固定相机位姿且对位姿误差敏感。因此，需要一个统一框架从随意拍摄的视图中同时获得准确位姿、可靠深度、高质量渲染和精确3D表面。

Method: NeVStereo结合了NeRF驱动的新视角合成和立体视觉架构：1）使用NeRF-based NVS生成适合立体匹配的渲染；2）置信度引导的多视角深度估计；3）NeRF耦合的束调整进行位姿优化；4）迭代优化阶段同时更新深度和辐射场以提高几何一致性。该设计缓解了NeRF常见问题如表面堆叠、伪影和位姿-深度耦合。

Result: 在室内、室外、桌面和航空基准测试中，NeVStereo实现了持续强大的零样本性能：深度误差降低达36%，位姿精度提升10.4%，NVS保真度提高4.5%，网格质量达到SOTA（F1 91.93%，Chamfer 4.35 mm）。

Conclusion: NeVStereo成功地将NeRF渲染与立体视觉相结合，提供了一个统一的框架，能够从多视角RGB输入中联合输出相机位姿、多视角深度、新视角合成和表面重建，解决了现有方法的局限性，并在多个任务上实现了显著的性能提升。

Abstract: In modern dense 3D reconstruction, feed-forward systems (e.g., VGGT, pi3) focus on end-to-end matching and geometry prediction but do not explicitly output the novel view synthesis (NVS). Neural rendering-based approaches offer high-fidelity NVS and detailed geometry from posed images, yet they typically assume fixed camera poses and can be sensitive to pose errors. As a result, it remains non-trivial to obtain a single framework that can offer accurate poses, reliable depth, high-quality rendering, and accurate 3D surfaces from casually captured views. We present NeVStereo, a NeRF-driven NVS-stereo architecture that aims to jointly deliver camera poses, multi-view depth, novel view synthesis, and surface reconstruction from multi-view RGB-only inputs. NeVStereo combines NeRF-based NVS for stereo-friendly renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and an iterative refinement stage that updates both depth and the radiance field to improve geometric consistency. This design mitigated the common NeRF-based issues such as surface stacking, artifacts, and pose-depth coupling. Across indoor, outdoor, tabletop, and aerial benchmarks, our experiments indicate that NeVStereo achieves consistently strong zero-shot performance, with up to 36% lower depth error, 10.4% improved pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm) compared to existing prestigious methods.

</details>


### [7] [Stable Velocity: A Variance Perspective on Flow Matching](https://arxiv.org/abs/2602.05435)
*Donglin Yang,Yongxing Zhang,Xin Yu,Liang Hou,Xin Tao,Pengfei Wan,Xiaojuan Qi,Renjie Liao*

Main category: cs.CV

TL;DR: 提出Stable Velocity框架，通过方差分析改进流匹配训练和采样，在低方差区域实现2倍以上加速且不损失质量


<details>
  <summary>Details</summary>
Motivation: 传统流匹配依赖单样本条件速度，导致高方差训练目标，使优化不稳定且收敛缓慢。需要解决这一方差问题来改进训练效率和采样速度。

Method: 1) 分析条件速度方差，识别高方差（先验附近）和低方差（数据分布附近）区域；2) 提出Stable Velocity Matching (StableVM)无偏方差减少目标；3) 提出Variance-Aware Representation Alignment (VA-REPA)在低方差区域自适应增强辅助监督；4) 提出Stable Velocity Sampling (StableVS)利用低方差区域闭式简化实现免微调加速

Result: 在ImageNet 256×256和大规模预训练文本到图像/视频模型（SD3.5、Flux、Qwen-Image、Wan2.2）上验证，训练效率提升，低方差区域采样速度提高2倍以上且不降低样本质量

Conclusion: 通过方差分析提出的Stable Velocity框架有效解决了流匹配的方差问题，在训练和采样方面均取得显著改进，为生成模型提供了更稳定高效的解决方案

Abstract: While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.

</details>


### [8] [Attention Retention for Continual Learning with Vision Transformers](https://arxiv.org/abs/2602.05454)
*Yue Lu,Xiangyu Zhou,Shizhou Zhang,Yinghui Xing,Guoqiang Liang,Wencong Zhang*

Main category: cs.CV

TL;DR: 提出基于注意力保持的持续学习方法，通过梯度掩码防止Vision Transformer中的注意力漂移，缓解灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 持续学习中灾难性遗忘是核心挑战，研究发现Vision Transformer中的注意力漂移是导致遗忘的主要原因，受人类视觉系统选择性注意力机制启发，需要防止注意力从已学概念漂移

Method: 提出注意力保持框架：1）使用层间rollout机制提取前一任务的注意力图，生成实例自适应二进制掩码；2）学习新任务时，应用掩码将前一任务注意力区域的梯度置零，防止已学视觉概念被破坏；为兼容现代优化器，通过按比例缩放参数更新来保持相对幅度

Result: 实验和可视化证明该方法能有效缓解灾难性遗忘并保持视觉概念，在多种持续学习场景中达到最先进性能并展现鲁棒泛化能力

Conclusion: 注意力漂移是Vision Transformer中灾难性遗忘的关键因素，提出的注意力保持框架通过梯度掩码机制成功缓解了这一问题，为持续学习提供了有效的解决方案

Abstract: Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the attention to previously learned visual concepts shifts significantly after learning new tasks. Inspired by neuroscientific insights into the selective attention in the human visual system, we propose a novel attention-retaining framework to mitigate forgetting in CL. Our method constrains attention drift by explicitly modifying gradients during backpropagation through a two-step process: 1) extracting attention maps of the previous task using a layer-wise rollout mechanism and generating instance-adaptive binary masks, and 2) when learning a new task, applying these masks to zero out gradients associated with previous attention regions, thereby preventing disruption of learned visual concepts. For compatibility with modern optimizers, the gradient masking process is further enhanced by scaling parameter updates proportionally to maintain their relative magnitudes. Experiments and visualizations demonstrate the effectiveness of our method in mitigating catastrophic forgetting and preserving visual concepts. It achieves state-of-the-art performance and exhibits robust generalizability across diverse CL scenarios.

</details>


### [9] [UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos](https://arxiv.org/abs/2602.05638)
*Jinlin Wu,Felix Holm,Chuxi Chen,An Wang,Yaxin Hu,Xiaofan Ye,Zelin Zang,Miao Xu,Lihua Zhou,Huai Liao,Danny T. M. Chan,Ming Feng,Wai S. Poon,Hongliang Ren,Dong Yi,Nassir Navab,Gaofeng Meng,Jiebo Luo,Hongbin Liu,Zhen Lei*

Main category: cs.CV

TL;DR: UniSurg是一个基于视频原生架构的手术视频基础模型，通过从像素级重建转向潜在运动预测，专注于语义结构而非低层次视觉细节，在多个手术视频分析任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于基础模型的手术视频分析方法主要依赖像素级重建目标，浪费模型容量在烟雾、镜面反射、流体运动等低层次视觉细节上，而不是关注对手术理解至关重要的语义结构。

Method: 基于视频联合嵌入预测架构(V-JEPA)，提出三个关键技术创新：1)运动引导的潜在预测以优先考虑语义重要区域；2)时空亲和性自蒸馏以强制关系一致性；3)特征多样性正则化以防止纹理稀疏手术场景中的表示崩溃。使用UniSurg-15M数据集进行大规模预训练。

Result: 在17个基准测试中显著优于最先进方法：手术工作流识别（EgoSurgery上F1提升14.6%，PitVis上提升10.3%）、动作三元组识别（CholecT50上39.54% mAP-IVT）、技能评估、息肉分割和深度估计。

Conclusion: UniSurg通过从像素级重建转向运动预测的学习范式转变，建立了通用、运动导向的手术视频理解新标准，专注于语义结构而非低层次视觉细节。

Abstract: While foundation models have advanced surgical video analysis, current approaches rely predominantly on pixel-level reconstruction objectives that waste model capacity on low-level visual details - such as smoke, specular reflections, and fluid motion - rather than semantic structures essential for surgical understanding. We present UniSurg, a video-native foundation model that shifts the learning paradigm from pixel-level reconstruction to latent motion prediction. Built on the Video Joint Embedding Predictive Architecture (V-JEPA), UniSurg introduces three key technical innovations tailored to surgical videos: 1) motion-guided latent prediction to prioritize semantically meaningful regions, 2) spatiotemporal affinity self-distillation to enforce relational consistency, and 3) feature diversity regularization to prevent representation collapse in texture-sparse surgical scenes. To enable large-scale pretraining, we curate UniSurg-15M, the largest surgical video dataset to date, comprising 3,658 hours of video from 50 sources across 13 anatomical regions. Extensive experiments across 17 benchmarks demonstrate that UniSurg significantly outperforms state-of-the-art methods on surgical workflow recognition (+14.6% F1 on EgoSurgery, +10.3% on PitVis), action triplet recognition (39.54% mAP-IVT on CholecT50), skill assessment, polyp segmentation, and depth estimation. These results establish UniSurg as a new standard for universal, motion-oriented surgical video understanding.

</details>


### [10] [Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing](https://arxiv.org/abs/2602.05737)
*Luca Ciampi,Ludovico Iannello,Fabrizio Tonelli,Gabriele Lagani,Angelo Di Garbo,Federico Cremisi,Giuseppe Amato*

Main category: cs.CV

TL;DR: 利用体外培养的皮层神经元网络作为物理储层，构建生物储层计算系统，通过高密度微电极阵列进行刺激和读取，实现静态视觉模式识别任务。


<details>
  <summary>Details</summary>
Motivation: 传统储层计算依赖人工循环模型近似神经动力学，本研究旨在利用真实生物神经回路作为计算基底，将生物原理融入机器学习，为神经形态计算开辟新途径。

Method: 使用体外培养的皮层神经元网络作为物理储层，通过高密度微电极阵列同时进行刺激和读取，输入模式通过选定电极传递，其余电极捕获高维神经响应，最后用线性读出层（单层感知器）对储层状态进行分类。

Result: 系统在从点到定向条、时钟数字形状到MNIST手写数字等难度递增的任务中表现稳定，尽管存在生物神经响应的固有变异性，但仍能生成支持准确分类的高维表示。

Conclusion: 体外皮层网络可作为静态视觉模式识别的有效储层，为将活体神经基底整合到神经形态计算框架开辟新途径，展示了生物神经系统如何为高效且生物学基础的计算模型设计提供参考。

Abstract: In this paper, we present a neuro-inspired approach to reservoir computing (RC) in which a network of in vitro cultured cortical neurons serves as the physical reservoir. Rather than relying on artificial recurrent models to approximate neural dynamics, our biological reservoir computing (BRC) system leverages the spontaneous and stimulus-evoked activity of living neural circuits as its computational substrate. A high-density multi-electrode array (HD-MEA) provides simultaneous stimulation and readout across hundreds of channels: input patterns are delivered through selected electrodes, while the remaining ones capture the resulting high-dimensional neural responses, yielding a biologically grounded feature representation. A linear readout layer (single-layer perceptron) is then trained to classify these reservoir states, enabling the living neural network to perform static visual pattern-recognition tasks within a computer-vision framework. We evaluate the system across a sequence of tasks of increasing difficulty, ranging from pointwise stimuli to oriented bars, clock-digit-like shapes, and handwritten digits from the MNIST dataset. Despite the inherent variability of biological neural responses-arising from noise, spontaneous activity, and inter-session differences-the system consistently generates high-dimensional representations that support accurate classification. These results demonstrate that in vitro cortical networks can function as effective reservoirs for static visual pattern recognition, opening new avenues for integrating living neural substrates into neuromorphic computing frameworks. More broadly, this work contributes to the effort to incorporate biological principles into machine learning and supports the goals of neuro-inspired vision by illustrating how living neural systems can inform the design of efficient and biologically grounded computational models.

</details>


### [11] [EoCD: Encoder only Remote Sensing Change Detection](https://arxiv.org/abs/2602.05882)
*Mubashir Noman,Mustansar Fiaz,Hiyam Debary,Abdul Hannan,Shah Nawaz,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 提出EoCD方法，仅使用编码器进行变化检测，通过早期融合时间数据并用参数免费的多尺度特征融合模块替代解码器，显著降低模型复杂度，在性能和速度间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有变化检测方法存在两个主要问题：1）基于孪生编码器的方法需要分别提取时间特征再进行融合，计算成本高且模型复杂；2）早期融合方法虽然避免了孪生编码器的开销，但仍依赖复杂的解码器，且性能不如后期融合方法。需要一种既简单又有效的方法来平衡性能和计算效率。

Method: 提出编码器仅变化检测（EoCD）方法：1）对时间数据进行早期融合；2）用参数免费的多尺度特征融合模块替代传统解码器；3）证明模型性能主要取决于编码器网络，解码器只是额外组件。

Result: 在四个具有挑战性的变化检测数据集上进行广泛实验，EoCD方法在各种编码器架构下都表现出变化检测性能和预测速度之间的最佳平衡，同时显著降低了模型整体复杂度。

Conclusion: EoCD是一种简单有效的遥感变化检测方法，通过早期融合和参数免费特征融合模块，在保持高性能的同时大幅降低模型复杂度，证明了编码器在变化检测中的主导作用。

Abstract: Being a cornerstone of temporal analysis, change detection has been playing a pivotal role in modern earth observation. Existing change detection methods rely on the Siamese encoder to individually extract temporal features followed by temporal fusion. Subsequently, these methods design sophisticated decoders to improve the change detection performance without taking into consideration the complexity of the model. These aforementioned issues intensify the overall computational cost as well as the network's complexity which is undesirable. Alternatively, few methods utilize the early fusion scheme to combine the temporal images. These methods prevent the extra overhead of Siamese encoder, however, they also rely on sophisticated decoders for better performance. In addition, these methods demonstrate inferior performance as compared to late fusion based methods. To bridge these gaps, we introduce encoder only change detection (EoCD) that is a simple and effective method for the change detection task. The proposed method performs the early fusion of the temporal data and replaces the decoder with a parameter-free multiscale feature fusion module thereby significantly reducing the overall complexity of the model. EoCD demonstrate the optimal balance between the change detection performance and the prediction speed across a variety of encoder architectures. Additionally, EoCD demonstrate that the performance of the model is predominantly dependent on the encoder network, making the decoder an additional component. Extensive experimentation on four challenging change detection datasets reveals the effectiveness of the proposed method.

</details>


### [12] [Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028)
*Shuo Chen,Cong Wei,Sun Sun,Ping Nie,Kai Zhou,Ge Zhang,Ming-Hsuan Yang,Wenhu Chen*

Main category: cs.CV

TL;DR: 提出Context Forcing框架，通过长上下文教师训练长上下文学生，解决现有流式调优中的师生不匹配问题，实现超过20秒的有效上下文长度


<details>
  <summary>Details</summary>
Motivation: 现有实时长视频生成方法采用流式调优策略，使用短上下文（无记忆）教师训练长上下文学生。这种结构差异导致师生不匹配：教师无法访问长期历史，无法指导学生处理全局时间依赖，限制了学生的上下文长度

Method: 提出Context Forcing框架，通过长上下文教师训练长上下文学生，消除监督不匹配。为实现极端时长（如2分钟）的计算可行性，引入上下文管理系统，将线性增长的上下文转换为慢-快记忆架构，显著减少视觉冗余

Result: 方法实现超过20秒的有效上下文长度，比LongLive和Infinite-RoPE等最先进方法长2-10倍。利用扩展的上下文，Context Forcing在长时段内保持优越的一致性，在各种长视频评估指标上超越最先进基线

Conclusion: Context Forcing通过解决师生不匹配问题，实现了长上下文视频生成，显著提升了长视频的时序一致性，为实时长视频生成提供了有效解决方案

Abstract: Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Multi-Aspect Mining and Anomaly Detection for Heterogeneous Tensor Streams](https://arxiv.org/abs/2602.04917)
*Soshi Kakio,Yasuko Matsubara,Ren Fujiwara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: HeteroComp：一种处理异构张量流（包含分类和连续属性）的组件提取和群体异常检测方法，使用高斯过程先验建模连续属性分布和时间动态。


<details>
  <summary>Details</summary>
Motivation: 现有张量分解和异常检测方法无法处理包含分类属性（如IP地址）和连续属性（如数据包长度）的异构张量流，且通常需要离散化时间戳，无法捕捉流的时间动态，导致群体异常检测效果不佳。

Method: 提出HeteroComp方法，将异构张量流连续总结为表示各属性中潜在群体及其时间动态的"组件"。使用高斯过程先验建模连续属性的未知分布和时间动态，直接从数据估计概率密度。

Result: 在真实数据集上的广泛实验表明，HeteroComp在群体异常检测准确率上优于现有最先进算法，且计算时间不依赖于数据流长度。

Conclusion: HeteroComp能够有效处理异构张量流，准确检测群体异常，为包含分类和连续属性的时间序列数据提供了一种有效的分析和异常检测方法。

Abstract: Analysis and anomaly detection in event tensor streams consisting of timestamps and multiple attributes - such as communication logs(time, IP address, packet length)- are essential tasks in data mining. While existing tensor decomposition and anomaly detection methods provide useful insights, they face the following two limitations. (i) They cannot handle heterogeneous tensor streams, which comprises both categorical attributes(e.g., IP address) and continuous attributes(e.g., packet length). They typically require either discretizing continuous attributes or treating categorical attributes as continuous, both of which distort the underlying statistical properties of the data.Furthermore, incorrect assumptions about the distribution family of continuous attributes often degrade the model's performance. (ii) They discretize timestamps, failing to track the temporal dynamics of streams(e.g., trends, abnormal events), which makes them ineffective for detecting anomalies at the group level, referred to as 'group anomalies' (e.g, DoS attacks). To address these challenges, we propose HeteroComp, a method for continuously summarizing heterogeneous tensor streams into 'components' representing latent groups in each attribute and their temporal dynamics, and detecting group anomalies. Our method employs Gaussian process priors to model unknown distributions of continuous attributes, and temporal dynamics, which directly estimate probability densities from data. Extracted components give concise but effective summarization, enabling accurate group anomaly detection. Extensive experiments on real datasets demonstrate that HeteroComp outperforms the state-of-the-art algorithms for group anomaly detection accuracy, and its computational time does not depend on the data stream length.

</details>


### [14] [ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation](https://arxiv.org/abs/2602.05051)
*Songyuan Zhang,Oswin So,H. M. Sabbir Ahmad,Eric Yang Yu,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: ReFORM是一种基于流策略的离线强化学习方法，通过构造强制执行支持约束来避免分布外错误，同时在OGBench基准测试中优于所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中存在两个主要挑战：1）分布外错误问题，传统方法通过惩罚统计距离项来约束策略接近行为策略，但这限制了策略改进且不能完全防止OOD动作；2）最优策略分布可能是多模态且难以表示的，现有扩散或流策略方法不清楚如何在保持策略表达能力的同时避免OOD错误。

Method: ReFORM基于流策略，通过构造强制执行支持约束。首先学习一个有界源分布的行为克隆流策略来捕获动作分布的支持，然后优化一个反射流，该流为BC流生成有界噪声同时保持支持，以最大化性能。

Result: 在OGBench基准测试的40个具有不同质量数据集的挑战性任务中，使用恒定超参数集的ReFORM在性能曲线图上优于所有手动调优超参数的基线方法。

Conclusion: ReFORM通过流策略的构造方式有效解决了离线RL中的OOD错误问题，同时保持了策略的表达能力，在多个任务中展现出优越性能。

Abstract: Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed dataset generated by behavior policies without additional environment interactions. One common challenge that arises in this setting is the out-of-distribution (OOD) error, which occurs when the policy leaves the training distribution. Prior methods penalize a statistical distance term to keep the policy close to the behavior policy, but this constrains policy improvement and may not completely prevent OOD actions. Another challenge is that the optimal policy distribution can be multimodal and difficult to represent. Recent works apply diffusion or flow policies to address this problem, but it is unclear how to avoid OOD errors while retaining policy expressiveness. We propose ReFORM, an offline RL method based on flow policies that enforces the less restrictive support constraint by construction. ReFORM learns a behavior cloning (BC) flow policy with a bounded source distribution to capture the support of the action distribution, then optimizes a reflected flow that generates bounded noise for the BC flow while keeping the support, to maximize the performance. Across 40 challenging tasks from the OGBench benchmark with datasets of varying quality and using a constant set of hyperparameters for all tasks, ReFORM dominates all baselines with hand-tuned hyperparameters on the performance profile curves.

</details>


### [15] [Constrained Group Relative Policy Optimization](https://arxiv.org/abs/2602.05863)
*Roger Girgis,Rodrigue de Schaetzen,Luke Rowe,Azalée Robitaille,Christopher Pal,Liam Paull*

Main category: cs.LG

TL;DR: 论文提出了Constrained GRPO，一种基于拉格朗日方法的约束策略优化框架，解决了多组件优势估计中的优化问题，通过标量化优势构造恢复约束控制。


<details>
  <summary>Details</summary>
Motivation: 虽然GRPO已成为无评论者策略学习的可扩展框架，但在具有显式行为约束的设置中扩展仍未被充分探索。需要一种能够处理约束的策略优化方法，特别是在机器人任务和依赖大型多模态基础模型的具身AI领域。

Method: 提出Constrained GRPO，基于拉格朗日松弛的GRPO扩展。使用指示器成本函数指定约束，通过拉格朗日松弛直接优化违反率。发现多组件优势估计会破坏约束学习，因此提出标量化优势构造来保持奖励和约束项之间的预期权衡。

Result: 在玩具网格世界实验中证实了预测的优化病理问题，并证明标量化优势能够恢复稳定的约束控制。在机器人任务评估中，Constrained GRPO提高了约束满足度同时增加了任务成功率。

Conclusion: Constrained GRPO为具身AI领域的约束策略优化提供了一个简单有效的方案，特别是在日益依赖大型多模态基础模型的场景中，能够同时改善约束满足和任务性能。

Abstract: While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.

</details>


### [16] [StagePilot: A Deep Reinforcement Learning Agent for Stage-Controlled Cybergrooming Simulation](https://arxiv.org/abs/2602.05060)
*Heajun An,Qi Zhang,Minqian Liu,Xinyi Zhang,Sang Won Lee,Lifu Huang,Pamela J. Wisniewski,Jin-Hee Cho*

Main category: cs.LG

TL;DR: StagePilot是一个基于离线强化学习的对话代理，用于模拟网络诱骗的阶段进展，通过平衡用户情感和目标接近度的复合奖励选择对话阶段，在LLM模拟中表现出色。


<details>
  <summary>Details</summary>
Motivation: 网络诱骗是对青少年的持续威胁，需要主动的教育干预措施来预防。现有方法缺乏对诱骗行为阶段进展的模拟，难以提供有效的预防训练。

Method: 提出StagePilot离线RL对话代理，使用复合奖励平衡用户情感和目标接近度来选择对话阶段，阶段转换限制在相邻阶段以确保真实性和可解释性。通过LLM模拟评估对话质量。

Result: StagePilot能生成真实且连贯的对话，与诱骗动态保持一致。在测试方法中，IQL+AWAC代理在战略规划和情感连贯性之间达到最佳平衡，最终阶段到达频率比基线高43%，同时保持超过70%的情感对齐。

Conclusion: StagePilot为网络诱骗预防训练提供了有效的对话模拟工具，能够生成符合诱骗阶段进展的真实对话，在战略规划和情感连贯性方面表现出色。

Abstract: Cybergrooming is an evolving threat to youth, necessitating proactive educational interventions. We propose StagePilot, an offline RL-based dialogue agent that simulates the stage-wise progression of grooming behaviors for prevention training. StagePilot selects conversational stages using a composite reward that balances user sentiment and goal proximity, with transitions constrained to adjacent stages for realism and interpretability. We evaluate StagePilot through LLM-based simulations, measuring stage completion, dialogue efficiency, and emotional engagement. Results show that StagePilot generates realistic and coherent conversations aligned with grooming dynamics. Among tested methods, the IQL+AWAC agent achieves the best balance between strategic planning and emotional coherence, reaching the final stage up to 43% more frequently than baselines while maintaining over 70% sentiment alignment.

</details>


### [17] [Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks](https://arxiv.org/abs/2602.05125)
*William F. Shen,Xinchi Qiu,Chenxi Whitehouse,Lisa Alazraki,Shashwat Goel,Francesco Barbieri,Timon Willi,Akhil Mathur,Ilias Leontiadis*

Main category: cs.LG

TL;DR: 提出RRD框架，通过递归分解-过滤循环优化评分标准，提升LLM评估准确性和强化学习奖励信号


<details>
  <summary>Details</summary>
Motivation: 现有评分标准生成方法难以控制，存在覆盖不全、维度混淆、偏好方向错位、冗余和高度相关标准等问题，导致评估准确性下降和强化学习训练效果不佳

Method: 提出RRD框架，采用递归分解-过滤循环：1) 将粗粒度评分标准分解为细粒度、可区分的标准；2) 过滤机制移除错位和冗余标准；3) 相关性感知加权方案防止高度相关标准过度表示

Result: 在评估方面：在JudgeBench和PPE上显著提升GPT-4o和Llama3.1-405B的偏好判断准确性，在JudgeBench上最高提升17.7分；在训练方面：作为WildChat上RFT的奖励源，Qwen3-4B奖励提升160%，Llama3.1-8B提升60%，远优于基线方法，且能迁移到其他基准

Conclusion: RRD建立了可扩展、可解释的递归评分标准优化基础，为开放领域LLM评估和奖励建模提供了有效解决方案

Abstract: Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.

</details>


### [18] [Cross-talk based multi-task learning for fault classification of physically coupled machine system](https://arxiv.org/abs/2602.05146)
*Wonjun Yi,Rismaya Kumar Mishra,Yong-Hwa Park*

Main category: cs.LG

TL;DR: 该论文提出了一种基于交叉对话结构的多任务学习框架，通过联合学习故障条件和相关物理变量来提升故障分类性能，在两个基准数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器系统产生的信号中，故障条件与各种物理变量之间存在物理耦合。现有故障分类研究大多只依赖直接故障标签，忽略了信号中自然嵌入的其他物理耦合信息。利用这种耦合关系可以提升故障分类性能。

Method: 采用多任务学习框架，特别是交叉对话结构，在之前提出的残差神经降维模型基础上扩展应用。交叉对话结构允许任务间通过交叉对话层进行受控信息交换，同时防止负迁移。在两个基准数据集（无人机故障数据集和电机复合故障数据集）上进行测试。

Result: 在两个基准数据集上，残差神经降维模型始终优于单任务模型、合并所有标签组合的多类模型以及共享主干多任务模型。交叉对话架构通过同时学习故障分类和物理属性，能够更好地分类故障。

Conclusion: 利用信号中自然存在的物理耦合信息，通过交叉对话多任务学习框架可以有效提升故障分类性能。该方法在无人机故障和电机复合故障两个基准数据集上都取得了优于现有方法的性能。

Abstract: Machine systems inherently generate signals in which fault conditions and various physical variables are physically coupled. Although many existing fault classification studies rely solely on direct fault labels, the aforementioned signals naturally embed additional information shaped by other physically coupled information. Herein, we leverage this coupling through a multi-task learning (MTL) framework that jointly learns fault conditions and the related physical variables. Among MTL architectures, crosstalk structures have distinct advantages because they allow for controlled information exchange between tasks through the cross-talk layer while preventing negative transfer, in contrast to shared trunk architectures that often mix incompatible features. We build on our previously introduced residual neural dimension reductor model, and extend its application to two benchmarks where physical coupling is prominent. The first benchmark is a drone fault dataset, in which machine type and maneuvering direction significantly alter the frequency components of measured signals even under the same nominal condition. By learning fault classification together with these physical attributes, the cross-talk architecture can better classify faults. The second benchmark dataset is the motor compound fault dataset. In this system, each fault component, inner race fault, outer race fault, misalignment, and unbalance is coupled to the other. For motor compound fault, we also test classification performance when we use single-channel data or multi-channel data as input to the classifier. Across both benchmarks, our residual neural dimension reductor, consistently outperformed single-task models, multi-class models that merge all label combinations, and shared trunk multi-task models.

</details>


### [19] [Extreme Weather Nowcasting via Local Precipitation Pattern Prediction](https://arxiv.org/abs/2602.05204)
*Changhoon Song,Teng Yuan Chang,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出exPreCast框架和平衡雷达数据集，用于高效生成精细的雷达预报，在普通和极端降雨情况下均实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 极端天气准确预报对风险管理至关重要，现有方法存在缺陷：扩散模型计算昂贵不适合实时应用，确定性模型偏向普通降雨，现有数据集不平衡限制了实际应用

Method: 提出exPreCast确定性框架，集成局部时空注意力、纹理保持立方双上采样解码器和时间提取器，可灵活调整预报时域；同时构建包含普通和极端降雨的平衡KMA雷达数据集

Result: 在SEVIR、MeteoNet和平衡KMA数据集上的实验表明，该方法在普通和极端降雨情况下均达到最先进性能，提供准确可靠的临近预报

Conclusion: exPreCast框架和平衡数据集解决了现有方法的局限性，为实际应用提供了高效准确的降雨临近预报解决方案

Abstract: Accurate forecasting of extreme weather events such as heavy rainfall or storms is critical for risk management and disaster mitigation. Although high-resolution radar observations have spurred extensive research on nowcasting models, precipitation nowcasting remains particularly challenging due to pronounced spatial locality, intricate fine-scale rainfall structures, and variability in forecasting horizons. While recent diffusion-based generative ensembles show promising results, they are computationally expensive and unsuitable for real-time applications. In contrast, deterministic models are computationally efficient but remain biased toward normal rainfall. Furthermore, the benchmark datasets commonly used in prior studies are themselves skewed--either dominated by ordinary rainfall events or restricted to extreme rainfall episodes--thereby hindering general applicability in real-world settings. In this paper, we propose exPreCast, an efficient deterministic framework for generating finely detailed radar forecasts, and introduce a newly constructed balanced radar dataset from the Korea Meteorological Administration (KMA), which encompasses both ordinary precipitation and extreme events. Our model integrates local spatiotemporal attention, a texture-preserving cubic dual upsampling decoder, and a temporal extractor to flexibly adjust forecasting horizons. Experiments on established benchmarks (SEVIR and MeteoNet) as well as on the balanced KMA dataset demonstrate that our approach achieves state-of-the-art performance, delivering accurate and reliable nowcasts across both normal and extreme rainfall regimes.

</details>


### [20] [Joint Embedding Variational Bayes](https://arxiv.org/abs/2602.05639)
*Amin Oji,Paul Fieguth*

Main category: cs.LG

TL;DR: VJE是一个结合联合嵌入和变分推断的自监督学习框架，用于学习概率表示，无需重建和非对比设置，在多个数据集上达到与非对比基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于能量的预测目标优化点间差异，而VJE旨在通过变分推断框架学习概率表示，避免重建和非对比设置中的不稳定性。

Method: VJE通过最大化对称条件证据下界(ELBO)来学习潜在变量模型，使用重尾Student-t分布建模条件似然，通过极坐标分解解耦方向和径向因子，采用摊销推断网络参数化对角高斯变分后验。

Result: 在ImageNet-1K、CIFAR-10/100和STL-10数据集上，VJE在线性和k-NN评估中达到与非对比基线相当的性能；在一类CIFAR-10异常检测中，基于似然的评分优于其他自监督基线。

Conclusion: VJE成功地将变分推断与联合嵌入结合，实现了重建自由、非对比的自监督概率表示学习，能够捕获各向异性不确定性，并在下游任务中表现出色。

Abstract: We introduce Variational Joint Embedding (VJE), a framework that synthesizes joint embedding and variational inference to enable self-supervised learning of probabilistic representations in a reconstruction-free, non-contrastive setting. Compared to energy-based predictive objectives that optimize pointwise discrepancies, VJE maximizes a symmetric conditional evidence lower bound (ELBO) for a latent-variable model defined directly on encoder embeddings. We instantiate the conditional likelihood with a heavy-tailed Student-$t$ model using a polar decomposition that explicitly decouples directional and radial factors to prevent norm-induced instabilities during training. VJE employs an amortized inference network to parameterize a diagonal Gaussian variational posterior whose feature-wise variances are shared with the likelihood scale to capture anisotropic uncertainty without auxiliary projection heads. Across ImageNet-1K, CIFAR-10/100, and STL-10, VJE achieves performance comparable to standard non-contrastive baselines under linear and k-NN evaluation. We further validate these probabilistic semantics through one-class CIFAR-10 anomaly detection, where likelihood-based scoring under the proposed model outperforms comparable self-supervised baselines.

</details>


### [21] [Accelerating Benchmarking of Functional Connectivity Modeling via Structure-aware Core-set Selection](https://arxiv.org/abs/2602.05667)
*Ling Zhan,Zhen Li,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: 提出SCLCS方法，通过选择代表性核心集来保留功能连接建模方法的相对性能排名，解决大规模fMRI数据集基准测试的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 大规模fMRI数据集中功能连接建模方法的基准测试对于可重复神经科学至关重要，但模型-数据配对的组合爆炸使得穷举评估计算上不可行，阻碍了这种评估成为常规预分析步骤。

Method: 提出结构感知对比学习的核心集选择框架：1) 使用自适应Transformer学习每个样本的独特功能连接结构；2) 引入结构扰动评分量化训练期间学习结构的稳定性；3) 采用密度平衡采样策略确保核心集的结构鲁棒性和分布代表性。

Result: 在REST-meta-MDD数据集上，SCLCS仅使用10%的数据就能保留真实模型排名，在排名一致性(nDCG@k)上比最先进的核心集选择方法高出23.2%。

Conclusion: 这是首个将核心集选择形式化用于功能连接算子基准测试的工作，使大规模算子比较成为计算神经科学中可行且不可或缺的部分。

Abstract: Benchmarking the hundreds of functional connectivity (FC) modeling methods on large-scale fMRI datasets is critical for reproducible neuroscience. However, the combinatorial explosion of model-data pairings makes exhaustive evaluation computationally prohibitive, preventing such assessments from becoming a routine pre-analysis step. To break this bottleneck, we reframe the challenge of FC benchmarking by selecting a small, representative core-set whose sole purpose is to preserve the relative performance ranking of FC operators. We formalize this as a ranking-preserving subset selection problem and propose Structure-aware Contrastive Learning for Core-set Selection (SCLCS), a self-supervised framework to select these core-sets. SCLCS first uses an adaptive Transformer to learn each sample's unique FC structure. It then introduces a novel Structural Perturbation Score (SPS) to quantify the stability of these learned structures during training, identifying samples that represent foundational connectivity archetypes. Finally, while SCLCS identifies stable samples via a top-k ranking, we further introduce a density-balanced sampling strategy as a necessary correction to promote diversity, ensuring the final core-set is both structurally robust and distributionally representative. On the large-scale REST-meta-MDD dataset, SCLCS preserves the ground-truth model ranking with just 10% of the data, outperforming state-of-the-art (SOTA) core-set selection methods by up to 23.2% in ranking consistency (nDCG@k). To our knowledge, this is the first work to formalize core-set selection for FC operator benchmarking, thereby making large-scale operators comparisons a feasible and integral part of computational neuroscience. Code is publicly available on https://github.com/lzhan94swu/SCLCS

</details>


### [22] [Distributional Reinforcement Learning with Diffusion Bridge Critics](https://arxiv.org/abs/2602.05783)
*Shutong Ding,Yimiao Zhou,Ke Hu,Mokai Pan,Shan Zhong,Yanwei Fu,Jingya Wang,Ye Shi*

Main category: cs.LG

TL;DR: 提出了一种基于扩散桥批评器的新型分布强化学习方法DBC，首次将扩散桥模型用作批评器，通过直接建模Q值的逆累积分布函数来准确捕捉价值分布。


<details>
  <summary>Details</summary>
Motivation: 现有扩散强化学习方法主要关注扩散策略，而忽略了扩散批评器。由于策略优化本质上依赖于批评器，准确的价值估计比策略表达能力更重要。此外，考虑到强化学习任务的随机性，批评器更适合用分布模型来描述。

Method: 提出扩散桥批评器(DBC)，直接建模Q值的逆累积分布函数，利用扩散桥的强大分布匹配能力防止价值分布坍缩为平凡高斯分布。进一步推导了处理DBC中离散化误差的解析积分公式。

Result: 在MuJoCo机器人控制基准测试中，DBC相比之前的分布批评器模型表现出优越性能。DBC是一个即插即用组件，可以集成到大多数现有RL框架中。

Conclusion: DBC是首个将扩散桥模型用作批评器的工作，通过准确捕捉价值分布提升了分布强化学习的性能，为扩散模型在强化学习中的更广泛应用提供了新思路。

Abstract: Recent advances in diffusion-based reinforcement learning (RL) methods have demonstrated promising results in a wide range of continuous control tasks. However, existing works in this field focus on the application of diffusion policies while leaving the diffusion critics unexplored. In fact, since policy optimization fundamentally relies on the critic, accurate value estimation is far more important than policy expressiveness. Furthermore, given the stochasticity of most reinforcement learning tasks, it has been confirmed that the critic is more appropriately depicted with a distributional model. Motivated by these points, we propose a novel distributional RL method with Diffusion Bridge Critics (DBC). DBC directly models the inverse cumulative distribution function (CDF) of the Q value. This allows us to accurately capture the value distribution and prevents it from collapsing into a trivial Gaussian distribution owing to the strong distribution-matching capability of the diffusion bridge. Moreover, we further derive an analytic integral formula to address discretization errors in DBC, which is essential in value estimation. To our knowledge, DBC is the first work to employ the diffusion bridge model as the critic. Notably, DBC is also a plug-and-play component and can be integrated into most existing RL frameworks. Experimental results on MuJoCo robot control benchmarks demonstrate the superiority of DBC compared with previous distributional critic models.

</details>


### [23] [Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference](https://arxiv.org/abs/2602.06029)
*Yingke Li,Anjali Parashar,Enlu Zhou,Chuchu Fan*

Main category: cs.LG

TL;DR: 论文为主动推理中的期望自由能最小化提供了首个理论保证，证明"足够的好奇心"能同时确保贝叶斯后验一致性和无遗憾优化，并建立了与经典贝叶斯实验设计和贝叶斯优化的理论联系。


<details>
  <summary>Details</summary>
Motivation: 主动推理通过期望自由能最小化统一探索与利用，但一直缺乏理论指导来平衡认知价值（信息增益）和实用价值（任务性能）。不清楚何时这种平衡能同时实现一致学习和高效决策。

Method: 建立理论分析框架，证明"足够的好奇心"这一单一要求能同时保证贝叶斯后验一致性和有界累积遗憾。分析该机制如何依赖于初始不确定性、可识别性和目标对齐。

Result: 获得了主动推理中期望自由能最小化代理的首个理论保证，将主动推理与经典贝叶斯实验设计和贝叶斯优化统一在一个理论框架内。

Conclusion: 理论分析转化为实际设计指南，用于在混合学习-优化问题中调整认知-实用权衡，并通过真实世界实验验证。

Abstract: Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: DemPO框架通过算法抽签构建代表性人类评分者小组，用于AI偏好对齐训练，相比传统便利样本能更好地反映多元人口价值观。


<details>
  <summary>Details</summary>
Motivation: 当前基于偏好的AI对齐方法（如RLHF）依赖人类评分者，但这些评分者通常是便利样本，存在人口代表性偏差，无法反映多元群体的价值观。

Method: 提出民主偏好优化（DemPO）框架，采用算法抽签机制构建代表性评分小组。提供两种训练方案：硬面板（仅使用抽签选出的代表性小组数据）和软面板（保留所有数据但按抽签概率重新加权）。

Result: 在1B到8B参数的Llama模型上实验表明，硬面板方案在六种聚合方法中始终排名第一，软面板始终优于未加权基线，且模型容量越大效果越明显。

Conclusion: 在偏好收集阶段强制实施人口代表性，而非事后修正，能训练出更好地反映代表性公众价值观的AI模型。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [25] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE框架通过对抗学习和教学性语言评估，让LLM内部化推理逻辑，无需人工监督即可实现专家级推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖标量奖励存在成本高、领域脆弱、无法理解解决方案底层逻辑的问题，这阻碍了LLM获得专家级推理能力。

Method: ALIVE框架基于"认知协同"原则，将问题提出、解决和评判统一在单一策略模型中，通过对抗学习和教学性语言反馈，让模型从原始语料中内部化评估标准。

Result: 在数学推理、代码生成和逻辑推理基准测试中，ALIVE显著缓解了奖励信号限制，在相同数据和计算条件下获得准确率提升、跨领域泛化能力增强和更高的自我纠正率。

Conclusion: ALIVE通过推理三位一体（问题提出、解决、评判）促进了能力自我持续增长，为无需人工监督的通用推理对齐提供了可扩展基础。

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [26] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 开发数据驱动的离散事件模拟器，用于评估学校安全干预措施，特别是机器人干预策略，以解决VR研究中需要大量参与者的限制问题。


<details>
  <summary>Details</summary>
Motivation: VR虽然能有效评估学校安全措施，但需要为每个条件招募新参与者，使得大规模或迭代评估困难，尤其是在需要大量训练场景的干预策略学习中。

Method: 开发数据驱动的离散事件模拟器（DES），将射击者移动和区域内行动建模为从VR研究中参与者行为学习到的随机过程，用于评估机器人干预策略。

Result: 模拟器能够重现关键经验模式，使得能够进行大规模评估和学习那些无法直接通过人类受试者训练的干预策略。

Conclusion: 这项工作展示了一个高到中保真度的模拟工作流程，为开发和评估自主学校安全干预措施提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>


### [27] [Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach](https://arxiv.org/abs/2602.05533)
*Zhengyi Guo,Wenpin Tang,Renyuan Xu*

Main category: cs.AI

TL;DR: 提出基于Doob's h-transform的扩散模型条件生成框架，通过漂移修正实现硬约束满足，无需修改预训练分数网络，并提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用和罕见事件模拟中，需要确保生成样本以概率1满足硬约束，而现有的软约束或基于奖励的引导方法无法保证约束满足。

Method: 基于Doob's h-transform、鞅表示和二次变差过程，提出条件扩散引导框架：1）通过添加包含条件函数对数梯度的显式漂移修正；2）提出基于鞅损失和鞅协变损失的两种离策略学习算法估计h及其梯度。

Result: 在总变差和Wasserstein距离上提供了非渐近理论保证，明确刻画了分数近似和引导估计误差的影响。数值实验验证了方法在强制执行硬约束和生成罕见事件样本方面的有效性。

Conclusion: 该框架为扩散模型的条件生成提供了理论严谨的硬约束满足方法，在安全关键应用和罕见事件模拟中具有重要价值。

Abstract: We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.

</details>


### [28] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 提出Generative Ontology框架，结合传统本体论的结构严谨性和LLM的创造力，通过可执行的Pydantic模式约束LLM生成，应用于游戏设计等领域。


<details>
  <summary>Details</summary>
Motivation: 传统本体论能描述领域结构但无法生成新内容，而LLM能流畅生成但缺乏结构有效性，经常产生幻觉。需要结合两者的优势：本体论提供语法，LLM提供创造力。

Method: 将领域知识编码为可执行的Pydantic模式，通过DSPy签名约束LLM生成。采用多智能体管道，为不同本体领域分配专门角色（如机制架构师、主题编织者、平衡批评家），每个智能体带有专业"焦虑"防止浅薄输出。使用检索增强生成和迭代验证确保机制与组件的连贯性。

Result: 开发了GameGrammar系统，能够根据主题提示（如"洞穴生态系统中发光真菌竞争"）生成结构完整、可玩的桌面游戏设计，包括机制、组件、胜利条件和设置说明，既满足本体约束又保持创造性。

Conclusion: 该框架可推广到游戏以外的领域，任何具有专家词汇、有效性约束和积累范例的领域（如音乐创作、软件架构、烹饪艺术）都适合使用Generative Ontology。约束不是限制创造力，而是使其成为可能，正如语法使诗歌成为可能一样。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [29] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: 论文提出Anchored Policy Optimization (APO)方法，解决强化学习中验证奖励导致的递归空间收缩问题，通过从全局形状匹配转向支持覆盖，在保持准确性的同时恢复多样性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习验证奖励方法存在递归空间收缩问题，导致有效替代方案的采样概率消失。KL正则化虽然试图缓解此问题，但强加了僵化的形状匹配约束，与正确性所需的锐化产生梯度冲突。

Method: 提出Anchored Policy Optimization (APO)，将范式从全局形状匹配转向支持覆盖。基于参考模型高置信度支持定义安全流形，允许激进锐化以提高效率，同时在错误校正时选择性调用恢复力以防止崩溃。

Result: 在数学基准测试中，APO打破了准确性与多样性的权衡，显著提高了Pass@1性能，同时恢复了标准策略梯度方法通常丢失的Pass@K多样性。

Conclusion: APO作为一种梯度对齐机制，能够最大化支持覆盖，实现弹性恢复，重新膨胀有效分支，解决了强化学习验证奖励中的递归空间收缩问题。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [30] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 提出RLFKV框架，通过细粒度知识验证和强化学习减少金融RAG系统中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 金融RAG系统中，模型依赖检索文档生成准确回答，但由于金融领域的时间敏感性，生成的回答仍存在与检索信息矛盾的幻觉问题

Method: 提出RLFKV框架：1) 将金融回答分解为原子知识单元；2) 评估每个单元的正确性计算细粒度忠实度奖励；3) 加入信息性奖励防止奖励攻击；4) 使用强化学习优化模型

Result: 在公开的FDD任务和新提出的FDD-ANT数据集上实验，均显示一致性改进，证实了方法的有效性

Conclusion: RLFKV框架通过细粒度知识验证和强化学习，有效减少了金融RAG系统中的幻觉问题，提高了回答与检索文档的一致性

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories](https://arxiv.org/abs/2602.05085)
*Sidi Lu,Zhenwen Liang,Dongyang Ma,Yan Wang,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: Locas是一种局部支持的参数化记忆机制，可与Transformer的FFN模块共享设计，能够灵活地从模型参数中卸载或合并，支持高效的持续学习，同时最小化灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 桥接测试时训练与新型参数化记忆，使记忆能够灵活地从模型参数中卸载或合并，以支持高效的持续学习并减少灾难性遗忘。

Method: 提出Locas（局部支持的参数化记忆），采用与Transformer FFN模块相似的设计，有两种主要变体：传统两层MLP设计（理论保证更清晰）和与SOTA LLMs相同的GLU-FFN结构。关键是通过重用模型参数、激活和/或梯度来正确初始化这种低秩侧向FFN式记忆。

Result: 在PG-19整书语言建模和LoCoMo长上下文对话问答任务上验证。Locas-GLU仅需0.02%额外参数即可存储过去上下文信息，同时保持较小的上下文窗口。MMLU评估显示，在记忆整本书后，模型的一般能力损失最小。

Conclusion: Locas能够将过去上下文永久化为参数化知识，同时最小化对模型现有内部知识的灾难性遗忘，展示了在持续学习中参数化记忆的潜力。

Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.

</details>


### [32] [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220)
*Jinchuan Tian,Haoran Wang,Bo-Hao Su,Chien-yu Huang,Qingzheng Wang,Jiatong Shi,William Chen,Xun Gong,Siddhant Arora,Chin-Jou Li,Masao Someki,Takashi Maekaku,Yusuke Shinohara,Jin Sakuma,Chao-Han Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: Bagpiper是一个80亿参数的音频基础模型，通过丰富的自然语言描述（字幕）来理解物理音频信号，实现了音频理解与生成的统一，在多项任务上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前音频基础模型通常依赖僵化的任务特定监督，只能处理音频的孤立因素而非整体。相比之下，人类智能以整体方式处理音频，无缝连接物理信号与抽象认知概念来执行复杂任务。需要开发能够模拟人类认知过程的音频模型。

Method: 1. 使用丰富的字幕（全面自然语言描述）来解释物理音频，这些字幕封装了信号中的关键认知概念（如转录、音频事件）；2. 在600B token的大规模语料上进行预训练，建立原始音频与高级概念空间之间的稳健双向映射；3. 微调时采用"先字幕后处理"的工作流程，模拟中间认知推理步骤来解决多样化任务，无需任务特定先验。

Result: 1. 在音频理解方面，Bagpiper在MMAU和AIRBench上超越了Qwen-2.5-Omni；2. 在生成质量方面，超越了CosyVoice3和TangoFlux，能够合成语音、音乐和音效的任意组合；3. 据作者所知，这是首批实现通用音频统一理解与生成的工作之一。

Conclusion: Bagpiper通过将物理音频信号映射到丰富的认知概念空间，实现了音频理解与生成的统一，模拟了人类处理音频的认知过程，在多项任务上表现出色，为音频AI的发展提供了新方向。

Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.

</details>


### [33] [CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs](https://arxiv.org/abs/2602.05258)
*Haoran Li,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CL

TL;DR: CoPE通过软裁剪RoPE的低频分量，统一了OOD缓解和语义建模两个目标，在长度泛化上达到SOTA性能，支持256k上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有的RoPE扩展方法主要分为两类：OOD缓解（调整频率以适应未见位置）和语义建模（注意力分数应优先语义相似token）。这两种看似不同的目标需要统一的理论框架。

Method: 提出CoPE方法：对RoPE的低频分量进行软裁剪。这种方法不仅消除了OOD异常值并优化了语义信号，还避免了硬裁剪引起的频谱泄漏。

Result: 大量实验表明，将软裁剪策略应用于RoPE能带来显著的性能提升，可扩展到256k上下文长度，验证了理论分析并确立了CoPE在长度泛化上的SOTA地位。

Conclusion: CoPE通过简单的软裁剪干预，统一了OOD缓解和语义建模两个目标，为RoPE的长度扩展提供了有效的解决方案，在长上下文处理中表现出色。

Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.

</details>


### [34] [Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions](https://arxiv.org/abs/2602.05932)
*Léo Labat,Etienne Ollion,François Yvon*

Main category: cs.CL

TL;DR: 该研究探讨多语言大语言模型在价值观选择题上的跨语言一致性，发现大型指令微调模型整体一致性较高，但某些问题仍存在语言特异性行为。


<details>
  <summary>Details</summary>
Motivation: 研究多语言大语言模型在价值观选择题上的跨语言一致性，探究模型是像理论上的多语者那样在不同语言中保持一致性，还是像多个单语模型那样在不同语言中表现出不同的价值观。

Method: 创建了多语言欧洲价值观调查（MEVS）语料库，包含8种欧洲语言的人工翻译调查问题。对30多个不同规模、制造商和微调状态的多语言大语言模型进行测试，控制提示变体包括答案顺序、符号类型和尾部字符。

Result: 大型指令微调模型整体一致性较高，但响应稳健性在不同问题间差异很大。某些问题在所有模型内部和跨模型间完全一致，而另一些问题则导致模型答案分裂。所有一致的指令微调模型在某些问题上都表现出语言特异性行为。

Conclusion: 多语言大语言模型在价值观选择题上并非完全一致的多语者，而是在某些问题上表现出语言特异性。需要进一步研究偏好微调的选择性效应，以及语言如何影响模型的价值表达。

Abstract: Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [35] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: VLN-Pilot是一个新颖框架，使用大型视觉语言模型作为室内无人机导航的"人类飞行员"，通过自然语言指令和视觉感知实现自主导航，无需GPS或传统路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统室内无人机导航依赖规则基础或几何路径规划方法，需要大量任务特定工程。本文旨在利用VLLM的多模态推理能力，实现更自然、语义理解驱动的自主导航，减少操作员工作量并提高安全性。

Method: VLN-Pilot框架让VLLM充当无人机飞行员，通过解释自由形式的自然语言指令，并将其与视觉观察相结合来规划和执行轨迹。框架整合了语言驱动的语义理解和视觉感知，支持空间关系推理、避障和对意外事件的动态响应。

Result: 在定制的逼真室内模拟基准测试中，VLLM驱动的智能体在复杂指令跟随任务上取得了高成功率，包括具有多个语义目标的长期导航。结果表明语言引导的自主代理可以替代远程无人机飞行员。

Conclusion: VLLM为基础的飞行员可以显著减少操作员工作量，同时在受限室内环境中提高安全性和任务灵活性，为检查、搜救和设施监控等任务的可扩展、人性化室内无人机控制开辟了新途径。

Abstract: This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.

</details>


### [36] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出一种神经形态控制框架，通过动态分岔机制解决机器人导航中的对称性破缺问题，将视觉目标激励直接转换为运动指令


<details>
  <summary>Details</summary>
Motivation: 机器人导航中反应式传感器控制与模型规划器之间存在矛盾，当多个目标选项均等时容易产生决策犹豫，需要在不依赖计算密集型规划器的情况下打破对称性

Method: 使用神经形态控制框架，将机载摄像头像素编码为动态神经元群输入，直接将视觉目标激励转换为以自我为中心的运动指令，通过动态分岔机制延迟决策直到环境几何诱导的临界点

Result: 在仿真环境和四旋翼无人机实验平台上验证了该方法的有效性，实现了实时自主导航，计算负担小，参数可解释性强

Conclusion: 该神经形态控制器能够弥合反应式控制与模型规划之间的鸿沟，为视觉引导导航和跟踪提供了一种简约高效的解决方案，可无缝集成到应用特定的图像处理流程中

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>
