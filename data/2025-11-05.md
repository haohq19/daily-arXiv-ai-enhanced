<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Autobiasing Event Cameras for Flickering Mitigation](https://arxiv.org/abs/2511.02180)
*Mehdi Sefidgar Dilmaghani,Waseem Shariff,Cian Ryan,Joe Lemley,Peter Corcoran*

Main category: cs.CV

TL;DR: 提出了一种基于CNN的自适应偏置调节机制，通过动态调整事件相机的偏置设置来抑制25-500Hz范围内的闪烁效应，无需额外硬件或软件滤波。


<details>
  <summary>Details</summary>
Motivation: 解决事件相机在不同光照环境下因光强快速变化产生的闪烁效应，提升事件相机在多样化环境中的性能表现。

Method: 利用卷积神经网络在空间域识别闪烁现象，并动态调节特定偏置参数来最小化闪烁影响，通过人脸检测框架在多种光照条件下验证效果。

Result: 显著提升YOLO人脸检测置信度，增加检测到人脸的帧数比例，在良好光照和低光条件下平均梯度分别降低38.2%和53.6%。

Conclusion: 该方法能有效改善事件相机在不利光照场景下的功能表现，具有广泛应用潜力。

Abstract: Understanding and mitigating flicker effects caused by rapid variations in
light intensity is critical for enhancing the performance of event cameras in
diverse environments. This paper introduces an innovative autonomous mechanism
for tuning the biases of event cameras, effectively addressing flicker across a
wide frequency range -25 Hz to 500 Hz. Unlike traditional methods that rely on
additional hardware or software for flicker filtering, our approach leverages
the event cameras inherent bias settings. Utilizing a simple Convolutional
Neural Networks -CNNs, the system identifies instances of flicker in a spatial
space and dynamically adjusts specific biases to minimize its impact. The
efficacy of this autobiasing system was robustly tested using a face detector
framework under both well-lit and low-light conditions, as well as across
various frequencies. The results demonstrated significant improvements:
enhanced YOLO confidence metrics for face detection, and an increased
percentage of frames capturing detected faces. Moreover, the average gradient,
which serves as an indicator of flicker presence through edge detection,
decreased by 38.2 percent in well-lit conditions and by 53.6 percent in
low-light conditions. These findings underscore the potential of our approach
to significantly improve the functionality of event cameras in a range of
adverse lighting scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR](https://arxiv.org/abs/2511.01937)
*Abdelaziz Bounhar,Hadi Abdine,Evan Dufraisse,Ahmad Chamma,Amr Mohamed,Dani Bouch,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.LG

TL;DR: 通过保留并适度加权中等难度问题，可以在不显式惩罚长度的情况下实现输出简洁性，使模型在保持准确性的同时生成更短的解决方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在逐步推理时往往过于冗长，增加推理成本。标准的RLVR流程过滤掉简单问题，导致模型主要在需要长推理链的难题上训练，使模型错误地将"思考更久"等同于"思考更好"。

Method: 保留并适度加权中等难度问题作为隐式长度正则化器，让模型接触可解决的短链任务来约束输出分布，防止过度冗长。

Result: 在Qwen3-4B-Thinking-2507上的RLVR实验实现了基线pass@1 AIME25准确率，同时生成的解决方案平均缩短近一倍。

Conclusion: 无需显式长度惩罚即可实现简洁性，模型学会解决更难问题而不会增加输出长度，实现了"免费出现的简洁性"。

Abstract: Large language models (LLMs) trained for step-by-step reasoning often become
excessively verbose, raising inference cost. Standard Reinforcement Learning
with Verifiable Rewards (RLVR) pipelines filter out ``easy'' problems for
training efficiency, leaving the model to train primarily on harder problems
that require longer reasoning chains. This skews the output length distribution
upward, resulting in a \textbf{model that conflates ``thinking longer'' with
``thinking better''}. In this work, we show that retaining and modestly
up-weighting moderately easy problems acts as an implicit length regularizer.
Exposing the model to solvable short-chain tasks constrains its output
distribution and prevents runaway verbosity. The result is
\textbf{\emph{emergent brevity for free}}: the model learns to solve harder
problems without inflating the output length, \textbf{ despite the absence of
any explicit length penalization}. RLVR experiments using this approach on
\textit{Qwen3-4B-Thinking-2507} (with a 16k token limit) achieve baseline
pass@1 AIME25 accuracy while generating solutions that are, on average, nearly
twice as short. The code is available at
\href{https://github.com/MBZUAI-Paris/Frugal-AI}{GitHub}, with datasets and
models on
\href{https://huggingface.co/collections/MBZUAI-Paris/k2-think-mini-68dcfa8b114686a4bd3dc2bc}{Hugging
Face}.

</details>


### [3] [Quantum-Enhanced Generative Models for Rare Event Prediction](https://arxiv.org/abs/2511.02042)
*M. Z. Haider,M. U. Ghouri,Tayyaba Noreen,M. Salman*

Main category: cs.LG

TL;DR: 提出量子增强生成模型(QEGM)，一种混合经典-量子框架，通过变分量子电路增强对罕见事件的建模能力，显著降低尾部KL散度并改善罕见事件召回率。


<details>
  <summary>Details</summary>
Motivation: 罕见事件（如金融危机、极端气候）由于稀缺性和重尾分布难以建模，传统深度生成模型在捕捉这些罕见事件时容易出现模式崩溃或不确定性估计不准的问题。

Method: 结合深度隐变量模型与变分量子电路，采用混合损失函数联合优化重构保真度和尾部感知似然，并通过量子随机性驱动的噪声注入增强样本多样性。

Result: 在合成高斯混合和真实数据集（金融、气候、蛋白质结构）上评估，QEGM相比最先进基线（GAN、VAE、Diffusion）将尾部KL散度降低达50%，同时改善罕见事件召回率和覆盖校准。

Conclusion: QEGM为罕见事件预测提供了一种原则性方法，展现出超越纯经典方法的鲁棒性潜力。

Abstract: Rare events such as financial crashes, climate extremes, and biological
anomalies are notoriously difficult to model due to their scarcity and
heavy-tailed distributions. Classical deep generative models often struggle to
capture these rare occurrences, either collapsing low-probability modes or
producing poorly calibrated uncertainty estimates. In this work, we propose the
Quantum-Enhanced Generative Model (QEGM), a hybrid classical-quantum framework
that integrates deep latent-variable models with variational quantum circuits.
The framework introduces two key innovations: (1) a hybrid loss function that
jointly optimizes reconstruction fidelity and tail-aware likelihood, and (2)
quantum randomness-driven noise injection to enhance sample diversity and
mitigate mode collapse. Training proceeds via a hybrid loop where classical
parameters are updated through backpropagation while quantum parameters are
optimized using parameter-shift gradients. We evaluate QEGM on synthetic
Gaussian mixtures and real-world datasets spanning finance, climate, and
protein structure. Results demonstrate that QEGM reduces tail KL divergence by
up to 50 percent compared to state-of-the-art baselines (GAN, VAE, Diffusion),
while improving rare-event recall and coverage calibration. These findings
highlight the potential of QEGM as a principled approach for rare-event
prediction, offering robustness beyond what is achievable with purely classical
methods.

</details>


### [4] [H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart Sound Recordings](https://arxiv.org/abs/2511.02379)
*Rohith Shinoj Kumar,Rushdeep Dinda,Aditya Tyagi,Annappa B.,Naveen Kumar M. R*

Main category: cs.LG

TL;DR: 提出了一种结合CNN、H-Infinity滤波器和LSTM的新型架构，用于从心音记录中检测心律失常，在PhysioNet数据集上取得了99.42%的准确率和98.85%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 心律失常的早期检测可以预防严重并发症，但传统手动诊断依赖视觉解释且具有主观性。现有深度学习模型在真实场景中泛化能力不足，特别是在处理小样本或噪声数据时。

Method: 提出CNN-H-Infinity-LSTM混合架构，引入控制理论中的H-Infinity滤波器可训练参数来增强鲁棒性和泛化能力。

Result: 在PhysioNet CinC Challenge 2016数据集上的实验表明，该模型实现了稳定收敛，测试准确率达到99.42%，F1分数达到98.85%，优于现有基准方法。

Conclusion: 所提出的CNN-H-Infinity-LSTM架构在心律失常检测中表现出色，通过结合控制理论概念显著提升了模型的鲁棒性和泛化性能。

Abstract: Early detection of heart arrhythmia can prevent severe future complications
in cardiac patients. While manual diagnosis still remains the clinical
standard, it relies heavily on visual interpretation and is inherently
subjective. In recent years, deep learning has emerged as a powerful tool to
automate arrhythmia detection, offering improved accuracy, consistency, and
efficiency. Several variants of convolutional and recurrent neural network
architectures have been widely explored to capture spatial and temporal
patterns in physiological signals. However, despite these advancements, current
models often struggle to generalize well in real-world scenarios, especially
when dealing with small or noisy datasets, which are common challenges in
biomedical applications. In this paper, a novel CNN-H-Infinity-LSTM
architecture is proposed to identify arrhythmic heart signals from heart sound
recordings. This architecture introduces trainable parameters inspired by the
H-Infinity filter from control theory, enhancing robustness and generalization.
Extensive experimentation on the PhysioNet CinC Challenge 2016 dataset, a
public benchmark of heart audio recordings, demonstrates that the proposed
model achieves stable convergence and outperforms existing benchmarks, with a
test accuracy of 99.42% and an F1 score of 98.85%.

</details>


### [5] [Directional-Clamp PPO](https://arxiv.org/abs/2511.02577)
*Gilad Karpel,Ruida Zhou,Shoham Sabach,Mohammad Ghavamzadeh*

Main category: cs.LG

TL;DR: 提出了DClamp-PPO算法，通过惩罚重要性比率向"错误"方向移动的动作来改进PPO算法，在各种MuJoCo环境中表现优于PPO及其变体。


<details>
  <summary>Details</summary>
Motivation: PPO优化过程中，由于策略优化的随机性，重要性比率经常向"错误"方向移动，这是阻碍PPO改进的关键因素，但一直被忽视。

Method: 提出方向性钳位PPO算法，在严格"错误"方向区域（优势为正时比率低于1-β，优势为负时比率高于1+β）施加更陡峭的损失斜率来惩罚这些动作。

Result: DClamp-PPO在各种MuJoCo环境中使用不同随机种子时，始终优于PPO及其变体，理论和实证都表明能更好地避免"错误"方向更新。

Conclusion: 通过关注修改目标函数在"错误"方向区域的行为，DClamp-PPO能更好地保持重要性比率接近1，提高PPO算法的性能。

Abstract: Proximal Policy Optimization (PPO) is widely regarded as one of the most
successful deep reinforcement learning algorithms, known for its robustness and
effectiveness across a range of problems.
  The PPO objective encourages the importance ratio between the current and
behavior policies to move to the "right" direction -- starting from importance
sampling ratios equal to 1, increasing the ratios for actions with positive
advantages and decreasing those with negative advantages. A clipping function
is introduced to prevent over-optimization when updating the importance ratio
in these "right" direction regions. Many PPO variants have been proposed to
extend its success, most of which modify the objective's behavior by altering
the clipping in the "right" direction regions. However, due to randomness in
the rollouts and stochasticity of the policy optimization, we observe that the
ratios frequently move to the "wrong" direction during the PPO optimization.
This is a key factor hindering the improvement of PPO, but it has been largely
overlooked. To address this, we propose the Directional-Clamp PPO algorithm
(DClamp-PPO), which further penalizes the actions going to the strict "wrong"
direction regions, where the advantage is positive (negative) and importance
ratio falls below (above) $1 - \beta$ ($1+\beta$),
  for a tunable parameter $\beta \in (0, 1)$. The penalty is by enforcing a
steeper loss slope, i.e., a clamp, in those regions. We demonstrate that
DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing
on modifying the objective's behavior in the "right" direction, across various
MuJoCo environments, using different random seeds. The proposed method is
shown, both theoretically and empirically, to better avoid "wrong" direction
updates while keeping the importance ratio closer to 1.

</details>


### [6] [In Situ Training of Implicit Neural Compressors for Scientific Simulations via Sketch-Based Regularization](https://arxiv.org/abs/2511.02659)
*Cooper Simpson,Stephen Becker,Alireza Doostan*

Main category: cs.LG

TL;DR: 提出了一种新颖的原地训练协议，使用完整数据和草图数据的有限内存缓冲区，通过草图数据防止灾难性遗忘，特别针对基于隐式神经表示的神经压缩任务。


<details>
  <summary>Details</summary>
Motivation: 解决在连续学习场景中，特别是在原地神经压缩任务中，如何防止灾难性遗忘的问题。草图数据被用作正则化器来维持先前学到的知识。

Method: 使用有限内存缓冲区存储完整和草图数据样本，通过Johnson-Lindenstrauss理论指导的草图技术作为正则化器，在隐式神经表示的超网络上进行原地训练。

Result: 在多种复杂仿真数据上（2D/3D、长时间跨度、非结构化网格和非笛卡尔几何）展示了强大的重建性能和高压缩率，草图方法使原地方案性能接近等效离线方法。

Conclusion: 草图技术能够有效防止灾难性遗忘，使原地训练方案在神经压缩任务中达到与离线方法相当的性能，该方法在连续学习领域具有广泛的应用潜力。

Abstract: Focusing on implicit neural representations, we present a novel in situ
training protocol that employs limited memory buffers of full and sketched data
samples, where the sketched data are leveraged to prevent catastrophic
forgetting. The theoretical motivation for our use of sketching as a
regularizer is presented via a simple Johnson-Lindenstrauss-informed result.
While our methods may be of wider interest in the field of continual learning,
we specifically target in situ neural compression using implicit neural
representation-based hypernetworks. We evaluate our method on a variety of
complex simulation data in two and three dimensions, over long time horizons,
and across unstructured grids and non-Cartesian geometries. On these tasks, we
show strong reconstruction performance at high compression rates. Most
importantly, we demonstrate that sketching enables the presented in situ scheme
to approximately match the performance of the equivalent offline method.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents](https://arxiv.org/abs/2511.02734)
*Jiayu Liu,Cheng Qian,Zhaochen Su,Qing Zong,Shijue Huang,Bingxiang He,Yi R. Fung*

Main category: cs.AI

TL;DR: CostBench是一个以成本为中心的基准测试，用于评估LLM代理的经济推理和重新规划能力，发现在静态和动态环境下代理都难以找到成本最优解。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理评估主要关注任务完成度，忽视了资源效率和适应性，特别是代理在变化环境中制定和调整成本最优计划的能力。

Method: 在旅行规划领域构建CostBench基准，包含可通过多种原子和复合工具序列解决的任务，支持四种动态阻塞事件（如工具故障和成本变化）来模拟现实世界的不确定性。

Result: 评估显示代理在成本感知规划方面存在显著差距：在静态设置中经常无法找到成本最优解，GPT-5在最难任务上的精确匹配率低于75%，动态条件下性能进一步下降约40%。

Conclusion: CostBench通过诊断这些弱点，为开发既经济理性又鲁棒的未来代理奠定了基础。

Abstract: Current evaluations of Large Language Model (LLM) agents primarily emphasize
task completion, often overlooking resource efficiency and adaptability. This
neglects a crucial capability: agents' ability to devise and adjust
cost-optimal plans in response to changing environments. To bridge this gap, we
introduce CostBench, a scalable, cost-centric benchmark designed to evaluate
agents' economic reasoning and replanning abilities. Situated in the
travel-planning domain, CostBench comprises tasks solvable via multiple
sequences of atomic and composite tools with diverse, customizable costs. It
also supports four types of dynamic blocking events, such as tool failures and
cost changes, to simulate real-world unpredictability and necessitate agents to
adapt in real time. Evaluating leading open-sourced and proprietary models on
CostBench reveals a substantial gap in cost-aware planning: agents frequently
fail to identify cost-optimal solutions in static settings, with even GPT-5
achieving less than 75% exact match rate on the hardest tasks, and performance
further dropping by around 40% under dynamic conditions. By diagnosing these
weaknesses, CostBench lays the groundwork for developing future agents that are
both economically rational and robust.

</details>


### [8] [Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning](https://arxiv.org/abs/2511.02818)
*Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu*

Main category: cs.AI

TL;DR: Orion-MSP是一种创新的表格数据上下文学习架构，通过多尺度处理、块稀疏注意力和Perceiver风格记忆解决了现有方法的局限性，在保持高性能的同时实现了对高维表格的有效扩展。


<details>
  <summary>Details</summary>
Motivation: 当前表格上下文学习方法存在三个主要限制：单尺度特征处理忽略层次依赖、密集注意力机制在表格宽度上呈二次方扩展、严格顺序组件处理阻碍迭代表示优化和跨组件通信。

Method: 提出Orion-MSP架构，包含三个关键创新：多尺度处理捕获层次特征交互；块稀疏注意力结合窗口化、全局和随机模式实现可扩展效率和长程连接；Perceiver风格记忆实现跨组件的安全双向信息流。

Result: 在多样化基准测试中，Orion-MSP达到或超越了最先进方法的性能，同时能够有效扩展到高维表格。

Conclusion: Orion-MSP为高效表格上下文学习设立了新标准，解决了现有架构的关键限制，实现了高性能和可扩展性的平衡。

Abstract: Tabular data remain the predominant format for real-world applications. Yet,
developing effective neural models for tabular data remains challenging due to
heterogeneous feature types and complex interactions occurring at multiple
scales. Recent advances in tabular in-context learning (ICL), such as TabPFN
and TabICL, have achieved state-of-the-art performance comparable to
gradient-boosted trees (GBTs) without task-specific fine-tuning. However,
current architectures exhibit key limitations: (1) single-scale feature
processing that overlooks hierarchical dependencies, (2) dense attention with
quadratic scaling in table width, and (3) strictly sequential component
processing that prevents iterative representation refinement and
cross-component communication. To address these challenges, we introduce
Orion-MSP, a tabular ICL architecture featuring three key innovations: (1)
multi-scale processing to capture hierarchical feature interactions; (2)
block-sparse attention combining windowed, global, and random patterns for
scalable efficiency and long-range connectivity; and (3) a Perceiver-style
memory enabling safe bidirectional information flow across components. Across
diverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performance
while scaling effectively to high-dimensional tables, establishing a new
standard for efficient tabular in-context learning. The model is publicly
available at https://github.com/Lexsi-Labs/Orion-MSP .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic LLM Personas](https://arxiv.org/abs/2511.02458)
*Giulia Iadisernia,Carolina Camassa*

Main category: cs.CL

TL;DR: 评估基于角色的提示是否能提升LLM在宏观经济预测任务中的表现，发现GPT-4o与人类专家预测精度相似，但角色描述对预测准确性无显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究角色提示对大型语言模型在宏观经济预测任务中的有效性，特别是与人类专家预测表现的比较。

Method: 使用PersonaHub语料库中的2,368个经济学相关角色提示GPT-4o，复制ECB专业预测者调查的50个季度轮次（2013-2025），并与人类专家小组和无角色描述的基线预测进行比较。

Result: GPT-4o与人类预测者达到相似的准确度水平，差异虽统计显著但实际不大；在2024-2025年样本外评估中保持竞争力；角色描述未带来可测量的预测优势。

Conclusion: GPT-4o在提供相关上下文数据时能在宏观经济预测中达到有竞争力的准确性，但多样化提示产生的预测相比人类小组更加同质化，角色描述可省略以节省计算成本。

Abstract: We evaluate whether persona-based prompting improves Large Language Model
(LLM) performance on macroeconomic forecasting tasks. Using 2,368
economics-related personas from the PersonaHub corpus, we prompt GPT-4o to
replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds
(2013-2025). We compare the persona-prompted forecasts against the human
experts panel, across four target variables (HICP, core HICP, GDP growth,
unemployment) and four forecast horizons. We also compare the results against
100 baseline forecasts without persona descriptions to isolate its effect. We
report two main findings. Firstly, GPT-4o and human forecasters achieve
remarkably similar accuracy levels, with differences that are statistically
significant yet practically modest. Our out-of-sample evaluation on 2024-2025
data demonstrates that GPT-4o can maintain competitive forecasting performance
on unseen events, though with notable differences compared to the in-sample
period. Secondly, our ablation experiment reveals no measurable forecasting
advantage from persona descriptions, suggesting these prompt components can be
omitted to reduce computational costs without sacrificing accuracy. Our results
provide evidence that GPT-4o can achieve competitive forecasting accuracy even
on out-of-sample macroeconomic events, if provided with relevant context data,
while revealing that diverse prompts produce remarkably homogeneous forecasts
compared to human panels.

</details>
