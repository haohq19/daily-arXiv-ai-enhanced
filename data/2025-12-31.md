<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 13]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Signal-SGN++: Topology-Enhanced Time-Frequency Spiking Graph Network for Skeleton-Based Action Recognition](https://arxiv.org/abs/2512.22214)
*Naichuan Zheng,Xiahai Lun,Weiyi Li,Yuchen Du*

Main category: cs.CV

TL;DR: 提出Signal-SGN++，一种结合拓扑感知与脉冲动态的图神经网络框架，用于高效的动作识别，在保持高准确率的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 传统图卷积网络（GCNs）在骨骼动作识别中表现出色但能耗高，而脉冲神经网络（SNNs）虽然节能，但难以捕捉人体运动的时空-频率耦合依赖和拓扑结构。需要一种能兼顾能效和性能的解决方案。

Method: 提出拓扑感知脉冲图框架，包含：1）1D脉冲图卷积和频率脉冲卷积的主干网络；2）拓扑转移自注意力机制；3）多尺度小波变换融合分支和拓扑感知时频融合单元。

Result: 在大规模基准测试中，Signal-SGN++实现了优越的准确率-效率权衡，超越了现有基于SNN的方法，并在显著降低能耗的情况下达到了与最先进GCNs竞争的结果。

Conclusion: Signal-SGN++成功地将拓扑适应性与脉冲动态相结合，为高效的动作识别提供了有效的解决方案，在保持高性能的同时大幅降低了计算能耗。

Abstract: Graph Convolutional Networks (GCNs) demonstrate strong capability in modeling skeletal topology for action recognition, yet their dense floating-point computations incur high energy costs. Spiking Neural Networks (SNNs), characterized by event-driven and sparse activation, offer energy efficiency but remain limited in capturing coupled temporal-frequency and topological dependencies of human motion. To bridge this gap, this article proposes Signal-SGN++, a topology-aware spiking graph framework that integrates structural adaptivity with time-frequency spiking dynamics. The network employs a backbone composed of 1D Spiking Graph Convolution (1D-SGC) and Frequency Spiking Convolution (FSC) for joint spatiotemporal and spectral feature extraction. Within this backbone, a Topology-Shift Self-Attention (TSSA) mechanism is embedded to adaptively route attention across learned skeletal topologies, enhancing graph-level sensitivity without increasing computational complexity. Moreover, an auxiliary Multi-Scale Wavelet Transform Fusion (MWTF) branch decomposes spiking features into multi-resolution temporal-frequency representations, wherein a Topology-Aware Time-Frequency Fusion (TATF) unit incorporates structural priors to preserve topology-consistent spectral fusion. Comprehensive experiments on large-scale benchmarks validate that Signal-SGN++ achieves superior accuracy-efficiency trade-offs, outperforming existing SNN-based methods and achieving competitive results against state-of-the-art GCNs under substantially reduced energy consumption.

</details>


### [2] [VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs](https://arxiv.org/abs/2512.22226)
*Naishan Zheng,Jie Huang,Qingpei Guo,Feng Zhao*

Main category: cs.CV

TL;DR: VideoScaffold是一个用于流式视频理解的动态表示框架，通过自适应调整事件粒度并保留细粒度视觉语义，解决了现有静态方法在连续视频流中产生碎片化或过度压缩输出的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的视频理解方法在处理长视频时面临挑战：帧间冗余严重且需要时间连贯表示。现有的静态策略（如稀疏采样、帧压缩和聚类）为离线场景优化，应用于连续视频流时会产生碎片化或过度压缩的输出。

Method: 提出VideoScaffold框架，包含两个核心组件：1) 弹性尺度事件分割(EES)：通过预测引导的分割动态细化事件边界；2) 分层事件整合(HEC)：逐步将语义相关的片段聚合成多层次抽象表示。两者协同工作，使框架能够随着视频流展开，从细粒度帧理解平滑过渡到抽象事件推理。

Result: 在离线和流式视频理解基准测试上的广泛实验表明，VideoScaffold实现了最先进的性能。该框架是模块化和即插即用的，能够无缝扩展现有的基于图像的多模态大语言模型到连续视频理解任务。

Conclusion: VideoScaffold通过动态调整事件粒度和保留视觉语义，有效解决了流式视频理解中的挑战，为连续视频理解提供了灵活高效的解决方案，代码已开源。

Abstract: Understanding long videos with multimodal large language models (MLLMs) remains challenging due to the heavy redundancy across frames and the need for temporally coherent representations. Existing static strategies, such as sparse sampling, frame compression, and clustering, are optimized for offline settings and often produce fragmented or over-compressed outputs when applied to continuous video streams. We present VideoScaffold, a dynamic representation framework designed for streaming video understanding. It adaptively adjusts event granularity according to video duration while preserving fine-grained visual semantics. VideoScaffold introduces two key components: Elastic-Scale Event Segmentation (EES), which performs prediction-guided segmentation to dynamically refine event boundaries, and Hierarchical Event Consolidation (HEC), which progressively aggregates semantically related segments into multi-level abstractions. Working in concert, EES and HEC enable VideoScaffold to transition smoothly from fine-grained frame understanding to abstract event reasoning as the video stream unfolds. Extensive experiments across both offline and streaming video understanding benchmarks demonstrate that VideoScaffold achieves state-of-the-art performance. The framework is modular and plug-and-play, seamlessly extending existing image-based MLLMs to continuous video comprehension. The code is available at https://github.com/zheng980629/VideoScaffold.

</details>


### [3] [LECalib: Line-Based Event Camera Calibration](https://arxiv.org/abs/2512.22441)
*Zibin Liu,Banglei Guana,Yang Shanga,Zhenbao Yu,Yifei Bian,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种基于线特征的事件相机标定框架，利用人造环境中常见物体的几何线条（如门窗、箱子等），直接从事件流中检测线条进行标定，无需专用标定板。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机标定方法通常需要闪烁图案、重建强度图像或使用标定板，过程耗时且需要人工放置标定物，无法适应快速变化的场景需求。

Method: 1) 直接从事件流中检测线条；2) 利用事件-线条标定模型生成相机参数初始估计；3) 采用非线性优化细化参数。方法适用于平面和非平面线条。

Result: 通过仿真和真实世界实验验证了方法的可行性和准确性，在单目和立体事件相机上均进行了验证。代码已开源。

Conclusion: 提出了一种无需专用标定板、直接从事件流中利用环境线条进行事件相机标定的实用框架，适用于动态场景。

Abstract: Camera calibration is an essential prerequisite for event-based vision applications. Current event camera calibration methods typically involve using flashing patterns, reconstructing intensity images, and utilizing the features extracted from events. Existing methods are generally time-consuming and require manually placed calibration objects, which cannot meet the needs of rapidly changing scenarios. In this paper, we propose a line-based event camera calibration framework exploiting the geometric lines of commonly-encountered objects in man-made environments, e.g., doors, windows, boxes, etc. Different from previous methods, our method detects lines directly from event streams and leverages an event-line calibration model to generate the initial guess of camera parameters, which is suitable for both planar and non-planar lines. Then, a non-linear optimization is adopted to refine camera parameters. Both simulation and real-world experiments have demonstrated the feasibility and accuracy of our method, with validation performed on monocular and stereo event cameras. The source code is released at https://github.com/Zibin6/line_based_event_camera_calib.

</details>


### [4] [Comparing Object Detection Models for Electrical Substation Component Mapping](https://arxiv.org/abs/2512.22454)
*Haley Mody,Namish Bansal,Dennies Kiprono Bor,Edward J. Oughton*

Main category: cs.CV

TL;DR: 该研究使用YOLOv8、YOLOv11和RF-DETR三种计算机视觉模型对变电站组件进行自动检测和映射，比较了各模型在准确度、精度和效率方面的表现，为大规模变电站基础设施映射提供了机器学习解决方案。


<details>
  <summary>Details</summary>
Motivation: 变电站是电网的关键组成部分，其资产（如变压器）容易受到飓风、洪水、地震和地磁感应电流等多种灾害的破坏。电网作为关键国家基础设施，任何故障都可能带来重大的经济和公共安全影响。传统的人工变电站基础设施映射方法耗时耗力，因此需要开发自动化的计算机视觉解决方案来提高效率和便利性。

Method: 研究使用手动标注的美国变电站图像数据集，训练并比较了三种计算机视觉模型：YOLOv8、YOLOv11和RF-DETR。评估了各模型在检测准确度、精度和效率方面的表现，并利用这些模型对美国各地的变电站组件进行有效映射。

Result: 研究展示了三种模型在变电站组件检测中的性能表现，分析了各模型的关键优势和局限性，确定了哪种模型能够提供可靠且可扩展的大规模变电站组件映射解决方案。

Conclusion: 该研究证明了机器学习在变电站映射中的实用价值，为电网基础设施的脆弱性评估和风险管理提供了自动化工具，有助于预防和减轻变电站故障带来的经济和安全影响。

Abstract: Electrical substations are a significant component of an electrical grid. Indeed, the assets at these substations (e.g., transformers) are prone to disruption from many hazards, including hurricanes, flooding, earthquakes, and geomagnetically induced currents (GICs). As electrical grids are considered critical national infrastructure, any failure can have significant economic and public safety implications. To help prevent and mitigate these failures, it is thus essential that we identify key substation components to quantify vulnerability. Unfortunately, traditional manual mapping of substation infrastructure is time-consuming and labor-intensive. Therefore, an autonomous solution utilizing computer vision models is preferable, as it allows for greater convenience and efficiency. In this research paper, we train and compare the outputs of 3 models (YOLOv8, YOLOv11, RF-DETR) on a manually labeled dataset of US substation images. Each model is evaluated for detection accuracy, precision, and efficiency. We present the key strengths and limitations of each model, identifying which provides reliable and large-scale substation component mapping. Additionally, we utilize these models to effectively map the various substation components in the United States, showcasing a use case for machine learning in substation mapping.

</details>


### [5] [Event-based high temporal resolution measurement of shock wave motion field](https://arxiv.org/abs/2512.22474)
*Taihang Lei,Banglei Guan,Minzu Liang,Pengju Sun,Jing Tao,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种基于多事件相机的高时空分辨率冲击波运动参数测量框架，通过极坐标编码、自适应ROI提取和迭代斜率分析实现冲击波前事件提取，最终实现运动场重建和爆炸当量反演。


<details>
  <summary>Details</summary>
Motivation: 冲击波在电力场测试和损伤评估等应用中需要高时空分辨率的精确测量，但冲击波的快速、不均匀传播和不稳定的测试条件带来了重大挑战。

Method: 1. 建立极坐标系对事件进行编码以揭示冲击波传播模式，通过事件偏移计算进行自适应ROI提取；2. 利用迭代斜率分析提取冲击波前事件，利用速度变化的连续性；3. 根据事件光学成像模型推导事件几何模型和冲击波运动参数，结合3D重建模型。

Result: 与压力传感器和经验公式的速度测量结果比较，最大误差为5.20%，最小误差为0.06%。实验结果表明该方法实现了高时空分辨率的高精度冲击波运动场测量。

Conclusion: 该方法利用多事件相机的高速度和高动态范围能力，实现了多角度冲击波测量、运动场重建和爆炸当量反演，代表了该领域的显著进展。

Abstract: Accurate measurement of shock wave motion parameters with high spatiotemporal resolution is essential for applications such as power field testing and damage assessment. However, significant challenges are posed by the fast, uneven propagation of shock waves and unstable testing conditions. To address these challenges, a novel framework is proposed that utilizes multiple event cameras to estimate the asymmetry of shock waves, leveraging its high-speed and high-dynamic range capabilities. Initially, a polar coordinate system is established, which encodes events to reveal shock wave propagation patterns, with adaptive region-of-interest (ROI) extraction through event offset calculations. Subsequently, shock wave front events are extracted using iterative slope analysis, exploiting the continuity of velocity changes. Finally, the geometric model of events and shock wave motion parameters is derived according to event-based optical imaging model, along with the 3D reconstruction model. Through the above process, multi-angle shock wave measurement, motion field reconstruction, and explosive equivalence inversion are achieved. The results of the speed measurement are compared with those of the pressure sensors and the empirical formula, revealing a maximum error of 5.20% and a minimum error of 0.06%. The experimental results demonstrate that our method achieves high-precision measurement of the shock wave motion field with both high spatial and temporal resolution, representing significant progress.

</details>


### [6] [PoseStreamer: A Multi-modal Framework for 6DoF Pose Estimation of Unseen Moving Objects](https://arxiv.org/abs/2512.22979)
*Huiming Yang,Linglin Liao,Fei Ding,Sibo Wang,Zijian Zeng*

Main category: cs.CV

TL;DR: PoseStreamer：一个针对高速运动场景设计的鲁棒多模态6DoF姿态估计框架，通过历史姿态记忆、物体中心跟踪和射线姿态过滤提升性能，并在新数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 在高速和低光场景中，传统RGB相机存在运动模糊问题，而事件相机虽然具有高时间分辨率，但现有的6DoF姿态估计方法在高速物体运动场景中表现不佳，需要专门针对高速运动设计的解决方案。

Method: 提出PoseStreamer框架，包含三个核心组件：1）自适应姿态记忆队列，利用历史方向线索保持时间一致性；2）物体中心2D跟踪器，提供强2D先验以提升3D中心召回率；3）射线姿态过滤器，沿相机射线进行几何细化。此外还构建了MoCapCube6D多模态数据集用于基准测试。

Result: 大量实验表明，PoseStreamer在高速运动场景中不仅实现了更高的精度，而且作为无模板框架对未见过的运动物体表现出强大的泛化能力。

Conclusion: PoseStreamer为解决高速运动场景下的6DoF姿态估计问题提供了有效的多模态解决方案，通过时间一致性、2D先验和几何细化相结合的方法显著提升了性能，并在新构建的数据集上验证了其优越性。

Abstract: Six degree of freedom (6DoF) pose estimation for novel objects is a critical task in computer vision, yet it faces significant challenges in high-speed and low-light scenarios where standard RGB cameras suffer from motion blur. While event cameras offer a promising solution due to their high temporal resolution, current 6DoF pose estimation methods typically yield suboptimal performance in high-speed object moving scenarios. To address this gap, we propose PoseStreamer, a robust multi-modal 6DoF pose estimation framework designed specifically on high-speed moving scenarios. Our approach integrates three core components: an Adaptive Pose Memory Queue that utilizes historical orientation cues for temporal consistency, an Object-centric 2D Tracker that provides strong 2D priors to boost 3D center recall, and a Ray Pose Filter for geometric refinement along camera rays. Furthermore, we introduce MoCapCube6D, a novel multi-modal dataset constructed to benchmark performance under rapid motion. Extensive experiments demonstrate that PoseStreamer not only achieves superior accuracy in high-speed moving scenarios, but also exhibits strong generalizability as a template-free framework for unseen moving objects.

</details>


### [7] [RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models](https://arxiv.org/abs/2512.23239)
*Fan Wei,Runmin Dong,Yushan Lai,Yixiang Yang,Zhaoyang Luo,Jinxiao Zhang,Miao Yang,Shuai Yuan,Jiyao Zhao,Bin Luo,Haohuan Fu*

Main category: cs.CV

TL;DR: 提出一种免训练的两阶段数据剪枝方法，通过熵值筛选和场景感知聚类，在高剪枝率下选择高质量遥感图像子集，显著提升扩散基础模型的收敛速度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有遥感扩散基础模型依赖大量全局代表性数据，但这些数据通常包含冗余、噪声和类别不平衡问题，降低了训练效率并阻碍收敛。现有方法要么简单聚合多个分类数据集，要么应用简单的去重，忽视了生成建模的分布要求和遥感图像的异质性。

Method: 提出免训练的两阶段数据剪枝方法：1）基于熵的准则快速移除低信息样本；2）利用遥感场景分类数据集作为参考基准，进行场景感知聚类和分层采样，在平衡簇级均匀性和样本代表性的同时，实现高剪枝率下的细粒度选择。

Result: 即使剪枝85%的训练数据，该方法仍能显著改善收敛性和生成质量。使用该方法训练的扩散基础模型在下游任务（如超分辨率和语义图像合成）中持续达到最先进的性能。

Conclusion: 该数据剪枝范式为开发遥感生成基础模型提供了实用指导，能够在保持整体多样性和代表性的同时，通过高效数据选择提升模型训练效率和性能。

Abstract: Diffusion-based remote sensing (RS) generative foundation models are cruial for downstream tasks. However, these models rely on large amounts of globally representative data, which often contain redundancy, noise, and class imbalance, reducing training efficiency and preventing convergence. Existing RS diffusion foundation models typically aggregate multiple classification datasets or apply simplistic deduplication, overlooking the distributional requirements of generation modeling and the heterogeneity of RS imagery. To address these limitations, we propose a training-free, two-stage data pruning approach that quickly select a high-quality subset under high pruning ratios, enabling a preliminary foundation model to converge rapidly and serve as a versatile backbone for generation, downstream fine-tuning, and other applications. Our method jointly considers local information content with global scene-level diversity and representativeness. First, an entropy-based criterion efficiently removes low-information samples. Next, leveraging RS scene classification datasets as reference benchmarks, we perform scene-aware clustering with stratified sampling to improve clustering effectiveness while reducing computational costs on large-scale unlabeled data. Finally, by balancing cluster-level uniformity and sample representativeness, the method enables fine-grained selection under high pruning ratios while preserving overall diversity and representativeness. Experiments show that, even after pruning 85\% of the training data, our method significantly improves convergence and generation quality. Furthermore, diffusion foundation models trained with our method consistently achieve state-of-the-art performance across downstream tasks, including super-resolution and semantic image synthesis. This data pruning paradigm offers practical guidance for developing RS generative foundation models.

</details>


### [8] [Contour Information Aware 2D Gaussian Splatting for Image Representation](https://arxiv.org/abs/2512.23255)
*Masaya Takabe,Hiroshi Watanabe,Sujun Hong,Tomohiro Ikai,Zheming Fan,Ryo Ishimoto,Kakeru Sugimoto,Ruri Imichi*

Main category: cs.CV

TL;DR: 提出一种轮廓信息感知的2D高斯泼溅框架，通过融入物体分割先验来改善图像表示中的边界清晰度问题


<details>
  <summary>Details</summary>
Motivation: 现有的2D高斯泼溅方法在少量高斯分布情况下会产生模糊或不清晰的边界，缺乏轮廓感知能力，这限制了其在压缩场景下的图像表示质量

Method: 提出轮廓信息感知的2D高斯泼溅框架，将物体分割先验融入高斯表示中，通过约束每个高斯分布在特定分割区域内进行光栅化，防止跨边界混合；同时引入预热方案来稳定训练并改善收敛

Result: 在合成色卡和DAVIS数据集上的实验表明，该方法在物体边缘区域实现了比现有2DGS方法更高的重建质量，特别是在高斯数量很少的情况下改进尤为明显，同时保持了快速渲染和低内存使用

Conclusion: 通过融入分割先验和约束高斯分布区域，提出的轮廓信息感知2D高斯泼溅框架有效解决了边界模糊问题，在保持高效性的同时显著提升了图像表示质量

Abstract: Image representation is a fundamental task in computer vision. Recently, Gaussian Splatting has emerged as an efficient representation framework, and its extension to 2D image representation enables lightweight, yet expressive modeling of visual content. While recent 2D Gaussian Splatting (2DGS) approaches provide compact storage and real-time decoding, they often produce blurry or indistinct boundaries when the number of Gaussians is small due to the lack of contour awareness. In this work, we propose a Contour Information-Aware 2D Gaussian Splatting framework that incorporates object segmentation priors into Gaussian-based image representation. By constraining each Gaussian to a specific segmentation region during rasterization, our method prevents cross-boundary blending and preserves edge structures under high compression. We also introduce a warm-up scheme to stabilize training and improve convergence. Experiments on synthetic color charts and the DAVIS dataset demonstrate that our approach achieves higher reconstruction quality around object edges compared to existing 2DGS methods. The improvement is particularly evident in scenarios with very few Gaussians, while our method still maintains fast rendering and low memory usage.

</details>


### [9] [SoulX-LiveTalk Technical Report](https://arxiv.org/abs/2512.23379)
*Le Shen,Qiao Qian,Tan Yu,Ke Zhou,Tianhang Yu,Yu Zhan,Zhenjie Wang,Ming Tao,Shunshun Yin,Siyuan Liu*

Main category: cs.CV

TL;DR: SoulX-LiveTalk是一个14B参数框架，通过自校正双向蒸馏和多步回顾自校正机制，在保持高视觉保真度的同时实现实时音频驱动虚拟人生成，达到0.87秒启动延迟和32FPS实时吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大规模扩散模型在实时、无限时长、音频驱动的虚拟人生成中存在计算负载与严格延迟约束的冲突，现有方法通常通过强制单向注意力或降低模型容量来牺牲视觉保真度。

Method: 采用自校正双向蒸馏策略在视频块内保留双向注意力，保持关键时空相关性；引入多步回顾自校正机制防止无限生成中的错误累积；开发全栈推理加速套件，包括混合序列并行、并行VAE和内核级优化。

Result: SoulX-LiveTalk是首个14B规模系统，实现亚秒级启动延迟（0.87秒）和32FPS实时吞吐量，为高保真交互式数字人合成设定了新标准。

Conclusion: 该框架成功解决了实时音频驱动虚拟人生成中计算负载与延迟约束的冲突，通过创新的双向注意力保留和自校正机制，在保持高视觉保真度的同时实现了实时性能。

Abstract: Deploying massive diffusion models for real-time, infinite-duration, audio-driven avatar generation presents a significant engineering challenge, primarily due to the conflict between computational load and strict latency constraints. Existing approaches often compromise visual fidelity by enforcing strictly unidirectional attention mechanisms or reducing model capacity. To address this problem, we introduce \textbf{SoulX-LiveTalk}, a 14B-parameter framework optimized for high-fidelity real-time streaming. Diverging from conventional unidirectional paradigms, we use a \textbf{Self-correcting Bidirectional Distillation} strategy that retains bidirectional attention within video chunks. This design preserves critical spatiotemporal correlations, significantly enhancing motion coherence and visual detail. To ensure stability during infinite generation, we incorporate a \textbf{Multi-step Retrospective Self-Correction Mechanism}, enabling the model to autonomously recover from accumulated errors and preventing collapse. Furthermore, we engineered a full-stack inference acceleration suite incorporating hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations. Extensive evaluations confirm that SoulX-LiveTalk is the first 14B-scale system to achieve a \textbf{sub-second start-up latency (0.87s)} while reaching a real-time throughput of \textbf{32 FPS}, setting a new standard for high-fidelity interactive digital human synthesis.

</details>


### [10] [AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization](https://arxiv.org/abs/2512.23537)
*Binhe Yu,Zhen Wang,Kexin Li,Yuqian Yuan,Wenqiao Zhang,Long Chen,Juncheng Li,Jun Xiao,Yueting Zhuang*

Main category: cs.CV

TL;DR: AnyMS：无需训练的布局引导多主体定制框架，通过双级注意力解耦机制平衡文本对齐、主体身份保持和布局控制


<details>
  <summary>Details</summary>
Motivation: 现有多主体定制方法在平衡文本对齐、主体身份保持和布局控制三个关键目标方面存在困难，且依赖额外训练限制了可扩展性和效率

Method: 提出AnyMS训练免费框架，采用底部向上的双级注意力解耦机制：全局解耦分离文本和视觉条件的交叉注意力确保文本对齐；局部解耦将每个主体的注意力限制在指定区域防止冲突，保证身份保持和布局控制

Result: 实验证明AnyMS达到最先进性能，支持复杂构图并扩展到更多主体数量

Conclusion: AnyMS通过创新的注意力解耦机制解决了多主体定制中的关键平衡问题，无需训练提高了可扩展性和效率

Abstract: Multi-subject customization aims to synthesize multiple user-specified subjects into a coherent image. To address issues such as subjects missing or conflicts, recent works incorporate layout guidance to provide explicit spatial constraints. However, existing methods still struggle to balance three critical objectives: text alignment, subject identity preservation, and layout control, while the reliance on additional training further limits their scalability and efficiency. In this paper, we present AnyMS, a novel training-free framework for layout-guided multi-subject customization. AnyMS leverages three input conditions: text prompt, subject images, and layout constraints, and introduces a bottom-up dual-level attention decoupling mechanism to harmonize their integration during generation. Specifically, global decoupling separates cross-attention between textual and visual conditions to ensure text alignment. Local decoupling confines each subject's attention to its designated area, which prevents subject conflicts and thus guarantees identity preservation and layout control. Moreover, AnyMS employs pre-trained image adapters to extract subject-specific features aligned with the diffusion model, removing the need for subject learning or adapter tuning. Extensive experiments demonstrate that AnyMS achieves state-of-the-art performance, supporting complex compositions and scaling to a larger number of subjects.

</details>


### [11] [LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation](https://arxiv.org/abs/2512.23576)
*Ethan Chern,Zhulin Hu,Bohao Tang,Jiadi Su,Steffi Chern,Zhijie Deng,Pengfei Liu*

Main category: cs.CV

TL;DR: 本文提出一种实时交互式视频扩散模型蒸馏方法，通过改进蒸馏配方解决多模态条件输入下的视觉伪影问题，实现20倍推理加速，并构建了LiveTalk实时多模态交互化身系统。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型采用双向注意力迭代去噪，无法实现实时交互。虽然蒸馏方法可以减少采样步骤，但主要针对文本到视频生成，在多模态条件（文本、图像、音频）下的人类-AI交互仍不自然且效率低下。Self Forcing蒸馏方法在多模态条件下存在闪烁、黑帧等视觉伪影和质量下降问题。

Method: 提出改进的蒸馏配方，重点关注条件输入质量以及在线策略优化的初始化和调度。在HDTF、AVSpeech和CelebV-HQ等多模态条件化身视频生成基准上验证。将模型与音频语言模型和长视频推理技术Anchor-Heavy Identity Sinks集成，构建LiveTalk实时多模态交互化身系统。

Result: 蒸馏模型在视觉质量上与完整步骤双向基线相当，推理成本和延迟降低20倍。LiveTalk系统在精心策划的多轮交互基准上，在多轮视频连贯性和内容质量方面优于Sora2、Veo3等最先进模型，将响应延迟从1-2分钟降低到实时生成。

Conclusion: 通过改进的蒸馏方法实现了实时多模态交互视频生成，显著降低了推理延迟，使人类-AI多模态交互更加自然流畅。LiveTalk系统展示了实时交互式化身视频生成的可行性，为构建通用多模态交互AI系统奠定了基础。

Abstract: Real-time video generation via diffusion is essential for building general-purpose multimodal interactive AI systems. However, the simultaneous denoising of all video frames with bidirectional attention via an iterative process in diffusion models prevents real-time interaction. While existing distillation methods can make the model autoregressive and reduce sampling steps to mitigate this, they focus primarily on text-to-video generation, leaving the human-AI interaction unnatural and less efficient. This paper targets real-time interactive video diffusion conditioned on a multimodal context, including text, image, and audio, to bridge the gap. Given the observation that the leading on-policy distillation approach Self Forcing encounters challenges (visual artifacts like flickering, black frames, and quality degradation) with multimodal conditioning, we investigate an improved distillation recipe with emphasis on the quality of condition inputs as well as the initialization and schedule for the on-policy optimization. On benchmarks for multimodal-conditioned (audio, image, and text) avatar video generation including HDTF, AVSpeech, and CelebV-HQ, our distilled model matches the visual quality of the full-step, bidirectional baselines of similar or larger size with 20x less inference cost and latency. Further, we integrate our model with audio language models and long-form video inference technique Anchor-Heavy Identity Sinks to build LiveTalk, a real-time multimodal interactive avatar system. System-level evaluation on our curated multi-turn interaction benchmark shows LiveTalk outperforms state-of-the-art models (Sora2, Veo3) in multi-turn video coherence and content quality, while reducing response latency from 1 to 2 minutes to real-time generation, enabling seamless human-AI multimodal interaction.

</details>


### [12] [Memorization in 3D Shape Generation: An Empirical Study](https://arxiv.org/abs/2512.23628)
*Shu Pu,Boya Zeng,Kaichen Zhou,Mengyu Wang,Zhuang Liu*

Main category: cs.CV

TL;DR: 本文提出一个评估框架来量化3D生成模型的记忆效应，并通过实验发现数据模态、多样性、细粒度条件以及模型设计（如引导尺度、向量集长度、旋转增强）都会影响记忆程度，同时提出了减少记忆而不降低生成质量的策略。


<details>
  <summary>Details</summary>
Motivation: 3D生成模型在合成新形状时是否依赖记忆训练数据尚不明确。理解这种记忆效应有助于防止训练数据泄露并提高生成结果的多样性。

Method: 设计了一个评估框架来量化3D生成模型的记忆效应，首先应用于现有方法，然后通过控制实验使用潜在向量集扩散模型研究数据和建模设计对记忆的影响。

Result: 发现：数据方面，记忆取决于数据模态，随数据多样性和细粒度条件增加而增加；建模方面，记忆在中等引导尺度达到峰值，可通过更长的向量集和简单旋转增强来缓解。

Conclusion: 该框架和分析提供了对3D生成模型记忆效应的实证理解，并提出了简单有效的策略来减少记忆而不降低生成质量。

Abstract: Generative models are increasingly used in 3D vision to synthesize novel shapes, yet it remains unclear whether their generation relies on memorizing training shapes. Understanding their memorization could help prevent training data leakage and improve the diversity of generated results. In this paper, we design an evaluation framework to quantify memorization in 3D generative models and study the influence of different data and modeling designs on memorization. We first apply our framework to quantify memorization in existing methods. Next, through controlled experiments with a latent vector-set (Vecset) diffusion model, we find that, on the data side, memorization depends on data modality, and increases with data diversity and finer-grained conditioning; on the modeling side, it peaks at a moderate guidance scale and can be mitigated by longer Vecsets and simple rotation augmentation. Together, our framework and analysis provide an empirical understanding of memorization in 3D generative models and suggest simple yet effective strategies to reduce it without degrading generation quality. Our code is available at https://github.com/zlab-princeton/3d_mem.

</details>


### [13] [OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding](https://arxiv.org/abs/2512.23646)
*Keda Tao,Wenjie Du,Bohan Yu,Weiqiang Wang,Jian Liu,Huan Wang*

Main category: cs.CV

TL;DR: OmniAgent：一种完全音频引导的主动感知智能体，通过动态编排专用工具实现细粒度视听推理，在多个基准测试中超越现有模型10-20%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有全模态大语言模型在统一音频和视觉模态方面取得进展，但缺乏细粒度跨模态理解能力，难以实现多模态对齐。需要从被动响应生成转向主动多模态查询。

Method: 提出完全音频引导的主动感知智能体，采用动态规划自主编排工具调用，通过粗到细的音频引导感知范式，利用音频线索定位时间事件并指导后续推理。

Result: 在三个音频-视频理解基准测试中取得最先进性能，超越领先的开源和专有模型10-20%的准确率。

Conclusion: OmniAgent实现了从被动响应生成到主动多模态查询的范式转变，通过动态工具编排和音频引导感知显著提升了细粒度视听推理能力。

Abstract: Omnimodal large language models have made significant strides in unifying audio and visual modalities; however, they often lack the fine-grained cross-modal understanding and have difficulty with multimodal alignment. To address these limitations, we introduce OmniAgent, a fully audio-guided active perception agent that dynamically orchestrates specialized tools to achieve more fine-grained audio-visual reasoning. Unlike previous works that rely on rigid, static workflows and dense frame-captioning, this paper demonstrates a paradigm shift from passive response generation to active multimodal inquiry. OmniAgent employs dynamic planning to autonomously orchestrate tool invocation on demand, strategically concentrating perceptual attention on task-relevant cues. Central to our approach is a novel coarse-to-fine audio-guided perception paradigm, which leverages audio cues to localize temporal events and guide subsequent reasoning. Extensive empirical evaluations on three audio-video understanding benchmarks demonstrate that OmniAgent achieves state-of-the-art performance, surpassing leading open-source and proprietary models by substantial margins of 10% - 20% accuracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents](https://arxiv.org/abs/2512.22200)
*Dhruv Tiwari*

Main category: cs.LG

TL;DR: 论文提出EILS框架，用类似生物情感的连续稳态信号（好奇心、压力、自信）作为内部反馈机制，替代传统静态奖励函数，以增强AI在开放环境中的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前AI依赖外部定义的静态奖励函数，在封闭环境中表现优异但在开放、非平稳的真实世界中脆弱。标准智能体缺乏内部自主性：难以在没有密集反馈下探索、无法适应分布变化、需要大量手动调参。论文认为生物情感的功能类似物是鲁棒自主性的关键因素。

Method: 提出情感启发学习信号（EILS）框架，将情感建模为连续的稳态评估信号（好奇心、压力、自信），而非语义标签。这些信号是从交互历史中导出的向量值内部状态，实时动态调节智能体的优化景观：好奇心调节熵防止模式崩溃，压力调节可塑性克服不活跃，自信调整信任区域稳定收敛。

Result: 论文假设这种闭环稳态调节能使EILS智能体在样本效率和非平稳适应方面优于标准基线方法。

Conclusion: EILS提供了一个统一的生物启发内部反馈引擎，用连贯的情感类似信号替代分散的优化启发式方法，有望解决当前AI在开放环境中鲁棒性不足的问题。

Abstract: The ruling method in modern Artificial Intelligence spanning from Deep Reinforcement Learning (DRL) to Large Language Models (LLMs) relies on a surge of static, externally defined reward functions. While this "extrinsic maximization" approach has rendered superhuman performance in closed, stationary fields, it produces agents that are fragile in open-ended, real-world environments. Standard agents lack internal autonomy: they struggle to explore without dense feedback, fail to adapt to distribution shifts (non-stationarity), and require extensive manual tuning of static hyperparameters. This paper proposes that the unaddressed factor in robust autonomy is a functional analog to biological emotion, serving as a high-level homeostatic control mechanism. We introduce Emotion-Inspired Learning Signals (EILS), a unified framework that replaces scattered optimization heuristics with a coherent, bio-inspired internal feedback engine. Unlike traditional methods that treat emotions as semantic labels, EILS models them as continuous, homeostatic appraisal signals such as Curiosity, Stress, and Confidence. We formalize these signals as vector-valued internal states derived from interaction history. These states dynamically modulate the agent's optimization landscape in real time: curiosity regulates entropy to prevent mode collapse, stress modulates plasticity to overcome inactivity, and confidence adapts trust regions to stabilize convergence. We hypothesize that this closed-loop homeostatic regulation can enable EILS agents to outperform standard baselines in terms of sample efficiency and non-stationary adaptation.

</details>


### [15] [Valori: A Deterministic Memory Substrate for AI Systems](https://arxiv.org/abs/2512.22280)
*Varshith Gudur*

Main category: cs.LG

TL;DR: Valori提出确定性AI内存基板，使用定点算术替代浮点运算，确保跨平台比特级一致的内存状态和检索结果


<details>
  <summary>Details</summary>
Motivation: 现代AI系统依赖浮点算术进行向量嵌入存储和搜索，但相同模型、输入和代码在不同硬件架构（如x86 vs ARM）上会产生不同的内存状态和检索结果，导致不可重现性和安全部署问题，影响受监管行业的审计追踪

Method: 使用定点算术（Q16.16）替代浮点内存操作，将内存建模为可重现的状态机，在内存边界强制执行确定性

Result: Valori保证跨平台的比特级相同内存状态、快照和搜索结果，证明非确定性出现在索引或检索之前，确定性内存是可信AI系统的必要基础

Conclusion: 确定性内存是构建可信AI系统的关键基础组件，Valori提供了开源实现，确保AI系统在不同硬件平台上的一致性和可重现性

Abstract: Modern AI systems rely on vector embeddings stored and searched using floating-point arithmetic. While effective for approximate similarity search, this design introduces fundamental non-determinism: identical models, inputs, and code can produce different memory states and retrieval results across hardware architectures (e.g., x86 vs. ARM). This prevents replayability and safe deployment, leading to silent data divergence that prevents post-hoc verification and compromises audit trails in regulated sectors. We present Valori, a deterministic AI memory substrate that replaces floating-point memory operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. Valori guarantees bit-identical memory states, snapshots, and search results across platforms. We demonstrate that non-determinism arises before indexing or retrieval and show how Valori enforces determinism at the memory boundary. Our results suggest that deterministic memory is a necessary primitive for trustworthy AI systems. The reference implementation is open-source and available at https://github.com/varshith-Git/Valori-Kernel (archived at https://zenodo.org/records/18022660).

</details>


### [16] [Multi-Head Spectral-Adaptive Graph Anomaly Detection](https://arxiv.org/abs/2512.22291)
*Qingyue Cao,Bo Jin,Changwei Gong,Xin Tong,Wenzheng Li,Xiaodong Zhou*

Main category: cs.LG

TL;DR: 提出MHSA-GNN方法，通过轻量级超网络动态生成Chebyshev滤波器参数，结合双正则化策略解决图异常检测中异常节点伪装和异质性共存的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法在处理复杂多变的异常模式时面临挑战，异常节点常伪装与正常节点混合，导致图中同质性和异质性共存。现有谱图神经网络使用固定全局滤波器，容易导致过平滑，抹去欺诈检测所需的高频信号，且缺乏对不同图实例的自适应能力。

Method: 提出多头谱自适应图神经网络(MHSA-GNN)：1) 设计轻量级超网络，基于包含结构统计和Rayleigh商特征的"谱指纹"，动态生成针对每个实例的Chebyshev滤波器参数；2) 引入双正则化策略防止多头机制模式崩溃，结合师生对比学习保证表示准确性，使用Barlow Twins多样性损失强制头间正交性。

Result: 在四个真实世界数据集上的大量实验表明，该方法能有效保留高频异常信号，显著优于现有最先进方法，在高度异质性数据集上表现出优秀的鲁棒性。

Conclusion: MHSA-GNN通过实例自适应的谱滤波器和双正则化策略，成功解决了图异常检测中异常信号保留和异质性处理的问题，为金融欺诈和风控等应用提供了更有效的解决方案。

Abstract: Graph anomaly detection technology has broad applications in financial fraud and risk control. However, existing graph anomaly detection methods often face significant challenges when dealing with complex and variable abnormal patterns, as anomalous nodes are often disguised and mixed with normal nodes, leading to the coexistence of homophily and heterophily in the graph domain. Recent spectral graph neural networks have made notable progress in addressing this issue; however, current techniques typically employ fixed, globally shared filters. This 'one-size-fits-all' approach can easily cause over-smoothing, erasing critical high-frequency signals needed for fraud detection, and lacks adaptive capabilities for different graph instances. To solve this problem, we propose a Multi-Head Spectral-Adaptive Graph Neural Network (MHSA-GNN). The core innovation is the design of a lightweight hypernetwork that, conditioned on a 'spectral fingerprint' containing structural statistics and Rayleigh quotient features, dynamically generates Chebyshev filter parameters tailored to each instance. This enables a customized filtering strategy for each node and its local subgraph. Additionally, to prevent mode collapse in the multi-head mechanism, we introduce a novel dual regularization strategy that combines teacher-student contrastive learning (TSC) to ensure representation accuracy and Barlow Twins diversity loss (BTD) to enforce orthogonality among heads. Extensive experiments on four real-world datasets demonstrate that our method effectively preserves high-frequency abnormal signals and significantly outperforms existing state-of-the-art methods, especially showing excellent robustness on highly heterogeneous datasets.

</details>


### [17] [LangPrecip: Language-Aware Multimodal Precipitation Nowcasting](https://arxiv.org/abs/2512.22317)
*Xudong Ling,Tianxi Huang,Qian Dong,Tao He,Chaorong Li,Guiduo Duan*

Main category: cs.LG

TL;DR: LangPrecip：一个语言感知的多模态降水临近预报框架，通过将气象文本作为降水演化的语义运动约束，在Rectified Flow范式下实现文本和雷达信息的有效融合，显著提升强降水预报精度。


<details>
  <summary>Details</summary>
Motivation: 短期降水临近预报具有高度不确定性和约束不足的特点，现有生成方法主要依赖视觉条件，导致未来运动约束弱且模糊。需要更强的语义约束来提升预报准确性。

Method: 提出语言感知多模态临近预报框架，将气象文本作为降水演化的语义运动约束，在Rectified Flow范式下将临近预报建模为语义约束的轨迹生成问题，在潜在空间实现文本和雷达信息的有效融合。

Result: 在瑞典和MRMS数据集上实验显示，相比现有最优方法，在80分钟预报时效下，强降水CSI指标分别提升超过60%和19%。

Conclusion: LangPrecip框架通过引入语言约束显著提升了降水临近预报性能，特别是在强降水事件中表现优异，证明了多模态信息融合在气象预报中的重要性。

Abstract: Short-term precipitation nowcasting is an inherently uncertain and under-constrained spatiotemporal forecasting problem, especially for rapidly evolving and extreme weather events. Existing generative approaches rely primarily on visual conditioning, leaving future motion weakly constrained and ambiguous. We propose a language-aware multimodal nowcasting framework(LangPrecip) that treats meteorological text as a semantic motion constraint on precipitation evolution. By formulating nowcasting as a semantically constrained trajectory generation problem under the Rectified Flow paradigm, our method enables efficient and physically consistent integration of textual and radar information in latent space.We further introduce LangPrecip-160k, a large-scale multimodal dataset with 160k paired radar sequences and motion descriptions. Experiments on Swedish and MRMS datasets show consistent improvements over state-of-the-art methods, achieving over 60 \% and 19\% gains in heavy-rainfall CSI at an 80-minute lead time.

</details>


### [18] [Causality-Inspired Safe Residual Correction for Multivariate Time Series](https://arxiv.org/abs/2512.22428)
*Jianxiang Xie,Yuncheng Hua*

Main category: cs.LG

TL;DR: CRC是一个因果启发的安全残差校正框架，通过解耦自变量和交叉变量动态，并采用四重安全机制确保性能不退化，实现安全可靠的预测校正。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer和GNN等多元预测模型存在系统误差，且缺乏部署时的性能退化保证。传统残差校正方法虽然可能提高平均准确率，但可能"错误地帮助"——过度校正可靠预测并在未见场景中导致局部失败。

Method: CRC采用分而治之策略：1) 因果启发编码器通过解耦自变量和交叉变量动态来暴露方向感知结构；2) 混合校正器建模残差误差；3) 关键的四重安全机制严格控制校正过程，防止有害更新。

Result: 在多个数据集和预测骨干网络上的实验表明，CRC能持续提高准确率。消融研究证实其核心安全机制确保了极高的非退化率(NDR)，使其适合安全可靠的部署。

Conclusion: CRC是一个即插即用的安全残差校正框架，通过因果启发结构和严格安全机制，解决了预测模型在部署中的"安全差距"问题，确保性能不退化。

Abstract: While modern multivariate forecasters such as Transformers and GNNs achieve strong benchmark performance, they often suffer from systematic errors at specific variables or horizons and, critically, lack guarantees against performance degradation in deployment. Existing post-hoc residual correction methods attempt to fix these errors, but are inherently greedy: although they may improve average accuracy, they can also "help in the wrong way" by overcorrecting reliable predictions and causing local failures in unseen scenarios.
  To address this critical "safety gap," we propose CRC (Causality-inspired Safe Residual Correction), a plug-and-play framework explicitly designed to ensure non-degradation. CRC follows a divide-and-conquer philosophy: it employs a causality-inspired encoder to expose direction-aware structure by decoupling self- and cross-variable dynamics, and a hybrid corrector to model residual errors. Crucially, the correction process is governed by a strict four-fold safety mechanism that prevents harmful updates.
  Experiments across multiple datasets and forecasting backbones show that CRC consistently improves accuracy, while an in-depth ablation study confirms that its core safety mechanisms ensure exceptionally high non-degradation rates (NDR), making CRC a correction framework suited for safe and reliable deployment.

</details>


### [19] [Predictive Modeling of Power Outages during Extreme Events: Integrating Weather and Socio-Economic Factors](https://arxiv.org/abs/2512.22699)
*Antar Kumar Biswas,Masoud H. Nazari*

Main category: cs.LG

TL;DR: 提出基于机器学习预测极端事件导致停电的框架，整合多源数据，LSTM模型表现最佳，发现经济条件和基础设施发展与停电风险负相关


<details>
  <summary>Details</summary>
Motivation: 针对低概率高后果的停电场景，需要准确预测极端事件导致的停电风险，以支持应急响应和基础设施规划

Method: 整合EAGLE-I停电记录（2014-2024）与天气、社会经济、基础设施和季节性事件数据，评估四种机器学习模型：随机森林、支持向量机、自适应提升和长短期记忆网络

Result: 在密歇根州下半岛的大规模数据集上验证，LSTM网络获得最低预测误差，结果显示经济条件更强、基础设施更发达的地区停电发生率更低

Conclusion: 提出的学习框架能有效预测极端事件导致的停电风险，LSTM模型表现最佳，社会经济和基础设施特征是重要预测因子

Abstract: This paper presents a novel learning-based framework for predicting power outages caused by extreme events. The proposed approach specifically targets low-probability, high-consequence outage scenarios and leverages a comprehensive set of features derived from publicly available data sources. We integrate EAGLE-I outage records (2014-2024) with weather, socio-economic, infrastructure, and seasonal event data. Incorporating social and demographic indicators reveals underlying patterns of community vulnerability and provides a clearer understanding of outage risk during extreme conditions. Four machine learning models (Random Forest (RF), Support Vector Machine (SVM), Adaptive Boosting (AdaBoost), and Long Short-Term Memory (LSTM)) are evaluated. Experimental validation is performed on a large-scale dataset covering counties in the lower peninsula of Michigan. Among all models tested, the LSTM network achieves the lowest prediction error. Additionally, the results demonstrate that stronger economic conditions and more developed infrastructure are associated with lower outage occurrence.

</details>


### [20] [Debugging Tabular Log as Dynamic Graphs](https://arxiv.org/abs/2512.22903)
*Chumeng Liang,Zhanyang Jin,Zahaib Akhtar,Mona Pereira,Haofei Yu,Jiaxuan You*

Main category: cs.LG

TL;DR: 提出GraphLogDebugger框架，通过动态图建模表格日志，使用简单动态GNN即可超越LLM在日志调试中的性能


<details>
  <summary>Details</summary>
Motivation: 表格日志记录了现实世界系统和事件的抽象更新，可用于检测系统不一致性。但现有处理文本丰富表格日志的方法过度依赖LLM等重型模型，导致灵活性和可扩展性受限。

Method: 提出GraphLogDebugger框架，为对象和事件构建异构节点并连接节点边，将表格日志背后的系统恢复为演化动态图。通过动态图建模，使用简单的动态图神经网络进行调试。

Result: 在计算机系统和学术论文的真实日志数据集上的实验结果表明，基于动态图建模的简单动态GNN在调试表格日志方面能够超越LLM的性能。

Conclusion: GraphLogDebugger框架通过动态图建模表格日志，使用轻量级动态GNN即可实现优于LLM的调试性能，解决了现有方法依赖重型模型导致的灵活性和可扩展性问题。

Abstract: Tabular log abstracts objects and events in the real-world system and reports their updates to reflect the change of the system, where one can detect real-world inconsistencies efficiently by debugging corresponding log entries. However, recent advances in processing text-enriched tabular log data overly depend on large language models (LLMs) and other heavy-load models, thus suffering from limited flexibility and scalability. This paper proposes a new framework, GraphLogDebugger, to debug tabular log based on dynamic graphs. By constructing heterogeneous nodes for objects and events and connecting node-wise edges, the framework recovers the system behind the tabular log as an evolving dynamic graph. With the help of our dynamic graph modeling, a simple dynamic Graph Neural Network (GNN) is representative enough to outperform LLMs in debugging tabular log, which is validated by experimental results on real-world log datasets of computer systems and academic papers.

</details>


### [21] [GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks](https://arxiv.org/abs/2512.22772)
*Xuyan Li,Jie Wang,Zheng Yan*

Main category: cs.LG

TL;DR: GRExplainer：首个通用、高效且用户友好的TGNN解释方法，通过节点序列统一表示、BFS搜索和RNN生成模型，解决现有TGNN解释方法通用性差、计算成本高、用户不友好等问题。


<details>
  <summary>Details</summary>
Motivation: TGNN在处理动态图方面表现出色，但缺乏透明度和可解释性限制了实际应用。现有TGNN解释方法存在三个主要问题：1）针对特定TGNN类型，通用性差；2）计算成本高，不适合大规模网络；3）忽略解释的结构连通性且需要先验知识，用户不友好。

Method: 提出GRExplainer方法：1）提取节点序列作为统一特征表示，使其独立于特定输入格式，适用于基于快照和基于事件的TGNN；2）利用广度优先搜索和时序信息构建输入节点序列，减少冗余计算；3）设计基于RNN的生成模型，实现自动化连续解释生成。

Result: 在6个真实世界数据集和3个目标TGNN上的实验表明，GRExplainer在通用性、效率和用户友好性方面优于现有基线方法。

Conclusion: GRExplainer是首个通用、高效且用户友好的TGNN解释方法，解决了现有方法的局限性，为TGNN的可解释性提供了有效解决方案。

Abstract: Dynamic graphs are widely used to represent evolving real-world networks. Temporal Graph Neural Networks (TGNNs) have emerged as a powerful tool for processing such graphs, but the lack of transparency and explainability limits their practical adoption. Research on TGNN explainability is still in its early stages and faces several key issues: (i) Current methods are tailored to specific TGNN types, restricting generality. (ii) They suffer from high computational costs, making them unsuitable for large-scale networks. (iii) They often overlook the structural connectivity of explanations and require prior knowledge, reducing user-friendliness. To address these issues, we propose GRExplainer, the first universal, efficient, and user-friendly explanation method for TGNNs. GRExplainer extracts node sequences as a unified feature representation, making it independent of specific input formats and thus applicable to both snapshot-based and event-based TGNNs (the major types of TGNNs). By utilizing breadth-first search and temporal information to construct input node sequences, GRExplainer reduces redundant computation and improves efficiency. To enhance user-friendliness, we design a generative model based on Recurrent Neural Networks (RNNs), enabling automated and continuous explanation generation. Experiments on six real-world datasets with three target TGNNs show that GRExplainer outperforms existing baseline methods in generality, efficiency, and user-friendliness.

</details>


### [22] [PFed-Signal: An ADR Prediction Model based on Federated Learning](https://arxiv.org/abs/2512.23262)
*Tao Li,Peilin Li,Kui Lu,Yilei Wang,Junliang Shang,Guangshun Li,Huiyu Zhou*

Main category: cs.LG

TL;DR: PFed-signal：基于联邦学习的ADR信号预测模型，利用欧氏距离消除FAERS中的偏差数据，提高ADR预测准确性


<details>
  <summary>Details</summary>
Motivation: 基于FAERS偏差记录的ADR预测可能误导在线诊断，传统基于ROR/PRR的统计方法无法消除偏差数据，导致信号预测不准确

Method: 提出PFed-signal联邦学习模型：1) Pfed-Split方法按ADR分割原始数据集；2) ADR-signal模型包含基于联邦学习的偏差数据识别（使用欧氏距离）和基于Transformer的ADR预测模型

Result: 清洁数据集上的ROR和PRR优于传统方法；PFed-signal的准确率0.887、F1分数0.890、召回率0.913、AUC 0.957，均优于基线方法

Conclusion: PFed-signal通过联邦学习和欧氏距离有效消除FAERS偏差数据，显著提高ADR预测准确性，优于传统统计方法

Abstract: The adverse drug reactions (ADRs) predicted based on the biased records in FAERS (U.S. Food and Drug Administration Adverse Event Reporting System) may mislead diagnosis online. Generally, such problems are solved by optimizing reporting odds ratio (ROR) or proportional reporting ratio (PRR). However, these methods that rely on statistical methods cannot eliminate the biased data, leading to inaccurate signal prediction. In this paper, we propose PFed-signal, a federated learning-based signal prediction model of ADR, which utilizes the Euclidean distance to eliminate the biased data from FAERS, thereby improving the accuracy of ADR prediction. Specifically, we first propose Pfed-Split, a method to split the original dataset into a split dataset based on ADR. Then we propose ADR-signal, an ADR prediction model, including a biased data identification method based on federated learning and an ADR prediction model based on Transformer. The former identifies the biased data according to the Euclidean distance and generates a clean dataset by deleting the biased data. The latter is an ADR prediction model based on Transformer trained on the clean data set. The results show that the ROR and PRR on the clean dataset are better than those of the traditional methods. Furthermore, the accuracy rate, F1 score, recall rate and AUC of PFed-Signal are 0.887, 0.890, 0.913 and 0.957 respectively, which are higher than the baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Bidirectional RAG: Safe Self-Improving Retrieval-Augmented Generation Through Multi-Stage Validation](https://arxiv.org/abs/2512.22199)
*Teja Chinthala*

Main category: cs.AI

TL;DR: Bidirectional RAG 是一种新型检索增强生成架构，通过验证高质量生成响应的写回机制实现安全的语料库扩展，相比标准RAG将覆盖率提升近一倍，同时减少72%的文档添加。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用静态知识库，无法从用户交互中学习和进化，限制了系统的持续改进能力。需要一种既能扩展知识库又能防止幻觉污染的安全机制。

Method: 提出Bidirectional RAG架构，采用多阶段接受层，结合基于NLI的蕴含验证、归因检查和新颖性检测，确保高质量生成响应的安全写回，实现语料库的受控扩展。

Result: 在四个数据集（Natural Questions, TriviaQA, HotpotQA, Stack Overflow）上，Bidirectional RAG达到40.58%的平均覆盖率，几乎是标准RAG（20.33%）的两倍，同时比朴素写回方法减少72%的文档添加（140 vs 500）。

Conclusion: 研究表明，通过严格验证机制，自改进的RAG系统是可行且安全的，为从部署中学习的RAG系统提供了实用路径，实现了知识的安全积累和系统性能的持续提升。

Abstract: Retrieval-Augmented Generation RAG systems enhance large language models by grounding responses in external knowledge bases, but conventional RAG architectures operate with static corpora that cannot evolve from user interactions. We introduce Bidirectional RAG, a novel RAG architecture that enables safe corpus expansion through validated write back of high quality generated responses. Our system employs a multi stage acceptance layer combining grounding verification (NLI based entailment, attribution checking, and novelty detection to prevent hallucination pollution while enabling knowledge accumulation. Across four datasets Natural Questions, TriviaQA, HotpotQA, Stack Overflow with three random seeds 12 experiments per system, Bidirectional RAG achieves 40.58% average coverage nearly doubling Standard RAG 20.33% while adding 72% fewer documents than naive write back 140 vs 500. Our work demonstrates that self improving RAG is feasible and safe when governed by rigorous validation, offering a practical path toward RAG systems that learn from deployment.

</details>


### [24] [Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities](https://arxiv.org/abs/2512.23508)
*Alessio Benavoli,Alessandro Facchini,Marco Zaffalon*

Main category: cs.AI

TL;DR: 论文探讨如何确保AI系统与人类价值观对齐并保持安全，通过AI辅助和AI关机游戏框架研究该问题，指出解决这些挑战需要AI代理能够处理不确定性和非阿基米德偏好。


<details>
  <summary>Details</summary>
Motivation: 确保AI系统与人类价值观对齐并保持安全是重要挑战。AI辅助问题涉及设计能够帮助人类最大化其效用函数的AI代理，但只有人类知道这些函数；关机问题涉及设计能够在按下关机按钮时关闭、不试图阻止或导致按钮按下、同时能胜任完成任务的AI代理。

Method: 通过AI辅助游戏和AI关机游戏的理论框架来研究这些问题。AI辅助游戏关注AI代理学习人类未知效用函数的问题；AI关机游戏关注AI代理在关机场景中的行为规范。论文提出解决这些挑战需要AI代理具备在不确定性下推理的能力，并能处理不完全偏好和非阿基米德偏好。

Result: 分析表明，要解决AI对齐和安全问题，AI系统必须能够：1）在不确定性下进行推理；2）处理不完全偏好（人类效用函数未知）；3）处理非阿基米德偏好（不同价值维度无法简单比较）。这些能力对于设计安全的AI辅助系统和可控制的AI关机机制至关重要。

Conclusion: 确保AI系统与人类价值观对齐并保持安全需要AI代理具备处理不确定性和复杂偏好的能力。通过AI辅助和AI关机游戏框架，可以系统地研究这些对齐问题，为设计安全可靠的AI系统提供理论基础。未来的AI系统需要能够推理不确定性、学习人类偏好并处理非阿基米德价值比较。

Abstract: How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [25] [NepEMO: A Multi-Label Emotion and Sentiment Analysis on Nepali Reddit with Linguistic Insights and Temporal Trends](https://arxiv.org/abs/2512.22823)
*Sameer Sitoula,Tej Bahadur Shahi,Laxmi Prasad Bhatt,Anisha Pokhrel,Arjun Neupane*

Main category: cs.CL

TL;DR: 研究者构建了NepEMO数据集，包含4,462条尼泊尔语Reddit帖子，用于多标签情感和情感分类任务，并比较了多种机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台如Reddit为用户提供了匿名表达敏感话题（如健康和生活）的空间，特别是在挑战性事件期间。研究者希望为尼泊尔语社交媒体内容创建情感分析资源，填补现有研究的空白。

Method: 构建了NepEMO数据集，包含2019年1月至2025年6月的4,462条帖子，标注了五种情感（恐惧、愤怒、悲伤、快乐、抑郁）和三种情感极性（积极、消极、中性）。进行了详细的语言分析，包括情感趋势、情感共现、情感特定n-gram分析，以及使用LDA和TF-IDF的主题建模。比较了传统机器学习、深度学习和Transformer模型。

Result: Transformer模型在多标签情感分类和情感分类任务上均优于传统机器学习和深度学习模型。

Conclusion: NepEMO数据集为尼泊尔语社交媒体情感分析提供了有价值的资源，Transformer模型在该任务上表现最佳，为未来的研究奠定了基础。

Abstract: Social media (SM) platforms (e.g. Facebook, Twitter, and Reddit) are increasingly leveraged to share opinions and emotions, specifically during challenging events, such as natural disasters, pandemics, and political elections, and joyful occasions like festivals and celebrations. Among the SM platforms, Reddit provides a unique space for its users to anonymously express their experiences and thoughts on sensitive issues such as health and daily life. In this work, we present a novel dataset, called NepEMO, for multi-label emotion (MLE) and sentiment classification (SC) on the Nepali subreddit post. We curate and build a manually annotated dataset of 4,462 posts (January 2019- June 2025) written in English, Romanised Nepali and Devanagari script for five emotions (fear, anger, sadness, joy, and depression) and three sentiment classes (positive, negative, and neutral). We perform a detailed analysis of posts to capture linguistic insights, including emotion trends, co-occurrence of emotions, sentiment-specific n-grams, and topic modelling using Latent Dirichlet Allocation and TF-IDF keyword extraction. Finally, we compare various traditional machine learning (ML), deep learning (DL), and transformer models for MLE and SC tasks. The result shows that transformer models consistently outperform the ML and DL models for both tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [26] [ParaMaP: Parallel Mapping and Collision-free Motion Planning for Reactive Robot Manipulation](https://arxiv.org/abs/2512.22575)
*Xuewei Zhang,Bailing Tian,Kai Zheng,Yulin Hui,Junjie Lu,Zhiyu Li*

Main category: cs.RO

TL;DR: 提出并行建图与运动规划框架，集成距离变换环境表示与采样模型预测控制，实现未知环境中实时无碰撞的机械臂运动规划


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中机器人操作面临的实时运动规划挑战，包括连续感知更新和频繁在线重规划的需求

Method: 1) GPU并行化EDT距离场建图，加入机器人掩码更新机制避免自碰撞误检；2) 将运动生成建模为随机优化问题，在SMPC框架中并行评估候选轨迹；3) 使用SE(3)上的几何一致位姿跟踪度量确保快速准确收敛

Result: 通过大量仿真和7自由度机械臂真实实验验证了框架的有效性，支持高频重规划

Conclusion: 提出的并行建图与规划框架能够有效解决未知环境中实时无碰撞运动规划问题，实现高效可靠的机械臂操作

Abstract: Real-time and collision-free motion planning remains challenging for robotic manipulation in unknown environments due to continuous perception updates and the need for frequent online replanning. To address these challenges, we propose a parallel mapping and motion planning framework that tightly integrates Euclidean Distance Transform (EDT)-based environment representation with a sampling-based model predictive control (SMPC) planner. On the mapping side, a dense distance-field-based representation is constructed using a GPU-based EDT and augmented with a robot-masked update mechanism to prevent false self-collision detections during online perception. On the planning side, motion generation is formulated as a stochastic optimization problem with a unified objective function and efficiently solved by evaluating large batches of candidate rollouts in parallel within a SMPC framework, in which a geometrically consistent pose tracking metric defined on SE(3) is incorporated to ensure fast and accurate convergence to the target pose. The entire mapping and planning pipeline is implemented on the GPU to support high-frequency replanning. The effectiveness of the proposed framework is validated through extensive simulations and real-world experiments on a 7-DoF robotic manipulator. More details are available at: https://zxw610.github.io/ParaMaP.

</details>


### [27] [Sistema de navegación de cobertura para vehículos no holonómicos en ambientes de exterior](https://arxiv.org/abs/2512.22734)
*Michelle Valenzuela,Francisco Leiva,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出了一种用于非完整机器人的覆盖导航系统，旨在实现特定区域的完全覆盖，并具备动态障碍物避让和恢复能力，为采矿等工业自动化提供概念验证。


<details>
  <summary>Details</summary>
Motivation: 移动机器人覆盖导航在工业自动化中至关重要，特别是在采矿行业，涉及清洁、倾倒场、尾矿坝建设等多个单元过程。自动化这些过程对提高操作安全性至关重要。

Method: 开发了非完整机器人的覆盖导航系统，包括计算覆盖特定区域的路径规划，并集成了恢复行为机制，能够处理动态障碍物和未映射障碍物，执行规避动作和恢复后继续覆盖。

Result: 系统在模拟和真实室外环境中测试，大多数实验获得接近90%的覆盖率。下一步将扩展到采矿机械/车辆，并在真实环境中验证操作。

Conclusion: 该覆盖导航系统为采矿等工业自动化提供了有效的概念验证，具备处理动态障碍的能力，展示了在复杂工业环境中实现自动化覆盖导航的潜力。

Abstract: In mobile robotics, coverage navigation refers to the deliberate movement of a robot with the purpose of covering a certain area or volume. Performing this task properly is fundamental for the execution of several activities, for instance, cleaning a facility with a robotic vacuum cleaner. In the mining industry, it is required to perform coverage in several unit processes related with material movement using industrial machinery, for example, in cleaning tasks, in dumps, and in the construction of tailings dam walls. The automation of these processes is fundamental to enhance the security associated with their execution. In this work, a coverage navigation system for a non-holonomic robot is presented. This work is intended to be a proof of concept for the potential automation of various unit processes that require coverage navigation like the ones mentioned before. The developed system includes the calculation of routes that allow a mobile platform to cover a specific area, and incorporates recovery behaviors in case that an unforeseen event occurs, such as the arising of dynamic or previously unmapped obstacles in the terrain to be covered, e.g., other machines or pedestrians passing through the area, being able to perform evasive maneuvers and post-recovery to ensure a complete coverage of the terrain. The system was tested in different simulated and real outdoor environments, obtaining results near 90% of coverage in the majority of experiments. The next step of development is to scale up the utilized robot to a mining machine/vehicle whose operation will be validated in a real environment. The result of one of the tests performed in the real world can be seen in the video available in https://youtu.be/gK7_3bK1P5g.

</details>


### [28] [SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling](https://arxiv.org/abs/2512.23162)
*Yufan He,Pengfei Guo,Mengya Xu,Zhaoshuo Li,Andriy Myronenko,Dillan Imans,Bingjie Liu,Dongren Yang,Mingxue Gu,Yongnan Ji,Yueming Jin,Ren Zhao,Baiyong Shen,Daguang Xu*

Main category: cs.RO

TL;DR: 提出SurgWorld世界模型，通过生成合成手术视频和推断伪运动学数据，解决手术机器人数据稀缺问题，显著提升VLA策略性能


<details>
  <summary>Details</summary>
Motivation: 手术机器人面临数据稀缺的根本障碍，虽然有大量手术视频但缺乏对应的动作标签，无法直接应用模仿学习或VLA训练

Method: 1) 创建SATA数据集包含详细手术机器人动作描述；2) 基于先进物理AI世界模型构建SurgWorld生成多样化、可泛化的合成手术视频；3) 使用逆动力学模型从合成视频推断伪运动学数据；4) 用增强数据训练手术VLA策略

Result: 使用增强数据训练的手术VLA策略在真实手术机器人平台上显著优于仅使用真实演示数据训练的模型

Conclusion: 该方法通过利用未标记手术视频和生成式世界建模，为自主手术技能获取提供了可扩展路径，开启了可泛化且数据高效的手术机器人策略之门

Abstract: Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.

</details>
