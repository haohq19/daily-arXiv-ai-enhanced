{"id": "2601.08928", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.08928", "abs": "https://arxiv.org/abs/2601.08928", "authors": ["Shahnawaz Alam", "Mohammed Abdul Rahman", "Bareera Sadeqa"], "title": "DriftGuard: A Hierarchical Framework for Concept Drift Detection and Remediation in Supply Chain Forecasting", "comment": null, "summary": "Supply chain forecasting models degrade over time as real-world conditions change. Promotions shift, consumer preferences evolve, and supply disruptions alter demand patterns, causing what is known as concept drift. This silent degradation leads to stockouts or excess inventory without triggering any system warnings. Current industry practice relies on manual monitoring and scheduled retraining every 3-6 months, which wastes computational resources during stable periods while missing rapid drift events. Existing academic methods focus narrowly on drift detection without addressing diagnosis or remediation, and they ignore the hierarchical structure inherent in supply chain data. What retailers need is an end-to-end system that detects drift early, explains its root causes, and automatically corrects affected models. We propose DriftGuard, a five-module framework that addresses the complete drift lifecycle. The system combines an ensemble of four complementary detection methods, namely error-based monitoring, statistical tests, autoencoder anomaly detection, and Cumulative Sum (CUSUM) change-point analysis, with hierarchical propagation analysis to identify exactly where drift occurs across product lines. Once detected, Shapley Additive Explanations (SHAP) analysis diagnoses the root causes, and a cost-aware retraining strategy selectively updates only the most affected models. Evaluated on over 30,000 time series from the M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.", "AI": {"tldr": "DriftGuard\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4f9b\u5e94\u94fe\u9884\u6d4b\u6f02\u79fb\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3001\u5c42\u6b21\u4f20\u64ad\u5206\u6790\u3001SHAP\u6839\u56e0\u8bca\u65ad\u548c\u6210\u672c\u611f\u77e5\u91cd\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u73b0\u65e9\u671f\u6f02\u79fb\u68c0\u6d4b\u3001\u6839\u56e0\u89e3\u91ca\u548c\u81ea\u52a8\u4fee\u590d\u3002", "motivation": "\u4f9b\u5e94\u94fe\u9884\u6d4b\u6a21\u578b\u4f1a\u968f\u65f6\u95f4\u9000\u5316\uff08\u6982\u5ff5\u6f02\u79fb\uff09\uff0c\u5bfc\u81f4\u5e93\u5b58\u95ee\u9898\u4f46\u65e0\u7cfb\u7edf\u8b66\u544a\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u68c0\u6d4b\uff0c\u5ffd\u7565\u8bca\u65ad\u548c\u4fee\u590d\uff0c\u4e14\u672a\u8003\u8651\u4f9b\u5e94\u94fe\u6570\u636e\u7684\u5c42\u6b21\u7ed3\u6784\u3002\u9700\u8981\u7aef\u5230\u7aef\u7cfb\u7edf\u6765\u68c0\u6d4b\u3001\u89e3\u91ca\u5e76\u81ea\u52a8\u4fee\u590d\u6f02\u79fb\u3002", "method": "\u63d0\u51faDriftGuard\u4e94\u6a21\u5757\u6846\u67b6\uff1a1\uff09\u96c6\u6210\u56db\u79cd\u4e92\u8865\u68c0\u6d4b\u65b9\u6cd5\uff08\u57fa\u4e8e\u8bef\u5dee\u76d1\u63a7\u3001\u7edf\u8ba1\u68c0\u9a8c\u3001\u81ea\u7f16\u7801\u5668\u5f02\u5e38\u68c0\u6d4b\u3001CUSUM\u53d8\u70b9\u5206\u6790\uff09\uff1b2\uff09\u5c42\u6b21\u4f20\u64ad\u5206\u6790\u5b9a\u4f4d\u4ea7\u54c1\u7ebf\u6f02\u79fb\u4f4d\u7f6e\uff1b3\uff09SHAP\u5206\u6790\u8bca\u65ad\u6839\u56e0\uff1b4\uff09\u6210\u672c\u611f\u77e5\u91cd\u8bad\u7ec3\u7b56\u7565\u9009\u62e9\u6027\u66f4\u65b0\u53d7\u5f71\u54cd\u6a21\u578b\uff1b5\uff09\u7aef\u5230\u7aef\u7cfb\u7edf\u6574\u5408\u3002", "result": "\u5728M5\u96f6\u552e\u6570\u636e\u96c6\u768430,000\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u4e0a\u8bc4\u4f30\uff0cDriftGuard\u57284.2\u5929\u5185\u5b9e\u73b097.8%\u7684\u68c0\u6d4b\u53ec\u56de\u7387\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u4fee\u590d\u83b7\u5f97\u9ad8\u8fbe417\u7684\u6295\u8d44\u56de\u62a5\u7387\u3002", "conclusion": "DriftGuard\u89e3\u51b3\u4e86\u4f9b\u5e94\u94fe\u9884\u6d4b\u4e2d\u6982\u5ff5\u6f02\u79fb\u7684\u5b8c\u6574\u751f\u547d\u5468\u671f\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u4f9b\u65e9\u671f\u68c0\u6d4b\u3001\u6839\u56e0\u89e3\u91ca\u548c\u81ea\u52a8\u4fee\u590d\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u624b\u52a8\u76d1\u63a7\u548c\u5b9a\u671f\u91cd\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2601.09100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09100", "abs": "https://arxiv.org/abs/2601.09100", "authors": ["Lixiang Zhang", "Chenggong Zhao", "Qing Gao", "Xiaoke Zhao", "Gengyi Bai", "Jinhu Lv"], "title": "DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model", "comment": "14 pages, 6 figures", "summary": "Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDScheLLM\uff0c\u4e00\u79cd\u57fa\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53cc\u7cfb\u7edf\uff08\u5feb-\u6162\uff09\u63a8\u7406\u67b6\u6784\uff0c\u7528\u4e8e\u5904\u7406\u52a8\u6001\u751f\u4ea7\u8c03\u5ea6\u4e2d\u7684\u5404\u7c7b\u6270\u52a8\uff0c\u5728\u6807\u51c6\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u751f\u4ea7\u8c03\u5ea6\u65b9\u6cd5\u5bf9\u52a8\u6001\u6270\u52a8\uff08\u5982\u52a0\u5de5\u65f6\u95f4\u53d8\u5316\u3001\u673a\u5668\u53ef\u7528\u6027\u53d8\u5316\u3001\u610f\u5916\u4efb\u52a1\u63d2\u5165\uff09\u7684\u9002\u5e94\u6027\u6709\u9650\uff0c\u901a\u5e38\u4f9d\u8d56\u7279\u5b9a\u4e8b\u4ef6\u6a21\u578b\u548c\u663e\u5f0f\u5206\u6790\u516c\u5f0f\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u6270\u52a8\u60c5\u51b5\u3002", "method": "\u6784\u5efa\u7edf\u4e00\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u5904\u7406\u52a8\u6001\u4e8b\u4ef6\uff0c\u4f7f\u7528\u8fd0\u7b79\u5b66\u6c42\u89e3\u5668\u83b7\u5f97\u7684\u7cbe\u786e\u8c03\u5ea6\u751f\u6210\u5feb\u6162\u63a8\u7406\u6a21\u5f0f\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u534e\u4e3aOpenPangu Embedded-7B\u6a21\u578b\uff0c\u91c7\u7528LoRA\u6280\u672f\u5728\u6df7\u5408\u63a8\u7406\u8303\u5f0f\u4e0b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u6807\u51c6\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u5feb\u601d\u8003\u6a21\u5f0f\u80fd\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u8c03\u5ea6\u65b9\u6848\uff0c\u6162\u601d\u8003\u6a21\u5f0f\u80fd\u4ea7\u751f\u4e0e\u6c42\u89e3\u5668\u517c\u5bb9\u4e14\u683c\u5f0f\u826f\u597d\u7684\u51b3\u7b56\u8f93\u5165\u3002", "conclusion": "\u8fd9\u662f\u6700\u65e9\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u52a8\u6001\u73af\u5883\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u7684\u7814\u7a76\u4e4b\u4e00\uff0c\u51f8\u663e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u81ea\u9002\u5e94\u8c03\u5ea6\u4f18\u5316\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2601.08881", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08881", "abs": "https://arxiv.org/abs/2601.08881", "authors": ["Yu Xu", "Hongbin Yan", "Juan Cao", "Yiji Cheng", "Tiankai Hang", "Runze He", "Zijin Yin", "Shiyi Zhang", "Yuxin Zhang", "Jintao Li", "Chunyu Wang", "Qinglin Lu", "Tong-Yee Lee", "Fan Tang"], "title": "TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts", "comment": "Project page: https://yuci-gpt.github.io/TAG-MoE/", "summary": "Unified image generation and editing models suffer from severe task interference in dense diffusion transformers architectures, where a shared parameter space must compromise between conflicting objectives (e.g., local editing v.s. subject-driven generation). While the sparse Mixture-of-Experts (MoE) paradigm is a promising solution, its gating networks remain task-agnostic, operating based on local features, unaware of global task intent. This task-agnostic nature prevents meaningful specialization and fails to resolve the underlying task interference. In this paper, we propose a novel framework to inject semantic intent into MoE routing. We introduce a Hierarchical Task Semantic Annotation scheme to create structured task descriptors (e.g., scope, type, preservation). We then design Predictive Alignment Regularization to align internal routing decisions with the task's high-level semantics. This regularization evolves the gating network from a task-agnostic executor to a dispatch center. Our model effectively mitigates task interference, outperforming dense baselines in fidelity and quality, and our analysis shows that experts naturally develop clear and semantically correlated specializations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7a00\u758f\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4e2d\u6ce8\u5165\u8bed\u4e49\u610f\u56fe\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u4efb\u52a1\u8bed\u4e49\u6807\u6ce8\u548c\u9884\u6d4b\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u4f7f\u8def\u7531\u51b3\u7b56\u4e0e\u9ad8\u5c42\u4efb\u52a1\u8bed\u4e49\u5bf9\u9f50\uff0c\u6709\u6548\u7f13\u89e3\u56fe\u50cf\u751f\u6210\u4e0e\u7f16\u8f91\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\u3002", "motivation": "\u7edf\u4e00\u7684\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u6a21\u578b\u5728\u5bc6\u96c6\u6269\u6563\u53d8\u6362\u5668\u67b6\u6784\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u5171\u4eab\u53c2\u6570\u7a7a\u95f4\u9700\u8981\u5728\u51b2\u7a81\u76ee\u6807\uff08\u5982\u5c40\u90e8\u7f16\u8f91\u4e0e\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\uff09\u4e4b\u95f4\u59a5\u534f\u3002\u867d\u7136\u7a00\u758f\u6df7\u5408\u4e13\u5bb6\u8303\u5f0f\u662f\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u95e8\u63a7\u7f51\u7edc\u4ecd\u7136\u662f\u4efb\u52a1\u65e0\u5173\u7684\uff0c\u4ec5\u57fa\u4e8e\u5c40\u90e8\u7279\u5f81\u64cd\u4f5c\uff0c\u4e0d\u4e86\u89e3\u5168\u5c40\u4efb\u52a1\u610f\u56fe\uff0c\u8fd9\u963b\u788d\u4e86\u6709\u610f\u4e49\u7684\u4e13\u4e1a\u5316\u5e76\u65e0\u6cd5\u89e3\u51b3\u4efb\u52a1\u5e72\u6270\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u6846\u67b6\uff0c\u5c06\u8bed\u4e49\u610f\u56fe\u6ce8\u5165MoE\u8def\u7531\u4e2d\u3002\u5f15\u5165\u5c42\u6b21\u5316\u4efb\u52a1\u8bed\u4e49\u6807\u6ce8\u65b9\u6848\u6765\u521b\u5efa\u7ed3\u6784\u5316\u4efb\u52a1\u63cf\u8ff0\u7b26\uff08\u5982\u8303\u56f4\u3001\u7c7b\u578b\u3001\u4fdd\u7559\u8981\u6c42\uff09\u3002\u8bbe\u8ba1\u9884\u6d4b\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u4f7f\u5185\u90e8\u8def\u7531\u51b3\u7b56\u4e0e\u4efb\u52a1\u7684\u9ad8\u5c42\u8bed\u4e49\u5bf9\u9f50\uff0c\u5c06\u95e8\u63a7\u7f51\u7edc\u4ece\u4efb\u52a1\u65e0\u5173\u6267\u884c\u5668\u6f14\u53d8\u4e3a\u8c03\u5ea6\u4e2d\u5fc3\u3002", "result": "\u6a21\u578b\u6709\u6548\u7f13\u89e3\u4e86\u4efb\u52a1\u5e72\u6270\uff0c\u5728\u4fdd\u771f\u5ea6\u548c\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u5bc6\u96c6\u57fa\u7ebf\u6a21\u578b\u3002\u5206\u6790\u8868\u660e\uff0c\u4e13\u5bb6\u81ea\u7136\u53d1\u5c55\u51fa\u6e05\u6670\u4e14\u8bed\u4e49\u76f8\u5173\u7684\u4e13\u4e1a\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8bed\u4e49\u610f\u56fe\u6ce8\u5165MoE\u8def\u7531\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u6a21\u578b\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u4f7f\u7a00\u758f\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u6709\u610f\u4e49\u7684\u4efb\u52a1\u4e13\u4e1a\u5316\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.08999", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08999", "abs": "https://arxiv.org/abs/2601.08999", "authors": ["Pranjal Patil", "Anli Ji", "Berkay Aydin"], "title": "Physics-Guided Counterfactual Explanations for Large-Scale Multivariate Time Series: Application in Scalable and Interpretable SEP Event Prediction", "comment": "This is a pre-print of an accepted paper at IEEE BigData 2025, SS 11:Towards an Understanding of Artificial Intelligence: Bridging Theory, Explainability, and Practical Applications", "summary": "Accurate prediction of solar energetic particle events is vital for safeguarding satellites, astronauts, and space-based infrastructure. Modern space weather monitoring generates massive volumes of high-frequency, multivariate time series (MVTS) data from sources such as the Geostationary perational Environmental Satellites (GOES). Machine learning (ML) models trained on this data show strong predictive power, but most existing methods overlook domain-specific feasibility constraints. Counterfactual explanations have emerged as a key tool for improving model interpretability, yet existing approaches rarely enforce physical plausibility. This work introduces a Physics-Guided Counterfactual Explanation framework, a novel method for generating counterfactual explanations in time series classification tasks that remain consistent with underlying physical principles. Applied to solar energetic particles (SEP) forecasting, this framework achieves over 80% reduction in Dynamic Time Warping (DTW) distance increasing the proximity, produces counterfactual explanations with higher sparsity, and reduces runtime by nearly 50% compared to state-of-the-art baselines such as DiCE. Beyond numerical improvements, this framework ensures that generated counterfactual explanations are physically plausible and actionable in scientific domains. In summary, the framework generates counterfactual explanations that are both valid and physically consistent, while laying the foundation for scalable counterfactual generation in big data environments.", "AI": {"tldr": "\u63d0\u51fa\u7269\u7406\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff0c\u7528\u4e8e\u592a\u9633\u9ad8\u80fd\u7c92\u5b50\u4e8b\u4ef6\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u7269\u7406\u5408\u7406\u6027\u7684\u540c\u65f6\u63d0\u5347\u89e3\u91ca\u8d28\u91cf\u4e0e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7a7a\u95f4\u5929\u6c14\u9884\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u7684\u53ef\u884c\u6027\u7ea6\u675f\u3002\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u7269\u7406\u5408\u7406\u6027\uff0c\u96be\u4ee5\u5728\u5b9e\u9645\u79d1\u5b66\u9886\u57df\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u7269\u7406\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u751f\u6210\u7b26\u5408\u7269\u7406\u539f\u7406\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e94\u7528\u4e8e\u592a\u9633\u9ad8\u80fd\u7c92\u5b50\u4e8b\u4ef6\u9884\u6d4b\u3002", "result": "\u76f8\u6bd4DiCE\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u8ddd\u79bb\u51cf\u5c1180%\u4ee5\u4e0a\uff0c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7a00\u758f\u6027\u66f4\u9ad8\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u8fd150%\uff0c\u4e14\u786e\u4fdd\u7269\u7406\u5408\u7406\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u751f\u6210\u65e2\u6709\u6548\u53c8\u7269\u7406\u4e00\u81f4\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u4e3a\u5927\u6570\u636e\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u53cd\u4e8b\u5b9e\u751f\u6210\u5960\u5b9a\u57fa\u7840\uff0c\u63d0\u5347\u79d1\u5b66\u9886\u57df\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.09578", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09578", "abs": "https://arxiv.org/abs/2601.09578", "authors": ["Jiajun Sun", "Yangyi Ou", "Haoyuan Zheng", "Chao yang", "Yue Ma"], "title": "Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping", "comment": "5 pages,7 figures. Under review", "summary": "In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u8bed\u4e49\u589e\u5f3a3D\u70b9\u4e91\u5730\u56fe\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u53ef\u89c1\u5149\u548c\u7ea2\u5916\u56fe\u50cf\uff0c\u5c06\u70ed\u4fe1\u606f\u4f5c\u4e3a\u8bed\u4e49\u5c42\u6dfb\u52a0\u5230LiDAR\u70b9\u4e91\u5730\u56fe\u4e2d\uff0c\u5b9e\u73b0\u73af\u5883\u51e0\u4f55\u548c\u6e29\u5ea6\u8bed\u4e49\u7684\u53cc\u91cd\u7406\u89e3\u3002", "motivation": "\u5728\u590d\u6742\u73af\u5883\u4e2d\uff0c\u81ea\u4e3b\u673a\u5668\u4eba\u5bfc\u822a\u548c\u73af\u5883\u611f\u77e5\u5bf9SLAM\u6280\u672f\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u9700\u8981\u4e0d\u4ec5\u63d0\u4f9b\u51e0\u4f55\u4fe1\u606f\uff0c\u8fd8\u80fd\u7406\u89e3\u73af\u5883\u8bed\u4e49\u7279\u5f81\uff08\u5982\u70ed\u6e90\uff09\u7684\u5730\u56fe\uff0c\u4ee5\u652f\u6301\u707e\u5bb3\u8bc4\u4f30\u3001\u5de5\u4e1a\u9884\u9632\u6027\u7ef4\u62a4\u7b49\u7279\u5b9a\u5e94\u7528\u3002", "method": "1. \u5728\u50cf\u7d20\u7ea7\u878d\u5408\u53ef\u89c1\u5149\u548c\u7ea2\u5916\u56fe\u50cf\uff1b2. \u5c06\u5b9e\u65f6LiDAR\u70b9\u4e91\u6295\u5f71\u5230\u878d\u5408\u56fe\u50cf\u6d41\u4e0a\uff1b3. \u5728\u70ed\u901a\u9053\u4e2d\u5206\u5272\u70ed\u6e90\u7279\u5f81\uff0c\u5b9e\u65f6\u8bc6\u522b\u9ad8\u6e29\u76ee\u6807\uff1b4. \u5c06\u6e29\u5ea6\u4fe1\u606f\u4f5c\u4e3a\u8bed\u4e49\u5c42\u5e94\u7528\u5230\u6700\u7ec8\u76843D\u5730\u56fe\u4e2d\u3002", "result": "\u751f\u6210\u7684\u5730\u56fe\u4e0d\u4ec5\u5177\u6709\u7cbe\u786e\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd8\u5305\u542b\u5bf9\u73af\u5883\u7684\u8bed\u4e49\u7406\u89e3\uff08\u7279\u522b\u662f\u70ed\u6e90\u4fe1\u606f\uff09\uff0c\u80fd\u591f\u5b9e\u65f6\u8bc6\u522b\u9ad8\u6e29\u76ee\u6807\uff0c\u4e3a\u5feb\u901f\u707e\u5bb3\u8bc4\u4f30\u548c\u5de5\u4e1a\u9884\u9632\u6027\u7ef4\u62a4\u7b49\u5e94\u7528\u63d0\u4f9b\u91cd\u8981\u4ef7\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u70ed\u4fe1\u606f\u4f5c\u4e3a\u8bed\u4e49\u5c42\u96c6\u6210\u52303D\u70b9\u4e91\u5730\u56fe\u4e2d\uff0c\u5b9e\u73b0\u4e86\u51e0\u4f55\u51c6\u786e\u6027\u548c\u8bed\u4e49\u7406\u89e3\u7684\u53cc\u91cd\u76ee\u6807\uff0c\u4e3a\u7279\u5b9a\u5e94\u7528\u573a\u666f\uff08\u5982\u707e\u5bb3\u8bc4\u4f30\u548c\u5de5\u4e1a\u7ef4\u62a4\uff09\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u3001\u66f4\u6709\u4ef7\u503c\u7684\u73af\u5883\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2601.09281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09281", "abs": "https://arxiv.org/abs/2601.09281", "authors": ["Jingjing Zhou", "Gaoxiang Cong", "Li Su", "Liang Li"], "title": "STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.", "AI": {"tldr": "STaR\u662f\u4e00\u4e2a\u65e0\u9700\u53c2\u6570\u7684\u63a8\u7406\u65f6\u9057\u5fd8\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u6d4b\u3001\u5b89\u5168\u63d0\u793a\u524d\u7f00\u3001\u8f68\u8ff9\u611f\u77e5\u6291\u5236\u548c\u81ea\u9002\u5e94\u8fc7\u6ee4\u7b49\u6280\u672f\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5168\u9762\u79fb\u9664\u654f\u611f\u4fe1\u606f\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u591f\u751f\u6210\u590d\u6742\u7684\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u4f46\u8fd9\u4e5f\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u654f\u611f\u4fe1\u606f\u53ef\u80fd\u6df1\u5d4c\u4e8e\u63a8\u7406\u8fc7\u7a0b\u4e2d\u3002\u73b0\u6709\u7684LLM\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u53ea\u4fee\u6539\u6700\u7ec8\u7b54\u6848\uff0c\u65e0\u6cd5\u79fb\u9664\u4e2d\u95f4\u6b65\u9aa4\u7684\u654f\u611f\u5185\u5bb9\uff0c\u5bfc\u81f4\u6301\u7eed\u7684\u9690\u79c1\u6cc4\u9732\u548c\u5b89\u5168\u95ee\u9898\u3002", "method": "STaR\u6846\u67b6\u5305\u542b\u56db\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a1) \u8bed\u4e49\u611f\u77e5\u68c0\u6d4b\u8bc6\u522b\u654f\u611f\u5185\u5bb9\uff1b2) \u901a\u8fc7\u5b89\u5168\u63d0\u793a\u524d\u7f00\u6ce8\u5165\u5168\u5c40\u5b89\u5168\u7ea6\u675f\uff1b3) \u8f68\u8ff9\u611f\u77e5\u6291\u5236\u52a8\u6001\u963b\u65ad\u6574\u4e2a\u63a8\u7406\u94fe\u4e2d\u7684\u654f\u611f\u5185\u5bb9\uff1b4) \u4ee4\u724c\u7ea7\u81ea\u9002\u5e94\u8fc7\u6ee4\u9632\u6b62\u751f\u6210\u7cbe\u786e\u548c\u8f6c\u8ff0\u7684\u654f\u611f\u4ee4\u724c\u3002\u6b64\u5916\u8fd8\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u8bc4\u4f30\u6307\u6807\uff1a\u591a\u89e3\u7801\u4e00\u81f4\u6027\u8bc4\u4f30\u548c\u591a\u7c92\u5ea6\u6210\u5458\u63a8\u7406\u653b\u51fb\u8bc4\u4f30\u3002", "result": "\u5728R-TOFU\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTaR\u5b9e\u73b0\u4e86\u5168\u9762\u7a33\u5b9a\u7684\u9057\u5fd8\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u5c0f\u7684\u6548\u7528\u635f\u5931\uff0c\u4e3aLRMs\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u63a8\u7406\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002", "conclusion": "STaR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u6311\u6218\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u7684\u8f68\u8ff9\u7ea7\u9057\u5fd8\u673a\u5236\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6548\u7528\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5168\u9762\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.09382", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09382", "abs": "https://arxiv.org/abs/2601.09382", "authors": ["Qinglong Shi", "Donghai Wang", "Hantao Zhou", "Jiguo Li", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments", "comment": "8 pages, 2 figures", "summary": "Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e3b\u52a8\u5f0f\u4efb\u52a1\u5bfc\u5411\u667a\u80fd\u4f53\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u610f\u56fe\u6761\u4ef6\u76d1\u63a7\u548c\u4e8b\u4ef6\u89e6\u53d1\u8ddf\u8fdb\uff0c\u89e3\u51b3\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u957f\u671f\u610f\u56fe\u4fdd\u6301\u7684\u4e0d\u8db3\uff0c\u5e76\u521b\u5efaChronosBench\u57fa\u51c6\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u4e3b\u8981\u91c7\u7528\u88ab\u52a8\u54cd\u5e94\u8303\u5f0f\uff0c\u53ea\u80fd\u5728\u77ed\u671f\u4f1a\u8bdd\u4e2d\u54cd\u5e94\u7528\u6237\u5373\u65f6\u67e5\u8be2\uff0c\u65e0\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u957f\u671f\u4fdd\u6301\u7528\u6237\u610f\u56fe\u5e76\u9002\u5e94\u73af\u5883\u53d8\u5316\uff0c\u8fd9\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u5f0f\u4efb\u52a1\u5bfc\u5411\u667a\u80fd\u4f53\u65b0\u8303\u5f0f\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u80fd\u529b\uff1a1\uff09\u610f\u56fe\u6761\u4ef6\u76d1\u63a7\uff1a\u667a\u80fd\u4f53\u57fa\u4e8e\u5bf9\u8bdd\u5386\u53f2\u81ea\u4e3b\u5236\u5b9a\u89e6\u53d1\u6761\u4ef6\uff1b2\uff09\u4e8b\u4ef6\u89e6\u53d1\u8ddf\u8fdb\uff1a\u68c0\u6d4b\u5230\u6709\u7528\u73af\u5883\u66f4\u65b0\u65f6\u4e3b\u52a8\u4e0e\u7528\u6237\u4e92\u52a8\u3002\u540c\u65f6\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u5408\u6210\u7ba1\u9053\u751f\u6210\u52a8\u6001\u73af\u5883\u4e2d\u7684\u590d\u6742\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\uff0c\u5e76\u521b\u5efaChronosBench\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\u5fae\u8c03\u7684\u6a21\u578b\u5728\u5305\u542b\u7528\u6237\u610f\u56fe\u8f6c\u53d8\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u8fbe\u523085.19%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u6d4b\u8bd5\u6a21\u578b\u3002\u540c\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u9886\u5148\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\u5728\u957f\u671f\u4efb\u52a1\u5bfc\u5411\u4ea4\u4e92\u4e2d\u7684\u7f3a\u9677\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e3b\u52a8\u5f0f\u667a\u80fd\u4f53\u8303\u5f0f\u548c\u6570\u636e\u9a71\u52a8\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u73af\u5883\u4e2d\u957f\u671f\u4efb\u52a1\u5bfc\u5411\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u9a8c\u8bc1\u4e86\u610f\u56fe\u6761\u4ef6\u76d1\u63a7\u548c\u4e8b\u4ef6\u89e6\u53d1\u8ddf\u8fdb\u673a\u5236\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u4f53\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.09151", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09151", "abs": "https://arxiv.org/abs/2601.09151", "authors": ["Yang Nan", "Qihao Wen", "Jiahao Wang", "Pengfei He", "Ravi Tandon", "Yong Ge", "Han Xu"], "title": "Interpretable Probability Estimation with LLMs via Shapley Reconstruction", "comment": null, "summary": "Large Language Models (LLMs) demonstrate potential to estimate the probability of uncertain events, by leveraging their extensive knowledge and reasoning capabilities. This ability can be applied to support intelligent decision-making across diverse fields, such as financial forecasting and preventive healthcare. However, directly prompting LLMs for probability estimation faces significant challenges: their outputs are often noisy, and the underlying predicting process is opaque. In this paper, we propose PRISM: Probability Reconstruction via Shapley Measures, a framework that brings transparency and precision to LLM-based probability estimation. PRISM decomposes an LLM's prediction by quantifying the marginal contribution of each input factor using Shapley values. These factor-level contributions are then aggregated to reconstruct a calibrated final estimate. In our experiments, we demonstrate PRISM improves predictive accuracy over direct prompting and other baselines, across multiple domains including finance, healthcare, and agriculture. Beyond performance, PRISM provides a transparent prediction pipeline: our case studies visualize how individual factors shape the final estimate, helping build trust in LLM-based decision support systems.", "AI": {"tldr": "PRISM\u6846\u67b6\u901a\u8fc7Shapley\u503c\u5206\u89e3LLM\u7684\u6982\u7387\u4f30\u8ba1\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6", "motivation": "LLM\u5177\u6709\u4f30\u8ba1\u4e0d\u786e\u5b9a\u4e8b\u4ef6\u6982\u7387\u7684\u6f5c\u529b\uff0c\u4f46\u76f4\u63a5\u63d0\u793a\u5b58\u5728\u8f93\u51fa\u566a\u58f0\u5927\u3001\u9884\u6d4b\u8fc7\u7a0b\u4e0d\u900f\u660e\u7684\u6311\u6218\uff0c\u9700\u8981\u63d0\u9ad8\u6982\u7387\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "method": "\u63d0\u51faPRISM\u6846\u67b6\uff1a\u4f7f\u7528Shapley\u503c\u91cf\u5316\u6bcf\u4e2a\u8f93\u5165\u56e0\u7d20\u7684\u8fb9\u9645\u8d21\u732e\uff0c\u7136\u540e\u805a\u5408\u8fd9\u4e9b\u56e0\u7d20\u7ea7\u8d21\u732e\u6765\u91cd\u6784\u6821\u51c6\u540e\u7684\u6700\u7ec8\u4f30\u8ba1", "result": "PRISM\u5728\u91d1\u878d\u3001\u533b\u7597\u3001\u519c\u4e1a\u7b49\u591a\u4e2a\u9886\u57df\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\u548c\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u900f\u660e\u7684\u9884\u6d4b\u6d41\u7a0b", "conclusion": "PRISM\u6846\u67b6\u4e3aLLM\u6982\u7387\u4f30\u8ba1\u5e26\u6765\u4e86\u900f\u660e\u5ea6\u548c\u7cbe\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u5bf9\u57fa\u4e8eLLM\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u4fe1\u4efb"}}
{"id": "2601.09050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09050", "abs": "https://arxiv.org/abs/2601.09050", "authors": ["Tianyi Xu", "Xuan Ouyang", "Binwei Yao", "Shoua Xiong", "Sara Misurelli", "Maichou Lor", "Junjie Hu"], "title": "SITA: Learning Speaker-Invariant and Tone-Aware Speech Representations for Low-Resource Tonal Languages", "comment": "8 pages (excluding references, limitations, ethics, acknowledgement, and appendix); 4 figures in the main paper; appendix included", "summary": "Tonal low-resource languages are widely spoken yet remain underserved by modern speech technology. A key challenge is learning representations that are robust to nuisance variation such as gender while remaining tone-aware for different lexical meanings. To address this, we propose SITA, a lightweight adaptation recipe that enforces Speaker-Invariance and Tone-Awareness for pretrained wav2vec-style encoders. SITA uses staged multi-objective training: (i) a cross-gender contrastive objective encourages lexical consistency across speakers, while a tone-repulsive loss prevents tone collapse by explicitly separating same-word different-tone realizations; and (ii) an auxiliary Connectionist Temporal Classification (CTC)-based ASR objective with distillation stabilizes recognition-relevant structure. We evaluate primarily on Hmong, a highly tonal and severely under-resourced language where off-the-shelf multilingual encoders fail to represent tone effectively. On a curated Hmong word corpus, SITA improves cross-gender lexical retrieval accuracy, while maintaining usable ASR accuracy relative to an ASR-adapted XLS-R teacher. We further observe similar gains when transferring the same recipe to Mandarin, suggesting SITA is a general, plug-in approach for adapting multilingual speech encoders to tonal languages.", "AI": {"tldr": "SITA\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9002\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5236\u8bf4\u8bdd\u4eba\u4e0d\u53d8\u6027\u548c\u97f3\u8c03\u611f\u77e5\u6765\u6539\u8fdb\u9884\u8bad\u7ec3\u8bed\u97f3\u7f16\u7801\u5668\u5bf9\u4f4e\u8d44\u6e90\u58f0\u8c03\u8bed\u8a00\u7684\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u58f0\u8c03\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u73b0\u4ee3\u8bed\u97f3\u6280\u672f\u4e2d\u670d\u52a1\u4e0d\u8db3\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u5728\u4fdd\u6301\u8bf4\u8bdd\u4eba\u4e0d\u53d8\u6027\u7684\u540c\u65f6\u6709\u6548\u6355\u6349\u97f3\u8c03\u4fe1\u606f\uff0c\u5bfc\u81f4\u8bcd\u6c47\u610f\u4e49\u6df7\u6dc6\u3002", "method": "\u91c7\u7528\u5206\u9636\u6bb5\u591a\u76ee\u6807\u8bad\u7ec3\uff1a1)\u8de8\u6027\u522b\u5bf9\u6bd4\u5b66\u4e60\u4fc3\u8fdb\u8bcd\u6c47\u4e00\u81f4\u6027\uff0c\u97f3\u8c03\u6392\u65a5\u635f\u5931\u9632\u6b62\u97f3\u8c03\u5d29\u6e83\uff1b2)\u57fa\u4e8eCTC\u7684ASR\u76ee\u6807\u4e0e\u84b8\u998f\u7a33\u5b9a\u8bc6\u522b\u76f8\u5173\u7ed3\u6784\u3002", "result": "\u5728\u82d7\u8bed\uff08\u9ad8\u5ea6\u58f0\u8c03\u4e14\u8d44\u6e90\u4e25\u91cd\u4e0d\u8db3\uff09\u4e0a\uff0cSITA\u63d0\u9ad8\u4e86\u8de8\u6027\u522b\u8bcd\u6c47\u68c0\u7d22\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u7528\u7684ASR\u51c6\u786e\u7387\uff1b\u5728\u666e\u901a\u8bdd\u4e0a\u4e5f\u89c2\u5bdf\u5230\u7c7b\u4f3c\u6539\u8fdb\u3002", "conclusion": "SITA\u662f\u4e00\u79cd\u901a\u7528\u3001\u5373\u63d2\u5373\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u5c06\u591a\u8bed\u8a00\u8bed\u97f3\u7f16\u7801\u5668\u9002\u914d\u5230\u58f0\u8c03\u8bed\u8a00\uff0c\u6709\u6548\u89e3\u51b3\u4f4e\u8d44\u6e90\u58f0\u8c03\u8bed\u8a00\u7684\u8bed\u97f3\u8868\u793a\u95ee\u9898\u3002"}}
{"id": "2601.09680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09680", "abs": "https://arxiv.org/abs/2601.09680", "authors": ["Sara AlMahri", "Liming Xu", "Alexandra Brintrup"], "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach", "comment": null, "summary": "Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53AI\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\u76d1\u63a7\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u68c0\u6d4b\u3001\u5206\u6790\u548c\u5e94\u5bf9\u591a\u5c42\u7ea7\u4f9b\u5e94\u94fe\u4e2d\u65ad\uff0c\u76f8\u6bd4\u4f20\u7edf\u4eba\u5de5\u5206\u6790\u5c06\u54cd\u5e94\u65f6\u95f4\u7f29\u77ed\u4e09\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u4ee3\u4f9b\u5e94\u94fe\u9762\u4e34\u5730\u7f18\u653f\u6cbb\u3001\u9700\u6c42\u51b2\u51fb\u3001\u8d38\u6613\u9650\u5236\u548c\u81ea\u7136\u707e\u5bb3\u7b49\u591a\u79cd\u4e2d\u65ad\u98ce\u9669\uff0c\u4f46\u5927\u591a\u6570\u516c\u53f8\u7f3a\u4e4f\u4e00\u7ea7\u4f9b\u5e94\u5546\u4e4b\u5916\u7684\u53ef\u89c1\u6027\uff0c\u65e0\u6cd5\u53ca\u65f6\u53d1\u73b0\u4e0a\u6e38\u6f0f\u6d1e\uff0c\u5bfc\u81f4\u4e2d\u65ad\u5f71\u54cd\u5411\u4e0b\u6e38\u7ea7\u8054\u4f20\u64ad\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u6700\u5c0f\u76d1\u7763\u7684\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u5305\u542b\u4e03\u4e2a\u7531\u5927\u8bed\u8a00\u6a21\u578b\u548c\u786e\u5b9a\u6027\u5de5\u5177\u9a71\u52a8\u7684\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u5171\u540c\u4ece\u975e\u7ed3\u6784\u5316\u65b0\u95fb\u4e2d\u68c0\u6d4b\u4e2d\u65ad\u4fe1\u53f7\uff0c\u5c06\u5176\u6620\u5c04\u5230\u591a\u5c42\u7ea7\u4f9b\u5e94\u5546\u7f51\u7edc\uff0c\u57fa\u4e8e\u7f51\u7edc\u7ed3\u6784\u8bc4\u4f30\u66b4\u9732\u98ce\u9669\uff0c\u5e76\u63a8\u8350\u7f13\u89e3\u63aa\u65bd\u5982\u66ff\u4ee3\u91c7\u8d2d\u9009\u9879\u3002", "result": "\u572830\u4e2a\u5408\u6210\u573a\u666f\uff08\u6db5\u76d6\u4e09\u5bb6\u6c7d\u8f66\u5236\u9020\u5546\u548c\u4e94\u7c7b\u4e2d\u65ad\uff09\u4e2d\u8bc4\u4f30\uff0c\u7cfb\u7edf\u5728\u6838\u5fc3\u4efb\u52a1\u4e0a\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\uff08F1\u5206\u65700.962-0.991\uff09\uff0c\u7aef\u5230\u7aef\u5206\u6790\u5e73\u5747\u8017\u65f63.83\u5206\u949f\uff0c\u6bcf\u6b21\u4e2d\u65ad\u6210\u672c0.0836\u7f8e\u5143\u3002\u76f8\u6bd4\u884c\u4e1a\u57fa\u51c6\uff08\u591a\u65e5\u7684\u4eba\u5de5\u9a71\u52a8\u8bc4\u4f30\uff09\uff0c\u54cd\u5e94\u65f6\u95f4\u7f29\u77ed\u4e09\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\u30022022\u5e74\u4fc4\u4e4c\u51b2\u7a81\u7684\u771f\u5b9e\u6848\u4f8b\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u64cd\u4f5c\u9002\u7528\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6784\u5efa\u80fd\u591f\u7ba1\u7406\u6df1\u5c42\u7f51\u7edc\u4e2d\u65ad\u7684\u5f39\u6027\u3001\u4e3b\u52a8\u548c\u81ea\u4e3b\u4f9b\u5e94\u94fe\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u4ece\u88ab\u52a8\u6062\u590d\u5230\u4e3b\u52a8\u5f39\u6027\u7684\u8f6c\u53d8\u3002"}}
{"id": "2601.09220", "categories": ["cs.LG", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.09220", "abs": "https://arxiv.org/abs/2601.09220", "authors": ["Xinzi Tan", "Kejian Zhang", "Junhan Yu", "Doudou Zhou"], "title": "From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences", "comment": null, "summary": "Marked Temporal Point Processes (MTPPs) arise naturally in medical, social, commercial, and financial domains. However, existing Transformer-based methods mostly inject temporal information only via positional encodings, relying on shared or parametric decay structures, which limits their ability to capture heterogeneous and type-specific temporal effects. Inspired by this observation, we derive a novel attention operator called Hawkes Attention from the multivariate Hawkes process theory for MTPP, using learnable per-type neural kernels to modulate query, key and value projections, thereby replacing the corresponding parts in the traditional attention. Benefited from the design, Hawkes Attention unifies event timing and content interaction, learning both the time-relevant behavior and type-specific excitation patterns from the data. The experimental results show that our method achieves better performance compared to the baselines. In addition to the general MTPP, our attention mechanism can also be easily applied to specific temporal structures, such as time series forecasting.", "AI": {"tldr": "\u63d0\u51faHawkes Attention\uff0c\u4ece\u591a\u5143Hawkes\u8fc7\u7a0b\u7406\u8bba\u63a8\u5bfc\u7684\u65b0\u578b\u6ce8\u610f\u529b\u7b97\u5b50\uff0c\u7528\u53ef\u5b66\u4e60\u7684\u6bcf\u7c7b\u578b\u795e\u7ecf\u6838\u8c03\u5236\u67e5\u8be2\u3001\u952e\u548c\u503c\u6295\u5f71\uff0c\u66ff\u4ee3\u4f20\u7edf\u6ce8\u610f\u529b\uff0c\u7edf\u4e00\u4e8b\u4ef6\u65f6\u95f4\u548c\u5185\u5bb9\u4ea4\u4e92\uff0c\u5728MTPP\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u4f4d\u7f6e\u7f16\u7801\u6ce8\u5165\u65f6\u95f4\u4fe1\u606f\uff0c\u4f9d\u8d56\u5171\u4eab\u6216\u53c2\u6570\u5316\u8870\u51cf\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u6355\u6349\u5f02\u6784\u548c\u7c7b\u578b\u7279\u5b9a\u65f6\u95f4\u6548\u5e94\u7684\u80fd\u529b\u3002", "method": "\u4ece\u591a\u5143Hawkes\u8fc7\u7a0b\u7406\u8bba\u63a8\u5bfcHawkes Attention\u7b97\u5b50\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u6bcf\u7c7b\u578b\u795e\u7ecf\u6838\u8c03\u5236\u67e5\u8be2\u3001\u952e\u548c\u503c\u6295\u5f71\uff0c\u66ff\u4ee3\u4f20\u7edf\u6ce8\u610f\u529b\u76f8\u5e94\u90e8\u5206\uff0c\u7edf\u4e00\u4e8b\u4ef6\u65f6\u95f4\u548c\u5185\u5bb9\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u83b7\u5f97\u66f4\u597d\u6027\u80fd\uff0c\u9664\u4e86\u901a\u7528MTPP\u5916\uff0c\u6ce8\u610f\u529b\u673a\u5236\u4e5f\u80fd\u8f7b\u677e\u5e94\u7528\u4e8e\u7279\u5b9a\u65f6\u95f4\u7ed3\u6784\u5982\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "conclusion": "Hawkes Attention\u901a\u8fc7\u4eceHawkes\u8fc7\u7a0b\u7406\u8bba\u63a8\u5bfc\uff0c\u7528\u53ef\u5b66\u4e60\u795e\u7ecf\u6838\u8c03\u5236\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u6355\u6349\u5f02\u6784\u65f6\u95f4\u6548\u5e94\u548c\u7c7b\u578b\u7279\u5b9a\u6fc0\u53d1\u6a21\u5f0f\uff0c\u5728MTPP\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2601.09195", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09195", "abs": "https://arxiv.org/abs/2601.09195", "authors": ["Tao Liu", "Taiqiang Wu", "Runming Yang", "Shaoning Sun", "Junjie Wang", "Yujiu Yang"], "title": "ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection", "comment": null, "summary": "Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. However, traditional SFT often ignores the one-to-many nature of language by forcing alignment with a single reference answer, leading to the model overfitting to non-core expressions. Although our empirical analysis suggests that introducing multiple reference answers can mitigate this issue, the prohibitive data and computational costs necessitate a strategic shift: prioritizing the mitigation of single-reference overfitting over the costly pursuit of answer diversity. To achieve this, we reveal the intrinsic connection between token probability and semantic importance: high-probability tokens carry the core logical framework, while low-probability tokens are mostly replaceable expressions. Based on this insight, we propose ProFit, which selectively masks low-probability tokens to prevent surface-level overfitting. Extensive experiments confirm that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.", "AI": {"tldr": "ProFit\u901a\u8fc7\u9009\u62e9\u6027\u63a9\u7801\u4f4e\u6982\u7387token\u6765\u7f13\u89e3SFT\u4e2d\u7684\u5355\u53c2\u8003\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u5347LLM\u5bf9\u9f50\u6548\u679c", "motivation": "\u4f20\u7edfSFT\u4f7f\u7528\u5355\u4e00\u53c2\u8003\u7b54\u6848\uff0c\u5ffd\u7565\u4e86\u8bed\u8a00\u7684\u4e00\u5bf9\u591a\u7279\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u62df\u5408\u975e\u6838\u5fc3\u8868\u8fbe\u3002\u867d\u7136\u591a\u53c2\u8003\u7b54\u6848\u53ef\u4ee5\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u6570\u636e\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u7f13\u89e3\u5355\u53c2\u8003\u8fc7\u62df\u5408", "method": "\u63d0\u51faProFit\u65b9\u6cd5\uff1a\u57fa\u4e8etoken\u6982\u7387\u4e0e\u8bed\u4e49\u91cd\u8981\u6027\u7684\u5185\u5728\u8054\u7cfb\uff0c\u9009\u62e9\u6027\u63a9\u7801\u4f4e\u6982\u7387token\uff08\u901a\u5e38\u662f\u53ef\u66ff\u6362\u8868\u8fbe\uff09\uff0c\u9632\u6b62\u8868\u9762\u5c42\u8fc7\u62df\u5408\uff0c\u540c\u65f6\u4fdd\u7559\u9ad8\u6982\u7387token\uff08\u627f\u8f7d\u6838\u5fc3\u903b\u8f91\u6846\u67b6\uff09", "result": "\u5728\u901a\u7528\u63a8\u7406\u548c\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProFit\u4e00\u81f4\u4f18\u4e8e\u4f20\u7edfSFT\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u5229\u7528token\u6982\u7387\u4e0e\u8bed\u4e49\u91cd\u8981\u6027\u7684\u76f8\u5173\u6027\uff0cProFit\u6709\u6548\u7f13\u89e3\u4e86SFT\u4e2d\u7684\u5355\u53c2\u8003\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u4e3aLLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u65b9\u6cd5"}}
{"id": "2601.09248", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09248", "abs": "https://arxiv.org/abs/2601.09248", "authors": ["Ni Wang", "Zihan You", "Emre Neftci", "Thorben Schoepe"], "title": "Hybrid guided variational autoencoder for visual place recognition", "comment": null, "summary": "Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of our model is based on a spiking neural network model which is compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in our new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while, showing robust performance also under various illumination conditions. When tested with novel visual inputs from unknown scenes, our model can distinguish between these places, which demonstrates a high generalization capability by learning the essential features of location. Our compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u76f8\u673a\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\u65b9\u6cd5\uff0c\u4f7f\u7528\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u5668\uff0c\u5728\u5ba4\u5185\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u5730\u70b9\u8bc6\u522b\uff0c\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u3001\u673a\u5668\u4eba\u548c\u65e0\u4eba\u673a\u9700\u8981\u5728GPS\u53d7\u9650\u7684\u5ba4\u5185\u73af\u5883\u4e2d\u7cbe\u786e\u5b9a\u4f4d\u3002\u73b0\u6709\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\u6a21\u578b\u8981\u4e48\u5185\u5b58\u5360\u7528\u5927\u96be\u4ee5\u79fb\u52a8\u90e8\u7f72\uff0c\u8981\u4e48\u7d27\u51d1\u6a21\u578b\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u4e8b\u4ef6\u76f8\u673a\u548c\u5f15\u5bfc\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u7f16\u7801\u5668\u91c7\u7528\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u517c\u5bb9\u4f4e\u529f\u8017\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u3002\u5728\u65b0\u5efa\u7684\u5ba4\u5185VPR\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u6210\u529f\u89e3\u802616\u4e2a\u4e0d\u540c\u5730\u70b9\u7684\u89c6\u89c9\u7279\u5f81\u3002", "result": "\u6a21\u578b\u5206\u7c7b\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u4e0d\u540c\u5149\u7167\u6761\u4ef6\u4e0b\u8868\u73b0\u9c81\u68d2\u3002\u5bf9\u672a\u77e5\u573a\u666f\u7684\u65b0\u89c6\u89c9\u8f93\u5165\u4e5f\u80fd\u533a\u5206\u4e0d\u540c\u5730\u70b9\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u5b66\u4e60\u5730\u70b9\u672c\u8d28\u7279\u5f81\u7684\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7d27\u51d1\u3001\u9c81\u68d2\u4e14\u5177\u6709\u6cdb\u5316\u80fd\u529b\u7684\u5f15\u5bfcVAE\u4e3a\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6a21\u578b\uff0c\u53ef\u663e\u8457\u589e\u5f3a\u79fb\u52a8\u673a\u5668\u4eba\u5728\u5df2\u77e5\u548c\u672a\u77e5\u5ba4\u5185\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u80fd\u529b\u3002"}}
{"id": "2601.09365", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09365", "abs": "https://arxiv.org/abs/2601.09365", "authors": ["Biswesh Mohapatra", "Th\u00e9o Charlot", "Giovanni Duca", "Mayank Palan", "Laurent Romary", "Justine Cassell"], "title": "Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs", "comment": null, "summary": "Common ground plays a critical role in situated spoken dialogues, where interlocutors must establish and maintain shared references to entities, events, and relations to sustain coherent interaction. For dialog systems, the ability to correctly ground conversational content in order to refer back to it later is particularly important. Prior studies have demonstrated that LLMs are capable of performing grounding acts such as requesting clarification or producing acknowledgments, yet relatively little work has investigated how common ground can be explicitly represented and stored for later use. Without such mechanisms, it remains unclear whether acknowledgment or clarification behaviors truly reflect a grounded understanding. In this work, we evaluate a model's ability to establish and exploit common ground through relational references to entities within the shared context in a situational dialogue. We test multiple methods for representing common ground in situated dialogues and further propose approaches to improve both the establishment of common ground and its subsequent use in the conversation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u5728\u60c5\u5883\u5bf9\u8bdd\u4e2d\u663e\u5f0f\u8868\u793a\u548c\u5b58\u50a8\u5171\u540c\u57fa\u7840\uff0c\u4ee5\u652f\u6301\u540e\u7eed\u7684\u5b9e\u4f53\u5173\u7cfb\u5f15\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5171\u540c\u57fa\u7840\u5efa\u7acb\u548c\u5229\u7528\u7684\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u8868\u660eLLMs\u80fd\u591f\u6267\u884c\u6f84\u6e05\u8bf7\u6c42\u6216\u786e\u8ba4\u7b49\u57fa\u7840\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5171\u540c\u57fa\u7840\u5982\u4f55\u663e\u5f0f\u8868\u793a\u548c\u5b58\u50a8\u4ee5\u4f9b\u540e\u7eed\u4f7f\u7528\u7684\u7814\u7a76\u3002\u6ca1\u6709\u8fd9\u6837\u7684\u673a\u5236\uff0c\u65e0\u6cd5\u786e\u5b9a\u786e\u8ba4\u6216\u6f84\u6e05\u884c\u4e3a\u662f\u5426\u771f\u6b63\u53cd\u6620\u57fa\u4e8e\u5171\u540c\u57fa\u7840\u7684\u7406\u89e3\u3002", "method": "\u5728\u60c5\u5883\u5bf9\u8bdd\u4e2d\u8bc4\u4f30\u6a21\u578b\u901a\u8fc7\u5173\u7cfb\u5f15\u7528\u5efa\u7acb\u548c\u5229\u7528\u5171\u540c\u57fa\u7840\u7684\u80fd\u529b\uff0c\u6d4b\u8bd5\u591a\u79cd\u5171\u540c\u57fa\u7840\u8868\u793a\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5171\u540c\u57fa\u7840\u5efa\u7acb\u548c\u540e\u7eed\u4f7f\u7528\u7684\u65b9\u6cd5\u3002", "result": "\u8bba\u6587\u8bc4\u4f30\u4e86\u6a21\u578b\u5728\u60c5\u5883\u5bf9\u8bdd\u4e2d\u5efa\u7acb\u548c\u5229\u7528\u5171\u540c\u57fa\u7840\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u6cd5\uff0c\u4f46\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u6570\u636e\u3002", "conclusion": "\u9700\u8981\u663e\u5f0f\u8868\u793a\u548c\u5b58\u50a8\u5171\u540c\u57fa\u7840\u673a\u5236\u6765\u786e\u4fdd\u5bf9\u8bdd\u7cfb\u7edf\u771f\u6b63\u7406\u89e3\u60c5\u5883\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u52a9\u4e8e\u6539\u8fdb\u5bf9\u8bdd\u7cfb\u7edf\u5728\u60c5\u5883\u5bf9\u8bdd\u4e2d\u7684\u5171\u540c\u57fa\u7840\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2601.09373", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09373", "abs": "https://arxiv.org/abs/2601.09373", "authors": ["Bolei Ma", "Yusuke Miyao"], "title": "The Imperfective Paradox in Large Language Models", "comment": null, "summary": "Do Large Language Models (LLMs) genuinely grasp the compositional semantics of events, or do they rely on surface-level probabilistic heuristics? We investigate the Imperfective Paradox, a logical phenomenon where the past progressive aspect entails event realization for activities (e.g., running $\\to$ ran) but not for accomplishments (e.g., building $\\nrightarrow$ built). We introduce ImperfectiveNLI, a diagnostic dataset designed to probe this distinction across diverse semantic classes. Evaluating state-of-the-art open-weight models, we uncover a pervasive Teleological Bias: models systematically hallucinate completion for goal-oriented events, often overriding explicit textual negation. Representational analyses show that while internal embeddings often distinguish process from result, inference decisions are dominated by strong priors about goal attainment. We further find that prompting-based interventions reduce hallucinated completions but also increase incorrect rejections of valid entailments. Our findings suggest that current LLMs lack structural aspectual awareness, operating as predictive narrative engines rather than faithful logical reasoners.", "AI": {"tldr": "LLMs\u5728\u5904\u7406\u8fdb\u884c\u65f6\u6096\u8bba\u65f6\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u76ee\u6807\u5bfc\u5411\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u5e7b\u89c9\u76ee\u6807\u4e8b\u4ef6\u7684\u5b8c\u6210\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u4f53\u6001\u8bed\u4e49\u7406\u89e3\u3002", "motivation": "\u63a2\u7a76LLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u4e8b\u4ef6\u7684\u7ec4\u5408\u8bed\u4e49\uff0c\u8fd8\u662f\u4ec5\u4ec5\u4f9d\u8d56\u8868\u9762\u6982\u7387\u542f\u53d1\u5f0f\u3002\u901a\u8fc7\u8fdb\u884c\u65f6\u6096\u8bba\u8fd9\u4e00\u903b\u8f91\u73b0\u8c61\u6765\u6d4b\u8bd5\u6a21\u578b\u5bf9\u4f53\u6001\u8bed\u4e49\u7684\u638c\u63e1\u7a0b\u5ea6\u3002", "method": "\u5f15\u5165ImperfectiveNLI\u8bca\u65ad\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u6a21\u578b\u5728\u5904\u7406\u8fdb\u884c\u65f6\u6096\u8bba\u65f6\u7684\u8868\u73b0\u3002\u901a\u8fc7\u8868\u793a\u5206\u6790\u7814\u7a76\u5185\u90e8\u5d4c\u5165\u7279\u5f81\uff0c\u5e76\u5c1d\u8bd5\u57fa\u4e8e\u63d0\u793a\u7684\u5e72\u9884\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u666e\u904d\u5b58\u5728\u7684\u76ee\u6807\u5bfc\u5411\u504f\u89c1\uff1a\u6a21\u578b\u7cfb\u7edf\u6027\u5e7b\u89c9\u76ee\u6807\u5bfc\u5411\u4e8b\u4ef6\u7684\u5b8c\u6210\uff0c\u7ecf\u5e38\u8986\u76d6\u660e\u786e\u7684\u6587\u672c\u5426\u5b9a\u3002\u8868\u793a\u5206\u6790\u663e\u793a\u5185\u90e8\u5d4c\u5165\u80fd\u533a\u5206\u8fc7\u7a0b\u548c\u7ed3\u679c\uff0c\u4f46\u63a8\u7406\u51b3\u7b56\u88ab\u5f3a\u70c8\u7684\u76ee\u6807\u8fbe\u6210\u5148\u9a8c\u4e3b\u5bfc\u3002\u63d0\u793a\u5e72\u9884\u80fd\u51cf\u5c11\u5e7b\u89c9\u5b8c\u6210\uff0c\u4f46\u4e5f\u4f1a\u589e\u52a0\u5bf9\u6709\u6548\u8574\u6db5\u7684\u9519\u8bef\u62d2\u7edd\u3002", "conclusion": "\u5f53\u524dLLMs\u7f3a\u4e4f\u7ed3\u6784\u6027\u4f53\u6001\u610f\u8bc6\uff0c\u4f5c\u4e3a\u9884\u6d4b\u6027\u53d9\u4e8b\u5f15\u64ce\u800c\u975e\u5fe0\u5b9e\u903b\u8f91\u63a8\u7406\u5668\u8fd0\u884c\uff0c\u672a\u80fd\u771f\u6b63\u7406\u89e3\u8fdb\u884c\u65f6\u6096\u8bba\u6240\u4f53\u73b0\u7684\u4f53\u6001\u8bed\u4e49\u533a\u522b\u3002"}}
{"id": "2601.09445", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09445", "abs": "https://arxiv.org/abs/2601.09445", "authors": ["Minh Vu Pham", "Hsuvas Borkakoty", "Yufang Hou"], "title": "Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models", "comment": null, "summary": "In language models (LMs), intra-memory knowledge conflict largely arises when inconsistent information about the same event is encoded within the model's parametric knowledge. While prior work has primarily focused on resolving conflicts between a model's internal knowledge and external resources through approaches such as fine-tuning or knowledge editing, the problem of localizing conflicts that originate during pre-training within the model's internal representations remain unexplored. In this work, we design a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from the pre-training data is encoded within LMs. Our findings contribute to a growing body of evidence that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and we demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b9a\u4f4d\u8bed\u8a00\u6a21\u578b\u4e2d\u9884\u8bad\u7ec3\u671f\u95f4\u4ea7\u751f\u7684\u5185\u90e8\u77e5\u8bc6\u51b2\u7a81\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u63a7\u5236\u63a8\u7406\u65f6\u7684\u51b2\u7a81\u77e5\u8bc6\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u5185\u90e8\u77e5\u8bc6\u51b2\u7a81\u95ee\u9898\uff0c\u5373\u540c\u4e00\u4e8b\u4ef6\u7684\u4e0d\u4e00\u81f4\u4fe1\u606f\u88ab\u7f16\u7801\u5728\u6a21\u578b\u7684\u53c2\u6570\u77e5\u8bc6\u4e2d\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u89e3\u51b3\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\u4e0e\u5916\u90e8\u8d44\u6e90\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u800c\u9884\u8bad\u7ec3\u671f\u95f4\u4ea7\u751f\u7684\u5185\u90e8\u51b2\u7a81\u5728\u6a21\u578b\u8868\u793a\u4e2d\u7684\u5b9a\u4f4d\u95ee\u9898\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u51b2\u7a81\u77e5\u8bc6\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7f16\u7801\u4f4d\u7f6e\u548c\u65b9\u5f0f\u3002\u5229\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u8fdb\u884c\u56e0\u679c\u5e72\u9884\uff0c\u63a7\u5236\u63a8\u7406\u65f6\u7684\u51b2\u7a81\u77e5\u8bc6\u3002", "result": "\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u7279\u5b9a\u5185\u90e8\u7ec4\u4ef6\u8d1f\u8d23\u7f16\u7801\u9884\u8bad\u7ec3\u4e2d\u7684\u51b2\u7a81\u77e5\u8bc6\uff0c\u5e76\u8bc1\u660e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u53ef\u7528\u4e8e\u56e0\u679c\u5e72\u9884\u548c\u63a7\u5236\u63a8\u7406\u65f6\u7684\u51b2\u7a81\u77e5\u8bc6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u4e2d\u5185\u90e8\u77e5\u8bc6\u51b2\u7a81\u7684\u7f16\u7801\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5c55\u793a\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u5b9a\u4f4d\u548c\u5e72\u9884\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\u51b2\u7a81\u65b9\u9762\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.09588", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09588", "abs": "https://arxiv.org/abs/2601.09588", "authors": ["Wai-Lun Lam"], "title": "Energy-Entropy Regularization: The True Power of Minimal Looped Transformers", "comment": "19 pages, 2 figures", "summary": "Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The internal mechanisms of these single-head looped transformer models remain poorly understood, and training them from scratch remains a significant challenge. In this paper, we propose a novel training framework that leverages Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape. By treating the parameter updates as a physical flow, we successfully trained a single-head looped Transformer with model dimension $d = 8$ to solve induction head task with input sequence length of 1000 tokens. This success reveals the internal mechanism behind the superior reasoning capability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTsallis\u71b5\u548c\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u6210\u529f\u8bad\u7ec3\u5355\u5934\u5faa\u73afTransformer\u89e3\u51b3\u5f52\u7eb3\u5934\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u5176\u63a8\u7406\u80fd\u529b\u7684\u5185\u90e8\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u5355\u5934\u5faa\u73afTransformer\u5728\u57fa\u51c6\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7ecf\u5e38\u5931\u8d25\u6216\u6027\u80fd\u4e0d\u4f73\uff0c\u539f\u56e0\u662f\u635f\u5931\u51fd\u6570\u9ad8\u5ea6\u975e\u51f8\u4e14\u4e0d\u89c4\u5219\uff0c\u4f18\u5316\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u503c\u548c\u978d\u70b9\uff0c\u4e14\u5176\u5185\u90e8\u673a\u5236\u4e0d\u660e\u786e\uff0c\u4ece\u5934\u8bad\u7ec3\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528Tsallis\u71b5\u548c\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u6765\u8f6c\u6362\u635f\u5931\u51fd\u6570\u7684\u5730\u5f62\u51e0\u4f55\u3002\u5c06\u53c2\u6570\u66f4\u65b0\u89c6\u4e3a\u7269\u7406\u6d41\u52a8\uff0c\u6210\u529f\u8bad\u7ec3\u4e86\u6a21\u578b\u7ef4\u5ea6d=8\u7684\u5355\u5934\u5faa\u73afTransformer\u3002", "result": "\u6210\u529f\u8bad\u7ec3\u5355\u5934\u5faa\u73afTransformer\u89e3\u51b3\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u4e3a1000\u4e2atoken\u7684\u5f52\u7eb3\u5934\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u5176\u4f18\u8d8a\u63a8\u7406\u80fd\u529b\u80cc\u540e\u7684\u5185\u90e8\u673a\u5236\u3002", "conclusion": "\u901a\u8fc7Tsallis\u71b5\u548c\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u8f6c\u6362\u635f\u5931\u51fd\u6570\u5730\u5f62\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u8bad\u7ec3\u5355\u5934\u5faa\u73afTransformer\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u9762\u4e34\u7684\u56f0\u96be\uff0c\u5e76\u63ed\u793a\u4e86\u8fd9\u7c7b\u6a21\u578b\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u3002"}}
{"id": "2601.09626", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09626", "abs": "https://arxiv.org/abs/2601.09626", "authors": ["Ge Lei", "Ferran Brosa Planella", "Sterling G. Baird", "Samuel J. Cooper"], "title": "From Prompt to Protocol: Fast Charging Batteries with Large Language Models", "comment": null, "summary": "Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u7535\u6c60\u5145\u7535\u534f\u8bae\u4f18\u5316\u65b9\u6cd5P2O\u548cP2P\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u76f8\u540c\u8bc4\u4f30\u9884\u7b97\u4e0b\u5b9e\u73b0\u7ea64.2%\u7684\u5065\u5eb7\u72b6\u6001\u63d0\u5347\u3002", "motivation": "\u7535\u6c60\u5145\u7535\u534f\u8bae\u4f18\u5316\u9762\u4e34\u8bc4\u4f30\u7f13\u6162\u3001\u6210\u672c\u9ad8\u3001\u4e0d\u53ef\u5fae\u5206\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u7ea6\u675f\u641c\u7d22\u7a7a\u95f4\u9650\u5236\u4e86\u534f\u8bae\u591a\u6837\u6027\uff0c\u963b\u788d\u4e86\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u73b0\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65e0\u68af\u5ea6\u3001LLM\u9a71\u52a8\u7684\u95ed\u73af\u65b9\u6cd5\uff1aP2O\u4f7f\u7528LLM\u751f\u6210\u5c0f\u578b\u795e\u7ecf\u7f51\u7edc\u534f\u8bae\u4ee3\u7801\u5e76\u901a\u8fc7\u5185\u5faa\u73af\u8bad\u7ec3\uff1bP2P\u76f4\u63a5\u7f16\u5199\u7535\u6d41\u7684\u663e\u5f0f\u51fd\u6570\u53ca\u5176\u6807\u91cf\u53c2\u6570\u3002", "result": "LLM\u5f15\u5bfc\u7684P2O\u5728\u591a\u4e2a\u6848\u4f8b\u4e2d\u4f18\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u3001\u8fdb\u5316\u7b97\u6cd5\u548c\u968f\u673a\u641c\u7d22\u8bbe\u8ba1\u7684\u795e\u7ecf\u7f51\u7edc\uff1b\u5728\u5feb\u901f\u5145\u7535\u573a\u666f\u4e2d\uff0cP2O\u548cP2P\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u591a\u6b65\u6052\u6d41\u57fa\u7ebf\u5b9e\u73b0\u4e86\u7ea64.2%\u7684\u5065\u5eb7\u72b6\u6001\u63d0\u5347\u3002", "conclusion": "LLM\u80fd\u591f\u6269\u5c55\u534f\u8bae\u51fd\u6570\u5f62\u5f0f\u7a7a\u95f4\uff0c\u6574\u5408\u57fa\u4e8e\u8bed\u8a00\u7684\u7ea6\u675f\uff0c\u5e76\u5728\u9ad8\u6210\u672c\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\u3002"}}
