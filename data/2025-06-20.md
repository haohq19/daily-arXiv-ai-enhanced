<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: MonoVQD是一种基于DETR的单目3D检测框架，通过引入掩码分离自注意力机制、变分查询去噪技术和自蒸馏策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决DETR在单目3D检测中的固有局限性，优化性能。

Method: 1. 掩码分离自注意力机制；2. 变分查询去噪技术；3. 自蒸馏策略。

Result: 在KITTI和nuScenes数据集上表现优异，具有强泛化能力。

Conclusion: MonoVQD通过创新方法显著提升了单目3D检测性能，并适用于多场景。

Abstract: Precisely localizing 3D objects from a single image constitutes a central challenge in monocular 3D detection. While DETR-like architectures offer a powerful paradigm, their direct application in this domain encounters inherent limitations, preventing optimal performance. Our work addresses these challenges by introducing MonoVQD, a novel framework designed to fundamentally advance DETR-based monocular 3D detection. We propose three main contributions. First, we propose the Mask Separated Self-Attention mechanism that enables the integration of the denoising process into a DETR architecture. This improves the stability of Hungarian matching to achieve a consistent optimization objective. Second, we present the Variational Query Denoising technique to address the gradient vanishing problem of conventional denoising methods, which severely restricts the efficiency of the denoising process. This explicitly introduces stochastic properties to mitigate this fundamental limitation and unlock substantial performance gains. Finally, we introduce a sophisticated self-distillation strategy, leveraging insights from later decoder layers to synergistically improve query quality in earlier layers, thereby amplifying the iterative refinement process. Rigorous experimentation demonstrates that MonoVQD achieves superior performance on the challenging KITTI monocular benchmark. Highlighting its broad applicability, MonoVQD's core components seamlessly integrate into other architectures, delivering significant performance gains even in multi-view 3D detection scenarios on the nuScenes dataset and underscoring its robust generalization capabilities.

</details>


### [2] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSIC的图像压缩方法，通过多解码选项保护用户隐私，同时保留图像压缩功能。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言预训练模型语义理解能力的提升，公开图像易被搜索引擎等工具利用，因此需要保护用户隐私。

Method: 提出PSIC方法，通过Conditional Latent Trigger Generation模块和Uncertainty-Aware Encryption-Oriented优化函数，实现多解码选项和隐私保护。

Result: 实验证明PSIC在多个下游任务中有效，既能保护隐私，又能保持图像质量。

Conclusion: PSIC是一种即插即用的方法，可集成到现有图像压缩模型中，同时实现隐私保护和图像质量优化。

Abstract: The improved semantic understanding of vision-language pretrained (VLP) models has made it increasingly difficult to protect publicly posted images from being exploited by search engines and other similar tools. In this context, this paper seeks to protect users' privacy by implementing defenses at the image compression stage to prevent exploitation. Specifically, we propose a flexible coding method, termed Privacy-Shielded Image Compression (PSIC), that can produce bitstreams with multiple decoding options. By default, the bitstream is decoded to preserve satisfactory perceptual quality while preventing interpretation by VLP models. Our method also retains the original image compression functionality. With a customizable input condition, the proposed scheme can reconstruct the image that preserves its full semantic information. A Conditional Latent Trigger Generation (CLTG) module is proposed to produce bias information based on customizable conditions to guide the decoding process into different reconstructed versions, and an Uncertainty-Aware Encryption-Oriented (UAEO) optimization function is designed to leverage the soft labels inferred from the target VLP model's uncertainty on the training data. This paper further incorporates an adaptive multi-objective optimization strategy to obtain improved encrypting performance and perceptual quality simultaneously within a unified training process. The proposed scheme is plug-and-play and can be seamlessly integrated into most existing Learned Image Compression (LIC) models. Extensive experiments across multiple downstream tasks have demonstrated the effectiveness of our design.

</details>


### [3] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

Main category: cs.CV

TL;DR: ViMAT是一种无需标记或固定工作空间设置的AI驱动系统，用于实时监控工业装配任务。


<details>
  <summary>Details</summary>
Motivation: 现有商业解决方案通常需要固定工作空间或视觉标记，限制了灵活性。ViMAT旨在克服这些限制。

Method: ViMAT结合了从多视角视频流提取视觉信息的感知模块和基于观察状态与任务知识推理动作的推理模块。

Result: 在LEGO组件更换和液压模具重组任务中，ViMAT在部分和不确定视觉观察下表现有效。

Conclusion: ViMAT在复杂真实场景中展示了其灵活性和有效性。

Abstract: Visual monitoring of industrial assembly tasks is critical for preventing equipment damage due to procedural errors and ensuring worker safety. Although commercial solutions exist, they typically require rigid workspace setups or the application of visual markers to simplify the problem. We introduce ViMAT, a novel AI-driven system for real-time visual monitoring of assembly tasks that operates without these constraints. ViMAT combines a perception module that extracts visual observations from multi-view video streams with a reasoning module that infers the most likely action being performed based on the observed assembly state and prior task knowledge. We validate ViMAT on two assembly tasks, involving the replacement of LEGO components and the reconfiguration of hydraulic press molds, demonstrating its effectiveness through quantitative and qualitative analysis in challenging real-world scenarios characterized by partial and uncertain visual observations. Project page: https://tev-fbk.github.io/ViMAT

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model](https://arxiv.org/abs/2506.14830)
*Zhizhao Wen,Ruoxin Zhang,Chao Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种结合双向门控循环单元（BiGRU）和多头注意力机制（MHA）的混合模型，用于SSD健康状态预测，显著提高了分类准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: SSD健康状态预测对数据可靠性至关重要，传统模型存在泛化能力不足的问题，需要一种更准确且稳定的方法。

Method: 模型结合BiGRU的双向时序建模能力和MHA的动态特征权重分配，提取时间特征并聚焦关键信息。

Result: 模型在训练集和测试集上的分类准确率分别为92.70%和92.44%，AUC为0.94，表现出优异的泛化能力和鲁棒性。

Conclusion: 该模型为SSD健康预测提供了新技术方案，解决了传统模型的泛化瓶颈，具有实际应用价值，可降低数据丢失风险并优化维护成本。

Abstract: Aiming at the critical role of SSD health state prediction in data reliability assurance, this study proposes a hybrid BiGRU-MHA model that incorporates a multi-head attention mechanism to enhance the accuracy and stability of storage device health classification. The model innovatively integrates temporal feature extraction and key information focusing capabilities. Specifically, it leverages the bidirectional timing modeling advantages of the BiGRU network to capture both forward and backward dependencies of SSD degradation features. Simultaneously, the multi-head attention mechanism dynamically assigns feature weights, improving the model's sensitivity to critical health indicators. Experimental results show that the proposed model achieves classification accuracies of 92.70% on the training set and 92.44% on the test set, with a minimal performance gap of only 0.26%, demonstrating excellent generalization ability. Further analysis using the receiver operating characteristic (ROC) curve shows an area under the curve (AUC) of 0.94 on the test set, confirming the model's robust binary classification performance. This work not only presents a new technical approach for SSD health prediction but also addresses the generalization bottleneck of traditional models, offering a verifiable method with practical value for preventive maintenance of industrial-grade storage systems. The results show the model can significantly reduce data loss risks by providing early failure warnings and help optimize maintenance costs, supporting intelligent decision-making in building reliable storage systems for cloud computing data centers and edge storage environments.

</details>


### [5] [Event-Driven Online Vertical Federated Learning](https://arxiv.org/abs/2506.14911)
*Ganyu Wang,Boyu Wang,Bin Gu,Charles Ling*

Main category: cs.LG

TL;DR: 论文提出了一种事件驱动的在线垂直联邦学习（VFL）框架，解决了数据异步到达和非凸模型在非平稳环境中的挑战。


<details>
  <summary>Details</summary>
Motivation: 在线学习在VFL中更具适应性，但数据异步到达和事件驱动的特性带来了挑战，现有研究未充分解决。

Method: 提出事件驱动的在线VFL框架，仅激活部分客户端，并引入动态局部遗憾（DLR）处理非凸和非平稳问题。

Result: 实验表明，该框架在非平稳数据下更稳定，显著降低了通信和计算成本。

Conclusion: 该框架有效解决了在线VFL中的挑战，为实际应用提供了更高效的解决方案。

Abstract: Online learning is more adaptable to real-world scenarios in Vertical Federated Learning (VFL) compared to offline learning. However, integrating online learning into VFL presents challenges due to the unique nature of VFL, where clients possess non-intersecting feature sets for the same sample. In real-world scenarios, the clients may not receive data streaming for the disjoint features for the same entity synchronously. Instead, the data are typically generated by an \emph{event} relevant to only a subset of clients. We are the first to identify these challenges in online VFL, which have been overlooked by previous research. To address these challenges, we proposed an event-driven online VFL framework. In this framework, only a subset of clients were activated during each event, while the remaining clients passively collaborated in the learning process. Furthermore, we incorporated \emph{dynamic local regret (DLR)} into VFL to address the challenges posed by online learning problems with non-convex models within a non-stationary environment. We conducted a comprehensive regret analysis of our proposed framework, specifically examining the DLR under non-convex conditions with event-driven online VFL. Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [6] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 本文介绍了一个手动标注的老年患者出院摘要中不良事件（AE）提取的语料库，填补了临床NLP资源中老年人群的空白。数据集包含14种临床显著AE及上下文属性，支持不连续和重叠实体标注。评估显示，BERT等模型在粗粒度任务上表现优异，但在细粒度和罕见事件上仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 老年患者在临床NLP资源中代表性不足，现有研究很少处理不连续和重叠实体的挑战。

Method: 构建了一个包含14种AE及上下文属性的标注数据集，支持复杂实体标注。使用FlairNLP评估多种模型在三个粒度上的表现。

Result: BERT在文档级粗粒度任务上F1=0.943，但在细粒度任务（如F1=0.675）和罕见事件上表现显著下降。

Conclusion: 尽管模型在粗粒度任务上表现良好，但细粒度AE提取和复杂临床语言仍具挑战性。数据集可作为未来研究的基准。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE) extraction from discharge summaries of elderly patients, a population often underrepresented in clinical NLP resources. The dataset includes 14 clinically significant AEs-such as falls, delirium, and intracranial haemorrhage, along with contextual attributes like negation, diagnosis type, and in-hospital occurrence. Uniquely, the annotation schema supports both discontinuous and overlapping entities, addressing challenges rarely tackled in prior work. We evaluate multiple models using FlairNLP across three annotation granularities: fine-grained, coarse-grained, and coarse-grained with negation. While transformer-based models (e.g., BERT-cased) achieve strong performance on document-level coarse-grained extraction (F1 = 0.943), performance drops notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly for rare events and complex attributes. These results demonstrate that despite high-level scores, significant challenges remain in detecting underrepresented AEs and capturing nuanced clinical language. Developed within a Trusted Research Environment (TRE), the dataset is available upon request via DataLoch and serves as a robust benchmark for evaluating AE extraction methods and supporting future cross-dataset generalisation.

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

Main category: cs.CL

TL;DR: 该论文通过自然语言处理技术分析执法和法医叙述，识别社会隔离和孤独感对自杀率的影响，并开发了高质量的分类器。


<details>
  <summary>Details</summary>
Motivation: 社会隔离和孤独感近年显著增加，且与自杀率密切相关，但未被美国国家暴力死亡报告系统记录。研究旨在填补这一空白。

Method: 使用主题建模生成词典，并结合监督学习分类器，分析2002至2020年30万例自杀案例。

Result: 开发出高精度分类器（F1平均0.86，准确率0.82），识别出1,198例慢性社会隔离案例，并发现男性、同性恋和离婚者风险更高。

Conclusion: 该方法可改进美国对社会隔离和孤独感的监测与预防。

Abstract: Social isolation and loneliness, which have been increasing in recent years strongly contribute toward suicide rates. Although social isolation and loneliness are not currently recorded within the US National Violent Death Reporting System's (NVDRS) structured variables, natural language processing (NLP) techniques can be used to identify these constructs in law enforcement and coroner medical examiner narratives. Using topic modeling to generate lexicon development and supervised learning classifiers, we developed high-quality classifiers (average F1: .86, accuracy: .82). Evaluating over 300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic social isolation. Decedents had higher odds of chronic social isolation classification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR = 3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001). We found significant predictors for other social isolation topics of recent or impending divorce, child custody loss, eviction or recent move, and break-up. Our methods can improve surveillance and prevention of social isolation and loneliness in the United States.

</details>


### [8] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

Main category: cs.CL

TL;DR: GenRecal是一种通用的视觉语言模型（VLM）蒸馏框架，通过特征对齐实现跨异构VLM的知识迁移，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型VLM在资源受限设备上部署困难，且不同VLM架构差异大，需要一种通用蒸馏方法。

Method: 提出GenRecal框架，包含Recalibrator模块，用于对齐异构VLM的特征表示。

Result: 实验表明，GenRecal在多个基准测试中显著优于基线及大型开源和闭源VLM。

Conclusion: GenRecal为跨异构VLM的知识蒸馏提供了有效解决方案，具有广泛适用性。

Abstract: Recent advancements in vision-language models (VLMs) have leveraged large language models (LLMs) to achieve performance on par with closed-source systems like GPT-4V. However, deploying these models in real-world scenarios, particularly on resource-constrained devices, remains challenging due to their substantial computational demands. This has spurred interest in distilling knowledge from large VLMs into smaller, more efficient counterparts. A key challenge arises here from the diversity of VLM architectures, which are built on different LLMs and employ varying token types-differing in vocabulary size, token splits, and token index ordering. To address this challenge of limitation to a specific VLM type, we present Generation after Recalibration (GenRecal), a novel, general-purpose distillation framework for VLMs. GenRecal incorporates a Recalibrator that aligns and adapts feature representations between heterogeneous VLMs, enabling effective knowledge transfer across different types of VLMs. Through extensive experiments on multiple challenging benchmarks, we demonstrate that GenRecal significantly improves baseline performances, eventually outperforming large-scale open- and closed-source VLMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [Human Locomotion Implicit Modeling Based Real-Time Gait Phase Estimation](https://arxiv.org/abs/2506.15150)
*Yuanlong Ji,Xingbang Yang,Ruoqi Zhao,Qihan Ye,Quan Zheng,Yubo Fan*

Main category: cs.RO

TL;DR: 该论文提出了一种基于IMU信号的步态相位估计神经网络，通过隐式建模和预训练策略，显著提高了精度和鲁棒性，尤其在复杂地形下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有步态相位估计方法在复杂地形变化时精度和鲁棒性不足的问题，提升外骨骼系统的适应性和智能性。

Method: 结合时间卷积和Transformer层进行特征提取与多通道信息融合，并采用通道掩码重建预训练策略增强模型泛化能力。

Result: 在稳定地形下步态相位RMSE为2.729±1.071%，相位率MAE为0.037±0.016%；地形变化时RMSE为3.215±1.303%，MAE为0.050±0.023%。硬件验证表明算法能可靠识别步态周期和关键事件。

Conclusion: 该方法为智能自适应外骨骼系统提供了新思路，提升了人机交互的安全性和效率。

Abstract: Gait phase estimation based on inertial measurement unit (IMU) signals facilitates precise adaptation of exoskeletons to individual gait variations. However, challenges remain in achieving high accuracy and robustness, particularly during periods of terrain changes. To address this, we develop a gait phase estimation neural network based on implicit modeling of human locomotion, which combines temporal convolution for feature extraction with transformer layers for multi-channel information fusion. A channel-wise masked reconstruction pre-training strategy is proposed, which first treats gait phase state vectors and IMU signals as joint observations of human locomotion, thus enhancing model generalization. Experimental results demonstrate that the proposed method outperforms existing baseline approaches, achieving a gait phase RMSE of $2.729 \pm 1.071%$ and phase rate MAE of $0.037 \pm 0.016%$ under stable terrain conditions with a look-back window of 2 seconds, and a phase RMSE of $3.215 \pm 1.303%$ and rate MAE of $0.050 \pm 0.023%$ under terrain transitions. Hardware validation on a hip exoskeleton further confirms that the algorithm can reliably identify gait cycles and key events, adapting to various continuous motion scenarios. This research paves the way for more intelligent and adaptive exoskeleton systems, enabling safer and more efficient human-robot interaction across diverse real-world environments.

</details>
