<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission](https://arxiv.org/abs/2506.20222)
*Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu*

Main category: cs.CV

TL;DR: 提出了一种联合事件和图像（E-I）传输框架，通过贝叶斯建模和信息瓶颈方法消除冗余，优化带宽利用，同时实现实时去模糊。


<details>
  <summary>Details</summary>
Motivation: 混合系统中事件相机和RGB相机传输大量数据存在挑战，且两者输出存在冗余信息。

Method: 采用贝叶斯建模和信息瓶颈方法，分离共享和领域特定信息，自适应分配传输带宽。

Result: 仿真结果表明，该方案在重建质量和去模糊性能上优于传统系统。

Conclusion: 提出的框架有效解决了数据冗余和带宽优化问题，提升了系统性能。

Abstract: Event cameras asynchronously capture pixel-level intensity changes with
extremely low latency. They are increasingly used in conjunction with RGB
cameras for a wide range of vision-related applications. However, a major
challenge in these hybrid systems lies in the transmission of the large volume
of triggered events and RGB images. To address this, we propose a transmission
scheme that retains efficient reconstruction performance of both sources while
accomplishing real-time deblurring in parallel. Conventional RGB cameras and
event cameras typically capture the same scene in different ways, often
resulting in significant redundant information across their outputs. To address
this, we develop a joint event and image (E-I) transmission framework to
eliminate redundancy and thereby optimize channel bandwidth utilization. Our
approach employs Bayesian modeling and the information bottleneck method to
disentangle the shared and domain-specific information within the E-I inputs.
This disentangled information bottleneck framework ensures both the compactness
and informativeness of extracted shared and domain-specific information.
Moreover, it adaptively allocates transmission bandwidth based on scene
dynamics, i.e., more symbols are allocated to events for dynamic details or to
images for static information. Simulation results demonstrate that the proposed
scheme not only achieves superior reconstruction quality compared to
conventional systems but also delivers enhanced deblurring performance.

</details>


### [2] [A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners](https://arxiv.org/abs/2506.20464)
*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

Main category: cs.CV

TL;DR: 论文提出了一种名为DeepBolt的两阶段深度学习架构，用于在复杂3D点云中自动高效识别岩石锚杆，解决了数据噪声、环境变化和目标遮挡等问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 地下矿山中岩石锚杆的频繁评估对维持岩体稳定性至关重要，但手动检测因环境恶劣且耗时，自动化检测成为必要。现有方法在复杂点云中表现不佳。

Method: 提出DeepBolt方法，采用两阶段深度学习架构，专门处理类别不平衡问题，实现岩石锚杆的自动识别。

Result: DeepBolt在岩石锚杆点的IoU上比现有语义分割模型提升42.5%，分类精度和召回率分别达到96.41%和96.96%。

Conclusion: DeepBolt在复杂地下环境中表现出色，为岩石锚杆的自动化检测提供了高效解决方案。

Abstract: Rock bolts are crucial components of the subterranean support systems in
underground mines that provide adequate structural reinforcement to the rock
mass to prevent unforeseen hazards like rockfalls. This makes frequent
assessments of such bolts critical for maintaining rock mass stability and
minimising risks in underground mining operations. Where manual surveying of
rock bolts is challenging due to the low light conditions in the underground
mines and the time-intensive nature of the process, automated detection of rock
bolts serves as a plausible solution. To that end, this study focuses on the
automatic identification of rock bolts within medium to large-scale 3D point
clouds obtained from underground mines using mobile laser scanners. Existing
techniques for automated rock bolt identification primarily rely on feature
engineering and traditional machine learning approaches. However, such
techniques lack robustness as these point clouds present several challenges due
to data noise, varying environments, and complex surrounding structures.
Moreover, the target rock bolts are extremely small objects within large-scale
point clouds and are often partially obscured due to the application of
reinforcement shotcrete. Addressing these challenges, this paper proposes an
approach termed DeepBolt, which employs a novel two-stage deep learning
architecture specifically designed for handling severe class imbalance for the
automatic and efficient identification of rock bolts in complex 3D point
clouds. The proposed method surpasses state-of-the-art semantic segmentation
models by up to 42.5% in Intersection over Union (IoU) for rock bolt points.
Additionally, it outperforms existing rock bolt identification techniques,
achieving a 96.41% precision and 96.96% recall in classifying rock bolts,
demonstrating its robustness and effectiveness in complex underground
environments.

</details>


### [3] [Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization](https://arxiv.org/abs/2506.20567)
*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan*

Main category: cs.CV

TL;DR: 提出了一种基于分割与总结（DaS）的密集视频字幕框架，通过两阶段LSTM网络和分层注意力机制生成描述性句子。


<details>
  <summary>Details</summary>
Motivation: 解决未修剪长视频的密集字幕生成问题，通过分割视频为事件提案并利用视觉特征辅助句子总结。

Method: 1. 分割视频为事件提案，提取视觉特征并生成句子描述；2. 使用两阶段LSTM网络（编码器-解码器）和分层注意力机制总结句子。

Result: 在ActivityNet Captions数据集上验证了DaS框架的有效性。

Conclusion: DaS框架通过视觉特征辅助句子总结，显著提升了密集视频字幕生成的效果。

Abstract: In this work, we propose a division-and-summarization (DaS) framework for
dense video captioning. After partitioning each untrimmed long video as
multiple event proposals, where each event proposal consists of a set of short
video segments, we extract visual feature (e.g., C3D feature) from each segment
and use the existing image/video captioning approach to generate one sentence
description for this segment. Considering that the generated sentences contain
rich semantic descriptions about the whole event proposal, we formulate the
dense video captioning task as a visual cue aided sentence summarization
problem and propose a new two stage Long Short Term Memory (LSTM) approach
equipped with a new hierarchical attention mechanism to summarize all generated
sentences as one descriptive sentence with the aid of visual features.
Specifically, the first-stage LSTM network takes all semantic words from the
generated sentences and the visual features from all segments within one event
proposal as the input, and acts as the encoder to effectively summarize both
semantic and visual information related to this event proposal. The
second-stage LSTM network takes the output from the first-stage LSTM network
and the visual features from all video segments within one event proposal as
the input, and acts as the decoder to generate one descriptive sentence for
this event proposal. Our comprehensive experiments on the ActivityNet Captions
dataset demonstrate the effectiveness of our newly proposed DaS framework for
dense video captioning.

</details>


### [4] [Dense Video Captioning using Graph-based Sentence Summarization](https://arxiv.org/abs/2506.20583)
*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于图的分区与总结（GPaS）框架，通过分区和总结两阶段改进密集视频描述，利用GCN和LSTM结合的方法优化语义总结。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分探索事件时间提案内的场景演变，导致在场景和对象变化较大的情况下表现不佳。

Method: 采用两阶段框架：分区阶段将事件提案拆分为更短的视频片段进行描述；总结阶段通过GCN-LSTM交互模块（GLI）将片段描述总结为完整事件描述。

Result: 在ActivityNet Captions和YouCook II数据集上优于现有方法。

Conclusion: GPaS框架通过分区和总结两阶段有效提升了密集视频描述的性能，特别是在场景变化较大的情况下。

Abstract: Recently, dense video captioning has made attractive progress in detecting
and captioning all events in a long untrimmed video. Despite promising results
were achieved, most existing methods do not sufficiently explore the scene
evolution within an event temporal proposal for captioning, and therefore
perform less satisfactorily when the scenes and objects change over a
relatively long proposal. To address this problem, we propose a graph-based
partition-and-summarization (GPaS) framework for dense video captioning within
two stages. For the ``partition" stage, a whole event proposal is split into
short video segments for captioning at a finer level. For the ``summarization"
stage, the generated sentences carrying rich description information for each
segment are summarized into one sentence to describe the whole event. We
particularly focus on the ``summarization" stage, and propose a framework that
effectively exploits the relationship between semantic words for summarization.
We achieve this goal by treating semantic words as nodes in a graph and
learning their interactions by coupling Graph Convolutional Network (GCN) and
Long Short Term Memory (LSTM), with the aid of visual cues. Two schemes of
GCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN
and LSTM. The effectiveness of our approach is demonstrated via an extensive
comparison with the state-of-the-arts methods on the two benchmarks ActivityNet
Captions dataset and YouCook II dataset.

</details>


### [5] [Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects](https://arxiv.org/abs/2506.20638)
*Clément Forray,Pauline Delporte,Nicolas Delaygue,Florence Genin,Dawa Derksen*

Main category: cs.CV

TL;DR: 该论文利用NeRF技术从模拟图像中重建非合作空间物体的3D模型，重点优化相机姿态与NeRF的联合训练，实验表明逐帧训练能获得最准确的3D重建效果。


<details>
  <summary>Details</summary>
Motivation: 了解地球轨道物体的状态和行为对太空碎片清除、在轨维护和异常检测等应用至关重要，3D模型是太空态势感知（SSA）的重要信息来源。

Method: 使用NeRF技术从模拟图像中重建3D模型，重点优化相机姿态与NeRF的联合训练，采用逐帧训练和正则化防止相机姿态变化过大。

Result: 实验结果显示，逐帧训练能获得最准确的3D重建效果。

Conclusion: 通过优化相机姿态与NeRF的联合训练，可以有效提升非合作空间物体的3D重建精度。

Abstract: Obtaining a better knowledge of the current state and behavior of objects
orbiting Earth has proven to be essential for a range of applications such as
active debris removal, in-orbit maintenance, or anomaly detection. 3D models
represent a valuable source of information in the field of Space Situational
Awareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to
perform 3D reconstruction of non-cooperative space objects from simulated
images. This scenario is challenging for NeRF models due to unusual camera
characteristics and environmental conditions : mono-chromatic images, unknown
object orientation, limited viewing angles, absence of diffuse lighting etc. In
this work we focus primarly on the joint optimization of camera poses alongside
the NeRF. Our experimental results show that the most accurate 3D
reconstruction is achieved when training with successive images one-by-one. We
estimate camera poses by optimizing an uniform rotation and use regularization
to prevent successive poses from being too far apart.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://arxiv.org/abs/2506.19999)
*Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell*

Main category: cs.LG

TL;DR: 本文提出了一种基于时空点过程的概率模型，用于更全面地模拟阅读行为，包括注视点的位置、时间和持续时间，以及扫视的动态。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于聚合的眼动追踪数据和强假设模型，忽略了阅读中的时空动态。本文旨在通过更通用的模型捕捉这些细节。

Method: 使用标记的时空点过程模型，扫视通过Hawkes过程建模，注视持续时间通过时间卷积的预测变量建模。

Result: Hawkes过程模型在拟合人类扫视行为上优于基线模型，但上下文惊奇度对注视持续时间的预测改进有限。

Conclusion: 结果表明，惊奇度理论在解释精细眼动行为方面存在局限性。

Abstract: Reading is a process that unfolds across space and time, alternating between
fixations where a reader focuses on a specific point in space, and saccades
where a reader rapidly shifts their focus to a new point. An ansatz of
psycholinguistics is that modeling a reader's fixations and saccades yields
insight into their online sentence processing. However, standard approaches to
such modeling rely on aggregated eye-tracking measurements and models that
impose strong assumptions, ignoring much of the spatio-temporal dynamics that
occur during reading. In this paper, we propose a more general probabilistic
model of reading behavior, based on a marked spatio-temporal point process,
that captures not only how long fixations last, but also where they land in
space and when they take place in time. The saccades are modeled using a Hawkes
process, which captures how each fixation excites the probability of a new
fixation occurring near it in time and space. The duration time of fixation
events is modeled as a function of fixation-specific predictors convolved
across time, thus capturing spillover effects. Empirically, our Hawkes process
model exhibits a better fit to human saccades than baselines. With respect to
fixation durations, we observe that incorporating contextual surprisal as a
predictor results in only a marginal improvement in the model's predictive
accuracy. This finding suggests that surprisal theory struggles to explain
fine-grained eye movements.

</details>


### [7] [Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons](https://arxiv.org/abs/2506.20015)
*Dengyu Wu,Jiechen Chen,H. Vincent Poor,Bipin Rajendran,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 论文提出了一种基于共振放电神经元（RF）的无线分计算架构，用于高效处理时域信号，减少计算和传输能耗。


<details>
  <summary>Details</summary>
Motivation: 传统LIF神经元无法有效捕捉边缘应用中丰富的频谱特征，需昂贵预处理。

Method: 采用RF神经元直接处理时域信号，利用可调谐频率提取局部频谱特征，结合OFDM无线接口传输。

Result: RF-SNN架构在音频和调制分类任务中与LIF-SNN和ANN精度相当，但显著降低脉冲率和能耗。

Conclusion: RF神经元在边缘计算中具有高效能优势，适合实时时域信号处理。

Abstract: Neuromorphic computing offers an energy-efficient alternative to conventional
deep learning accelerators for real-time time-series processing. However, many
edge applications, such as wireless sensing and audio recognition, generate
streaming signals with rich spectral features that are not effectively captured
by conventional leaky integrate-and-fire (LIF) spiking neurons. This paper
investigates a wireless split computing architecture that employs
resonate-and-fire (RF) neurons with oscillatory dynamics to process time-domain
signals directly, eliminating the need for costly spectral pre-processing. By
resonating at tunable frequencies, RF neurons extract time-localized spectral
features while maintaining low spiking activity. This temporal sparsity
translates into significant savings in both computation and transmission
energy. Assuming an OFDM-based analog wireless interface for spike
transmission, we present a complete system design and evaluate its performance
on audio classification and modulation classification tasks. Experimental
results show that the proposed RF-SNN architecture achieves comparable accuracy
to conventional LIF-SNNs and ANNs, while substantially reducing spike rates and
total energy consumption during inference and communication.

</details>


### [8] [Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets](https://arxiv.org/abs/2506.20204)
*Eduardo Gutierrez Maestro,Hadi Banaee,Amy Loutfi*

Main category: cs.LG

TL;DR: 论文提出了一种名为Affective Priming Score (APS)的数据驱动方法，用于检测情感计算中受启动效应影响的数据点，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 情感计算中启动效应的模糊性对数据分类造成挑战，目前研究多从标签角度解决，但对数据本身（尤其是生理信号）的影响研究不足。

Method: 提出APS方法，为每个数据点打分以量化启动效应的影响，并在SEED和SEED-VII数据集上验证。

Result: 使用去启动效应数据后，模型的误分类率显著降低。

Conclusion: APS方法通过数据层面识别和缓解启动效应，提升了模型鲁棒性，为情感计算数据集的设计和收集提供了新思路。

Abstract: Affective priming exemplifies the challenge of ambiguity in affective
computing. While the community has largely addressed this issue from a
label-based perspective, identifying data points in the sequence affected by
the priming effect, the impact of priming on data itself, particularly in
physiological signals, remains underexplored. Data affected by priming can lead
to misclassifications when used in learning models. This study proposes the
Affective Priming Score (APS), a data-driven method to detect data points
influenced by the priming effect. The APS assigns a score to each data point,
quantifying the extent to which it is affected by priming. To validate this
method, we apply it to the SEED and SEED-VII datasets, which contain sufficient
transitions between emotional events to exhibit priming effects. We train
models with the same configuration using both the original data and
priming-free sequences. The misclassification rate is significantly reduced
when using priming-free sequences compared to the original data. This work
contributes to the broader challenge of ambiguity by identifying and mitigating
priming effects at the data level, enhancing model robustness, and offering
valuable insights for the design and collection of affective computing
datasets.

</details>


### [9] [Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning](https://arxiv.org/abs/2506.20623)
*Fariba Jangjoo,Matteo Marsili,Yasser Roudi*

Main category: cs.LG

TL;DR: 研究了闭环学习过程中参数动态的收敛性及其对初始偏见的放大作用，并提出了防止方法。


<details>
  <summary>Details</summary>
Motivation: 探讨大神经网络模型未来可能主要依赖自身生成数据训练的问题，研究闭环学习对模型参数的影响。

Method: 针对指数族模型，推导参数动态的运动方程，分析最大似然估计的性质。

Result: 发现闭环学习会放大初始偏见，但可通过数据污染、最大后验估计或正则化避免。

Conclusion: 闭环学习的渐进行为不满足参数化不变性，需谨慎设计训练策略。

Abstract: Closed-loop learning is the process of repeatedly estimating a model from
data generated from the model itself. It is receiving great attention due to
the possibility that large neural network models may, in the future, be
primarily trained with data generated by artificial neural networks themselves.
We study this process for models that belong to exponential families, deriving
equations of motions that govern the dynamics of the parameters. We show that
maximum likelihood estimation of the parameters endows sufficient statistics
with the martingale property and that as a result the process converges to
absorbing states that amplify initial biases present in the data. However, we
show that this outcome may be prevented by polluting the data with an
infinitesimal fraction of data points generated from a fixed model, by relying
on maximum a posteriori estimation or by introducing regularisation.
Furthermore, we show that the asymptotic behavior of the dynamics is not
reparametrisation invariant.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation](https://arxiv.org/abs/2506.20401)
*Jinchun Du,Bojie Shen,Muhammad Aamir Cheema,Adel N. Toosi*

Main category: cs.AI

TL;DR: 论文提出了电动汽车导向问题（EVOP-V2G），结合V2G技术优化电动汽车的充放电策略，以最大化利润。通过MIP模型和两种元启发式算法（EA和LNS），实验显示其方法显著提升了利润。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的普及和V2G技术的发展，如何在服务系统中优化电动汽车的充放电策略以提升利润成为关键问题。

Method: 采用混合整数规划（MIP）模型，并提出两种元启发式算法：进化算法（EA）和大邻域搜索（LNS）。

Result: 实验表明，该方法在真实数据上能将司机利润翻倍，并在小规模实例上接近最优，大规模实例上具有良好扩展性。

Conclusion: 研究为电动汽车移动系统提供了更智能、更盈利的解决方案，同时支持电网的能源管理。

Abstract: With the rising popularity of electric vehicles (EVs), modern service
systems, such as ride-hailing delivery services, are increasingly integrating
EVs into their operations. Unlike conventional vehicles, EVs often have a
shorter driving range, necessitating careful consideration of charging when
fulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -
allowing EVs to also discharge energy back to the grid - new opportunities and
complexities emerge. We introduce the Electric Vehicle Orienteering Problem
with V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select
customer requests or orders while managing when and where to charge or
discharge. This involves navigating dynamic electricity prices, charging
station selection, and route constraints. We formulate the problem as a Mixed
Integer Programming (MIP) model and propose two near-optimal metaheuristic
algorithms: one evolutionary (EA) and the other based on large neighborhood
search (LNS). Experiments on real-world data show our methods can double driver
profits compared to baselines, while maintaining near-optimal performance on
small instances and excellent scalability on larger ones. Our work highlights a
promising path toward smarter, more profitable EV-based mobility systems that
actively support the energy grid.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition](https://arxiv.org/abs/2506.20373)
*Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger*

Main category: cs.RO

TL;DR: CARMA是一个用于人机群体交互中情境感知的系统，通过识别和跟踪参与者、物体及其交互，生成结构化的三元组（参与者-动作-物体），为协作任务提供支持。


<details>
  <summary>Details</summary>
Motivation: 在群体交互中，机器人需要情境感知能力以有效协作，这要求对参与者、物体及其交互进行一致的表征和跟踪。

Method: CARMA通过唯一标识现实世界中的实体，并将其组织为参与者-动作-物体的三元组，实现情境感知。

Result: 实验验证了CARMA在角色区分、多参与者感知和实例识别方面的能力，能够可靠生成准确的三元组。

Conclusion: CARMA为需要时空推理和情境决策的协作任务提供了结构化且鲁棒的基础。

Abstract: We introduce CARMA, a system for situational grounding in human-robot group
interactions. Effective collaboration in such group settings requires
situational awareness based on a consistent representation of present persons
and objects coupled with an episodic abstraction of events regarding actors and
manipulated objects. This calls for a clear and consistent assignment of
instances, ensuring that robots correctly recognize and track actors, objects,
and their interactions over time. To achieve this, CARMA uniquely identifies
physical instances of such entities in the real world and organizes them into
grounded triplets of actors, objects, and actions.
  To validate our approach, we conducted three experiments, where multiple
humans and a robot interact: collaborative pouring, handovers, and sorting.
These scenarios allow the assessment of the system's capabilities as to role
distinction, multi-actor awareness, and consistent instance identification. Our
experiments demonstrate that the system can reliably generate accurate
actor-action-object triplets, providing a structured and robust foundation for
applications requiring spatiotemporal reasoning and situated decision-making in
collaborative settings.

</details>
