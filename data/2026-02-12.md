<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Low-Rank Defense Method for Adversarial Attack on Diffusion Models](https://arxiv.org/abs/2602.10319)
*Jiaxuan Zhu,Siyu Huang*

Main category: cs.CV

TL;DR: 提出LoRD防御策略，通过低秩适应模块和平衡参数来检测和防御潜在扩散模型的对抗攻击，确保模型在对抗样本和干净样本上都能生成高质量图像。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型及其微调过程中对抗攻击算法的快速发展，为防止这些攻击算法影响扩散模型的实际应用，需要开发相应的防御策略。

Method: 提出LoRD防御策略，结合合并思想和平衡参数，利用低秩适应模块来检测和防御对抗样本。基于LoRD构建防御流程，将学习到的LoRD模块应用于帮助扩散模型防御攻击算法。

Result: 在面部和风景图像上进行了大量实验，相比基线方法，该方法显示出显著更好的防御性能，确保在对抗样本和干净样本上微调的LDM仍能生成高质量图像。

Conclusion: LoRD是一种有效的防御策略，能够成功防御潜在扩散模型的对抗攻击，为扩散模型的实际应用提供了安全保障。

Abstract: Recently, adversarial attacks for diffusion models as well as their fine-tuning process have been developed rapidly. To prevent the abuse of these attack algorithms from affecting the practical application of diffusion models, it is critical to develop corresponding defensive strategies. In this work, we propose an efficient defensive strategy, named Low-Rank Defense (LoRD), to defend the adversarial attack on Latent Diffusion Models (LDMs). LoRD introduces the merging idea and a balance parameter, combined with the low-rank adaptation (LoRA) modules, to detect and defend the adversarial samples. Based on LoRD, we build up a defense pipeline that applies the learned LoRD modules to help diffusion models defend against attack algorithms. Our method ensures that the LDM fine-tuned on both adversarial and clean samples can still generate high-quality images. To demonstrate the effectiveness of our approach, we conduct extensive experiments on facial and landscape images, and our method shows significantly better defense performance compared to the baseline methods.

</details>


### [2] [Monte Carlo Maximum Likelihood Reconstruction for Digital Holography with Speckle](https://arxiv.org/abs/2602.10344)
*Xi Chen,Arian Maleki,Shirin Jalali*

Main category: cs.CV

TL;DR: 提出PGD-MC方法，通过随机线性代数技术实现可扩展的最大似然估计，解决相干成像中斑点噪声和有限孔径建模的计算难题


<details>
  <summary>Details</summary>
Motivation: 相干成像中斑点噪声被建模为乘性噪声，给图像重建带来根本挑战。最大似然估计(MLE)为斑点抑制提供了原则性框架，但在数字全息等有限孔径系统中，高维矩阵求逆的计算成本过高，阻碍了物理精确孔径建模的MLE应用

Method: 提出投影梯度下降与蒙特卡洛估计(PGD-MC)框架：利用随机线性代数方法，通过共轭梯度进行似然梯度评估，避免显式矩阵求逆；结合三种代表性去噪器作为正则化

Result: PGD-MC框架：(1)对多样且物理精确的孔径模型具有鲁棒性；(2)在重建质量和计算效率上实现显著提升；(3)能有效扩展到高分辨率数字全息；在准确性和速度上均优于先前的即插即用模型迭代重建方法

Conclusion: PGD-MC为有限孔径数字全息提供了一个灵活有效的MLE重建框架，通过随机线性代数技术解决了传统MLE计算瓶颈，支持物理精确的孔径建模而不需要简化假设

Abstract: In coherent imaging, speckle is statistically modeled as multiplicative noise, posing a fundamental challenge for image reconstruction. While maximum likelihood estimation (MLE) provides a principled framework for speckle mitigation, its application to coherent imaging system such as digital holography with finite apertures is hindered by the prohibitive cost of high-dimensional matrix inversion, especially at high resolutions. This computational burden has prevented the use of MLE-based reconstruction with physically accurate aperture modeling. In this work, we propose a randomized linear algebra approach that enables scalable MLE optimization without explicit matrix inversions in gradient computation. By exploiting the structural properties of sensing matrix and using conjugate gradient for likelihood gradient evaluation, the proposed algorithm supports accurate aperture modeling without the simplifying assumptions commonly imposed for tractability. We term the resulting method projected gradient descent with Monte Carlo estimation (PGD-MC). The proposed PGD-MC framework (i) demonstrates robustness to diverse and physically accurate aperture models, (ii) achieves substantial improvements in reconstruction quality and computational efficiency, and (iii) scales effectively to high-resolution digital holography. Extensive experiments incorporating three representative denoisers as regularization show that PGD-MC provides a flexible and effective MLE-based reconstruction framework for digital holography with finite apertures, consistently outperforming prior Plug-and-Play model-based iterative reconstruction methods in both accuracy and speed. Our code is available at: https://github.com/Computational-Imaging-RU/MC_Maximum_Likelihood_Digital_Holography_Speckle.

</details>


### [3] [ResWorld: Temporal Residual World Model for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.10884)
*Jinqing Zhang,Zehua Fu,Zelin Xu,Wenying Dai,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: TR-World通过时间残差专注动态物体建模，结合FGTR模块实现轨迹与未来BEV特征交互，提升自动驾驶规划性能


<details>
  <summary>Details</summary>
Motivation: 现有世界模型对静态区域冗余建模且缺乏与轨迹的深度交互，限制了其在自动驾驶规划中的效果

Method: 提出TR-World通过时间残差提取动态物体信息，结合FGTR模块实现轨迹与未来BEV特征的交互优化

Result: 在nuScenes和NAVSIM数据集上达到最先进的规划性能

Conclusion: 专注于动态物体建模的时间残差世界模型结合轨迹细化模块能有效提升自动驾驶规划精度

Abstract: The comprehensive understanding capabilities of world models for driving scenarios have significantly improved the planning accuracy of end-to-end autonomous driving frameworks. However, the redundant modeling of static regions and the lack of deep interaction with trajectories hinder world models from exerting their full effectiveness. In this paper, we propose Temporal Residual World Model (TR-World), which focuses on dynamic object modeling. By calculating the temporal residuals of scene representations, the information of dynamic objects can be extracted without relying on detection and tracking. TR-World takes only temporal residuals as input, thus predicting the future spatial distribution of dynamic objects more precisely. By combining the prediction with the static object information contained in the current BEV features, accurate future BEV features can be obtained. Furthermore, we propose Future-Guided Trajectory Refinement (FGTR) module, which conducts interaction between prior trajectories (predicted from the current scene representation) and the future BEV features. This module can not only utilize future road conditions to refine trajectories, but also provides sparse spatial-temporal supervision on future BEV features to prevent world model collapse. Comprehensive experiments conducted on the nuScenes and NAVSIM datasets demonstrate that our method, namely ResWorld, achieves state-of-the-art planning performance. The code is available at https://github.com/mengtan00/ResWorld.git.

</details>


### [4] [FastUSP: A Multi-Level Collaborative Acceleration Framework for Distributed Diffusion Model Inference](https://arxiv.org/abs/2602.10940)
*Guandong Li*

Main category: cs.CV

TL;DR: FastUSP：针对大规模扩散模型分布式推理的多级优化框架，通过编译级、通信级和算子级优化，相比基线USP实现1.09-1.16倍加速


<details>
  <summary>Details</summary>
Motivation: 现有Unified Sequence Parallelism（USP）实现存在显著低效问题，包括过多的内核启动开销和次优的计算-通信调度，这在大规模扩散模型（如FLUX 12B和Stable Diffusion 3 8B）的多GPU推理中成为瓶颈

Method: 提出FastUSP多级优化框架：1）编译级优化（使用CUDA Graphs进行图编译和计算-通信重排序）；2）通信级优化（FP8量化集体通信）；3）算子级优化（带双缓冲的流水线Ring attention）

Result: 在FLUX（12B）上实现1.12-1.16倍端到端加速，编译级优化贡献最大改进；在Qwen-Image上2GPU实现1.09倍加速，4-8GPU因PyTorch Inductor兼容性问题无法应用编译优化；分析显示现代高带宽GPU互连中内核启动开销是主要瓶颈而非通信延迟

Conclusion: FastUSP通过多级优化有效解决了USP实现中的效率问题，显著提升大规模扩散模型的分布式推理性能，并揭示了内核启动开销是现代GPU系统中的主要瓶颈

Abstract: Large-scale diffusion models such as FLUX (12B parameters) and Stable Diffusion 3 (8B parameters) require multi-GPU parallelism for efficient inference. Unified Sequence Parallelism (USP), which combines Ulysses and Ring attention mechanisms, has emerged as the state-of-the-art approach for distributed attention computation. However, existing USP implementations suffer from significant inefficiencies including excessive kernel launch overhead and suboptimal computation-communication scheduling. In this paper, we propose \textbf{FastUSP}, a multi-level optimization framework that integrates compile-level optimization (graph compilation with CUDA Graphs and computation-communication reordering), communication-level optimization (FP8 quantized collective communication), and operator-level optimization (pipelined Ring attention with double buffering). We evaluate FastUSP on FLUX (12B) and Qwen-Image models across 2, 4, and 8 NVIDIA RTX 5090 GPUs. On FLUX, FastUSP achieves consistent \textbf{1.12$\times$--1.16$\times$} end-to-end speedup over baseline USP, with compile-level optimization contributing the dominant improvement. On Qwen-Image, FastUSP achieves \textbf{1.09$\times$} speedup on 2 GPUs; on 4--8 GPUs, we identify a PyTorch Inductor compatibility limitation with Ring attention that prevents compile optimization, while baseline USP scales to 1.30$\times$--1.46$\times$ of 2-GPU performance. We further provide a detailed analysis of the performance characteristics of distributed diffusion inference, revealing that kernel launch overhead -- rather than communication latency -- is the primary bottleneck on modern high-bandwidth GPU interconnects.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Signature-Kernel Based Evaluation Metrics for Robust Probabilistic and Tail-Event Forecasting](https://arxiv.org/abs/2602.10182)
*Benjamin R. Redhead,Thomas L. Lee,Peng Gu,Víctor Elvira,Amos Storkey*

Main category: cs.LG

TL;DR: 提出两种基于核的度量方法：Sig-MMD和CSig-MMD，用于改进概率预测评估，能捕捉复杂依赖关系并特别关注尾部事件。


<details>
  <summary>Details</summary>
Motivation: 当前概率预测评估框架存在两个关键缺陷：1）常假设时间步或变量间独立；2）对尾部事件缺乏敏感性，而尾部事件在实际决策中最为关键。

Method: 提出两种基于核的度量：签名最大平均差异（Sig-MMD）和新的截断Sig-MMD（CSig-MMD）。利用签名核捕捉复杂的变量间和时间依赖关系，对缺失数据保持鲁棒。CSig-MMD引入截断方案，优先评估预测尾部事件的能力，同时严格保持properness特性。

Result: 这些度量方法能够更可靠地评估直接多步预测，促进开发更鲁棒的概率算法。

Conclusion: Sig-MMD和CSig-MMD解决了当前概率预测评估框架的关键缺陷，提供了能够捕捉复杂依赖关系并特别关注尾部事件的改进评估方法。

Abstract: Probabilistic forecasting is increasingly critical across high-stakes domains, from finance and epidemiology to climate science. However, current evaluation frameworks lack a consensus metric and suffer from two critical flaws: they often assume independence across time steps or variables, and they demonstrably lack sensitivity to tail events, the very occurrences that are most pivotal in real-world decision-making. To address these limitations, we propose two kernel-based metrics: the signature maximum mean discrepancy (Sig-MMD) and our novel censored Sig-MMD (CSig-MMD). By leveraging the signature kernel, these metrics capture complex inter-variate and inter-temporal dependencies and remain robust to missing data. Furthermore, CSig-MMD introduces a censoring scheme that prioritizes a forecaster's capability to predict tail events while strictly maintaining properness, a vital property for a good scoring rule. These metrics enable a more reliable evaluation of direct multi-step forecasting, facilitating the development of more robust probabilistic algorithms.

</details>


### [6] [Frame-Level Internal Tool Use for Temporal Grounding in Audio LMs](https://arxiv.org/abs/2602.10230)
*Joesph An,Phillip Keung,Jiaqi Wang,Orevaoghene Ahia,Noah A. Smith*

Main category: cs.LG

TL;DR: 提出帧级内部工具使用框架，让音频语言模型利用自身内部音频表示直接进行时间定位，相比基于文本token的时间戳生成方法，实现了>50倍推理加速和更好的长度泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型音频语言模型在处理需要精确时间定位的任务（如词对齐、说话人分离）时存在困难，传统的基于文本token生成时间戳的方法计算成本高且容易产生幻觉，特别是在处理超出训练分布长度的音频时表现不佳。

Method: 提出帧级内部工具使用框架，训练音频语言模型利用自身内部音频表示直接进行时间定位。采用轻量级预测机制，通过两个目标进行训练：二元帧分类器和新颖的非齐次泊松过程损失函数来建模时间事件强度。

Result: 在词定位、说话人分离和事件定位任务上均优于基于token的基线方法。实现了>50倍的推理加速，并在超出分布长度的音频上表现出强大的长度泛化能力，而标准基于token的模型在这些情况下完全失效。

Conclusion: 帧级内部工具使用框架为音频语言模型的时间定位任务提供了一种高效且鲁棒的解决方案，显著提升了推理速度和长度泛化能力，解决了传统方法在计算成本和幻觉问题上的局限性。

Abstract: Large audio language models are increasingly used for complex audio understanding tasks, but they struggle with temporal tasks that require precise temporal grounding, such as word alignment and speaker diarization. The standard approach, where we generate timestamps as sequences of text tokens, is computationally expensive and prone to hallucination, especially when processing audio lengths outside the model's training distribution. In this work, we propose frame-level internal tool use, a method that trains audio LMs to use their own internal audio representations to perform temporal grounding directly. We introduce a lightweight prediction mechanism trained via two objectives: a binary frame classifier and a novel inhomogeneous Poisson process (IHP) loss that models temporal event intensity. Across word localization, speaker diarization, and event localization tasks, our approach outperforms token-based baselines. Most notably, it achieves a >50x inference speedup and demonstrates robust length generalization, maintaining high accuracy on out-of-distribution audio durations where standard token-based models collapse completely.

</details>


### [7] [ICODEN: Ordinary Differential Equation Neural Networks for Interval-Censored Data](https://arxiv.org/abs/2602.10303)
*Haoling Wang,Lang Zeng,Tao Sun,Youngjoo Cho,Ying Ding*

Main category: cs.LG

TL;DR: ICOden是一个基于常微分方程的神经网络方法，用于处理区间删失生存数据，无需比例风险假设或参数化风险函数形式，在高维生物医学数据中表现稳健。


<details>
  <summary>Details</summary>
Motivation: 区间删失生存数据的预测具有挑战性，因为确切事件时间未知。现有方法要么依赖强模型假设，要么无法处理高维预测因子，需要一种更灵活、假设更少的方法。

Method: ICOden使用深度神经网络建模风险函数，通过求解常微分方程获得累积风险函数。该方法不要求比例风险假设，也不预设风险函数的参数形式，允许灵活的生存建模。

Result: 在模拟研究中，无论比例风险还是非比例风险，线性或非线性协变量效应，ICOden都能保持满意的预测准确性，且随着预测因子数量增加保持稳定。在ADNI和AREDS/AREDS2的实际应用中，ICOden能有效利用数百到上千个SNPs进行预测，并支持数据驱动的亚组识别。

Conclusion: ICOden为高维生物医学环境中的区间删失生存数据预测提供了一个实用的、假设较少的方法工具，在阿尔茨海默病和年龄相关性黄斑变性等疾病的时间预测中表现出色。

Abstract: Predicting time-to-event outcomes when event times are interval censored is challenging because the exact event time is unobserved. Many existing survival analysis approaches for interval-censored data rely on strong model assumptions or cannot handle high-dimensional predictors. We develop ICODEN, an ordinary differential equation-based neural network for interval-censored data that models the hazard function through deep neural networks and obtains the cumulative hazard by solving an ordinary differential equation. ICODEN does not require the proportional hazards assumption or a prespecified parametric form for the hazard function, thereby permitting flexible survival modeling. Across simulation settings with proportional or non-proportional hazards and both linear and nonlinear covariate effects, ICODEN consistently achieves satisfactory predictive accuracy and remains stable as the number of predictors increases. Applications to data from multiple phases of the Alzheimer's Disease Neuroimaging Initiative (ADNI) and to two Age-Related Eye Disease Studies (AREDS and AREDS2) for age-related macular degeneration (AMD) demonstrate ICODEN's robust prediction performance. In both applications, predicting time-to-AD or time-to-late AMD, ICODEN effectively uses hundreds to more than 1,000 SNPs and supports data-driven subgroup identification with differential progression risk profiles. These results establish ICODEN as a practical assumption-lean tool for prediction with interval-censored survival data in high-dimensional biomedical settings.

</details>


### [8] [Time-to-Event Transformer to Capture Timing Attention of Events in EHR Time Series](https://arxiv.org/abs/2602.10385)
*Jia Li,Yu Hou,Rui Zhang*

Main category: cs.LG

TL;DR: LITT是一种新型时序Transformer架构，通过虚拟相对时间线对齐序列事件，实现事件时序聚焦的注意力机制，在临床轨迹个性化解释和心脏毒性预测方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 从大规模时序数据中自动发现个性化序列事件对精准医疗至关重要，但现有AI模型（如Transformer）大多忽略事件时序和顺序，无法进行因果推理。需要一种能评估患者特定轨迹对齐程度并识别共享模式的方法。

Method: 提出LITT（Timing-Transformer）架构，将时间作为可计算维度，在虚拟"相对时间线"上临时对齐序列事件，实现事件时序聚焦的注意力机制，为临床轨迹提供个性化解释。

Result: 在3276名乳腺癌患者的真实世界纵向EHR数据上验证了可解释性和有效性，成功预测心脏毒性诱发心脏病的发病时间。在公共数据集上优于基准和最先进的生存分析方法。

Conclusion: LITT代表了临床AI精准医疗的重要进展，通过将时间作为可计算维度，实现了对患者轨迹的个性化解释和时序模式识别，为临床决策提供了有力工具。

Abstract: Automatically discovering personalized sequential events from large-scale time-series data is crucial for enabling precision medicine in clinical research, yet it remains a formidable challenge even for contemporary AI models. For example, while transformers capture rich associations, they are mostly agnostic to event timing and ordering, thereby bypassing potential causal reasoning.
  Intuitively, we need a method capable of evaluating the "degree of alignment" among patient-specific trajectories and identifying their shared patterns, i.e., the significant events in a consistent sequence. This necessitates treating timing as a true \emph{computable} dimension, allowing models to assign ``relative timestamps'' to candidate events beyond their observed physical times.
  In this work, we introduce LITT, a novel Timing-Transformer architecture that enables temporary alignment of sequential events on a virtual ``relative timeline'', thereby enabling \emph{event-timing-focused attention} and personalized interpretations of clinical trajectories. Its interpretability and effectiveness are validated on real-world longitudinal EHR data from 3,276 breast cancer patients to predict the onset timing of cardiotoxicity-induced heart disease. Furthermore, LITT outperforms both the benchmark and state-of-the-art survival analysis methods on public datasets, positioning it as a significant step forward for precision medicine in clinical AI.

</details>


### [9] [Enhancing Ride-Hailing Forecasting at DiDi with Multi-View Geospatial Representation Learning from the Web](https://arxiv.org/abs/2602.10502)
*Xixuan Hao,Guicheng Li,Daiqiang Wu,Xusen Guo,Yumeng Zhu,Zhichao Zou,Peng Zhen,Yao Yao,Yuxuan Liang*

Main category: cs.LG

TL;DR: MVGR-Net：通过多视图地理空间表征学习和LLM提示微调的两阶段框架，用于提升网约车预测精度


<details>
  <summary>Details</summary>
Motivation: 网约车服务改变了城市出行模式，准确预测对优化乘客体验和交通效率至关重要。现有方法面临地理空间异质性和外部事件高度敏感性的挑战。

Method: 提出MVGR-Net两阶段框架：1) 预训练阶段整合POI和时序移动模式，从语义属性和时序移动模式双视图学习地理空间表征；2) 预测阶段通过提示赋能框架微调大语言模型，并融入外部事件信息。

Result: 在滴滴真实数据集上的大量实验表明，该方法达到了最先进的性能水平。

Conclusion: MVGR-Net通过多视图地理空间表征学习和LLM提示微调，有效解决了网约车预测中的地理空间异质性和外部事件敏感性挑战。

Abstract: The proliferation of ride-hailing services has fundamentally transformed urban mobility patterns, making accurate ride-hailing forecasting crucial for optimizing passenger experience and urban transportation efficiency. However, ride-hailing forecasting faces significant challenges due to geospatial heterogeneity and high susceptibility to external events. This paper proposes MVGR-Net(Multi-View Geospatial Representation Learning), a novel framework that addresses these challenges through a two-stage approach. In the pretraining stage, we learn comprehensive geospatial representations by integrating Points-of-Interest and temporal mobility patterns to capture regional characteristics from both semantic attribute and temporal mobility pattern views. The forecasting stage leverages these representations through a prompt-empowered framework that fine-tunes Large Language Models while incorporating external events. Extensive experiments on DiDi's real-world datasets demonstrate the state-of-the-art performance.

</details>


### [10] [Bridging the Compression-Precision Paradox: A Hybrid Architecture for Clinical EEG Report Generation with Guaranteed Measurement Accuracy](https://arxiv.org/abs/2602.10544)
*Wuyang Zhang,Zhen Luo,Chuqiao Gu,Jianming Ma,Yebo Cao,Wangming Yuan,Yinzhi Jin*

Main category: cs.LG

TL;DR: 提出混合架构分离测量提取与文本生成，通过信号处理计算精确临床值，实现首个保证临床测量精度的自动化EEG报告系统


<details>
  <summary>Details</summary>
Motivation: 现有自动化EEG监测系统面临两大挑战：1) 临床EEG记录超过LLM上下文窗口，需要极端压缩(400:1+比例)破坏时间精度；2) LLM缺乏时间序列理解能力，依赖压缩表示的统计关联，导致产生临床错误的测量值

Method: 采用混合架构分离测量提取与文本生成：1) 压缩前通过信号处理计算精确临床值；2) 使用跨模态桥梁进行EEG到语言的翻译；3) 参数高效微调与约束解码；4) 多速率采样保持长程上下文同时保留事件级精度

Result: 在TUH和CHB-MIT数据集上评估，实现60%更少的误报、50%更快的检测速度，以及亚临床测量精度，是首个保证临床测量准确性的自动化EEG报告系统

Conclusion: 通过分离测量提取与文本生成的混合架构，解决了自动化EEG监测中的精度问题，为临床EEG报告提供了可靠的技术方案

Abstract: Automated EEG monitoring requires clinician-level precision for seizure detection and reporting. Clinical EEG recordings exceed LLM context windows, requiring extreme compression (400:1+ ratios) that destroys fine-grained temporal precision. A 0.5 Hz error distinguishes absence epilepsy from Lennox-Gastaut syndrome. LLMs lack inherent time-series comprehension and rely on statistical associations from compressed representations. This dual limitation causes systems to hallucinate clinically incorrect measurement values.
  We separate measurement extraction from text generation. Our hybrid architecture computes exact clinical values via signal processing before compression, employs a cross-modal bridge for EEG-to-language translation, and uses parameter-efficient fine-tuning with constrained decoding around frozen slots. Multirate sampling maintains long-range context while preserving event-level precision. Evaluation on TUH and CHB-MIT datasets achieves 60% fewer false alarms, 50% faster detection, and sub-clinical measurement precision. This is the first system guaranteeing clinical measurement accuracy in automated EEG reports.

</details>


### [11] [Enhancing Multivariate Time Series Forecasting with Global Temporal Retrieval](https://arxiv.org/abs/2602.10847)
*Fanpu Cao,Lu Dai,Jindong Han,Hui Xiong*

Main category: cs.LG

TL;DR: GTR是一个轻量级即插即用模块，通过维护全局时间嵌入和动态检索对齐全局周期模式，增强多元时间序列预测模型的全局周期性建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有MTSF模型受限于有限的历史上下文，无法有效捕捉跨越多个周期的全局周期性模式，而简单扩展历史窗口会导致过拟合、计算成本高和信息冗余等问题。

Method: GTR维护整个周期的自适应全局时间嵌入，动态检索并对齐相关全局片段与输入序列，通过2D卷积和残差融合联合建模局部和全局依赖关系。

Result: 在六个真实世界数据集上的实验表明，GTR在短期和长期预测场景中均能实现最先进的性能，同时仅引入最小的参数和计算开销。

Conclusion: GTR是增强MTSF任务中全局周期性建模的高效通用解决方案，无需改变宿主模型架构即可有效桥接短期观测与长期周期性。

Abstract: Multivariate time series forecasting (MTSF) plays a vital role in numerous real-world applications, yet existing models remain constrained by their reliance on a limited historical context. This limitation prevents them from effectively capturing global periodic patterns that often span cycles significantly longer than the input horizon - despite such patterns carrying strong predictive signals. Naive solutions, such as extending the historical window, lead to severe drawbacks, including overfitting, prohibitive computational costs, and redundant information processing. To address these challenges, we introduce the Global Temporal Retriever (GTR), a lightweight and plug-and-play module designed to extend any forecasting model's temporal awareness beyond the immediate historical context. GTR maintains an adaptive global temporal embedding of the entire cycle and dynamically retrieves and aligns relevant global segments with the input sequence. By jointly modeling local and global dependencies through a 2D convolution and residual fusion, GTR effectively bridges short-term observations with long-term periodicity without altering the host model architecture. Extensive experiments on six real-world datasets demonstrate that GTR consistently delivers state-of-the-art performance across both short-term and long-term forecasting scenarios, while incurring minimal parameter and computational overhead. These results highlight GTR as an efficient and general solution for enhancing global periodicity modeling in MTSF tasks. Code is available at this repository: https://github.com/macovaseas/GTR.

</details>


### [12] [When Fusion Helps and When It Breaks: View-Aligned Robustness in Same-Source Financial Imaging](https://arxiv.org/abs/2602.11020)
*Rui Ma*

Main category: cs.LG

TL;DR: 该研究探讨了金融图像表示中的同源多视图学习和对抗鲁棒性，用于次日方向预测。研究发现结果高度依赖标签噪声机制，通过最小波动过滤器减少标签模糊性，揭示了数据-噪声权衡。融合策略效果因机制而异，晚期融合表现最佳。对抗攻击测试显示系统在微小扰动下脆弱，晚期融合能提升单视图攻击下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决金融时间序列预测中的两个关键问题：1) 如何有效利用多视图数据（价格/成交量图表和技术指标矩阵）进行次日方向预测；2) 如何评估和提高模型在对抗攻击下的鲁棒性，这对于金融应用中的实际部署至关重要。

Method: 方法包括：1) 从上海黄金交易所现货黄金数据构建两个窗口对齐的视图：OHLCV渲染的价格/成交量图表和技术指标矩阵；2) 采用防泄漏的时间块分割和Matthews相关系数进行可靠评估；3) 应用事后最小波动过滤器减少标签模糊性；4) 比较早期融合（通道堆叠）和晚期融合（双编码器+融合头）策略；5) 使用FGSM和PGD方法评估对抗鲁棒性，包括视图约束攻击和联合攻击两种威胁场景。

Result: 结果显示：1) 预测性能强烈依赖标签噪声机制，最小波动过滤器揭示了非单调的数据-噪声权衡；2) 在稳定子集中，融合效果因机制而异，早期融合可能出现负迁移，而晚期融合在干净性能上表现最佳；3) 跨视图一致性正则化具有次要的、依赖于骨干网络的效果；4) 对抗攻击测试显示系统在微小扰动预算下极其脆弱，晚期融合能提高视图约束攻击下的鲁棒性，但联合攻击仍具挑战性，可能导致严重的性能下降。

Conclusion: 结论是：金融图像表示中的多视图学习需要仔细考虑标签噪声机制和融合策略。晚期融合在干净性能和单视图攻击鲁棒性方面表现最佳，但对抗联合攻击仍需进一步研究。最小波动过滤器作为离线基准构建工具而非推理时决策规则，有助于揭示预测信号。

Abstract: We study same-source multi-view learning and adversarial robustness for next-day direction prediction with financial image representations. On Shanghai Gold Exchange (SGE) spot gold data (2005-2025), we construct two window-aligned views from each rolling window: an OHLCV-rendered price/volume chart and a technical-indicator matrix. To ensure reliable evaluation, we adopt leakage-resistant time-block splits with embargo and use Matthews correlation coefficient (MCC). We find that results depend strongly on the label-noise regime: we apply an ex-post minimum-movement filter that discards samples with realized next-day absolute return below tau to define evaluation subsets with reduced near-zero label ambiguity. This induces a non-monotonic data-noise trade-off that can reveal predictive signal but eventually increases variance as sample size shrinks; the filter is used for offline benchmark construction rather than an inference-time decision rule. In the stabilized subsets, fusion is regime dependent: early fusion by channel stacking can exhibit negative transfer, whereas late fusion with dual encoders and a fusion head provides the dominant clean-performance gains; cross-view consistency regularization has secondary, backbone-dependent effects. We further evaluate test-time L-infinity perturbations using FGSM and PGD under two threat scenarios: view-constrained attacks that perturb one view and joint attacks that perturb both. We observe severe vulnerability at tiny budgets with strong view asymmetry. Late fusion consistently improves robustness under view-constrained attacks, but joint attacks remain challenging and can still cause substantial worst-case degradation.

</details>


### [13] [Divide, Harmonize, Then Conquer It: Shooting Multi-Commodity Flow Problems with Multimodal Language Models](https://arxiv.org/abs/2602.11057)
*Xinyu Yuan,Yan Qiao,Zonghui Wang,Wenzhi Chen*

Main category: cs.LG

TL;DR: Pram：首个基于多模态语言模型（MLM）解决多商品流问题的ML方法，通过分治策略和强化学习协调，在保证最优性的同时大幅提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着分配系统的快速扩展，现有优化引擎难以平衡最优性和可计算性。服务提供商亟需解决这一权衡困境，因此需要开发新的方法。

Method: Pram将原始问题分解为局部子问题，由MLM驱动的"智能体"解决，并通过多智能体强化学习算法协调这些子问题以确保全局一致性。该方法学习在上下文中执行梯度下降。

Result: 在真实世界数据集和公共拓扑上，Pram性能与线性规划求解器相当（甚至在某些情况下超越），运行时间快1-2个数量级，且在链路故障或流量突发下表现出强鲁棒性（性能下降<10%）。

Conclusion: Pram是首个利用MLM推理能力解决MCF问题的方法，理论可证明收敛到最优解，具有目标无关性，能无缝集成到主流分配系统，为未来网络提供实用且可扩展的解决方案。

Abstract: The multi-commodity flow (MCF) problem is a fundamental topic in network flow and combinatorial optimization, with broad applications in transportation, communication, and logistics, etc. Nowadays, the rapid expansion of allocation systems has posed challenges for existing optimization engines in balancing optimality and tractability. In this paper, we present Pram, the first ML-based method that leverages the reasoning power of multimodal language models (MLMs) for addressing the trade-off dilemma -- a great need of service providers. As part of our proposal, Pram (i) quickly computes high-quality allocations by dividing the original problem into local subproblems, which are then resolved by an MLM-powered "agent", and (ii) ensures global consistency by harmonizing these subproblems via a multi-agent reinforcement learning algorithm. Theoretically, we show that Pram, which learns to perform gradient descent in context, provably converges to the optimum within the family of MCF problems. Empirically, on real-world datasets and public topologies, Pram achieves performance comparable to, and in some cases even surpassing, linear programming solvers (very close to the optimal solution), and substantially lower runtimes (1 to 2 orders of magnitude faster). Moreover, Pram exhibits strong robustness (<10\% performance degradation under link failures or flow bursts), demonstrating MLM's generalization ability to unforeseen events. Pram is objective-agnostic and seamlessly integrates with mainstream allocation systems, providing a practical and scalable solution for future networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [14] [To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks](https://arxiv.org/abs/2602.10625)
*Nanxu Gong,Haotian Li,Sixun Dong,Jianxun Lian,Yanjie Fu,Xing Xie*

Main category: cs.AI

TL;DR: 研究发现推理模型在心理理论任务上并不比非推理模型表现更好，有时甚至更差，揭示了推理模型在社交推理中的局限性


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在数学和编程等正式推理任务上取得了进步，但这些优势是否能转移到心理理论等社交认知技能上仍不清楚。研究旨在系统评估推理模型在心理理论任务上的表现。

Method: 对9个先进的大型语言模型进行系统研究，比较推理模型与非推理模型在三个代表性心理理论基准上的表现。通过细粒度分析揭示问题，并设计了两种干预方法：慢到快自适应推理和思考到匹配捷径预防。

Result: 推理模型在心理理论任务上并不一致优于非推理模型，有时表现更差。分析发现：1)慢思考崩溃现象；2)适度自适应推理有益；3)选项匹配捷径问题。干预方法验证了这些问题。

Conclusion: 大型推理模型在正式推理（如数学、编程）上的进步不能完全转移到心理理论这种典型的社交推理任务上。实现稳健的心理理论需要开发超越现有推理方法的独特能力。

Abstract: Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [Deep Learning-based Method for Expressing Knowledge Boundary of Black-Box LLM](https://arxiv.org/abs/2602.10801)
*Haotian Sheng,Heyong Wang,Ming Hong,Hongman He,Junqiu Liu*

Main category: cs.CL

TL;DR: 提出LSCL方法，通过深度学习模型表达黑盒大语言模型的知识边界，解决幻觉问题，显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在内容生成失真（幻觉）问题，核心原因是缺乏对自身存储知识的认知，无法像人类一样表达超出知识边界的问题。现有研究主要关注白盒模型，而黑盒模型（仅提供API访问）的知识边界表达方法尚未充分探索。

Method: 提出LSCL（LLM-Supervised Confidence Learning），基于知识蒸馏框架设计深度学习模型。以黑盒LLM的输入问题、输出答案和token概率作为输入，构建输入与模型内部知识状态之间的映射，实现黑盒LLM知识边界的量化和表达。对于不支持token概率访问的黑盒LLM，还提出了自适应替代方法。

Result: 在多个公共数据集和主流黑盒LLM上的实验表明，LSCL能有效帮助黑盒LLM准确表达知识边界，在准确率和召回率等指标上显著优于现有基线模型。替代方法的性能接近LSCL，也优于基线模型。

Conclusion: LSCL方法成功解决了黑盒大语言模型知识边界表达的问题，为减少幻觉提供了有效工具，且具有良好的适应性和实用性。

Abstract: Large Language Models (LLMs) have achieved remarkable success, however, the emergence of content generation distortion (hallucination) limits their practical applications. The core cause of hallucination lies in LLMs' lack of awareness regarding their stored internal knowledge, preventing them from expressing their knowledge state on questions beyond their internal knowledge boundaries, as humans do. However, existing research on knowledge boundary expression primarily focuses on white-box LLMs, leaving methods suitable for black-box LLMs which offer only API access without revealing internal parameters-largely unexplored. Against this backdrop, this paper proposes LSCL (LLM-Supervised Confidence Learning), a deep learning-based method for expressing the knowledge boundaries of black-box LLMs. Based on the knowledge distillation framework, this method designs a deep learning model. Taking the input question, output answer, and token probability from a black-box LLM as inputs, it constructs a mapping between the inputs and the model' internal knowledge state, enabling the quantification and expression of the black-box LLM' knowledge boundaries. Experiments conducted on diverse public datasets and with multiple prominent black-box LLMs demonstrate that LSCL effectively assists black-box LLMs in accurately expressing their knowledge boundaries. It significantly outperforms existing baseline models on metrics such as accuracy and recall rate. Furthermore, considering scenarios where some black-box LLMs do not support access to token probability, an adaptive alternative method is proposed. The performance of this alternative approach is close to that of LSCL and surpasses baseline models.

</details>


### [16] [Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study](https://arxiv.org/abs/2602.11028)
*Artsvik Avetisyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 该研究使用三种语言表征（原始文本、词性增强、纯词性）分析自发语音，发现语法和句法特征在缺乏词汇内容时仍能有效区分认知衰退，支持基于语言特征的透明认知筛查。


<details>
  <summary>Details</summary>
Motivation: 自发语言中的细微变化是认知衰退的最早指标之一。识别可解释的语言标记可以支持透明且临床基础的筛查方法，用于早期痴呆检测。

Method: 使用DementiaBank Pitt Corpus的自发语音转录，采用三种语言表征：原始清理文本、词性增强表征（结合词汇和语法信息）、纯词性句法表征。使用逻辑回归和随机森林模型，在两种协议下评估：转录级训练测试分割和受试者级五折交叉验证（防止说话者重叠）。通过全局特征重要性检查模型可解释性，并使用Mann-Whitney U检验和Cliff's delta效应量进行统计验证。

Result: 所有表征下模型均获得稳定性能，句法和语法特征即使在缺乏词汇内容时仍保持强区分能力。受试者级评估产生更保守但一致的结果，特别是词性增强和纯词性表征。统计分析显示功能词使用、词汇多样性、句子结构和语篇连贯性存在显著组间差异，与机器学习特征重要性发现高度一致。

Conclusion: 抽象语言特征在临床现实评估中捕捉到早期认知衰退的稳健标记。通过将可解释机器学习与非参数统计验证相结合，本研究支持使用基于语言的特征进行透明可靠的语言认知筛查。

Abstract: Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches.
  Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation. Logistic regression and random forest models were evaluated under two protocols: transcript-level train-test splits and subject-level five-fold cross-validation to prevent speaker overlap. Model interpretability was examined using global feature importance, and statistical validation was conducted using Mann-Whitney U tests with Cliff's delta effect sizes.
  Results: Across representations, models achieved stable performance, with syntactic and grammatical features retaining strong discriminative power even in the absence of lexical content. Subject-level evaluation yielded more conservative but consistent results, particularly for POS-enhanced and POS-only representations. Statistical analysis revealed significant group differences in functional word usage, lexical diversity, sentence structure, and discourse coherence, aligning closely with machine learning feature importance findings.
  Conclusion: The results demonstrate that abstract linguistic features capture robust markers of early cognitive decline under clinically realistic evaluation. By combining interpretable machine learning with non-parametric statistical validation, this study supports the use of linguistically grounded features for transparent and reliable language-based cognitive screening.

</details>


### [17] [Conversational Behavior Modeling Foundation Model With Multi-Level Perception](https://arxiv.org/abs/2602.11065)
*Dingkun Zhou,Shuchang Pan,Jiachen Lian,Siddharth Banerjee,Sarika Pasumarthy,Dhruv Hebbar,Siddhant Patel,Zeyi Austin Li,Kan Jen Cheng,Sanay Bordia,Krish Patel,Akshaj Gupta,Tingle Li,Gopala Anumanchipalli*

Main category: cs.CL

TL;DR: 提出Graph-of-Thoughts框架，通过多层次感知建模对话中的思维链，预测交流意图和言语行为，实现全双工对话系统的推理和决策。


<details>
  <summary>Details</summary>
Motivation: 人类对话由隐含的思维链组织，表现为定时的言语行为。捕捉这种感知路径对于构建自然的全双工交互系统至关重要。

Method: 引入Graph-of-Thoughts框架，将对话过程建模为多层次感知，通过分层标注方案形式化意图到行动的路径，预测高层次交流意图和低层次言语行为，学习其因果和时间依赖关系。

Result: 在合成和真实全双工对话上的实验表明，该框架能够实现稳健的行为检测，产生可解释的推理链，并为全双工口语对话系统的对话推理基准测试奠定基础。

Conclusion: GoT框架通过将流式预测结构化为演化图，使Transformer能够预测下一个言语行为，生成决策的简明理由，并动态优化其推理，为自然全双工交互系统提供了有效解决方案。

Abstract: Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this perceptual pathway is key to building natural full-duplex interactive systems. We introduce a framework that models this process as multi-level perception, and then reasons over conversational behaviors via a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a high quality corpus that pairs controllable, event-rich dialogue data with human-annotated labels. The GoT framework structures streaming predictions as an evolving graph, enabling a transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [ReSPEC: A Framework for Online Multispectral Sensor Reconfiguration in Dynamic Environments](https://arxiv.org/abs/2602.10547)
*Yanchen Liu,Yuang Fan,Minghui Zhao,Xiaofan Jiang*

Main category: cs.RO

TL;DR: 提出一个将感知、学习和执行统一到闭环重构框架中的自适应多传感器融合系统，通过RL动态调整传感器配置以节省资源


<details>
  <summary>Details</summary>
Motivation: 现有多传感器融合系统采用静态配置，无论环境条件如何都以固定速率和保真度收集所有模态数据，浪费带宽、计算和能量，且无法在恶劣条件下优先使用关键传感器

Method: 引入一个统一感知、学习和执行的闭环重构框架：任务特定检测骨干提取多光谱特征并产生各模态的贡献分数，RL代理根据这些分数实时动态调整传感器配置（采样频率、分辨率、感知范围等）

Result: 在移动机器人上实现和评估该框架，自适应控制相比启发式基线减少29.3%的GPU负载，仅损失5.3%的准确率

Conclusion: 结果突显了资源感知自适应感知在嵌入式机器人平台上的潜力，通过动态调整传感器配置实现资源效率与性能的平衡

Abstract: Multi-sensor fusion is central to robust robotic perception, yet most existing systems operate under static sensor configurations, collecting all modalities at fixed rates and fidelity regardless of their situational utility. This rigidity wastes bandwidth, computation, and energy, and prevents systems from prioritizing sensors under challenging conditions such as poor lighting or occlusion. Recent advances in reinforcement learning (RL) and modality-aware fusion suggest the potential for adaptive perception, but prior efforts have largely focused on re-weighting features at inference time, ignoring the physical cost of sensor data collection. We introduce a framework that unifies sensing, learning, and actuation into a closed reconfiguration loop. A task-specific detection backbone extracts multispectral features (e.g. RGB, IR, mmWave, depth) and produces quantitative contribution scores for each modality. These scores are passed to an RL agent, which dynamically adjusts sensor configurations, including sampling frequency, resolution, sensing range, and etc., in real time. Less informative sensors are down-sampled or deactivated, while critical sensors are sampled at higher fidelity as environmental conditions evolve. We implement and evaluate this framework on a mobile rover, showing that adaptive control reduces GPU load by 29.3\% with only a 5.3\% accuracy drop compared to a heuristic baseline. These results highlight the potential of resource-aware adaptive sensing for embedded robotic platforms.

</details>


### [19] [Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces](https://arxiv.org/abs/2602.10961)
*Simone Orelli,Mirko Mizzoni,Antonio Franchi*

Main category: cs.RO

TL;DR: 首次为受寄生力影响的浮动刚体系统提供形式化稳定性分析，建立了悬停平衡点的局部指数稳定性


<details>
  <summary>Details</summary>
Motivation: 传统几何控制依赖力-力矩解耦假设，但在许多空中平台中，控制力矩会自然诱发寄生力，导致该假设失效。虽然已有针对此类耦合系统的策略得到实验验证，但缺乏严格的理论稳定性证明。

Method: 引入规范模型，构建基于李雅普诺夫函数的证明，建立悬停平衡点的局部指数稳定性。分析明确处理了结构挑战——特别是诱导的非最小相位行为——这些挑战阻碍了标准级联论证的应用。

Result: 为受寄生力影响的通用浮动刚体类别提供了首个形式化稳定性分析，证明了悬停平衡点的局部指数稳定性。

Conclusion: 填补了耦合系统稳定性理论认证的空白，为受寄生力影响的浮动刚体系统提供了严格的稳定性理论基础，解决了传统几何控制方法在非解耦系统中的局限性。

Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.

</details>


### [20] [YOR: Your Own Mobile Manipulator for Generalizable Robotics](https://arxiv.org/abs/2602.11150)
*Manan H Anjaria,Mehmet Enes Erciyes,Vedant Ghatnekar,Neha Navarkar,Haritheja Etukuru,Xiaole Jiang,Kanad Patel,Dhawal Kabra,Nicholas Wojno,Radhika Ajay Prayage,Soumith Chintala,Lerrel Pinto,Nur Muhammad Mahi Shafiullah,Zichen Jeff Cui*

Main category: cs.RO

TL;DR: YOR是一个开源、低成本（<1万美元）的移动操作机器人平台，集成了全向移动底盘、垂直升降机构和双臂系统，用于全身协调操作研究。


<details>
  <summary>Details</summary>
Motivation: 随着机器人学习技术的进步和驱动器的普及，低成本机器人平台需求增长，但移动操作的最佳形态（尤其是在预算有限情况下）仍是一个开放问题。

Method: 设计了一个模块化、易于组装的移动操作机器人YOR，采用现成组件，包括全向移动底盘、垂直升降机构和两个带夹爪的机械臂，实现全身移动和操作能力。

Result: YOR能够完成需要全身协调控制、双手操作和自主导航的任务，在移动操作研究中提供与现有平台相当的功能，但成本仅为现有平台的一小部分。

Conclusion: YOR为移动操作研究提供了一个功能竞争性强、成本低廉的开源平台，有助于推动机器人学习研究的发展。

Abstract: Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source, low-cost mobile manipulator that integrates an omnidirectional base, a telescopic vertical lift, and two arms with grippers to achieve whole-body mobility and manipulation. Our design emphasizes modularity, ease of assembly using off-the-shelf components, and affordability, with a bill-of-materials cost under 10,000 USD. We demonstrate YOR's capability by completing tasks that require coordinated whole-body control, bimanual manipulation, and autonomous navigation. Overall, YOR offers competitive functionality for mobile manipulation research at a fraction of the cost of existing platforms. Project website: https://www.yourownrobot.ai/

</details>
