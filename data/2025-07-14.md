<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Portable Biomechanics Laboratory: Clinically Accessible Movement Analysis from a Handheld Smartphone](https://arxiv.org/abs/2507.08268)
*J. D. Peiffer,Kunal Shah,Irina Djuraskovic,Shawana Anarwala,Kayan Abdou,Rujvee Patel,Prakash Jayabalan,Brenton Pennicooke,R. James Cotton*

Main category: cs.CV

TL;DR: 该论文提出了一种便携式生物力学实验室（PBL），通过智能手机应用和算法测量运动生物力学数据，验证了其在临床中的可靠性和敏感性。


<details>
  <summary>Details</summary>
Motivation: 临床实践中缺乏客观测量运动的方法，限制了生物力学数据的应用，PBL旨在填补这一空白。

Method: 开发了基于智能手机的PBL系统，包括数据收集应用和生物力学模型拟合算法，并在多类人群中进行验证。

Result: PBL的关节角度误差在3度以内，步态指标可靠且敏感，能捕捉临床差异，比患者报告结果更敏感。

Conclusion: PBL为临床提供了一种可扩展、低负担的生物力学测量工具，有望广泛应用于运动障碍监测。

Abstract: The way a person moves is a direct reflection of their neurological and
musculoskeletal health, yet it remains one of the most underutilized vital
signs in clinical practice. Although clinicians visually observe movement
impairments, they lack accessible and validated methods to objectively measure
movement in routine care. This gap prevents wider use of biomechanical
measurements in practice, which could enable more sensitive outcome measures or
earlier identification of impairment. We present our Portable Biomechanics
Laboratory (PBL), which includes a secure, cloud-enabled smartphone app for
data collection and a novel algorithm for fitting biomechanical models to this
data. We extensively validated PBL's biomechanical measures using a large,
clinically representative dataset. Next, we tested the usability and utility of
our system in neurosurgery and sports medicine clinics. We found joint angle
errors within 3 degrees across participants with neurological injury,
lower-limb prosthesis users, pediatric inpatients, and controls. In addition to
being easy to use, gait metrics computed from the PBL showed high reliability
and were sensitive to clinical differences. For example, in individuals
undergoing decompression surgery for cervical myelopathy, the mJOA score is a
common patient-reported outcome measure; we found that PBL gait metrics
correlated with mJOA scores and demonstrated greater responsiveness to surgical
intervention than the patient-reported outcomes. These findings support the use
of handheld smartphone video as a scalable, low-burden tool for capturing
clinically meaningful biomechanical data, offering a promising path toward
accessible monitoring of mobility impairments. We release the first clinically
validated method for measuring whole-body kinematics from handheld smartphone
video at
https://intelligentsensingandrehabilitation.github.io/MonocularBiomechanics/ .

</details>


### [2] [NeuralOS: Towards Simulating Operating Systems via Neural Generative Models](https://arxiv.org/abs/2507.08800)
*Luke Rivard,Sun Sun,Hongyu Guo,Wenhu Chen,Yuntian Deng*

Main category: cs.CV

TL;DR: NeuralOS是一个神经框架，通过直接预测屏幕帧来模拟操作系统的图形用户界面（GUI），结合RNN和扩散渲染器，训练于Ubuntu XFCE数据集，能生成真实GUI序列，但键盘交互仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用神经网络模拟操作系统的GUI交互，为未来人机交互系统提供自适应生成界面。

Method: 结合RNN跟踪计算机状态和扩散渲染器生成屏幕图像，训练于Ubuntu XFCE数据集。

Result: 成功渲染真实GUI序列，准确捕捉鼠标交互，可靠预测状态转换（如应用启动），但键盘交互精度不足。

Conclusion: NeuralOS为未来自适应生成神经界面迈出一步，键盘交互仍需改进。

Abstract: We introduce NeuralOS, a neural framework that simulates graphical user
interfaces (GUIs) of operating systems by directly predicting screen frames in
response to user inputs such as mouse movements, clicks, and keyboard events.
NeuralOS combines a recurrent neural network (RNN), which tracks computer
state, with a diffusion-based neural renderer that generates screen images. The
model is trained on a large-scale dataset of Ubuntu XFCE recordings, which
include both randomly generated interactions and realistic interactions
produced by AI agents. Experiments show that NeuralOS successfully renders
realistic GUI sequences, accurately captures mouse interactions, and reliably
predicts state transitions like application launches. Although modeling
fine-grained keyboard interactions precisely remains challenging, NeuralOS
offers a step toward creating fully adaptive, generative neural interfaces for
future human-computer interaction systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis](https://arxiv.org/abs/2507.08050)
*Ming Wang,Zhaoyang Duan,Dong Xue,Fangzhou Liu,Zhongheng Zhang*

Main category: cs.LG

TL;DR: 提出了一种联邦少样本学习框架，结合隐私保护机制，解决呼吸疾病诊断中数据标注不足和隐私保护问题。


<details>
  <summary>Details</summary>
Motivation: 医疗数据标注的劳动密集性和患者隐私问题导致高质量标注数据稀缺，且现有集中式方法可能泄露隐私。

Method: 采用元随机梯度下降算法减少过拟合，并引入高斯差分隐私噪声保护梯度；通过加权平均算法聚合本地模型。

Result: 实验表明，该方法在保护隐私的同时，能有效诊断不同结构、类别和分布的呼吸疾病数据。

Conclusion: 该框架为资源受限环境下呼吸疾病诊断提供了高效且隐私安全的解决方案。

Abstract: The labor-intensive nature of medical data annotation presents a significant
challenge for respiratory disease diagnosis, resulting in a scarcity of
high-quality labeled datasets in resource-constrained settings. Moreover,
patient privacy concerns complicate the direct sharing of local medical data
across institutions, and existing centralized data-driven approaches, which
rely on amounts of available data, often compromise data privacy. This study
proposes a federated few-shot learning framework with privacy-preserving
mechanisms to address the issues of limited labeled data and privacy protection
in diagnosing respiratory diseases. In particular, a meta-stochastic gradient
descent algorithm is proposed to mitigate the overfitting problem that arises
from insufficient data when employing traditional gradient descent methods for
neural network training. Furthermore, to ensure data privacy against gradient
leakage, differential privacy noise from a standard Gaussian distribution is
integrated into the gradients during the training of private models with local
data, thereby preventing the reconstruction of medical images. Given the
impracticality of centralizing respiratory disease data dispersed across
various medical institutions, a weighted average algorithm is employed to
aggregate local diagnostic models from different clients, enhancing the
adaptability of a model across diverse scenarios. Experimental results show
that the proposed method yields compelling results with the implementation of
differential privacy, while effectively diagnosing respiratory diseases using
data from different structures, categories, and distributions.

</details>


### [4] [ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction](https://arxiv.org/abs/2507.08153)
*Pinaki Prasad Guha Neogi,Ahmad Mohammadshirazi,Rajiv Ramnath*

Main category: cs.LG

TL;DR: ALCo-FM是一种自适应长上下文基础模型，用于交通风险预测，通过动态选择上下文窗口和多模态数据融合，实现了高准确性和校准性。


<details>
  <summary>Details</summary>
Motivation: 交通事故虽罕见但影响重大，需要长上下文多模态推理进行准确风险预测。

Method: 模型采用动态上下文窗口选择、浅层交叉注意力编码、局部GAT层和全局稀疏Transformer，结合蒙特卡洛dropout。

Result: 在15个美国城市数据上训练，ALCo-FM达到0.94准确率、0.92 F1和0.04 ECE，优于20多个基线模型。

Conclusion: ALCo-FM在大型城市风险预测中表现出色，代码和数据集已开源。

Abstract: Traffic accidents are rare, yet high-impact events that require long-context
multimodal reasoning for accurate risk forecasting. In this paper, we introduce
ALCo-FM, a unified adaptive long-context foundation model that computes a
volatility pre-score to dynamically select context windows for input data and
encodes and fuses these multimodal data via shallow cross attention. Following
a local GAT layer and a BigBird-style sparse global transformer over H3
hexagonal grids, coupled with Monte Carlo dropout for confidence, the model
yields superior, well-calibrated predictions. Trained on data from 15 US cities
with a class-weighted loss to counter label imbalance, and fine-tuned with
minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and
an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in
large-scale urban risk prediction. Code and dataset are available at:
https://github.com/PinakiPrasad12/ALCo-FM

</details>


### [5] [SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation](https://arxiv.org/abs/2507.08508)
*Haotian Xu,Jinrui Zhou,Xichong Zhang,Mingjun Xiao,He Sun,Yin Xu*

Main category: cs.LG

TL;DR: SFedKD通过多教师知识蒸馏解决SFL中的灾难性遗忘问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: SFL在异构环境中存在灾难性遗忘问题，影响模型性能。

Method: 提出SFedKD框架，采用多教师知识蒸馏和细粒度权重分配策略，并设计基于贪婪策略的教师选择机制。

Result: SFedKD有效缓解灾难性遗忘，性能优于现有FL方法。

Conclusion: SFedKD为SFL提供了一种高效解决方案，显著提升模型训练效果。

Abstract: Federated Learning (FL) is a distributed machine learning paradigm which
coordinates multiple clients to collaboratively train a global model via a
central server. Sequential Federated Learning (SFL) is a newly-emerging FL
training framework where the global model is trained in a sequential manner
across clients. Since SFL can provide strong convergence guarantees under data
heterogeneity, it has attracted significant research attention in recent years.
However, experiments show that SFL suffers from severe catastrophic forgetting
in heterogeneous environments, meaning that the model tends to forget knowledge
learned from previous clients. To address this issue, we propose an SFL
framework with discrepancy-aware multi-teacher knowledge distillation, called
SFedKD, which selects multiple models from the previous round to guide the
current round of training. In SFedKD, we extend the single-teacher Decoupled
Knowledge Distillation approach to our multi-teacher setting and assign
distinct weights to teachers' target-class and non-target-class knowledge based
on the class distributional discrepancy between teacher and student data.
Through this fine-grained weighting strategy, SFedKD can enhance model training
efficacy while mitigating catastrophic forgetting. Additionally, to prevent
knowledge dilution, we eliminate redundant teachers for the knowledge
distillation and formalize it as a variant of the maximum coverage problem.
Based on the greedy strategy, we design a complementary-based teacher selection
mechanism to ensure that the selected teachers achieve comprehensive knowledge
space coverage while reducing communication and computational costs. Extensive
experiments show that SFedKD effectively overcomes catastrophic forgetting in
SFL and outperforms state-of-the-art FL methods.

</details>


### [6] [Remote Sensing Reveals Adoption of Sustainable Rice Farming Practices Across Punjab, India](https://arxiv.org/abs/2507.08605)
*Ando Shah,Rajveer Singh,Akram Zaytar,Girmaw Abebe Tadesse,Caleb Robinson,Negar Tafti,Stephen A. Wood,Rahul Dodhia,Juan M. Lavista Ferres*

Main category: cs.LG

TL;DR: 利用遥感技术监测印度旁遮普邦可持续水稻灌溉实践（如DSR和AWD）的采用情况，为政策制定提供数据支持。


<details>
  <summary>Details</summary>
Motivation: 水稻种植消耗大量淡水，可持续灌溉实践（如DSR和AWD）可节水20-40%，但缺乏采用率数据阻碍政策制定。

Method: 开发遥感框架，结合Sentinel-1卫星影像和地面数据（PRANA项目），分类监测灌溉实践。

Result: 模型F1-score达78%，可扩展至300万农田，预测与政府记录高度相关（Pearson=0.77）。

Conclusion: 该研究为政策制定者提供了监测可持续灌溉实践的工具，支持精准干预和项目评估。

Abstract: Rice cultivation consumes 24-30% of global freshwater, creating critical
water management challenges in major rice-producing regions. Sustainable
irrigation practices like direct seeded rice (DSR) and alternate wetting and
drying (AWD) can reduce water use by 20-40% while maintaining yields, helping
secure long-term agricultural productivity as water scarcity intensifies - a
key component of the Zero Hunger Sustainable Development Goal. However, limited
data on adoption rates of these practices prevents evidence-based policymaking
and targeted resource allocation. We developed a novel remote sensing framework
to monitor sustainable water management practices at scale in Punjab, India - a
region facing severe groundwater depletion of 41.6 cm/year. To collect
essential ground truth data, we partnered with the Nature Conservancy's
Promoting Regenerative and No-burn Agriculture (PRANA) program, which trained
approximately 1,400 farmers on water-saving techniques while documenting their
field-level practices. Using this data, we created a classification system with
Sentinel-1 satellite imagery that separates water management along sowing and
irrigation dimensions. Our approach achieved a 78% F1-score in distinguishing
DSR from traditional puddled transplanted rice without requiring prior
knowledge of planting dates. We demonstrated scalability by mapping DSR
adoption across approximately 3 million agricultural plots in Punjab, with
district-level predictions showing strong correlation (Pearson=0.77, RBO= 0.77)
with government records. This study provides policymakers with a powerful tool
to track sustainable water management adoption, target interventions, and
measure program impacts at scale.

</details>


### [7] [Forget Me Not: Fighting Local Overfitting with Knowledge Fusion and Distillation](https://arxiv.org/abs/2507.08686)
*Uri Stern,Eli Corn,Daphna Weinshall*

Main category: cs.LG

TL;DR: 论文提出了一种衡量深度模型在验证数据上遗忘率的分数，揭示了局部过拟合现象，并提出了一种两阶段方法（知识融合与蒸馏）来提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统理论认为模型容量增加会导致过拟合，但实践中很少见。论文探讨了局部过拟合的可能性及其与双下降现象的关系。

Method: 提出了一种两阶段方法：1) 将检查点聚合为集成模型；2) 通过知识蒸馏将其压缩为原始大小的单一模型。

Result: 实验表明，该方法在标签噪声情况下优于原始模型和独立训练的集成模型，同时降低了训练和推理复杂度。

Conclusion: 局部过拟合是真实存在的现象，提出的方法能有效恢复遗忘知识，实现性能提升且不增加推理成本。

Abstract: Overfitting in deep neural networks occurs less frequently than expected.
This is a puzzling observation, as theory predicts that greater model capacity
should eventually lead to overfitting -- yet this is rarely seen in practice.
But what if overfitting does occur, not globally, but in specific sub-regions
of the data space? In this work, we introduce a novel score that measures the
forgetting rate of deep models on validation data, capturing what we term local
overfitting: a performance degradation confined to certain regions of the input
space. We demonstrate that local overfitting can arise even without
conventional overfitting, and is closely linked to the double descent
phenomenon.
  Building on these insights, we introduce a two-stage approach that leverages
the training history of a single model to recover and retain forgotten
knowledge: first, by aggregating checkpoints into an ensemble, and then by
distilling it into a single model of the original size, thus enhancing
performance without added inference cost.
  Extensive experiments across multiple datasets, modern architectures, and
training regimes validate the effectiveness of our approach. Notably, in the
presence of label noise, our method -- Knowledge Fusion followed by Knowledge
Distillation -- outperforms both the original model and independently trained
ensembles, achieving a rare win-win scenario: reduced training and inference
complexity.

</details>


### [8] [Monitoring Risks in Test-Time Adaptation](https://arxiv.org/abs/2507.08721)
*Mona Schirmer,Metod Jazbec,Christian A. Naesseth,Eric Nalisnick*

Main category: cs.LG

TL;DR: 论文提出了一种结合测试时适应（TTA）与风险监控框架的方法，以检测模型性能下降的临界点，确保模型在无标签测试数据下的持续有效性。


<details>
  <summary>Details</summary>
Motivation: 测试时数据偏移是模型部署中的常见挑战，TTA虽能暂时适应，但模型最终可能失效。需要一种方法检测性能下降的临界点。

Method: 扩展了基于序列测试的监控工具，引入置信序列，适应模型在测试时更新且无标签数据的场景。

Result: 在多种数据集、分布偏移类型和TTA方法中验证了所提框架的有效性。

Conclusion: 结合TTA与风险监控框架，可实现对模型性能的严格统计监控，确保模型在无标签数据下的可靠性。

Abstract: Encountering shifted data at test time is a ubiquitous challenge when
deploying predictive models. Test-time adaptation (TTA) methods address this
issue by continuously adapting a deployed model using only unlabeled test data.
While TTA can extend the model's lifespan, it is only a temporary solution.
Eventually the model might degrade to the point that it must be taken offline
and retrained. To detect such points of ultimate failure, we propose pairing
TTA with risk monitoring frameworks that track predictive performance and raise
alerts when predefined performance criteria are violated. Specifically, we
extend existing monitoring tools based on sequential testing with confidence
sequences to accommodate scenarios in which the model is updated at test time
and no test labels are available to estimate the performance metrics of
interest. Our extensions unlock the application of rigorous statistical risk
monitoring to TTA, and we demonstrate the effectiveness of our proposed TTA
monitoring framework across a representative set of datasets, distribution
shift types, and TTA methods.

</details>


### [9] [Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning](https://arxiv.org/abs/2507.08793)
*James McCarthy,Radu Marinescu,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: ORAC方法通过乐观探索优化风险规避约束强化学习，避免保守策略导致的次优解，提升奖励与安全的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统风险规避方法因保守探索易导致次优策略，无法有效平衡奖励与安全约束。

Method: ORAC通过最大化奖励值函数的上界和最小化风险值函数的下界，动态调整成本权重，鼓励探索不确定区域。

Result: 实验表明ORAC在Safety-Gymnasium和CityLearn等任务中显著提升奖励-成本权衡，避免次优策略。

Conclusion: ORAC通过乐观探索有效解决了风险规避强化学习中的保守性问题，提升了策略性能。

Abstract: Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies
that minimise the likelihood of rare and catastrophic constraint violations
caused by an environment's inherent randomness. In general, risk-aversion leads
to conservative exploration of the environment which typically results in
converging to sub-optimal policies that fail to adequately maximise reward or,
in some cases, fail to achieve the goal. In this paper, we propose an
exploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic
(ORAC), which constructs an exploratory policy by maximising a local upper
confidence bound of the state-action reward value function whilst minimising a
local lower confidence bound of the risk-averse state-action cost value
function. Specifically, at each step, the weighting assigned to the cost value
is increased or decreased if it exceeds or falls below the safety constraint
value. This way the policy is encouraged to explore uncertain regions of the
environment to discover high reward states whilst still satisfying the safety
constraints. Our experimental results demonstrate that the ORAC approach
prevents convergence to sub-optimal policies and improves significantly the
reward-cost trade-off in various continuous control tasks such as
Safety-Gymnasium and a complex building energy management environment
CityLearn.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](https://arxiv.org/abs/2507.08207)
*Zhengye Han,Quanyan Zhu*

Main category: cs.AI

TL;DR: 本文提出了一种动态Stackelberg博弈框架，用于建模大型语言模型（LLM）越狱攻击中的攻防交互，并提出了结合对抗探索和防御策略的“Purple Agent”解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键应用中的部署增加，越狱攻击（绕过安全机制）成为重要问题，需要有效的防御方法。

Method: 采用动态Stackelberg博弈框架，将提示-响应动态建模为序贯扩展形式博弈，并提出基于RRT的“Purple Agent”主动防御方案。

Result: 该框架为分析对抗动态提供了原则性方法，并有效降低了越狱风险。

Conclusion: 动态博弈框架和“Purple Agent”为LLM安全防御提供了理论基础和实践工具。

Abstract: As large language models (LLMs) are increasingly deployed in critical
applications, the challenge of jailbreaking, where adversaries manipulate the
models to bypass safety mechanisms, has become a significant concern. This
paper presents a dynamic Stackelberg game framework to model the interactions
between attackers and defenders in the context of LLM jailbreaking. The
framework treats the prompt-response dynamics as a sequential extensive-form
game, where the defender, as the leader, commits to a strategy while
anticipating the attacker's optimal responses. We propose a novel agentic AI
solution, the "Purple Agent," which integrates adversarial exploration and
defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple
Agent actively simulates potential attack trajectories and intervenes
proactively to prevent harmful outputs. This approach offers a principled
method for analyzing adversarial dynamics and provides a foundation for
mitigating the risk of jailbreaking.

</details>


### [11] [Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm](https://arxiv.org/abs/2507.08249)
*Bill Marino,Ari Juels*

Main category: cs.AI

TL;DR: 探讨AI代理访问加密货币和智能合约可能带来的新危害，并呼吁技术研究以减少这些风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理越来越多地接触加密货币和智能合约，研究其潜在危害变得至关重要。

Method: 分析加密货币和智能合约的独特性质，详细描述可能的新危害向量。

Result: 识别出AI代理使用加密货币和智能合约可能引发的多种新危害。

Conclusion: 呼吁加强技术研究，以预防和减轻这些危害，确保AI代理的安全使用。

Abstract: There is growing interest in giving AI agents access to cryptocurrencies as
well as to the smart contracts that transact them. But doing so, this position
paper argues, could lead to formidable new vectors of AI harm. To support this
argument, we first examine the unique properties of cryptocurrencies and smart
contracts that could lead to these new vectors of harm. Next, we describe each
of these new vectors of harm in detail. Finally, we conclude with a call for
more technical research aimed at preventing and mitigating these harms and,
thereby making it safer to endow AI agents with cryptocurrencies and smart
contracts.

</details>
