<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos](https://arxiv.org/abs/2507.16878)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang,Wentao Zhang*

Main category: cs.CV

TL;DR: 研究者提出了CausalStep基准测试，专门评估大语言模型在视频中的逐步因果推理能力，发现当前模型与人类水平存在显著差距


<details>
  <summary>Details</summary>
Motivation: 现有的视频基准测试主要评估浅层理解和推理，允许模型利用全局上下文，无法严格评估真正的因果和逐步推理能力，而大语言模型在视频推理方面仍面临重大挑战

Method: 构建CausalStep基准测试：将视频分割为因果关联的单元，执行严格的逐步问答协议，要求顺序回答并防止捷径解决方案，包含100个视频、6个类别、1852个多选题，并引入7个诊断指标进行全面评估

Result: 通过对领先的专有和开源模型以及人类基线的实验评估，发现当前模型与人类水平的逐步推理能力之间存在显著差距

Conclusion: CausalStep提供了一个严格的基准测试来推动稳健且可解释的视频推理进展，为评估模型的因果推理能力提供了有效工具

Abstract: Recent advances in large language models (LLMs) have improved reasoning in
text and image domains, yet achieving robust video reasoning remains a
significant challenge. Existing video benchmarks mainly assess shallow
understanding and reasoning and allow models to exploit global context, failing
to rigorously evaluate true causal and stepwise reasoning. We present
CausalStep, a benchmark designed for explicit stepwise causal reasoning in
videos. CausalStep segments videos into causally linked units and enforces a
strict stepwise question-answer (QA) protocol, requiring sequential answers and
preventing shortcut solutions. Each question includes carefully constructed
distractors based on error type taxonomy to ensure diagnostic value. The
benchmark features 100 videos across six categories and 1,852 multiple-choice
QA pairs. We introduce seven diagnostic metrics for comprehensive evaluation,
enabling precise diagnosis of causal reasoning capabilities. Experiments with
leading proprietary and open-source models, as well as human baselines, reveal
a significant gap between current models and human-level stepwise reasoning.
CausalStep provides a rigorous benchmark to drive progress in robust and
interpretable video reasoning.

</details>


### [2] [PolarAnything: Diffusion-based Polarimetric Image Synthesis](https://arxiv.org/abs/2507.17268)
*Kailong Zhang,Youwei Lyu,Heng Guo,Si Li,Zhanyu Ma,Boxin Shi*

Main category: cs.CV

TL;DR: 本文提出PolarAnything，一个基于扩散模型的框架，能够从单张RGB图像生成具有真实感和物理准确性的偏振图像，解决了现有偏振相机可及性有限和传统偏振模拟器需要大量3D资产的问题。


<details>
  <summary>Details</summary>
Motivation: 偏振图像在图像增强和3D重建任务中很有用，但偏振相机的可及性有限阻碍了其广泛应用。现有的偏振模拟器Mitsuba依赖参数化偏振图像形成模型，需要大量包含形状和PBR材质的3D资产，无法生成大规模的真实感图像。因此需要开发能够合成真实感偏振图像的新方法。

Method: 作者提出PolarAnything，一个基于扩散模型的生成框架。该方法受到预训练扩散模型零样本性能的启发，采用有效的表示策略来保持偏振特性的保真度，能够从单张RGB输入生成偏振图像，消除了对3D资产集合的依赖。

Result: 实验表明，该模型能够生成高质量的偏振图像，同时具有真实感和物理准确性。生成的偏振图像还能够支持下游任务，如基于偏振的形状恢复（shape from polarization）。

Conclusion: PolarAnything成功解决了偏振图像合成中的关键问题，通过基于扩散模型的框架实现了从单张RGB图像到偏振图像的转换，既保证了视觉真实感又维持了物理准确性，为偏振成像技术的广泛应用提供了新的可能性。

Abstract: Polarization images facilitate image enhancement and 3D reconstruction tasks,
but the limited accessibility of polarization cameras hinders their broader
application. This gap drives the need for synthesizing photorealistic
polarization images.The existing polarization simulator Mitsuba relies on a
parametric polarization image formation model and requires extensive 3D assets
covering shape and PBR materials, preventing it from generating large-scale
photorealistic images. To address this problem, we propose PolarAnything,
capable of synthesizing polarization images from a single RGB input with both
photorealism and physical accuracy, eliminating the dependency on 3D asset
collections. Drawing inspiration from the zero-shot performance of pretrained
diffusion models, we introduce a diffusion-based generative framework with an
effective representation strategy that preserves the fidelity of polarization
properties. Experiments show that our model generates high-quality polarization
images and supports downstream tasks like shape from polarization.

</details>


### [3] [Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2507.17281)
*Huanli Zhuo,Leilei Ma,Haifeng Zhao,Shiwei Zhou,Dengdi Sun,Yanping Fu*

Main category: cs.CV

TL;DR: 提出了FA-SAM框架，通过自动提示生成模型(AGM)和图像-提示嵌入融合(IPEF)模块，实现了医学图像分割的全自动化SAM，解决了SAM依赖专家标注提示和错误提示导致分割失败的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的医学图像分割模型面临两个主要挑战：1)SAM高度依赖领域专家标注的提示，无法实现全自动医学图像分割，限制临床应用；2)错误的提示(如过大或过小的边界框)会误导SAM生成错误的掩码结果

Method: 提出FA-SAM单源域泛化框架，包含两个关键创新：1)配备浅层特征不确定性建模(SUFM)模块的自动提示生成模型(AGM)分支；2)集成到SAM掩码解码器中的图像-提示嵌入融合(IPEF)模块。AGM通过SUFM模块建模浅层特征的不确定性分布来生成边界框提示，IPEF模块整合SAM图像嵌入和提示嵌入的多尺度信息来捕获目标对象的全局和局部细节

Result: 在公开的前列腺和眼底血管数据集上进行的大量实验验证了FA-SAM的有效性，证明其能够解决上述挑战并具有良好的应用潜力

Conclusion: FA-SAM框架通过自动提示生成和图像-提示嵌入融合技术，成功实现了医学图像分割的全自动化SAM，有效缓解了错误提示的影响，为SAM在临床环境中的应用提供了可行的解决方案

Abstract: Although SAM-based single-source domain generalization models for medical
image segmentation can mitigate the impact of domain shift on the model in
cross-domain scenarios, these models still face two major challenges. First,
the segmentation of SAM is highly dependent on domain-specific expert-annotated
prompts, which prevents SAM from achieving fully automated medical image
segmentation and therefore limits its application in clinical settings. Second,
providing poor prompts (such as bounding boxes that are too small or too large)
to the SAM prompt encoder can mislead SAM into generating incorrect mask
results. Therefore, we propose the FA-SAM, a single-source domain
generalization framework for medical image segmentation that achieves fully
automated SAM. FA-SAM introduces two key innovations: an Auto-prompted
Generation Model (AGM) branch equipped with a Shallow Feature Uncertainty
Modeling (SUFM) module, and an Image-Prompt Embedding Fusion (IPEF) module
integrated into the SAM mask decoder. Specifically, AGM models the uncertainty
distribution of shallow features through the SUFM module to generate bounding
box prompts for the target domain, enabling fully automated segmentation with
SAM. The IPEF module integrates multiscale information from SAM image
embeddings and prompt embeddings to capture global and local details of the
target object, enabling SAM to mitigate the impact of poor prompts. Extensive
experiments on publicly available prostate and fundus vessel datasets validate
the effectiveness of FA-SAM and highlight its potential to address the above
challenges.

</details>


### [4] [Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras](https://arxiv.org/abs/2507.17664)
*Lingdong Kong,Dongyue Lu,Ao Liang,Rong Li,Yuhao Dong,Tianshuai Hu,Lai Xing Ng,Wei Tsang Ooi,Benoit R. Cottereau*

Main category: cs.CV

TL;DR: 本文提出了Talk2Event，这是首个基于事件相机的大规模语言驱动目标定位基准数据集，包含超过30,000个验证的指称表达式，并开发了EventRefer框架来处理多属性融合的目标定位任务。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有微秒级延迟和运动模糊鲁棒性，适合理解动态环境，但将这些异步流与人类语言连接仍是一个开放挑战。现有研究缺乏大规模的基于事件的语言驱动目标定位基准。

Method: 构建了Talk2Event数据集，包含超过30,000个来自真实驾驶数据的验证指称表达式，每个表达式都包含四个定位属性（外观、状态、与观察者的关系、与其他物体的关系）。提出EventRefer框架，使用事件-属性专家混合模型(MoEE)动态融合多属性表示。

Result: EventRefer方法在仅事件、仅帧和事件-帧融合三种设置下都相对于最先进基线方法取得了一致的性能提升，能够适应不同模态和场景动态。

Conclusion: 该数据集和方法为推进多模态、时间感知和语言驱动的感知技术在真实世界机器人和自主系统中的应用奠定了基础。

Abstract: Event cameras offer microsecond-level latency and robustness to motion blur,
making them ideal for understanding dynamic environments. Yet, connecting these
asynchronous streams to human language remains an open challenge. We introduce
Talk2Event, the first large-scale benchmark for language-driven object
grounding in event-based perception. Built from real-world driving data, we
provide over 30,000 validated referring expressions, each enriched with four
grounding attributes -- appearance, status, relation to viewer, and relation to
other objects -- bridging spatial, temporal, and relational reasoning. To fully
exploit these cues, we propose EventRefer, an attribute-aware grounding
framework that dynamically fuses multi-attribute representations through a
Mixture of Event-Attribute Experts (MoEE). Our method adapts to different
modalities and scene dynamics, achieving consistent gains over state-of-the-art
baselines in event-only, frame-only, and event-frame fusion settings. We hope
our dataset and approach will establish a foundation for advancing multimodal,
temporally-aware, and language-driven perception in real-world robotics and
autonomy.

</details>


### [5] [Principled Multimodal Representation Learning](https://arxiv.org/abs/2507.17343)
*Xiaohao Liu,Xiaobo Xia,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了PMRL框架，通过优化表示矩阵的主奇异值来实现多模态同时对齐，避免了传统方法对锚点模态的依赖，并通过基于softmax的损失函数和实例级对比正则化提高了对齐的稳定性和效果。


<details>
  <summary>Details</summary>
Motivation: 传统多模态表示学习方法依赖成对对比学习和预定义锚点模态，限制了所有模态间的对齐效果。现有的多模态同时对齐方法存在固定锚点限制和奇异值乘积优化不稳定等问题，需要一种更稳定、无锚点依赖的多模态对齐方法。

Method: 提出PMRL（原则性多模态表示学习）框架，基于完全对齐对应rank-1格拉姆矩阵的理论洞察，通过优化表示矩阵的主奇异值来沿共享主方向对齐模态。使用基于softmax的损失函数将奇异值作为logits来优先考虑最大奇异值，并采用主特征向量上的实例级对比正则化来维持实例间可分性并防止表示崩塌。

Result: 在多种任务上的广泛实验表明PMRL相比基线方法具有优越性，实现了更好的多模态对齐效果。

Conclusion: PMRL框架成功解决了传统多模态对齐方法的局限性，通过理论指导的奇异值优化实现了稳定的无锚点多模态同时对齐，为多模态表示学习提供了新的有效解决方案。

Abstract: Multimodal representation learning seeks to create a unified representation
space by integrating diverse data modalities to improve multimodal
understanding. Traditional methods often depend on pairwise contrastive
learning, which relies on a predefined anchor modality, restricting alignment
across all modalities. Recent advances have investigated the simultaneous
alignment of multiple modalities, yet several challenges remain, such as
limitations imposed by fixed anchor points and instability arising from
optimizing the product of singular values. To address the challenges, in this
paper, we propose Principled Multimodal Representation Learning (PMRL), a novel
framework that achieves simultaneous alignment of multiple modalities without
anchor dependency in a more stable manner. Specifically, grounded in the
theoretical insight that full alignment corresponds to a rank-1 Gram matrix,
PMRL optimizes the dominant singular value of the representation matrix to
align modalities along a shared leading direction. We propose a softmax-based
loss function that treats singular values as logits to prioritize the largest
singular value. Besides, instance-wise contrastive regularization on the
leading eigenvectors maintains inter-instance separability and prevents
representation collapse. Extensive experiments across diverse tasks demonstrate
PMRL's superiority compared to baseline methods. The source code will be
publicly available.

</details>


### [6] [SFUOD: Source-Free Unknown Object Detection](https://arxiv.org/abs/2507.17373)
*Keon-Hee Park,Seun-An Choe,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: 提出了Source-Free Unknown Object Detection (SFUOD)场景，通过CollaPAUL框架在无需源域数据的情况下，既能检测已知目标也能发现未定义的未知目标


<details>
  <summary>Details</summary>
Motivation: 传统的无源域目标检测假设目标域中只存在源域预定义的目标，这种封闭集设定限制了检测器发现未定义目标的能力，因此需要放宽这一假设

Method: 提出CollaPAUL框架，包含两个核心组件：1）协作调优通过跨域注意力机制整合辅助编码器的目标相关知识和预训练检测器的源域知识；2）基于主轴的未知标注通过主轴投影估计目标性并结合模型预测置信度为未知目标分配伪标签

Result: 在SFUOD基准测试中达到了最先进的性能，广泛的实验验证了方法的有效性

Conclusion: CollaPAUL成功解决了无源域目标检测中的未知目标发现问题，通过协作调优和主轴未知标注实现了对已知和未知目标的有效检测

Abstract: Source-free object detection adapts a detector pre-trained on a source domain
to an unlabeled target domain without requiring access to labeled source data.
While this setting is practical as it eliminates the need for the source
dataset during domain adaptation, it operates under the restrictive assumption
that only pre-defined objects from the source domain exist in the target
domain. This closed-set setting prevents the detector from detecting undefined
objects. To ease this assumption, we propose Source-Free Unknown Object
Detection (SFUOD), a novel scenario which enables the detector to not only
recognize known objects but also detect undefined objects as unknown objects.
To this end, we propose CollaPAUL (Collaborative tuning and Principal
Axis-based Unknown Labeling), a novel framework for SFUOD. Collaborative tuning
enhances knowledge adaptation by integrating target-dependent knowledge from
the auxiliary encoder with source-dependent knowledge from the pre-trained
detector through a cross-domain attention mechanism. Additionally, principal
axes-based unknown labeling assigns pseudo-labels to unknown objects by
estimating objectness via principal axes projection and confidence scores from
model predictions. The proposed CollaPAUL achieves state-of-the-art
performances on SFUOD benchmarks, and extensive experiments validate its
effectiveness.

</details>


### [7] [Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection](https://arxiv.org/abs/2507.17436)
*Yehao Lu,Minghe Weng,Zekang Xiao,Rui Jiang,Wei Su,Guangcong Zheng,Ping Lu,Xi Li*

Main category: cs.CV

TL;DR: 本文提出Dynamic-DINO，将Grounding DINO 1.5 Edge从密集模型扩展为动态推理框架，通过MoE架构在实时开放词汇目标检测中实现性能提升，仅用156万开源数据就超越了在私有2000万数据集上预训练的基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管混合专家(MoE)架构在大型视觉-语言模型中表现出色，但其在实时开放词汇目标检测器中的潜力尚未被探索。这些检测器同样利用大规模视觉-语言数据集但使用较小的模型，因此有必要研究MoE在此领域的应用。

Method: 提出Dynamic-DINO框架，通过高效的MoE-Tuning策略将Grounding DINO 1.5 Edge扩展为动态推理模型。设计粒度分解机制将基础模型的前馈网络分解为多个小型专家网络，扩展子网搜索空间。提出预训练权重分配策略和特定的路由器初始化方法防止微调初期性能下降。推理时只激活与输入相关的专家形成紧凑子网。

Result: 实验表明，仅使用156万开源数据预训练的Dynamic-DINO超越了在私有Grounding20M数据集上预训练的Grounding DINO 1.5 Edge。发现浅层专家倾向于与多样化伙伴合作扩展搜索空间，深层则形成固定协作结构，每个专家维持2-3个固定伙伴，不同专家组合专门处理特定模式。

Conclusion: Dynamic-DINO成功证明了MoE架构在实时开放词汇目标检测中的有效性，通过动态专家选择和高效的训练策略，在使用更少数据的情况下实现了更好的性能，为该领域提供了新的研究方向。

Abstract: The Mixture of Experts (MoE) architecture has excelled in Large
Vision-Language Models (LVLMs), yet its potential in real-time open-vocabulary
object detectors, which also leverage large-scale vision-language datasets but
smaller models, remains unexplored. This work investigates this domain,
revealing intriguing insights. In the shallow layers, experts tend to cooperate
with diverse peers to expand the search space. While in the deeper layers,
fixed collaborative structures emerge, where each expert maintains 2-3 fixed
partners and distinct expert combinations are specialized in processing
specific patterns. Concretely, we propose Dynamic-DINO, which extends Grounding
DINO 1.5 Edge from a dense model to a dynamic inference framework via an
efficient MoE-Tuning strategy. Additionally, we design a granularity
decomposition mechanism to decompose the Feed-Forward Network (FFN) of base
model into multiple smaller expert networks, expanding the subnet search space.
To prevent performance degradation at the start of fine-tuning, we further
propose a pre-trained weight allocation strategy for the experts, coupled with
a specific router initialization. During inference, only the input-relevant
experts are activated to form a compact subnet. Experiments show that,
pretrained with merely 1.56M open-source data, Dynamic-DINO outperforms
Grounding DINO 1.5 Edge, pretrained on the private Grounding20M dataset.

</details>


### [8] [Accelerating Parallel Diffusion Model Serving with Residual Compression](https://arxiv.org/abs/2507.17511)
*Jiajun Luo,Yicheng Xiao,Jianru Xu,Yangxiu You,Rongwei Lu,Chen Tang,Jingyan Jiang,Zhi Wang*

Main category: cs.CV

TL;DR: CompactFusion是一个压缩框架，通过利用扩散模型激活的时间冗余性，使用残差压缩技术显著减少并行推理中的通信开销，在保持生成质量的同时实现3.0-6.7倍的速度提升


<details>
  <summary>Details</summary>
Motivation: 扩散模型需要多加速器并行推理来实现实时部署，但并行推理中设备间交换大量激活数据会产生显著的通信开销，限制了效率和可扩展性。现有方法在减少通信的同时往往牺牲生成质量

Method: 提出CompactFusion压缩框架，核心是残差压缩(Residual Compression)技术：1)观察到扩散激活具有强时间冗余性-相邻步骤产生高度相似的激活；2)仅传输压缩的残差(步骤间激活差异)而非完整激活；3)集成轻量级错误反馈机制防止误差累积；4)基于经验分析和理论证明来移除冗余数据

Result: 在4xL20上实现3.0倍加速，同时大幅提升保真度；在慢速网络上支持序列并行等通信密集策略，相比先前重叠方法实现6.7倍加速；框架具有广泛适用性，可应用于各种扩散模型和并行设置，易于集成且无需重构流水线

Conclusion: CompactFusion为并行扩散推理建立了新范式，通过有效利用时间冗余性实现了通信压缩与生成质量的平衡。该方法不仅显著降低了延迟，还支持更灵活的并行策略，为扩散模型的实时部署提供了实用解决方案

Abstract: Diffusion models produce realistic images and videos but require substantial
computational resources, necessitating multi-accelerator parallelism for
real-time deployment. However, parallel inference introduces significant
communication overhead from exchanging large activations between devices,
limiting efficiency and scalability. We present CompactFusion, a compression
framework that significantly reduces communication while preserving generation
quality. Our key observation is that diffusion activations exhibit strong
temporal redundancy-adjacent steps produce highly similar activations,
saturating bandwidth with near-duplicate data carrying little new information.
To address this inefficiency, we seek a more compact representation that
encodes only the essential information. CompactFusion achieves this via
Residual Compression that transmits only compressed residuals (step-wise
activation differences). Based on empirical analysis and theoretical
justification, we show that it effectively removes redundant data, enabling
substantial data reduction while maintaining high fidelity. We also integrate
lightweight error feedback to prevent error accumulation. CompactFusion
establishes a new paradigm for parallel diffusion inference, delivering lower
latency and significantly higher generation quality than prior methods. On
4xL20, it achieves 3.0x speedup while greatly improving fidelity. It also
uniquely supports communication-heavy strategies like sequence parallelism on
slow networks, achieving 6.7x speedup over prior overlap-based method.
CompactFusion applies broadly across diffusion models and parallel settings,
and integrates easily without requiring pipeline rework. Portable
implementation demonstrated on xDiT is publicly available at
https://github.com/Cobalt-27/CompactFusion

</details>


### [9] [Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding](https://arxiv.org/abs/2507.17533)
*Liwen Liu,Weidong Yang,Lipeng Ma,Ben Fei*

Main category: cs.CV

TL;DR: 本文提出MMPT框架，通过三个预训练任务（标记级重建、点级重建、多模态对比学习）来增强点云理解，无需3D标注即可实现有效的多模态表示学习


<details>
  <summary>Details</summary>
Motivation: 现有多模态预训练框架主要依赖单一预训练任务来收集3D应用中的多模态数据，这种限制阻止了模型获取其他相关任务提供的丰富信息，特别是在复杂多样的领域中会影响下游任务的性能

Method: 提出MMPT多模态多任务预训练框架，包含三个预训练任务：(1)标记级重建(TLR)恢复被遮挡的点标记；(2)点级重建(PLR)直接预测被遮挡点的位置；(3)多模态对比学习(MCL)结合模态内和跨模态的特征对应关系，以自监督方式从3D点云和2D图像中获取丰富学习信号

Result: 在广泛使用的基准测试中，该方法在各种判别和生成应用上相比最先进方法表现出有效性，训练的编码器可以有效迁移到各种下游任务

Conclusion: MMPT框架通过多任务预训练和多模态学习有效增强了点云理解能力，无需3D标注使其具有良好的可扩展性，能够在大规模数据集上应用并在下游任务中取得优异性能

Abstract: Recent advances in multi-modal pre-training methods have shown promising
effectiveness in learning 3D representations by aligning multi-modal features
between 3D shapes and their corresponding 2D counterparts. However, existing
multi-modal pre-training frameworks primarily rely on a single pre-training
task to gather multi-modal data in 3D applications. This limitation prevents
the models from obtaining the abundant information provided by other relevant
tasks, which can hinder their performance in downstream tasks, particularly in
complex and diverse domains. In order to tackle this issue, we propose MMPT, a
Multi-modal Multi-task Pre-training framework designed to enhance point cloud
understanding. Specifically, three pre-training tasks are devised: (i)
Token-level reconstruction (TLR) aims to recover masked point tokens, endowing
the model with representative learning abilities. (ii) Point-level
reconstruction (PLR) is integrated to predict the masked point positions
directly, and the reconstructed point cloud can be considered as a transformed
point cloud used in the subsequent task. (iii) Multi-modal contrastive learning
(MCL) combines feature correspondences within and across modalities, thus
assembling a rich learning signal from both 3D point cloud and 2D image
modalities in a self-supervised manner. Moreover, this framework operates
without requiring any 3D annotations, making it scalable for use with large
datasets. The trained encoder can be effectively transferred to various
downstream tasks. To demonstrate its effectiveness, we evaluated its
performance compared to state-of-the-art methods in various discriminant and
generative applications under widely-used benchmarks.

</details>


### [10] [See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2507.17659)
*Junjie Wang,Yunhan Tang,Yijie Wang,Zhihao Yuan,Huan Wang,Yangfan He,Bin Li*

Main category: cs.CV

TL;DR: 提出了Synergos-VQA框架，通过融合整体证据、结构证据和因果证据三种互补证据流，解决多模态大语言模型在知识型视觉问答中依赖单一维度证据的局限性，在多个基准测试中取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在知识型视觉问答任务中存在根本性瓶颈，即过度依赖单一维度的证据进行推理，采用"只见树木不见森林"的方法，无法实现稳健的多面理解。

Method: 提出Synergos-VQA协同推理框架，在推理时并发生成并融合三种互补证据流：(1)整体证据-感知整个场景("森林")；(2)结构证据-通过原型驱动模块识别关键对象("树木")；(3)因果证据-通过反事实探测确保推理稳健接地。

Result: 在三个具有挑战性的基准测试(包括OK-VQA和A-OKVQA)上建立了新的最优性能记录。该方法展现出强大的即插即用能力，显著提升了各种开源多模态大语言模型的性能，证明了优秀的方法设计可以超越纯粹的模型规模扩展。

Conclusion: 通过协同融合多面证据，Synergos-VQA实现了更全面可靠的推理过程，在知识型视觉问答任务中取得显著突破，证明了方法论创新的重要性超越单纯的模型规模提升。

Abstract: Multimodal Large Language Models (MLLMs) have pushed the frontiers of
Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is
fundamentally bottlenecked by a reliance on uni-dimensional evidence. This
"seeing only the trees, but not the forest" approach prevents robust,
multi-faceted understanding. Inspired by the principle of seeing both the
forest and trees, we propose Synergos-VQA, a novel synergistic reasoning
framework. At its core, Synergos-VQA concurrently generates and fuses three
complementary evidence streams at inference time: (1) Holistic Evidence to
perceive the entire scene (the "forest"), (2) Structural Evidence from a
prototype-driven module to identify key objects (the "trees"), and (3) Causal
Evidence from a counterfactual probe to ensure the reasoning is robustly
grounded. By synergistically fusing this multi-faceted evidence, our framework
achieves a more comprehensive and reliable reasoning process. Extensive
experiments show that Synergos-VQA decisively establishes a new
state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA.
Furthermore, our approach demonstrates strong plug-and-play capabilities,
significantly boosting various open-source MLLMs and proving that superior
methodological design can outperform sheer model scale.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [Model Compression Engine for Wearable Devices Skin Cancer Diagnosis](https://arxiv.org/abs/2507.17125)
*Jacob M. Delgado-López,Andrea P. Seda-Hernandez,Juan D. Guadalupe-Rosado,Luis E. Fernandez Ramirez,Miguel Giboyeaux-Camilo,Wilfredo E. Lugo-Beauchamp*

Main category: cs.LG

TL;DR: 本研究开发了一个基于MobileNetV2和TensorRT优化的AI皮肤癌诊断工具，可在资源受限的嵌入式设备上高效运行，实现了87.18%的F1分数，同时显著降低了模型大小和能耗。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是最常见且可预防的癌症类型之一，但早期检测仍然困难，特别是在资源有限、缺乏专业医疗服务的地区。因此需要开发适用于嵌入式系统的AI诊断工具来解决这一问题。

Method: 采用迁移学习技术，使用MobileNetV2架构进行皮肤病变的二分类（"皮肤癌"和"其他"）；使用TensorRT框架对模型进行压缩和优化，以便在NVIDIA Jetson Orin Nano上部署，平衡性能与能效。

Result: 优化后的模型保持了良好性能，F1分数达到87.18%，精确率93.18%，召回率81.91%；模型大小减少至0.41倍，推理速度和吞吐量提升，INT8精度下能耗降低至0.93倍。

Conclusion: 验证了在资源受限的边缘设备上部署高性能、高能效诊断工具的可行性；该研究方法在其他医疗诊断和需要可访问、高效AI解决方案的领域具有广泛应用前景；优化的AI系统有潜力革命性地改变医疗诊断，缩小先进技术与服务不足地区之间的差距。

Abstract: Skin cancer is one of the most prevalent and preventable types of cancer, yet
its early detection remains a challenge, particularly in resource-limited
settings where access to specialized healthcare is scarce. This study proposes
an AI-driven diagnostic tool optimized for embedded systems to address this
gap. Using transfer learning with the MobileNetV2 architecture, the model was
adapted for binary classification of skin lesions into "Skin Cancer" and
"Other." The TensorRT framework was employed to compress and optimize the model
for deployment on the NVIDIA Jetson Orin Nano, balancing performance with
energy efficiency. Comprehensive evaluations were conducted across multiple
benchmarks, including model size, inference speed, throughput, and power
consumption. The optimized models maintained their performance, achieving an
F1-Score of 87.18% with a precision of 93.18% and recall of 81.91%.
Post-compression results showed reductions in model size of up to 0.41, along
with improvements in inference speed and throughput, and a decrease in energy
consumption of up to 0.93 in INT8 precision. These findings validate the
feasibility of deploying high-performing, energy-efficient diagnostic tools on
resource-constrained edge devices. Beyond skin cancer detection, the
methodologies applied in this research have broader applications in other
medical diagnostics and domains requiring accessible, efficient AI solutions.
This study underscores the potential of optimized AI systems to revolutionize
healthcare diagnostics, thereby bridging the divide between advanced technology
and underserved regions.

</details>


### [12] [Tabular Diffusion based Actionable Counterfactual Explanations for Network Intrusion Detection](https://arxiv.org/abs/2507.17161)
*Vinura Galwaduge,Jagath Samarabandu*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的反事实解释框架，用于网络入侵检测系统的可解释AI，能够生成可操作的解释并转化为全局防御规则。


<details>
  <summary>Details</summary>
Motivation: 现代网络入侵检测系统使用深度学习模型的"黑盒"特性阻碍了对检测决策的理解和信任，现有的可解释AI方法难以转化为可操作的对抗措施，需要开发能够提供可操作解释的新方法。

Method: 提出了一种新颖的基于扩散模型的反事实解释框架，通过生成最小化、多样化的反事实解释，并将这些解释总结为全局规则集，实现从实例级到全局级的可操作解释。

Result: 在3个现代网络入侵数据集上的评估显示，所提方法相比其他反事实解释算法能够更高效地生成最小化、多样化的反事实解释，减少了解释生成时间，并成功创建了能够有效过滤攻击查询的全局反事实规则。

Conclusion: 该框架不仅提供了网络入侵检测系统中反事实解释算法的首次比较分析，还证明了反事实解释可以转化为实例级和全局级的可操作解释，这些全局规则对于高效的入侵检测和防御机制至关重要。

Abstract: Modern network intrusion detection systems (NIDS) frequently utilize the
predictive power of complex deep learning models. However, the "black-box"
nature of such deep learning methods adds a layer of opaqueness that hinders
the proper understanding of detection decisions, trust in the decisions and
prevent timely countermeasures against such attacks. Explainable AI (XAI)
methods provide a solution to this problem by providing insights into the
causes of the predictions. The majority of the existing XAI methods provide
explanations which are not convenient to convert into actionable
countermeasures. In this work, we propose a novel diffusion-based
counterfactual explanation framework that can provide actionable explanations
for network intrusion attacks. We evaluated our proposed algorithm against
several other publicly available counterfactual explanation algorithms on 3
modern network intrusion datasets. To the best of our knowledge, this work also
presents the first comparative analysis of existing counterfactual explanation
algorithms within the context of network intrusion detection systems. Our
proposed method provide minimal, diverse counterfactual explanations out of the
tested counterfactual explanation algorithms in a more efficient manner by
reducing the time to generate explanations. We also demonstrate how
counterfactual explanations can provide actionable explanations by summarizing
them to create a set of global rules. These rules are actionable not only at
instance level but also at the global level for intrusion attacks. These global
counterfactual rules show the ability to effectively filter out incoming attack
queries which is crucial for efficient intrusion detection and defense
mechanisms.

</details>


### [13] [Met$^2$Net: A Decoupled Two-Stage Spatio-Temporal Forecasting Model for Complex Meteorological Systems](https://arxiv.org/abs/2507.17189)
*Shaohan Li,Hao Yang,Min Chen,Xiaolin Qin*

Main category: cs.LG

TL;DR: 提出了一种隐式两阶段训练方法Met2Net，通过为每个变量配置独立的编码器和解码器，并引入自注意力机制进行多变量融合，显著提升了极端天气预测的准确性


<details>
  <summary>Details</summary>
Motivation: 全球气候变化导致极端天气事件频发，迫切需要准确的天气预测。现有端到端方法在多变量集成中存在表示不一致性问题，难以有效捕获复杂天气系统中变量间的依赖关系。传统的两阶段训练方法由于两个阶段训练任务不一致，效果往往不理想

Method: 提出隐式两阶段训练方法：第一阶段冻结Translator，让编码器和解码器学习共享潜在空间；第二阶段冻结编码器和解码器，让Translator捕获变量间交互进行预测。同时引入自注意力机制在潜在空间中进行多变量融合

Result: 在近地表气温和相对湿度预测中，MSE分别降低了28.82%和23.39%，达到了最先进的性能水平

Conclusion: 该方法有效解决了多变量天气预测中的表示不一致性问题，通过改进的两阶段训练策略和自注意力机制，显著提升了极端天气预测的准确性

Abstract: The increasing frequency of extreme weather events due to global climate
change urges accurate weather prediction. Recently, great advances have been
made by the \textbf{end-to-end methods}, thanks to deep learning techniques,
but they face limitations of \textit{representation inconsistency} in
multivariable integration and struggle to effectively capture the dependency
between variables, which is required in complex weather systems. Treating
different variables as distinct modalities and applying a \textbf{two-stage
training approach} from multimodal models can partially alleviate this issue,
but due to the inconformity in training tasks between the two stages, the
results are often suboptimal. To address these challenges, we propose an
implicit two-stage training method, configuring separate encoders and decoders
for each variable. In detailed, in the first stage, the Translator is frozen
while the Encoders and Decoders learn a shared latent space, in the second
stage, the Encoders and Decoders are frozen, and the Translator captures
inter-variable interactions for prediction. Besides, by introducing a
self-attention mechanism for multivariable fusion in the latent space, the
performance achieves further improvements. Empirically, extensive experiments
show the state-of-the-art performance of our method. Specifically, it reduces
the MSE for near-surface air temperature and relative humidity predictions by
28.82\% and 23.39\%, respectively. The source code is available at
https://github.com/ShremG/Met2Net.

</details>


### [14] [Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance](https://arxiv.org/abs/2507.17273)
*Rishi Parekh,Saisubramaniam Gopalakrishnan,Zishan Ahmad,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 本文提出了一个结合知识图谱(KG)和大语言模型(LLM)代理的框架，用于分析仓库运营的离散事件仿真(DES)输出数据，自动识别瓶颈和低效问题，显著减少了人工分析工作量并提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 分析仓库运营的离散事件仿真产生的大型复杂输出数据集以识别瓶颈和低效问题是一项关键但具有挑战性的任务，通常需要大量的人工工作或专门的分析工具，因此需要一种更自动化和智能化的分析方法。

Method: 构建了一个集成知识图谱和大语言模型代理的框架：1）将原始DES数据转换为语义丰富的知识图谱，捕获仿真事件和实体之间的关系；2）使用基于LLM的代理进行迭代推理，生成相互依赖的子问题；3）为每个子问题创建Cypher查询与知识图谱交互，提取信息并进行自我反思以纠正错误；4）通过这种自适应、迭代和自我纠错的过程来识别运营问题。

Result: 在设备故障和流程异常的测试中，该方法在仓库瓶颈识别方面优于基线方法。对于运营问题，在识别低效问题方面实现了近乎完美的通过率。对于复杂的调查性问题，展示了其在发现微妙、相互关联问题方面的卓越诊断能力。

Conclusion: 这项工作成功连接了仿真建模和人工智能技术（知识图谱+大语言模型），提供了一种更直观的方法来获得可操作的洞察，减少了获得洞察所需的时间，并实现了自动化的仓库低效评估和诊断。

Abstract: Analyzing large, complex output datasets from Discrete Event Simulations
(DES) of warehouse operations to identify bottlenecks and inefficiencies is a
critical yet challenging task, often demanding significant manual effort or
specialized analytical tools. Our framework integrates Knowledge Graphs (KGs)
and Large Language Model (LLM)-based agents to analyze complex Discrete Event
Simulation (DES) output data from warehouse operations. It transforms raw DES
data into a semantically rich KG, capturing relationships between simulation
events and entities. An LLM-based agent uses iterative reasoning, generating
interdependent sub-questions. For each sub-question, it creates Cypher queries
for KG interaction, extracts information, and self-reflects to correct errors.
This adaptive, iterative, and self-correcting process identifies operational
issues mimicking human analysis. Our DES approach for warehouse bottleneck
identification, tested with equipment breakdowns and process irregularities,
outperforms baseline methods. For operational questions, it achieves
near-perfect pass rates in pinpointing inefficiencies. For complex
investigative questions, we demonstrate its superior diagnostic ability to
uncover subtle, interconnected issues. This work bridges simulation modeling
and AI (KG+LLM), offering a more intuitive method for actionable insights,
reducing time-to-insight, and enabling automated warehouse inefficiency
evaluation and diagnosis.

</details>


### [15] [DeCo-SGD: Joint Optimization of Delay Staleness and Gradient Compression Ratio for Distributed SGD](https://arxiv.org/abs/2507.17346)
*Rongwei Lu,Jingyan Jiang,Chunyang Li,Haotian Dong,Xingguang Wei,Delin Cai,Zhi Wang*

Main category: cs.LG

TL;DR: 本文提出了DeCo-SGD算法，通过动态调整梯度压缩比和延迟同步步数来解决分布式机器学习在高延迟、低带宽网络环境下的吞吐量下降问题，相比传统方法实现了最高5.07倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 分布式机器学习在高延迟、低带宽且变化的网络环境中面临严重的吞吐量下降问题。现有方法通常结合梯度压缩和延迟聚合来应对低带宽和高延迟，但这引入了压缩比、延迟步数和模型收敛率之间复杂的三方权衡。由于缺乏理论指导，现有工作依赖静态启发式策略，无法实现在变化带宽条件下的动态平衡。

Method: 本文引入了新的理论工具，将联合优化问题分解为传统收敛率分析与多个可分析噪声项的组合。通过将收敛率与网络感知的时间最小化条件相结合，提出了DeCo-SGD算法，该算法能够根据实时网络条件和训练任务动态调整压缩比和延迟步数。

Result: DeCo-SGD在高延迟和低变化带宽网络中分别实现了相比D-SGD最高5.07倍和相比静态策略1.37倍的速度提升。研究首次揭示了延迟会指数级放大梯度压缩对训练性能的负面影响。

Conclusion: 本文填补了压缩和延迟梯度如何影响训练的理论空白，提供了动态调整策略的理论基础。DeCo-SGD算法通过实时适应网络条件，有效解决了分布式机器学习在具有挑战性网络环境中的性能问题，为分布式优化提供了新的解决方案。

Abstract: Distributed machine learning in high end-to-end latency and low, varying
bandwidth network environments undergoes severe throughput degradation. Due to
its low communication requirements, distributed SGD (D-SGD) remains the
mainstream optimizer in such challenging networks, but it still suffers from
significant throughput reduction. To mitigate these limitations, existing
approaches typically employ gradient compression and delayed aggregation to
alleviate low bandwidth and high latency, respectively. To address both
challenges simultaneously, these strategies are often combined, introducing a
complex three-way trade-off among compression ratio, staleness (delayed
synchronization steps), and model convergence rate. To achieve the balance
under varying bandwidth conditions, an adaptive policy is required to
dynamically adjust these parameters. Unfortunately, existing works rely on
static heuristic strategies due to the lack of theoretical guidance, which
prevents them from achieving this goal. This study fills in this theoretical
gap by introducing a new theoretical tool, decomposing the joint optimization
problem into a traditional convergence rate analysis with multiple analyzable
noise terms. We are the first to reveal that staleness exponentially amplifies
the negative impact of gradient compression on training performance, filling a
critical gap in understanding how compressed and delayed gradients affect
training. Furthermore, by integrating the convergence rate with a network-aware
time minimization condition, we propose DeCo-SGD, which dynamically adjusts the
compression ratio and staleness based on the real-time network condition and
training task. DeCo-SGD achieves up to 5.07 and 1.37 speed-ups over D-SGD and
static strategy in high-latency and low, varying bandwidth networks,
respectively.

</details>


### [16] [ViRN: Variational Inference and Distribution Trilateration for Long-Tailed Continual Representation Learning](https://arxiv.org/abs/2507.17368)
*Hao Dai,Chong Tang,Jagmohan Chauhan*

Main category: cs.LG

TL;DR: 提出了ViRN框架，通过变分推理和分布三角测量技术解决持续学习中长尾数据分布的挑战，在六个基准测试中平均准确率提升10.24%


<details>
  <summary>Details</summary>
Motivation: 现实世界AI系统面临持续学习中长尾数据分布的关键挑战，模型需要在严重类别不平衡的情况下顺序适应新类别同时保持对旧类别的知识，现有方法难以平衡稳定性和可塑性，经常在极端样本稀缺下崩溃

Method: 提出ViRN框架，集成变分推理和分布三角测量：1）通过变分自编码器建模类条件分布以减轻对头部类别的偏差；2）通过基于Wasserstein距离的邻域检索和几何融合重构尾部类别分布，实现尾部类别表示的样本高效对齐

Result: 在六个长尾分类基准测试上进行评估，包括语音任务（如稀有声学事件、口音）和图像任务，ViRN相比最先进方法平均准确率提升10.24%

Conclusion: ViRN框架通过变分推理和分布三角测量技术有效解决了持续学习中长尾数据分布的挑战，在多个基准测试中显著提升了性能，为处理类别不平衡的持续学习提供了新的解决方案

Abstract: Continual learning (CL) with long-tailed data distributions remains a
critical challenge for real-world AI systems, where models must sequentially
adapt to new classes while retaining knowledge of old ones, despite severe
class imbalance. Existing methods struggle to balance stability and plasticity,
often collapsing under extreme sample scarcity. To address this, we propose
ViRN, a novel CL framework that integrates variational inference (VI) with
distributional trilateration for robust long-tailed learning. First, we model
class-conditional distributions via a Variational Autoencoder to mitigate bias
toward head classes. Second, we reconstruct tail-class distributions via
Wasserstein distance-based neighborhood retrieval and geometric fusion,
enabling sample-efficient alignment of tail-class representations. Evaluated on
six long-tailed classification benchmarks, including speech (e.g., rare
acoustic events, accents) and image tasks, ViRN achieves a 10.24% average
accuracy gain over state-of-the-art methods.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [17] [Harnessing RLHF for Robust Unanswerability Recognition and Trustworthy Response Generation in LLMs](https://arxiv.org/abs/2507.16951)
*Shuyuan Lin,Lei Duan,Philip Hughes,Yuxuan Sheng*

Main category: cs.CL

TL;DR: 本文提出了SALU（Self-Aware LLM for Unanswerability），一种能够在生成过程中直接检测无法回答问题的新方法，通过多任务学习和置信度引导的强化学习显著减少了对话信息检索系统中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 传统的对话信息检索系统在处理无法回答的问题时存在重大挑战，容易产生误导性或幻觉内容。现有方法依赖外部分类器，可能与核心生成式大语言模型产生不一致性。

Method: 提出SALU方法，将无法回答检测直接集成到LLM的生成过程中。采用多任务学习框架同时进行标准问答和显式拒绝生成训练，并结合置信度评分引导的人类反馈强化学习(RLHF)阶段，明确惩罚幻觉回答并奖励适当的拒绝回答。

Result: 在自建的C-IR_Answerability数据集上的广泛实验表明，SALU在正确回答或拒绝问题的整体准确性方面consistently优于强基线方法，包括混合LLM-分类器系统。人工评估进一步确认了SALU在事实性、适当拒绝和显著减少幻觉方面的优越可靠性。

Conclusion: SALU成功实现了大语言模型的内在自我意识，能够可靠地识别知识边界并适当地"知道何时说'我不知道'"，为构建更可靠的对话信息检索系统提供了有效解决方案。

Abstract: Conversational Information Retrieval (CIR) systems, while offering intuitive
access to information, face a significant challenge: reliably handling
unanswerable questions to prevent the generation of misleading or hallucinated
content. Traditional approaches often rely on external classifiers, which can
introduce inconsistencies with the core generative Large Language Models
(LLMs). This paper introduces Self-Aware LLM for Unanswerability (SALU), a
novel approach that deeply integrates unanswerability detection directly within
the LLM's generative process. SALU is trained using a multi-task learning
framework for both standard Question Answering (QA) and explicit abstention
generation for unanswerable queries. Crucially, it incorporates a
confidence-score-guided reinforcement learning with human feedback (RLHF)
phase, which explicitly penalizes hallucinated responses and rewards
appropriate abstentions, fostering intrinsic self-awareness of knowledge
boundaries. Through extensive experiments on our custom-built
C-IR_Answerability dataset, SALU consistently outperforms strong baselines,
including hybrid LLM-classifier systems, in overall accuracy for correctly
answering or abstaining from questions. Human evaluation further confirms
SALU's superior reliability, achieving high scores in factuality, appropriate
abstention, and, most importantly, a dramatic reduction in hallucination,
demonstrating its ability to robustly "know when to say 'I don't know'."

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens](https://arxiv.org/abs/2507.16841)
*Waseem Akram,Muhayy Ud Din,Abdelhaleem Saad,Irfan Hussain*

Main category: cs.RO

TL;DR: 提出了AquaChat框架，一个集成大语言模型的水下机器人系统，用于智能化水产养殖网箱检查，通过自然语言交互实现自适应任务规划和执行。


<details>
  <summary>Details</summary>
Motivation: 传统的水产养殖网箱检查方法依赖预编程任务或人工控制，在动态水下环境和用户特定需求面前适应性有限，需要更智能、更灵活的检查系统来维护养殖系统的结构完整性、生物安全性和运营效率。

Method: 设计了AquaChat多层架构框架：(1)高层规划层使用大语言模型解释自然语言用户指令并生成符号化任务计划；(2)中层任务管理器将计划转换为ROV控制序列；(3)低层运动控制层精确执行导航和检查任务。系统还集成了实时反馈和事件触发的重新规划机制。

Result: 在模拟环境和受控水生环境中的实验验证表明，该框架在任务灵活性、检查精度和操作效率方面都有显著改善，能够有效适应具有挑战性的水产养殖环境。

Conclusion: AquaChat展示了语言AI与海洋机器人技术集成的潜力，能够为可持续水产养殖作业提供智能化、用户交互式的检查系统，为水产养殖业的自动化和智能化发展提供了新的技术路径。

Abstract: Inspection of aquaculture net pens is essential for maintaining the
structural integrity, biosecurity, and operational efficiency of fish farming
systems. Traditional inspection approaches rely on pre-programmed missions or
manual control, offering limited adaptability to dynamic underwater conditions
and user-specific demands. In this study, we propose AquaChat, a novel Remotely
Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs)
for intelligent and adaptive net pen inspection. The system features a
multi-layered architecture: (1) a high-level planning layer that interprets
natural language user commands using an LLM to generate symbolic task plans;
(2) a mid-level task manager that translates plans into ROV control sequences;
and (3) a low-level motion control layer that executes navigation and
inspection tasks with precision. Real-time feedback and event-triggered
replanning enhance robustness in challenging aquaculture environments. The
framework is validated through experiments in both simulated and controlled
aquatic environments representative of aquaculture net pens. Results
demonstrate improved task flexibility, inspection accuracy, and operational
efficiency. AquaChat illustrates the potential of integrating language-based AI
with marine robotics to enable intelligent, user-interactive inspection systems
for sustainable aquaculture operations.

</details>


### [19] [Event Detection for Active Lower Limb Prosthesis](https://arxiv.org/abs/2507.17649)
*J. D. Clark,P. Ellison*

Main category: cs.RO

TL;DR: 研究使用双髁膝关节设计中的十字韧带拉伸来改进步态事件检测，发现韧带拉伸模式可用于预测步态周期中的关键事件，从而提高动力假肢控制器的准确性


<details>
  <summary>Details</summary>
Motivation: 传统的销轴关节简化设计会丢失自然膝关节的复杂运动学特性，影响步态特征。准确的事件检测对半被动和动力假肢的成功设计至关重要，需要探索更好的膝关节设计来改善事件检测能力

Method: 采用双髁膝关节设计，通过前后十字韧带类似物进行约束。使用与Russell膝关节韧带平行的LVDT记录韧带拉伸情况。在弯膝拐杖上进行实验，在跑步机上以3种不同速度采集数据，分析韧带拉伸与步态周期的关系

Result: 发现十字韧带拉伸存在速度依赖性，主要出现在步态周期的5%和80%处（后十字韧带和前十字韧带）。周期轮廓随速度保持一致，在90%和95%处出现转折点特征，可分别用于预测初始接触和足平放置事件

Conclusion: 双髁膝关节设计能够改善步态周期中的事件检测，通过韧带拉伸模式可以预测关键步态事件，从而提高动力假肢后续控制器的准确性，为假肢控制系统的改进提供了新的思路

Abstract: Accurate event detection is key to the successful design of semi-passive and
powered prosthetics. Kinematically, the natural knee is complex, with
translation and rotation components that have a substantial impact on gait
characteristics. When simplified to a pin joint, some of this behaviour is
lost. This study investigates the role of cruciate ligament stretch in event
detection. A bicondylar knee design was used, constrained by analogues of the
anterior and posterior cruciate ligaments. This offers the ability to
characterize knee kinematics by the stretch of the ligaments. The ligament
stretch was recorded using LVDTs parallel to the ligaments of the Russell knee
on a bent knee crutch. Which was used to capture data on a treadmill at 3
speeds. This study finds speed dependence within the stretch of the cruciate
ligaments, prominently around 5\% and 80\% of the gait cycle for the posterior
and anterior. The cycle profile remains consistent with speed; therefore, other
static events such as the turning point feature at around 90\% and 95\% of the
cycle, for the posterior and anterior, respectively, could be used as a
predictive precursor for initial contact. Likewise at 90\% and 95\%, another
pair of turning points that in this case could be used to predict foot flat.
This concludes that the use of a bicondylar knee design could improve the
detection of events during the gait cycle, and therefore could increase the
accuracy of subsequent controllers for powered prosthetics.

</details>
