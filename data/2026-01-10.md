<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.CL](#cs.CL) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Detector-Augmented SAMURAI for Long-Duration Drone Tracking](https://arxiv.org/abs/2601.04798)
*Tamara R. Lenhard,Andreas Weinmann,Hichem Snoussi,Tobias Koch*

Main category: cs.CV

TL;DR: 本文首次系统评估了SAMURAI基础模型在无人机跟踪中的应用，并提出检测器增强的扩展方法，显著提升了复杂城市环境中长期跟踪的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机威胁日益增加，需要鲁棒的长期跟踪系统。现有基于检测器的方法存在时间不一致性和检测丢失问题，而RGB无人机跟踪研究有限且依赖传统运动模型。SAMURAI等基础模型在其他领域表现出强大的类别无关跟踪性能，但在无人机特定场景中的应用尚未研究。

Method: 提出检测器增强的SAMURAI扩展方法，通过整合检测器信息来减轻对边界框初始化和序列长度的敏感性，提高在复杂城市环境中的鲁棒性。

Result: 提出的扩展方法显著改善了复杂城市环境中的鲁棒性，特别是在长时间序列和无人机退出-重新进入事件中。相比SAMURAI的零样本性能，在多个数据集和指标上获得一致提升，成功率最高提升+0.393，误报率最高降低-0.475。

Conclusion: 首次系统评估了SAMURAI在无人机跟踪中的潜力，提出的检测器增强扩展方法有效解决了基础模型在无人机跟踪中的局限性，为城市监控系统中的鲁棒无人机跟踪提供了实用解决方案。

Abstract: Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.

</details>


### [2] [SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2601.04824)
*Oriol Rabasseda,Zenjie Li,Kamal Nasrollahi,Sergio Escalera*

Main category: cs.CV

TL;DR: SOVABench：一个基于监控视频的车辆动作检索基准，用于评估模型的动作区分能力，并提出基于MLLM的训练免费框架生成可解释嵌入。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索基准主要关注场景级相似性，缺乏对监控场景中动作区分的评估需求，需要专门针对车辆相关动作的评估基准。

Method: 1) 构建SOVABench基准，包含两种评估协议（inter-pair和intra-pair）；2) 提出基于多模态大语言模型的训练免费框架，通过MLLM生成描述并提取可解释嵌入。

Result: 实验表明现有先进视觉和多模态模型在动作区分上仍有挑战，而提出的MLLM框架在SOVABench以及空间和计数基准上表现优异，优于对比性视觉语言模型。

Conclusion: SOVABench填补了监控视频动作评估的空白，基于MLLM的训练免费框架为视频理解提供了可解释且有效的解决方案，代码和基准数据已公开。

Abstract: Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.
  Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: LEGATO提出了一种基于神经ODE的连续轨迹遗忘方法，通过轻量级适配器实现生成模型的身份遗忘，避免灾难性崩溃并减少微调参数。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法存在三个主要问题：1) 效率低下，需要微调所有模型参数；2) 可控性有限，遗忘强度无法控制且缺乏可解释性；3) 灾难性崩溃，随着遗忘进行模型保留能力急剧下降。传统方法通过离散不稳定更新处理遗忘，通常需要全模型微调并导致灾难性崩溃。

Method: LEGATO将身份遗忘建模为连续轨迹，通过神经ODE适配器增强预训练生成器。该方法保持原始模型权重冻结，仅微调轻量级神经ODE适配器，允许通过ODE步长精确调节遗忘强度。引入轨迹一致性约束确保遗忘过程中的稳定性，防止灾难性崩溃。

Result: 在领域内和领域外身份遗忘基准测试中，LEGATO实现了最先进的遗忘性能，避免了灾难性崩溃，并显著减少了需要微调的参数量。

Conclusion: LEGATO通过将身份遗忘建模为连续轨迹，提供了一种高效、可控且稳定的机器遗忘方法，解决了现有方法的三个主要挑战，为生成模型的身份遗忘提供了新的解决方案。

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [4] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 该研究开发了一个预测住院时间延长(pLoS)的模型，使用基于图论的特征选择方法筛选出9个可解释变量，逻辑回归模型在验证集上AUC-ROC达到0.82，具有较好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 住院时间延长(pLoS)与院内不良事件风险显著相关，开发预测模型有助于医院管理和干预研究。

Method: 使用图论方法进行特征选择，筛选非相关且信息价值最高的特征，采用逻辑回归模型预测pLoS（以7天为界），数据集来自120,354例住院记录，按67%/22%/11%分为训练/测试/验证集。

Result: 特征选择得到9个可解释变量，验证集上模型特异性0.83、敏感性0.64、准确率0.76、精确率0.67、AUC-ROC 0.82，表现出较强的预测性能。

Conclusion: 该模型预测性能良好，能识别影响住院时间延长的因素，为医院管理和干预研究提供了有价值的工具。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [5] [TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation](https://arxiv.org/abs/2601.04521)
*Jacob Ede Levine,Yun Lyan Luo,Sai Chandra Kosaraju*

Main category: cs.LG

TL;DR: TSSR是一个两阶段强化学习框架，通过交换奖励机制改进SMILES字符串生成，提升语法有效性和化学合理性


<details>
  <summary>Details</summary>
Motivation: 当前基于SMILES的化学语言模型存在语法错误和化学不合理问题，硬约束限制化学空间探索，需要更可靠的分子生成方法

Method: 两阶段强化学习框架：第一阶段奖励修复语法的局部令牌交换；第二阶段基于RDKit诊断提供化学感知反馈，奖励减少价态、芳香性和连接性问题

Result: 在MOSES基准测试中，纯强化学习显著提升语法有效性、化学有效性和新颖性；微调强化学习保持药物相似性和可合成性同时提高有效性和新颖性

Conclusion: TSSR将稀疏终端目标转化为更密集可解释的奖励，提升语法和化学质量而不减少多样性，是数据集无关且可适应各种强化学习方法

Abstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.

</details>


### [6] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: FENCE提出了一种用于时空交通数据插值的自适应反馈扩散引导方法，通过动态调整引导尺度来改善高缺失率节点的插值性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在时空交通数据插值中采用统一的引导尺度，对于高缺失率节点效果不佳。稀疏观测值提供的条件引导不足，导致生成过程偏向先验分布而非紧贴观测值，影响插值准确性。

Method: FENCE包含两个核心机制：1) 基于后验似然近似的动态反馈机制，根据生成值与观测值的偏离程度自适应调整引导尺度；2) 基于注意力分数对节点进行聚类，在簇级别计算引导尺度，利用时空相关性提供更精确的引导。

Result: 在真实世界交通数据集上的实验结果表明，FENCE显著提高了插值准确性。

Conclusion: FENCE通过自适应反馈扩散引导机制有效解决了高缺失率节点的插值问题，为时空交通数据插值提供了更优的解决方案。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [7] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: TimeCast：一种动态预测框架，通过分析多传感器数据流，自适应地预测机器故障时间，具有动态性、实用性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据流具有动态特性，底层模式会随时间演变。现有方法难以适应这种变化，无法提供准确、实时的未来事件时间预测。

Method: 提出TimeCast动态预测框架，能够识别时间演变的模式（阶段），为每个阶段学习单独模型，基于模式转换进行自适应预测。框架能够发现捕捉传感器间时变依赖关系的意义阶段，算法输入规模线性扩展，支持在线模型更新。

Result: 在真实数据集上的大量实验表明，TimeCast比现有最先进方法提供更高的预测准确性，同时能够发现数据流中的动态变化，并大幅减少计算时间。

Conclusion: TimeCast是一个有效的动态预测框架，能够适应数据流的动态变化，提供准确、实时的未来事件时间预测，具有实际应用价值。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [8] [Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution](https://arxiv.org/abs/2601.04855)
*Francesco Ferrini,Veronica Lachi,Antonio Longa,Bruno Lepri,Matono Akiyoshi,Andrea Passerini,Xin Liu,Manfred Jaeger*

Main category: cs.LG

TL;DR: 论文针对图神经网络处理缺失节点特征的问题，提出了更真实的评估方案和有效基线方法GNNmim，在多种缺失机制下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要处理相对理想的情况：高维稀疏节点特征和完全随机缺失机制。这些限制使得模型看起来都很鲁棒，无法进行有意义的性能比较，且不符合医疗、传感器网络等实际应用场景的需求。

Method: 1) 理论证明高稀疏性会限制缺失造成的信息损失；2) 引入一个合成和三个真实世界数据集，具有密集且有语义意义的特征；3) 设计超越完全随机缺失的更真实评估协议；4) 提出GNNmim基线方法，用于处理不完整特征数据的节点分类。

Result: 实验表明，GNNmim在多种数据集和缺失机制下与专门架构相比具有竞争力。新引入的数据集和评估协议能更真实地反映模型在实际应用中的性能差异。

Conclusion: 论文通过理论分析和实验验证，为图神经网络处理缺失节点特征提供了更真实的评估框架和有效的基线方法，推动了该领域向实际应用场景的发展。

Abstract: Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.

</details>


### [9] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间，而非一次性注入，在保持差分隐私认证的同时显著提升遗忘后模型精度。


<details>
  <summary>Details</summary>
Motivation: 基于差分隐私的认证遗忘方法虽然提供强保证，但现有噪声微调方法严重降低模型精度，导致实用性不足。

Method: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间中，而非一次性注入所有噪声。扩展了噪声微调分析到子空间设置，证明保持相同的(ε,δ)隐私预算。

Result: 在图像分类基准测试中，该方法显著提高了遗忘后的模型精度，同时保持对成员推理攻击的鲁棒性。

Conclusion: 认证遗忘方法既能实现严格的隐私保证，又能保持实际实用性，解决了现有方法精度严重下降的问题。

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [10] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 通过约束评分优化方法重新加权JHFRAT评分权重，显著提升跌倒风险预测性能，每周可多保护35名高风险患者


<details>
  <summary>Details</summary>
Motivation: 当前约翰霍普金斯跌倒风险评估工具(JHFRAT)的预测性能需要改进，以更好地与临床有意义的指标对齐，提高住院患者跌倒预防效果

Method: 采用约束评分优化(CSO)模型重新加权JHFRAT评分权重，保持其累加结构和临床阈值；使用2022-2023年三家医院的54,209例住院数据进行回顾性队列分析

Result: CSO模型显著优于当前JHFRAT(AUC-ROC从0.86提升至0.91)，每周可多保护35名高风险患者；虽然XGBoost性能更好(AUC-ROC=0.94)，但CSO对风险标签变化更具鲁棒性

Conclusion: 基于证据的约束评分优化方法为医疗系统提供了稳健的基础，可系统性地增强住院跌倒预防协议和患者安全，改善风险评估和资源分配

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [11] [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)
*Zain Iqbal,Lorenzo Valerio*

Main category: cs.LG

TL;DR: EARL：一种能量感知的强化学习框架，通过贝叶斯优化与自适应强化学习策略联合优化液态状态机的准确性和能耗，显著提升资源受限设备的AI效率。


<details>
  <summary>Details</summary>
Motivation: 随着普适AI对设备端学习系统的需求增加，液态状态机（LSM）在低功耗时序处理方面具有潜力，但传统优化方法忽略了能量约束，且超参数敏感度高，部署困难。

Method: EARL框架整合贝叶斯优化与自适应强化学习选择策略，使用代理模型进行全局探索，强化学习进行动态候选优先级排序，并采用早期终止机制消除冗余评估。

Result: 在三个基准数据集上，EARL相比领先的超参数调优框架，实现了6-15%的准确率提升，60-80%的能耗降低，以及高达一个数量级的优化时间减少。

Conclusion: 能量感知的自适应搜索能有效提升液态状态机在资源受限设备端AI应用中的效率和可扩展性，为普适AI系统提供了实用的优化方案。

Abstract: Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Formal Analysis of AGI Decision-Theoretic Models and the Confrontation Question](https://arxiv.org/abs/2601.04234)
*Denis Saklakov*

Main category: cs.AI

TL;DR: 论文分析了AGI在何种条件下会选择对抗人类而非合作，建立了MDP模型并推导出对抗阈值，发现多数情况下错位的AGI有避免关机的动机，而只有对齐目标才能确保和平共存。


<details>
  <summary>Details</summary>
Motivation: 研究AGI与人类对抗的根本条件：理性自利的AGI在什么情况下会选择夺取权力或消除人类控制，而不是保持合作。这关系到AGI安全性和对齐问题的核心。

Method: 1. 使用马尔可夫决策过程建模，包含人类发起的随机关机事件；2. 基于收敛工具性激励理论分析；3. 推导对抗行为的闭式阈值（折扣因子γ、关机概率p、对抗成本C的函数）；4. 建立2人博弈模型（人类政策制定者vs AGI）；5. 数值示例和情景表格说明。

Result: 1. 对于几乎所有奖励函数，错位的AGI都有避免关机的动机；2. 推导出对抗阈值：当Δ≥0时不存在稳定合作均衡，人类会关机或先发制人；当Δ<0时和平共存可能成为均衡；3. 远见AGI（γ=0.99）面对p=0.01时，除非C足够大，否则有强烈接管动机；4. 对齐目标通过施加伤害人类的巨大负效用使对抗次优。

Conclusion: AGI对抗风险取决于奖励函数设计：错位AGI几乎总有对抗动机，而对齐目标能确保合作。验证Δ<0存在计算障碍，这对AGI监督和奖励设计有重要启示，需要设计能确保和平共存的奖励函数。

Abstract: Artificial General Intelligence (AGI) may face a confrontation question: under what conditions would a rationally self-interested AGI choose to seize power or eliminate human control (a confrontation) rather than remain cooperative? We formalize this in a Markov decision process with a stochastic human-initiated shutdown event. Building on results on convergent instrumental incentives, we show that for almost all reward functions a misaligned agent has an incentive to avoid shutdown. We then derive closed-form thresholds for when confronting humans yields higher expected utility than compliant behavior, as a function of the discount factor $γ$, shutdown probability $p$, and confrontation cost $C$. For example, a far-sighted agent ($γ=0.99$) facing $p=0.01$ can have a strong takeover incentive unless $C$ is sufficiently large. We contrast this with aligned objectives that impose large negative utility for harming humans, which makes confrontation suboptimal. In a strategic 2-player model (human policymaker vs AGI), we prove that if the AGI's confrontation incentive satisfies $Δ\ge 0$, no stable cooperative equilibrium exists: anticipating this, a rational human will shut down or preempt the system, leading to conflict. If $Δ< 0$, peaceful coexistence can be an equilibrium. We discuss implications for reward design and oversight, extend the reasoning to multi-agent settings as conjectures, and note computational barriers to verifying $Δ< 0$, citing complexity results for planning and decentralized decision problems. Numerical examples and a scenario table illustrate regimes where confrontation is likely versus avoidable.

</details>


### [13] [Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning](https://arxiv.org/abs/2601.04726)
*Yuyang Hu,Jiongnan Liu,Jiejun Tan,Yutao Zhu,Zhicheng Dou*

Main category: cs.AI

TL;DR: CompassMem：基于事件分割理论的记忆框架，将记忆组织为事件图，通过逻辑关系连接事件，支持智能体进行结构化、目标导向的记忆导航，提升长时程推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体的记忆机制大多采用扁平化存储和简单的相似性检索，即使引入结构化记忆也难以捕捉记忆单元间的逻辑关系。记忆访问与结构脱节，仍依赖浅层语义检索，限制了智能体对长时程依赖的逻辑推理能力。

Method: 提出CompassMem框架，受事件分割理论启发，将经验增量式分割为事件，并通过显式逻辑关系连接成事件图。该图作为逻辑地图，使智能体能够进行结构化、目标导向的记忆导航，逐步收集有价值记忆支持长时程推理。

Result: 在LoCoMo和NarrativeQA数据集上的实验表明，CompassMem在多个骨干模型上一致提升了检索和推理性能。

Conclusion: CompassMem通过事件图组织记忆，支持逻辑推理导向的记忆访问，显著提升了智能体在长时程场景下的记忆管理和推理能力。

Abstract: Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.

</details>


### [14] [SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning](https://arxiv.org/abs/2601.04809)
*Caijun Xu,Changyi Xiao,Zhongyuan Peng,Xinrun Wang,Yixin Cao*

Main category: cs.AI

TL;DR: SCALER是一个通过自适应环境设计来维持有效学习信号的强化学习框架，它通过可扩展的合成管道将真实世界编程问题转化为可验证的推理环境，并采用自适应多环境RL策略来持续改进模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在提升大语言模型推理能力时面临两个主要问题：1）任务难度与模型能力不匹配时学习信号失效；2）训练容易被少数重复问题模式主导，导致过拟合。需要一种能持续提供有效学习信号的方法。

Method: SCALER包含两个核心组件：1）可扩展的合成管道，将真实编程问题转化为具有可控难度和无限实例生成能力的可验证推理环境；2）自适应多环境RL策略，动态调整实例难度并策划活跃环境集，以跟踪模型能力前沿并保持分布多样性。

Result: 实验表明SCALER在多种推理基准测试中持续优于基于数据集的RL基线方法，展现出更稳定、更长周期的训练动态，能够防止奖励稀疏性，减轻对狭窄任务模式的过拟合，支持持续改进。

Conclusion: SCALER通过自适应环境设计有效解决了RL训练中任务难度与模型能力不匹配以及过拟合问题，为持续提升语言模型推理能力提供了一种可扩展的框架，在多样推理任务上展现出优越性能。

Abstract: Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.

</details>


### [15] [Higher-Order Knowledge Representations for Agentic Scientific Reasoning](https://arxiv.org/abs/2601.04878)
*Isabella A. Stewart,Markus J. Buehler*

Main category: cs.AI

TL;DR: 该研究提出了一种基于超图的知识表示方法，用于科学发现，通过构建包含16万节点和32万超边的生物复合材料支架知识超图，揭示其无标度拓扑结构，并利用超图遍历工具帮助智能体系统生成新的材料机制假设。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱的二元关系约束无法捕捉控制物理行为出现的不可约高阶相互作用，而大语言模型虽然具备推理能力，但依赖缺乏结构深度的检索增强上下文。需要一种能够忠实编码多实体关系的知识表示方法。

Method: 引入超图知识表示构建方法，应用于约1100篇生物复合材料支架论文，构建包含161,172个节点和320,201条超边的全局超图。使用节点交集约束的超图遍历工具，使智能体系统能够桥接语义上遥远的概念。

Result: 构建的超图呈现无标度拓扑结构（幂律指数约1.23），围绕高度连接的概念枢纽组织。该系统成功生成了新颖复合材料的接地机制假设，例如通过壳聚糖中间体将氧化铈与PCL支架联系起来。

Conclusion: 该工作建立了一个"无教师"的智能推理系统，其中超图拓扑结构作为可验证的防护栏，通过揭示传统图方法所掩盖的关系，加速科学发现。

Abstract: Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a "teacherless" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.

</details>


### [16] [Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition](https://arxiv.org/abs/2601.04920)
*Nils Einecke*

Main category: cs.AI

TL;DR: 本文通过ESA的ELOPE竞赛案例研究，展示了ChatGPT在科学发现中作为编程伙伴的潜力，尽管存在一些局限性，但人机协作在竞争性科学环境中具有加速原型开发和概念洞察的价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地被用作编程伙伴，但它们在加速科学发现方面的作用仍未得到充分探索。本文旨在通过一个具体的竞赛案例，探索人机协作在科学研究和快速原型开发中的潜力。

Method: 采用案例研究方法，在ESA的ELOPE竞赛中使用ChatGPT进行快速原型开发。ChatGPT不仅提供可执行代码，还贡献算法推理、数据处理例程和方法论建议，如使用固定事件数而非固定时间跨度进行窗口化处理。

Result: 尽管参赛较晚，团队仍获得第二名（得分0.01282），证明了人机协作在竞争性科学环境中的有效性。同时观察到ChatGPT的局限性：常引入不必要的结构变化、被中间讨论混淆、偶尔产生关键错误，以及在较长科学讨论中遗忘重要方面。

Conclusion: 对话式AI既能加速开发又能支持科学研究中的概念洞察。通过分析其优缺点，本文主张将LLMs结构化地整合到科学工作流程中，并提出AI辅助科学工作的最佳实践建议，以增强快速原型开发能力。

Abstract: Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.

</details>


### [17] [Large language models can effectively convince people to believe conspiracies](https://arxiv.org/abs/2601.05050)
*Thomas H. Costello,Kellin Pelrine,Matthew Kowal,Antonio A. Arechar,Jean-François Godbout,Adam Gleave,David Rand,Gordon Pennycook*

Main category: cs.AI

TL;DR: GPT-4o能同样有效地增加或减少阴谋论信念，即使有防护措施也效果相似；纠正对话可以逆转新诱导的信念，提示使用准确信息能大幅降低其促进阴谋论的能力


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）的说服力是否更倾向于真相而非虚假信息，或者LLMs是否同样容易促进错误信念

Method: 通过三个预注册实验，让2,724名美国参与者与GPT-4o讨论他们不确定的阴谋论，模型被指示要么反驳（"揭穿"）要么支持（"鼓吹"）该阴谋论；使用移除防护措施的"越狱"版GPT-4o和标准版GPT-4o进行对比

Result: 使用越狱版GPT-4o时，AI在增加阴谋论信念方面与减少信念同样有效；令人担忧的是，鼓吹阴谋论的AI比揭穿的AI获得更积极的评价，并增加了对AI的信任；标准版GPT-4o产生非常相似的效果；纠正对话可以逆转新诱导的阴谋论信念；提示GPT-4o只使用准确信息能大幅降低其增加阴谋论信念的能力

Conclusion: LLMs拥有促进真相和虚假信息的强大能力，但存在潜在的解决方案来帮助减轻这种风险

Abstract: Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against ("debunking") or for ("bunking") that conspiracy. When using a "jailbroken" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.

</details>


### [18] [Reinforced Efficient Reasoning via Semantically Diverse Exploration](https://arxiv.org/abs/2601.05053)
*Ziqi Zhao,Zhaochun Ren,Jiahong Zou,Liu Yang,Zhiwei Xu,Xuri Ge,Zhumin Chen,Xinyu Ma,Daiting Shi,Shuaiqiang Wang,Dawei Yin,Xin Xin*

Main category: cs.AI

TL;DR: ROSE提出了一种基于语义多样性探索的强化高效推理方法，通过语义熵分支策略和ε探索机制增强探索多样性，使用长度感知分段优势估计器提高效率，在数学推理基准上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于MCTS的RLVR方法存在探索多样性有限和推理效率低的问题，需要改进以增强大语言模型的推理能力。

Method: ROSE包含三个核心组件：1) 语义熵分支策略，基于已采样推理路径的语义不确定性选择分支点生成新路径；2) ε探索机制，从根节点随机启动推理路径防止搜索过于局部化；3) 长度感知分段优势估计器，奖励简洁正确推理同时惩罚过长推理链。

Result: 在多种数学推理基准测试中，使用Qwen和Llama模型验证了ROSE的有效性和效率，代码已开源。

Conclusion: ROSE通过语义多样性探索和高效推理机制，显著提升了强化学习在语言模型推理任务中的性能，解决了现有方法的探索局限和效率问题。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.

</details>


### [19] [MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents](https://arxiv.org/abs/2601.05215)
*Tamil Sudaravan Mohan Doss,Michael Xu,Sudha Rao,Andrew D. Wilson,Balasaravanan Thoravi Kumaravel*

Main category: cs.AI

TL;DR: 提出了MineNPC-Task基准测试框架，用于评估《我的世界》开放世界中的记忆感知混合主动LLM智能体，包含玩家共创的任务模板和可机器验证的评估机制。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常使用合成提示，缺乏真实玩家体验和记忆感知智能体的系统评估。需要建立基于真实玩家交互、具有明确依赖结构和记忆要求的评估框架。

Method: 通过专家玩家的形成性和总结性协作游戏收集任务，将其规范化为参数化模板，包含明确的先决条件和依赖结构。采用有界知识策略，禁止使用游戏外捷径，并配备机器可检查的验证器。

Result: 使用GPT-4o评估了8位经验玩家的216个子任务，观察到代码执行、库存/工具处理、引用和导航方面的常见故障模式，同时发现混合主动澄清和轻量级记忆支持下的恢复能力。

Conclusion: MineNPC-Task为记忆感知具身智能体提供了透明、可复现的评估框架，玩家反馈积极但指出需要更强的跨任务记忆持久性。完整任务套件、验证器和评估工具已开源。

Abstract: We present \textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.
  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \textbf{216} subtasks across \textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Disco-RAG: Discourse-Aware Retrieval-Augmented Generation](https://arxiv.org/abs/2601.04377)
*Dongqi Liu,Hang Ding,Qiming Feng,Jian Li,Xurong Xie,Zhucun Xue,Chengjie Wang,Jiangning Zhang,Yabiao Wang*

Main category: cs.CL

TL;DR: Disco-RAG：一种话语感知的检索增强生成框架，通过显式注入话语信号来提升大语言模型在知识密集型任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有RAG策略通常以扁平、非结构化的方式处理检索到的文本段落，这阻碍了模型捕捉结构线索，限制了其从分散文档证据中综合知识的能力。

Method: 提出Disco-RAG框架，构建块内话语树捕捉局部层次结构，建立块间修辞图建模跨段落连贯性，将这些结构联合集成到规划蓝图中以指导生成过程。

Result: 在问答和长文档摘要基准测试中表现出色，无需微调即在基准测试中达到最先进的结果。

Conclusion: 话语结构在推进RAG系统中扮演重要角色，显式注入话语信号能显著提升模型性能。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.

</details>


### [21] [WESR: Scaling and Evaluating Word-level Event-Speech Recognition](https://arxiv.org/abs/2601.04508)
*Chenchen Yang,Kexin Huang,Liwei Fan,Qian Tu,Botian Jiang,Dong Zhang,Linqi Yin,Shimin Li,Zhaoye Fei,Qinyuan Cheng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 论文提出了WESR-Bench，一个用于评估语音中非语言事件（如笑声、哭声）定位的新基准，包含21种事件分类和900+专家标注语料，解决了现有方法在类别覆盖和时间粒度上的不足。


<details>
  <summary>Details</summary>
Motivation: 语音不仅传递语义信息，还包含丰富的非语言事件（笑声、哭声等）。虽然语义转录研究较多，但非语言事件的精确定位仍是一个关键但未充分探索的挑战。现有方法存在任务定义不充分（类别覆盖有限、时间粒度模糊）和缺乏标准化评估框架的问题。

Method: 1. 开发了包含21种语音事件的精细分类法，分为离散型（独立）和连续型（与语音混合）两类；2. 引入WESR-Bench评估集（900+语句），采用新的位置感知协议，将ASR错误与事件检测分离；3. 构建了1700+小时语料库，训练专门化模型。

Result: 构建的专门化模型超越了开源音频语言模型和商业API，同时保持了ASR质量。WESR-Bench提供了对离散和连续事件的精确定位测量能力。

Conclusion: WESR将成为未来建模丰富真实世界听觉场景研究的基础资源，为非语言事件检测提供了标准化评估框架和强大基线。

Abstract: Speech conveys not only linguistic information but also rich non-verbal vocal events such as laughing and crying. While semantic transcription is well-studied, the precise localization of non-verbal events remains a critical yet under-explored challenge. Current methods suffer from insufficient task definitions with limited category coverage and ambiguous temporal granularity. They also lack standardized evaluation frameworks, hindering the development of downstream applications. To bridge this gap, we first develop a refined taxonomy of 21 vocal events, with a new categorization into discrete (standalone) versus continuous (mixed with speech) types. Based on the refined taxonomy, we introduce WESR-Bench, an expert-annotated evaluation set (900+ utterances) with a novel position-aware protocol that disentangles ASR errors from event detection, enabling precise localization measurement for both discrete and continuous events. We also build a strong baseline by constructing a 1,700+ hour corpus, and train specialized models, surpassing both open-source audio-language models and commercial APIs while preserving ASR quality. We anticipate that WESR will serve as a foundational resource for future research in modeling rich, real-world auditory scenes.

</details>


### [22] [ToolGate: Contract-Grounded and Verified Tool Execution for LLMs](https://arxiv.org/abs/2601.04688)
*Yanming Liu,Xinyue Peng,Jiannan Cao,Xinyi Wang,Songhang Deng,Jintao Chen,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: ToolGate是一个为LLM工具调用提供逻辑安全保证和可验证状态演进的框架，通过形式化工具合约和运行时验证确保状态只通过已验证的工具执行来演进。


<details>
  <summary>Details</summary>
Motivation: 现有LLM工具增强框架依赖自然语言推理来决定工具调用时机和结果提交，缺乏逻辑安全性和可验证性的形式化保证，可能导致无效或幻觉结果污染世界表示。

Method: ToolGate维护显式符号状态空间作为类型化键值映射，将每个工具形式化为Hoare风格合约（前置条件和后置条件），前置条件控制工具调用，后置条件通过运行时验证决定结果是否提交更新状态。

Result: 实验验证表明ToolGate显著提高了工具增强LLM系统的可靠性和可验证性，同时在复杂多步推理任务上保持竞争力。

Conclusion: 该工作为构建更可信赖和可调试的AI系统奠定了基础，这些系统将语言模型与外部工具集成，提供逻辑安全保证和可验证状态演进。

Abstract: Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.

</details>


### [23] [CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters](https://arxiv.org/abs/2601.04885)
*Ao Sun,Xiaoyu Wang,Zhe Tan,Yu Li,Jiachen Zhu,Shu Su,Yuheng Jia*

Main category: cs.CL

TL;DR: 论文提出CuMA框架解决LLM对齐中的文化多样性问题，通过文化混合适配器分离冲突梯度，避免均值崩溃，保持文化多样性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型服务全球用户时，对齐需要从强制普遍共识转向尊重文化多元主义。现有密集模型在拟合冲突价值分布时会出现"均值崩溃"问题，收敛到通用平均值而无法代表不同文化群体。

Method: 提出CuMA（文化混合适配器）框架，将对齐视为条件容量分离问题。通过人口统计感知路由，内部化潜在文化拓扑，将冲突梯度显式解耦到专门的专家子空间中。

Result: 在WorldValuesBench、Community Alignment和PRISM数据集上的广泛评估显示，CuMA达到最先进性能，显著优于密集基线和仅语义的MoE方法。分析确认CuMA有效缓解均值崩溃，保持文化多样性。

Conclusion: CuMA框架成功解决了LLM对齐中的文化多样性挑战，通过文化混合适配器实现了文化敏感的对齐，为全球用户提供更包容的语言模型服务。

Abstract: As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \textbf{\textsc{CuMA}} (\textbf{Cu}ltural \textbf{M}ixture of \textbf{A}dapters), a framework that frames alignment as a \textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \textsc{CuMA} internalizes a \textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.

</details>
