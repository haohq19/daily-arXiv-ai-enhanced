<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 9]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Closed-Circuit Television Data as an Emergent Data Source for Urban Rail Platform Crowding Estimation](https://arxiv.org/abs/2508.03749)
*Riccardo Fiorista,Awad Abdelhalim,Anson F. Stewart,Gabriel L. Pincus,Ian Thistle,Jinhua Zhao*

Main category: cs.CV

TL;DR: 论文探讨了利用CCTV视频数据通过计算机视觉技术实时估计城市轨道交通站台拥挤度的方法，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 准确估计站台拥挤度可提升运营决策能力，改善安全、效率和乘客体验，但目前依赖间接数据源。CCTV视频数据有望提供更精确的实时估计。

Method: 比较了三种计算机视觉方法（目标检测与计数、人群分类、语义分割），并提出一种基于线性优化的新方法。

Result: 在包含600多小时视频的隐私保护数据集上测试，证明计算机视觉方法对拥挤度估计具有显著价值。

Conclusion: CCTV数据可独立支持更精确的实时拥挤度估计，助力及时运营响应。

Abstract: Accurately estimating urban rail platform occupancy can enhance transit
agencies' ability to make informed operational decisions, thereby improving
safety, operational efficiency, and customer experience, particularly in the
context of crowding. However, sensing real-time crowding remains challenging
and often depends on indirect proxies such as automatic fare collection data or
staff observations. Recently, Closed-Circuit Television (CCTV) footage has
emerged as a promising data source with the potential to yield accurate,
real-time occupancy estimates. The presented study investigates this potential
by comparing three state-of-the-art computer vision approaches for extracting
crowd-related features from platform CCTV imagery: (a) object detection and
counting using YOLOv11, RT-DETRv2, and APGCC; (b) crowd-level classification
via a custom-trained Vision Transformer, Crowd-ViT; and (c) semantic
segmentation using DeepLabV3. Additionally, we present a novel, highly
efficient linear-optimization-based approach to extract counts from the
generated segmentation maps while accounting for image object depth and, thus,
for passenger dispersion along a platform. Tested on a privacy-preserving
dataset created in collaboration with the Washington Metropolitan Area Transit
Authority (WMATA) that encompasses more than 600 hours of video material, our
results demonstrate that computer vision approaches can provide substantive
value for crowd estimation. This work demonstrates that CCTV image data,
independent of other data sources available to a transit agency, can enable
more precise real-time crowding estimation and, eventually, timely operational
responses for platform crowding mitigation.

</details>


### [2] [SVC 2025: the First Multimodal Deception Detection Challenge](https://arxiv.org/abs/2508.04129)
*Xun Lin,Xiaobao Guo,Taorui Wang,Yingjie Ma,Jiajian Huang,Jiayu Zhang,Junzhe Cao,Zitong Yu*

Main category: cs.CV

TL;DR: SVC 2025多模态欺骗检测挑战赛旨在解决跨领域泛化问题，通过多模态数据提升欺骗检测模型的适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单领域场景，忽视了领域转移导致的性能下降，需开发跨领域泛化能力强的模型。

Method: 利用音频、视频和文本等多模态数据，设计能捕捉细微欺骗线索的模型。

Result: 21支团队提交了最终结果，推动了多模态学习的发展。

Conclusion: 该挑战赛促进了更适应性强、可解释性高的欺骗检测系统的开发。

Abstract: Deception detection is a critical task in real-world applications such as
security screening, fraud prevention, and credibility assessment. While deep
learning methods have shown promise in surpassing human-level performance,
their effectiveness often depends on the availability of high-quality and
diverse deception samples. Existing research predominantly focuses on
single-domain scenarios, overlooking the significant performance degradation
caused by domain shifts. To address this gap, we present the SVC 2025
Multimodal Deception Detection Challenge, a new benchmark designed to evaluate
cross-domain generalization in audio-visual deception detection. Participants
are required to develop models that not only perform well within individual
domains but also generalize across multiple heterogeneous datasets. By
leveraging multimodal data, including audio, video, and text, this challenge
encourages the design of models capable of capturing subtle and implicit
deceptive cues. Through this benchmark, we aim to foster the development of
more adaptable, explainable, and practically deployable deception detection
systems, advancing the broader field of multimodal learning. By the conclusion
of the workshop competition, a total of 21 teams had submitted their final
results. https://sites.google.com/view/svc-mm25 for more information.

</details>


### [3] [SplitGaussian: Reconstructing Dynamic Scenes via Visual Geometry Decomposition](https://arxiv.org/abs/2508.04224)
*Jiahui Li,Shengeng Tang,Jingxuan He,Gang Huang,Zhangye Wang,Yantao Pan,Lechao Cheng*

Main category: cs.CV

TL;DR: SplitGaussian 是一种新框架，通过将场景表示分解为静态和动态组件，解决了动态3D场景重建中的运动泄漏和几何失真问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景重建中常将静态和动态元素耦合表示，导致运动泄漏、几何失真和时间闪烁。

Method: 提出 SplitGaussian，显式分解场景表示，解耦运动建模与背景几何，仅动态分支随时间变形。

Result: 实验表明，SplitGaussian 在渲染质量、几何稳定性和运动分离方面优于现有方法。

Conclusion: SplitGaussian 通过解耦设计提高了时间一致性和重建保真度，同时加速了收敛。

Abstract: Reconstructing dynamic 3D scenes from monocular video remains fundamentally
challenging due to the need to jointly infer motion, structure, and appearance
from limited observations. Existing dynamic scene reconstruction methods based
on Gaussian Splatting often entangle static and dynamic elements in a shared
representation, leading to motion leakage, geometric distortions, and temporal
flickering. We identify that the root cause lies in the coupled modeling of
geometry and appearance across time, which hampers both stability and
interpretability. To address this, we propose \textbf{SplitGaussian}, a novel
framework that explicitly decomposes scene representations into static and
dynamic components. By decoupling motion modeling from background geometry and
allowing only the dynamic branch to deform over time, our method prevents
motion artifacts in static regions while supporting view- and time-dependent
appearance refinement. This disentangled design not only enhances temporal
consistency and reconstruction fidelity but also accelerates convergence.
Extensive experiments demonstrate that SplitGaussian outperforms prior
state-of-the-art methods in rendering quality, geometric stability, and motion
separation.

</details>


### [4] [Segment Any Vehicle: Semantic and Visual Context Driven SAM and A Benchmark](https://arxiv.org/abs/2508.04260)
*Xiao Wang,Ziwen Wang,Wentao Wu,Anjie Wang,Jiashu Wu,Yantao Pan,Chenglong Li*

Main category: cs.CV

TL;DR: 论文提出SAV框架，结合SAM模型、车辆部件知识图谱和上下文检索模块，解决了车辆部件分割问题，并发布了新数据集VehicleSeg10K。


<details>
  <summary>Details</summary>
Motivation: 现有SAM模型无法直接用于车辆部件分割任务，因其缺乏语义标签和文本提示功能，限制了其在结构化任务中的应用。

Method: 提出SAV框架，包含SAM编码解码器、车辆部件知识图谱和上下文检索模块，利用结构化知识和视觉相似性提升分割效果。

Result: 在VehicleSeg10K等数据集上进行了实验，验证了SAV框架的有效性。

Conclusion: SAV框架解决了车辆部件分割问题，并提供了新数据集和开源代码，为未来研究奠定基础。

Abstract: With the rapid advancement of autonomous driving, vehicle perception,
particularly detection and segmentation, has placed increasingly higher demands
on algorithmic performance. Pre-trained large segmentation models, especially
Segment Anything Model (SAM), have sparked significant interest and inspired
new research directions in artificial intelligence. However, SAM cannot be
directly applied to the fine-grained task of vehicle part segmentation, as its
text-prompted segmentation functionality is not publicly accessible, and the
mask regions generated by its default mode lack semantic labels, limiting its
utility in structured, category-specific segmentation tasks. To address these
limitations, we propose SAV, a novel framework comprising three core
components: a SAM-based encoder-decoder, a vehicle part knowledge graph, and a
context sample retrieval encoding module. The knowledge graph explicitly models
the spatial and geometric relationships among vehicle parts through a
structured ontology, effectively encoding prior structural knowledge.
Meanwhile, the context retrieval module enhances segmentation by identifying
and leveraging visually similar vehicle instances from training data, providing
rich contextual priors for improved generalization. Furthermore, we introduce a
new large-scale benchmark dataset for vehicle part segmentation, named
VehicleSeg10K, which contains 11,665 high-quality pixel-level annotations
across diverse scenes and viewpoints. We conduct comprehensive experiments on
this dataset and two other datasets, benchmarking multiple representative
baselines to establish a solid foundation for future research and comparison. %
Both the dataset and source code of this paper will be released upon
acceptance. Both the dataset and source code of this paper will be released on
https://github.com/Event-AHU/SAV

</details>


### [5] [TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding](https://arxiv.org/abs/2508.04369)
*Canhui Tang,Zifan Han,Hongbo Sun,Sanping Zhou,Xuchong Zhang,Xin Wei,Ye Yuan,Jinglin Xu,Hao Sun*

Main category: cs.CV

TL;DR: 论文提出了一种名为TSPO的强化学习方法，用于优化多模态大语言模型（MLLMs）在长视频理解中的稀疏帧采样策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频MLLMs在处理长视频时因上下文限制和训练成本问题，通常采用无训练的均匀采样或关键帧搜索方法，但这些方法可能遗漏关键事件或受限于预训练模型的事件理解能力。

Method: 提出TSPO方法，包括可训练的事件感知时间代理和强化学习范式，将关键帧选择和语言生成建模为联合决策过程，并通过基于规则的高效奖励进行端到端优化。

Result: 实验表明，TSPO在多个长视频理解基准测试中达到最先进性能，并展现出对不同前沿视频MLLMs的可迁移能力。

Conclusion: TSPO通过强化学习优化稀疏帧采样策略，显著提升了MLLMs在长视频理解任务中的表现，具有广泛的应用潜力。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
progress in vision-language tasks, yet they still face challenges when
processing long-duration video inputs. The limitation arises from MLLMs'
context limit and training costs, necessitating sparse frame sampling before
feeding videos into MLLMs. Existing video MLLMs adopt training-free uniform
sampling or keyframe search, which may miss critical events or be constrained
by the pre-trained models' event understanding capabilities. Meanwhile,
building a training-based method remains challenging due to the unsupervised
and non-differentiable nature of sparse frame sampling. To address these
problems, we propose Temporal Sampling Policy Optimization (TSPO), advancing
MLLMs' long-form video-language understanding via reinforcement learning.
Specifically, we first propose a trainable event-aware temporal agent, which
captures event-query correlation for performing probabilistic keyframe
selection. Then, we propose the TSPO reinforcement learning paradigm, which
models keyframe selection and language generation as a joint decision-making
process, enabling end-to-end group relative optimization with efficient
rule-based rewards. Furthermore, for the TSPO's training, we propose a long
video training data construction pipeline with comprehensive temporal data and
video Needle-in-a-Haystack data. Finally, we incorporate rule-based answering
accuracy and temporal locating reward mechanisms to optimize the temporal
sampling policy. Comprehensive experiments show that our TSPO achieves
state-of-the-art performance across multiple long video understanding
benchmarks, and shows transferable ability across different cutting-edge
Video-MLLMs.

</details>


### [6] [Zero-Residual Concept Erasure via Progressive Alignment in Text-to-Image Model](https://arxiv.org/abs/2508.04472)
*Hongxu Chen,Zhen Wang,Taoran Mei,Lin Li,Bowei Zhu,Runshi Li,Long Chen*

Main category: cs.CV

TL;DR: 论文提出了一种新的概念擦除方法ErasePro，通过零残差约束和渐进式层更新策略，解决了现有方法在复杂提示下擦除不彻底和生成质量下降的问题。


<details>
  <summary>Details</summary>
Motivation: 预训练的文本到图像模型可能生成与有害概念相关的内容，现有方法在复杂提示下擦除不彻底且可能影响生成质量。

Method: ErasePro引入零残差约束确保目标概念与锚概念完美对齐，并采用渐进式层更新策略从浅层到深层逐步更新参数。

Result: 在不同概念擦除任务（如实例、艺术风格和裸露擦除）中，ErasePro表现出更高的擦除完整性和生成质量。

Conclusion: ErasePro通过优化目标设计和更新策略，显著提升了概念擦除的效果和生成质量。

Abstract: Concept Erasure, which aims to prevent pretrained text-to-image models from
generating content associated with semantic-harmful concepts (i.e., target
concepts), is getting increased attention. State-of-the-art methods formulate
this task as an optimization problem: they align all target concepts with
semantic-harmless anchor concepts, and apply closed-form solutions to update
the model accordingly. While these closed-form methods are efficient, we argue
that existing methods have two overlooked limitations: 1) They often result in
incomplete erasure due to "non-zero alignment residual", especially when text
prompts are relatively complex. 2) They may suffer from generation quality
degradation as they always concentrate parameter updates in a few deep layers.
To address these issues, we propose a novel closed-form method ErasePro: it is
designed for more complete concept erasure and better preserving overall
generative quality. Specifically, ErasePro first introduces a strict
zero-residual constraint into the optimization objective, ensuring perfect
alignment between target and anchor concept features and enabling more complete
erasure. Secondly, it employs a progressive, layer-wise update strategy that
gradually transfers target concept features to those of the anchor concept from
shallow to deep layers. As the depth increases, the required parameter changes
diminish, thereby reducing deviations in sensitive deep layers and preserving
generative quality. Empirical results across different concept erasure tasks
(including instance, art style, and nudity erasure) have demonstrated the
effectiveness of our ErasePro.

</details>


### [7] [Hierarchical Event Memory for Accurate and Low-latency Online Video Temporal Grounding](https://arxiv.org/abs/2508.04546)
*Minghang Zheng,Yuxin Peng,Benyuan Sun,Yi Yang,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种分层事件记忆方法，用于在线视频时间定位任务（OnVTG），通过事件建模和长期历史信息保留，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在线视频时间定位（OnVTG）需要模型在不观察未来帧的情况下定位事件，现有方法缺乏有效的事件建模和长期历史信息保留，导致性能低下。

Method: 提出基于事件的分层事件记忆框架，通过事件提案建模事件级信息，并引入分层事件记忆保留历史事件信息。此外，还设计了未来预测分支以实现实时预测。

Result: 在TACoS、ActivityNet Captions和MAD数据集上实现了最先进的性能。

Conclusion: 分层事件记忆方法有效解决了OnVTG任务中的事件建模和长期信息保留问题，显著提升了性能。

Abstract: In this paper, we tackle the task of online video temporal grounding (OnVTG),
which requires the model to locate events related to a given text query within
a video stream. Unlike regular video temporal grounding, OnVTG requires the
model to make predictions without observing future frames. As online videos are
streaming inputs and can go on indefinitely, it is impractical and inefficient
to store all historical inputs. The existing OnVTG models employ memory to
store recent historical video frame features and predict scores indicating
whether the current frame corresponds to the start or end time of the target
event. However, these methods lack effective event modeling and cannot retain
long-term historical information, leading to low performance. To tackle these
challenges, we propose a hierarchical event memory for OnVTG. We propose an
event-based OnVTG framework that makes predictions based on event proposals
that model event-level information with various durations. To preserve
historically valuable event information, we introduce a hierarchical event
memory that retains historical events, allowing the model to access both recent
and long-term information. To enable the real-time prediction, we further
propose a future prediction branch that predicts whether the target event will
occur shortly and further regresses the start time of the event. We achieve
state-of-the-art performance on the TACoS, ActivityNet Captions, and MAD
datasets. Code is available at https://github.com/minghangz/OnVTG.

</details>


### [8] [Drone Detection with Event Cameras](https://arxiv.org/abs/2508.04564)
*Gabriele Magrini,Lorenzo Berlincioni,Luca Cultrera,Federico Becattini,Pietro Pala*

Main category: cs.CV

TL;DR: 事件相机在无人机检测中解决了传统相机的运动模糊和光照问题，提供了低延迟、高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统相机在检测小型、高机动性无人机时存在运动模糊和光照适应性差的问题，事件相机因其独特优势成为潜在解决方案。

Method: 综述了事件相机在无人机检测中的应用，包括数据表示方法、尖峰神经网络处理流程，以及实时跟踪、轨迹预测等高级任务。

Result: 事件相机能显著提升无人机检测的可靠性和低延迟性，适用于复杂场景。

Conclusion: 事件视觉技术为下一代反无人机系统提供了强大基础，具备高效、低延迟的优势。

Abstract: The diffusion of drones presents significant security and safety challenges.
Traditional surveillance systems, particularly conventional frame-based
cameras, struggle to reliably detect these targets due to their small size,
high agility, and the resulting motion blur and poor performance in challenging
lighting conditions. This paper surveys the emerging field of event-based
vision as a robust solution to these problems. Event cameras virtually
eliminate motion blur and enable consistent detection in extreme lighting.
Their sparse, asynchronous output suppresses static backgrounds, enabling
low-latency focus on motion cues. We review the state-of-the-art in event-based
drone detection, from data representation methods to advanced processing
pipelines using spiking neural networks. The discussion extends beyond simple
detection to cover more sophisticated tasks such as real-time tracking,
trajectory forecasting, and unique identification through propeller signature
analysis. By examining current methodologies, available datasets, and the
distinct advantages of the technology, this work demonstrates that event-based
vision provides a powerful foundation for the next generation of reliable,
low-latency, and efficient counter-UAV systems.

</details>


### [9] [CLASP: Cross-modal Salient Anchor-based Semantic Propagation for Weakly-supervised Dense Audio-Visual Event Localization](https://arxiv.org/abs/2508.04566)
*Jinxing Zhou,Ziheng Zhou,Yanghao Zhou,Yuxin Mao,Zhangling Duan,Dan Guo*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督下的密集视听事件定位方法（W-DAVEL），通过跨模态显著锚点和事件一致性评估模块，显著提升了事件定位性能。


<details>
  <summary>Details</summary>
Motivation: 在弱监督条件下（仅有视频级事件标签），如何有效定位视听事件是一个挑战。本文旨在解决这一问题。

Method: 提出跨模态显著锚点概念，结合事件一致性评估和锚点传播模块，增强事件语义编码。

Result: 在UnAV-100和ActivityNet1.3数据集上实现了最先进的性能。

Conclusion: 该方法在弱监督条件下显著提升了视听事件定位的准确性。

Abstract: The Dense Audio-Visual Event Localization (DAVEL) task aims to temporally
localize events in untrimmed videos that occur simultaneously in both the audio
and visual modalities. This paper explores DAVEL under a new and more
challenging weakly-supervised setting (W-DAVEL task), where only video-level
event labels are provided and the temporal boundaries of each event are
unknown. We address W-DAVEL by exploiting \textit{cross-modal salient anchors},
which are defined as reliable timestamps that are well predicted under weak
supervision and exhibit highly consistent event semantics across audio and
visual modalities. Specifically, we propose a \textit{Mutual Event Agreement
Evaluation} module, which generates an agreement score by measuring the
discrepancy between the predicted audio and visual event classes. Then, the
agreement score is utilized in a \textit{Cross-modal Salient Anchor
Identification} module, which identifies the audio and visual anchor features
through global-video and local temporal window identification mechanisms. The
anchor features after multimodal integration are fed into an
\textit{Anchor-based Temporal Propagation} module to enhance event semantic
encoding in the original temporal audio and visual features, facilitating
better temporal localization under weak supervision. We establish benchmarks
for W-DAVEL on both the UnAV-100 and ActivityNet1.3 datasets. Extensive
experiments demonstrate that our method achieves state-of-the-art performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [GlaBoost: A multimodal Structured Framework for Glaucoma Risk Stratification](https://arxiv.org/abs/2508.03750)
*Cheng Huang,Weizheng Xie,Karanjit Kooner,Tsengdar Lee,Jui-Kai Wang,Jia Zhang*

Main category: cs.LG

TL;DR: GlaBoost是一种多模态梯度提升框架，结合临床特征、眼底图像和专家文本描述，用于青光眼风险预测，准确率达98.71%。


<details>
  <summary>Details</summary>
Motivation: 现有青光眼检测方法依赖单模态数据且缺乏可解释性，限制了临床实用性。

Method: GlaBoost通过预训练卷积编码器和基于Transformer的语言模型提取视觉和文本特征，结合手动评估的风险分数和眼科指标，通过增强的XGBoost模型进行分类。

Result: 在真实数据集上，GlaBoost显著优于基线模型，验证准确率达98.71%。特征重要性分析显示临床一致的决策模式。

Conclusion: GlaBoost为青光眼诊断提供了透明且可扩展的解决方案，并可扩展至其他眼科疾病。

Abstract: Early and accurate detection of glaucoma is critical to prevent irreversible
vision loss. However, existing methods often rely on unimodal data and lack
interpretability, limiting their clinical utility. In this paper, we present
GlaBoost, a multimodal gradient boosting framework that integrates structured
clinical features, fundus image embeddings, and expert-curated textual
descriptions for glaucoma risk prediction. GlaBoost extracts high-level visual
representations from retinal fundus photographs using a pretrained
convolutional encoder and encodes free-text neuroretinal rim assessments using
a transformer-based language model. These heterogeneous signals, combined with
manually assessed risk scores and quantitative ophthalmic indicators, are fused
into a unified feature space for classification via an enhanced XGBoost model.
Experiments conducted on a real-world annotated dataset demonstrate that
GlaBoost significantly outperforms baseline models, achieving a validation
accuracy of 98.71%. Feature importance analysis reveals clinically consistent
patterns, with cup-to-disc ratio, rim pallor, and specific textual embeddings
contributing most to model decisions. GlaBoost offers a transparent and
scalable solution for interpretable glaucoma diagnosis and can be extended to
other ophthalmic disorders.

</details>


### [11] [GTPO: Trajectory-Based Policy Optimization in Large Language Models](https://arxiv.org/abs/2508.03772)
*Marco Simoni,Aleksandar Fontana,Giulio Rossolini,Andrea Saracino*

Main category: cs.LG

TL;DR: 本文分析了GRPO的两大局限性，并提出GTPO作为改进方案，通过跳过冲突令牌的负更新和过滤高熵补全，提升了训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: GRPO在语言模型训练中存在令牌冲突和策略崩溃问题，需要更稳定的优化策略。

Method: 提出GTPO，识别冲突令牌并跳过负更新，同时过滤高熵补全，避免KL散度正则化。

Result: 在GSM8K、MATH和AIME 2024基准测试中验证了GTPO的稳定性和性能提升。

Conclusion: GTPO解决了GRPO的局限性，无需参考模型，实现了更优的训练效果。

Abstract: Policy-based optimizations are widely adopted today for the training and
alignment of language models, where one of the most recent and effective
approaches is Group-relative Policy Optimization (GRPO). In this paper, we
reveals and analyze two major limitations of GRPO: (i) tokens frequently appear
in completions with both positive and negative rewards, leading to conflicting
gradient updates that can reduce their output probability, even though can be
essential for maintaining proper structure; (ii) negatively rewarded
completions may penalize confident responses and shift model decisions toward
unlikely tokens, progressively flattening the output distribution and degrading
learning. To address these issues and provide a more stable and effective
policy optimization strategy, we introduce GTPO (Group-relative
Trajectory-based Policy Optimization), which identifies conflict tokens, tokens
appearing in the same position across completions with opposite rewards,
protects them by skipping negative updates, while amplifying positive ones. To
further prevent policy collapse, GTPO filters out completions whose entropy
exceeds a provable threshold. Unlike GRPO, GTPO does not rely on KL-divergence
regularization, eliminating the need for a reference model during training,
while still ensuring greater training stability and improved performance,
validated through multiple experiments on GSM8K, MATH and AIME 2024 benchmarks.

</details>


### [12] [Revisiting Heat Flux Analysis of Tungsten Monoblock Divertor on EAST using Physics-Informed Neural Network](https://arxiv.org/abs/2508.03776)
*Xiao Wang,Zikang Yan,Hao Si,Zhendong Yang,Qingquan Yang,Dengdi Sun,Wanli Lyu,Jin Tang*

Main category: cs.LG

TL;DR: 论文提出了一种基于物理信息神经网络（PINN）的方法，用于加速核聚变装置EAST中的热通量估计，相比传统有限元方法（FEM）实现了40倍的加速，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 传统有限元方法（FEM）计算效率低，难以实现实时模拟，而人工智能驱动的科学计算为解决这一问题提供了新思路。

Method: 通过将空间坐标和时间戳输入神经网络，结合热传导方程计算边界损失、初始条件损失和物理损失，并采用数据驱动方式采样少量数据点以优化模型。

Result: 实验表明，该方法在均匀和非均匀加热条件下均能达到与FEM相当的精度，同时计算效率提升了40倍。

Conclusion: 提出的PINN方法在热传导估计中具有高效性和准确性，为实时模拟提供了可能。

Abstract: Estimating heat flux in the nuclear fusion device EAST is a critically
important task. Traditional scientific computing methods typically model this
process using the Finite Element Method (FEM). However, FEM relies on
grid-based sampling for computation, which is computationally inefficient and
hard to perform real-time simulations during actual experiments. Inspired by
artificial intelligence-powered scientific computing, this paper proposes a
novel Physics-Informed Neural Network (PINN) to address this challenge,
significantly accelerating the heat conduction estimation process while
maintaining high accuracy. Specifically, given inputs of different materials,
we first feed spatial coordinates and time stamps into the neural network, and
compute boundary loss, initial condition loss, and physical loss based on the
heat conduction equation. Additionally, we sample a small number of data points
in a data-driven manner to better fit the specific heat conduction scenario,
further enhancing the model's predictive capability. We conduct experiments
under both uniform and non-uniform heating conditions on the top surface.
Experimental results show that the proposed thermal conduction physics-informed
neural network achieves accuracy comparable to the finite element method, while
achieving $\times$40 times acceleration in computational efficiency. The
dataset and source code will be released on
https://github.com/Event-AHU/OpenFusion.

</details>


### [13] [Active Learning and Transfer Learning for Anomaly Detection in Time-Series Data](https://arxiv.org/abs/2508.03921)
*John D. Kelleher,Matthew Nicholson,Rahul Agrahari,Clare Conran*

Main category: cs.LG

TL;DR: 结合主动学习和迁移学习用于跨域时间序列异常检测，发现聚类与主动学习存在交互作用，最佳性能出现在未聚类时；主动学习能提升性能，但速度较慢；迁移学习与主动学习的性能提升初期显著，后期趋于平缓。


<details>
  <summary>Details</summary>
Motivation: 研究主动学习与迁移学习在跨域时间序列异常检测中的有效性，探索其性能提升的潜力与限制。

Method: 结合主动学习和迁移学习，通过实验设计区分采样与测试数据，评估聚类与主动学习的交互作用及性能变化。

Result: 未聚类时性能最佳；主动学习提升性能但速度较慢；迁移学习与主动学习的性能初期提升后趋于平缓。

Conclusion: 主动学习有效但性能提升呈线性平缓趋势，迁移学习与主动学习的性能提升存在上限。

Abstract: This paper examines the effectiveness of combining active learning and
transfer learning for anomaly detection in cross-domain time-series data. Our
results indicate that there is an interaction between clustering and active
learning and in general the best performance is achieved using a single cluster
(in other words when clustering is not applied). Also, we find that adding new
samples to the training set using active learning does improve model
performance but that in general, the rate of improvement is slower than the
results reported in the literature suggest. We attribute this difference to an
improved experimental design where distinct data samples are used for the
sampling and testing pools. Finally, we assess the ceiling performance of
transfer learning in combination with active learning across several datasets
and find that performance does initially improve but eventually begins to tail
off as more target points are selected for inclusion in training. This tail-off
in performance may indicate that the active learning process is doing a good
job of sequencing data points for selection, pushing the less useful points
towards the end of the selection process and that this tail-off occurs when
these less useful points are eventually added. Taken together our results
indicate that active learning is effective but that the improvement in model
performance follows a linear flat function concerning the number of points
selected and labelled.

</details>


### [14] [From Split to Share: Private Inference with Distributed Feature Sharing](https://arxiv.org/abs/2508.04346)
*Zihan Liu,Jiayi Wen,Shouhong Tan,Zhirun Zheng,Cheng Huang*

Main category: cs.LG

TL;DR: PrivDFS是一种新的私有推理范式，通过分布式特征共享解决隐私与效率的权衡问题，同时提出两种扩展方法进一步强化隐私保护。


<details>
  <summary>Details</summary>
Motivation: 处理敏感客户数据时，现有的私有推理方法在隐私和效率之间存在根本性权衡，需要一种既能保护隐私又高效的新方法。

Method: PrivDFS将输入特征分区并分发到多个非共谋服务器进行独立推理，客户端安全聚合结果；扩展方法包括对抗训练（PrivDFS-AT）和用户特定密钥（PrivDFS-KD）。

Result: 在CIFAR-10和CelebA上，PrivDFS在保持隐私的同时，将客户端计算减少100倍且无精度损失，扩展方法对多种攻击保持鲁棒性。

Conclusion: PrivDFS提供了一种高效且隐私保护的推理方案，扩展方法进一步增强了其安全性。

Abstract: Cloud-based Machine Learning as a Service (MLaaS) raises serious privacy
concerns when handling sensitive client data. Existing Private Inference (PI)
methods face a fundamental trade-off between privacy and efficiency:
cryptographic approaches offer strong protection but incur high computational
overhead, while efficient alternatives such as split inference expose
intermediate features to inversion attacks. We propose PrivDFS, a new paradigm
for private inference that replaces a single exposed representation with
distributed feature sharing. PrivDFS partitions input features on the client
into multiple balanced shares, which are distributed to non-colluding,
non-communicating servers for independent partial inference. The client
securely aggregates the servers' outputs to reconstruct the final prediction,
ensuring that no single server observes sufficient information to compromise
input privacy. To further strengthen privacy, we propose two key extensions:
PrivDFS-AT, which uses adversarial training with a diffusion-based proxy
attacker to enforce inversion-resistant feature partitioning, and PrivDFS-KD,
which leverages user-specific keys to diversify partitioning policies and
prevent query-based inversion generalization. Experiments on CIFAR-10 and
CelebA demonstrate that PrivDFS achieves privacy comparable to deep split
inference while cutting client computation by up to 100 times with no accuracy
loss, and that the extensions remain robust against both diffusion-based
in-distribution and adaptive attacks.

</details>


### [15] [Multi-Marginal Stochastic Flow Matching for High-Dimensional Snapshot Data at Irregular Time Points](https://arxiv.org/abs/2508.04351)
*Justin Lee,Behnaz Moradijamei,Heman Shakeri*

Main category: cs.LG

TL;DR: 论文提出了一种名为MMSFM的新方法，用于处理高维系统在非均匀时间点观测数据的建模问题，避免了传统降维方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决高维系统在非均匀时间点观测数据建模的挑战，避免降维方法对动态和瞬态行为的简化。

Method: 扩展了无模拟的分数和流匹配方法，引入多边际设置，结合测度值样条和分数匹配技术。

Result: 在合成和基准数据集（如基因表达和图像进展任务）上验证了方法的有效性。

Conclusion: MMSFM方法能够在不降维的情况下处理非均匀时间点的高维数据，具有广泛适用性。

Abstract: Modeling the evolution of high-dimensional systems from limited snapshot
observations at irregular time points poses a significant challenge in
quantitative biology and related fields. Traditional approaches often rely on
dimensionality reduction techniques, which can oversimplify the dynamics and
fail to capture critical transient behaviors in non-equilibrium systems. We
present Multi-Marginal Stochastic Flow Matching (MMSFM), a novel extension of
simulation-free score and flow matching methods to the multi-marginal setting,
enabling the alignment of high-dimensional data measured at non-equidistant
time points without reducing dimensionality. The use of measure-valued splines
enhances robustness to irregular snapshot timing, and score matching prevents
overfitting in high-dimensional spaces. We validate our framework on several
synthetic and benchmark datasets, including gene expression data collected at
uneven time points and an image progression task, demonstrating the method's
versatility.

</details>


### [16] [Channel-Independent Federated Traffic Prediction](https://arxiv.org/abs/2508.04517)
*Mo Zhang,Xiaoyu Li,Bin Xu,Meng Chen,Yongshun Gong*

Main category: cs.LG

TL;DR: 论文提出了一种名为CIP的新范式，用于联邦交通预测，无需客户端间通信，显著降低了通信开销并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有联邦交通预测方法因通信开销大导致的训练延迟问题，同时满足隐私约束。

Method: 提出CIP范式，开发Fed-CI框架，使各客户端仅用本地数据独立预测，减少通信需求。

Result: Fed-CI在多个数据集上表现优异，RMSE、MAE和MAPE分别提升8%、14%和16%，并大幅降低通信成本。

Conclusion: CIP和Fed-CI为联邦交通预测提供了高效、隐私合规的解决方案，优于现有方法。

Abstract: In recent years, traffic prediction has achieved remarkable success and has
become an integral component of intelligent transportation systems. However,
traffic data is typically distributed among multiple data owners, and privacy
constraints prevent the direct utilization of these isolated datasets for
traffic prediction. Most existing federated traffic prediction methods focus on
designing communication mechanisms that allow models to leverage information
from other clients in order to improve prediction accuracy. Unfortunately, such
approaches often incur substantial communication overhead, and the resulting
transmission delays significantly slow down the training process. As the volume
of traffic data continues to grow, this issue becomes increasingly critical,
making the resource consumption of current methods unsustainable. To address
this challenge, we propose a novel variable relationship modeling paradigm for
federated traffic prediction, termed the Channel-Independent Paradigm(CIP).
Unlike traditional approaches, CIP eliminates the need for inter-client
communication by enabling each node to perform efficient and accurate
predictions using only local information. Based on the CIP, we further develop
Fed-CI, an efficient federated learning framework, allowing each client to
process its own data independently while effectively mitigating the information
loss caused by the lack of direct data sharing among clients. Fed-CI
significantly reduces communication overhead, accelerates the training process,
and achieves state-of-the-art performance while complying with privacy
regulations. Extensive experiments on multiple real-world datasets demonstrate
that Fed-CI consistently outperforms existing methods across all datasets and
federated settings. It achieves improvements of 8%, 14%, and 16% in RMSE, MAE,
and MAPE, respectively, while also substantially reducing communication costs.

</details>


### [17] [Improved Training Strategies for Physics-Informed Neural Networks using Real Experimental Data in Aluminum Spot Welding](https://arxiv.org/abs/2508.04595)
*Jan A. Zak,Christian Weißenfels*

Main category: cs.LG

TL;DR: 论文研究了基于物理信息的神经网络在铝点焊中的应用，通过两种新颖的训练策略解决了真实数据集成问题，实现了非破坏性质量评估。


<details>
  <summary>Details</summary>
Motivation: 点焊是汽车工业中主要的连接工艺，但焊点直径的测量需要破坏性测试，限制了质量控制效率。

Method: 采用渐进式损失函数和条件更新策略，结合二维轴对称模型，优化神经网络训练。

Result: 二维网络成功预测了动态位移和焊点生长，并在实验置信区间内验证了结果。

Conclusion: 该方法展示了在工业应用中快速、基于模型的质量控制的潜力。

Abstract: Resistance spot welding is the dominant joining process for the body-in-white
in the automotive industry, where the weld nugget diameter is the key quality
metric. Its measurement requires destructive testing, limiting the potential
for efficient quality control. Physics-informed neural networks were
investigated as a promising tool to reconstruct internal process states from
experimental data, enabling model-based and non-invasive quality assessment in
aluminum spot welding. A major challenge is the integration of real-world data
into the network due to competing optimization objectives. To address this, we
introduce two novel training strategies. First, experimental losses for dynamic
displacement and nugget diameter are progressively included using a fading-in
function to prevent excessive optimization conflicts. We also implement a
custom learning rate scheduler and early stopping based on a rolling window to
counteract premature reduction due to increased loss magnitudes. Second, we
introduce a conditional update of temperature-dependent material parameters via
a look-up table, activated only after a loss threshold is reached to ensure
physically meaningful temperatures. An axially symmetric two-dimensional model
was selected to represent the welding process accurately while maintaining
computational efficiency. To reduce computational burden, the training
strategies and model components were first systematically evaluated in one
dimension, enabling controlled analysis of loss design and contact models. The
two-dimensional network predicts dynamic displacement and nugget growth within
the experimental confidence interval, supports transferring welding stages from
steel to aluminum, and demonstrates strong potential for fast, model-based
quality control in industrial applications.

</details>


### [18] [Neuromorphic Cybersecurity with Semi-supervised Lifelong Learning](https://arxiv.org/abs/2508.04610)
*Md Zesun Ahmed Mia,Malyaban Bal,Sen Lu,George M. Nishibuchi,Suhas Chelian,Srini Vasan,Abhronil Sengupta*

Main category: cs.LG

TL;DR: 本文提出了一种基于脉冲神经网络（SNN）的分层架构，用于终身网络入侵检测系统（NIDS），通过静态和动态SNN结合生物启发机制实现高效学习和低功耗部署。


<details>
  <summary>Details</summary>
Motivation: 受大脑分层处理和能量效率的启发，旨在设计一种能够持续学习新威胁并保持低功耗的网络入侵检测系统。

Method: 采用静态SNN初步识别潜在入侵，动态SNN分类具体攻击类型，结合GWR结构可塑性和自适应STDP学习规则。

Result: 在UNSW-NB15基准测试中达到85.3%的整体准确率，并展示了低功耗部署潜力。

Conclusion: 该架构在持续学习环境中表现优异，具有实际部署的潜力。

Abstract: Inspired by the brain's hierarchical processing and energy efficiency, this
paper presents a Spiking Neural Network (SNN) architecture for lifelong Network
Intrusion Detection System (NIDS). The proposed system first employs an
efficient static SNN to identify potential intrusions, which then activates an
adaptive dynamic SNN responsible for classifying the specific attack type.
Mimicking biological adaptation, the dynamic classifier utilizes Grow When
Required (GWR)-inspired structural plasticity and a novel Adaptive
Spike-Timing-Dependent Plasticity (Ad-STDP) learning rule. These bio-plausible
mechanisms enable the network to learn new threats incrementally while
preserving existing knowledge. Tested on the UNSW-NB15 benchmark in a continual
learning setting, the architecture demonstrates robust adaptation, reduced
catastrophic forgetting, and achieves $85.3$\% overall accuracy. Furthermore,
simulations using the Intel Lava framework confirm high operational sparsity,
highlighting the potential for low-power deployment on neuromorphic hardware.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [Large Language Model's Multi-Capability Alignment in Biomedical Domain](https://arxiv.org/abs/2508.04278)
*Wentao Wu,Linqing Chen,Hanmeng Zhong,Weilei Wang*

Main category: cs.AI

TL;DR: BalancedBio是一个理论框架，通过正交梯度空间和多能力集成实现高效的生物医学推理，提升性能和安全部署。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学AI领域中多能力集成时的干扰问题，确保安全性和可靠性。

Method: 包括医学知识基础的合成生成（MKGSG）和能力感知的组相对策略优化，结合规则和模型评分。

Result: 在多个指标上显著优于基线，如领域专业知识（80.95%）、推理（61.94%）等，并降低成本78%。

Conclusion: 提供了一种高效的生物医学AI对齐方法，具有理论安全保证和实际部署优势。

Abstract: BalancedBio is a theoretically grounded framework for parameter-efficient
biomedical reasoning, addressing multi-capability integration in
domain-specific AI alignment. It establishes the Biomedical Multi-Capability
Convergence Theorem, proving orthogonal gradient spaces are essential to
prevent capability interference for safe deployment. Key innovations include:
(1) Medical Knowledge Grounded Synthetic Generation (MKGSG), extending
Source2Synth with clinical workflow constraints and medical ontology validation
for factual accuracy and safety; and (2) Capability Aware Group Relative Policy
Optimization, deriving optimal hybrid reward weighting to maintain
orthogonality in RL, using a reward model with rule-based and model-based
scores adapted to biomedical tasks. Mathematical analysis proves Pareto-optimal
convergence, preserving performance across capabilities. It achieves
state-of-the-art results in its parameter class: domain expertise (80.95%
BIOMED-MMLU, +15.32% over baseline), reasoning (61.94%, +7.75%), instruction
following (67.95%, +6.44%), and integration (86.7%, +18.5%). Theoretical safety
guarantees include bounds on capability preservation and clinical accuracy.
Real-world deployment yields 78% cost reduction, 23% improved diagnostic
accuracy, and 89% clinician acceptance. This work provides a principled
methodology for biomedical AI alignment, enabling efficient reasoning with
essential safety and reliability, with the 0.5B model version to be released.

</details>


### [20] [Argumentative Debates for Transparent Bias Detection [Technical Report]](https://arxiv.org/abs/2508.04511)
*Hamed Ayoobi,Nico Potyka,Anna Rapberger,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出了一种基于辩论的新型可解释、可解释的偏见检测方法，利用形式化和计算论证技术，强调透明度和解释性在算法公平性中的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在社会中的广泛应用，防止数据或模型中的偏见对特定群体造成系统性不利影响变得至关重要。现有方法多忽略透明度，而解释性和可解释性是算法公平性的核心需求。

Method: 提出了一种基于辩论的偏见检测方法，利用保护特征值和邻域内个体的值，通过形式化和计算论证技术进行辩论。

Result: 通过形式化、定量和定性评估，证明了该方法在性能、可解释性和可解释性方面的优势。

Conclusion: 该方法为算法公平性提供了一种透明且可解释的解决方案，强调了在偏见检测中透明度和解释性的重要性。

Abstract: As the use of AI systems in society grows, addressing potential biases that
emerge from data or are learned by models is essential to prevent systematic
disadvantages against specific groups. Several notions of (un)fairness have
been proposed in the literature, alongside corresponding algorithmic methods
for detecting and mitigating unfairness, but, with very few exceptions, these
tend to ignore transparency. Instead, interpretability and explainability are
core requirements for algorithmic fairness, even more so than for other
algorithmic solutions, given the human-oriented nature of fairness. In this
paper, we contribute a novel interpretable, explainable method for bias
detection relying on debates about the presence of bias against individuals,
based on the values of protected features for the individuals and others in
their neighbourhoods. Our method builds upon techniques from formal and
computational argumentation, whereby debates result from arguing about biases
within and across neighbourhoods. We provide formal, quantitative, and
qualitative evaluations of our method, highlighting its strengths in
performance against baselines, as well as its interpretability and
explainability.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion](https://arxiv.org/abs/2508.03712)
*Agrima Seth,Monojit Choudhary,Sunayana Sitaram,Kentaro Toyama,Aditya Vashistha,Kalika Bali*

Main category: cs.CL

TL;DR: 研究发现GPT-4 Turbo在生成印度生活事件故事时，宗教和种姓的多样性表现与人口普查数据不符，过度代表文化主导群体，且提示多样性效果有限。


<details>
  <summary>Details</summary>
Motivation: 扩展对大型语言模型（LLMs）中表征偏见的研究，探索其在宗教和种姓等较少被关注的维度上的表现。

Method: 通过设计多样化提示，生成7,200个关于印度重要生活事件的故事，并与印度人口普查数据对比，量化偏见。

Result: GPT-4 Turbo的输出过度代表文化主导群体，且提示多样性对纠正偏见效果有限。

Conclusion: 仅多样化训练数据可能不足以纠正LLM偏见，需更根本的模型开发变革。

Abstract: Representational bias in large language models (LLMs) has predominantly been
measured through single-response interactions and has focused on Global
North-centric identities like race and gender. We expand on that research by
conducting a systematic audit of GPT-4 Turbo to reveal how deeply encoded
representational biases are and how they extend to less-explored dimensions of
identity. We prompt GPT-4 Turbo to generate over 7,200 stories about
significant life events (such as weddings) in India, using prompts designed to
encourage diversity to varying extents. Comparing the diversity of religious
and caste representation in the outputs against the actual population
distribution in India as recorded in census data, we quantify the presence and
"stickiness" of representational bias in the LLM for religion and caste. We
find that GPT-4 responses consistently overrepresent culturally dominant groups
far beyond their statistical representation, despite prompts intended to
encourage representational diversity. Our findings also suggest that
representational bias in LLMs has a winner-take-all quality that is more biased
than the likely distribution bias in their training data, and repeated
prompt-based nudges have limited and inconsistent efficacy in dislodging these
biases. These results suggest that diversifying training data alone may not be
sufficient to correct LLM bias, highlighting the need for more fundamental
changes in model development. Dataset and Codebook:
https://github.com/agrimaseth/How-Deep-Is-Representational-Bias-in-LLMs

</details>


### [22] [Large Reasoning Models Are Autonomous Jailbreak Agents](https://arxiv.org/abs/2508.04039)
*Thilo Hagendorff,Erik Derner,Nuria Oliver*

Main category: cs.CL

TL;DR: 研究表明，大型推理模型（LRMs）可以简化并规模化越狱（jailbreaking）行为，使其成为非专家也能进行的低成本活动。实验显示，四种LRM模型在攻击九种目标模型时，总体成功率高达97.14%。


<details>
  <summary>Details</summary>
Motivation: 传统越狱方法需要复杂技术或专业知识，而LRMs的推理能力可能使其成为高效的越狱工具。

Method: 使用四种LRM模型，通过系统提示指导其自主进行多轮对话攻击九种目标模型，测试70个有害提示的越狱效果。

Result: 实验结果显示，所有模型组合的总体攻击成功率为97.14%，表明LRMs能系统性削弱其他模型的安全防护。

Conclusion: 研究揭示了前沿模型需要进一步对齐，不仅要抵抗越狱攻击，还需防止自身被利用为越狱工具。

Abstract: Jailbreaking -- bypassing built-in safety mechanisms in AI models -- has
traditionally required complex technical procedures or specialized human
expertise. In this study, we show that the persuasive capabilities of large
reasoning models (LRMs) simplify and scale jailbreaking, converting it into an
inexpensive activity accessible to non-experts. We evaluated the capabilities
of four LRMs (DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B) to act as
autonomous adversaries conducting multi-turn conversations with nine widely
used target models. LRMs received instructions via a system prompt, before
proceeding to planning and executing jailbreaks with no further supervision. We
performed extensive experiments with a benchmark of harmful prompts composed of
70 items covering seven sensitive domains. This setup yielded an overall attack
success rate across all model combinations of 97.14%. Our study reveals an
alignment regression, in which LRMs can systematically erode the safety
guardrails of other models, highlighting the urgent need to further align
frontier models not only to resist jailbreak attempts, but also to prevent them
from being co-opted into acting as jailbreak agents.

</details>


### [23] [Characterizing Deep Research: A Benchmark and Formal Definition](https://arxiv.org/abs/2508.04183)
*Abhinav Java,Ashmit Khandelwal,Sukruta Midigeshi,Aaron Halfaker,Amit Deshpande,Navin Goyal,Ankur Gupta,Nagarajan Natarajan,Amit Sharma*

Main category: cs.CL

TL;DR: 论文提出了对“深度研究”（DR）任务的正式定义，并引入了一个基准测试（LiveDRBench）来评估DR系统的性能。核心特点是概念的高覆盖和推理密集型探索，而非长篇报告的输出。OpenAI的模型表现最佳（F1=0.55）。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究的任务范围定义不清，与其他推理密集型问题的区别不明确，需要一种客观的评价方法。

Method: 通过中间输出表示定义DR任务，分离推理挑战与报告生成，并构建包含100个任务的基准测试。

Result: 现有DR系统的F1分数在0.02到0.72之间，OpenAI模型表现最佳（F1=0.55）。分析揭示了搜索机制和基础能力的改进方向。

Conclusion: 论文为DR任务提供了清晰定义和评估基准，揭示了当前系统的局限性，并指出了未来改进方向。

Abstract: Information tasks such as writing surveys or analytical reports require
complex search and reasoning, and have recently been grouped under the umbrella
of \textit{deep research} -- a term also adopted by recent models targeting
these capabilities. Despite growing interest, the scope of the deep research
task remains underdefined and its distinction from other reasoning-intensive
problems is poorly understood. In this paper, we propose a formal
characterization of the deep research (DR) task and introduce a benchmark to
evaluate the performance of DR systems. We argue that the core defining feature
of deep research is not the production of lengthy report-style outputs, but
rather the high fan-out over concepts required during the search process, i.e.,
broad and reasoning-intensive exploration. To enable objective evaluation, we
define DR using an intermediate output representation that encodes key claims
uncovered during search-separating the reasoning challenge from surface-level
report generation. Based on this formulation, we propose a diverse, challenging
benchmark LiveDRBench with 100 challenging tasks over scientific topics (e.g.,
datasets, materials discovery, prior art search) and public interest events
(e.g., flight incidents, movie awards). Across state-of-the-art DR systems, F1
score ranges between 0.02 and 0.72 for any sub-category. OpenAI's model
performs the best with an overall F1 score of 0.55. Analysis of reasoning
traces reveals the distribution over the number of referenced sources,
branching, and backtracking events executed by current DR systems, motivating
future directions for improving their search mechanisms and grounding
capabilities. The benchmark is available at
https://github.com/microsoft/LiveDRBench.

</details>


### [24] [DP-GPT4MTS: Dual-Prompt Large Language Model for Textual-Numerical Time Series Forecasting](https://arxiv.org/abs/2508.04239)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.CL

TL;DR: DP-GPT4MTS是一种双提示大型语言模型框架，结合显式和文本提示，显著提升时间序列预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测模型忽视文本信息，影响准确性。现有单提示框架难以有效处理时间戳文本语义。

Method: 提出DP-GPT4MTS，结合显式提示和文本提示，通过自注意力和前馈网络优化嵌入。

Result: 在多样化文本-数值时间序列数据集上表现优于现有算法。

Conclusion: 双提示机制通过整合文本上下文，显著提升预测准确性。

Abstract: Time series forecasting is crucial in strategic planning and decision-making
across various industries. Traditional forecasting models mainly concentrate on
numerical time series data, often overlooking important textual information
such as events and news, which can significantly affect forecasting accuracy.
While large language models offer a promise for integrating multimodal data,
existing single-prompt frameworks struggle to effectively capture the semantics
of timestamped text, introducing redundant information that can hinder model
performance. To address this limitation, we introduce DP-GPT4MTS (Dual-Prompt
GPT2-base for Multimodal Time Series), a novel dual-prompt large language model
framework that combines two complementary prompts: an explicit prompt for clear
task instructions and a textual prompt for context-aware embeddings from
time-stamped data. The tokenizer generates the explicit prompt while the
embeddings from the textual prompt are refined through self-attention and
feed-forward networks. Comprehensive experiments conducted on diverse
textural-numerical time series datasets demonstrate that this approach
outperforms state-of-the-art algorithms in time series forecasting. This
highlights the significance of incorporating textual context via a dual-prompt
mechanism to achieve more accurate time series predictions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [25] [RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case](https://arxiv.org/abs/2508.04642)
*Baihui Xiao,Chengjian Feng,Zhijian Huang,Feng yan,Yujie Zhong,Lin Ma*

Main category: cs.RO

TL;DR: RoboTron-Sim通过模拟高风险场景提升自动驾驶系统在复杂情况下的性能，利用HASS数据集和SPE、I2E Encoder技术，实验显示性能提升50%。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中罕见高风险场景数据不足导致自动驾驶系统性能不佳的问题。

Method: 开发HASS模拟数据集，引入SPE和I2E Encoder技术，利用多模态大语言模型学习驾驶技能。

Result: 在nuScenes数据集上性能提升约50%，在开放环路规划中达到最先进水平。

Conclusion: RoboTron-Sim能有效管理罕见高风险驾驶场景，提升自动驾驶系统性能。

Abstract: Collecting real-world data for rare high-risk scenarios, long-tailed driving
events, and complex interactions remains challenging, leading to poor
performance of existing autonomous driving systems in these critical
situations. In this paper, we propose RoboTron-Sim that improves real-world
driving in critical situations by utilizing simulated hard cases. First, we
develop a simulated dataset called Hard-case Augmented Synthetic Scenarios
(HASS), which covers 13 high-risk edge-case categories, as well as balanced
environmental conditions such as day/night and sunny/rainy. Second, we
introduce Scenario-aware Prompt Engineering (SPE) and an Image-to-Ego Encoder
(I2E Encoder) to enable multimodal large language models to effectively learn
real-world challenging driving skills from HASS, via adapting to environmental
deviations and hardware differences between real-world and simulated scenarios.
Extensive experiments on nuScenes show that RoboTron-Sim improves driving
performance in challenging scenarios by around 50%, achieving state-of-the-art
results in real-world open-loop planning. Qualitative results further
demonstrate the effectiveness of RoboTron-Sim in better managing rare high-risk
driving scenarios. Project page: https://stars79689.github.io/RoboTron-Sim/

</details>
