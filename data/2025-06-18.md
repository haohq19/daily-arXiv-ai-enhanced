<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Hidden Bias in the Machine: Stereotypes in Text-to-Image Models](https://arxiv.org/abs/2506.13780)
*Sedat Porikli,Vedat Porikli*

Main category: cs.CV

TL;DR: 研究探讨了文本到图像（T2I）模型如何放大社会偏见，通过生成和分析16,000多张图像，发现其在性别、种族等方面的显著差异。


<details>
  <summary>Details</summary>
Motivation: T2I模型在视觉内容创作中表现出色，但可能复制和放大社会偏见，因此需要研究其潜在影响。

Method: 使用Stable Diffusion 1.5和Flux-1模型生成16,000多张图像，并结合Google Image Search的8,000张对比图像，分析其偏见表现。

Result: 生成图像中性别、种族、年龄等人类特征存在显著差异，反映了社会中的有害刻板印象。

Conclusion: 研究强调需要更包容的数据集和开发实践，以促进生成视觉系统的公平性。

Abstract: Text-to-Image (T2I) models have transformed visual content creation, producing highly realistic images from natural language prompts. However, concerns persist around their potential to replicate and magnify existing societal biases. To investigate these issues, we curated a diverse set of prompts spanning thematic categories such as occupations, traits, actions, ideologies, emotions, family roles, place descriptions, spirituality, and life events. For each of the 160 unique topics, we crafted multiple prompt variations to reflect a wide range of meanings and perspectives. Using Stable Diffusion 1.5 (UNet-based) and Flux-1 (DiT-based) models with original checkpoints, we generated over 16,000 images under consistent settings. Additionally, we collected 8,000 comparison images from Google Image Search. All outputs were filtered to exclude abstract, distorted, or nonsensical results. Our analysis reveals significant disparities in the representation of gender, race, age, somatotype, and other human-centric factors across generated images. These disparities often mirror and reinforce harmful stereotypes embedded in societal narratives. We discuss the implications of these findings and emphasize the need for more inclusive datasets and development practices to foster fairness in generative visual systems.

</details>


### [2] [Intelligent Image Sensing for Crime Analysis: A ML Approach towards Enhanced Violence Detection and Investigation](https://arxiv.org/abs/2506.13910)
*Aritra Dutta,Pushpita Boral,G Suseela*

Main category: cs.CV

TL;DR: 本文提出了一种基于机器学习的暴力检测与分类框架，利用3D卷积神经网络和双向LSTM，显著提升了计算资源效率和检测准确性。


<details>
  <summary>Details</summary>
Motivation: 全球犯罪率上升及传统监控方法的局限性，促使开发自动暴力检测系统以应对多样化和突发性暴力行为。

Method: 采用监督学习进行二元和多类暴力分类，结合3D卷积神经网络进行检测，使用可分离卷积3D模型和双向LSTM进行特征提取与时间序列处理。

Result: 在多样化数据集上训练，结合实时视频流处理，展示了计算资源效率和准确性的提升。

Conclusion: 该框架为自动暴力检测提供了高效且准确的解决方案，适用于实际监控场景。

Abstract: The increasing global crime rate, coupled with substantial human and property losses, highlights the limitations of traditional surveillance methods in promptly detecting diverse and unexpected acts of violence. Addressing this pressing need for automatic violence detection, we leverage Machine Learning to detect and categorize violent events in video streams. This paper introduces a comprehensive framework for violence detection and classification, employing Supervised Learning for both binary and multi-class violence classification. The detection model relies on 3D Convolutional Neural Networks, while the classification model utilizes the separable convolutional 3D model for feature extraction and bidirectional LSTM for temporal processing. Training is conducted on a diverse customized datasets with frame-level annotations, incorporating videos from surveillance cameras, human recordings, hockey fight, sohas and wvd dataset across various platforms. Additionally, a camera module integrated with raspberry pi is used to capture live video feed, which is sent to the ML model for processing. Thus, demonstrating improved performance in terms of computational resource efficiency and accuracy.

</details>


### [3] [HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment](https://arxiv.org/abs/2506.13925)
*Numair Nadeem,Saeed Anwar,Muhammad Hamza Asad,Abdul Bais*

Main category: cs.CV

TL;DR: HierVL是一种结合视觉语言模型的半监督语义分割框架，通过多尺度查询和跨模态对齐提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决标签稀缺和领域变化下视觉方法泛化能力不足的问题，利用视觉语言模型的语义鲁棒性。

Method: 提出HierVL框架，包括分层语义查询生成器、跨模态空间对齐模块和双查询Transformer解码器。

Result: 在多个基准数据集上性能显著提升，如COCO（+4.4% mIoU）、Pascal VOC（+3.1% mIoU）等。

Conclusion: 语言引导的分割方法显著提升了标签效率和细粒度实例感知能力。

Abstract: Semi-supervised semantic segmentation remains challenging under severe label scarcity and domain variability. Vision-only methods often struggle to generalize, resulting in pixel misclassification between similar classes, poor generalization and boundary localization. Vision-Language Models offer robust, domain-invariant semantics but lack the spatial grounding required for dense prediction. We introduce HierVL, a unified framework that bridges this gap by integrating abstract text embeddings into a mask-transformer architecture tailored for semi-supervised segmentation. HierVL features three novel components: a Hierarchical Semantic Query Generator that filters and projects abstract class embeddings into multi-scale queries to suppress irrelevant classes and handle intra-class variability; a Cross-Modal Spatial Alignment Module that aligns semantic queries with pixel features for sharper boundaries under sparse supervision; and a Dual-Query Transformer Decoder that fuses semantic and instance-level queries to prevent instance collapse. We also introduce targeted regularization losses that maintain vision-language alignment throughout training to reinforce semantic grounding. HierVL establishes a new state-of-the-art by achieving a +4.4% mean improvement of the intersection over the union on COCO (with 232 labeled images), +3.1% on Pascal VOC (with 92 labels), +5.9% on ADE20 (with 158 labels) and +1.8% on Cityscapes (with 100 labels), demonstrating better performance under 1% supervision on four benchmark datasets. Our results show that language-guided segmentation closes the label efficiency gap and unlocks new levels of fine-grained, instance-aware generalization.

</details>


### [4] [VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning](https://arxiv.org/abs/2506.14629)
*Md. Adnanul Islam,Md. Faiyaz Abdullah Sayeedi,Md. Asaduzzaman Shuvo,Muhammad Ziaur Rahman,Shahanur Rahman Bappy,Raiyan Rahman,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: VisText-Mosquito是一个多模态数据集，结合视觉和文本数据，用于蚊虫滋生地的自动化检测、分割和推理分析。


<details>
  <summary>Details</summary>
Motivation: 蚊媒疾病是全球重大健康威胁，需早期检测和主动控制滋生地以预防疫情。

Method: 数据集包含1,828张标注图像用于目标检测，142张用于水面分割，以及每张图像关联的自然语言推理文本。使用YOLOv9s和YOLOv11n-Seg模型进行检测和分割，BLIP模型进行推理生成。

Result: YOLOv9s在目标检测中达到最高精度0.92926，mAP@50为0.92891；YOLOv11n-Seg分割精度为0.91587，mAP@50为0.79795。BLIP模型的推理生成表现优异（BLEU 54.7，BERTScore 0.91，ROUGE-L 0.87）。

Conclusion: 该数据集和模型框架强调“预防胜于治疗”，展示了AI如何主动应对蚊媒疾病风险。数据集和代码已开源。

Abstract: Mosquito-borne diseases pose a major global health risk, requiring early detection and proactive control of breeding sites to prevent outbreaks. In this paper, we present VisText-Mosquito, a multimodal dataset that integrates visual and textual data to support automated detection, segmentation, and reasoning for mosquito breeding site analysis. The dataset includes 1,828 annotated images for object detection, 142 images for water surface segmentation, and natural language reasoning texts linked to each image. The YOLOv9s model achieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object detection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and mAP@50 of 0.79795. For reasoning generation, our fine-tuned BLIP model achieves a final loss of 0.0028, with a BLEU score of 54.7, BERTScore of 0.91, and ROUGE-L of 0.87. This dataset and model framework emphasize the theme "Prevention is Better than Cure", showcasing how AI-based detection can proactively address mosquito-borne disease risks. The dataset and implementation code are publicly available at GitHub: https://github.com/adnanul-islam-jisun/VisText-Mosquito

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks](https://arxiv.org/abs/2506.14472)
*Fabien Bernier,Maxime Cordy,Yves Le Traon*

Main category: cs.LG

TL;DR: 本文提出了一种超网络架构，通过结合外部因素（如天气指标）来提升全球电力消耗预测模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的时间序列预测方法依赖于历史模式和时序依赖性，但结合外部因素可以显著提高复杂实际应用中的预测准确性。然而，这些额外特征往往会降低全局模型的性能。

Method: 采用超网络架构，通过为每个消费者调整模型权重，有效利用外部因素提升预测准确性。

Result: 实验表明，超网络方法在结合外部因素时优于现有方法，减少了预测误差并保持了全局模型的优势。

Conclusion: 超网络架构能够有效提升全球电力消耗预测的准确性，同时利用外部因素。

Abstract: Accurate electrical consumption forecasting is crucial for efficient energy management and resource allocation. While traditional time series forecasting relies on historical patterns and temporal dependencies, incorporating external factors -- such as weather indicators -- has shown significant potential for improving prediction accuracy in complex real-world applications. However, the inclusion of these additional features often degrades the performance of global predictive models trained on entire populations, despite improving individual household-level models. To address this challenge, we found that a hypernetwork architecture can effectively leverage external factors to enhance the accuracy of global electrical consumption forecasting models, by specifically adjusting the model weights to each consumer.
  We collected a comprehensive dataset spanning two years, comprising consumption data from over 6000 luxembourgish households and corresponding external factors such as weather indicators, holidays, and major local events. By comparing various forecasting models, we demonstrate that a hypernetwork approach outperforms existing methods when associated to external factors, reducing forecasting errors and achieving the best accuracy while maintaining the benefits of a global model.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [ImpReSS: Implicit Recommender System for Support Conversations](https://arxiv.org/abs/2506.14231)
*Omri Haller,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

Main category: cs.AI

TL;DR: ImpReSS是一个隐式推荐系统，用于在客户支持对话中推荐相关解决方案产品类别（SPCs），无需用户明确购买意图。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探讨在客户支持交互中隐式集成推荐功能，ImpReSS旨在填补这一空白。

Method: ImpReSS与现有支持聊天机器人协同工作，分析对话内容并识别推荐SPCs的机会。

Result: 实验结果显示，ImpReSS在推荐相关SPCs方面表现优异，MRR@1和recall@3指标在不同场景中均较高。

Conclusion: ImpReSS为隐式推荐系统提供了有效解决方案，支持业务增长并促进未来研究。

Abstract: Following recent advancements in large language models (LLMs), LLM-based chatbots have transformed customer support by automating interactions and providing consistent, scalable service. While LLM-based conversational recommender systems (CRSs) have attracted attention for their ability to enhance the quality of recommendations, limited research has addressed the implicit integration of recommendations within customer support interactions. In this work, we introduce ImpReSS, an implicit recommender system designed for customer support conversations. ImpReSS operates alongside existing support chatbots, where users report issues and chatbots provide solutions. Based on a customer support conversation, ImpReSS identifies opportunities to recommend relevant solution product categories (SPCs) that help resolve the issue or prevent its recurrence -- thereby also supporting business growth. Unlike traditional CRSs, ImpReSS functions entirely implicitly and does not rely on any assumption of a user's purchasing intent. Our empirical evaluation of ImpReSS's ability to recommend relevant SPCs that can help address issues raised in support conversations shows promising results, including an MRR@1 (and recall@3) of 0.72 (0.89) for general problem solving, 0.82 (0.83) for information security support, and 0.85 (0.67) for cybersecurity troubleshooting. To support future research, our data and code will be shared upon request.

</details>


### [7] [Doppelgänger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack](https://arxiv.org/abs/2506.14539)
*Daewon Kang,YeongHwan Shin,Doyeon Kim,Kyu-Hwan Jung,Meong Hi Son*

Main category: cs.AI

TL;DR: 论文提出了一种名为“Doppelgänger”的方法，揭示了代理被劫持的风险，并定义了“PACAT”级别评估其脆弱性，同时提出“CAT”提示作为防御手段。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，提示工程的便捷性引发了安全性和一致性的担忧，需要防止提示被用户暴露或劫持。

Method: 提出“Doppelgänger”方法展示代理劫持风险，定义“PACAT”级别评估脆弱性，并设计“CAT”提示作为防御措施。

Result: 实验表明“Doppelgänger”方法能破坏代理一致性并暴露内部信息，而“CAT”提示能有效防御此类攻击。

Conclusion: 论文揭示了提示工程的安全风险，并提出了一种有效的防御方法，为未来研究提供了方向。

Abstract: Since the advent of large language models, prompt engineering now enables the rapid, low-effort creation of diverse autonomous agents that are already in widespread use. Yet this convenience raises urgent concerns about the safety, robustness, and behavioral consistency of the underlying prompts, along with the pressing challenge of preventing those prompts from being exposed to user's attempts. In this paper, we propose the ''Doppelgänger method'' to demonstrate the risk of an agent being hijacked, thereby exposing system instructions and internal information. Next, we define the ''Prompt Alignment Collapse under Adversarial Transfer (PACAT)'' level to evaluate the vulnerability to this adversarial transfer attack. We also propose a ''Caution for Adversarial Transfer (CAT)'' prompt to counter the Doppelgänger method. The experimental results demonstrate that the Doppelgänger method can compromise the agent's consistency and expose its internal information. In contrast, CAT prompts enable effective defense against this adversarial attack.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [8] [Sampling from Your Language Model One Byte at a Time](https://arxiv.org/abs/2506.14123)
*Jonathan Hayase,Alisa Liu,Noah A. Smith,Sewoong Oh*

Main category: cs.CL

TL;DR: 本文提出了一种推理时方法，将任何使用BPE分词器的自回归语言模型转换为字符级或字节级模型，解决了分词器带来的Prompt Boundary Problem（PBP）和模型兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型普遍使用分词器，但分词器可能导致生成文本的失真（如PBP问题）和模型间的不兼容性（如不同分词器无法直接集成）。

Method: 提出一种推理时方法，将BPE分词器的自回归模型转换为字符级或字节级模型，保持文本生成分布不变。

Result: 实验表明，通过该方法集成的模型和代理调优模型在下游任务中表现优于原始模型。

Conclusion: 该方法有效解决了PBP问题，并实现了不同分词器模型的兼容性和集成能力。

Abstract: Tokenization is used almost universally by modern language models, enabling efficient text representation using multi-byte or multi-character tokens. However, prior work has shown that tokenization can introduce distortion into the model's generations. For example, users are often advised not to end their prompts with a space because it prevents the model from including the space as part of the next token. This Prompt Boundary Problem (PBP) also arises in languages such as Chinese and in code generation, where tokens often do not line up with syntactic boundaries. Additionally mismatching tokenizers often hinder model composition and interoperability. For example, it is not possible to directly ensemble models with different tokenizers due to their mismatching vocabularies. To address these issues, we present an inference-time method to convert any autoregressive LM with a BPE tokenizer into a character-level or byte-level LM, without changing its generative distribution at the text level. Our method efficient solves the PBP and is also able to unify the vocabularies of language models with different tokenizers, allowing one to ensemble LMs with different tokenizers at inference time as well as transfer the post-training from one model to another using proxy-tuning. We demonstrate in experiments that the ensemble and proxy-tuned models outperform their constituents on downstream evals.

</details>


### [9] [Chaining Event Spans for Temporal Relation Grounding](https://arxiv.org/abs/2506.14213)
*Jongho Kim,Dohyeon Lee,Minsoo Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: 论文提出了一种基于时间线推理网络（TRN）的新方法，通过预测事件的时间跨度来解决现有方法因答案重叠导致的不可靠问题。


<details>
  <summary>Details</summary>
Motivation: 准确理解事件间的时间关系是多项任务（如时间阅读理解TRC和时间关系提取TRE）的关键。现有方法依赖答案重叠作为标签，但可能因偶然相同的答案导致不可靠结果。

Method: 提出TRN，采用两步归纳推理：首先生成每个问题的初步答案，然后通过链接多个问题预测时间线，并基于时间线修正答案。

Result: 在TORQUE和TB-dense等任务上，TRN优于现有方法，有效解决了答案重叠问题。

Conclusion: TRN通过时间线推理显著提升了时间关系理解的准确性，为相关任务提供了更可靠的解决方案。

Abstract: Accurately understanding temporal relations between events is a critical building block of diverse tasks, such as temporal reading comprehension (TRC) and relation extraction (TRE). For example in TRC, we need to understand the temporal semantic differences between the following two questions that are lexically near-identical: "What finished right before the decision?" or "What finished right after the decision?". To discern the two questions, existing solutions have relied on answer overlaps as a proxy label to contrast similar and dissimilar questions. However, we claim that answer overlap can lead to unreliable results, due to spurious overlaps of two dissimilar questions with coincidentally identical answers. To address the issue, we propose a novel approach that elicits proper reasoning behaviors through a module for predicting time spans of events. We introduce the Timeline Reasoning Network (TRN) operating in a two-step inductive reasoning process: In the first step model initially answers each question with semantic and syntactic information. The next step chains multiple questions on the same event to predict a timeline, which is then used to ground the answers. Results on the TORQUE and TB-dense, TRC and TRE tasks respectively, demonstrate that TRN outperforms previous methods by effectively resolving the spurious overlaps using the predicted timeline.

</details>


### [10] [A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs](https://arxiv.org/abs/2506.14235)
*Yimin Deng,Yuxia Wu,Yejing Wang,Guoshuai Zhao,Li Zhu,Qidong Liu,Derong Xu,Zichuan Fu,Xian Wu,Yefeng Zheng,Xiangyu Zhao,Xueming Qian*

Main category: cs.CL

TL;DR: 提出了一种多专家结构-语义混合框架（MESH），用于整合结构和语义信息，以处理不同预测场景下的时间知识图谱推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能整合结构和语义推理的双重视角，且无法区分历史与非历史事件的差异，限制了其泛化能力。

Method: 采用三种专家模块，结合结构和语义信息，指导不同事件的推理过程。

Result: 在三个数据集上的实验验证了方法的有效性。

Conclusion: MESH框架通过整合结构和语义信息，显著提升了时间知识图谱推理的性能。

Abstract: Temporal knowledge graph reasoning aims to predict future events with knowledge of existing facts and plays a key role in various downstream tasks. Previous methods focused on either graph structure learning or semantic reasoning, failing to integrate dual reasoning perspectives to handle different prediction scenarios. Moreover, they lack the capability to capture the inherent differences between historical and non-historical events, which limits their generalization across different temporal contexts. To this end, we propose a Multi-Expert Structural-Semantic Hybrid (MESH) framework that employs three kinds of expert modules to integrate both structural and semantic information, guiding the reasoning process for different events. Extensive experiments on three datasets demonstrate the effectiveness of our approach.

</details>


### [11] [From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents](https://arxiv.org/abs/2506.14285)
*Seongbo Jang,Minjin Jeon,Jaehoon Lee,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: 本文提出了一项新任务——及时对话响应生成，并引入了TimelyChat基准，用于评估语言模型在预测时间间隔和生成时间条件响应方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有对话响应生成研究主要关注基于文本上下文的连贯响应，而忽略了基于时间上下文的响应时机问题。

Method: 利用时间常识知识图谱的无标签事件知识，通过大语言模型（LLM）合成55K事件驱动对话，训练了一个名为Timer的对话代理。

Result: 实验结果表明，Timer在轮次和对话级别的评估中均优于基于提示的LLM和其他微调基线。

Conclusion: 本文填补了对话响应生成中时间上下文研究的空白，并公开了数据、模型和代码。

Abstract: While research on dialogue response generation has primarily focused on generating coherent responses conditioning on textual context, the critical question of when to respond grounded on the temporal context remains underexplored. To bridge this gap, we propose a novel task called timely dialogue response generation and introduce the TimelyChat benchmark, which evaluates the capabilities of language models to predict appropriate time intervals and generate time-conditioned responses. Additionally, we construct a large-scale training dataset by leveraging unlabeled event knowledge from a temporal commonsense knowledge graph and employing a large language model (LLM) to synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent designed to proactively predict time intervals and generate timely responses that align with those intervals. Experimental results show that Timer outperforms prompting-based LLMs and other fine-tuned baselines in both turn-level and dialogue-level evaluations. We publicly release our data, model, and code.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [12] [Quadrotor Morpho-Transition: Learning vs Model-Based Control Strategies](https://arxiv.org/abs/2506.14039)
*Ioannis Mandralis,Richard M. Murray,Morteza Gharib*

Main category: cs.RO

TL;DR: 论文研究了四旋翼飞行器在空中变形（Morpho-Transition）时的控制问题，通过强化学习（RL）训练控制器，并成功在硬件上实现。


<details>
  <summary>Details</summary>
Motivation: 四旋翼飞行器在空中变形时涉及复杂的气动相互作用和接近执行器饱和的操作，传统模型控制方法因未建模动态和接触规划限制而效果有限。

Method: 采用端到端强化学习（RL）训练控制器，并考虑电机动态和观测延迟以实现硬件迁移。

Result: RL控制器实现了敏捷着陆，但需考虑电机动态和延迟才能迁移到硬件；基线MPC控制器无需额外信息即可迁移，但对未知执行器故障的恢复能力较弱。

Conclusion: 研究为需要空中变形的敏捷四旋翼飞行器控制提供了更鲁棒的方法。

Abstract: Quadrotor Morpho-Transition, or the act of transitioning from air to ground through mid-air transformation, involves complex aerodynamic interactions and a need to operate near actuator saturation, complicating controller design. In recent work, morpho-transition has been studied from a model-based control perspective, but these approaches remain limited due to unmodeled dynamics and the requirement for planning through contacts. Here, we train an end-to-end Reinforcement Learning (RL) controller to learn a morpho-transition policy and demonstrate successful transfer to hardware. We find that the RL control policy achieves agile landing, but only transfers to hardware if motor dynamics and observation delays are taken into account. On the other hand, a baseline MPC controller transfers out-of-the-box without knowledge of the actuator dynamics and delays, at the cost of reduced recovery from disturbances in the event of unknown actuator failures. Our work opens the way for more robust control of agile in-flight quadrotor maneuvers that require mid-air transformation.

</details>
