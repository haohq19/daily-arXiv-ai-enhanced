<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Uncertainty-Aware 4D Gaussian Splatting for Monocular Occluded Human Rendering](https://arxiv.org/abs/2602.06343)
*Weiquan Wang,Feifei Shao,Lin Li,Zhen Wang,Jun Xiao,Long Chen*

Main category: cs.CV

TL;DR: U-4DGS：一种用于单目视频中动态人体渲染的新框架，通过概率变形网络和双重光栅化处理遮挡问题，利用不确定性映射自适应调节梯度，提高渲染保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理遮挡时存在严重问题：基于生成模型的方法会产生时间闪烁，而基于刚性几何启发式的方法无法捕捉多样外观。需要一种能自适应处理不可靠观测的解决方案。

Method: 将任务重新表述为异方差观测噪声下的最大后验估计问题。提出U-4DGS框架，包含概率变形网络和双重光栅化流水线，生成像素对齐的不确定性映射作为自适应梯度调节器。还引入置信感知正则化，防止缺乏可靠视觉线索区域的几何漂移。

Result: 在ZJU-MoCap和OcMotion数据集上的大量实验表明，U-4DGS在渲染保真度和鲁棒性方面达到了最先进水平。

Conclusion: U-4DGS通过概率建模和自适应不确定性处理，有效解决了动态人体渲染中的遮挡问题，实现了高质量且鲁棒的渲染效果。

Abstract: High-fidelity rendering of dynamic humans from monocular videos typically degrades catastrophically under occlusions. Existing solutions incorporate external priors-either hallucinating missing content via generative models, which induces severe temporal flickering, or imposing rigid geometric heuristics that fail to capture diverse appearances. To this end, we reformulate the task as a Maximum A Posteriori estimation problem under heteroscedastic observation noise. In this paper, we propose U-4DGS, a framework integrating a Probabilistic Deformation Network and a Double Rasterization pipeline. This architecture renders pixel-aligned uncertainty maps that act as an adaptive gradient modulator, automatically attenuating artifacts from unreliable observations. Furthermore, to prevent geometric drift in regions lacking reliable visual cues, we enforce Confidence-Aware Regularizations, which leverage the learned uncertainty to selectively propagate spatial-temporal validity. Extensive experiments on ZJU-MoCap and OcMotion demonstrate that U-4DGS achieves SOTA rendering fidelity and robustness.

</details>


### [2] [FlowConsist: Make Your Flow Consistent with Real Trajectory](https://arxiv.org/abs/2602.06346)
*Tianyi Zhang,Chengcheng Liu,Jinwei Chen,Chun-Le Guo,Chongyi Li,Ming-Ming Cheng,Bo Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: FlowConsist：通过使用模型自身预测的边际速度替代条件速度，并引入轨迹校正策略，解决快速流模型中的轨迹漂移和误差累积问题，在ImageNet 256×256上仅用1步采样达到FID 1.52的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 当前快速流模型训练存在两个根本问题：1）随机配对噪声-数据样本构建的条件速度引入系统性轨迹漂移，阻碍模型遵循一致的ODE路径；2）模型近似误差随时间步累积，导致长时区间严重偏差。

Method: 提出FlowConsist训练框架：1）用模型自身预测的边际速度替代条件速度，使优化与真实轨迹对齐；2）引入轨迹校正策略，在轨迹的每个时间步对齐生成样本和真实样本的边际分布。

Result: 在ImageNet 256×256上达到最先进水平，仅用1步采样获得FID 1.52。

Conclusion: FlowConsist通过解决轨迹一致性和误差累积问题，显著提升了快速流模型的性能，实现了高效的一步生成。

Abstract: Fast flow models accelerate the iterative sampling process by learning to directly predict ODE path integrals, enabling one-step or few-step generation. However, we argue that current fast-flow training paradigms suffer from two fundamental issues. First, conditional velocities constructed from randomly paired noise-data samples introduce systematic trajectory drift, preventing models from following a consistent ODE path. Second, the model's approximation errors accumulate over time steps, leading to severe deviations across long time intervals. To address these issues, we propose FlowConsist, a training framework designed to enforce trajectory consistency in fast flows. We propose a principled alternative that replaces conditional velocities with the marginal velocities predicted by the model itself, aligning optimization with the true trajectory. To further address error accumulation over time steps, we introduce a trajectory rectification strategy that aligns the marginal distributions of generated and real samples at every time step along the trajectory. Our method establishes a new state-of-the-art on ImageNet 256$\times$256, achieving an FID of 1.52 with only 1 sampling step.

</details>


### [3] [A neuromorphic model of the insect visual system for natural image processing](https://arxiv.org/abs/2602.06405)
*Adam D. Hines,Karin Nordström,Andrew B. Barron*

Main category: cs.CV

TL;DR: 提出了一种受昆虫视觉启发的生物启发视觉模型，通过完全自监督对比学习生成稀疏、判别性编码，在花朵识别和自然图像基准测试中表现优异，并实现了人工神经网络和脉冲神经网络两种实现。


<details>
  <summary>Details</summary>
Motivation: 当前许多视觉模型过于关注任务性能而忽视了生物真实的处理通路。昆虫视觉支持复杂行为但现有模型缺乏生物基础。需要开发既能捕捉昆虫视觉系统原理，又能生成稀疏判别性编码的生物启发模型。

Method: 开发了受昆虫视觉启发的生物启发视觉模型，采用完全自监督对比学习目标进行训练，无需标注数据。模型将密集视觉输入转换为稀疏、判别性编码，支持跨任务重用。实现了人工神经网络和脉冲神经网络两种版本。

Result: 模型在花朵识别任务和自然图像基准测试中生成可靠的稀疏编码，能区分视觉相似的输入。在模拟定位设置中，优于简单的图像下采样基线，展示了神经形态视觉处理通路的功能优势。

Conclusion: 该研究推进了昆虫计算建模，提供了一个通用的生物启发视觉模型，能够在多样化任务中实现稀疏计算，为理解生物视觉处理和开发高效视觉系统提供了新途径。

Abstract: Insect vision supports complex behaviors including associative learning, navigation, and object detection, and has long motivated computational models for understanding biological visual processing. However, many contemporary models prioritize task performance while neglecting biologically grounded processing pathways. Here, we introduce a bio-inspired vision model that captures principles of the insect visual system to transform dense visual input into sparse, discriminative codes. The model is trained using a fully self-supervised contrastive objective, enabling representation learning without labeled data and supporting reuse across tasks without reliance on domain-specific classifiers. We evaluated the resulting representations on flower recognition tasks and natural image benchmarks. The model consistently produced reliable sparse codes that distinguish visually similar inputs. To support different modelling and deployment uses, we have implemented the model as both an artificial neural network and a spiking neural network. In a simulated localization setting, our approach outperformed a simple image downsampling comparison baseline, highlighting the functional benefit of incorporating neuromorphic visual processing pathways. Collectively, these results advance insect computational modelling by providing a generalizable bio-inspired vision model capable of sparse computation across diverse tasks.

</details>


### [4] [MicroBi-ConvLSTM: An Ultra-Lightweight Efficient Model for Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.06523)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: 提出MicroBi-ConvLSTM，一种超轻量级卷积-循环架构，平均仅11.4K参数，比现有最佳轻量模型减少2.9-11.9倍参数，在8个HAR基准测试中保持竞争力，量化后仅23KB部署大小，适合内存受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的轻量级HAR模型（如TinierHAR和TinyHAR）虽然精度高，但在考虑操作系统开销后仍超出微控制器的内存限制。需要在保持精度的同时进一步减少模型参数以适应资源受限的可穿戴设备。

Method: 采用两阶段卷积特征提取（带4倍时间池化）和单层双向LSTM的卷积-循环架构，平均仅11.4K参数。保持线性O(N)复杂度，并通过INT8后训练量化进一步压缩模型。

Result: 在8个多样化HAR基准测试中表现优异：UCI-HAR上93.41%宏F1，SKODA装配手势94.46%，Daphnet步态冻结检测88.98%。量化后平均F1分数仅下降0.21%，部署大小平均23.0KB。

Conclusion: MicroBi-ConvLSTM成功实现了超轻量级HAR模型设计，在显著减少参数（2.9-11.9倍）的同时保持竞争力，特别适合内存受限的边缘设备部署，双向性对事件检测任务尤其有益。

Abstract: Human Activity Recognition (HAR) on resource constrained wearables requires models that balance accuracy against strict memory and computational budgets. State of the art lightweight architectures such as TinierHAR (34K parameters) and TinyHAR (55K parameters) achieve strong accuracy, but exceed memory budgets of microcontrollers with limited SRAM once operating system overhead is considered. We present MicroBi-ConvLSTM, an ultra-lightweight convolutional-recurrent architecture achieving 11.4K parameters on average through two stage convolutional feature extraction with 4x temporal pooling and a single bidirectional LSTM layer. This represents 2.9x parameter reduction versus TinierHAR and 11.9x versus DeepConvLSTM while preserving linear O(N) complexity. Evaluation across eight diverse HAR benchmarks shows that MicroBi-ConvLSTM maintains competitive performance within the ultra-lightweight regime: 93.41% macro F1 on UCI-HAR, 94.46% on SKODA assembly gestures, and 88.98% on Daphnet gait freeze detection. Systematic ablation reveals task dependent component contributions where bidirectionality benefits episodic event detection, but provides marginal gains on periodic locomotion. INT8 post training quantization incurs only 0.21% average F1-score degradation, yielding a 23.0 KB average deployment footprint suitable for memory constrained edge devices.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Agentic Workflow Using RBA$_θ$ for Event Prediction](https://arxiv.org/abs/2602.06097)
*Purbak Sengupta,Sambeet Mishra,Sonal Shreya*

Main category: cs.LG

TL;DR: 提出事件优先、频率感知的风电爬坡事件预测框架，直接预测爬坡事件并重建功率轨迹，而非从密集预测中推断事件，实现跨风电场零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 风电爬坡事件因强变异性、多尺度动态和站点特定气象效应而难以预测。传统基于密集功率预测再提取事件的方法泛化能力有限，需要更直接、可迁移的事件预测方法。

Method: 1. 提出事件优先预测范式：直接预测爬坡事件，然后重建功率轨迹；2. 基于增强的RBAθ方法的事件表示；3. 渐进集成统计、机器学习和深度学习模型；4. 引入事件优先深度架构：集成小波频率分解、时间激励特征和自适应特征选择；5. 提出智能体预测层：根据运行上下文动态选择专门工作流。

Result: 1. 随机森林直接事件预测比基于生存分析的公式更稳健；2. 事件优先深度架构实现稳定长时域事件预测、物理一致的轨迹重建和零样本迁移；3. 实证分析显示爬坡幅度和持续时间受不同中频带控制；4. 可从稀疏事件预测中准确重建信号。

Conclusion: 事件优先、频率感知的预测框架为风电功率预测提供了可迁移且与运行对齐的替代方案，优于传统的轨迹优先方法，特别适用于跨站点泛化和运行决策支持。

Abstract: Wind power ramp events are difficult to forecast due to strong variability, multi-scale dynamics, and site-specific meteorological effects. This paper proposes an event-first, frequency-aware forecasting paradigm that directly predicts ramp events and reconstructs the power trajectory thereafter, rather than inferring events from dense forecasts. The framework is built on an enhanced Ramping Behaviour Analysis (RBA$_θ$) method's event representation and progressively integrates statistical, machine-learning, and deep-learning models. Traditional forecasting models with post-hoc event extraction provides a strong interpretable baseline but exhibits limited generalisation across sites. Direct event prediction using Random Forests improves robustness over survival-based formulations, motivating fully event-aware modelling. To capture the multi-scale nature of wind ramps, we introduce an event-first deep architecture that integrates wavelet-based frequency decomposition, temporal excitation features, and adaptive feature selection. The resulting sequence models enable stable long-horizon event prediction, physically consistent trajectory reconstruction, and zero-shot transfer to previously unseen wind farms. Empirical analysis shows that ramp magnitude and duration are governed by distinct mid-frequency bands, allowing accurate signal reconstruction from sparse event forecasts. An agentic forecasting layer is proposed, in which specialised workflows are selected dynamically based on operational context. Together, the framework demonstrates that event-first, frequency-aware forecasting provides a transferable and operationally aligned alternative to trajectory-first wind-power prediction.

</details>


### [6] [PurSAMERE: Reliable Adversarial Purification via Sharpness-Aware Minimization of Expected Reconstruction Error](https://arxiv.org/abs/2602.06269)
*Vinh Hoang,Sebastian Krumscheid,Holger Rauhut,Raúl Tempone*

Main category: cs.LG

TL;DR: 提出一种确定性净化方法，通过将对抗样本映射到数据分布模式附近的样本，提高对抗鲁棒性，避免随机净化方法在完全知识攻击下的性能下降。


<details>
  <summary>Details</summary>
Motivation: 随机净化方法在攻击者完全了解系统及其随机性的情况下，有效鲁棒性会下降。需要一种确定性方法来确保可靠的测试精度，同时将对抗样本映射到数据分布模式附近，因为分类器在这些区域更可靠。

Method: 训练一个通过最小化噪声污染数据期望重构误差的得分模型，学习输入数据分布的结构特征。给定潜在对抗输入，在其局部邻域内搜索最小化噪声污染下期望重构误差的净化样本，然后将其输入分类器。使用锐度感知最小化引导净化样本朝向期望重构误差景观的平坦区域。

Result: 实验结果表明，在强确定性白盒攻击下，该方法在对抗鲁棒性方面相比最先进方法取得了显著提升。理论分析表明，随着噪声水平降低，最小化期望重构误差会使净化样本偏向高斯平滑密度的局部最大化器。

Conclusion: 提出的确定性净化方法能有效提高对抗鲁棒性，避免了随机方法的弱点，通过将对抗样本映射到数据分布模式附近，使分类器在更可靠的区域工作，同时在理论上保证了净化样本会收敛到局部密度最大化器。

Abstract: We propose a novel deterministic purification method to improve adversarial robustness by mapping a potentially adversarial sample toward a nearby sample that lies close to a mode of the data distribution, where classifiers are more reliable. We design the method to be deterministic to ensure reliable test accuracy and to prevent the degradation of effective robustness observed in stochastic purification approaches when the adversary has full knowledge of the system and its randomness. We employ a score model trained by minimizing the expected reconstruction error of noise-corrupted data, thereby learning the structural characteristics of the input data distribution. Given a potentially adversarial input, the method searches within its local neighborhood for a purified sample that minimizes the expected reconstruction error under noise corruption and then feeds this purified sample to the classifier. During purification, sharpness-aware minimization is used to guide the purified samples toward flat regions of the expected reconstruction error landscape, thereby enhancing robustness. We further show that, as the noise level decreases, minimizing the expected reconstruction error biases the purified sample toward local maximizers of the Gaussian-smoothed density; under additional local assumptions on the score model, we prove recovery of a local maximizer in the small-noise limit. Experimental results demonstrate significant gains in adversarial robustness over state-of-the-art methods under strong deterministic white-box attacks.

</details>


### [7] [Enhance and Reuse: A Dual-Mechanism Approach to Boost Deep Forest for Label Distribution Learning](https://arxiv.org/abs/2602.06353)
*Jia-Le Xu,Shen-Huan Lyu,Yu-Nian Wang,Ning Chen,Zhihao Qu,Bin Tang,Baoliu Ye*

Main category: cs.LG

TL;DR: 提出ERDF方法，通过标签相关性特征增强和度量感知特征重用机制，将深度森林应用于标签分布学习，提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 标签分布学习需要利用标签间的相关性，但现有深度森林方法在这方面缺乏有效机制。深度森林作为非反向传播的深度学习框架，在LDL领域的探索尚不充分。

Method: 提出ERDF方法，包含两个核心机制：1）利用标签相关性增强原始特征，使样本获得更全面的信息；2）对验证集上表现下降的样本特征进行重用操作，确保训练稳定性。

Result: 在六个评估指标上，ERDF方法均优于其他对比算法，证明了其有效性。

Conclusion: ERDF通过增强-重用模式，不仅丰富了样本特征，还验证了新特征的有效性并防止噪声传播，为深度森林在标签分布学习中的应用提供了有效方案。

Abstract: Label distribution learning (LDL) requires the learner to predict the degree of correlation between each sample and each label. To achieve this, a crucial task during learning is to leverage the correlation among labels. Deep Forest (DF) is a deep learning framework based on tree ensembles, whose training phase does not rely on backpropagation. DF performs in-model feature transform using the prediction of each layer and achieves competitive performance on many tasks. However, its exploration in the field of LDL is still in its infancy. The few existing methods that apply DF to the field of LDL do not have effective ways to utilize the correlation among labels. Therefore, we propose a method named Enhanced and Reused Feature Deep Forest (ERDF). It mainly contains two mechanisms: feature enhancement exploiting label correlation and measure-aware feature reuse. The first one is to utilize the correlation among labels to enhance the original features, enabling the samples to acquire more comprehensive information for the task of LDL. The second one performs a reuse operation on the features of samples that perform worse than the previous layer on the validation set, in order to ensure the stability of the training process. This kind of Enhance-Reuse pattern not only enables samples to enrich their features but also validates the effectiveness of their new features and conducts a reuse process to prevent the noise from spreading further. Experiments show that our method outperforms other comparison algorithms on six evaluation metrics.

</details>


### [8] [Reclaiming First Principles: A Differentiable Framework for Conceptual Hydrologic Models](https://arxiv.org/abs/2602.06429)
*Jasper A. Vrugt,Jonathan M. Frame,Ethan Bollman*

Main category: cs.LG

TL;DR: 提出基于精确参数敏感性的全解析可微水文建模框架，通过增广ODE系统联合演化模型状态和雅可比矩阵，为概念水文模型提供快速、稳定、透明的梯度校准方法。


<details>
  <summary>Details</summary>
Motivation: 概念水文模型的校准通常缓慢且数值脆弱，现有基于梯度的参数估计方法（有限差分或自动微分）计算量大，存在截断误差、求解器不稳定和显著开销等问题，尤其对于概念流域模型的ODE系统。

Method: 通过增广控制ODE系统，加入敏感性方程，联合演化模型状态和关于所有参数的雅可比矩阵。该雅可比矩阵为任何可微损失函数提供完全解析的梯度向量，包括经典目标函数、水文性能指标、鲁棒损失函数和水文过程线函数。

Result: 解析敏感性消除了数值微分的步长依赖性和噪声，避免了伴随方法的不稳定性和现代机器学习自动微分工具链的开销。所得梯度具有确定性、物理可解释性，易于嵌入基于梯度的优化器。

Conclusion: 该工作实现了概念水文模型的快速、稳定、透明的梯度校准，释放了可微建模的全部潜力，无需依赖外部、不透明或CPU密集的自动微分库。

Abstract: Conceptual hydrologic models remain the cornerstone of rainfall-runoff modeling, yet their calibration is often slow and numerically fragile. Most gradient-based parameter estimation methods rely on finite-difference approximations or automatic differentiation frameworks (e.g., JAX, PyTorch and TensorFlow), which are computationally demanding and introduce truncation errors, solver instabilities, and substantial overhead. These limitations are particularly acute for the ODE systems of conceptual watershed models. Here we introduce a fully analytic and computationally efficient framework for differentiable hydrologic modeling based on exact parameter sensitivities. By augmenting the governing ODE system with sensitivity equations, we jointly evolve the model states and the Jacobian matrix with respect to all parameters. This Jacobian then provides fully analytic gradient vectors for any differentiable loss function. These include classical objective functions such as the sum of absolute and squared residuals, widely used hydrologic performance metrics such as the Nash-Sutcliffe and Kling-Gupta efficiencies, robust loss functions that down-weight extreme events, and hydrograph-based functionals such as flow-duration and recession curves. The analytic sensitivities eliminate the step-size dependence and noise inherent to numerical differentiation, while avoiding the instability of adjoint methods and the overhead of modern machine-learning autodiff toolchains. The resulting gradients are deterministic, physically interpretable, and straightforward to embed in gradient-based optimizers. Overall, this work enables rapid, stable, and transparent gradient-based calibration of conceptual hydrologic models, unlocking the full potential of differentiable modeling without reliance on external, opaque, or CPU-intensive automatic-differentiation libraries.

</details>


### [9] [The Window Dilemma: Why Concept Drift Detection is Ill-Posed](https://arxiv.org/abs/2602.06456)
*Brandon Gower-Winter,Misja Groen,Georg Krempl*

Main category: cs.LG

TL;DR: 传统漂移检测器存在窗口困境问题，漂移检测本身定义不明确，实验表明传统批量学习方法通常优于漂移感知方法


<details>
  <summary>Details</summary>
Motivation: 数据流中的概念漂移现象已被广泛研究，漂移检测器通过比较数据窗口的差异来检测变化。但作者发现现有方法存在根本性问题：检测到的漂移可能是窗口选择的产物而非真实的数据生成过程变化，且漂移检测在实践中难以验证。

Method: 首先通过示例说明窗口困境问题，然后对多种漂移检测器与替代适应策略进行实证比较。研究展示了漂移检测的固有问题，并对比了不同方法在流分类任务中的表现。

Result: 主要发现是传统批量学习技术通常优于漂移感知方法，这进一步质疑了漂移检测器在流分类中的实际价值。实验结果表明窗口选择会显著影响漂移检测结果，而验证漂移事件在实践中几乎不可能。

Conclusion: 漂移检测存在根本性缺陷：窗口困境使得检测结果不可靠，且缺乏实际验证机制。传统批量学习方法在流分类中表现更好，建议重新评估漂移检测器的必要性。

Abstract: Non-stationarity of an underlying data generating process that leads to distributional changes over time is a key characteristic of Data Streams. This phenomenon, commonly referred to as Concept Drift, has been intensively studied, and Concept Drift Detectors have been established as a class of methods for detecting such changes (drifts). For the most part, Drift Detectors compare regions (windows) of the data stream and detect drift if those windows are sufficiently dissimilar.
  In this work, we introduce the Window Dilemma, an observation that perceived drift is a product of windowing and not necessarily the underlying data generating process. Additionally, we highlight that drift detection is ill-posed, primarily because verification of drift events are implausible in practice. We demonstrate these contributions first by an illustrative example, followed by empirical comparisons of drift detectors against a variety of alternative adaptation strategies. Our main finding is that traditional batch learning techniques often perform better than their drift-aware counterparts further bringing into question the purpose of detectors in Stream Classification.

</details>


### [10] [Trust Regions Sell, But Who's Buying? Overlap Geometry as an Alternative Trust Region for Policy Optimization](https://arxiv.org/abs/2602.06627)
*Gaurish Trivedi,Alakh Sharma,Kartikey Singh Bhandari,Yash Sinha,Pratik Narang,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.LG

TL;DR: 提出基于分布重叠几何的信任区域方法，用Bhattacharyya系数替代KL散度，通过控制平方根似然比来防止训练不稳定


<details>
  <summary>Details</summary>
Motivation: 标准KL信任区域方法只控制平均散度，无法防止罕见但破坏性大的似然比偏移，这正是PPO等启发式方法试图解决的问题

Method: 提出Bhattacharyya-TRPO和Bhattacharyya-PPO，通过平方根似然比更新来约束分布重叠，BPPO对平方根比进行裁剪，BTRPO应用二次Hellinger/Bhattacharyya惩罚

Result: 在相同训练预算下，基于重叠的更新提高了鲁棒性和聚合性能（通过RLiable评估）

Conclusion: 重叠约束是KL散度的一个实用且有理论依据的替代方案，可用于稳定策略优化

Abstract: Standard trust-region methods constrain policy updates via Kullback-Leibler (KL) divergence. However, KL controls only an average divergence and does not directly prevent rare, large likelihood-ratio excursions that destabilize training--precisely the failure mode that motivates heuristics such as PPO's clipping. We propose overlap geometry as an alternative trust region, constraining distributional overlap via the Bhattacharyya coefficient (closely related to the Hellinger/Renyi-1/2 geometry). This objective penalizes separation in the ratio tails, yielding tighter control over likelihood-ratio excursions without relying on total variation bounds that can be loose in tail regimes. We derive Bhattacharyya-TRPO (BTRPO) and Bhattacharyya-PPO (BPPO), enforcing overlap constraints via square-root ratio updates: BPPO clips the square-root ratio q = sqrt(r), and BTRPO applies a quadratic Hellinger/Bhattacharyya penalty. Empirically, overlap-based updates improve robustness and aggregate performance as measured by RLiable under matched training budgets, suggesting overlap constraints as a practical, principled alternative to KL for stable policy optimization.

</details>


### [11] [Displacement-Resistant Extensions of DPO with Nonconvex $f$-Divergences](https://arxiv.org/abs/2602.06788)
*Idan Pipano,Shoham Sabach,Kavosh Asadi,Mohammad Ghavamzadeh*

Main category: cs.LG

TL;DR: 论文提出了一种更广义的RLHF优化框架，放宽了f-散度的凸性要求，定义了DPO-inducing条件，并提出了防止概率位移的displacement-resistant条件，最终基于满足这两个条件的f函数开发了新的SquaredPO损失函数。


<details>
  <summary>Details</summary>
Motivation: 现有DPO及相关算法通过KL散度惩罚来对齐语言模型，但KL散度只是f-散度的一种特例。虽然已有工作将KL推广到凸f-散度，但凸性限制可能过于严格。本文旨在寻找更一般的条件，使RLHF问题保持可解性，同时解决概率位移这一实际问题。

Method: 1. 提出DPO-inducing条件，精确刻画RLHF问题保持可解性的f函数特征，放宽了凸性要求。2. 建立displacement-resistant条件，防止概率位移现象。3. 基于同时满足这两个条件的特定f函数，开发新的SquaredPO损失函数。

Result: 1. 证明了凸性不是RLHF问题可解的必要条件，提出了更一般的DPO-inducing条件。2. 识别了防止概率位移的displacement-resistant条件。3. SquaredPO损失在理论上比DPO有更强的保证，在实践中表现相当。

Conclusion: 本文扩展了RLHF优化框架的理论基础，放宽了f-散度的凸性要求，提出了防止概率位移的条件，并开发了具有更强理论保证的SquaredPO损失函数，为语言模型对齐提供了更灵活和稳健的方法。

Abstract: DPO and related algorithms align language models by directly optimizing the RLHF objective: find a policy that maximizes the Bradley-Terry reward while staying close to a reference policy through a KL divergence penalty. Previous work showed that this approach could be further generalized: the original problem remains tractable even if the KL divergence is replaced by a family of $f$-divergence with a convex generating function $f$. Our first contribution is to show that convexity of $f$ is not essential. Instead, we identify a more general condition, referred to as DPO-inducing, that precisely characterizes when the RLHF problem remains tractable. Our next contribution is to establish a second condition on $f$ that is necessary to prevent probability displacement, a known empirical phenomenon in which the probabilities of the winner and the loser responses approach zero. We refer to any $f$ that satisfies this condition as displacement-resistant. We finally focus on a specific DPO-inducing and displacement-resistant $f$, leading to our novel SquaredPO loss. Compared to DPO, this new loss offers stronger theoretical guarantees while performing competitively in practice.

</details>


### [12] [Rare Event Analysis of Large Language Models](https://arxiv.org/abs/2602.06791)
*Jake McAllister Dorman,Edward Gillman,Dominic C. Rose,Jamie F. Mair,Juan P. Garrahan*

Main category: cs.LG

TL;DR: 本文提出了一个用于系统分析大语言模型中罕见事件的端到端框架，包括理论、高效生成策略、概率估计和误差分析，并展示了具体应用示例。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为概率模型，在推理过程中会出现罕见事件——这些行为远离典型但非常重要。由于罕见事件的定义特性，它们很难被观察到，但LLM的巨大使用规模意味着在开发阶段完全未观察到的事件很可能在部署后变得显著。因此需要系统分析这些罕见事件。

Method: 提出了一个端到端框架，包含理论基础、高效生成策略、概率估计方法和误差分析。提供了实际实现，并通过具体示例进行说明。

Result: 开发了一个完整的分析框架，能够系统性地识别、生成和评估LLM中的罕见事件，为理解和处理这些重要但难以观察的现象提供了工具。

Conclusion: 该框架具有通用性，可以扩展到其他模型和上下文，展示了所提出概念和技术的广泛适用性，为LLM罕见事件分析提供了系统化的方法论。

Abstract: Being probabilistic models, during inference large language models (LLMs) display rare events: behaviour that is far from typical but highly significant. By definition all rare events are hard to see, but the enormous scale of LLM usage means that events completely unobserved during development are likely to become prominent in deployment. Here we present an end-to-end framework for the systematic analysis of rare events in LLMs. We provide a practical implementation spanning theory, efficient generation strategies, probability estimation and error analysis, which we illustrate with concrete examples. We outline extensions and applications to other models and contexts, highlighting the generality of the concepts and techniques presented here.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [CAST: Character-and-Scene Episodic Memory for Agents](https://arxiv.org/abs/2602.06051)
*Kexin Ma,Bojun Li,Yuhua Tang,Ruochun Jin,Liting Sun*

Main category: cs.CL

TL;DR: 提出基于戏剧理论的角色与场景记忆架构(CAST)，通过构建3D场景(时间/地点/主题)并组织成角色档案来表示情景记忆，结合图语义记忆形成双记忆系统，显著提升对话问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统主要关注语义回忆，将经验表示为键值对、向量或图结构，难以表示和检索连贯的事件。人类的情景记忆能够回忆基于谁、何时、何地的连贯事件，需要新的记忆架构来解决这一挑战。

Method: 提出CAST记忆架构，受戏剧理论启发：1) 构建3D场景(时间/地点/主题)并组织成角色档案来总结角色事件，表示情景记忆；2) 结合基于图的语义记忆，形成双记忆设计。

Result: 实验显示CAST在多个数据集上平均提升8.11% F1分数和10.21% J(LLM-as-a-Judge)评分，尤其在开放性和时间敏感的对话问题上表现突出。

Conclusion: CAST通过戏剧理论启发的角色与场景架构有效表示情景记忆，结合语义记忆形成双记忆系统，显著提升智能体在对话任务中的记忆和推理能力。

Abstract: Episodic memory is a central component of human memory, which refers to the ability to recall coherent events grounded in who, when, and where. However, most agent memory systems only emphasize semantic recall and treat experience as structures such as key-value, vector, or graph, which makes them struggle to represent and retrieve coherent events. To address this challenge, we propose a Character-and-Scene based memory architecture(CAST) inspired by dramatic theory. Specifically, CAST constructs 3D scenes (time/place/topic) and organizes them into character profiles that summarize the events of a character to represent episodic memory. Moreover, CAST complements this episodic memory with a graph-based semantic memory, which yields a robust dual memory design. Experiments demonstrate that CAST has averagely improved 8.11% F1 and 10.21% J(LLM-as-a-Judge) than baselines on various datasets, especially on open and time-sensitive conversational questions.

</details>


### [14] [Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding](https://arxiv.org/abs/2602.06161)
*Yanzheng Xiang,Lan Wei,Yizhen Yao,Qinglin Zhu,Hanqi Yan,Chen Jin,Philip Alexander Teare,Dandan Zhang,Lin Gui,Amrutha Saseendran,Yulan He*

Main category: cs.CL

TL;DR: COVER提出一种新的并行扩散解码验证方法，通过KV缓存覆盖实现单次前向传播中的留一验证和稳定草稿生成，减少不必要的修订并加速推理。


<details>
  <summary>Details</summary>
Motivation: 现有并行扩散解码方法中，可撤销解码的验证方案经常触发"翻转振荡"问题，即令牌被重新掩码后又恢复原状，这既削弱了并行草稿生成的上下文条件，又浪费了修订预算，导致推理速度下降。

Method: COVER采用KV缓存覆盖技术：1) 通过掩码选定种子位置进行验证，同时将其缓存的键值状态注入所有其他查询以保留上下文信息；2) 使用闭式对角线校正防止种子位置的自泄漏；3) 设计稳定性感知评分来平衡不确定性、下游影响和缓存漂移；4) 自适应调整每步验证的种子数量。

Result: 在多个基准测试中，COVER显著减少了不必要的修订，在保持输出质量的同时实现了更快的解码速度。

Conclusion: COVER通过创新的KV缓存覆盖机制解决了并行扩散解码中的翻转振荡问题，实现了更高效的验证和更稳定的并行草稿生成，为加速扩散语言模型推理提供了有效方案。

Abstract: Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality.

</details>


### [15] [MPIB: A Benchmark for Medical Prompt Injection Attacks and Clinical Safety in LLMs](https://arxiv.org/abs/2602.06268)
*Junhyeok Lee,Han Jang,Kyu Sung Choi*

Main category: cs.CL

TL;DR: MPIB是一个医疗提示注入基准测试套件，用于评估LLM和RAG系统在临床环境中的安全性，重点关注临床伤害事件率（CHER）和攻击成功率（ASR）的差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和RAG系统越来越多地集成到临床工作流程中，提示注入攻击可能导致临床不安全或误导性输出，需要系统评估临床安全性。

Method: 创建MPIB基准测试套件，包含9,697个精心策划的实例，通过多阶段质量门控和临床安全检查构建。评估指标包括临床伤害事件率（CHER）和攻击成功率（ASR），区分直接提示注入和间接RAG介导的注入。

Result: 评估发现ASR和CHER存在显著差异，鲁棒性关键取决于对抗性指令出现在用户查询中还是检索上下文中。提供了代码、数据和文档支持可重复研究。

Conclusion: MPIB为临床提示注入研究提供了系统评估框架，强调了区分指令遵从性和下游患者风险的重要性，有助于开发更安全的临床AI系统。

Abstract: Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly integrated into clinical workflows; however, prompt injection attacks can steer these systems toward clinically unsafe or misleading outputs. We introduce the Medical Prompt Injection Benchmark (MPIB), a dataset-and-benchmark suite for evaluating clinical safety under both direct prompt injection and indirect, RAG-mediated injection across clinically grounded tasks. MPIB emphasizes outcome-level risk via the Clinical Harm Event Rate (CHER), which measures high-severity clinical harm events under a clinically grounded taxonomy, and reports CHER alongside Attack Success Rate (ASR) to disentangle instruction compliance from downstream patient risk. The benchmark comprises 9,697 curated instances constructed through multi-stage quality gates and clinical safety linting. Evaluating MPIB across a diverse set of baseline LLMs and defense configurations, we find that ASR and CHER can diverge substantially, and that robustness depends critically on whether adversarial instructions appear in the user query or in retrieved context. We release MPIB with evaluation code, adversarial baselines, and comprehensive documentation to support reproducible and systematic research on clinical prompt injection. Code and data are available at GitHub (code) and Hugging Face (data).

</details>


### [16] [RoPE-LIME: RoPE-Space Locality + Sparse-K Sampling for Efficient LLM Attribution](https://arxiv.org/abs/2602.06275)
*Isaac Picov,Ritesh Goru*

Main category: cs.CL

TL;DR: RoPE-LIME：一种用于解释闭源大语言模型输出的方法，通过使用开源替代模型和优化的扰动策略，在减少API调用成本的同时提供更好的特征归因。


<details>
  <summary>Details</summary>
Motivation: 解释闭源LLM输出具有挑战性，因为API访问阻止了基于梯度的归因方法，而基于扰动的传统方法成本高且噪声大（依赖于重新生成文本）。

Method: RoPE-LIME扩展了gSMILE方法，将推理与解释解耦：给定闭源模型的固定输出，使用较小的开源替代模型基于概率目标（负对数似然和散度目标）计算输入扰动下的token级归因。包含两个关键组件：(i) 基于RoPE嵌入空间中计算的Relaxed Word Mover's Distance的局部性核函数，确保掩码下的稳定相似性；(ii) Sparse-K采样，一种高效的扰动策略，在有限预算下提高交互覆盖率。

Result: 在HotpotQA（句子特征）和手工标注的MMLU子集（单词特征）上的实验表明，RoPE-LIME比留一法采样产生更具信息量的归因，相比gSMILE有所改进，同时显著减少了闭源模型的API调用。

Conclusion: RoPE-LIME提供了一种有效的方法来解释闭源LLM输出，通过使用开源替代模型和优化的扰动策略，在保持解释质量的同时大幅降低了计算成本。

Abstract: Explaining closed-source LLM outputs is challenging because API access prevents gradient-based attribution, while perturbation methods are costly and noisy when they depend on regenerated text. We introduce RoPE-LIME, an open-source extension of gSMILE that decouples reasoning from explanation: given a fixed output from a closed model, a smaller open-source surrogate computes token-level attributions from probability-based objectives (negative log-likelihood and divergence targets) under input perturbations. RoPE-LIME incorporates (i) a locality kernel based on Relaxed Word Mover's Distance computed in RoPE embedding space for stable similarity under masking, and (ii) Sparse-K sampling, an efficient perturbation strategy that improves interaction coverage under limited budgets. Experiments on HotpotQA (sentence features) and a hand-labeled MMLU subset (word features) show that RoPE-LIME produces more informative attributions than leave-one-out sampling and improves over gSMILE while substantially reducing closed-model API calls.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [17] [Think Proprioceptively: Embodied Visual Reasoning for VLA Manipulation](https://arxiv.org/abs/2602.06575)
*Fangyuan Wang,Peng Zhou,Jiaming Qi,Shipeng Lyu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: ThinkProprio 是一种VLA模型，通过将本体感觉转换为文本标记并与任务指令早期融合，让机器人状态参与视觉推理和标记选择，减少视觉标记数量，提高推理速度50%以上。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常将本体感觉作为后期条件信号，这限制了机器人状态对指令理解和视觉注意力分布的影响。需要让机器人状态更早地参与视觉推理过程。

Method: 将本体感觉转换为VLM嵌入空间中的文本标记序列，与任务指令在输入层早期融合。这种方法让机器人状态参与后续的视觉推理和标记选择，偏向于动作关键证据，同时抑制冗余视觉标记。

Result: 文本标记化比学习投影器更有效；保留约15%的视觉标记即可达到使用完整标记集的性能；在CALVIN、LIBERO和真实世界操作中，ThinkProprio匹配或优于强基线，同时将端到端推理延迟降低50%以上。

Conclusion: 通过将本体感觉转换为文本标记并与指令早期融合，ThinkProprio让机器人状态更有效地参与视觉推理过程，在保持性能的同时显著提高推理效率。

Abstract: Vision-language-action (VLA) models typically inject proprioception only as a late conditioning signal, which prevents robot state from shaping instruction understanding and from influencing which visual tokens are attended throughout the policy. We introduce ThinkProprio, which converts proprioception into a sequence of text tokens in the VLM embedding space and fuses them with the task instruction at the input. This early fusion lets embodied state participate in subsequent visual reasoning and token selection, biasing computation toward action-critical evidence while suppressing redundant visual tokens. In a systematic ablation over proprioception encoding, state entry point, and action-head conditioning, we find that text tokenization is more effective than learned projectors, and that retaining roughly 15% of visual tokens can match the performance of using the full token set. Across CALVIN, LIBERO, and real-world manipulation, ThinkProprio matches or improves over strong baselines while reducing end-to-end inference latency over 50%.

</details>


### [18] [RAPID: Reconfigurable, Adaptive Platform for Iterative Design](https://arxiv.org/abs/2602.06653)
*Zi Yin,Fanhong Li,Shurui Zheng,Jia Liu*

Main category: cs.RO

TL;DR: RAPID是一个全栈可重构机器人平台，通过模块化硬件架构和软件堆栈，将多模态配置设置时间减少两个数量级，支持传感器热插拔和策略持续执行。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略开发是迭代和假设驱动的过程，但即使微小的末端执行器更改也需要机械重新装配和系统重新集成，这严重拖慢了迭代速度。研究人员希望通过系统化多模态消融研究来测试触觉传感、夹持器几何形状和传感器放置，但传统工作流程效率低下。

Method: RAPID采用免工具模块化硬件架构，统一手持数据收集和机器人部署；匹配的软件堆栈通过基于USB事件的驱动级物理掩码保持对底层硬件配置的实时感知。物理掩码将模态存在作为显式运行时信号，支持自动配置和传感器热插拔时的优雅降级。

Result: 系统中心实验显示，RAPID将多模态配置设置时间相比传统工作流程减少两个数量级，并在运行时传感器热拔插事件下保持策略执行。平台支持在无需重复系统启动的情况下系统化扫描多样化的夹持器和传感配置。

Conclusion: RAPID通过模块化硬件和软件堆栈显著减少了机器人操作策略开发的迭代摩擦，使系统化多模态消融研究变得实用，并支持传感器热插拔下的策略持续执行。硬件设计、驱动程序和软件堆栈已开源。

Abstract: Developing robotic manipulation policies is iterative and hypothesis-driven: researchers test tactile sensing, gripper geometries, and sensor placements through real-world data collection and training. Yet even minor end-effector changes often require mechanical refitting and system re-integration, slowing iteration. We present RAPID, a full-stack reconfigurable platform designed to reduce this friction. RAPID is built around a tool-free, modular hardware architecture that unifies handheld data collection and robot deployment, and a matching software stack that maintains real-time awareness of the underlying hardware configuration through a driver-level Physical Mask derived from USB events. This modular hardware architecture reduces reconfiguration to seconds and makes systematic multi-modal ablation studies practical, allowing researchers to sweep diverse gripper and sensing configurations without repeated system bring-up. The Physical Mask exposes modality presence as an explicit runtime signal, enabling auto-configuration and graceful degradation under sensor hot-plug events, so policies can continue executing when sensors are physically added or removed. System-centric experiments show that RAPID reduces the setup time for multi-modal configurations by two orders of magnitude compared to traditional workflows and preserves policy execution under runtime sensor hot-unplug events. The hardware designs, drivers, and software stack are open-sourced at https://rapid-kit.github.io/ .

</details>


### [19] [SURE: Safe Uncertainty-Aware Robot-Environment Interaction using Trajectory Optimization](https://arxiv.org/abs/2602.06864)
*Zhuocheng Zhang,Haizhou Zhao,Xudong Sun,Aaron M. Johnson,Majid Khadiv*

Main category: cs.RO

TL;DR: SURE：一种考虑接触时序不确定性的鲁棒轨迹优化框架，通过分支轨迹设计提升机器人接触任务的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 机器人接触交互任务中的轨迹优化面临挑战，传统方法假设确定性接触事件限制了实际环境中的鲁棒性和适应性

Method: 提出SURE框架，允许从可能的预碰撞状态分支多条轨迹，随后重新汇合到共享轨迹，在统一优化框架中实现鲁棒性和计算效率

Result: 在不确定墙壁位置的倒立摆平衡任务中，分支切换使成功率平均提升21.6%；在机器人抓鸡蛋实验中，成功率提升40%

Conclusion: SURE框架相比传统名义规划方法显著提升了接触时序不确定情况下的鲁棒性

Abstract: Robotic tasks involving contact interactions pose significant challenges for trajectory optimization due to discontinuous dynamics. Conventional formulations typically assume deterministic contact events, which limit robustness and adaptability in real-world settings. In this work, we propose SURE, a robust trajectory optimization framework that explicitly accounts for contact timing uncertainty. By allowing multiple trajectories to branch from possible pre-impact states and later rejoin a shared trajectory, SURE achieves both robustness and computational efficiency within a unified optimization framework. We evaluate SURE on two representative tasks with unknown impact times. In a cart-pole balancing task involving uncertain wall location, SURE achieves an average improvement of 21.6% in success rate when branch switching is enabled during control. In an egg-catching experiment using a robotic manipulator, SURE improves the success rate by 40%. These results demonstrate that SURE substantially enhances robustness compared to conventional nominal formulations.

</details>
