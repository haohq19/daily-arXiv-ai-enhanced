<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models](https://arxiv.org/abs/2512.08228)
*Jusheng Zhang,Kaitong Cai,Xiaoyang Guo,Sidi Liu,Qinhan Lv,Ruiqi Chen,Jing Yang,Yijia Fan,Xiaofei Sun,Jian Wang,Ziliang Chen,Liang Lin,Keze Wang*

Main category: cs.CV

TL;DR: MM-CoT是一个诊断性基准，专门用于评估多模态模型中思维链推理的视觉基础和逻辑连贯性，通过要求模型选择同时满足视觉一致性和逻辑连贯性的事件链来测试推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注生成能力而忽视验证能力，无法评估多模态模型的思维链推理是否真正基于视觉证据且逻辑连贯。需要一个新的基准来诊断推理的视觉基础和逻辑有效性。

Method: 设计MM-CoT基准，要求模型从多个事件链中选择唯一满足两个正交约束的选项：视觉一致性（所有步骤都基于可观察证据）和逻辑连贯性（因果和常识有效性）。通过设计违反其中一个约束的对抗性干扰项来暴露不同的推理失败。

Result: 评估领先的视觉语言模型发现，即使最先进的系统也在MM-CoT上表现不佳，揭示了生成流畅性与真实推理保真度之间的显著差距。MM-CoT与现有基准相关性低，确认其测量的是视觉基础和逻辑推理的独特组合。

Conclusion: MM-CoT为开发未来模型提供了基础，这些模型不仅能够进行看似合理的推理，而且能够在视觉世界中忠实且连贯地进行推理，填补了现有基准在验证能力方面的空白。

Abstract: The ability to perform Chain-of-Thought (CoT) reasoning marks a major milestone for multimodal models (MMs), enabling them to solve complex visual reasoning problems. Yet a critical question remains: is such reasoning genuinely grounded in visual evidence and logically coherent? Existing benchmarks emphasize generation but neglect verification, i.e., the capacity to assess whether a reasoning chain is both visually consistent and logically valid. To fill this gap, we introduce MM-CoT, a diagnostic benchmark specifically designed to probe the visual grounding and logical coherence of CoT reasoning in MMs. Instead of generating free-form explanations, models must select the sole event chain that satisfies two orthogonal constraints: (i) visual consistency, ensuring all steps are anchored in observable evidence, and (ii) logical coherence, ensuring causal and commonsense validity. Adversarial distractors are engineered to violate one of these constraints, exposing distinct reasoning failures. We evaluate leading vision-language models on MM-CoT and find that even the most advanced systems struggle, revealing a sharp discrepancy between generative fluency and true reasoning fidelity. MM-CoT shows low correlation with existing benchmarks, confirming that it measures a unique combination of visual grounding and logical reasoning. This benchmark provides a foundation for developing future models that reason not just plausibly, but faithfully and coherently within the visual world.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Space Alignment Matters: The Missing Piece for Inducing Neural Collapse in Long-Tailed Learning](https://arxiv.org/abs/2512.07844)
*Jinping Wang,Zhiqiang Gao,Zhiwu Xie*

Main category: cs.LG

TL;DR: 该论文针对长尾分布中神经坍缩现象缺失的问题，提出通过特征与分类器权重空间对齐来提升性能，无需改变网络架构。


<details>
  <summary>Details</summary>
Motivation: 在长尾数据分布中，样本不平衡阻碍了神经坍缩现象的出现，导致泛化性能下降。现有方法主要关注恢复ETF几何结构，但忽视了特征空间与分类器权重空间之间的严重错位问题。

Method: 通过最优误差指数分析理论量化错位的危害，提出三种即插即用的显式对齐策略，可直接应用于现有长尾学习方法而不需要改变网络架构。

Result: 在CIFAR-10-LT、CIFAR-100-LT和ImageNet-LT数据集上的大量实验表明，所提方法能持续提升基线性能，并达到最先进的性能水平。

Conclusion: 特征与分类器权重空间的对齐对于长尾学习至关重要，提出的即插即用对齐策略能有效提升现有方法的性能，为解决长尾分布中的神经坍缩问题提供了新思路。

Abstract: Recent studies on Neural Collapse (NC) reveal that, under class-balanced conditions, the class feature means and classifier weights spontaneously align into a simplex equiangular tight frame (ETF). In long-tailed regimes, however, severe sample imbalance tends to prevent the emergence of the NC phenomenon, resulting in poor generalization performance. Current efforts predominantly seek to recover the ETF geometry by imposing constraints on features or classifier weights, yet overlook a critical problem: There is a pronounced misalignment between the feature and the classifier weight spaces. In this paper, we theoretically quantify the harm of such misalignment through an optimal error exponent analysis. Built on this insight, we propose three explicit alignment strategies that plug-and-play into existing long-tail methods without architectural change. Extensive experiments on the CIFAR-10-LT, CIFAR-100-LT, and ImageNet-LT datasets consistently boost examined baselines and achieve the state-of-the-art performances.

</details>


### [3] [GPU Memory Prediction for Multimodal Model Training](https://arxiv.org/abs/2512.07853)
*Jinwoo Jeong,Minchul Kang,Younghun Go,Changyong Shin,Hyunho Lee,Junho Yoon,Gyeongsik Yang,Chuck Yoo*

Main category: cs.LG

TL;DR: 提出一个预测多模态模型GPU峰值内存使用的框架，通过分解模型架构和分析训练行为来准确预测内存使用，防止OOM错误


<details>
  <summary>Details</summary>
Motivation: 随着智能体AI系统中深度学习模型的规模和复杂性增加，GPU内存需求经常超过可用容量，导致内存溢出(OOM)错误，这会中断训练并浪费计算资源。现有研究仅关注单模态架构，无法推广到多模态模型，而多模态模型在智能体AI系统中很常见。

Method: 提出一个框架，通过分析多模态模型的架构和训练行为来预测GPU峰值内存使用。具体方法是将多模态模型分解为组成层，并应用因子化来估计每层的内存使用。

Result: 评估显示该框架实现了约8.7%的平均MAPE（平均绝对百分比误差），具有较高的预测准确性。

Conclusion: 该框架能够准确预测多模态模型的GPU峰值内存使用，有助于防止OOM错误，提高智能体AI系统训练的资源利用效率。

Abstract: As deep learning models in agentic AI systems grow in scale and complexity, GPU memory requirements increase and often exceed the available GPU memory capacity, so that out-of-memory (OoM) errors occur. It is well known that OoM interrupts the whole training itself and wastes substantial computational resources. Therefore, to prevent OoM, accurate prediction of GPU memory usage is essential. However, previous studies focus only on unimodal architectures and fail to generalize to multimodal models, even though the multimodal models are a common choice in agentic AI systems. To address this limitation, we propose a framework that predicts the peak GPU memory usage by analyzing the model architecture and training behavior of multimodal models. Specifically, the framework decomposes the multimodal model into its constituent layers and applies factorization to estimate the memory usage of each layer. Our evaluation shows that our framework achieves high prediction accuracy of ~8.7% average MAPE.

</details>


### [4] [Semi-Supervised Contrastive Learning with Orthonormal Prototypes](https://arxiv.org/abs/2512.07880)
*Huanran Li,Manh Nguyen,Daniel Pimentel-Alarcón*

Main category: cs.LG

TL;DR: 本文提出CLOP损失函数，通过促进类别嵌入形成正交线性子空间来防止对比学习中的维度坍缩问题，在图像分类和目标检测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 对比学习在深度学习中表现出色，但维度坍缩问题（嵌入收敛到低维空间）在自监督和半监督设置中构成重大挑战，尤其是在高学习率下会导致坍缩解。

Method: 首先识别了导致维度坍缩的关键学习率阈值，然后提出CLOP损失函数，通过促进类别嵌入形成正交线性子空间来防止维度坍缩。

Result: 在真实和合成数据集上的实验表明，CLOP在图像分类和目标检测任务中提高了性能，同时在不同学习率和批量大小下表现出更好的稳定性。

Conclusion: CLOP通过防止维度坍缩有效解决了对比学习中的关键问题，提高了表示学习的质量和稳定性，为半监督对比学习提供了更可靠的解决方案。

Abstract: Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first identify a critical learning-rate threshold, beyond which standard contrastive losses converge to collapsed solutions. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP improves performance in image classification and object detection tasks while also exhibiting greater stability across different learning rates and batch sizes.

</details>


### [5] [Scalable Offline Model-Based RL with Action Chunks](https://arxiv.org/abs/2512.08108)
*Kwanyoung Park,Seohong Park,Youngwoon Lee,Sergey Levine*

Main category: cs.LG

TL;DR: MAC提出了一种基于模型的离线强化学习方法，通过动作块模型减少长期预测误差，结合拒绝采样防止模型利用，在复杂长时域任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究基于模型的强化学习（特别是基于模型的价值扩展）能否为离线RL中的复杂长时域任务提供可扩展的解决方案。传统方法在减少价值引导偏差（通过增大n）和累积模型误差之间存在权衡。

Method: 提出MAC方法：1）使用动作块模型，预测动作序列（而非单个动作）后的未来状态，减少复合误差；2）采用拒绝采样从表达性行为动作块策略中采样，防止模型利用和分布外动作问题。

Result: 在包含高达1亿个转移的大规模数据集上的高度挑战性任务实验中，MAC在离线基于模型RL算法中表现最佳，尤其在挑战性长时域任务上。

Conclusion: MAC通过动作块模型和拒绝采样的组合，有效解决了基于模型价值扩展中的偏差-误差权衡问题，为离线RL中的复杂长时域任务提供了有效的解决方案。

Abstract: In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion, can provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. Model-based value expansion fits an on-policy value function using length-n imaginary rollouts generated by the current policy and a learned dynamics model. While larger n reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions. We address this trade-off with an \emph{action-chunk} model that predicts a future state from a sequence of actions (an "action chunk") instead of a single action, which reduces compounding errors. In addition, instead of directly training a policy to maximize rewards, we employ rejection sampling from an expressive behavioral action-chunk policy, which prevents model exploitation from out-of-distribution actions. We call this recipe \textbf{Model-Based RL with Action Chunks (MAC)}. Through experiments on highly challenging tasks with large-scale datasets of up to 100M transitions, we show that MAC achieves the best performance among offline model-based RL algorithms, especially on challenging long-horizon tasks.

</details>


### [6] [Solving Over-Smoothing in GNNs via Nonlocal Message Passing: Algebraic Smoothing and Depth Scalability](https://arxiv.org/abs/2512.08475)
*Weiqi Guan,Junlin He*

Main category: cs.LG

TL;DR: 提出一种基于Post-LN的新方法，通过诱导代数平滑来解决深度GNN中的过平滑和深度诅咒问题，支持高达256层的网络且无需额外参数。


<details>
  <summary>Details</summary>
Motivation: 层归一化(LN)放置与过平滑现象之间的关系尚未充分探索。Pre-LN架构避免过平滑但受深度诅咒影响，而Post-LN架构绕过深度诅咒但经历过平滑，需要解决这一关键困境。

Method: 基于Post-LN提出新方法，诱导代数平滑以防止过平滑，同时避免深度诅咒。该方法无需额外参数，支持构建更深层网络。

Result: 在五个基准测试上的实证结果表明，该方法支持更深层网络（高达256层）并提升性能，无需额外参数。

Conclusion: 成功解决了LN放置的困境，提出了一种参数高效的方法，既能避免过平滑又能绕过深度诅咒，为构建更深层GNN提供了可行方案。

Abstract: The relationship between Layer Normalization (LN) placement and the over-smoothing phenomenon remains underexplored. We identify a critical dilemma: Pre-LN architectures avoid over-smoothing but suffer from the curse of depth, while Post-LN architectures bypass the curse of depth but experience over-smoothing.
  To resolve this, we propose a new method based on Post-LN that induces algebraic smoothing, preventing over-smoothing without the curse of depth. Empirical results across five benchmarks demonstrate that our approach supports deeper networks (up to 256 layers) and improves performance, requiring no additional parameters.
  Key contributions:
  Theoretical Characterization: Analysis of LN dynamics and their impact on over-smoothing and the curse of depth.
  A Principled Solution: A parameter-efficient method that induces algebraic smoothing and avoids over-smoothing and the curse of depth.
  Empirical Validation: Extensive experiments showing the effectiveness of the method in deeper GNNs.

</details>


### [7] [Differentially Private Synthetic Data Generation Using Context-Aware GANs](https://arxiv.org/abs/2512.08869)
*Anantaa Kotal,Anupam Joshi*

Main category: cs.LG

TL;DR: ContextGAN：一种上下文感知的差分隐私生成对抗网络，通过约束矩阵整合领域特定规则，生成既保护隐私又符合领域约束的高质量合成数据。


<details>
  <summary>Details</summary>
Motivation: 大数据应用引发隐私担忧，GDPR/HIPAA等法规对数据处理有严格要求。传统合成数据方法难以捕捉复杂的隐式领域规则（如医疗中的处方指南、药物相互作用），导致生成的数据可能不现实或不适用。

Method: 提出ContextGAN（上下文感知差分隐私生成对抗网络），通过约束矩阵编码显式和隐式领域知识，使用约束感知判别器评估合成数据是否符合领域规则，同时应用差分隐私保护原始数据的敏感信息。

Result: 在医疗、安全和金融领域验证表明，ContextGAN能生成高质量合成数据，既尊重领域规则又保护隐私。相比传统方法，显著提高了数据的真实性和实用性。

Conclusion: ContextGAN通过强制执行领域约束，在严格隐私保证下生成符合显式模式和隐式规则的合成数据，适用于需要同时满足隐私保护和领域合规性的应用场景。

Abstract: The widespread use of big data across sectors has raised major privacy concerns, especially when sensitive information is shared or analyzed. Regulations such as GDPR and HIPAA impose strict controls on data handling, making it difficult to balance the need for insights with privacy requirements. Synthetic data offers a promising solution by creating artificial datasets that reflect real patterns without exposing sensitive information. However, traditional synthetic data methods often fail to capture complex, implicit rules that link different elements of the data and are essential in domains like healthcare. They may reproduce explicit patterns but overlook domain-specific constraints that are not directly stated yet crucial for realism and utility. For example, prescription guidelines that restrict certain medications for specific conditions or prevent harmful drug interactions may not appear explicitly in the original data. Synthetic data generated without these implicit rules can lead to medically inappropriate or unrealistic profiles. To address this gap, we propose ContextGAN, a Context-Aware Differentially Private Generative Adversarial Network that integrates domain-specific rules through a constraint matrix encoding both explicit and implicit knowledge. The constraint-aware discriminator evaluates synthetic data against these rules to ensure adherence to domain constraints, while differential privacy protects sensitive details from the original data. We validate ContextGAN across healthcare, security, and finance, showing that it produces high-quality synthetic data that respects domain rules and preserves privacy. Our results demonstrate that ContextGAN improves realism and utility by enforcing domain constraints, making it suitable for applications that require compliance with both explicit patterns and implicit rules under strict privacy guarantees.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Scalable Back-End for an AI-Based Diabetes Prediction Application](https://arxiv.org/abs/2512.08147)
*Henry Anand Septian Radityo,Bernardus Willson,Reynard Tanadi,Latifa Dwiyanti,Saiful Akbar*

Main category: cs.AI

TL;DR: 开发了一个用于糖尿病预测移动应用的扩展性后端系统，采用水平扩展、数据库分片和消息队列异步通信，83%功能达到性能目标，支持1万并发用户。


<details>
  <summary>Details</summary>
Motivation: 全球糖尿病患病率上升需要早期检测，AI预测应用需要响应迅速且可扩展的后端架构来服务大规模用户群。

Method: 采用水平扩展、数据库分片和通过消息队列（RabbitMQ）的异步通信架构，设计可扩展的后端系统。

Result: 83%的系统功能（24个中的20个）达到性能目标（故障率<5%，平均延迟<1000ms），支持1万并发用户，异步通信有效降低了计算密集型预测请求的错误率。

Conclusion: 该可扩展后端系统成功满足了糖尿病预测应用的性能需求，验证了架构设计的有效性，特别是异步通信在保证系统可靠性方面的关键作用。

Abstract: The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While AI-powered prediction applications offer a promising solution, they require a responsive and scalable back-end architecture to serve a large user base effectively. This paper details the development and evaluation of a scalable back-end system designed for a mobile diabetes prediction application. The primary objective was to maintain a failure rate below 5% and an average latency of under 1000 ms. The architecture leverages horizontal scaling, database sharding, and asynchronous communication via a message queue. Performance evaluation showed that 83% of the system's features (20 out of 24) met the specified performance targets. Key functionalities such as user profile management, activity tracking, and read-intensive prediction operations successfully achieved the desired performance. The system demonstrated the ability to handle up to 10,000 concurrent users without issues, validating its scalability. The implementation of asynchronous communication using RabbitMQ proved crucial in minimizing the error rate for computationally intensive prediction requests, ensuring system reliability by queuing requests and preventing data loss under heavy load.

</details>


### [9] [Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems](https://arxiv.org/abs/2512.08411)
*Mingwei Li,Xiaoyuan Zhang,Chengwei Yang,Zilong Zheng,Yaodong Yang*

Main category: cs.AI

TL;DR: PRISM-WM：一种用于机器人混合动力学的结构化世界模型，通过上下文感知的专家混合框架分解复杂动态，减少长时域规划中的累积误差。


<details>
  <summary>Details</summary>
Motivation: 机器人领域中的基于模型的规划面临混合动力学的根本挑战——连续运动与离散事件（如接触、碰撞）交织。传统潜在世界模型使用全局连续的单体神经网络，不可避免地过度平滑不同的动态模式（如粘附vs滑动、飞行vs站立），导致规划器在物理边界处产生灾难性的累积误差。

Method: 提出棱镜世界模型（PRISM-WM），采用结构化架构将复杂混合动力学分解为可组合的基本单元。利用上下文感知的专家混合（MoE）框架，其中门控机制隐式识别当前物理模式，专门化的专家预测相关转移动态。引入潜在正交化目标确保专家多样性，有效防止模式崩溃。

Result: PRISM-WM通过精确建模系统动态中的尖锐模式转换，显著减少了滚动漂移。在具有挑战性的连续控制基准测试（包括高维人形机器人和多样化多任务设置）上的广泛实验表明，PRISM-WM为轨迹优化算法（如TD-MPC）提供了卓越的高保真度基础。

Conclusion: PRISM-WM通过结构化分解混合动力学，解决了传统世界模型在物理边界处的平滑问题，为下一代基于模型的智能体提供了强大的基础模型，显著提升了长时域规划的可靠性。

Abstract: Model-based planning in robotic domains is fundamentally challenged by the hybrid nature of physical dynamics, where continuous motion is punctuated by discrete events such as contacts and impacts. Conventional latent world models typically employ monolithic neural networks that enforce global continuity, inevitably over-smoothing the distinct dynamic modes (e.g., sticking vs. sliding, flight vs. stance). For a planner, this smoothing results in catastrophic compounding errors during long-horizon lookaheads, rendering the search process unreliable at physical boundaries. To address this, we introduce the Prismatic World Model (PRISM-WM), a structured architecture designed to decompose complex hybrid dynamics into composable primitives. PRISM-WM leverages a context-aware Mixture-of-Experts (MoE) framework where a gating mechanism implicitly identifies the current physical mode, and specialized experts predict the associated transition dynamics. We further introduce a latent orthogonalization objective to ensure expert diversity, effectively preventing mode collapse. By accurately modeling the sharp mode transitions in system dynamics, PRISM-WM significantly reduces rollout drift. Extensive experiments on challenging continuous control benchmarks, including high-dimensional humanoids and diverse multi-task settings, demonstrate that PRISM-WM provides a superior high-fidelity substrate for trajectory optimization algorithms (e.g., TD-MPC), proving its potential as a powerful foundational model for next-generation model-based agents.

</details>


### [10] [The SMART+ Framework for AI Systems](https://arxiv.org/abs/2512.08592)
*Laxmiraju Kandikatla,Branislav Radeljic*

Main category: cs.AI

TL;DR: SMART+框架：一个基于安全、监控、问责、可靠、透明等支柱，并增强隐私安全、数据治理、公平性、护栏的综合性AI治理框架，适用于医疗、金融、制造等多个行业。


<details>
  <summary>Details</summary>
Motivation: AI系统在各行业广泛应用（医疗、金融、制造等）提高了运营效率，但也带来了安全、问责和监管合规等新挑战，需要建立一个全面的治理框架来应对这些风险。

Method: 提出SMART+框架，该框架基于五大支柱（安全、监控、问责、可靠、透明），并增强四个关键维度（隐私与安全、数据治理、公平性与偏见、护栏），为AI系统提供结构化评估和治理模型。

Result: SMART+框架能够实现风险缓解、建立信任和合规准备，通过整合运营保障、监督程序以及强化的隐私和治理控制，为有效AI治理提供坚实基础。

Conclusion: SMART+框架为跨行业AI系统提供了实用、全面的评估和治理方法，支持负责任的AI采用并确保可审计性，特别适用于临床研究等关键领域。

Abstract: Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming finance through real-time fraud detection, automated loan risk assessment, and algorithmic decision-making. Similarly, in manufacturing, AI enables predictive maintenance to reduce equipment downtime, enhances quality control through computer-vision inspection, and optimizes production workflows using real-time operational data. While these technologies enhance operational efficiency, they introduce new challenges regarding safety, accountability, and regulatory compliance. To address these concerns, we introduce the SMART+ Framework - a structured model built on the pillars of Safety, Monitoring, Accountability, Reliability, and Transparency, and further enhanced with Privacy & Security, Data Governance, Fairness & Bias, and Guardrails. SMART+ offers a practical, comprehensive approach to evaluating and governing AI systems across industries. This framework aligns with evolving mechanisms and regulatory guidance to integrate operational safeguards, oversight procedures, and strengthened privacy and governance controls. SMART+ demonstrates risk mitigation, trust-building, and compliance readiness. By enabling responsible AI adoption and ensuring auditability, SMART+ provides a robust foundation for effective AI governance in clinical research.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation](https://arxiv.org/abs/2512.08123)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 该论文提出了一种通用对抗后缀攻击方法，通过优化短token序列（4-10个token）来降低多种任务和模型上的分类准确率，具有很好的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 语言模型作为零样本或少样本分类器时对对抗性提示很脆弱。现有方法通常针对特定任务或模型优化触发器，导致结果难以比较且迁移性有限。

Method: 使用Gumbel-Softmax松弛学习可微分的"软"后缀，然后离散化用于推理。训练时最大化标签区域的校准交叉熵，同时屏蔽黄金token防止信息泄露，并加入熵正则化避免崩溃。

Result: 单个后缀在一个模型上训练后能有效迁移到其他模型，持续降低准确率和校准置信度。在情感分析、自然语言推理、释义检测、常识问答和物理推理等任务上，对Qwen2-1.5B、Phi-1.5和TinyLlama-1.1B模型均表现出一致的攻击效果。

Conclusion: 通用对抗后缀是有效的攻击方法，能够跨任务和模型家族实现一致的攻击效果和迁移性，揭示了语言模型在对抗性攻击下的脆弱性。

Abstract: Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable "soft" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.

</details>


### [12] [Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models](https://arxiv.org/abs/2512.08480)
*Ju-Young Kim,Ji-Hong Park,Se-Yeon Lee,Sujin Park,Gun-Woo Kim*

Main category: cs.CL

TL;DR: 提出一种软归纳偏置方法，通过明确定义推理视角来指导大语言模型的推理过程，用于韩语不当言论检测，相比标准监督学习提升约3.89%的准确率。


<details>
  <summary>Details</summary>
Motivation: 在线游戏和匿名社区中不当言论常升级为言语暴力和犯罪行为，需要检测技术来构建更安全的交流环境。虽然韩语大语言模型和思维链推理受到关注，但在不当言论检测中的应用研究仍有限。

Method: 提出软归纳偏置方法，明确定义推理视角来指导推理过程，促进理性决策并防止推理错误。使用该方法对韩语大语言模型进行微调，并进行不同训练策略的定量性能比较和定性评估。

Result: Kanana-1.5模型平均准确率达到87.0046，相比标准监督学习提升约3.89%。该方法不仅模仿知识，还能通过约束推理视角实现更精确和一致的判断。

Conclusion: 提出的软归纳偏置方法通过约束推理视角，使大语言模型超越简单知识模仿，实现更精确和一致的不当言论检测，证明了该方法在不当言论检测任务中的有效性。

Abstract: Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.

</details>
