<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 12]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Food Portion Estimation: From Pixels to Calories](https://arxiv.org/abs/2602.05078)
*Gautham Vinod,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文综述了基于图像的饮食评估中食物体积估计的各种策略，包括深度图、多视角输入、模板匹配等辅助输入方法，以及深度学习在单目图像或组合输入中的应用。


<details>
  <summary>Details</summary>
Motivation: 基于图像的饮食评估对于准确便捷地监测个体健康、预防慢性疾病和肥胖至关重要，但面临从2D图像估计食物3D尺寸的挑战。

Method: 探索了多种策略：使用深度图、多视角输入等辅助输入，基于模型的模板匹配方法，以及深度学习技术（使用单目图像或图像与辅助输入的组合）。

Result: 论文综述了不同策略在准确估计食物分量方面的应用，但没有提供具体的实验结果数据。

Conclusion: 基于图像的饮食评估需要克服从2D图像估计3D食物尺寸的挑战，多种策略已被开发来应对这一关键限制，深度学习技术在其中发挥了重要作用。

Abstract: Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.

</details>


### [2] [GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling](https://arxiv.org/abs/2602.05202)
*Shivanshu Shekhar,Uttaran Bhattacharya,Raghavendra Addanki,Mehrab Tanjim,Somdeb Sarkhel,Tong Zhang*

Main category: cs.CV

TL;DR: 提出Generative-Transformer-based Self-Supervised Video Judge (GTSVJ)，将视频生成模型重新用作奖励模型，通过对比学习训练能量模型来评估视频质量，仅需3万人工标注就能达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型(VLMs)的视频奖励建模方法难以捕捉细微的时间动态。视频生成模型天生具备建模时间结构的能力，但尚未被用于奖励建模。

Method: 将视频生成模型重新构建为能量模型，通过对比目标训练，使其为高质量视频分配低能量、低质量视频分配高能量。设计具有挑战性的合成负样本视频（时间切片、特征交换、帧重排）来防止模型利用表面差异。

Result: 在GenAI-Bench和MonteBench上达到最先进性能，仅使用3万人工标注，比现有VLM方法少6-65倍数据量。

Conclusion: 视频生成模型可以有效地重新用作时间感知的奖励模型，通过对比学习和精心设计的负样本训练，能够精确评估视频质量，大大减少对人工标注的依赖。

Abstract: Aligning video generative models with human preferences remains challenging: current approaches rely on Vision-Language Models (VLMs) for reward modeling, but these models struggle to capture subtle temporal dynamics. We propose a fundamentally different approach: repurposing video generative models, which are inherently designed to model temporal structure, as reward models. We present the Generative-Transformer-based Self-Supervised Video Judge (\modelname), a novel evaluation model that transforms state-of-the-art video generation models into powerful temporally-aware reward models. Our key insight is that generative models can be reformulated as energy-based models (EBMs) that assign low energy to high-quality videos and high energy to degraded ones, enabling them to discriminate video quality with remarkable precision when trained via contrastive objectives. To prevent the model from exploiting superficial differences between real and generated videos, we design challenging synthetic negative videos through controlled latent-space perturbations: temporal slicing, feature swapping, and frame shuffling, which simulate realistic but subtle visual degradations. This forces the model to learn meaningful spatiotemporal features rather than trivial artifacts. \modelname achieves state-of-the-art performance on GenAI-Bench and MonteBench using only 30K human-annotations: $6\times$ to $65\times$ fewer than existing VLM-based approaches.

</details>


### [3] [E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching](https://arxiv.org/abs/2602.05215)
*Jiahao Nie,Wenbin An,Gongjie Zhang,Yicheng Xu,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: E.M.Ground是一种新颖的视频大语言模型，通过引入事件令牌、平滑处理和多粒度特征聚合，显著提升了时序视频定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在时序视频定位任务中，通常通过比较帧特征与两个独立令牌来匹配起始和结束帧，这种方法过度依赖精确时间戳，无法捕捉事件的语义连续性和完整性，导致定位模糊。

Method: 提出了E.M.Ground模型，包含三个关键创新：1) 引入特殊<event>令牌，聚合查询事件所有帧的信息以保持语义连续性；2) 使用Savitzky-Golay平滑减少时间戳间令牌-帧相似度的噪声；3) 采用多粒度帧特征聚合增强匹配可靠性和时序理解，补偿压缩导致的信息损失。

Result: 在基准数据集上的广泛实验表明，E.M.Ground在时序视频定位任务上持续显著优于现有的最先进视频大语言模型。

Conclusion: E.M.Ground通过关注整体和连贯的事件感知，有效解决了现有方法在时序视频定位中的语义连续性问题，为视频理解提供了更准确的时序定位能力。

Abstract: Despite recent advances in Video Large Language Models (Vid-LLMs), Temporal Video Grounding (TVG), which aims to precisely localize time segments corresponding to query events, remains a significant challenge. Existing methods often match start and end frames by comparing frame features with two separate tokens, relying heavily on exact timestamps. However, this approach fails to capture the event's semantic continuity and integrity, leading to ambiguities. To address this, we propose E.M.Ground, a novel Vid-LLM for TVG that focuses on holistic and coherent event perception. E.M.Ground introduces three key innovations: (i) a special <event> token that aggregates information from all frames of a query event, preserving semantic continuity for accurate event matching; (ii) Savitzky-Golay smoothing to reduce noise in token-to-frame similarities across timestamps, improving prediction accuracy; (iii) multi-grained frame feature aggregation to enhance matching reliability and temporal understanding, compensating for compression-induced information loss. Extensive experiments on benchmark datasets show that E.M.Ground consistently outperforms state-of-the-art Vid-LLMs by significant margins.

</details>


### [4] [SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback](https://arxiv.org/abs/2602.05380)
*Xiaoxuan He,Siming Fu,Wanli Li,Zhiyuan Li,Dacheng Yin,Kang Rong,Fengyun Rao,Bo Zhang*

Main category: cs.CV

TL;DR: SAIL框架通过自增强迭代学习，让扩散模型作为自己的老师，仅需少量人工标注偏好对就能实现对齐，无需外部奖励模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型与人类偏好的对齐面临挑战：奖励模型难以获取，大规模偏好数据集收集成本高昂。核心问题是能否仅用最少人工反馈，不依赖辅助奖励模型，通过挖掘扩散模型自身潜力实现有效对齐。

Method: 提出SAIL（自增强迭代学习）框架：从少量人工标注偏好对开始，采用闭环方式让模型逐步生成多样样本，基于其演化理解进行自标注偏好，并使用自增强数据集进行自我精炼。引入排名偏好混合策略平衡探索与初始人类先验，防止灾难性遗忘。

Result: SAIL在多个基准测试中持续优于最先进方法，仅需现有方法6%的偏好数据。实验表明扩散模型具有显著的自改进能力，当被适当利用时，可以有效替代大规模人工标注和外部奖励模型。

Conclusion: 扩散模型拥有强大的自改进能力，通过SAIL框架的闭环自增强学习，仅需最少人工反馈就能实现有效对齐，无需外部奖励模型，为扩散模型对齐提供了高效实用的解决方案。

Abstract: Aligning diffusion models with human preferences remains challenging, particularly when reward models are unavailable or impractical to obtain, and collecting large-scale preference datasets is prohibitively expensive. \textit{This raises a fundamental question: can we achieve effective alignment using only minimal human feedback, without auxiliary reward models, by unlocking the latent capabilities within diffusion models themselves?} In this paper, we propose \textbf{SAIL} (\textbf{S}elf-\textbf{A}mplified \textbf{I}terative \textbf{L}earning), a novel framework that enables diffusion models to act as their own teachers through iterative self-improvement. Starting from a minimal seed set of human-annotated preference pairs, SAIL operates in a closed-loop manner where the model progressively generates diverse samples, self-annotates preferences based on its evolving understanding, and refines itself using this self-augmented dataset. To ensure robust learning and prevent catastrophic forgetting, we introduce a ranked preference mixup strategy that carefully balances exploration with adherence to initial human priors. Extensive experiments demonstrate that SAIL consistently outperforms state-of-the-art methods across multiple benchmarks while using merely 6\% of the preference data required by existing approaches, revealing that diffusion models possess remarkable self-improvement capabilities that, when properly harnessed, can effectively replace both large-scale human annotation and external reward models.

</details>


### [5] [TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions](https://arxiv.org/abs/2602.05414)
*Ngoc Doan-Minh Huynh,Duong Nguyen-Ngoc Tran,Long Hoang Pham,Tai Huu-Phuong Tran,Hyung-Joon Jeon,Huy-Hung Nguyen,Duong Khac Vu,Hyung-Min Jeon,Son Hong Phan,Quoc Pham-Nam Ho,Chi Dai Tran,Trinh Le Ba Khanh,Jae Wook Jeon*

Main category: cs.CV

TL;DR: 该研究提出了TSBOW数据集，这是一个包含多种极端天气条件下交通监控视频的综合数据集，用于改进遮挡车辆检测，包含超过32小时真实交通数据、48,000个手动标注和320万个半标注帧。


<details>
  <summary>Details</summary>
Motivation: 全球变暖加剧了极端天气事件的频率和严重性，这些天气会降低CCTV信号和视频质量，同时扰乱交通流，增加交通事故率。现有数据集通常只包含轻度雾霾、雨雪等条件，无法捕捉极端天气情况，因此需要更全面的数据集来应对这些挑战。

Method: 研究团队收集了来自人口密集城市地区的超过32小时真实交通数据，创建了TSBOW数据集。该数据集包含超过48,000个手动标注帧和320万个半标注帧，涵盖八个交通参与者类别（从大型车辆到微移动设备和行人）。建立了对象检测基准，突出了遮挡和恶劣天气带来的挑战。

Result: TSBOW数据集成为首个全面涵盖多种年度天气场景的交通监控数据集，包含不同的道路类型、尺度和视角。研究建立了对象检测基准，展示了该数据集在推动智能交通系统发展方面的潜力。数据集已公开可用。

Conclusion: TSBOW数据集为应对极端天气条件下的交通监控挑战提供了关键资源，强调了基于CCTV的交通监控潜力，为新的研究和应用铺平了道路。该数据集公开可用，将促进智能交通系统的发展。

Abstract: Global warming has intensified the frequency and severity of extreme weather events, which degrade CCTV signal and video quality while disrupting traffic flow, thereby increasing traffic accident rates. Existing datasets, often limited to light haze, rain, and snow, fail to capture extreme weather conditions. To address this gap, this study introduces the Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions (TSBOW), a comprehensive dataset designed to enhance occluded vehicle detection across diverse annual weather scenarios. Comprising over 32 hours of real-world traffic data from densely populated urban areas, TSBOW includes more than 48,000 manually annotated and 3.2 million semi-labeled frames; bounding boxes spanning eight traffic participant classes from large vehicles to micromobility devices and pedestrians. We establish an object detection benchmark for TSBOW, highlighting challenges posed by occlusions and adverse weather. With its varied road types, scales, and viewpoints, TSBOW serves as a critical resource for advancing Intelligent Transportation Systems. Our findings underscore the potential of CCTV-based traffic monitoring, pave the way for new research and applications. The TSBOW dataset is publicly available at: https://github.com/SKKUAutoLab/TSBOW.

</details>


### [6] [NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks](https://arxiv.org/abs/2602.05423)
*Pengcheng Chen,Yue Hu,Wenhao Li,Nicole M Gunderson,Andrew Feng,Zhenglong Sun,Peter Beerel,Eric J Seibel*

Main category: cs.CV

TL;DR: NeVStereo：结合NeRF渲染与立体视觉的联合框架，从多视角RGB输入同时估计相机位姿、深度、新视角合成和表面重建，解决现有方法在几何一致性和多任务集成方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：前馈系统（如VGGT、pi3）专注于端到端匹配和几何预测但不输出新视角合成；基于神经渲染的方法能提供高质量渲染和几何细节，但通常假设固定相机位姿且对位姿误差敏感。目前缺乏一个能从随意拍摄视角同时提供准确位姿、可靠深度、高质量渲染和精确3D表面的统一框架。

Method: NeVStereo结合NeRF驱动的新视角合成与立体视觉架构：1）基于NeRF的新视角合成生成立体友好的渲染；2）置信度引导的多视角深度估计；3）NeRF耦合的束调整用于位姿优化；4）迭代优化阶段同时更新深度和辐射场以提高几何一致性。该设计缓解了NeRF常见的表面堆叠、伪影和位姿-深度耦合问题。

Result: 在室内、室外、桌面和航拍基准测试中，NeVStereo实现了一致的强零样本性能：深度误差降低达36%，位姿精度提升10.4%，新视角合成保真度提高4.5%，网格质量达到SOTA水平（F1 91.93%，Chamfer距离4.35毫米）。

Conclusion: NeVStereo成功构建了一个统一框架，能够从多视角RGB输入联合提供相机位姿、多视角深度、新视角合成和表面重建，在多个任务上均优于现有方法，解决了神经渲染与几何估计的集成挑战。

Abstract: In modern dense 3D reconstruction, feed-forward systems (e.g., VGGT, pi3) focus on end-to-end matching and geometry prediction but do not explicitly output the novel view synthesis (NVS). Neural rendering-based approaches offer high-fidelity NVS and detailed geometry from posed images, yet they typically assume fixed camera poses and can be sensitive to pose errors. As a result, it remains non-trivial to obtain a single framework that can offer accurate poses, reliable depth, high-quality rendering, and accurate 3D surfaces from casually captured views. We present NeVStereo, a NeRF-driven NVS-stereo architecture that aims to jointly deliver camera poses, multi-view depth, novel view synthesis, and surface reconstruction from multi-view RGB-only inputs. NeVStereo combines NeRF-based NVS for stereo-friendly renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and an iterative refinement stage that updates both depth and the radiance field to improve geometric consistency. This design mitigated the common NeRF-based issues such as surface stacking, artifacts, and pose-depth coupling. Across indoor, outdoor, tabletop, and aerial benchmarks, our experiments indicate that NeVStereo achieves consistently strong zero-shot performance, with up to 36% lower depth error, 10.4% improved pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm) compared to existing prestigious methods.

</details>


### [7] [Stable Velocity: A Variance Perspective on Flow Matching](https://arxiv.org/abs/2602.05435)
*Donglin Yang,Yongxing Zhang,Xin Yu,Liang Hou,Xin Tao,Pengfei Wan,Xiaojuan Qi,Renjie Liao*

Main category: cs.CV

TL;DR: 提出Stable Velocity框架，通过方差分析改进流匹配的训练和采样，在低方差区域实现2倍加速且不降低质量


<details>
  <summary>Details</summary>
Motivation: 流匹配依赖单样本条件速度导致高方差训练目标，使优化不稳定且收敛慢，需要解决这一根本问题

Method: 提出Stable Velocity框架：1) StableVM方差减少训练目标；2) VA-REPA自适应辅助监督；3) StableVS低方差区域闭式简化采样加速

Result: 在ImageNet 256×256及SD3.5、Flux等大型预训练模型上，训练效率提升，低方差区域采样加速超过2倍且质量不降

Conclusion: 通过方差分析提出的Stable Velocity框架有效解决了流匹配的方差问题，显著提升了训练稳定性和采样效率

Abstract: While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.

</details>


### [8] [Attention Retention for Continual Learning with Vision Transformers](https://arxiv.org/abs/2602.05454)
*Yue Lu,Xiangyu Zhou,Shizhou Zhang,Yinghui Xing,Guoqiang Liang,Wencong Zhang*

Main category: cs.CV

TL;DR: 提出基于注意力保持的持续学习方法，通过梯度掩码防止Vision Transformers中的注意力漂移，缓解灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 持续学习中灾难性遗忘是核心挑战，研究发现Vision Transformers中的注意力漂移是导致遗忘的主要原因，即学习新任务后对先前视觉概念的注意力发生显著偏移

Method: 提出注意力保持框架：1）使用层间展开机制提取先前任务的注意力图并生成实例自适应二进制掩码；2）学习新任务时应用这些掩码将先前注意力区域的梯度置零，防止已学习视觉概念被破坏。为兼容现代优化器，通过按比例缩放参数更新来保持相对幅度

Result: 实验和可视化表明该方法能有效缓解灾难性遗忘并保持视觉概念，在多种持续学习场景中取得最先进性能并展现出强大的泛化能力

Conclusion: 通过约束Vision Transformers中的注意力漂移，提出的注意力保持框架能有效缓解持续学习中的灾难性遗忘问题

Abstract: Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the attention to previously learned visual concepts shifts significantly after learning new tasks. Inspired by neuroscientific insights into the selective attention in the human visual system, we propose a novel attention-retaining framework to mitigate forgetting in CL. Our method constrains attention drift by explicitly modifying gradients during backpropagation through a two-step process: 1) extracting attention maps of the previous task using a layer-wise rollout mechanism and generating instance-adaptive binary masks, and 2) when learning a new task, applying these masks to zero out gradients associated with previous attention regions, thereby preventing disruption of learned visual concepts. For compatibility with modern optimizers, the gradient masking process is further enhanced by scaling parameter updates proportionally to maintain their relative magnitudes. Experiments and visualizations demonstrate the effectiveness of our method in mitigating catastrophic forgetting and preserving visual concepts. It achieves state-of-the-art performance and exhibits robust generalizability across diverse CL scenarios.

</details>


### [9] [UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos](https://arxiv.org/abs/2602.05638)
*Jinlin Wu,Felix Holm,Chuxi Chen,An Wang,Yaxin Hu,Xiaofan Ye,Zelin Zang,Miao Xu,Lihua Zhou,Huai Liao,Danny T. M. Chan,Ming Feng,Wai S. Poon,Hongliang Ren,Dong Yi,Nassir Navab,Gaofeng Meng,Jiebo Luo,Hongbin Liu,Zhen Lei*

Main category: cs.CV

TL;DR: UniSurg是一个视频原生基础模型，通过从像素级重建转向潜在运动预测，专注于手术视频的语义理解，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于基础模型的手术视频分析方法主要依赖像素级重建目标，浪费模型能力在烟雾、镜面反射、流体运动等低层次视觉细节上，而不是手术理解所需的语义结构。

Method: 基于V-JEPA架构，提出三个关键技术创新：1) 运动引导的潜在预测以优先处理语义重要区域；2) 时空亲和性自蒸馏以强制关系一致性；3) 特征多样性正则化以防止纹理稀疏手术场景中的表示崩溃。使用UniSurg-15M数据集（3,658小时视频）进行大规模预训练。

Result: 在17个基准测试中显著优于最先进方法：手术工作流识别（EgoSurgery +14.6% F1，PitVis +10.3%）、动作三元组识别（CholecT50 39.54% mAP-IVT）、技能评估、息肉分割和深度估计。

Conclusion: UniSurg建立了通用、运动导向的手术视频理解新标准，通过专注于语义运动预测而非低层次视觉细节，实现了更好的手术视频分析性能。

Abstract: While foundation models have advanced surgical video analysis, current approaches rely predominantly on pixel-level reconstruction objectives that waste model capacity on low-level visual details - such as smoke, specular reflections, and fluid motion - rather than semantic structures essential for surgical understanding. We present UniSurg, a video-native foundation model that shifts the learning paradigm from pixel-level reconstruction to latent motion prediction. Built on the Video Joint Embedding Predictive Architecture (V-JEPA), UniSurg introduces three key technical innovations tailored to surgical videos: 1) motion-guided latent prediction to prioritize semantically meaningful regions, 2) spatiotemporal affinity self-distillation to enforce relational consistency, and 3) feature diversity regularization to prevent representation collapse in texture-sparse surgical scenes. To enable large-scale pretraining, we curate UniSurg-15M, the largest surgical video dataset to date, comprising 3,658 hours of video from 50 sources across 13 anatomical regions. Extensive experiments across 17 benchmarks demonstrate that UniSurg significantly outperforms state-of-the-art methods on surgical workflow recognition (+14.6% F1 on EgoSurgery, +10.3% on PitVis), action triplet recognition (39.54% mAP-IVT on CholecT50), skill assessment, polyp segmentation, and depth estimation. These results establish UniSurg as a new standard for universal, motion-oriented surgical video understanding.

</details>


### [10] [Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing](https://arxiv.org/abs/2602.05737)
*Luca Ciampi,Ludovico Iannello,Fabrizio Tonelli,Gabriele Lagani,Angelo Di Garbo,Federico Cremisi,Giuseppe Amato*

Main category: cs.CV

TL;DR: 该研究提出了一种基于体外培养皮层神经元的生物储层计算系统，利用活体神经回路的自发和刺激诱发活动作为计算基底，通过高密度微电极阵列进行刺激和记录，实现了静态视觉模式识别任务。


<details>
  <summary>Details</summary>
Motivation: 传统储层计算依赖人工循环模型近似神经动力学，本研究旨在利用活体神经回路作为物理储层，将生物神经原理融入机器学习，探索将活体神经基质整合到神经形态计算框架中的新途径。

Method: 使用体外培养的皮层神经元网络作为物理储层，通过高密度微电极阵列同时进行刺激和记录：输入模式通过选定电极传递，其余电极捕获高维神经响应，形成生物基础的特征表示，然后训练线性读出层（单层感知器）对这些储层状态进行分类。

Result: 系统在从点到定向条、时钟数字形状到MNIST手写数字等难度递增的任务中表现出色，尽管生物神经响应存在固有变异性（噪声、自发活动和会话间差异），但系统始终能生成支持准确分类的高维表示。

Conclusion: 体外皮层网络可作为静态视觉模式识别的有效储层，为将活体神经基质整合到神经形态计算框架开辟了新途径，展示了活体神经系统如何为高效且生物基础的计算模型设计提供信息。

Abstract: In this paper, we present a neuro-inspired approach to reservoir computing (RC) in which a network of in vitro cultured cortical neurons serves as the physical reservoir. Rather than relying on artificial recurrent models to approximate neural dynamics, our biological reservoir computing (BRC) system leverages the spontaneous and stimulus-evoked activity of living neural circuits as its computational substrate. A high-density multi-electrode array (HD-MEA) provides simultaneous stimulation and readout across hundreds of channels: input patterns are delivered through selected electrodes, while the remaining ones capture the resulting high-dimensional neural responses, yielding a biologically grounded feature representation. A linear readout layer (single-layer perceptron) is then trained to classify these reservoir states, enabling the living neural network to perform static visual pattern-recognition tasks within a computer-vision framework. We evaluate the system across a sequence of tasks of increasing difficulty, ranging from pointwise stimuli to oriented bars, clock-digit-like shapes, and handwritten digits from the MNIST dataset. Despite the inherent variability of biological neural responses-arising from noise, spontaneous activity, and inter-session differences-the system consistently generates high-dimensional representations that support accurate classification. These results demonstrate that in vitro cortical networks can function as effective reservoirs for static visual pattern recognition, opening new avenues for integrating living neural substrates into neuromorphic computing frameworks. More broadly, this work contributes to the effort to incorporate biological principles into machine learning and supports the goals of neuro-inspired vision by illustrating how living neural systems can inform the design of efficient and biologically grounded computational models.

</details>


### [11] [EoCD: Encoder only Remote Sensing Change Detection](https://arxiv.org/abs/2602.05882)
*Mubashir Noman,Mustansar Fiaz,Hiyam Debary,Abdul Hannan,Shah Nawaz,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 提出EoCD方法，仅使用编码器进行变化检测，通过早期融合时间数据和参数免费的多尺度特征融合模块，显著降低模型复杂度，在性能和速度间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有变化检测方法存在两个问题：1）基于孪生编码器的方法需要分别提取时间特征再进行融合，计算成本高且模型复杂；2）早期融合方法虽然避免了孪生编码器的开销，但仍依赖复杂的解码器，且性能不如晚期融合方法。需要一种既简单又有效的方法。

Method: 提出EoCD（仅编码器变化检测）方法：1）对时间数据进行早期融合；2）用参数免费的多尺度特征融合模块替代传统解码器；3）模型性能主要依赖于编码器网络，解码器成为附加组件。

Result: 在四个具有挑战性的变化检测数据集上进行了广泛实验，EoCD在变化检测性能和预测速度之间展现出最佳平衡，证明了方法的有效性。

Conclusion: EoCD是一种简单有效的变化检测方法，通过早期融合和参数免费的特征融合模块显著降低模型复杂度，同时保持良好性能，表明模型性能主要取决于编码器而非解码器。

Abstract: Being a cornerstone of temporal analysis, change detection has been playing a pivotal role in modern earth observation. Existing change detection methods rely on the Siamese encoder to individually extract temporal features followed by temporal fusion. Subsequently, these methods design sophisticated decoders to improve the change detection performance without taking into consideration the complexity of the model. These aforementioned issues intensify the overall computational cost as well as the network's complexity which is undesirable. Alternatively, few methods utilize the early fusion scheme to combine the temporal images. These methods prevent the extra overhead of Siamese encoder, however, they also rely on sophisticated decoders for better performance. In addition, these methods demonstrate inferior performance as compared to late fusion based methods. To bridge these gaps, we introduce encoder only change detection (EoCD) that is a simple and effective method for the change detection task. The proposed method performs the early fusion of the temporal data and replaces the decoder with a parameter-free multiscale feature fusion module thereby significantly reducing the overall complexity of the model. EoCD demonstrate the optimal balance between the change detection performance and the prediction speed across a variety of encoder architectures. Additionally, EoCD demonstrate that the performance of the model is predominantly dependent on the encoder network, making the decoder an additional component. Extensive experimentation on four challenging change detection datasets reveals the effectiveness of the proposed method.

</details>


### [12] [Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028)
*Shuo Chen,Cong Wei,Sun Sun,Ping Nie,Kai Zhou,Ge Zhang,Ming-Hsuan Yang,Wenhu Chen*

Main category: cs.CV

TL;DR: 提出Context Forcing框架，通过长上下文教师训练长上下文学生模型，解决现有流式调优中的师生不匹配问题，实现超过20秒的有效上下文长度


<details>
  <summary>Details</summary>
Motivation: 现有实时长视频生成方法采用流式调优策略，用短上下文（无记忆）教师训练长上下文学生。这种结构存在师生不匹配问题：教师无法访问长期历史，无法指导学生处理全局时间依赖，限制了学生的上下文长度

Method: 提出Context Forcing框架，通过长上下文教师训练长上下文学生。引入上下文管理系统，将线性增长的上下文转换为慢-快记忆架构，显著减少视觉冗余，使极端时长（如2分钟）的训练计算可行

Result: 方法实现超过20秒的有效上下文长度，比LongLive和Infinite-RoPE等SOTA方法长2-10倍。利用扩展的上下文，Context Forcing在长时间内保持优越的一致性，在各种长视频评估指标上超越现有基线

Conclusion: Context Forcing通过消除师生监督不匹配，实现了长上下文视频生成的稳健训练，显著提升了长视频生成的时间一致性和上下文长度

Abstract: Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Multi-Aspect Mining and Anomaly Detection for Heterogeneous Tensor Streams](https://arxiv.org/abs/2602.04917)
*Soshi Kakio,Yasuko Matsubara,Ren Fujiwara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: HeteroComp：一种处理异构张量流（包含分类和连续属性）的组异常检测方法，使用高斯过程先验建模连续属性和时间动态，无需离散化时间戳。


<details>
  <summary>Details</summary>
Motivation: 现有张量分解和异常检测方法存在两个主要限制：1) 无法处理包含分类属性（如IP地址）和连续属性（如数据包长度）的异构张量流；2) 需要离散化时间戳，无法捕捉流的时间动态，导致难以检测组级异常（如DoS攻击）。

Method: 提出HeteroComp方法，将异构张量流持续汇总为表示每个属性中潜在组及其时间动态的"组件"。使用高斯过程先验建模连续属性的未知分布和时间动态，直接从数据估计概率密度。提取的组件提供简洁有效的汇总，支持准确的组异常检测。

Result: 在真实数据集上的广泛实验表明，HeteroComp在组异常检测准确率上优于最先进算法，且计算时间不依赖于数据流长度。

Conclusion: HeteroComp成功解决了异构张量流分析和组异常检测的关键挑战，通过高斯过程先验建模连续属性和时间动态，无需离散化时间戳，实现了高效准确的异常检测。

Abstract: Analysis and anomaly detection in event tensor streams consisting of timestamps and multiple attributes - such as communication logs(time, IP address, packet length)- are essential tasks in data mining. While existing tensor decomposition and anomaly detection methods provide useful insights, they face the following two limitations. (i) They cannot handle heterogeneous tensor streams, which comprises both categorical attributes(e.g., IP address) and continuous attributes(e.g., packet length). They typically require either discretizing continuous attributes or treating categorical attributes as continuous, both of which distort the underlying statistical properties of the data.Furthermore, incorrect assumptions about the distribution family of continuous attributes often degrade the model's performance. (ii) They discretize timestamps, failing to track the temporal dynamics of streams(e.g., trends, abnormal events), which makes them ineffective for detecting anomalies at the group level, referred to as 'group anomalies' (e.g, DoS attacks). To address these challenges, we propose HeteroComp, a method for continuously summarizing heterogeneous tensor streams into 'components' representing latent groups in each attribute and their temporal dynamics, and detecting group anomalies. Our method employs Gaussian process priors to model unknown distributions of continuous attributes, and temporal dynamics, which directly estimate probability densities from data. Extracted components give concise but effective summarization, enabling accurate group anomaly detection. Extensive experiments on real datasets demonstrate that HeteroComp outperforms the state-of-the-art algorithms for group anomaly detection accuracy, and its computational time does not depend on the data stream length.

</details>


### [14] [ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation](https://arxiv.org/abs/2602.05051)
*Songyuan Zhang,Oswin So,H. M. Sabbir Ahmad,Eric Yang Yu,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: ReFORM是一种基于流策略的离线强化学习方法，通过构造强制执行较宽松的支持约束，解决了离线RL中的分布外误差问题，并在OGBench基准测试中优于所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中存在两个主要挑战：1）分布外（OOD）误差问题，当策略偏离训练分布时发生；2）最优策略分布可能是多模态且难以表示。现有方法要么通过惩罚统计距离项来约束策略接近行为策略（这会限制策略改进），要么使用扩散或流策略来增强表达能力，但无法同时解决OOD误差和保持策略表达能力。

Method: ReFORM提出了一种基于流策略的离线RL方法：1）学习一个有界源分布的行为克隆（BC）流策略，以捕捉动作分布的支持集；2）优化一个反射流，为BC流生成有界噪声，同时保持支持集，以最大化性能。这种方法通过构造强制执行支持约束，而不是惩罚统计距离。

Result: 在OGBench基准测试的40个具有不同质量数据集的挑战性任务中，ReFORM使用恒定的超参数集在所有任务上，在性能曲线分析中优于所有经过手动调优超参数的基线方法。

Conclusion: ReFORM通过流策略的构造方式有效解决了离线RL中的OOD误差问题，同时保持了策略的表达能力，在多个任务上展现出优越的性能和鲁棒性。

Abstract: Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed dataset generated by behavior policies without additional environment interactions. One common challenge that arises in this setting is the out-of-distribution (OOD) error, which occurs when the policy leaves the training distribution. Prior methods penalize a statistical distance term to keep the policy close to the behavior policy, but this constrains policy improvement and may not completely prevent OOD actions. Another challenge is that the optimal policy distribution can be multimodal and difficult to represent. Recent works apply diffusion or flow policies to address this problem, but it is unclear how to avoid OOD errors while retaining policy expressiveness. We propose ReFORM, an offline RL method based on flow policies that enforces the less restrictive support constraint by construction. ReFORM learns a behavior cloning (BC) flow policy with a bounded source distribution to capture the support of the action distribution, then optimizes a reflected flow that generates bounded noise for the BC flow while keeping the support, to maximize the performance. Across 40 challenging tasks from the OGBench benchmark with datasets of varying quality and using a constant set of hyperparameters for all tasks, ReFORM dominates all baselines with hand-tuned hyperparameters on the performance profile curves.

</details>


### [15] [Constrained Group Relative Policy Optimization](https://arxiv.org/abs/2602.05863)
*Roger Girgis,Rodrigue de Schaetzen,Luke Rowe,Azalée Robitaille,Christopher Pal,Liam Paull*

Main category: cs.LG

TL;DR: 提出Constrained GRPO，一种基于拉格朗日方法的GRPO扩展，用于约束策略优化。通过标量化优势估计解决多组件优势估计导致的约束学习失效问题，在机器人任务中实现更好的约束满足和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然GRPO已成为无评论家策略学习的可扩展框架，但在具有显式行为约束的设置中扩展GRPO仍未被充分探索。需要一种简单有效的约束策略优化方法，特别是在依赖大型多模态基础模型的具身AI领域。

Method: 提出Constrained GRPO，基于拉格朗日松弛的GRPO扩展。使用指示器成本函数指定约束，通过标量化优势构造（而非多组件优势估计）保持奖励和约束项之间的预期权衡，避免标准差不匹配导致的拉格朗日信号污染。

Result: 在玩具网格世界中验证了多组件优势估计的优化病理，并证明标量化优势恢复了稳定的约束控制。在机器人任务中，Constrained GRPO提高了约束满足度，同时增加了任务成功率。

Conclusion: Constrained GRPO为约束策略优化提供了一个简单有效的方案，特别适用于日益依赖大型多模态基础模型的具身AI领域。标量化优势构造对于保持拉格朗日方法的有效性至关重要。

Abstract: While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.

</details>


### [16] [StagePilot: A Deep Reinforcement Learning Agent for Stage-Controlled Cybergrooming Simulation](https://arxiv.org/abs/2602.05060)
*Heajun An,Qi Zhang,Minqian Liu,Xinyi Zhang,Sang Won Lee,Lifu Huang,Pamela J. Wisniewski,Jin-Hee Cho*

Main category: cs.LG

TL;DR: StagePilot是一个基于离线强化学习的对话代理，用于模拟网络诱骗的阶段进展，通过分阶段对话训练进行预防教育。


<details>
  <summary>Details</summary>
Motivation: 网络诱骗对青少年构成持续威胁，需要主动的教育干预措施来预防。现有方法缺乏对诱骗行为阶段进展的模拟，需要更真实、连贯的训练工具。

Method: 提出StagePilot对话代理，使用离线强化学习模拟诱骗行为的阶段进展。采用复合奖励函数平衡用户情感和目标接近度，阶段转换限制在相邻阶段以保证真实性和可解释性。通过LLM模拟进行评估。

Result: StagePilot能生成与诱骗动态一致的现实、连贯对话。在测试方法中，IQL+AWAC代理在战略规划和情感连贯性方面达到最佳平衡，到达最终阶段的频率比基线高43%，同时保持超过70%的情感对齐。

Conclusion: StagePilot为网络诱骗预防教育提供了有效的对话模拟工具，离线强化学习方法能够平衡战略目标和情感连贯性，为青少年网络安全培训提供了新途径。

Abstract: Cybergrooming is an evolving threat to youth, necessitating proactive educational interventions. We propose StagePilot, an offline RL-based dialogue agent that simulates the stage-wise progression of grooming behaviors for prevention training. StagePilot selects conversational stages using a composite reward that balances user sentiment and goal proximity, with transitions constrained to adjacent stages for realism and interpretability. We evaluate StagePilot through LLM-based simulations, measuring stage completion, dialogue efficiency, and emotional engagement. Results show that StagePilot generates realistic and coherent conversations aligned with grooming dynamics. Among tested methods, the IQL+AWAC agent achieves the best balance between strategic planning and emotional coherence, reaching the final stage up to 43% more frequently than baselines while maintaining over 70% sentiment alignment.

</details>


### [17] [Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks](https://arxiv.org/abs/2602.05125)
*William F. Shen,Xinchi Qiu,Chenxi Whitehouse,Lisa Alazraki,Shashwat Goel,Francesco Barbieri,Timon Willi,Akhil Mathur,Ilias Leontiadis*

Main category: cs.LG

TL;DR: RRD框架通过递归分解-过滤循环优化评分标准，提升LLM评估准确性和强化微调效果


<details>
  <summary>Details</summary>
Motivation: 现有评分标准存在覆盖不足、维度混淆、偏好方向错位、冗余和高度相关等问题，导致评估准确性下降和强化微调效果不佳

Method: 提出RRD框架：递归分解粗粒度评分标准为细粒度判别性标准，通过过滤机制移除错位和冗余标准，采用相关性感知加权方案避免高度相关标准过度代表

Result: 在JudgeBench和PPE上显著提升GPT-4o和Llama3.1-405B的评估准确性（JudgeBench最高提升17.7分）；在WildChat强化微调中，奖励提升达160%（Qwen3-4B）和60%（Llama3.1-8B），优于基线10-20%的提升

Conclusion: RRD建立了可扩展、可解释的递归评分标准优化基础，为开放领域LLM评估和奖励建模提供了有效解决方案

Abstract: Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.

</details>


### [18] [Cross-talk based multi-task learning for fault classification of physically coupled machine system](https://arxiv.org/abs/2602.05146)
*Wonjun Yi,Rismaya Kumar Mishra,Yong-Hwa Park*

Main category: cs.LG

TL;DR: 该论文提出了一种基于交叉对话结构的多任务学习框架，通过联合学习故障条件和相关物理变量来提升故障分类性能，在两个基准数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 机器系统产生的信号中，故障条件与各种物理变量存在物理耦合。现有故障分类研究通常只使用直接故障标签，但信号中自然包含了其他物理耦合信息。利用这种耦合关系可以提升故障分类性能。

Method: 采用多任务学习框架，通过交叉对话结构联合学习故障条件和相关物理变量。基于先前提出的残差神经降维模型，在无人机故障数据集和电机复合故障数据集上进行测试。交叉对话结构允许任务间受控信息交换，同时防止负迁移。

Result: 在两个基准数据集上，残差神经降维模型持续优于单任务模型、合并所有标签组合的多类模型以及共享主干多任务模型。对于电机复合故障，还测试了单通道和多通道数据输入的分类性能。

Conclusion: 通过多任务学习框架利用信号中的物理耦合信息，特别是采用交叉对话结构，能够有效提升故障分类性能，优于传统方法。

Abstract: Machine systems inherently generate signals in which fault conditions and various physical variables are physically coupled. Although many existing fault classification studies rely solely on direct fault labels, the aforementioned signals naturally embed additional information shaped by other physically coupled information. Herein, we leverage this coupling through a multi-task learning (MTL) framework that jointly learns fault conditions and the related physical variables. Among MTL architectures, crosstalk structures have distinct advantages because they allow for controlled information exchange between tasks through the cross-talk layer while preventing negative transfer, in contrast to shared trunk architectures that often mix incompatible features. We build on our previously introduced residual neural dimension reductor model, and extend its application to two benchmarks where physical coupling is prominent. The first benchmark is a drone fault dataset, in which machine type and maneuvering direction significantly alter the frequency components of measured signals even under the same nominal condition. By learning fault classification together with these physical attributes, the cross-talk architecture can better classify faults. The second benchmark dataset is the motor compound fault dataset. In this system, each fault component, inner race fault, outer race fault, misalignment, and unbalance is coupled to the other. For motor compound fault, we also test classification performance when we use single-channel data or multi-channel data as input to the classifier. Across both benchmarks, our residual neural dimension reductor, consistently outperformed single-task models, multi-class models that merge all label combinations, and shared trunk multi-task models.

</details>


### [19] [Extreme Weather Nowcasting via Local Precipitation Pattern Prediction](https://arxiv.org/abs/2602.05204)
*Changhoon Song,Teng Yuan Chang,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出exPreCast框架和平衡雷达数据集，用于高效生成精细的雷达预报，在普通和极端降雨情况下均表现优异


<details>
  <summary>Details</summary>
Motivation: 极端天气准确预报对风险管理至关重要，但现有方法存在计算成本高或偏向普通降雨的问题，且基准数据集不平衡，限制了实际应用

Method: 提出exPreCast确定性框架，集成局部时空注意力、纹理保持立方双上采样解码器和时间提取器，并构建包含普通和极端降雨的平衡KMA雷达数据集

Result: 在SEVIR、MeteoNet和KMA数据集上实现最先进性能，在普通和极端降雨情况下均能提供准确可靠的临近预报

Conclusion: exPreCast框架和平衡数据集解决了现有临近预报方法的局限性，为实际应用提供了高效准确的解决方案

Abstract: Accurate forecasting of extreme weather events such as heavy rainfall or storms is critical for risk management and disaster mitigation. Although high-resolution radar observations have spurred extensive research on nowcasting models, precipitation nowcasting remains particularly challenging due to pronounced spatial locality, intricate fine-scale rainfall structures, and variability in forecasting horizons. While recent diffusion-based generative ensembles show promising results, they are computationally expensive and unsuitable for real-time applications. In contrast, deterministic models are computationally efficient but remain biased toward normal rainfall. Furthermore, the benchmark datasets commonly used in prior studies are themselves skewed--either dominated by ordinary rainfall events or restricted to extreme rainfall episodes--thereby hindering general applicability in real-world settings. In this paper, we propose exPreCast, an efficient deterministic framework for generating finely detailed radar forecasts, and introduce a newly constructed balanced radar dataset from the Korea Meteorological Administration (KMA), which encompasses both ordinary precipitation and extreme events. Our model integrates local spatiotemporal attention, a texture-preserving cubic dual upsampling decoder, and a temporal extractor to flexibly adjust forecasting horizons. Experiments on established benchmarks (SEVIR and MeteoNet) as well as on the balanced KMA dataset demonstrate that our approach achieves state-of-the-art performance, delivering accurate and reliable nowcasts across both normal and extreme rainfall regimes.

</details>


### [20] [Joint Embedding Variational Bayes](https://arxiv.org/abs/2602.05639)
*Amin Oji,Paul Fieguth*

Main category: cs.LG

TL;DR: VJE是一种结合联合嵌入和变分推理的自监督学习框架，用于学习概率表示，无需重建和非对比设置，通过对称条件证据下界优化，使用学生t分布解耦方向和径向因子。


<details>
  <summary>Details</summary>
Motivation: 现有基于能量的预测目标优化点间差异，需要重建或对比设置。VJE旨在实现重建自由、非对比的自监督概率表示学习，避免训练中的范数诱导不稳定性。

Method: VJE框架结合联合嵌入和变分推理，最大化对称条件ELBO。使用学生t分布的条件似然，通过极分解显式解耦方向和径向因子。采用摊销推理网络参数化对角高斯变分后验，特征方差与似然尺度共享以捕获各向异性不确定性。

Result: 在ImageNet-1K、CIFAR-10/100和STL-10上，VJE在线性和k-NN评估中达到与非对比基线相当的性能。在一类CIFAR-10异常检测中，基于似然的评分优于可比的自监督基线。

Conclusion: VJE成功实现了重建自由、非对比的自监督概率表示学习，通过解耦方向和径向因子解决了训练不稳定性，并在多个数据集上验证了其有效性和概率语义。

Abstract: We introduce Variational Joint Embedding (VJE), a framework that synthesizes joint embedding and variational inference to enable self-supervised learning of probabilistic representations in a reconstruction-free, non-contrastive setting. Compared to energy-based predictive objectives that optimize pointwise discrepancies, VJE maximizes a symmetric conditional evidence lower bound (ELBO) for a latent-variable model defined directly on encoder embeddings. We instantiate the conditional likelihood with a heavy-tailed Student-$t$ model using a polar decomposition that explicitly decouples directional and radial factors to prevent norm-induced instabilities during training. VJE employs an amortized inference network to parameterize a diagonal Gaussian variational posterior whose feature-wise variances are shared with the likelihood scale to capture anisotropic uncertainty without auxiliary projection heads. Across ImageNet-1K, CIFAR-10/100, and STL-10, VJE achieves performance comparable to standard non-contrastive baselines under linear and k-NN evaluation. We further validate these probabilistic semantics through one-class CIFAR-10 anomaly detection, where likelihood-based scoring under the proposed model outperforms comparable self-supervised baselines.

</details>


### [21] [Accelerating Benchmarking of Functional Connectivity Modeling via Structure-aware Core-set Selection](https://arxiv.org/abs/2602.05667)
*Ling Zhan,Zhen Li,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: 提出SCLCS方法，通过结构感知对比学习选择核心集，仅用10%数据就能保持功能连接建模方法的性能排名，解决了大规模fMRI数据集上模型评估的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模fMRI数据集上评估数百种功能连接建模方法对可重复神经科学至关重要，但模型-数据组合的爆炸式增长使得穷举评估计算上不可行，阻碍了这种评估成为常规的预分析步骤。

Method: 提出SCLCS框架：1) 使用自适应Transformer学习每个样本的独特功能连接结构；2) 引入结构扰动分数(SPS)量化训练期间学习结构的稳定性，识别代表基础连接原型的样本；3) 采用密度平衡采样策略确保核心集的结构鲁棒性和分布代表性。

Result: 在REST-meta-MDD数据集上，SCLCS仅用10%的数据就能保持真实模型排名，在排名一致性(nDCG@k)上比现有最优核心集选择方法高出23.2%。

Conclusion: 这是首个将核心集选择形式化用于功能连接算子基准测试的工作，使大规模算子比较成为计算神经科学中可行且不可或缺的部分。

Abstract: Benchmarking the hundreds of functional connectivity (FC) modeling methods on large-scale fMRI datasets is critical for reproducible neuroscience. However, the combinatorial explosion of model-data pairings makes exhaustive evaluation computationally prohibitive, preventing such assessments from becoming a routine pre-analysis step. To break this bottleneck, we reframe the challenge of FC benchmarking by selecting a small, representative core-set whose sole purpose is to preserve the relative performance ranking of FC operators. We formalize this as a ranking-preserving subset selection problem and propose Structure-aware Contrastive Learning for Core-set Selection (SCLCS), a self-supervised framework to select these core-sets. SCLCS first uses an adaptive Transformer to learn each sample's unique FC structure. It then introduces a novel Structural Perturbation Score (SPS) to quantify the stability of these learned structures during training, identifying samples that represent foundational connectivity archetypes. Finally, while SCLCS identifies stable samples via a top-k ranking, we further introduce a density-balanced sampling strategy as a necessary correction to promote diversity, ensuring the final core-set is both structurally robust and distributionally representative. On the large-scale REST-meta-MDD dataset, SCLCS preserves the ground-truth model ranking with just 10% of the data, outperforming state-of-the-art (SOTA) core-set selection methods by up to 23.2% in ranking consistency (nDCG@k). To our knowledge, this is the first work to formalize core-set selection for FC operator benchmarking, thereby making large-scale operators comparisons a feasible and integral part of computational neuroscience. Code is publicly available on https://github.com/lzhan94swu/SCLCS

</details>


### [22] [Distributional Reinforcement Learning with Diffusion Bridge Critics](https://arxiv.org/abs/2602.05783)
*Shutong Ding,Yimiao Zhou,Ke Hu,Mokai Pan,Shan Zhong,Yanwei Fu,Jingya Wang,Ye Shi*

Main category: cs.LG

TL;DR: 提出DBC方法，首次将扩散桥模型用作分布RL的critic，直接建模Q值的逆CDF，在MuJoCo基准上优于现有分布critic模型


<details>
  <summary>Details</summary>
Motivation: 现有扩散RL方法主要关注扩散策略，忽略了扩散critic。由于策略优化依赖critic，准确的价值估计比策略表达能力更重要。考虑到RL任务的随机性，critic更适合用分布模型描述。

Method: 提出扩散桥critic（DBC），直接建模Q值的逆累积分布函数（CDF），利用扩散桥的强大分布匹配能力防止价值分布坍缩为平凡高斯分布。进一步推导解析积分公式解决DBC中的离散化误差问题。

Result: 在MuJoCo机器人控制基准测试中，DBC相比之前的分布critic模型表现出优越性。

Conclusion: DBC是首个将扩散桥模型用作critic的工作，是一个即插即用组件，可集成到大多数现有RL框架中，为分布RL提供了更准确的价值估计方法。

Abstract: Recent advances in diffusion-based reinforcement learning (RL) methods have demonstrated promising results in a wide range of continuous control tasks. However, existing works in this field focus on the application of diffusion policies while leaving the diffusion critics unexplored. In fact, since policy optimization fundamentally relies on the critic, accurate value estimation is far more important than policy expressiveness. Furthermore, given the stochasticity of most reinforcement learning tasks, it has been confirmed that the critic is more appropriately depicted with a distributional model. Motivated by these points, we propose a novel distributional RL method with Diffusion Bridge Critics (DBC). DBC directly models the inverse cumulative distribution function (CDF) of the Q value. This allows us to accurately capture the value distribution and prevents it from collapsing into a trivial Gaussian distribution owing to the strong distribution-matching capability of the diffusion bridge. Moreover, we further derive an analytic integral formula to address discretization errors in DBC, which is essential in value estimation. To our knowledge, DBC is the first work to employ the diffusion bridge model as the critic. Notably, DBC is also a plug-and-play component and can be integrated into most existing RL frameworks. Experimental results on MuJoCo robot control benchmarks demonstrate the superiority of DBC compared with previous distributional critic models.

</details>


### [23] [Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference](https://arxiv.org/abs/2602.06029)
*Yingke Li,Anjali Parashar,Enlu Zhou,Chuchu Fan*

Main category: cs.LG

TL;DR: 论文为主动推理中的期望自由能最小化提供了首个理论保证，证明足够的好奇心系数能同时确保贝叶斯后验一致性和无遗憾优化，并建立了与经典贝叶斯实验设计和贝叶斯优化的理论联系。


<details>
  <summary>Details</summary>
Motivation: 主动推理通过期望自由能平衡探索（信息增益）和利用（任务性能），但缺乏理论指导：好奇心不足导致短视利用和不确定性无法解决，好奇心过强则引发不必要探索和遗憾。需要建立理论保证来确定何时能实现一致学习和高效决策。

Method: 建立理论分析框架，证明单一条件——足够的好奇心——能同时保证自洽学习（贝叶斯后验一致性）和无遗憾优化（有界累积遗憾）。分析该机制如何依赖于初始不确定性、可识别性和目标对齐，将主动推理与经典贝叶斯实验设计和贝叶斯优化统一。

Result: 首次为EFE最小化智能体提供理论保证，证明足够的好奇心能同时确保贝叶斯后验一致性和有界累积遗憾。建立了主动推理与贝叶斯实验设计、贝叶斯优化的理论联系，并将理论转化为混合学习-优化问题中调节探索-利用权衡的实用设计指南。

Conclusion: 论文为主动推理的期望自由能最小化建立了首个理论框架，证明足够的好奇心是实现一致学习和高效决策的关键，统一了主动推理与经典贝叶斯方法，并为实际应用提供了设计指导。

Abstract: Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: DemPO框架通过算法抽签构建代表性人类评分者小组，用于AI偏好对齐训练，相比传统便利样本能更好地反映多元人口价值观。


<details>
  <summary>Details</summary>
Motivation: 当前AI偏好对齐方法（如RLHF）依赖的评分者通常是便利样本，系统性过度代表某些人口群体而低估其他群体，导致AI学习到的价值观不能代表整体人口。

Method: 提出民主偏好优化（DemPO）框架，采用公民大会的算法抽签机制构建代表性评分小组。提供两种训练方案：硬小组（仅使用抽签选出的配额满足小组数据）和软小组（保留所有数据但按抽签包含概率重新加权）。

Result: 在10亿到80亿参数的Llama模型上实验，使用包含人口统计信息的公共偏好数据集和代表性美国小组制定的75条宪法条款。硬小组在六种聚合方法中始终排名第一，软小组始终优于未加权基线，且模型容量越大效果越明显。

Conclusion: 在偏好收集阶段强制执行人口代表性，而非事后校正，能产生更好地反映代表性公众价值观的模型行为。DemPO框架为构建更具代表性的AI价值观对齐提供了有效方法。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [25] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE框架通过对抗学习和指导性语言反馈，让LLM内部化推理逻辑，无需人工监督即可实现专家级推理能力


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖标量奖励存在成本高、跨领域脆弱、无法理解解决方案底层逻辑等问题，阻碍了LLM获得专家级推理能力

Method: 提出ALIVE框架，基于认知协同原则，将问题提出、解决和评判统一到单一策略模型中，通过对抗学习和指导性语言反馈让模型从原始语料中内部化评估标准

Result: 在数学推理、代码生成和一般逻辑推理基准测试中，ALIVE显著缓解了奖励信号限制，在相同数据和计算条件下获得准确率提升、跨领域泛化能力增强和更高的自我纠正率

Conclusion: ALIVE通过推理三位一体实现了能力增长的自我维持轨迹，为无需人工监督的通用推理对齐提供了可扩展的基础

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [26] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 开发数据驱动的离散事件模拟器，用于评估学校安全干预策略，特别是机器人应对枪击事件的方案，解决VR研究中需要大量参与者的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: VR是评估学校安全措施的有力工具，但需要为每个条件招募新的参与者，使得大规模或迭代评估变得困难，尤其是在需要大量训练场景的学习有效干预策略时。

Method: 开发数据驱动的离散事件模拟器（DES），将枪手移动和区域内行动建模为从VR研究中参与者行为学习的随机过程，用于评估机器人干预策略。

Result: 模拟器能够重现关键经验模式，实现可扩展的干预策略评估和学习，这些策略难以直接通过人类受试者训练。

Conclusion: 这项工作展示了一个高到中保真度的模拟工作流程，为开发和评估自主学校安全干预提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>


### [27] [Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach](https://arxiv.org/abs/2602.05533)
*Zhengyi Guo,Wenpin Tang,Renyuan Xu*

Main category: cs.AI

TL;DR: 提出基于Doob's h-transform的扩散模型条件生成框架，通过漂移修正实现硬约束条件生成，无需修改预训练分数网络，并提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用和罕见事件模拟中，需要确保生成样本以概率1满足硬约束条件，而现有的软约束或基于奖励的引导方法无法提供约束满足的保证。

Method: 基于Doob's h-transform、鞅表示和二次变差过程，提出条件扩散引导框架。通过引入包含条件函数对数梯度的显式漂移修正来引导预训练扩散模型。设计了两种基于鞅损失和鞅协变损失的离策略学习算法来估计h及其梯度。

Result: 在总变差距离和Wasserstein距离上为非渐近条件采样器提供了理论保证，明确刻画了分数近似和引导估计误差的影响。数值实验验证了方法在强制硬约束和生成罕见事件样本方面的有效性。

Conclusion: 提出的基于Doob's h-transform的条件扩散引导框架能够有效处理硬约束条件生成问题，为安全关键应用和罕见事件模拟提供了理论保证的解决方案。

Abstract: We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.

</details>


### [28] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 提出Generative Ontology框架，结合传统本体论的结构严谨性与大语言模型的创造力，通过可执行的Pydantic模式约束LLM生成，并应用于游戏设计等领域。


<details>
  <summary>Details</summary>
Motivation: 传统本体论擅长描述领域结构但无法生成新内容，而大语言模型能流畅生成但缺乏结构有效性，经常产生幻觉输出。需要结合两者的互补优势。

Method: 将领域知识编码为可执行的Pydantic模式，通过DSPy签名约束LLM生成。采用多智能体管道，为不同本体领域分配专门角色（如机制架构师、主题编织者、平衡批评家），每个智能体带有专业"焦虑"以防止浅层输出。使用检索增强生成和迭代验证确保机制与组件的一致性。

Result: 开发了GameGrammar系统，能够根据主题提示生成结构完整、可玩的桌面游戏设计，满足本体约束的同时保持真正的创造性。该模式可推广到音乐创作、软件架构、烹饪艺术等其他领域。

Conclusion: 约束不会限制创造力，反而使其成为可能。正如语法使诗歌成为可能，本体论使结构化生成成为可能。Generative Ontology为需要专业词汇、有效性约束和积累范例的领域提供了通用框架。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [29] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: 论文提出Anchored Policy Optimization (APO)方法，解决强化学习中因Recursive Space Contraction导致的搜索空间崩溃问题，通过从全局形状匹配转向支持覆盖，在保持效率的同时恢复多样性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法存在系统性病理问题——递归空间收缩(RSC)，导致有效替代方案的采样概率消失。虽然KL正则化试图缓解此问题，但其强制的形状匹配约束与正确性所需的锐化产生梯度冲突。

Method: 提出锚定策略优化(APO)，将范式从全局形状匹配转向支持覆盖。基于参考模型的高置信度支持定义安全流形，允许积极锐化以提高效率，同时在错误校正时选择性调用恢复力以防止崩溃。

Result: 在数学基准测试中，APO打破了准确性与多样性之间的权衡，显著提高了Pass@1性能，同时恢复了标准策略梯度方法通常丢失的Pass@K多样性。

Conclusion: APO作为一种梯度对齐机制，通过最大化支持覆盖实现弹性恢复，有效防止搜索空间崩溃，在保持效率的同时恢复策略多样性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [30] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 提出RLFKV框架，通过细粒度知识验证和强化学习减少金融RAG系统中的幻觉问题，提高回答与检索文档的一致性


<details>
  <summary>Details</summary>
Motivation: 金融RAG系统中，模型依赖检索文档生成准确回答，但由于金融领域的时间敏感性，模型生成的回答仍存在与检索信息矛盾的幻觉问题，需要解决这种不一致性

Method: 提出RLFKV（强化学习框架增强细粒度知识验证）方法：1）将金融回答分解为原子知识单元；2）评估每个单元的正确性计算细粒度忠实度奖励；3）为防止奖励黑客（如过于简洁的回答），加入信息量奖励，鼓励策略模型至少保留与基础模型相同的知识单元数量

Result: 在公开的FDD任务和新提出的FDD-ANT数据集上进行实验，结果显示方法带来了一致的改进，证实了方法的有效性

Conclusion: RLFKV框架通过细粒度知识验证和强化学习，有效减少了金融RAG系统中的幻觉问题，提高了回答与检索文档的一致性

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories](https://arxiv.org/abs/2602.05085)
*Sidi Lu,Zhenwen Liang,Dongyang Ma,Yan Wang,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: Locas是一种局部支持的参数化记忆机制，可与Transformer的FFN块设计兼容，支持高效持续学习，通过低秩侧向FFN风格记忆的适当初始化来防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 将测试时训练与新型参数化记忆相结合，这种记忆可以灵活地从模型参数中卸载或合并，以支持高效的持续学习。

Method: 提出Locas（局部支持的参数化记忆），共享现代Transformer中FFN块的设计，可灵活永久化到模型参数中。提供两种变体：传统两层MLP设计（理论保证更清晰）和与SOTA LLMs共享GLU-FFN结构的设计（便于附加到现有模型）。关键是通过重用模型参数、激活和/或梯度来适当初始化低秩侧向FFN风格记忆。

Result: 在PG-19整书语言建模和LoCoMo长上下文对话问答任务上验证。Locas-GLU仅需0.02%额外参数就能存储过去上下文信息，同时保持更小的上下文窗口。MMLU评估显示Locas能够将过去上下文永久化为参数知识，同时最小化模型现有内部知识的灾难性遗忘。

Conclusion: Locas展示了将过去上下文永久化为参数知识的有前景能力，同时最小化灾难性遗忘，为参数高效和计算高效的持续学习提供了有效解决方案。

Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.

</details>


### [32] [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220)
*Jinchuan Tian,Haoran Wang,Bo-Hao Su,Chien-yu Huang,Qingzheng Wang,Jiatong Shi,William Chen,Xun Gong,Siddhant Arora,Chin-Jou Li,Masao Someki,Takashi Maekaku,Yusuke Shinohara,Jin Sakuma,Chao-Han Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: Bagpiper是一个80亿参数的音频基础模型，通过丰富的自然语言描述理解物理音频信号，在600B token上预训练，实现音频理解与生成的统一，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音频基础模型通常依赖刚性、任务特定的监督，处理孤立的音频因素而非整体。相比之下，人类智能以整体方式处理音频，无缝连接物理信号与抽象认知概念以执行复杂任务。基于这一理念，需要开发能够统一理解与生成通用音频的模型。

Method: 1. 引入Bagpiper（8B参数音频基础模型），通过丰富的自然语言描述（包含转录、音频事件等关键认知概念）解释物理音频
2. 在600B token的大规模语料上进行预训练，建立原始音频与高级概念空间之间的稳健双向映射
3. 微调时采用"描述-处理"工作流程，模拟中间认知推理步骤，无需任务特定先验即可解决多样化任务

Result: 1. 在音频理解方面，Bagpiper在MMAU和AIRBench基准测试中超越了Qwen-2.5-Omni
2. 在音频生成方面，超越了CosyVoice3和TangoFlux，能够合成语音、音乐和音效的任意组合
3. 据作者所知，这是首批实现通用音频统一理解与生成的工作之一

Conclusion: Bagpiper通过将物理音频信号映射到丰富的自然语言概念空间，实现了对音频的整体处理，成功统一了音频理解与生成能力，为通用音频处理提供了新的解决方案。模型、数据和代码已公开。

Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.

</details>


### [33] [CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs](https://arxiv.org/abs/2602.05258)
*Haoran Li,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CL

TL;DR: CoPE通过软裁剪RoPE的低频分量，统一了OOD缓解和语义建模两个目标，在长度泛化上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有的RoPE适应方法主要分为两类：OOD缓解和语义建模，但这两类方法看似目标不同。本文旨在通过一个简洁的干预来统一这两个目标。

Method: 提出CoPE（软裁剪位置编码），通过软裁剪RoPE的低频分量来同时消除OOD异常值、精炼语义信号，并防止硬裁剪引起的频谱泄漏。

Result: 实验表明，简单地将软裁剪策略应用于RoPE就能带来显著的性能提升，可扩展到256k上下文长度，在长度泛化上达到新的SOTA水平。

Conclusion: CoPE通过软裁剪RoPE低频分量的简约干预，成功统一了OOD缓解和语义建模两个看似不同的目标，为长度泛化提供了新的有效方法。

Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.

</details>


### [34] [Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions](https://arxiv.org/abs/2602.05932)
*Léo Labat,Etienne Ollion,François Yvon*

Main category: cs.CL

TL;DR: 研究多语言大语言模型在价值导向多选题上的跨语言一致性，发现大型指令微调模型整体一致性较高，但某些问题仍存在语言特异性行为。


<details>
  <summary>Details</summary>
Motivation: 虽然多语言性对LLM事实回忆的影响已有研究，但价值导向多选题中的语言诱导变异尚未充分探索。本研究旨在探究多语言LLM在价值导向多选题上是否具有跨语言一致性，还是像多个单语模型一样表现出语言依赖性。

Method: 发布新的多语言欧洲价值观调查（MEVS）语料库，包含8种欧洲语言的人工翻译调查问题。对30多个多语言LLM进行测试，控制提示变量（答案顺序、符号类型、尾部字符），分析跨语言一致性。

Result: 大型指令微调模型整体一致性较高，但响应稳健性因问题而异：某些问题在模型内外完全一致，而其他问题导致LLM答案分裂。所有一致的指令微调模型在某些问题上都表现出语言特异性行为。

Conclusion: 多语言LLM在价值导向多选题上并非完全一致的理论多语者，而是在某些问题上表现出语言依赖性，需要进一步研究偏好微调的选择性效应。

Abstract: Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [35] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: VLN-Pilot是一个基于大型视觉语言模型（VLLM）的无人机室内导航框架，让VLLM充当人类飞行员角色，通过自然语言指令和视觉感知实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则或几何路径规划的无人机导航方法需要大量特定任务工程，缺乏语义理解和上下文感知能力。室内GPS受限环境需要更智能、更人性化的控制方式。

Method: 利用VLLM的多模态推理能力，将自由形式的自然语言指令与视觉观察相结合，进行轨迹规划和执行。框架整合语言驱动的语义理解与视觉感知，支持空间关系推理、避障和动态反应。

Result: 在定制的逼真室内仿真基准测试中，VLLM驱动的智能体在复杂指令跟随任务上取得高成功率，包括具有多个语义目标的长期导航任务。

Conclusion: VLLM为基础的飞行员有望替代远程无人机操作员，显著降低操作员工作量，提高室内受限环境中的安全性和任务灵活性，为检查、搜救、设施监控等任务提供可扩展的人性化控制方案。

Abstract: This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.

</details>


### [36] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出一种简约的神经形态控制框架，通过动态神经元群体将视觉目标激励直接转换为自我中心运动指令，利用动态分岔机制解决导航中的犹豫问题


<details>
  <summary>Details</summary>
Motivation: 机器人导航长期面临反应式传感器控制与基于模型规划器之间的协调问题，特别是在目标选项无明显优势时，反应式系统难以打破对称性而陷入犹豫，需要避免计算密集的规划器

Method: 使用神经形态控制框架，将机载摄像头图像像素编码为动态神经元群体的输入，直接将视觉目标激励转换为自我中心运动指令；采用动态分岔机制延迟决策直到环境几何诱导的临界点出现

Result: 在仿真环境和实验四旋翼平台上验证了该方法的有效性，实现了实时自主性、最小计算负担、少量可解释参数，并能与特定应用的图像处理流程无缝集成

Conclusion: 该神经形态控制器受动物认知和意见动态机制模型启发，成功弥合了反应式控制与规划能力之间的鸿沟，为视觉引导导航和跟踪提供了简约有效的解决方案

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>
