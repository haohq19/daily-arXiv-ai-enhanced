<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.02200)
*Xiao Wang,Jingtao Jiang,Qiang Chen,Lan Chen,Lin Zhu,Yaowei Wang,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 提出了一种基于事件流的场景文本识别框架ESTR-CoT，通过链式思维推理增强识别效果，解决了现有方法在解释性和逻辑推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低光照、快速运动等极端场景下表现不佳，且缺乏解释性和逻辑推理能力。

Method: 采用EVA-CLIP视觉编码器和Vicuna-7B大语言模型，结合Q-former对齐视觉与语言特征，并通过监督微调优化。

Result: 在三个基准数据集上验证了框架的有效性和解释性。

Conclusion: ESTR-CoT在事件流场景文本识别中表现出色，并提供了可解释的推理过程。

Abstract: Event stream based scene text recognition is a newly arising research topic
in recent years which performs better than the widely used RGB cameras in
extremely challenging scenarios, especially the low illumination, fast motion.
Existing works either adopt end-to-end encoder-decoder framework or large
language models for enhanced recognition, however, they are still limited by
the challenges of insufficient interpretability and weak contextual logical
reasoning. In this work, we propose a novel chain-of-thought reasoning based
event stream scene text recognition framework, termed ESTR-CoT. Specifically,
we first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input
event stream into tokens and utilize a Llama tokenizer to encode the given
generation prompt. A Q-former is used to align the vision token to the
pre-trained large language model Vicuna-7B and output both the answer and
chain-of-thought (CoT) reasoning process simultaneously. Our framework can be
optimized using supervised fine-tuning in an end-to-end manner. In addition, we
also propose a large-scale CoT dataset to train our framework via a three stage
processing (i.e., generation, polish, and expert verification). This dataset
provides a solid data foundation for the development of subsequent
reasoning-based large models. Extensive experiments on three event stream STR
benchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the
effectiveness and interpretability of our proposed framework. The source code
and pre-trained models will be released on
https://github.com/Event-AHU/ESTR-CoT.

</details>


### [2] [Understanding Trade offs When Conditioning Synthetic Data](https://arxiv.org/abs/2507.02217)
*Brandon Trabucco,Qasim Wani,Benjamin Pikus,Vasu Sharma*

Main category: cs.CV

TL;DR: 论文研究了在少量图像数据下学习鲁棒物体检测器的挑战，比较了两种扩散模型的条件策略（提示和布局），发现布局条件在多样性高时更优，能显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 工业视觉系统中高质量训练数据收集耗时，合成数据成为关键解决方案，但现有方法生成慢且仿真与真实差距大。扩散模型虽高效，但精确控制困难。

Method: 研究80个视觉概念，比较提示条件和布局条件两种策略，分析其对合成数据质量的影响。

Result: 布局条件在多样性高时表现更优，匹配完整训练分布时，合成数据使平均精度提升34%，最高达177%。

Conclusion: 布局条件在多样性高时优于提示条件，合成数据能显著提升物体检测性能。

Abstract: Learning robust object detectors from only a handful of images is a critical
challenge in industrial vision systems, where collecting high quality training
data can take months. Synthetic data has emerged as a key solution for data
efficient visual inspection and pick and place robotics. Current pipelines rely
on 3D engines such as Blender or Unreal, which offer fine control but still
require weeks to render a small dataset, and the resulting images often suffer
from a large gap between simulation and reality. Diffusion models promise a
step change because they can generate high quality images in minutes, yet
precise control, especially in low data regimes, remains difficult. Although
many adapters now extend diffusion beyond plain text prompts, the effect of
different conditioning schemes on synthetic data quality is poorly understood.
We study eighty diverse visual concepts drawn from four standard object
detection benchmarks and compare two conditioning strategies: prompt based and
layout based. When the set of conditioning cues is narrow, prompt conditioning
yields higher quality synthetic data; as diversity grows, layout conditioning
becomes superior. When layout cues match the full training distribution,
synthetic data raises mean average precision by an average of thirty four
percent and by as much as one hundred seventy seven percent compared with using
real data alone.

</details>


### [3] [MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement](https://arxiv.org/abs/2507.02270)
*Fanghai Yi,Zehong Zheng,Zexiao Liang,Yihang Dong,Xiyang Fang,Wangyu Wu,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出了一种名为MAC-Lookup的模型，通过改进颜色准确性、清晰度和对比度来增强水下图像质量。


<details>
  <summary>Details</summary>
Motivation: 水下图像因光线变化、水体浑浊和气泡等问题存在可见性和颜色失真，传统方法效果不佳，且深度学习缺乏高质量数据集。

Method: 采用多轴条件查找（MAC-Lookup）模型，包括条件3D查找表颜色校正（CLTCC）和多轴自适应增强（MAAE）模块。

Result: 实验表明，MAC-Lookup在恢复细节和颜色方面优于现有方法。

Conclusion: MAC-Lookup有效解决了水下图像增强问题，避免了过度增强和饱和现象。

Abstract: Enhancing underwater images is crucial for exploration. These images face
visibility and color issues due to light changes, water turbidity, and bubbles.
Traditional prior-based methods and pixel-based methods often fail, while deep
learning lacks sufficient high-quality datasets. We introduce the Multi-Axis
Conditional Lookup (MAC-Lookup) model, which enhances visual quality by
improving color accuracy, sharpness, and contrast. It includes Conditional 3D
Lookup Table Color Correction (CLTCC) for preliminary color and quality
correction and Multi-Axis Adaptive Enhancement (MAAE) for detail refinement.
This model prevents over-enhancement and saturation while handling underwater
challenges. Extensive experiments show that MAC-Lookup excels in enhancing
underwater images by restoring details and colors better than existing methods.
The code is https://github.com/onlycatdoraemon/MAC-Lookup.

</details>


### [4] [Lightweight Shrimp Disease Detection Research Based on YOLOv8n](https://arxiv.org/abs/2507.02354)
*Fei Yuhuan,Wang Gengchen,Liu Fenghao,Zang Ran,Sun Xufei,Chang Hao*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLOv8n的轻量级网络架构，用于虾病智能检测，通过优化检测头和引入自注意力机制，显著提升了检测效率和精度。


<details>
  <summary>Details</summary>
Motivation: 虾病是虾养殖中经济损失的主要原因之一，亟需高效智能的检测方法以减少疾病传播。

Method: 设计了RLDD检测头和C2f-EMCM模块以降低计算复杂度，并引入改进的SegNext_Attention自注意力机制增强特征提取能力。

Result: 模型参数减少32.3%，mAP@0.5达92.7%（比YOLOv8n提升3%），并在泛化测试中表现更优。

Conclusion: 该方法在精度和效率间取得平衡，为虾病智能检测提供了可靠技术支持。

Abstract: Shrimp diseases are one of the primary causes of economic losses in shrimp
aquaculture. To prevent disease transmission and enhance intelligent detection
efficiency in shrimp farming, this paper proposes a lightweight network
architecture based on YOLOv8n. First, by designing the RLDD detection head and
C2f-EMCM module, the model reduces computational complexity while maintaining
detection accuracy, improving computational efficiency. Subsequently, an
improved SegNext_Attention self-attention mechanism is introduced to further
enhance the model's feature extraction capability, enabling more precise
identification of disease characteristics. Extensive experiments, including
ablation studies and comparative evaluations, are conducted on a
self-constructed shrimp disease dataset, with generalization tests extended to
the URPC2020 dataset. Results demonstrate that the proposed model achieves a
32.3% reduction in parameters compared to the original YOLOv8n, with a mAP@0.5
of 92.7% (3% improvement over YOLOv8n). Additionally, the model outperforms
other lightweight YOLO-series models in mAP@0.5, parameter count, and model
size. Generalization experiments on the URPC2020 dataset further validate the
model's robustness, showing a 4.1% increase in mAP@0.5 compared to YOLOv8n. The
proposed method achieves an optimal balance between accuracy and efficiency,
providing reliable technical support for intelligent disease detection in
shrimp aquaculture.

</details>


### [5] [Determination Of Structural Cracks Using Deep Learning Frameworks](https://arxiv.org/abs/2507.02416)
*Subhasis Dasgupta,Jaydip Sen,Tuhina Halder*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的残差U-Net集成模型，用于提高结构裂缝检测的准确性和效率，其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 手动检测结构裂缝存在效率低、一致性差和人为错误的问题，需要更可靠的自动化解决方案。

Method: 研究采用残差U-Net模型的不同配置，并将其集成到一个包含卷积块的元模型中，以提升预测效率。

Result: 集成模型在IoU和DICE系数上表现最佳，尤其在低分辨率图像中优于SegNet和传统U-Net。

Conclusion: 该研究为结构缺陷监测任务提供了更可靠的自动化系统解决方案。

Abstract: Structural crack detection is a critical task for public safety as it helps
in preventing potential structural failures that could endanger lives. Manual
detection by inexperienced personnel can be slow, inconsistent, and prone to
human error, which may compromise the reliability of assessments. The current
study addresses these challenges by introducing a novel deep-learning
architecture designed to enhance the accuracy and efficiency of structural
crack detection. In this research, various configurations of residual U-Net
models were utilized. These models, due to their robustness in capturing fine
details, were further integrated into an ensemble with a meta-model comprising
convolutional blocks. This unique combination aimed to boost prediction
efficiency beyond what individual models could achieve. The ensemble's
performance was evaluated against well-established architectures such as SegNet
and the traditional U-Net. Results demonstrated that the residual U-Net models
outperformed their predecessors, particularly with low-resolution imagery, and
the ensemble model exceeded the performance of individual models, proving it as
the most effective. The assessment was based on the Intersection over Union
(IoU) metric and DICE coefficient. The ensemble model achieved the highest
scores, signifying superior accuracy. This advancement suggests way for more
reliable automated systems in structural defects monitoring tasks.

</details>


### [6] [CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios](https://arxiv.org/abs/2507.02479)
*Teng Fu,Yuwen Chen,Zhuofan Chen,Mengyang Zhao,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 提出一个名为CrowdTrack的大规模复杂场景多行人跟踪数据集，弥补现有数据集的不足，并测试了多种先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有多行人跟踪数据集场景简单且不真实，难以支持复杂场景下的算法研究。

Method: 构建了一个包含33个视频、5,185条轨迹的第一人称视角数据集，标注完整边界框和唯一ID。

Result: 数据集为复杂场景下的算法开发提供了平台，并测试了多种先进模型的性能。

Conclusion: CrowdTrack数据集填补了复杂场景数据集的空白，推动了多行人跟踪算法的研究。

Abstract: Multi-object tracking is a classic field in computer vision. Among them,
pedestrian tracking has extremely high application value and has become the
most popular research category. Existing methods mainly use motion or
appearance information for tracking, which is often difficult in complex
scenarios. For the motion information, mutual occlusions between objects often
prevent updating of the motion state; for the appearance information,
non-robust results are often obtained due to reasons such as only partial
visibility of the object or blurred images. Although learning how to perform
tracking in these situations from the annotated data is the simplest solution,
the existing MOT dataset fails to satisfy this solution. Existing methods
mainly have two drawbacks: relatively simple scene composition and
non-realistic scenarios. Although some of the video sequences in existing
dataset do not have the above-mentioned drawbacks, the number is far from
adequate for research purposes. To this end, we propose a difficult large-scale
dataset for multi-pedestrian tracking, shot mainly from the first-person view
and all from real-life complex scenarios. We name it ``CrowdTrack'' because
there are numerous objects in most of the sequences. Our dataset consists of 33
videos, containing a total of 5,185 trajectories. Each object is annotated with
a complete bounding box and a unique object ID. The dataset will provide a
platform to facilitate the development of algorithms that remain effective in
complex situations. We analyzed the dataset comprehensively and tested multiple
SOTA models on our dataset. Besides, we analyzed the performance of the
foundation models on our dataset. The dataset and project code is released at:
https://github.com/loseevaya/CrowdTrack .

</details>


### [7] [APT: Adaptive Personalized Training for Diffusion Models with Limited Data](https://arxiv.org/abs/2507.02687)
*JungWoo Chae,Jiyoon Kim,JaeWoong Choi,Kyungyul Kim,Sangheum Hwang*

Main category: cs.CV

TL;DR: APT框架通过自适应训练策略和正则化方法，解决了扩散模型在有限数据下个性化训练中的过拟合问题，保持了先验知识和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在有限数据下个性化训练时出现的过拟合、先验知识丢失和文本对齐退化问题。

Method: APT框架包含三个关键组件：自适应训练调整、表示稳定化和注意力对齐，分别通过检测过拟合、正则化特征图和保持注意力图一致性来优化训练。

Result: 实验表明，APT能有效减少过拟合，保持先验知识，并在有限参考数据下生成高质量、多样化的图像。

Conclusion: APT为有限数据下的扩散模型个性化训练提供了一种有效的解决方案，显著提升了生成图像的质量和多样性。

Abstract: Personalizing diffusion models using limited data presents significant
challenges, including overfitting, loss of prior knowledge, and degradation of
text alignment. Overfitting leads to shifts in the noise prediction
distribution, disrupting the denoising trajectory and causing the model to lose
semantic coherence. In this paper, we propose Adaptive Personalized Training
(APT), a novel framework that mitigates overfitting by employing adaptive
training strategies and regularizing the model's internal representations
during fine-tuning. APT consists of three key components: (1) Adaptive Training
Adjustment, which introduces an overfitting indicator to detect the degree of
overfitting at each time step bin and applies adaptive data augmentation and
adaptive loss weighting based on this indicator; (2)Representation
Stabilization, which regularizes the mean and variance of intermediate feature
maps to prevent excessive shifts in noise prediction; and (3) Attention
Alignment for Prior Knowledge Preservation, which aligns the cross-attention
maps of the fine-tuned model with those of the pretrained model to maintain
prior knowledge and semantic coherence. Through extensive experiments, we
demonstrate that APT effectively mitigates overfitting, preserves prior
knowledge, and outperforms existing methods in generating high-quality, diverse
images with limited reference data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations](https://arxiv.org/abs/2507.02227)
*Xinquan Huang,Paris Perdikaris*

Main category: cs.LG

TL;DR: PhysicsCorrect是一种无需训练的校正框架，通过基于PDE残差的线性化逆问题，在每一步预测中强制PDE一致性，显著减少神经网络在长期预测中的误差累积。


<details>
  <summary>Details</summary>
Motivation: 神经网络作为PDE求解器的替代方法存在长期预测误差累积的问题，导致结果偏离物理有效解。

Method: 提出PhysicsCorrect框架，利用离线预计算Jacobian及其伪逆的高效缓存策略，降低计算开销。

Result: 在Navier-Stokes流体动力学、波动方程和混沌Kuramoto-Sivashinsky方程中，预测误差减少高达100倍，推理时间增加不到5%。

Conclusion: PhysicsCorrect将不稳定的神经网络替代工具转化为可靠的仿真工具，结合深度学习的高效计算和物理保真度。

Abstract: Neural networks have emerged as powerful surrogates for solving partial
differential equations (PDEs), offering significant computational speedups over
traditional methods. However, these models suffer from a critical limitation:
error accumulation during long-term rollouts, where small inaccuracies compound
exponentially, eventually causing complete divergence from physically valid
solutions. We present PhysicsCorrect, a training-free correction framework that
enforces PDE consistency at each prediction step by formulating correction as a
linearized inverse problem based on PDE residuals. Our key innovation is an
efficient caching strategy that precomputes the Jacobian and its pseudoinverse
during an offline warm-up phase, reducing computational overhead by two orders
of magnitude compared to standard correction approaches. Across three
representative PDE systems -- Navier-Stokes fluid dynamics, wave equations, and
the chaotic Kuramoto-Sivashinsky equation -- PhysicsCorrect reduces prediction
errors by up to 100x while adding negligible inference time (under 5\%). The
framework integrates seamlessly with diverse architectures including Fourier
Neural Operators, UNets, and Vision Transformers, effectively transforming
unstable neural surrogates into reliable simulation tools that bridge the gap
between deep learning's computational efficiency and the physical fidelity
demanded by practical scientific applications.

</details>


### [9] [L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation](https://arxiv.org/abs/2507.02619)
*Hazal Mogultay Ozcan,Sinan Kalkan,Fatos T. Yarman-Vural*

Main category: cs.LG

TL;DR: L-VAE是一种可学习变分自编码器，通过动态调整损失函数的权重和模型参数，有效平衡了解缠和重构损失，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决β-VAE中超参数η需手动调整的问题，实现动态权衡解缠与重构损失。

Method: 提出L-VAE模型，学习损失函数权重和模型参数，并添加正则化项防止偏差。

Result: 在多个数据集上表现优异，平衡了解缠和重构性能，定性实验验证了其有效性。

Conclusion: L-VAE在解缠表示学习中具有显著优势，为未来研究提供了新方向。

Abstract: In this paper, we propose a novel model called Learnable VAE (L-VAE), which
learns a disentangled representation together with the hyperparameters of the
cost function. L-VAE can be considered as an extension of \b{eta}-VAE, wherein
the hyperparameter, \b{eta}, is empirically adjusted. L-VAE mitigates the
limitations of \b{eta}-VAE by learning the relative weights of the terms in the
loss function to control the dynamic trade-off between disentanglement and
reconstruction losses. In the proposed model, the weight of the loss terms and
the parameters of the model architecture are learned concurrently. An
additional regularization term is added to the loss function to prevent bias
towards either reconstruction or disentanglement losses. Experimental analyses
show that the proposed L-VAE finds an effective balance between reconstruction
fidelity and disentangling the latent dimensions. Comparisons of the proposed
L-VAE against \b{eta}-VAE, VAE, ControlVAE, DynamicVAE, and {\sigma}-VAE on
datasets, such as dSprites, MPI3D-complex, Falcor3D, and Isaac3D reveals that
L-VAE consistently provides the best or the second best performances measured
by a set of disentanglement metrics. Moreover, qualitative experiments on
CelebA dataset, confirm the success of the L-VAE model for disentangling the
facial attributes.

</details>


### [10] [In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization](https://arxiv.org/abs/2507.02807)
*Thiti Suttaket,Stanley Kok*

Main category: cs.LG

TL;DR: GRADUATE模型通过多校准优化解决生存分析中少数子群体校准不足的问题，平衡校准与判别性能。


<details>
  <summary>Details</summary>
Motivation: 现有生存模型通常仅在群体层面校准，可能导致少数子群体校准不佳，影响临床决策。

Method: GRADUATE将多校准问题转化为约束优化，同时在训练中优化校准与判别性能。

Result: 实验证明GRADUATE优于现有基线，数学上证明了其优化方法的可行性和近优性。

Conclusion: GRADUATE在多校准和性能平衡方面表现出色，解决了现有模型的局限性。

Abstract: Survival analysis is an important problem in healthcare because it models the
relationship between an individual's covariates and the onset time of an event
of interest (e.g., death). It is important for survival models to be
well-calibrated (i.e., for their predicted probabilities to be close to
ground-truth probabilities) because badly calibrated systems can result in
erroneous clinical decisions. Existing survival models are typically calibrated
at the population level only, and thus run the risk of being poorly calibrated
for one or more minority subpopulations. We propose a model called GRADUATE
that achieves multicalibration by ensuring that all subpopulations are
well-calibrated too. GRADUATE frames multicalibration as a constrained
optimization problem, and optimizes both calibration and discrimination
in-training to achieve a good balance between them. We mathematically prove
that the optimization method used yields a solution that is both near-optimal
and feasible with high probability. Empirical comparisons against
state-of-the-art baselines on real-world clinical datasets demonstrate
GRADUATE's efficacy. In a detailed analysis, we elucidate the shortcomings of
the baselines vis-a-vis GRADUATE's strengths.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](https://arxiv.org/abs/2507.02197)
*Amogh Mannekote,Adam Davies,Guohao Li,Kristy Elizabeth Boyer,ChengXiang Zhai,Bonnie J Dorr,Francesco Pinto*

Main category: cs.AI

TL;DR: 研究探讨了基于LLM的角色扮演代理在生成合成数据时，其陈述的信念与实际行为之间的一致性，并提出了评估框架和一致性度量。


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为角色扮演代理用于人类行为研究，确保其输出与角色一致成为关键问题。

Method: 建立评估框架，使用增强版GenAgents角色库和信任游戏，引入信念-行为一致性度量，分析影响因素。

Result: 发现LLM的陈述信念与模拟行为存在系统性不一致，即使信念看似合理，也可能无法一致应用。

Conclusion: 需明确LLM信念与行为何时一致，以在行为研究中正确使用LLM代理。

Abstract: As LLMs are increasingly studied as role-playing agents to generate synthetic
data for human behavioral research, ensuring that their outputs remain coherent
with their assigned roles has become a critical concern. In this paper, we
investigate how consistently LLM-based role-playing agents' stated beliefs
about the behavior of the people they are asked to role-play ("what they say")
correspond to their actual behavior during role-play ("how they act").
Specifically, we establish an evaluation framework to rigorously measure how
well beliefs obtained by prompting the model can predict simulation outcomes in
advance. Using an augmented version of the GenAgents persona bank and the Trust
Game (a standard economic game used to quantify players' trust and
reciprocity), we introduce a belief-behavior consistency metric to
systematically investigate how it is affected by factors such as: (1) the types
of beliefs we elicit from LLMs, like expected outcomes of simulations versus
task-relevant attributes of individual characters LLMs are asked to simulate;
(2) when and how we present LLMs with relevant information about Trust Game;
and (3) how far into the future we ask the model to forecast its actions. We
also explore how feasible it is to impose a researcher's own theoretical priors
in the event that the originally elicited beliefs are misaligned with research
objectives. Our results reveal systematic inconsistencies between LLMs' stated
(or imposed) beliefs and the outcomes of their role-playing simulation, at both
an individual- and population-level. Specifically, we find that, even when
models appear to encode plausible beliefs, they may fail to apply them in a
consistent way. These findings highlight the need to identify how and when
LLMs' stated beliefs align with their simulated behavior, allowing researchers
to use LLM-based agents appropriately in behavioral studies.

</details>


### [12] [Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search](https://arxiv.org/abs/2507.02652)
*Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yang Zhao,Hongjin Qian,Zhicheng Dou*

Main category: cs.AI

TL;DR: HiRA框架通过分层规划与执行，显著提升了复杂搜索任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）和基于推理的方法在复杂信息需求中表现不佳，主要因为单一模型同时处理高层规划和细节执行。

Method: HiRA采用分层框架，将任务分解为子任务，由领域特定代理处理，并通过结构化机制协调结果。

Result: 在四个复杂跨模态搜索基准测试中，HiRA显著优于现有RAG和基于代理的系统。

Conclusion: 分层规划与执行分离有效提升了多步信息搜索任务的质量和效率。

Abstract: Complex information needs in real-world search scenarios demand deep
reasoning and knowledge synthesis across diverse sources, which traditional
retrieval-augmented generation (RAG) pipelines struggle to address effectively.
Current reasoning-based approaches suffer from a fundamental limitation: they
use a single model to handle both high-level planning and detailed execution,
leading to inefficient reasoning and limited scalability. In this paper, we
introduce HiRA, a hierarchical framework that separates strategic planning from
specialized execution. Our approach decomposes complex search tasks into
focused subtasks, assigns each subtask to domain-specific agents equipped with
external tools and reasoning capabilities, and coordinates the results through
a structured integration mechanism. This separation prevents execution details
from disrupting high-level reasoning while enabling the system to leverage
specialized expertise for different types of information processing.
Experiments on four complex, cross-modal deep search benchmarks demonstrate
that HiRA significantly outperforms state-of-the-art RAG and agent-based
systems. Our results show improvements in both answer quality and system
efficiency, highlighting the effectiveness of decoupled planning and execution
for multi-step information seeking tasks. Our code is available at
https://github.com/ignorejjj/HiRA.

</details>


### [13] [Time-critical and confidence-based abstraction dropping methods](https://arxiv.org/abs/2507.02703)
*Robin Schmöcker,Lennart Kampmann,Alexander Dockhorn*

Main category: cs.AI

TL;DR: 论文提出了两种新的抽象丢弃方案（OGA-IAAD和OGA-CAD），用于改进蒙特卡洛树搜索（MCTS）性能，且不会导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 非精确抽象在MCTS中引入近似误差，导致无法收敛到最优动作，因此需要设计安全的抽象丢弃方案。

Method: 提出了两种抽象丢弃方案：OGA-IAAD（适用于时间关键场景）和OGA-CAD（旨在相同迭代次数下提升MCTS性能）。

Result: 两种方案均能显著提升性能，且不会引起性能下降。

Conclusion: OGA-IAAD和OGA-CAD是安全且有效的抽象丢弃方案，适用于不同场景。

Abstract: One paradigm of Monte Carlo Tree Search (MCTS) improvements is to build and
use state and/or action abstractions during the tree search. Non-exact
abstractions, however, introduce an approximation error making convergence to
the optimal action in the abstract space impossible. Hence, as proposed as a
component of Elastic Monte Carlo Tree Search by Xu et al., abstraction
algorithms should eventually drop the abstraction. In this paper, we propose
two novel abstraction dropping schemes, namely OGA-IAAD and OGA-CAD which can
yield clear performance improvements whilst being safe in the sense that the
dropping never causes any notable performance degradations contrary to Xu's
dropping method. OGA-IAAD is designed for time critical settings while OGA-CAD
is designed to improve the MCTS performance with the same number of iterations.

</details>
