<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 11]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Can World Simulators Reason? Gen-ViRe: A Generative Visual Reasoning Benchmark](https://arxiv.org/abs/2511.13853)
*Xinxin Liu,Zhaopan Xu,Kai Wang,Yong Jae Lee,Yuzhang Shang*

Main category: cs.CV

TL;DR: Gen-ViRe是一个新的视觉推理基准测试框架，用于评估视频生成模型作为世界模拟器的推理能力，填补了现有基准测试在链式帧推理评估方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成基准测试主要关注保真度或对齐度，无法评估链式帧推理的核心认知能力，如多步规划、算法逻辑和抽象模式推断，这阻碍了对模型能力的系统理解和改进指导。

Method: 基于认知科学和实际AI应用，将链式帧推理分解为6个认知维度和24个子任务，通过多源数据整理、最小提示协议和混合VLM辅助评估来量化视频模型的推理能力。

Result: 对最先进系统的实验显示，视觉质量与推理深度之间存在显著差异，为真正的世界模拟器建立了基准和诊断工具。

Conclusion: Gen-ViRe提供了首个对视频模型作为推理器的定量评估，揭示了当前模型在推理能力方面的局限性，为开发真正具有认知能力的世界模拟器提供了指导。

Abstract: While Chain-of-Thought (CoT) prompting enables sophisticated symbolic reasoning in LLMs, it remains confined to discrete text and cannot simulate the continuous, physics-governed dynamics of the real world. Recent video generation models have emerged as potential world simulators through Chain-of-Frames (CoF) reasoning -- materializing thought as frame-by-frame visual sequences, with each frame representing a physically-grounded reasoning step. Despite compelling demonstrations, a challenge persists: existing benchmarks, focusing on fidelity or alignment, do not assess CoF reasoning and thus cannot measure core cognitive abilities in multi-step planning, algorithmic logic, or abstract pattern extrapolation. This evaluation void prevents systematic understanding of model capabilities and principled guidance for improvement. We introduce Gen-ViRe (Generative Visual Reasoning Benchmark), a framework grounded in cognitive science and real-world AI applications, which decomposes CoF reasoning into six cognitive dimensions -- from perceptual logic to abstract planning -- and 24 subtasks. Through multi-source data curation, minimal prompting protocols, and hybrid VLM-assisted evaluation with detailed criteria, Gen-ViRe delivers the first quantitative assessment of video models as reasoners. Our experiments on SOTA systems reveal substantial discrepancies between impressive visual quality and actual reasoning depth, establishing baselines and diagnostic tools to advance genuine world simulators.

</details>


### [2] [Segmenting Collision Sound Sources in Egocentric Videos](https://arxiv.org/abs/2511.13863)
*Kranti Kumar Parida,Omar Emara,Hazel Doughty,Dima Damen*

Main category: cs.CV

TL;DR: 提出碰撞声源分割任务(CS3)，通过音频条件从视频中分割产生碰撞声音的物体，在自我中心视频中特别有效。


<details>
  <summary>Details</summary>
Motivation: 人类擅长多感官感知，能从交互声音中识别物体属性。受此启发，研究如何通过碰撞声音来分割视觉输入中产生声音的物体。

Method: 使用弱监督的音频条件分割方法，利用基础模型(CLIP和SAM2)，并整合自我中心线索(如手中物体)来识别可能的碰撞声源。

Result: 在两个新基准EPIC-CS3和Ego4D-CS3上，方法性能分别比基线高3倍和4.7倍(mIoU)。

Conclusion: 提出的CS3任务和方法在自我中心视频中有效解决了碰撞声源分割问题，显著优于现有方法。

Abstract: Humans excel at multisensory perception and can often recognise object properties from the sound of their interactions. Inspired by this, we propose the novel task of Collision Sound Source Segmentation (CS3), where we aim to segment the objects responsible for a collision sound in visual input (i.e. video frames from the collision clip), conditioned on the audio. This task presents unique challenges. Unlike isolated sound events, a collision sound arises from interactions between two objects, and the acoustic signature of the collision depends on both. We focus on egocentric video, where sounds are often clear, but the visual scene is cluttered, objects are small, and interactions are brief.
  To address these challenges, we propose a weakly-supervised method for audio-conditioned segmentation, utilising foundation models (CLIP and SAM2). We also incorporate egocentric cues, i.e. objects in hands, to find acting objects that can potentially be collision sound sources. Our approach outperforms competitive baselines by $3\times$ and $4.7\times$ in mIoU on two benchmarks we introduce for the CS3 task: EPIC-CS3 and Ego4D-CS3.

</details>


### [3] [Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets](https://arxiv.org/abs/2511.13944)
*Noam Glazner,Noam Tsfaty,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出基于聚类的帧选择策略，通过视觉相似性分组来缓解视频帧数据集中的信息泄露问题


<details>
  <summary>Details</summary>
Motivation: 解决视频帧数据集中由于时间连续性导致的信息泄露问题，确保数据集划分更具代表性

Method: 在划分训练集、验证集和测试集之前，先对视觉相似的帧进行聚类分组

Result: 该方法能够产生更具代表性、平衡性和可靠性的数据集划分

Conclusion: 基于聚类的帧选择策略是缓解视频帧数据集中信息泄露问题的有效方法

Abstract: We propose a cluster-based frame selection strategy to mitigate information leakage in video-derived frames datasets. By grouping visually similar frames before splitting into training, validation, and test sets, the method produces more representative, balanced, and reliable dataset partitions.

</details>


### [4] [Coffee: Controllable Diffusion Fine-tuning](https://arxiv.org/abs/2511.14113)
*Ziyao Zeng,Jingcheng Ni,Ruyi Liu,Alex Wong*

Main category: cs.CV

TL;DR: Coffee是一种无需额外训练的方法，通过语言描述来指定不希望学习的概念，在微调过程中防止文本到图像扩散模型学习不需要的概念。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型在微调时容易学习到不需要的概念，并与用户提示产生纠缠，这在偏见缓解、防止恶意适应、属性解耦等下游任务中至关重要。

Method: 通过保持用户提示的嵌入与不希望学习的概念不对齐，使用语言描述来规范适应过程，无需额外训练且可以灵活修改不希望学习的概念。

Result: 实验结果表明，Coffee能够有效防止文本到图像模型在微调过程中学习指定的不希望概念，并优于现有方法。

Conclusion: Coffee提供了一种有效的可控微调方法，通过语言描述来防止模型学习不需要的概念，在多种应用场景中具有重要价值。

Abstract: Text-to-image diffusion models can generate diverse content with flexible prompts, which makes them well-suited for customization through fine-tuning with a small amount of user-provided data. However, controllable fine-tuning that prevents models from learning undesired concepts present in the fine-tuning data, and from entangling those concepts with user prompts, remains an open challenge. It is crucial for downstream tasks like bias mitigation, preventing malicious adaptation, attribute disentanglement, and generalizable fine-tuning of diffusion policy. We propose Coffee that allows using language to specify undesired concepts to regularize the adaptation process. The crux of our method lies in keeping the embeddings of the user prompt from aligning with undesired concepts. Crucially, Coffee requires no additional training and enables flexible modification of undesired concepts by modifying textual descriptions. We evaluate Coffee by fine-tuning on images associated with user prompts paired with undesired concepts. Experimental results demonstrate that Coffee can prevent text-to-image models from learning specified undesired concepts during fine-tuning and outperforms existing methods. Code will be released upon acceptance.

</details>


### [5] [Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models](https://arxiv.org/abs/2511.14120)
*Hao Zhen,Yunxiang Yang,Jidong J. Yang*

Main category: cs.CV

TL;DR: 提出了MP-PVIR框架，通过多视角视频分析和行人行为阶段分割，将行人-车辆事故转化为结构化诊断报告，提升交通安全分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频系统只能检测事故是否发生，但无法分析事故在不同认知阶段的发展过程，且缺乏多视角集成和时间结构化处理。

Method: 四阶段框架：事件触发多视角视频采集、行人行为阶段分割、阶段特定多视角推理、分层合成和诊断推理。使用两个专用VLM模型进行阶段分割和多视角分析。

Result: TG-VLM阶段分割mIoU达0.4881，PhaVR-VLM字幕评分33.063，问答准确率最高达64.70%。在Woven Traffic Safety数据集上验证有效。

Conclusion: MP-PVIR成功将多视角视频数据转化为可操作的见解，推进了车辆-基础设施协同系统的AI驱动交通安全分析。

Abstract: Pedestrian-vehicle incidents remain a critical urban safety challenge, with pedestrians accounting for over 20% of global traffic fatalities. Although existing video-based systems can detect when incidents occur, they provide little insight into how these events unfold across the distinct cognitive phases of pedestrian behavior. Recent vision-language models (VLMs) have shown strong potential for video understanding, but they remain limited in that they typically process videos in isolation, without explicit temporal structuring or multi-view integration. This paper introduces Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning (MP-PVIR), a unified framework that systematically processes multi-view video streams into structured diagnostic reports through four stages: (1) event-triggered multi-view video acquisition, (2) pedestrian behavior phase segmentation, (3) phase-specific multi-view reasoning, and (4) hierarchical synthesis and diagnostic reasoning. The framework operationalizes behavioral theory by automatically segmenting incidents into cognitive phases, performing synchronized multi-view analysis within each phase, and synthesizing results into causal chains with targeted prevention strategies. Particularly, two specialized VLMs underpin the MP-PVIR pipeline: TG-VLM for behavioral phase segmentation (mIoU = 0.4881) and PhaVR-VLM for phase-aware multi-view analysis, achieving a captioning score of 33.063 and up to 64.70% accuracy on question answering. Finally, a designated large language model is used to generate comprehensive reports detailing scene understanding, behavior interpretation, causal reasoning, and prevention recommendations. Evaluation on the Woven Traffic Safety dataset shows that MP-PVIR effectively translates multi-view video data into actionable insights, advancing AI-driven traffic safety analytics for vehicle-infrastructure cooperative systems.

</details>


### [6] [Few-Shot Precise Event Spotting via Unified Multi-Entity Graph and Distillation](https://arxiv.org/abs/2511.14186)
*Zhaoyu Liu,Kan Jiang,Murong Ma,Zhe Hou,Yun Lin,Jin Song Dong*

Main category: cs.CV

TL;DR: 提出了UMEG-Net，一种统一的多实体图网络，用于少样本精确事件检测，通过整合人体骨架和运动特定物体关键点来提升性能。


<details>
  <summary>Details</summary>
Motivation: 精确事件检测在体育分析中很重要，但由于快速连续动作、运动模糊和细微视觉差异而具有挑战性。现有方法依赖大量标注数据和特定领域训练，在少样本条件下表现不佳。

Method: UMEG-Net将人体骨架和运动特定物体关键点整合到统一图中，采用先进的GCN和多尺度时间位移进行时空特征提取，并使用多模态蒸馏将知识从关键点图迁移到视觉表示。

Result: 该方法在有限标注数据下实现了鲁棒性能，在少样本设置中显著优于基线模型。

Conclusion: UMEG-Net为少样本精确事件检测提供了一个可扩展且有效的解决方案。

Abstract: Precise event spotting (PES) aims to recognize fine-grained events at exact moments and has become a key component of sports analytics. This task is particularly challenging due to rapid succession, motion blur, and subtle visual differences. Consequently, most existing methods rely on domain-specific, end-to-end training with large labeled datasets and often struggle in few-shot conditions due to their dependence on pixel- or pose-based inputs alone. However, obtaining large labeled datasets is practically hard. We propose a Unified Multi-Entity Graph Network (UMEG-Net) for few-shot PES. UMEG-Net integrates human skeletons and sport-specific object keypoints into a unified graph and features an efficient spatio-temporal extraction module based on advanced GCN and multi-scale temporal shift. To further enhance performance, we employ multimodal distillation to transfer knowledge from keypoint-based graphs to visual representations. Our approach achieves robust performance with limited labeled data and significantly outperforms baseline models in few-shot settings, providing a scalable and effective solution for few-shot PES. Code is publicly available at https://github.com/LZYAndy/UMEG-Net.

</details>


### [7] [Stage Aware Diagnosis of Diabetic Retinopathy via Ordinal Regression](https://arxiv.org/abs/2511.14398)
*Saksham Kumar,D Sridhar Aditya,T Likhil Kumar,Thulasi Bikku,Srinivasarao Thota,Chandan Kumar*

Main category: cs.CV

TL;DR: 提出了一种基于序数回归的糖尿病视网膜病变检测框架，在APTOS-2019数据集上取得了0.8992的QWK分数，创下新纪录


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变已成为可预防性失明的主要原因，通过及时筛查和干预可以防止不可逆损伤

Method: 使用序数回归框架，结合绿通道提取、噪声掩蔽和CLAHE等预处理方法提取相关特征

Result: 在APTOS数据集上获得了0.8992的QWK分数，创下了新的基准

Conclusion: 该序数回归方法在糖尿病视网膜病变检测方面表现出色，为临床分级提供了高度一致的检测结果

Abstract: Diabetic Retinopathy (DR) has emerged as a major cause of preventable blindness in recent times. With timely screening and intervention, the condition can be prevented from causing irreversible damage. The work introduces a state-of-the-art Ordinal Regression-based DR Detection framework that uses the APTOS-2019 fundus image dataset. A widely accepted combination of preprocessing methods: Green Channel (GC) Extraction, Noise Masking, and CLAHE, was used to isolate the most relevant features for DR classification. Model performance was evaluated using the Quadratic Weighted Kappa, with a focus on agreement between results and clinical grading. Our Ordinal Regression approach attained a QWK score of 0.8992, setting a new benchmark on the APTOS dataset.

</details>


### [8] [CompEvent: Complex-valued Event-RGB Fusion for Low-light Video Enhancement and Deblurring](https://arxiv.org/abs/2511.14469)
*Mingchen Zhong,Xin Lu,Dong Li,Senyan Xu,Ruixuan Jiang,Xueyang Fu,Baocai Yin*

Main category: cs.CV

TL;DR: CompEvent是一个基于复数神经网络的低光视频去模糊框架，通过全流程融合事件数据和RGB帧，实现了时空对齐和深度融合，显著提升了低光条件下的视频去模糊性能。


<details>
  <summary>Details</summary>
Motivation: 低光视频去模糊在夜间监控和自动驾驶等应用中面临挑战，现有的事件相机融合方法通常采用分阶段策略，难以有效应对低光和运动模糊的联合退化问题。

Method: 提出CompEvent框架，包含复数时序对齐GRU（使用复数卷积和GRU迭代处理视频和事件流）和复数空间-频率学习模块（在空间和频域进行统一复数信号处理），实现全流程时空融合。

Result: 大量实验表明，CompEvent在解决这一挑战性任务上优于现有最先进方法。

Conclusion: 通过复数神经网络的全流程表示能力，CompEvent实现了模态间的互补学习，显著增强了低光视频去模糊能力。

Abstract: Low-light video deblurring poses significant challenges in applications like nighttime surveillance and autonomous driving due to dim lighting and long exposures. While event cameras offer potential solutions with superior low-light sensitivity and high temporal resolution, existing fusion methods typically employ staged strategies, limiting their effectiveness against combined low-light and motion blur degradations. To overcome this, we propose CompEvent, a complex neural network framework enabling holistic full-process fusion of event data and RGB frames for enhanced joint restoration. CompEvent features two core components: 1) Complex Temporal Alignment GRU, which utilizes complex-valued convolutions and processes video and event streams iteratively via GRU to achieve temporal alignment and continuous fusion; and 2) Complex Space-Frequency Learning module, which performs unified complex-valued signal processing in both spatial and frequency domains, facilitating deep fusion through spatial structures and system-level characteristics. By leveraging the holistic representation capability of complex-valued neural networks, CompEvent achieves full-process spatiotemporal fusion, maximizes complementary learning between modalities, and significantly strengthens low-light video deblurring capability. Extensive experiments demonstrate that CompEvent outperforms SOTA methods in addressing this challenging task. The code is available at https://github.com/YuXie1/CompEvent.

</details>


### [9] [HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring](https://arxiv.org/abs/2511.14698)
*Sriram Srinivasan,Srinivasan Aruchamy,Siva Ram Krisha Vadali*

Main category: cs.CV

TL;DR: 提出HyMAD框架，通过融合频谱特征和时序依赖来检测和区分同时发生的地震活动（人类入侵、动物移动、车辆行驶），解决边境监控中重叠活动识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 地震传感器在边境监控中具有隐蔽性优势，但复杂嘈杂的地震信号使得准确检测和区分同时发生的活动（如人类、动物、车辆）成为主要挑战，错误分类会降低监控系统的可靠性。

Method: 基于深度神经网络的HyMAD架构，集成SincNet提取的频谱特征和RNN建模的时序依赖，使用自注意力层增强模态内表示，通过跨模态融合模块实现稳健的多标签分类。

Result: 在真实边境监控场景数据集上评估，展示了该方法在复杂同时活动场景中的泛化能力，实现了有竞争力的性能。

Conclusion: HyMAD为现实世界安全应用中的地震活动识别提供了一个模块化框架，能够有效处理同时发生的多活动检测问题。

Abstract: Seismic sensing has emerged as a promising solution for border surveillance and monitoring; the seismic sensors that are often buried underground are small and cannot be noticed easily, making them difficult for intruders to detect, avoid, or vandalize. This significantly enhances their effectiveness compared to highly visible cameras or fences. However, accurately detecting and distinguishing between overlapping activities that are happening simultaneously, such as human intrusions, animal movements, and vehicle rumbling, remains a major challenge due to the complex and noisy nature of seismic signals. Correctly identifying simultaneous activities is critical because failing to separate them can lead to misclassification, missed detections, and an incomplete understanding of the situation, thereby reducing the reliability of surveillance systems. To tackle this problem, we propose HyMAD (Hybrid Multi-Activity Detection), a deep neural architecture based on spatio-temporal feature fusion. The framework integrates spectral features extracted with SincNet and temporal dependencies modeled by a recurrent neural network (RNN). In addition, HyMAD employs self-attention layers to strengthen intra-modal representations and a cross-modal fusion module to achieve robust multi-label classification of seismic events. e evaluate our approach on a dataset constructed from real-world field recordings collected in the context of border surveillance and monitoring, demonstrating its ability to generalize to complex, simultaneous activity scenarios involving humans, animals, and vehicles. Our method achieves competitive performance and offers a modular framework for extending seismic-based activity recognition in real-world security applications.

</details>


### [10] [SLAM-AGS: Slide-Label Aware Multi-Task Pretraining Using Adaptive Gradient Surgery in Computational Cytology](https://arxiv.org/abs/2511.14639)
*Marco Acerbis,Swarnadip Chatterjee,Christophe Avenel,Joakim Lindblad*

Main category: cs.CV

TL;DR: 提出了SLAM-AGS框架，通过多任务预训练解决计算细胞学中的标签稀缺和阳性样本率极低的问题，在低阳性率下显著提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 计算细胞学面临两个主要挑战：实例级标签不可靠且获取成本高，阳性样本率极低

Method: SLAM-AGS框架联合优化弱监督相似性目标（在阴性样本上）和自监督对比目标（在阳性样本上），使用自适应梯度手术解决任务梯度冲突，并集成到基于注意力的多实例学习聚合器中

Result: 在公开骨髓细胞学数据集上，当阳性率从10%降至0.5%时，SLAM-AGS在袋级F1分数和Top 400阳性细胞检索方面优于其他预训练方法，在低阳性率下增益最大

Conclusion: 解决梯度干扰能够实现稳定的预训练，并在下游任务中获得更好的性能

Abstract: Computational cytology faces two major challenges: i) instance-level labels are unreliable and prohibitively costly to obtain, ii) witness rates are extremely low. We propose SLAM-AGS, a Slide-Label-Aware Multitask pretraining framework that jointly optimizes (i) a weakly supervised similarity objective on slide-negative patches and (ii) a self-supervised contrastive objective on slide-positive patches, yielding stronger performance on downstream tasks. To stabilize learning, we apply Adaptive Gradient Surgery to tackle conflicting task gradients and prevent model collapse. We integrate the pretrained encoder into an attention-based Multiple Instance Learning aggregator for bag-level prediction and attention-guided retrieval of the most abnormal instances in a bag. On a publicly available bone-marrow cytology dataset, with simulated witness rates from 10% down to 0.5%, SLAM-AGS improves bag-level F1-Score and Top 400 positive cell retrieval over other pretraining methods, with the largest gains at low witness rates, showing that resolving gradient interference enables stable pretraining and better performance on downstream tasks. To facilitate reproducibility, we share our complete implementation and evaluation framework as open source: https://github.com/Ace95/SLAM-AGS.

</details>


### [11] [Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model](https://arxiv.org/abs/2511.14716)
*Xiyuan Wang,Muhan Zhang*

Main category: cs.CV

TL;DR: 提出DSD框架，将标准潜在扩散模型的三个组件统一为单一端到端可训练网络，解决了联合训练中的潜在崩溃问题，在ImageNet 256×256条件生成任务上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 标准潜在扩散模型的三部分架构计算效率低、性能次优，且阻碍了与视觉基础模型中单网络架构的统一。目标是统一编码器、解码器和扩散网络为单一端到端可训练网络。

Method: 提出扩散作为自蒸馏(DSD)框架，通过训练目标的修改来稳定潜在空间，首次实现单一网络的稳定端到端训练，同时学习编码、解码和扩散。

Result: 在ImageNet 256×256条件生成任务上取得FID=13.44/6.38/4.25，仅使用42M/118M/205M参数和50个训练周期，且不使用分类器自由引导。

Conclusion: DSD框架成功解决了潜在崩溃问题，实现了潜在扩散模型的单网络统一，在计算效率和性能上都表现出色。

Abstract: Standard Latent Diffusion Models rely on a complex, three-part architecture consisting of a separate encoder, decoder, and diffusion network, which are trained in multiple stages. This modular design is computationally inefficient, leads to suboptimal performance, and prevents the unification of diffusion with the single-network architectures common in vision foundation models. Our goal is to unify these three components into a single, end-to-end trainable network. We first demonstrate that a naive joint training approach fails catastrophically due to ``latent collapse'', where the diffusion training objective interferes with the network's ability to learn a good latent representation. We identify the root causes of this instability by drawing a novel analogy between diffusion and self-distillation based unsupervised learning method. Based on this insight, we propose Diffusion as Self-Distillation (DSD), a new framework with key modifications to the training objective that stabilize the latent space. This approach enables, for the first time, the stable end-to-end training of a single network that simultaneously learns to encode, decode, and perform diffusion. DSD achieves outstanding performance on the ImageNet $256\times 256$ conditional generation task: FID=13.44/6.38/4.25 with only 42M/118M/205M parameters and 50 training epochs on ImageNet, without using classifier-free-guidance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [Multi-Horizon Time Series Forecasting of non-parametric CDFs with Deep Lattice Networks](https://arxiv.org/abs/2511.13756)
*Niklas Erdmann,Lars Bentsen,Roy Stenbro,Heine Nygard Riise,Narada Dilp Warakagoda,Paal E. Engelstad*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度格网络(DLN)的单调约束隐式分位数回归方法，用于时间序列的概率预测，能够生成完整、非参数化的累积分布函数(CDF)，避免了分位数交叉问题。


<details>
  <summary>Details</summary>
Motivation: 概率预测不仅能提供更多未来信息，还能弥补点预测的弱点。传统CDF建模主要限于参数化方法，本文旨在连接概率预测和单调网络领域，实现隐式、完整、非参数化的CDF预测。

Method: 采用深度格网络(DLN)进行单调约束的隐式分位数回归，使用LSTM作为嵌入层，将分位数输入扩展到所有子格，利用DLN的单调约束能力防止分位数交叉，实现多时间步长的隐式CDF预测。

Result: 在太阳能辐照度预测实验中，改进的DLN方法性能与无约束方法相当或更好，且优于可扩展单调神经网络。

Conclusion: 通过DLN的改进，旨在促进单调神经网络和概率预测技术之间的交叉研究兴趣。

Abstract: Probabilistic forecasting is not only a way to add more information to a prediction of the future, but it also builds on weaknesses in point prediction. Sudden changes in a time series can still be captured by a cumulative distribution function (CDF), while a point prediction is likely to miss it entirely. The modeling of CDFs within forecasts has historically been limited to parametric approaches, but due to recent advances, this no longer has to be the case. We aim to advance the fields of probabilistic forecasting and monotonic networks by connecting them and propose an approach that permits the forecasting of implicit, complete, and nonparametric CDFs. For this purpose, we propose an adaptation to deep lattice networks (DLN) for monotonically constrained simultaneous/implicit quantile regression in time series forecasting. Quantile regression usually produces quantile crossovers, which need to be prevented to achieve a legitimate CDF. By leveraging long short term memory units (LSTM) as the embedding layer, and spreading quantile inputs to all sub-lattices of a DLN with an extended output size, we can produce a multi-horizon forecast of an implicit CDF due to the monotonic constraintability of DLNs that prevent quantile crossovers. We compare and evaluate our approach's performance to relevant state of the art within the context of a highly relevant application of time series forecasting: Day-ahead, hourly forecasts of solar irradiance observations. Our experiments show that the adaptation of a DLN performs just as well or even better than an unconstrained approach. Further comparison of the adapted DLN against a scalable monotonic neural network shows that our approach performs better. With this adaptation of DLNs, we intend to create more interest and crossover investigations in techniques of monotonic neural networks and probabilistic forecasting.

</details>


### [13] [Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds](https://arxiv.org/abs/2511.14056)
*Marios Papamichals,Regina Ruane*

Main category: cs.LG

TL;DR: 提出了Radial Compensation (RC)方法，通过选择切空间中的基础密度，使似然仅依赖于测地距离，解耦参数语义与曲率，为流形上的生成模型提供了稳健的默认方案。


<details>
  <summary>Details</summary>
Motivation: 现有流形生成模型中的指数映射和体积保持图表分别存在雅可比矩阵刚性和测地距离扭曲问题，且都将曲率与模型参数纠缠，导致梯度方差增大。在高维潜在归一化流中，包裹指数先验会使半径拉伸超出曲率尺度，导致测试似然差和求解器刚性。

Method: 引入径向补偿(RC)方法，在切空间中选择基础密度，使似然仅依赖于测地距离，解耦参数语义与曲率。推导了Balanced-Exponential (bExp)图表族，平衡体积扭曲和测地误差。

Result: RC在密度、VAE、图像和图的流以及蛋白质模型中均产生稳定的生成模型。RC提高了似然，恢复了清晰的测地半径，并防止了高维流中的半径爆炸。

Conclusion: RC-bExp成为流形上似然训练生成模型的稳健默认方案，通过解耦曲率与参数语义，改善了模型性能和数值稳定性。

Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.

</details>


### [14] [CFG-EC: Error Correction Classifier-Free Guidance](https://arxiv.org/abs/2511.14075)
*Nakkyu Yang,Yechan Lee,SooJean Han*

Main category: cs.LG

TL;DR: 提出了CFG-EC方法，通过修正无条件噪声预测来减少CFG在训练和采样过程中的不一致性，提高生成质量和提示对齐度。


<details>
  <summary>Details</summary>
Motivation: CFG在训练时交替使用条件提示和无提示，但在采样时同时输出两者，导致训练和采样过程中的噪声估计不一致，产生误差。

Method: CFG-EC通过将无条件噪声误差分量重新对齐为与条件误差分量正交，防止两个引导分量之间的干扰，从而约束采样误差的上界。

Result: 数值实验表明CFG-EC比CFG和CFG++更有效地处理无条件分量，在低引导采样机制下性能显著提升，整体提示对齐度更高。

Conclusion: CFG-EC是一种可增强任何基于CFG方法的通用校正方案，通过改进无条件噪声预测来建立更可靠的引导轨迹，实现高保真图像生成。

Abstract: Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.

</details>


### [15] [Synthetic Survival Control: Extending Synthetic Controls for "When-If" Decision](https://arxiv.org/abs/2511.14133)
*Jessy Xinyi Han,Devavrat Shah*

Main category: cs.LG

TL;DR: 提出Synthetic Survival Control (SSC)方法，在面板数据设置中估计反事实风险轨迹，解决观察数据中因果推断的挑战


<details>
  <summary>Details</summary>
Motivation: 观察数据中时间到事件结果的因果效应估计面临删失、样本量有限和非随机治疗分配的挑战，需要回答"如果-何时"问题

Method: SSC将目标单元的反事实风险轨迹估计为其他单元观察轨迹的加权组合，引入具有低秩结构的面板框架进行因果生存分析

Result: 在癌症治疗结果的多国临床数据验证中，发现新型治疗与改善生存相关，干预后风险轨迹低于合成对应物

Conclusion: SSC为使用观察数据进行反事实生存推断提供了一个通用且可解释的工具，在医学、经济学和公共政策领域具有广泛应用价值

Abstract: Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such "when-if" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.

</details>


### [16] [Parallelizing Tree Search with Twice Sequential Monte Carlo](https://arxiv.org/abs/2511.14220)
*Yaniv Oren,Joery A. de Vries,Pascal R. van der Vaart,Matthijs T. J. Spaan,Wendelin Böhmer*

Main category: cs.LG

TL;DR: 提出了TSMCTS算法来解决SMC方法在强化学习中存在的高方差和路径退化问题，该算法在离散和连续环境中都优于SMC基线和现代MCTS版本。


<details>
  <summary>Details</summary>
Motivation: 基于模型的强化学习方法中，SMC虽然比MCTS更容易并行化和GPU加速，但存在高方差和路径退化问题，限制了其在深度搜索中的扩展性。

Method: 提出了TSMCTS算法，通过方差减少和路径退化缓解技术，在保持SMC并行化优势的同时改善其扩展性。

Result: 在离散和连续环境中，TSMCTS都优于SMC基线和现代MCTS版本，能够更好地随顺序计算扩展。

Conclusion: TSMCTS通过解决SMC的关键问题，在保持并行化优势的同时实现了更好的性能扩展，为基于搜索的模型强化学习方法提供了新的解决方案。

Abstract: Model-based reinforcement learning (RL) methods that leverage search are responsible for many milestone breakthroughs in RL. Sequential Monte Carlo (SMC) recently emerged as an alternative to the Monte Carlo Tree Search (MCTS) algorithm which drove these breakthroughs. SMC is easier to parallelize and more suitable to GPU acceleration. However, it also suffers from large variance and path degeneracy which prevent it from scaling well with increased search depth, i.e., increased sequential compute. To address these problems, we introduce Twice Sequential Monte Carlo Tree Search (TSMCTS). Across discrete and continuous environments TSMCTS outperforms the SMC baseline as well as a popular modern version of MCTS. Through variance reduction and mitigation of path degeneracy, TSMCTS scales favorably with sequential compute while retaining the properties that make SMC natural to parallelize.

</details>


### [17] [Toward Robust and Harmonious Adaptation for Cross-modal Retrieval](https://arxiv.org/abs/2511.14416)
*Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 本文提出REST方法解决跨模态检索中的查询偏移问题，包括在线偏移和多样偏移，通过查询预测优化和梯度解耦模块实现鲁棒适应。


<details>
  <summary>Details</summary>
Motivation: 现有通用到定制化跨模态检索方法假设整个目标域数据可用，但现实场景中查询以在线方式到达且具有多样性，导致查询偏移问题，影响模型性能。

Method: REST方法通过查询预测制定QS鲁棒目标函数保护公共空间，并采用梯度解耦模块防止模型遗忘通用知识。

Result: 在3个跨模态检索任务的20个基准测试中验证了方法的有效性。

Conclusion: REST方法能够有效应对查询偏移问题，在在线和多样化场景下保持跨模态检索模型的鲁棒性。

Abstract: Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.

</details>


### [18] [Machine Learning Models for Predicting Smoking-Related Health Decline and Disease Risk](https://arxiv.org/abs/2511.14682)
*Vaskar Chakma,MD Jaheid Hasan Nerab,Abdur Rouf,Abu Sayed,Hossem MD Saim,Md. Nournabi Khan*

Main category: cs.LG

TL;DR: 本研究系统比较了机器学习方法在吸烟相关健康风险评估中的应用，发现随机森林模型表现最佳（AUC=0.926），并通过SHAP分析识别出血压、甘油三酯、肝酶和肾功能指标是吸烟者健康风险的关键预测因子。


<details>
  <summary>Details</summary>
Motivation: 吸烟是全球主要的可预防死因，但现有医疗筛查方法常错过早期预警信号，导致晚期诊断。本研究旨在开发可解释的机器学习模型来识别吸烟相关健康风险。

Method: 使用55,691人的健康筛查数据，比较随机森林、XGBoost和LightGBM三种算法，采用横断面设计基于生物标志物分类当前吸烟状态，并使用SHAP分析解释模型预测。

Result: 随机森林模型表现最佳，AUC达到0.926。SHAP分析显示血压、甘油三酯、肝酶和血清肌酐是最重要的预测因子。

Conclusion: 机器学习模型能有效识别吸烟相关健康风险，关键生物标志物为临床筛查提供了可解释的预测依据，有助于早期干预。

Abstract: Smoking continues to be a major preventable cause of death worldwide, affecting millions through damage to the heart, metabolism, liver, and kidneys. However, current medical screening methods often miss the early warning signs of smoking-related health problems, leading to late-stage diagnoses when treatment options become limited. This study presents a systematic comparative evaluation of machine learning approaches for smoking-related health risk assessment, emphasizing clinical interpretability and practical deployment over algorithmic innovation. We analyzed health screening data from 55,691 individuals, examining various health indicators, including body measurements, blood tests, and demographic information. We tested three advanced prediction algorithms - Random Forest, XGBoost, and LightGBM - to determine which could most accurately identify people at high risk. This study employed a cross-sectional design to classify current smoking status based on health screening biomarkers, not to predict future disease development. Our Random Forest model performed best, achieving an Area Under the Curve (AUC) of 0.926, meaning it could reliably distinguish between high-risk and lower-risk individuals. Using SHAP (SHapley Additive exPlanations) analysis to understand what the model was detecting, we found that key health markers played crucial roles in prediction: blood pressure levels, triglyceride concentrations, liver enzyme readings, and kidney function indicators (serum creatinine) were the strongest signals of declining health in smokers.

</details>


### [19] [LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data](https://arxiv.org/abs/2511.14738)
*Tzu-Hsuan Chou,Chun-Nan Chou*

Main category: cs.LG

TL;DR: 提出了LAUD框架，将大语言模型与主动学习结合，通过零样本学习构建初始标签集，解决无标签数据场景下的模型性能问题。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，缺乏标注数据阻碍了从业者获得高性能模型，迫使依赖繁琐、低效的基于提示的方法。

Method: LAUD框架整合大语言模型与主动学习，使用零样本学习缓解冷启动问题，构建初始标签集。

Result: 实验结果显示，LAUD框架下的大语言模型在商品名称分类任务上优于零样本或少样本学习。

Conclusion: LAUD框架有效解决了无标签数据场景下的模型训练问题，展示了其实际应用价值。

Abstract: Large language models (LLMs) have shown a remarkable ability to generalize beyond their pre-training data, and fine-tuning LLMs can elevate performance to human-level and beyond. However, in real-world scenarios, lacking labeled data often prevents practitioners from obtaining well-performing models, thereby forcing practitioners to highly rely on prompt-based approaches that are often tedious, inefficient, and driven by trial and error. To alleviate this issue of lacking labeled data, we present a learning framework integrating LLMs with active learning for unlabeled dataset (LAUD). LAUD mitigates the cold-start problem by constructing an initial label set with zero-shot learning. Experimental results show that LLMs derived from LAUD outperform LLMs with zero-shot or few-shot learning on commodity name classification tasks, demonstrating the effectiveness of LAUD.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 该论文系统分析了智能交通系统中大型视觉语言模型在精心设计的越狱攻击下的脆弱性，提出了基于图像排版操纵和多轮提示的新型越狱攻击方法，并开发了多层响应过滤防御技术。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在智能交通系统中应用广泛，但极易受到越狱攻击，存在严重安全隐患，需要系统分析其脆弱性并开发有效防御措施。

Method: 构建交通相关有害查询数据集；提出基于图像排版操纵和多轮提示的新型越狱攻击；开发多层响应过滤防御技术；使用GPT-4判断和人工验证评估攻击和防御效果。

Result: 实验表明提出的越狱攻击方法对开源和闭源LVLMs均有效，相比现有技术具有更强的攻击能力，同时防御技术能够有效阻止模型生成不当响应。

Conclusion: LVLMs在智能交通系统中存在严重安全风险，图像排版操纵和多轮提示的越狱攻击威胁巨大，需要多层防御机制来保障系统安全。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports](https://arxiv.org/abs/2511.14010)
*Chenchen Kuai,Zihao Li,Braden Rosen,Stephanie Paan,Navid Jafari,Jean-Louis Briaud,Yunlong Zhang,Youssef M. A. Hashash,Yang Zhou*

Main category: cs.CL

TL;DR: MoRA-RAG是一个基于知识的大型语言模型框架，通过混合检索机制和代理分块技术，将灾后勘察报告转化为结构化知识，用于多灾害推理，准确率高达94.5%。


<details>
  <summary>Details</summary>
Motivation: 灾后勘察报告包含理解多灾害相互作用的关键证据，但其非结构化叙述使得系统知识传递困难。大型语言模型在缺乏领域基础时会产生不可靠或幻觉输出。

Method: 开发了MoRA-RAG框架，包含混合检索机制动态路由跨灾害特定数据库的查询，使用代理分块保持检索中的上下文连贯性，并包含验证循环评估证据充分性、优化查询并在信息不完整时启动针对性搜索。

Result: MoRA-RAG在HazardRecQA数据集上达到94.5%准确率，比零样本LLM提高30%，比最先进RAG系统提高10%，同时在不同LLM架构中减少幻觉。还使开源LLM达到与专有模型相当的性能。

Conclusion: MoRA-RAG为将灾后文档转化为可操作、可信赖的灾害韧性情报建立了新范式。

Abstract: Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.

</details>


### [22] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 提出了一种名为Stealth Fine-Tuning的新型攻击方法，通过分段干扰和自生成监督数据，仅用499个样本在3小时内就能有效突破RVLMs的安全对齐防御，攻击成功率比IDEATOR提高38.52%


<details>
  <summary>Details</summary>
Motivation: 虽然RVLMs依赖安全对齐来防止有害行为，但其暴露的思维链轨迹引入了新的攻击面，安全对齐容易被突破

Method: 使用分段干扰引发有害思维链轨迹，将自生成输出作为监督微调数据，采用轮次加权损失设计，实现轻量级、分布一致的微调方法

Result: 在AdvBench和多个通用基准测试中，Stealth Fine-Tuning以低成本高效地绕过对齐防御，同时保持通用推理能力

Conclusion: Stealth Fine-Tuning是一种低成本且高效的攻击方法，能够有效突破RVLMs的安全对齐，同时保持模型的原始表示分布

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [23] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: ATLAS是一个面向AGI的大规模、高难度跨学科科学评估套件，包含约800个原创问题，旨在解决现有基准测试在区分前沿模型能力方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在性能饱和、学科范围狭窄、答案格式简化、数据污染等问题，无法有效评估模型在真实科学探究中的能力。

Method: 由领域专家开发，涵盖7个核心科学领域；采用原创问题防止数据泄露；强调跨学科知识整合；使用复杂开放式答案格式；实施多阶段专家评审和质量控制。

Result: 初步结果显示ATLAS能有效区分领先模型的先进科学推理能力。

Conclusion: ATLAS将发展成长期开放的社区驱动平台，为AGI进展提供可靠评估标准。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [24] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 提出了EduHarm基准和TSSF框架，用于评估和防御教育场景中LLM的安全漏洞，包括越狱攻击和微调攻击。


<details>
  <summary>Details</summary>
Motivation: LLM在教育应用中面临独特的安全挑战，现有研究主要关注通用安全评估，缺乏针对教育场景的安全需求。

Method: 构建EduHarm基准，提出三阶段防护框架TSSF：安全感知注意力重对齐、层级安全判断、防御驱动双路由。

Result: 在8种越狱攻击策略上有效增强安全性，在3个微调攻击数据集上实现稳健防御，同时保持良性查询的效用。

Conclusion: TSSF框架能够同时缓解越狱和微调攻击，为教育LLM提供有效的安全保障。

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>
