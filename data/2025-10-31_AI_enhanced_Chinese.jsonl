{"id": "2510.25778", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25778", "abs": "https://arxiv.org/abs/2510.25778", "authors": ["Pratik N. Kalamkar", "Anupama G. Phakatkar"], "title": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "comment": "10 pages, 3 figures, International Journal Of Engineering And\n  Computer Science ISSN:2319-7242", "summary": "Opinion mining, also called sentiment analysis, is the field of study that\nanalyzes people opinions, sentiments, evaluations, appraisals, attitudes, and\nemotions towards entities such as products, services, organizations,\nindividuals, issues, events, topics, and their attributes. Holistic\nlexicon-based approach does not consider the strength of each opinion, i.e.,\nwhether the opinion is very strongly negative (or positive), strongly negative\n(or positive), moderate negative (or positive), very weakly negative (or\npositive) and weakly negative (or positive). In this paper, we propose approach\nto rank entities based on orientation and strength of the entity reviews and\nuser's queries by classifying them in granularity levels (i.e. very weak, weak,\nmoderate, very strong and strong) by combining opinion words (i.e. adverb,\nadjective, noun and verb) that are related to aspect of interest of certain\nproduct. We shall use fuzzy logic algorithmic approach in order to classify\nopinion words into different category and syntactic dependency resolution to\nfind relations for desired aspect words. Opinion words related to certain\naspects of interest are considered to find the entity score for that aspect in\nthe review.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u548c\u53e5\u6cd5\u4f9d\u8d56\u89e3\u6790\u7684\u65b9\u6cd5\uff0c\u5bf9\u4ea7\u54c1\u8bc4\u8bba\u4e2d\u7684\u60c5\u611f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u7c7b\uff08\u975e\u5e38\u5f31\u3001\u5f31\u3001\u4e2d\u7b49\u3001\u5f3a\u3001\u975e\u5e38\u5f3a\uff09\uff0c\u5e76\u57fa\u4e8e\u60c5\u611f\u65b9\u5411\u548c\u5f3a\u5ea6\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6392\u540d\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u8bcd\u5178\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u60c5\u611f\u5f3a\u5ea6\uff0c\u65e0\u6cd5\u533a\u5206\u975e\u5e38\u5f3a\u70c8\u3001\u5f3a\u70c8\u3001\u4e2d\u7b49\u3001\u975e\u5e38\u5f31\u548c\u5f31\u7b49\u4e0d\u540c\u7ea7\u522b\u7684\u79ef\u6781\u6216\u6d88\u6781\u60c5\u611f\u3002", "method": "\u7ed3\u5408\u526f\u8bcd\u3001\u5f62\u5bb9\u8bcd\u3001\u540d\u8bcd\u548c\u52a8\u8bcd\u7b49\u89c2\u70b9\u8bcd\uff0c\u4f7f\u7528\u6a21\u7cca\u903b\u8f91\u7b97\u6cd5\u5c06\u89c2\u70b9\u8bcd\u5206\u7c7b\u5230\u4e0d\u540c\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7\u53e5\u6cd5\u4f9d\u8d56\u89e3\u6790\u627e\u5230\u4e0e\u76ee\u6807\u65b9\u9762\u8bcd\u7684\u5173\u7cfb\uff0c\u8ba1\u7b97\u5b9e\u4f53\u5728\u7279\u5b9a\u65b9\u9762\u7684\u5f97\u5206\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5bf9\u4ea7\u54c1\u8bc4\u8bba\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u60c5\u611f\u5f3a\u5ea6\u5206\u7c7b\uff0c\u5e76\u57fa\u4e8e\u60c5\u611f\u65b9\u5411\u548c\u5f3a\u5ea6\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6392\u540d\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u66f4\u51c6\u786e\u5730\u5206\u6790\u8bc4\u8bba\u4e2d\u7684\u60c5\u611f\u5f3a\u5ea6\u548c\u65b9\u5411\uff0c\u4e3a\u5b9e\u4f53\u6392\u540d\u63d0\u4f9b\u66f4\u7cbe\u7ec6\u7684\u60c5\u611f\u5206\u6790\u7ed3\u679c\u3002"}}
{"id": "2510.25914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25914", "abs": "https://arxiv.org/abs/2510.25914", "authors": ["Ngoc Phuoc An Vo", "Manish Kesarwani", "Ruchi Mahindru", "Chandrasekhar Narayanaswami"], "title": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization", "comment": null, "summary": "FinOps (Finance + Operations) represents an operational framework and\ncultural practice which maximizes cloud business value through collaborative\nfinancial accountability across engineering, finance, and business teams.\nFinOps practitioners face a fundamental challenge: billing data arrives in\nheterogeneous formats, taxonomies, and metrics from multiple cloud providers\nand internal systems which eventually lead to synthesizing actionable insights,\nand making time-sensitive decisions. To address this challenge, we propose\nleveraging autonomous, goal-driven AI agents for FinOps automation. In this\npaper, we built a FinOps agent for a typical use-case for IT infrastructure and\ncost optimization. We built a system simulating a realistic end-to-end industry\nprocess starting with retrieving data from various sources to consolidating and\nanalyzing the data to generate recommendations for optimization. We defined a\nset of metrics to evaluate our agent using several open-source and close-source\nlanguage models and it shows that the agent was able to understand, plan, and\nexecute tasks as well as an actual FinOps practitioner.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u81ea\u4e3bAI\u4ee3\u7406\u5b9e\u73b0FinOps\u81ea\u52a8\u5316\uff0c\u89e3\u51b3\u4e91\u8d26\u5355\u6570\u636e\u683c\u5f0f\u5f02\u6784\u95ee\u9898\uff0c\u901a\u8fc7\u6a21\u62df\u7aef\u5230\u7aef\u884c\u4e1a\u6d41\u7a0b\u9a8c\u8bc1\u4ee3\u7406\u6027\u80fd", "motivation": "FinOps\u4ece\u4e1a\u8005\u9762\u4e34\u4e91\u8d26\u5355\u6570\u636e\u683c\u5f0f\u5f02\u6784\u3001\u5206\u7c7b\u548c\u6307\u6807\u4e0d\u7edf\u4e00\u7684\u6311\u6218\uff0c\u96be\u4ee5\u5feb\u901f\u5408\u6210\u53ef\u64cd\u4f5c\u89c1\u89e3\u5e76\u505a\u51fa\u65f6\u6548\u6027\u51b3\u7b56", "method": "\u6784\u5efaFinOps\u4ee3\u7406\u7cfb\u7edf\uff0c\u6a21\u62df\u4ece\u591a\u6e90\u6570\u636e\u68c0\u7d22\u5230\u6570\u636e\u6574\u5408\u5206\u6790\u518d\u5230\u4f18\u5316\u5efa\u8bae\u751f\u6210\u7684\u5b8c\u6574\u884c\u4e1a\u6d41\u7a0b\uff0c\u4f7f\u7528\u591a\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30", "result": "\u4ee3\u7406\u80fd\u591f\u50cf\u5b9e\u9645FinOps\u4ece\u4e1a\u8005\u4e00\u6837\u7406\u89e3\u3001\u89c4\u5212\u548c\u6267\u884c\u4efb\u52a1\uff0c\u5728IT\u57fa\u7840\u8bbe\u65bd\u548c\u6210\u672c\u4f18\u5316\u7528\u4f8b\u4e2d\u8868\u73b0\u826f\u597d", "conclusion": "\u81ea\u4e3bAI\u4ee3\u7406\u662f\u89e3\u51b3FinOps\u6570\u636e\u5f02\u6784\u6311\u6218\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u81ea\u52a8\u5316\u6210\u672c\u4f18\u5316\u51b3\u7b56"}}
{"id": "2510.26113", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26113", "abs": "https://arxiv.org/abs/2510.26113", "authors": ["Minjoon Jung", "Junbin Xiao", "Junghyun Kim", "Byoung-Tak Zhang", "Angela Yao"], "title": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "comment": "project page:\n  \\url{https://minjoong507.github.io/projects/EgoExo-Con/}", "summary": "Can Video-LLMs achieve consistent temporal understanding when videos capture\nthe same event from different viewpoints? To study this, we introduce\nEgoExo-Con (Consistency), a benchmark of comprehensively synchronized\negocentric and exocentric video pairs with human-refined queries in natural\nlanguage. EgoExo-Con emphasizes two temporal understanding tasks: Temporal\nVerification and Temporal Grounding. It evaluates not only correctness but\nconsistency across viewpoints. Our analysis reveals two critical limitations of\nexisting Video-LLMs: (1) models often fail to maintain consistency, with\nresults far worse than their single-view performances. (2) When naively\nfinetuned with synchronized videos of both viewpoints, the models show improved\nconsistency but often underperform those trained on a single view. For\nimprovements, we propose View-GRPO, a novel reinforcement learning framework\nthat effectively strengthens view-specific temporal reasoning while encouraging\nconsistent comprehension across viewpoints. Our method demonstrates its\nsuperiority over naive SFT and GRPO, especially for improving cross-view\nconsistency. All resources will be made publicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86EgoExo-Con\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u9891LLM\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u7684\u65f6\u95f4\u7406\u89e3\u4e00\u81f4\u6027\uff0c\u5e76\u5f00\u53d1\u4e86View-GRPO\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u63d0\u5347\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u3002", "motivation": "\u7814\u7a76\u89c6\u9891LLM\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u662f\u5426\u80fd\u591f\u4fdd\u6301\u65f6\u95f4\u7406\u89e3\u7684\u4e00\u81f4\u6027\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002", "method": "\u5f15\u5165EgoExo-Con\u57fa\u51c6\uff0c\u5305\u542b\u540c\u6b65\u7684\u81ea\u6211\u4e2d\u5fc3\u548c\u4ed6\u8005\u89c6\u89d2\u89c6\u9891\u5bf9\uff0c\u5e76\u63d0\u51faView-GRPO\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u589e\u5f3a\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u3002", "result": "\u73b0\u6709\u89c6\u9891LLM\u5728\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u8f83\u5dee\uff0cView-GRPO\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edfSFT\u548cGRPO\u80fd\u663e\u8457\u63d0\u5347\u4e00\u81f4\u6027\u8868\u73b0\u3002", "conclusion": "\u8de8\u89c6\u89d2\u65f6\u95f4\u7406\u89e3\u4e00\u81f4\u6027\u662f\u89c6\u9891LLM\u7684\u91cd\u8981\u6311\u6218\uff0cView-GRPO\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2510.26536", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.26536", "abs": "https://arxiv.org/abs/2510.26536", "authors": ["Huajie Tan", "Cheng Chi", "Xiansheng Chen", "Yuheng Ji", "Zhongxia Zhao", "Xiaoshuai Hao", "Yaoxu Lyu", "Mingyu Cao", "Junkai Zhao", "Huaihai Lyu", "Enshen Zhou", "Ning Chen", "Yankai Fu", "Cheng Peng", "Wei Guo", "Dong Liang", "Zhuo Chen", "Mengsi Lyu", "Chenrui He", "Yulong Ao", "Yonghua Lin", "Pengwei Wang", "Zhongyuan Wang", "Shanghang Zhang"], "title": "RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration", "comment": null, "summary": "The proliferation of collaborative robots across diverse tasks and\nembodiments presents a central challenge: achieving lifelong adaptability,\nscalable coordination, and robust scheduling in multi-agent systems. Existing\napproaches, from vision-language-action (VLA) models to hierarchical\nframeworks, fall short due to their reliance on limited or dividual-agent\nmemory. This fundamentally constrains their ability to learn over long\nhorizons, scale to heterogeneous teams, or recover from failures, highlighting\nthe need for a unified memory representation. To address these limitations, we\nintroduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,\nand robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel\nSpatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene\ngeometry, temporal event history, and embodiment profiles into a shared\nrepresentation. This memory-centric design is integrated into a\nbrain-cerebellum framework, where a high-level brain model performs global\nplanning by retrieving and updating STEM, while low-level controllers execute\nactions locally. This closed loop between cognition, memory, and execution\nenables dynamic task allocation, fault-tolerant collaboration, and consistent\nstate synchronization. We conduct extensive experiments spanning complex\ncoordination tasks in restaurants, supermarkets, and households. Our results\ndemonstrate that RoboOS-NeXT achieves superior performance across heterogeneous\nembodiments, validating its effectiveness in enabling lifelong, scalable, and\nrobust multi-robot collaboration. Project website:\nhttps://flagopen.github.io/RoboOS/", "AI": {"tldr": "\u63d0\u51fa\u4e86RoboOS-NeXT\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u65f6\u7a7a-\u5177\u8eab\u8bb0\u5fc6(STEM)\u5b9e\u73b0\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u7ec8\u8eab\u9002\u5e94\u3001\u53ef\u6269\u5c55\u534f\u8c03\u548c\u9c81\u68d2\u8c03\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u7684\u4e2a\u4f53\u8bb0\u5fc6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u957f\u671f\u5b66\u4e60\u3001\u6269\u5c55\u5230\u5f02\u6784\u56e2\u961f\u6216\u4ece\u6545\u969c\u4e2d\u6062\u590d\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5185\u5b58\u8868\u793a\u3002", "method": "\u5f15\u5165STEM\u8bb0\u5fc6\uff0c\u96c6\u6210\u7a7a\u95f4\u573a\u666f\u51e0\u4f55\u3001\u65f6\u95f4\u4e8b\u4ef6\u5386\u53f2\u548c\u5177\u8eab\u914d\u7f6e\u6587\u4ef6\u5230\u5171\u4eab\u8868\u793a\u4e2d\uff0c\u91c7\u7528\u5927\u8111-\u5c0f\u8111\u6846\u67b6\uff0c\u9ad8\u5c42\u5927\u8111\u6a21\u578b\u8fdb\u884c\u5168\u5c40\u89c4\u5212\uff0c\u4f4e\u5c42\u63a7\u5236\u5668\u672c\u5730\u6267\u884c\u3002", "result": "\u5728\u9910\u5385\u3001\u8d85\u5e02\u548c\u5bb6\u5ead\u7b49\u590d\u6742\u534f\u8c03\u4efb\u52a1\u4e2d\uff0cRoboOS-NeXT\u5728\u5f02\u6784\u5177\u8eab\u673a\u5668\u4eba\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u4e86\u7ec8\u8eab\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u7684\u591a\u673a\u5668\u4eba\u534f\u4f5c\u3002"}}
{"id": "2510.26646", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26646", "abs": "https://arxiv.org/abs/2510.26646", "authors": ["Xiaoyi He", "Danggui Chen", "Zhenshuo Zhang", "Zimeng Bai"], "title": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments", "comment": "6 pages, 5 figures; ROS+Gazebo (TurtleBot3) implementation;\n  evaluation with PathBench metrics; code (primary):\n  https://github.com/MayaCHEN-github/HierarchicalRL-robot-navigation; mirror\n  (for reproducibility): https://github.com/ShowyHe/DRL-robot-navigation", "summary": "This paper presents a hierarchical path-planning and control framework that\ncombines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with\na low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller\nfor continuous actuation. The high-level module selects behaviors and\nsub-goals; the low-level module executes smooth velocity commands. We design a\npractical reward shaping scheme (direction, distance, obstacle avoidance,\naction smoothness, collision penalty, time penalty, and progress), together\nwith a LiDAR-based safety gate that prevents unsafe motions. The system is\nimplemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,\nincluding success rate, collision rate, path efficiency, and re-planning\nefficiency, in dynamic and partially observable environments. Experiments show\nimproved success rate and sample efficiency over single-algorithm baselines\n(DQN or TD3 alone) and rule-based planners, with better generalization to\nunseen obstacle configurations and reduced abrupt control changes. Code and\nevaluation scripts are available at the project repository.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u8def\u5f84\u89c4\u5212\u4e0e\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u5c42DQN\u8fdb\u884c\u79bb\u6563\u5b50\u76ee\u6807\u9009\u62e9\u4e0e\u5e95\u5c42TD3\u63a7\u5236\u5668\u8fdb\u884c\u8fde\u7eed\u9a71\u52a8\uff0c\u5728\u52a8\u6001\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u8def\u5f84\u89c4\u5212\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5355\u4e00\u7b97\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u8def\u5f84\u89c4\u5212\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u7ed3\u5408\u79bb\u6563\u51b3\u7b56\u548c\u8fde\u7eed\u63a7\u5236\uff0c\u63d0\u9ad8\u89c4\u5212\u6210\u529f\u7387\u548c\u6837\u672c\u6548\u7387\u3002", "method": "\u4f7f\u7528\u9ad8\u5c42Deep Q-Network\u9009\u62e9\u884c\u4e3a\u548c\u5b50\u76ee\u6807\uff0c\u5e95\u5c42Twin Delayed Deep Deterministic Policy Gradient\u6267\u884c\u5e73\u6ed1\u901f\u5ea6\u547d\u4ee4\uff0c\u7ed3\u5408LiDAR\u5b89\u5168\u95e8\u548c\u5b9e\u7528\u5956\u52b1\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u5355\u4e00\u7b97\u6cd5\u57fa\u51c6\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u89c4\u5212\u5668\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3001\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\uff0c\u5bf9\u672a\u89c1\u969c\u788d\u7269\u914d\u7f6e\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63a7\u5236\u53d8\u5316\u66f4\u5e73\u6ed1\u3002", "conclusion": "\u5206\u5c42\u6846\u67b6\u6709\u6548\u7ed3\u5408\u79bb\u6563\u548c\u8fde\u7eed\u63a7\u5236\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684\u8def\u5f84\u89c4\u5212\uff0c\u4f18\u4e8e\u5355\u4e00\u7b97\u6cd5\u65b9\u6cd5\u3002"}}
{"id": "2510.26309", "categories": ["cs.AI", "cs.IR", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.26309", "abs": "https://arxiv.org/abs/2510.26309", "authors": ["Jiseong Chung", "Ronny Ko", "Wonchul Yoo", "Makoto Onizuka", "Sungmok Kim", "Tae-Wan Kim", "Won-Yong Shin"], "title": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance", "comment": "Under review at The Web Conference 2026 (Semantics & Knowledge\n  track). Code will be released upon acceptance. This arXiv v1 contains no\n  repository links to preserve double-blind review", "summary": "Compliance at web scale poses practical challenges: each request may require\na regulatory assessment. Regulatory texts (e.g., the General Data Protection\nRegulation, GDPR) are cross-referential and normative, while runtime contexts\nare expressed in unstructured natural language. This setting motivates us to\nalign semantic information in unstructured text with the structured, normative\nelements of regulations. To this end, we introduce GraphCompliance, a framework\nthat represents regulatory texts as a Policy Graph and runtime contexts as a\nContext Graph, and aligns them. In this formulation, the policy graph encodes\nnormative structure and cross-references, whereas the context graph formalizes\nevents as subject-action-object (SAO) and entity-relation triples. This\nalignment anchors the reasoning of a judge large language model (LLM) in\nstructured information and helps reduce the burden of regulatory interpretation\nand event parsing, enabling a focus on the core reasoning step. In experiments\non 300 GDPR-derived real-world scenarios spanning five evaluation tasks,\nGraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than\nLLM-only and RAG baselines, with fewer under- and over-predictions, resulting\nin higher recall and lower false positive rates. Ablation studies indicate\ncontributions from each graph component, suggesting that structured\nrepresentations and a judge LLM are complementary for normative reasoning.", "AI": {"tldr": "GraphCompliance\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6cd5\u89c4\u6587\u672c\u8868\u793a\u4e3a\u7b56\u7565\u56fe\uff0c\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u8868\u793a\u4e3a\u4e0a\u4e0b\u6587\u56fe\uff0c\u5e76\u5bf9\u9f50\u4e24\u8005\u6765\u63d0\u5347\u7f51\u7edc\u89c4\u6a21\u5408\u89c4\u6027\u8bc4\u4f30\u7684\u6548\u679c\u3002", "motivation": "\u7f51\u7edc\u89c4\u6a21\u7684\u5408\u89c4\u6027\u9762\u4e34\u5b9e\u9645\u6311\u6218\uff1a\u6bcf\u4e2a\u8bf7\u6c42\u90fd\u9700\u8981\u6cd5\u89c4\u8bc4\u4f30\u3002\u6cd5\u89c4\u6587\u672c\u5177\u6709\u4ea4\u53c9\u5f15\u7528\u548c\u89c4\u8303\u6027\uff0c\u800c\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u662f\u975e\u7ed3\u6784\u5316\u7684\u81ea\u7136\u8bed\u8a00\uff0c\u9700\u8981\u5c06\u8bed\u4e49\u4fe1\u606f\u4e0e\u6cd5\u89c4\u7684\u7ed3\u6784\u5316\u89c4\u8303\u5143\u7d20\u5bf9\u9f50\u3002", "method": "\u5f15\u5165GraphCompliance\u6846\u67b6\uff0c\u5c06\u6cd5\u89c4\u6587\u672c\u8868\u793a\u4e3a\u7b56\u7565\u56fe\uff08\u7f16\u7801\u89c4\u8303\u7ed3\u6784\u548c\u4ea4\u53c9\u5f15\u7528\uff09\uff0c\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u8868\u793a\u4e3a\u4e0a\u4e0b\u6587\u56fe\uff08\u5c06\u4e8b\u4ef6\u5f62\u5f0f\u5316\u4e3aSAO\u4e09\u5143\u7ec4\u548c\u5b9e\u4f53\u5173\u7cfb\u4e09\u5143\u7ec4\uff09\uff0c\u5e76\u5bf9\u9f50\u4e24\u8005\u3002\u8fd9\u79cd\u5bf9\u9f50\u5c06\u6cd5\u5b98LLM\u7684\u63a8\u7406\u951a\u5b9a\u5728\u7ed3\u6784\u5316\u4fe1\u606f\u4e2d\u3002", "result": "\u5728300\u4e2aGDPR\u884d\u751f\u7684\u771f\u5b9e\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0cGraphCompliance\u5728\u4e94\u4e2a\u8bc4\u4f30\u4efb\u52a1\u4e0a\u7684micro-F1\u6bd4\u4ec5\u4f7f\u7528LLM\u548cRAG\u57fa\u7ebf\u9ad8\u51fa4.1-7.2\u4e2a\u767e\u5206\u70b9\uff0c\u5177\u6709\u66f4\u5c11\u7684\u6b20\u9884\u6d4b\u548c\u8fc7\u9884\u6d4b\uff0c\u53ec\u56de\u7387\u66f4\u9ad8\uff0c\u8bef\u62a5\u7387\u66f4\u4f4e\u3002", "conclusion": "\u6d88\u878d\u7814\u7a76\u8868\u660e\u6bcf\u4e2a\u56fe\u7ec4\u4ef6\u90fd\u6709\u8d21\u732e\uff0c\u7ed3\u6784\u5316\u8868\u793a\u548c\u6cd5\u5b98LLM\u5728\u89c4\u8303\u63a8\u7406\u4e2d\u662f\u4e92\u8865\u7684\u3002"}}
{"id": "2510.25993", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.25993", "abs": "https://arxiv.org/abs/2510.25993", "authors": ["Darius Masoum Zadeh-Jousdani", "Elvin Hajizada", "Eyke H\u00fcllermeier"], "title": "Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations", "comment": "Accepted at EdgeAI4R Workshop, IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2025", "summary": "Robotic systems operating at the edge require efficient online learning\nalgorithms that can continuously adapt to changing environments while\nprocessing streaming sensory data. Traditional backpropagation, while\neffective, conflicts with biological plausibility principles and may be\nsuboptimal for continuous adaptation scenarios. The Predictive Coding (PC)\nframework offers a biologically plausible alternative with local, Hebbian-like\nupdate rules, making it suitable for neuromorphic hardware implementation.\nHowever, PC's main limitation is its computational overhead due to multiple\ninference iterations during training. We present Predictive Coding Network with\nTemporal Amortization (PCN-TA), which preserves latent states across temporal\nframes. By leveraging temporal correlations, PCN-TA significantly reduces\ncomputational demands while maintaining learning performance. Our experiments\non the COIL-20 robotic perception dataset demonstrate that PCN-TA achieves 10%\nfewer weight updates compared to backpropagation and requires 50% fewer\ninference steps than baseline PC networks. These efficiency gains directly\ntranslate to reduced computational overhead for moving another step toward edge\ndeployment and real-time adaptation support in resource-constrained robotic\nsystems. The biologically-inspired nature of our approach also makes it a\npromising candidate for future neuromorphic hardware implementations, enabling\nefficient online learning at the edge.", "AI": {"tldr": "\u63d0\u51faPCN-TA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u65f6\u95f4\u76f8\u5173\u6027\u51cf\u5c11\u8ba1\u7b97\u9700\u6c42\uff0c\u5728\u4fdd\u6301\u5b66\u4e60\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u7f16\u7801\u7f51\u7edc\u7684\u8ba1\u7b97\u5f00\u9500", "motivation": "\u8fb9\u7f18\u673a\u5668\u4eba\u7cfb\u7edf\u9700\u8981\u9ad8\u6548\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\uff0c\u4f20\u7edf\u53cd\u5411\u4f20\u64ad\u4e0d\u7b26\u5408\u751f\u7269\u5408\u7406\u6027\u539f\u5219\uff0c\u9884\u6d4b\u7f16\u7801\u6846\u67b6\u867d\u5177\u751f\u7269\u5408\u7406\u6027\u4f46\u8ba1\u7b97\u5f00\u9500\u5927", "method": "PCN-TA\u65b9\u6cd5\u901a\u8fc7\u8de8\u65f6\u95f4\u5e27\u4fdd\u7559\u6f5c\u5728\u72b6\u6001\uff0c\u5229\u7528\u65f6\u95f4\u76f8\u5173\u6027\u6765\u51cf\u5c11\u8ba1\u7b97\u9700\u6c42", "result": "\u5728COIL-20\u6570\u636e\u96c6\u4e0a\uff0cPCN-TA\u6bd4\u53cd\u5411\u4f20\u64ad\u51cf\u5c1110%\u6743\u91cd\u66f4\u65b0\uff0c\u6bd4\u57fa\u7ebfPC\u7f51\u7edc\u51cf\u5c1150%\u63a8\u7406\u6b65\u9aa4", "conclusion": "PCN-TA\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5728\u7ebf\u5b66\u4e60\u65b9\u6848\uff0c\u9002\u5408\u672a\u6765\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u5b9e\u73b0"}}
{"id": "2510.26014", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26014", "abs": "https://arxiv.org/abs/2510.26014", "authors": ["Hyeonjun Lee", "Hyungseob Shin", "Gunhee Nam", "Hyeonsoo Lee"], "title": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "comment": "Accepted to NeurIPS 2025 workshop Learning from Time Series for\n  Health (TS4H)", "summary": "Survival analysis is a task to model the time until an event of interest\noccurs, widely used in clinical and biomedical research. A key challenge is to\nmodel patient heterogeneity while also adapting risk predictions to both\nindividual characteristics and temporal dynamics. We propose a dual\nmixture-of-experts (MoE) framework for discrete-time survival analysis. Our\napproach combines a feature-encoder MoE for subgroup-aware representation\nlearning with a hazard MoE that leverages patient features and time embeddings\nto capture temporal dynamics. This dual-MoE design flexibly integrates with\nexisting deep learning based survival pipelines. On METABRIC and GBSG breast\ncancer datasets, our method consistently improves performance, boosting the\ntime-dependent C-index up to 0.04 on the test sets, and yields further gains\nwhen incorporated into the Consurv framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u79bb\u6563\u65f6\u95f4\u751f\u5b58\u5206\u6790\u7684\u53cc\u91cd\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u7279\u5f81\u7f16\u7801\u5668MoE\u548c\u98ce\u9669MoE\uff0c\u5728\u4e73\u817a\u764c\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u751f\u5b58\u5206\u6790\u9700\u8981\u540c\u65f6\u5efa\u6a21\u60a3\u8005\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7075\u6d3b\u6574\u5408\u8fd9\u4e24\u4e2a\u65b9\u9762\u3002", "method": "\u4f7f\u7528\u53cc\u91cdMoE\u6846\u67b6\uff1a\u7279\u5f81\u7f16\u7801\u5668MoE\u7528\u4e8e\u4e9a\u7ec4\u611f\u77e5\u8868\u793a\u5b66\u4e60\uff0c\u98ce\u9669MoE\u5229\u7528\u60a3\u8005\u7279\u5f81\u548c\u65f6\u95f4\u5d4c\u5165\u6355\u6349\u65f6\u95f4\u52a8\u6001\u3002", "result": "\u5728METABRIC\u548cGBSG\u4e73\u817a\u764c\u6570\u636e\u96c6\u4e0a\uff0c\u65f6\u95f4\u4f9d\u8d56\u6027C\u6307\u6570\u5728\u6d4b\u8bd5\u96c6\u4e0a\u63d0\u5347\u9ad8\u8fbe0.04\uff0c\u5728Consurv\u6846\u67b6\u4e2d\u8fdb\u4e00\u6b65\u83b7\u5f97\u589e\u76ca\u3002", "conclusion": "\u53cc\u91cdMoE\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u60a3\u8005\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u663e\u8457\u63d0\u5347\u751f\u5b58\u5206\u6790\u6027\u80fd\uff0c\u5e76\u80fd\u7075\u6d3b\u96c6\u6210\u5230\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u751f\u5b58\u5206\u6790\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2510.26396", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26396", "abs": "https://arxiv.org/abs/2510.26396", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Stanley M. Bileschi"], "title": "A Pragmatic View of AI Personhood", "comment": "40 pages", "summary": "The emergence of agentic Artificial Intelligence (AI) is set to trigger a\n\"Cambrian explosion\" of new kinds of personhood. This paper proposes a\npragmatic framework for navigating this diversification by treating personhood\nnot as a metaphysical property to be discovered, but as a flexible bundle of\nobligations (rights and responsibilities) that societies confer upon entities\nfor a variety of reasons, especially to solve concrete governance problems. We\nargue that this traditional bundle can be unbundled, creating bespoke solutions\nfor different contexts. This will allow for the creation of practical tools --\nsuch as facilitating AI contracting by creating a target \"individual\" that can\nbe sanctioned -- without needing to resolve intractable debates about an AI's\nconsciousness or rationality. We explore how individuals fit in to social roles\nand discuss the use of decentralized digital identity technology, examining\nboth \"personhood as a problem\", where design choices can create \"dark patterns\"\nthat exploit human social heuristics, and \"personhood as a solution\", where\nconferring a bundle of obligations is necessary to ensure accountability or\nprevent conflict. By rejecting foundationalist quests for a single, essential\ndefinition of personhood, this paper offers a more pragmatic and flexible way\nto think about integrating AI agents into our society.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u4eba\u683c\u89c6\u4e3a\u793e\u4f1a\u8d4b\u4e88\u5b9e\u4f53\u7684\u4e49\u52a1\u6346\u7ed1\uff08\u6743\u5229\u4e0e\u8d23\u4efb\uff09\uff0c\u800c\u975e\u5f62\u800c\u4e0a\u5b66\u5c5e\u6027\uff0c\u4e3aAI\u4ee3\u7406\u878d\u5165\u793e\u4f1a\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\u3002", "motivation": "\u5e94\u5bf9AI\u4ee3\u7406\u6d8c\u73b0\u5e26\u6765\u7684\u65b0\u578b\u4eba\u683c\u591a\u6837\u6027\u6311\u6218\uff0c\u907f\u514d\u5173\u4e8eAI\u610f\u8bc6\u6216\u7406\u6027\u7684\u65e0\u89e3\u4e89\u8bba\uff0c\u89e3\u51b3\u5177\u4f53\u6cbb\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4eba\u683c\u4e49\u52a1\u6346\u7ed1\u89e3\u6784\u65b9\u6cd5\uff0c\u5229\u7528\u53bb\u4e2d\u5fc3\u5316\u6570\u5b57\u8eab\u4efd\u6280\u672f\uff0c\u5206\u6790\u4eba\u683c\u4f5c\u4e3a\u95ee\u9898\uff08\u8bbe\u8ba1\u9009\u62e9\u53ef\u80fd\u5229\u7528\u4eba\u7c7b\u793e\u4ea4\u542f\u53d1\u5f0f\uff09\u548c\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff08\u786e\u4fdd\u95ee\u8d23\u6216\u9632\u6b62\u51b2\u7a81\uff09\u7684\u53cc\u91cd\u4f5c\u7528\u3002", "result": "\u5efa\u7acb\u4e86\u65e0\u9700\u89e3\u51b3AI\u610f\u8bc6\u4e89\u8bae\u5373\u53ef\u521b\u5efa\u5b9e\u7528\u5de5\u5177\uff08\u5982\u53ef\u88ab\u5236\u88c1\u7684AI\u5408\u540c\u4e3b\u4f53\uff09\u7684\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u793e\u4f1a\u6574\u5408\u65b9\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u62d2\u7edd\u5bfb\u6c42\u5355\u4e00\u672c\u8d28\u6027\u4eba\u683c\u5b9a\u4e49\u7684\u57fa\u7840\u4e3b\u4e49\u8ffd\u6c42\uff0c\u672c\u6587\u4e3aAI\u4ee3\u7406\u878d\u5165\u793e\u4f1a\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u548c\u7075\u6d3b\u7684\u601d\u8003\u65b9\u5f0f\u3002"}}
{"id": "2510.26068", "categories": ["cs.LG", "cs.AI", "math.DG", "math.ST", "stat.TH", "68T05, 53B21, 65D18, 62B11", "I.2.6; I.5.1; G.1.8; G.4"], "pdf": "https://arxiv.org/pdf/2510.26068", "abs": "https://arxiv.org/abs/2510.26068", "authors": ["Di Zhang"], "title": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "comment": "9 pages", "summary": "This paper proposes a novel paradigm for machine learning that moves beyond\ntraditional parameter optimization. Unlike conventional approaches that search\nfor optimal parameters within a fixed geometric space, our core idea is to\ntreat the model itself as a malleable geometric entity. Specifically, we\noptimize the metric tensor field on a manifold with a predefined topology,\nthereby dynamically shaping the geometric structure of the model space. To\nachieve this, we construct a variational framework whose loss function\ncarefully balances data fidelity against the intrinsic geometric complexity of\nthe manifold. The former ensures the model effectively explains observed data,\nwhile the latter acts as a regularizer, penalizing overly curved or irregular\ngeometries to encourage simpler models and prevent overfitting. To address the\ncomputational challenges of this infinite-dimensional optimization problem, we\nintroduce a practical method based on discrete differential geometry: the\ncontinuous manifold is discretized into a triangular mesh, and the metric\ntensor is parameterized by edge lengths, enabling efficient optimization using\nautomatic differentiation tools. Theoretical analysis reveals a profound\nanalogy between our framework and the Einstein-Hilbert action in general\nrelativity, providing an elegant physical interpretation for the concept of\n\"data-driven geometry\". We further argue that even with fixed topology, metric\noptimization offers significantly greater expressive power than models with\nfixed geometry. This work lays a solid foundation for constructing fully\ndynamic \"meta-learners\" capable of autonomously evolving their geometry and\ntopology, and it points to broad application prospects in areas such as\nscientific model discovery and robust representation learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d85\u8d8a\u4f20\u7edf\u53c2\u6570\u4f18\u5316\u7684\u673a\u5668\u5b66\u4e60\u65b0\u8303\u5f0f\uff0c\u5c06\u6a21\u578b\u89c6\u4e3a\u53ef\u5851\u7684\u51e0\u4f55\u5b9e\u4f53\uff0c\u901a\u8fc7\u4f18\u5316\u9884\u5b9a\u4e49\u62d3\u6251\u6d41\u5f62\u4e0a\u7684\u5ea6\u91cf\u5f20\u91cf\u573a\u6765\u52a8\u6001\u5851\u9020\u6a21\u578b\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u56fa\u5b9a\u51e0\u4f55\u7a7a\u95f4\u4e2d\u641c\u7d22\u6700\u4f18\u53c2\u6570\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u52a8\u6001\u51e0\u4f55\u7ed3\u6784\u4f18\u5316\u6765\u589e\u5f3a\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u3002", "method": "\u6784\u5efa\u53d8\u5206\u6846\u67b6\uff0c\u635f\u5931\u51fd\u6570\u5e73\u8861\u6570\u636e\u4fdd\u771f\u5ea6\u548c\u6d41\u5f62\u5185\u5728\u51e0\u4f55\u590d\u6742\u5ea6\uff1b\u4f7f\u7528\u79bb\u6563\u5fae\u5206\u51e0\u4f55\u65b9\u6cd5\uff0c\u5c06\u8fde\u7eed\u6d41\u5f62\u79bb\u6563\u5316\u4e3a\u4e09\u89d2\u7f51\u683c\uff0c\u901a\u8fc7\u8fb9\u957f\u5ea6\u53c2\u6570\u5316\u5ea6\u91cf\u5f20\u91cf\uff0c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u5de5\u5177\u8fdb\u884c\u9ad8\u6548\u4f18\u5316\u3002", "result": "\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u8be5\u6846\u67b6\u4e0e\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u7231\u56e0\u65af\u5766-\u5e0c\u5c14\u4f2f\u7279\u4f5c\u7528\u7684\u6df1\u523b\u7c7b\u6bd4\uff0c\u4e3a\"\u6570\u636e\u9a71\u52a8\u51e0\u4f55\"\u6982\u5ff5\u63d0\u4f9b\u4e86\u4f18\u96c5\u7269\u7406\u89e3\u91ca\uff1b\u8bc1\u660e\u4e86\u5373\u4f7f\u56fa\u5b9a\u62d3\u6251\uff0c\u5ea6\u91cf\u4f18\u5316\u4e5f\u6bd4\u56fa\u5b9a\u51e0\u4f55\u6a21\u578b\u5177\u6709\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6784\u5efa\u80fd\u591f\u81ea\u4e3b\u6f14\u5316\u51e0\u4f55\u548c\u62d3\u6251\u7684\u5b8c\u5168\u52a8\u6001\"\u5143\u5b66\u4e60\u5668\"\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5728\u79d1\u5b66\u6a21\u578b\u53d1\u73b0\u548c\u9c81\u68d2\u8868\u793a\u5b66\u4e60\u7b49\u9886\u57df\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.26614", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.26614", "abs": "https://arxiv.org/abs/2510.26614", "authors": ["Christoffer Koo \u00d8hrstr\u00f8m", "Ronja G\u00fcldenring", "Lazaros Nalpantidis"], "title": "Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras", "comment": null, "summary": "We propose tokenization of events and present a tokenizer, Spiking Patches,\nspecifically designed for event cameras. Given a stream of asynchronous and\nspatially sparse events, our goal is to discover an event representation that\npreserves these properties. Prior works have represented events as frames or as\nvoxels. However, while these representations yield high accuracy, both frames\nand voxels are synchronous and decrease the spatial sparsity. Spiking Patches\ngives the means to preserve the unique properties of event cameras and we show\nin our experiments that this comes without sacrificing accuracy. We evaluate\nour tokenizer using a GNN, PCN, and a Transformer on gesture recognition and\nobject detection. Tokens from Spiking Patches yield inference times that are up\nto 3.4x faster than voxel-based tokens and up to 10.4x faster than frames. We\nachieve this while matching their accuracy and even surpassing in some cases\nwith absolute improvements up to 3.8 for gesture recognition and up to 1.4 for\nobject detection. Thus, tokenization constitutes a novel direction in\nevent-based vision and marks a step towards methods that preserve the\nproperties of event cameras.", "AI": {"tldr": "\u63d0\u51faSpiking Patches\u4e8b\u4ef6\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u4fdd\u7559\u4e8b\u4ef6\u76f8\u673a\u7684\u5f02\u6b65\u548c\u7a7a\u95f4\u7a00\u758f\u7279\u6027\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u4e8b\u4ef6\u8868\u793a\u4e3a\u5e27\u6216\u4f53\u7d20\uff0c\u867d\u7136\u7cbe\u5ea6\u9ad8\u4f46\u7834\u574f\u4e86\u4e8b\u4ef6\u76f8\u673a\u7684\u5f02\u6b65\u548c\u7a7a\u95f4\u7a00\u758f\u7279\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u4fdd\u7559\u8fd9\u4e9b\u72ec\u7279\u5c5e\u6027\u7684\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1Spiking Patches\u6807\u8bb0\u5668\uff0c\u5c06\u5f02\u6b65\u7a00\u758f\u4e8b\u4ef6\u6d41\u8f6c\u6362\u4e3a\u6807\u8bb0\u8868\u793a\uff0c\u4f7f\u7528GNN\u3001PCN\u548cTransformer\u5728\u59ff\u6001\u8bc6\u522b\u548c\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8bc4\u4f30\u3002", "result": "\u6807\u8bb0\u5316\u65b9\u6cd5\u63a8\u7406\u901f\u5ea6\u6bd4\u4f53\u7d20\u5feb3.4\u500d\uff0c\u6bd4\u5e27\u5feb10.4\u500d\uff0c\u7cbe\u5ea6\u76f8\u5f53\u751a\u81f3\u66f4\u597d\uff08\u59ff\u6001\u8bc6\u522b\u63d0\u53473.8\uff0c\u7269\u4f53\u68c0\u6d4b\u63d0\u53471.4\uff09\u3002", "conclusion": "\u4e8b\u4ef6\u6807\u8bb0\u5316\u662f\u4e8b\u4ef6\u89c6\u89c9\u7684\u65b0\u65b9\u5411\uff0c\u4e3a\u4fdd\u7559\u4e8b\u4ef6\u76f8\u673a\u7279\u6027\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.26412", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26412", "abs": "https://arxiv.org/abs/2510.26412", "authors": ["Xiangqing Zheng", "Chengyue Wu", "Kehai Chen", "Min Zhang"], "title": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "comment": null, "summary": "Recently text-to-video generation has made impressive progress in producing\nshort, high-quality clips, but evaluating long-form outputs remains a major\nchallenge especially when processing complex prompts. Existing benchmarks\nmostly rely on simplified prompts and focus on low-level metrics, overlooking\nfine-grained alignment with prompts and abstract dimensions such as narrative\ncoherence and thematic expression. To address these gaps, we propose\nLoCoT2V-Bench, a benchmark specifically designed for long video generation\n(LVG) under complex input conditions. Based on various real-world videos,\nLoCoT2V-Bench introduces a suite of realistic and complex prompts incorporating\nelements like scene transitions and event dynamics. Moreover, it constructs a\nmulti-dimensional evaluation framework that includes our newly proposed metrics\nsuch as event-level alignment, fine-grained temporal consistency, content\nclarity, and the Human Expectation Realization Degree (HERD) that focuses on\nmore abstract attributes like narrative flow, emotional response, and character\ndevelopment. Using this framework, we conduct a comprehensive evaluation of\nnine representative LVG models, finding that while current methods perform well\non basic visual and temporal aspects, they struggle with inter-event\nconsistency, fine-grained alignment, and high-level thematic adherence, etc.\nOverall, LoCoT2V-Bench provides a comprehensive and reliable platform for\nevaluating long-form complex text-to-video generation and highlights critical\ndirections for future method improvement.", "AI": {"tldr": "\u63d0\u51fa\u4e86LoCoT2V-Bench\u57fa\u51c6\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u590d\u6742\u8f93\u5165\u6761\u4ef6\u4e0b\u7684\u957f\u89c6\u9891\u751f\u6210\uff0c\u5305\u542b\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\u548c\u65b0\u6307\u6807\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u4e8b\u4ef6\u95f4\u4e00\u81f4\u6027\u3001\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u548c\u9ad8\u7ea7\u4e3b\u9898\u9075\u5faa\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u7b80\u5316\u63d0\u793a\u548c\u4f4e\u7ea7\u6307\u6807\uff0c\u5ffd\u89c6\u4e86\u4e0e\u63d0\u793a\u7684\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u4ee5\u53ca\u53d9\u4e8b\u8fde\u8d2f\u6027\u3001\u4e3b\u9898\u8868\u8fbe\u7b49\u62bd\u8c61\u7ef4\u5ea6\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u63d0\u793a\u548c\u957f\u89c6\u9891\u751f\u6210\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u771f\u5b9e\u89c6\u9891\u6784\u5efa\u5305\u542b\u573a\u666f\u8f6c\u6362\u548c\u4e8b\u4ef6\u52a8\u6001\u7684\u73b0\u5b9e\u590d\u6742\u63d0\u793a\u96c6\uff0c\u5efa\u7acb\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ec\u4e8b\u4ef6\u7ea7\u5bf9\u9f50\u3001\u7ec6\u7c92\u5ea6\u65f6\u95f4\u4e00\u81f4\u6027\u3001\u5185\u5bb9\u6e05\u6670\u5ea6\u548c\u5173\u6ce8\u53d9\u4e8b\u6d41\u7a0b\u3001\u60c5\u611f\u54cd\u5e94\u7b49\u62bd\u8c61\u5c5e\u6027\u7684\u4eba\u7c7b\u671f\u671b\u5b9e\u73b0\u5ea6(HERD)\u7b49\u65b0\u6307\u6807\u3002", "result": "\u5bf99\u4e2a\u4ee3\u8868\u6027\u957f\u89c6\u9891\u751f\u6210\u6a21\u578b\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u57fa\u672c\u89c6\u89c9\u548c\u65f6\u95f4\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u4e8b\u4ef6\u95f4\u4e00\u81f4\u6027\u3001\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u548c\u9ad8\u7ea7\u4e3b\u9898\u9075\u5faa\u7b49\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "LoCoT2V-Bench\u4e3a\u957f\u683c\u5f0f\u590d\u6742\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u63d0\u4f9b\u4e86\u5168\u9762\u53ef\u9760\u7684\u8bc4\u4f30\u5e73\u53f0\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u65b9\u6cd5\u6539\u8fdb\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2510.26336", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26336", "abs": "https://arxiv.org/abs/2510.26336", "authors": ["Nishit Neema", "Srinjoy Mukherjee", "Sapan Shah", "Gokul Ramakrishnan", "Ganesh Venkatesh"], "title": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "comment": null, "summary": "Large Language Models (LLMs) excel at general tasks but underperform in\nspecialized domains like economics and psychology, which require deep,\nprincipled understanding. To address this, we introduce ACER (Automated\nCurriculum-Enhanced Regimen) that transforms generalist models into domain\nexperts without sacrificing their broad capabilities. ACER first synthesizes a\ncomprehensive, textbook-style curriculum by generating a table of contents for\na subject and then creating question-answer (QA) pairs guided by Bloom's\ntaxonomy. This ensures systematic topic coverage and progressively increasing\ndifficulty. The resulting synthetic corpus is used for continual pretraining\nwith an interleaved curriculum schedule, aligning learning across both content\nand cognitive dimensions.\n  Experiments with Llama 3.2 (1B and 3B) show significant gains in specialized\nMMLU subsets. In challenging domains like microeconomics, where baselines\nstruggle, ACER boosts accuracy by 5 percentage points. Across all target\ndomains, we observe a consistent macro-average improvement of 3 percentage\npoints. Notably, ACER not only prevents catastrophic forgetting but also\nfacilitates positive cross-domain knowledge transfer, improving performance on\nnon-target domains by 0.7 points. Beyond MMLU, ACER enhances performance on\nknowledge-intensive benchmarks like ARC and GPQA by over 2 absolute points,\nwhile maintaining stable performance on general reasoning tasks. Our results\ndemonstrate that ACER offers a scalable and effective recipe for closing\ncritical domain gaps in LLMs.", "AI": {"tldr": "ACER\u65b9\u6cd5\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u6559\u79d1\u4e66\u5f0f\u8bfe\u7a0b\u548c\u57fa\u4e8e\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u7684QA\u5bf9\uff0c\u5c06\u901a\u7528LLM\u8f6c\u5316\u4e3a\u9886\u57df\u4e13\u5bb6\uff0c\u5728\u4fdd\u6301\u901a\u7528\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e13\u4e1a\u9886\u57df\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u7ecf\u6d4e\u5b66\u3001\u5fc3\u7406\u5b66\u7b49\u4e13\u4e1a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u9886\u57df\u9700\u8981\u6df1\u5165\u3001\u539f\u5219\u6027\u7684\u7406\u89e3\u3002", "method": "ACER\u65b9\u6cd5\uff1a1) \u81ea\u52a8\u751f\u6210\u6559\u79d1\u4e66\u5f0f\u8bfe\u7a0b\u5927\u7eb2\uff1b2) \u57fa\u4e8e\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u521b\u5efaQA\u5bf9\uff1b3) \u4f7f\u7528\u4ea4\u9519\u8bfe\u7a0b\u5b89\u6392\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u786e\u4fdd\u5185\u5bb9\u548c\u8ba4\u77e5\u7ef4\u5ea6\u7684\u5bf9\u9f50\u5b66\u4e60\u3002", "result": "\u5728Llama 3.2\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff1a\u5fae\u89c2\u7ecf\u6d4e\u5b66\u51c6\u786e\u7387\u63d0\u53475\u4e2a\u767e\u5206\u70b9\uff1b\u6240\u6709\u76ee\u6807\u9886\u57df\u5e73\u5747\u63d0\u53473\u4e2a\u767e\u5206\u70b9\uff1b\u975e\u76ee\u6807\u9886\u57df\u4e5f\u63d0\u53470.7\u70b9\uff1bARC\u548cGPQA\u57fa\u51c6\u63d0\u5347\u8d85\u8fc72\u4e2a\u7edd\u5bf9\u70b9\uff1b\u901a\u7528\u63a8\u7406\u4efb\u52a1\u6027\u80fd\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "ACER\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u6765\u7f29\u5c0fLLM\u5728\u5173\u952e\u9886\u57df\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u540c\u65f6\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u5e76\u4fc3\u8fdb\u8de8\u9886\u57df\u77e5\u8bc6\u8fc1\u79fb\u3002"}}
{"id": "2510.26188", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26188", "abs": "https://arxiv.org/abs/2510.26188", "authors": ["Avinash Kadimisetty", "Arun Rajagopalan", "Vijendra SK"], "title": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "comment": "NCMLAI 2018", "summary": "Reducing preventable hospital readmissions is a national priority for payers,\nproviders, and policymakers seeking to improve health care and lower costs. The\nrate of readmission is being used as a benchmark to determine the quality of\nhealthcare provided by the hospitals. In thisproject, we have used machine\nlearning techniques like Logistic Regression, Random Forest and Support Vector\nMachines to analyze the health claims data and identify demographic and medical\nfactors that play a crucial role in predicting all-cause readmissions. As the\nhealth claims data is high dimensional, we have used Principal Component\nAnalysis as a dimension reduction technique and used the results for building\nregression models. We compared and evaluated these models based on the Area\nUnder Curve (AUC) metric. Random Forest model gave the highest performance\nfollowed by Logistic Regression and Support Vector Machine models. These models\ncan be used to identify the crucial factors causing readmissions and help\nidentify patients to focus on to reduce the chances of readmission, ultimately\nbringing down the cost and increasing the quality of healthcare provided to the\npatients.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u5206\u6790\u5065\u5eb7\u7d22\u8d54\u6570\u636e\uff0c\u8bc6\u522b\u5bfc\u81f4\u518d\u5165\u9662\u7684\u5173\u952e\u56e0\u7d20\uff0c\u968f\u673a\u68ee\u6797\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u51cf\u5c11\u53ef\u9884\u9632\u7684\u533b\u9662\u518d\u5165\u9662\u662f\u56fd\u5bb6\u4f18\u5148\u4e8b\u9879\uff0c\u7528\u4e8e\u8bc4\u4f30\u533b\u7597\u8d28\u91cf\u548c\u964d\u4f4e\u6210\u672c\u3002", "method": "\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u548c\u652f\u6301\u5411\u91cf\u673a\u5206\u6790\u9ad8\u7ef4\u5065\u5eb7\u7d22\u8d54\u6570\u636e\uff0c\u91c7\u7528\u4e3b\u6210\u5206\u5206\u6790\u8fdb\u884c\u964d\u7ef4\uff0c\u57fa\u4e8eAUC\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u6027\u80fd\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u903b\u8f91\u56de\u5f52\u548c\u652f\u6301\u5411\u91cf\u673a\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u578b\u53ef\u7528\u4e8e\u8bc6\u522b\u5bfc\u81f4\u518d\u5165\u9662\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e2e\u52a9\u786e\u5b9a\u9700\u8981\u91cd\u70b9\u5173\u6ce8\u7684\u60a3\u8005\uff0c\u4ece\u800c\u964d\u4f4e\u518d\u5165\u9662\u7387\u3001\u51cf\u5c11\u6210\u672c\u5e76\u63d0\u9ad8\u533b\u7597\u8d28\u91cf\u3002"}}
{"id": "2510.26768", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26768", "abs": "https://arxiv.org/abs/2510.26768", "authors": ["Shengnan An", "Xunliang Cai", "Xuezhi Cao", "Xiaoyu Li", "Yehao Lin", "Junlin Liu", "Xinxuan Lv", "Dan Ma", "Xuanlin Wang", "Ziwen Wang", "Shuang Zhou"], "title": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "comment": "14 pages, 9 figures", "summary": "We present AMO-Bench, an Advanced Mathematical reasoning benchmark with\nOlympiad level or even higher difficulty, comprising 50 human-crafted problems.\nExisting benchmarks have widely leveraged high school math competitions for\nevaluating mathematical reasoning capabilities of large language models (LLMs).\nHowever, many existing math competitions are becoming less effective for\nassessing top-tier LLMs due to performance saturation (e.g., AIME24/25). To\naddress this, AMO-Bench introduces more rigorous challenges by ensuring all 50\nproblems are (1) cross-validated by experts to meet at least the International\nMathematical Olympiad (IMO) difficulty standards, and (2) entirely original\nproblems to prevent potential performance leakages from data memorization.\nMoreover, each problem in AMO-Bench requires only a final answer rather than a\nproof, enabling automatic and robust grading for evaluation. Experimental\nresults across 26 LLMs on AMO-Bench show that even the best-performing model\nachieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.\nBeyond these poor performances, our further analysis reveals a promising\nscaling trend with increasing test-time compute on AMO-Bench. These results\nhighlight the significant room for improving the mathematical reasoning in\ncurrent LLMs. We release AMO-Bench to facilitate further research into\nadvancing the reasoning abilities of language models.\nhttps://amo-bench.github.io/", "AI": {"tldr": "AMO-Bench\u662f\u4e00\u4e2a\u9ad8\u7ea7\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b50\u9053\u5965\u6797\u5339\u514b\u7ade\u8d5b\u96be\u5ea6\u6216\u66f4\u9ad8\u7684\u4eba\u7c7b\u7f16\u5199\u95ee\u9898\uff0c\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u9876\u7ea7LLMs\u7684\u8bc4\u4f30\u6548\u679c\u4e0b\u964d\uff0c\u5b58\u5728\u6027\u80fd\u9971\u548c\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u6311\u6218\u6765\u63a8\u52a8\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u8fdb\u6b65\u3002", "method": "\u521b\u5efa50\u9053\u7ecf\u8fc7\u4e13\u5bb6\u4ea4\u53c9\u9a8c\u8bc1\u3001\u7b26\u5408IMO\u96be\u5ea6\u6807\u51c6\u7684\u539f\u521b\u95ee\u9898\uff0c\u4ec5\u8981\u6c42\u6700\u7ec8\u7b54\u6848\u800c\u975e\u8bc1\u660e\uff0c\u5b9e\u73b0\u81ea\u52a8\u8bc4\u5206\u3002", "result": "\u572826\u4e2aLLMs\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6700\u4f73\u6a21\u578b\u51c6\u786e\u7387\u4ec5\u4e3a52.4%\uff0c\u5927\u591a\u6570\u6a21\u578b\u4f4e\u4e8e40%\uff0c\u4f46\u663e\u793a\u51fa\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u589e\u52a0\u7684\u6269\u5c55\u8d8b\u52bf\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\uff0cAMO-Bench\u7684\u53d1\u5e03\u5c06\u4fc3\u8fdb\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.26347", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26347", "abs": "https://arxiv.org/abs/2510.26347", "authors": ["Sebastian Zieglmeier", "Niklas Erdmann", "Narada D. Warakagoda"], "title": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "comment": null, "summary": "Reinforcement learning (RL) algorithms are designed to optimize\nproblem-solving by learning actions that maximize rewards, a task that becomes\nparticularly challenging in random and nonstationary environments. Even\nadvanced RL algorithms are often limited in their ability to solve problems in\nthese conditions. In applications such as searching for underwater pollution\nclouds with autonomous underwater vehicles (AUVs), RL algorithms must navigate\nreward-sparse environments, where actions frequently result in a zero reward.\nThis paper aims to address these challenges by revisiting and modifying\nclassical RL approaches to efficiently operate in sparse, randomized, and\nnonstationary environments. We systematically study a large number of\nmodifications, including hierarchical algorithm changes, multigoal learning,\nand the integration of a location memory as an external output filter to\nprevent state revisits. Our results demonstrate that a modified Monte\nCarlo-based approach significantly outperforms traditional Q-learning and two\nexhaustive search patterns, illustrating its potential in adapting RL to\ncomplex environments. These findings suggest that reinforcement learning\napproaches can be effectively adapted for use in random, nonstationary, and\nreward-sparse environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4fee\u6539\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u7a00\u758f\u3001\u968f\u673a\u548c\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\uff0c\u7279\u522b\u662f\u5728\u6c34\u4e0b\u6c61\u67d3\u4e91\u641c\u7d22\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u968f\u673a\u548c\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u5956\u52b1\u7a00\u758f\u7684\u73af\u5883\u4e2d\uff08\u5982\u81ea\u4e3b\u6c34\u4e0b\u8f66\u8f86\u641c\u7d22\u6c61\u67d3\u4e91\uff09\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u9002\u5e94\u8fd9\u4e9b\u590d\u6742\u6761\u4ef6\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u591a\u79cd\u4fee\u6539\u65b9\u6cd5\uff0c\u5305\u62ec\u5206\u5c42\u7b97\u6cd5\u53d8\u66f4\u3001\u591a\u76ee\u6807\u5b66\u4e60\uff0c\u4ee5\u53ca\u96c6\u6210\u4f4d\u7f6e\u8bb0\u5fc6\u4f5c\u4e3a\u5916\u90e8\u8f93\u51fa\u8fc7\u6ee4\u5668\u4ee5\u9632\u6b62\u72b6\u6001\u91cd\u590d\u8bbf\u95ee\uff0c\u91c7\u7528\u6539\u8fdb\u7684\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u3002", "result": "\u6539\u8fdb\u7684\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edfQ\u5b66\u4e60\u548c\u4e24\u79cd\u7a77\u4e3e\u641c\u7d22\u6a21\u5f0f\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u7684\u6f5c\u529b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u9002\u5e94\u968f\u673a\u3001\u975e\u5e73\u7a33\u548c\u5956\u52b1\u7a00\u758f\u7684\u73af\u5883\uff0c\u4e3a\u590d\u6742\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26376", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26376", "abs": "https://arxiv.org/abs/2510.26376", "authors": ["Ningning Tao", "Fei Xie", "Baoxiang Pan", "Hongyu Wang", "Han Huang", "Zhongpu Qiu", "Ke Gui", "Jiali Luo", "Xiaosong Chen"], "title": "Efficient Generative AI Boosts Probabilistic Forecasting of Sudden Stratospheric Warmings", "comment": null, "summary": "Sudden Stratospheric Warmings (SSWs) are key sources of subseasonal\npredictability and major drivers of extreme winter weather. Yet, their accurate\nand efficient forecast remains a persistent challenge for numerical weather\nprediction (NWP) systems due to limitations in physical representation,\ninitialization, and the immense computational demands of ensemble forecasts.\nWhile data-driven forecasting is rapidly evolving, its application to the\ncomplex, three-dimensional dynamics of SSWs, particularly for probabilistic\nforecast, remains underexplored. Here, we bridge this gap by developing a Flow\nMatching-based generative AI model (FM-Cast) for efficient and skillful\nprobabilistic forecasting of the spatiotemporal evolution of stratospheric\ncirculation. Evaluated across 18 major SSW events (1998-2024), FM-Cast\nskillfully forecasts the onset, intensity, and morphology of 10 events up to 20\ndays in advance, achieving ensemble accuracies above 50%. Its performance is\ncomparable to or exceeds leading NWP systems while requiring only two minutes\nfor a 50-member, 30-day forecast on a consumer GPU. Furthermore, leveraging\nFM-Cast as a scientific tool, we demonstrate through idealized experiments that\nSSW predictability is fundamentally linked to its underlying physical drivers,\ndistinguishing between events forced from the troposphere and those driven by\ninternal stratospheric dynamics. Our work thus establishes a computationally\nefficient paradigm for probabilistic forecasting stratospheric anomalies and\nshowcases generative AI's potential to deepen the physical understanding of\natmosphere-climate dynamics.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u57fa\u4e8eFlow Matching\u7684\u751f\u6210\u5f0fAI\u6a21\u578bFM-Cast\uff0c\u7528\u4e8e\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5e73\u6d41\u5c42\u73af\u6d41\u65f6\u7a7a\u6f14\u53d8\u7684\u6982\u7387\u9884\u62a5\uff0c\u5728SSW\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u6548\u7387\u8fdc\u8d85\u4f20\u7edf\u6570\u503c\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u3002", "motivation": "\u5e73\u6d41\u5c42\u7a81\u7136\u589e\u6e29\u4e8b\u4ef6\u662f\u6b21\u5b63\u8282\u53ef\u9884\u62a5\u6027\u7684\u5173\u952e\u6765\u6e90\u548c\u6781\u7aef\u51ac\u5b63\u5929\u6c14\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u4f20\u7edf\u6570\u503c\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u5728\u7269\u7406\u8868\u793a\u3001\u521d\u59cb\u5316\u548c\u8ba1\u7b97\u9700\u6c42\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u800c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u590d\u6742\u4e09\u7ef4SSW\u52a8\u529b\u5b66\u7279\u522b\u662f\u6982\u7387\u9884\u62a5\u65b9\u9762\u7684\u5e94\u7528\u4ecd\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u57fa\u4e8eFlow Matching\u7684\u751f\u6210\u5f0fAI\u6a21\u578bFM-Cast\uff0c\u5f00\u53d1\u4e86\u5e73\u6d41\u5c42\u73af\u6d41\u65f6\u7a7a\u6f14\u53d8\u7684\u6982\u7387\u9884\u62a5\u7cfb\u7edf\uff0c\u5e76\u572818\u4e2a\u4e3b\u8981SSW\u4e8b\u4ef6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "FM-Cast\u80fd\u591f\u63d0\u524d20\u5929\u51c6\u786e\u9884\u62a510\u4e2aSSW\u4e8b\u4ef6\u7684\u53d1\u751f\u3001\u5f3a\u5ea6\u548c\u5f62\u6001\uff0c\u96c6\u5408\u51c6\u786e\u7387\u8d85\u8fc750%\uff0c\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u9886\u5148\u7684NWP\u7cfb\u7edf\uff0c\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u4ec5\u97002\u5206\u949f\u5373\u53ef\u5b8c\u621050\u4e2a\u6210\u5458\u300130\u5929\u7684\u9884\u62a5\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u8ba1\u7b97\u9ad8\u6548\u7684\u5e73\u6d41\u5c42\u5f02\u5e38\u6982\u7387\u9884\u62a5\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u751f\u6210\u5f0fAI\u5728\u52a0\u6df1\u5bf9\u5927\u6c14-\u6c14\u5019\u52a8\u529b\u5b66\u7269\u7406\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u901a\u8fc7\u7406\u60f3\u5316\u5b9e\u9a8c\u8bc1\u660eSSW\u53ef\u9884\u62a5\u6027\u4e0e\u5176\u57fa\u7840\u7269\u7406\u9a71\u52a8\u56e0\u7d20\u5bc6\u5207\u76f8\u5173\u3002"}}
{"id": "2510.26616", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26616", "abs": "https://arxiv.org/abs/2510.26616", "authors": ["Lin Xu", "Xinyun Yuan", "Yuxuan Liang", "Suwan Yin", "Yuankai Wu"], "title": "Aeolus: A Multi-structural Flight Delay Dataset", "comment": null, "summary": "We introduce Aeolus, a large-scale Multi-modal Flight Delay Dataset designed\nto advance research on flight delay prediction and support the development of\nfoundation models for tabular data. Existing datasets in this domain are\ntypically limited to flat tabular structures and fail to capture the\nspatiotemporal dynamics inherent in delay propagation. Aeolus addresses this\nlimitation by providing three aligned modalities: (i) a tabular dataset with\nrich operational, meteorological, and airportlevel features for over 50 million\nflights; (ii) a flight chain module that models delay propagation along\nsequential flight legs, capturing upstream and downstream dependencies; and\n(iii) a flight network graph that encodes shared aircraft, crew, and airport\nresource connections, enabling cross-flight relational reasoning. The dataset\nis carefully constructed with temporal splits, comprehensive features, and\nstrict leakage prevention to support realistic and reproducible machine\nlearning evaluation. Aeolus supports a broad range of tasks, including\nregression, classification, temporal structure modeling, and graph learning,\nserving as a unified benchmark across tabular, sequential, and graph\nmodalities. We release baseline experiments and preprocessing tools to\nfacilitate adoption. Aeolus fills a key gap for both domain-specific modeling\nand general-purpose structured data research.Our source code and data can be\naccessed at https://github.com/Flnny/Delay-data", "AI": {"tldr": "Aeolus\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u822a\u73ed\u5ef6\u8bef\u6570\u636e\u96c6\uff0c\u5305\u542b\u8868\u683c\u6570\u636e\u3001\u822a\u73ed\u94fe\u6a21\u5757\u548c\u822a\u73ed\u7f51\u7edc\u56fe\u4e09\u79cd\u5bf9\u9f50\u6a21\u6001\uff0c\u7528\u4e8e\u652f\u6301\u822a\u73ed\u5ef6\u8bef\u9884\u6d4b\u548c\u8868\u683c\u6570\u636e\u57fa\u7840\u6a21\u578b\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u822a\u73ed\u5ef6\u8bef\u6570\u636e\u96c6\u901a\u5e38\u5c40\u9650\u4e8e\u5e73\u9762\u8868\u683c\u7ed3\u6784\uff0c\u65e0\u6cd5\u6355\u6349\u5ef6\u8bef\u4f20\u64ad\u7684\u65f6\u7a7a\u52a8\u6001\u7279\u6027\u3002Aeolus\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u4e3a\u9886\u57df\u7279\u5b9a\u5efa\u6a21\u548c\u901a\u7528\u7ed3\u6784\u5316\u6570\u636e\u7814\u7a76\u586b\u8865\u5173\u952e\u7a7a\u767d\u3002", "method": "\u63d0\u4f9b\u4e09\u79cd\u5bf9\u9f50\u6a21\u6001\uff1a1\uff09\u5305\u542b5000\u591a\u4e07\u822a\u73ed\u4e30\u5bcc\u7279\u5f81\u7684\u8868\u683c\u6570\u636e\u96c6\uff1b2\uff09\u5efa\u6a21\u5ef6\u8bef\u6cbf\u8fde\u7eed\u822a\u73ed\u4f20\u64ad\u7684\u822a\u73ed\u94fe\u6a21\u5757\uff1b3\uff09\u7f16\u7801\u5171\u4eab\u8d44\u6e90\u7684\u822a\u73ed\u7f51\u7edc\u56fe\u3002\u6570\u636e\u96c6\u91c7\u7528\u65f6\u95f4\u5206\u5272\u3001\u4e25\u683c\u9632\u6cc4\u6f0f\u8bbe\u8ba1\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u56de\u5f52\u3001\u5206\u7c7b\u3001\u65f6\u5e8f\u7ed3\u6784\u5efa\u6a21\u548c\u56fe\u5b66\u4e60\u7b49\u591a\u79cd\u4efb\u52a1\u7684\u7edf\u4e00\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u4e86\u57fa\u7ebf\u5b9e\u9a8c\u548c\u9884\u5904\u7406\u5de5\u5177\u3002", "conclusion": "Aeolus\u586b\u8865\u4e86\u822a\u73ed\u5ef6\u8bef\u9884\u6d4b\u548c\u8868\u683c\u6570\u636e\u57fa\u7840\u6a21\u578b\u7814\u7a76\u7684\u5173\u952e\u7a7a\u767d\uff0c\u652f\u6301\u8de8\u8868\u683c\u3001\u5e8f\u5217\u548c\u56fe\u6a21\u6001\u7684\u7edf\u4e00\u8bc4\u4f30\u3002"}}
