<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 20]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 7]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs](https://arxiv.org/abs/2512.06258)
*Chaoyang Wang,Yangfan He,Yiyang Zhou,Yixuan Wang,Jiaqi Liu,Peng Xia,Zhengzhong Tu,Mohit Bansal,Huaxiu Yao*

Main category: cs.CV

TL;DR: 论文揭示大型视觉语言模型存在路径选择偏差问题：即使知道正确答案，也常通过错误推理路径得出结果。提出PSO两阶段后训练框架，通过路径选择优化提升推理准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在一个关键但未被充分探索的缺陷：即使模型知道正确答案，也经常通过错误的推理路径得出结果。核心问题不是知识缺乏，而是在庞大的推理搜索空间中的路径选择偏差。模型虽然能够采样正确的解决方案轨迹，但不成比例地偏向不稳定或逻辑不一致的路径，导致结果不稳定和不可靠。

Method: 提出PSO（路径选择优化）两阶段后训练框架：第一阶段使用带有模板和答案奖励的组相对策略优化来培养结构化、逐步推理；第二阶段进行在线偏好优化，模型从GRPO生成的数据中采样推理路径，自我评估，并对齐到优选轨迹。错误或次优路径同时存储在负向回放记忆中作为硬负样本，定期回顾以防止模型重复先前错误并促进持续推理改进。

Result: 广泛实验表明，PSO有效修剪无效推理路径，显著提高推理准确性（平均提升7.4%），并产生更稳定一致的思维链。

Conclusion: PSO框架成功解决了大型视觉语言模型的路径选择偏差问题，通过优化推理路径选择显著提升了模型的推理准确性和稳定性，为改善LVLM的推理可靠性提供了有效方法。

Abstract: We reveal a critical yet underexplored flaw in Large Vision-Language Models (LVLMs): even when these models know the correct answer, they frequently arrive there through incorrect reasoning paths. The core issue is not a lack of knowledge, but a path selection bias within the vast reasoning search space. Although LVLMs are often capable of sampling correct solution trajectories, they disproportionately favor unstable or logically inconsistent ones, leading to erratic and unreliable outcomes. The substantial disparity between Pass@K (with large K) and Pass@1 across numerous models provides compelling evidence that such failures primarily stem from misreasoning rather than ignorance. To systematically investigate and address this issue, we propose PSO (Path-Select Optimization), a two-stage post-training framework designed to enhance both the reasoning performance and stability of existing LVLMs. In the first stage, we employ Group Relative Policy Optimization (GRPO) with template and answer-based rewards to cultivate structured, step-by-step reasoning. In the second stage, we conduct online preference optimization, where the model samples reasoning paths from GRPO-generated data, self-evaluates them, and aligns itself toward the preferred trajectories. Incorrect or suboptimal paths are concurrently stored in a Negative Replay Memory (NRM) as hard negatives, which are periodically revisited to prevent the model from repeating prior mistakes and to facilitate continual reasoning refinement. Extensive experiments show that PSO effectively prunes invalid reasoning paths, substantially enhances reasoning accuracy (with 7.4% improvements on average), and yields more stable and consistent chains of thought. Our code will be available at https://github.com/aiming-lab/PSO.

</details>


### [2] [TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06269)
*Quan Tran,Tuan Dang*

Main category: cs.CV

TL;DR: 本文提出了一种通过多视图三角测量约束来增强3D高斯泼溅几何一致性的新方法，解决了现有方法因仅依赖光度损失导致的浮游伪影和几何不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅方法仅依赖光度损失进行重建，导致几何不一致、浮游伪影和结构混乱的问题，限制了高质量表面的提取。

Method: 通过约束多视图三角测量来增强全局几何一致性，利用多个估计视图达成3D表示的共识，以自监督方式从相邻视图束重新三角化得到鲁棒共识点，并惩罚渲染3D点与共识点的偏差。

Result: 在多个数据集上验证了方法的有效性，在DTU数据集上达到了0.50mm的平均Chamfer距离，优于同类显式方法，取得了最先进的结果。

Conclusion: 提出的约束多视图三角测量方法能有效提升3D高斯泼溅的几何一致性，减少伪影，改善重建质量，代码将开源以促进社区验证和可复现性。

Abstract: 3D Gaussian Splatting is crucial for real-time novel view synthesis due to its efficiency and ability to render photorealistic images. However, building a 3D Gaussian is guided solely by photometric loss, which can result in inconsistencies in reconstruction. This under-constrained process often results in "floater" artifacts and unstructured geometry, preventing the extraction of high-fidelity surfaces. To address this issue, our paper introduces a novel method that improves reconstruction by enforcing global geometry consistency through constrained multi-view triangulation. Our approach aims to achieve a consensus on 3D representation in the physical world by utilizing various estimated views. We optimize this process by penalizing the deviation of a rendered 3D point from a robust consensus point, which is re-triangulated from a bundle of neighboring views in a self-supervised fashion. We demonstrate the effectiveness of our method across multiple datasets, achieving state-of-the-art results. On the DTU dataset, our method attains a mean Chamfer Distance of 0.50 mm, outperforming comparable explicit methods. We will make our code open-source to facilitate community validation and ensure reproducibility.

</details>


### [3] [A Sleep Monitoring System Based on Audio, Video and Depth Information](https://arxiv.org/abs/2512.06282)
*Lyn Chao-ling Chen,Kuan-Wen Chen,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 开发基于事件方法的非侵入式睡眠监测系统，通过红外深度传感器、RGB摄像头和麦克风阵列检测运动、灯光开关和噪音三类事件，用于家庭环境睡眠障碍定量评估。


<details>
  <summary>Details</summary>
Motivation: 需要一种非侵入式的定量评估睡眠障碍的方法，能够在家庭环境中监测睡眠干扰事件，避免传统监测方法对睡眠的干扰。

Method: 使用红外深度传感器、RGB摄像头和四麦克风阵列设备，在低光照环境下监测睡眠。建立深度信号背景模型检测运动幅度，建立彩色图像背景模型检测光照变化，结合事件检测算法从三类传感器数据中识别事件发生。

Result: 系统在睡眠条件下进行了测试，实验结果验证了系统的可靠性，能够有效检测运动、灯光开关和噪音三类睡眠干扰事件。

Conclusion: 提出的基于事件方法的非侵入式睡眠监测系统能够可靠地定量评估睡眠障碍，为家庭环境中的睡眠质量监测提供了有效工具。

Abstract: For quantitative evaluation of sleep disturbances, a noninvasive monitoring system is developed by introducing an event-based method. We observe sleeping in home context and classify the sleep disturbances into three types of events: motion events, light-on/off events and noise events. A device with an infrared depth sensor, a RGB camera, and a four-microphone array is used in sleep monitoring in an environment with barely light sources. One background model is established in depth signals for measuring magnitude of movements. Because depth signals cannot observe lighting changes, another background model is established in color images for measuring magnitude of lighting effects. An event detection algorithm is used to detect occurrences of events from the processed data of the three types of sensors. The system was tested in sleep condition and the experiment result validates the system reliability.

</details>


### [4] [Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation](https://arxiv.org/abs/2512.06306)
*Haoxian Zhou,Chuanzhi Xu,Langyi Chen,Haodong Chen,Yuk Ying Chung,Qiang Qu,Xaoming Chen,Weidong Cai*

Main category: cs.CV

TL;DR: 提出基于点云框架的事件流时空特性利用方法，通过事件时间切片卷积和事件切片序列模块增强人体姿态估计性能


<details>
  <summary>Details</summary>
Motivation: 现有方法将事件流转换为密集事件帧会带来额外计算并牺牲事件信号的高时间分辨率，需要更好地利用事件流的时空特性

Method: 基于点云框架，设计事件时间切片卷积模块捕获事件切片间的短期依赖，结合事件切片序列模块进行结构化时间建模，并在点云表示中应用边缘增强

Result: 在DHP19数据集上，该方法在PointNet、DGCNN和Point Transformer三种代表性点云骨干网络上均能持续提升性能

Conclusion: 提出的方法能有效利用事件流的时空特性，在保持高时间分辨率的同时提升人体姿态估计性能

Abstract: Human pose estimation focuses on predicting body keypoints to analyze human motion. Event cameras provide high temporal resolution and low latency, enabling robust estimation under challenging conditions. However, most existing methods convert event streams into dense event frames, which adds extra computation and sacrifices the high temporal resolution of the event signal. In this work, we aim to exploit the spatiotemporal properties of event streams based on point cloud-based framework, designed to enhance human pose estimation performance. We design Event Temporal Slicing Convolution module to capture short-term dependencies across event slices, and combine it with Event Slice Sequencing module for structured temporal modeling. We also apply edge enhancement in point cloud-based event representation to enhance spatial edge information under sparse event conditions to further improve performance. Experiments on the DHP19 dataset show our proposed method consistently improves performance across three representative point cloud backbones: PointNet, DGCNN, and Point Transformer.

</details>


### [5] [TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search](https://arxiv.org/abs/2512.06353)
*Kaicheng Yang,Kaisen Yang,Baiting Wu,Xun Zhang,Qianrui Yang,Haotong Qin,He Zhang,Yulun Zhang*

Main category: cs.CV

TL;DR: TreeQ是一个统一的DiT量化框架，通过树结构搜索、环境噪声引导和通用Monarch分支解决DiT量化中的关键挑战，首次在DiT模型上实现了接近无损的4位PTQ性能。


<details>
  <summary>Details</summary>
Motivation: DiT在图像生成方面表现出色，但实际部署面临高计算和内存需求。现有的混合精度量化方法在U-Net上成功，但在DiT架构上应用有限且探索不足。

Method: 1. 树结构搜索(TSS)：利用DiT的线性特性在O(n)时间内遍历解空间；2. 环境噪声引导(ENG)：使用单一超参数对齐PTQ和QAT配置；3. 通用Monarch分支(GMB)：结构化稀疏分支防止超低位量化中的信息瓶颈。

Result: 在DiT-XL/2模型上，在W3A3和W4A4 PTQ/PEFT设置下实现了最先进的性能，首次在DiT模型上实现了接近无损的4位PTQ性能。

Conclusion: TreeQ框架有效解决了DiT量化的关键挑战，为DiT模型的实用部署提供了可行的量化解决方案，代码和模型将开源。

Abstract: Diffusion Transformers (DiTs) have emerged as a highly scalable and effective backbone for image generation, outperforming U-Net architectures in both scalability and performance. However, their real-world deployment remains challenging due to high computational and memory demands. Mixed-Precision Quantization (MPQ), designed to push the limits of quantization, has demonstrated remarkable success in advancing U-Net quantization to sub-4bit settings while significantly reducing computational and memory overhead. Nevertheless, its application to DiT architectures remains limited and underexplored. In this work, we propose TreeQ, a unified framework addressing key challenges in DiT quantization. First, to tackle inefficient search and proxy misalignment, we introduce Tree Structured Search (TSS). This DiT-specific approach leverages the architecture's linear properties to traverse the solution space in O(n) time while improving objective accuracy through comparison-based pruning. Second, to unify optimization objectives, we propose Environmental Noise Guidance (ENG), which aligns Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) configurations using a single hyperparameter. Third, to mitigate information bottlenecks in ultra-low-bit regimes, we design the General Monarch Branch (GMB). This structured sparse branch prevents irreversible information loss, enabling finer detail generation. Through extensive experiments, our TreeQ framework demonstrates state-of-the-art performance on DiT-XL/2 under W3A3 and W4A4 PTQ/PEFT settings. Notably, our work is the first to achieve near-lossless 4-bit PTQ performance on DiT models. The code and models will be available at https://github.com/racoonykc/TreeQ

</details>


### [6] [Automated Deep Learning Estimation of Anthropometric Measurements for Preparticipation Cardiovascular Screening](https://arxiv.org/abs/2512.06434)
*Lucas R. Mareque,Ricardo L. Armentano,Leandro J. Cymberknop*

Main category: cs.CV

TL;DR: 提出基于深度学习的全自动方法，从2D合成人体图像估计5项关键人体测量指标，用于运动员心血管风险评估，模型达到亚厘米级精度。


<details>
  <summary>Details</summary>
Motivation: 传统运动员心血管检查中的人工测量方法劳动密集、操作依赖性强、难以规模化，需要自动化解决方案来支持大规模运动员筛查。

Method: 使用从3D身体网格生成的100,000张合成图像数据集，训练并评估VGG19、ResNet50和DenseNet121模型，通过全连接层进行回归分析，预测5项关键人体测量指标。

Result: 所有模型均达到亚厘米级精度，ResNet50表现最佳，在所有测量指标上的平均MAE为0.668厘米，证明深度学习能够提供准确的人体测量数据。

Conclusion: 深度学习方法能够规模化提供准确的人体测量数据，可作为运动员筛查协议的实际工具补充，未来将在真实世界图像上验证模型以扩展应用范围。

Abstract: Preparticipation cardiovascular examination (PPCE) aims to prevent sudden cardiac death (SCD) by identifying athletes with structural or electrical cardiac abnormalities. Anthropometric measurements, such as waist circumference, limb lengths, and torso proportions to detect Marfan syndrome, can indicate elevated cardiovascular risk. Traditional manual methods are labor-intensive, operator-dependent, and challenging to scale. We present a fully automated deep-learning approach to estimate five key anthropometric measurements from 2D synthetic human body images. Using a dataset of 100,000 images derived from 3D body meshes, we trained and evaluated VGG19, ResNet50, and DenseNet121 with fully connected layers for regression. All models achieved sub-centimeter accuracy, with ResNet50 performing best, achieving a mean MAE of 0.668 cm across all measurements. Our results demonstrate that deep learning can deliver accurate anthropometric data at scale, offering a practical tool to complement athlete screening protocols. Future work will validate the models on real-world images to extend applicability.

</details>


### [7] [From Remote Sensing to Multiple Time Horizons Forecasts: Transformers Model for CyanoHAB Intensity in Lake Champlain](https://arxiv.org/abs/2512.06598)
*Muhammad Adil,Patrick J. Clemins,Andrew W. Schroth,Panagiotis D. Oikonomou,Donna M. Rizzo,Peter D. F. Isles,Xiaohan Zhang,Kareem I. Hannoun,Scott Turnbull,Noah B. Beckage,Asim Zia,Safwan Wshah*

Main category: cs.CV

TL;DR: 本研究提出结合Transformer和BiLSTM的遥感预测框架，利用卫星数据预测蓝藻水华强度，可在数据稀疏条件下实现14天提前预警。


<details>
  <summary>Details</summary>
Motivation: 蓝藻有害藻华对水生生态系统和公共健康构成严重威胁，尚普兰湖等水域因营养富集和气候变异性易受其影响。遥感技术可为监测和预报提供可扩展解决方案，弥补现场观测的不足。

Method: 采用Transformer-BiLSTM混合模型，利用蓝藻评估网络的蓝藻指数和中分辨率成像光谱仪的温度数据。针对数据稀疏问题（蓝藻指数缺失30%，温度数据缺失90%），设计了两阶段预处理流程：像素级前向填充和加权时间插补，然后进行平滑处理。通过等频分箱提取蓝藻指数特征，并提取温度统计特征。

Result: 模型在多个预测时间窗口表现优异：1天、2天、3天预测的F1分数分别为89.5%、86.4%、85.5%；14天预测的F1分数为78.9%，AUC为82.6%。证明模型能从稀疏卫星数据中捕捉复杂的时空动态。

Conclusion: 该遥感预测框架能够有效利用稀疏卫星数据，为蓝藻水华管理提供可靠的早期预警，展示了深度学习模型在环境监测中的实用价值。

Abstract: Cyanobacterial Harmful Algal Blooms (CyanoHABs) pose significant threats to aquatic ecosystems and public health globally. Lake Champlain is particularly vulnerable to recurring CyanoHAB events, especially in its northern segment: Missisquoi Bay, St. Albans Bay, and Northeast Arm, due to nutrient enrichment and climatic variability. Remote sensing provides a scalable solution for monitoring and forecasting these events, offering continuous coverage where in situ observations are sparse or unavailable. In this study, we present a remote sensing only forecasting framework that combines Transformers and BiLSTM to predict CyanoHAB intensities up to 14 days in advance. The system utilizes Cyanobacterial Index data from the Cyanobacterial Assessment Network and temperature data from Moderate Resolution Imaging Spectroradiometer satellites to capture long range dependencies and sequential dynamics in satellite time series. The dataset is very sparse, missing more than 30% of the Cyanobacterial Index data and 90% of the temperature data. A two stage preprocessing pipeline addressed data gaps by applying forward fill and weighted temporal imputation at the pixel level, followed by smoothing to reduce the discontinuities of CyanoHAB events. The raw dataset is transformed into meaningful features through equal frequency binning for the Cyanobacterial Index values and extracted temperature statistics. Transformer BiLSTM model demonstrates strong forecasting performance across multiple horizons, achieving F1 scores of 89.5%, 86.4%, and 85.5% at one, two, and three-day forecasts, respectively, and maintaining an F1 score of 78.9% with an AUC of 82.6% at the 14-day horizon. These results confirm the model's ability to capture complex spatiotemporal dynamics from sparse satellite data and to provide reliable early warning for CyanoHABs management.

</details>


### [8] [1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning](https://arxiv.org/abs/2512.06673)
*Shida Gao,Feng Xue,Xiangfeng Wang,Anlong Ming,Teng Long,Yihua Shao,Haozhe Wang,Zhaowen Lin,Wei Wang,Nicu Sebe*

Main category: cs.CV

TL;DR: DEViL是一个结合视频大语言模型和开放词汇检测器的系统，通过参考语义令牌实现端到端学习，解决时空定位中的误差累积问题，并在STVG和GroundedVQA等任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在时空定位任务中采用自回归空间解码，导致输出序列过长，空间误差随时间累积，定位结果在视频中逐渐漂移。需要解决这些问题以提高时空定位的准确性和一致性。

Method: 提出DEViL系统，将视频大语言模型与开放词汇检测器通过参考语义令牌连接。RST既作为控制信号，又替代检测器的文本嵌入，实现端到端学习。同时提出管状挖掘时间正则化，确保检测器生成时间一致的目标查询。

Result: 实验表明DEViL在各种细粒度视频理解任务上表现强劲，特别是在时空视频定位和基于视觉问答任务上取得了优异性能。

Conclusion: DEViL通过结合视频大语言模型和开放词汇检测器，有效解决了自回归空间解码中的误差累积问题，实现了更准确和一致的时空定位与推理。

Abstract: Spatio-temporal grounding and reasoning aims to locate the temporal segment and spatial region of an event in a video given a user query, while also reasoning about semantics such as causality, temporal order, and action relationships. To achieve this, current MLLMs primarily treats bounding boxes as text tokens and generates them autoregressively. However, such autoregressive spatial decoding leads to very-long output sequences, causing spatial errors to accumulated over time and the localization results to progressively drift across a video. To address this, we present a Detector-Empowered Video LLM, short for DEViL, which couples a Video LLM with an open-vocabulary detector (OVD). Specifically, the MLLM and detector are connected via a reference-semantic token (RST) that distills the user query into a rich semantic representation. Unlike tokens that merely serve as spatial prompts or segmentor switches, the RST functions as both a control signal and a replacement for the OVD's text embedding, enabling end-to-end learning of both referential understanding and spatial localization. Furthermore, we propose a tube-mined temporal regularization (TTReg) within OVD, which drives the OVD to generate temporally-consistent queries for target objects, thereby ensuring effective temporal association. Experiments demonstrate that DEViL achieves strong performance across various fine-grained video understanding tasks, particularly STVG and GroundedVQA. Code will be released on https://github.com/gaostar123/DeViL.

</details>


### [9] [Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models](https://arxiv.org/abs/2512.07141)
*Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang*

Main category: cs.CV

TL;DR: 提出Think-Reflect-Revise (TRR)三阶段训练框架，通过策略引导的自我反思增强大型视觉语言模型的安全对齐，将安全响应率从42.8%提升至87.7%。


<details>
  <summary>Details</summary>
Motivation: 现有单次推理方法容易受到上下文或视觉越狱攻击，无法有效识别自身输出中的有害内容。关键洞察是利用被浪费的信号——通过反思利用第一轮推理中揭示的恶意内容，实现真正的自我修正。

Method: 1) 构建包含5000个示例的Reflective Safety Reasoning (ReSafe)数据集，遵循think-reflect-revise流程；2) 使用ReSafe数据集微调目标模型以初始化反思行为；3) 通过强化学习强化策略引导的反思。

Result: TRR显著提升了LVLMs在安全感知基准和越狱攻击评估中的安全性能，Qwen2.5-VL-7B的整体安全响应率从42.8%提高到87.7%，同时在MMMU和MMStar等通用基准上保持稳定性能。

Conclusion: 提出的TRR框架通过自我反思机制有效增强了LVLMs的安全对齐能力，解决了单次推理方法的安全漏洞，在保持通用性能的同时大幅提升了安全响应率。

Abstract: As multimodal reasoning improves the overall capabilities of Large Vision Language Models (LVLMs), recent studies have begun to explore safety-oriented reasoning, aiming to enhance safety awareness by analyzing potential safety risks during the reasoning process before generating the final response. Although such approaches improve safety awareness and interpretability, this single-pass think-then-answer paradigm remains vulnerable to contextual or visual jailbreak attacks. This reveals a critical flaw: single-pass reasoning may overlook explicit harmful content in its own output. Our key insight is to exploit this wasted signal through reflection, which can effectively leverage the malicious content revealed in the first-pass reasoning to enable genuine self-correction and prevent unsafe generations. Motivated by this, we propose Think-Reflect-Revise (TRR), a three-stage training framework designed to enhance the safety alignment of LVLMs through policy-guided self-reflection. We first build a Reflective Safety Reasoning (ReSafe) dataset with 5,000 examples that follow a think-reflect-revise process. We then fine-tune the target model using the ReSafe dataset to initialize reflective behavior, and finally reinforce policy-guided reflection through reinforcement learning. Experimental results show that TRR substantially improves the safety performance of LVLMs across both safety-awareness benchmarks and jailbreak attack evaluations, increasing the overall safe response rate from 42.8% to 87.7% on Qwen2.5-VL-7B, while preserving stable performance on general benchmarks such as MMMU and MMStar. The project page is available at https://think-reflect-revise.github.io/.

</details>


### [10] [Generating Storytelling Images with Rich Chains-of-Reasoning](https://arxiv.org/abs/2512.07198)
*Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu*

Main category: cs.CV

TL;DR: 提出Storytelling Image Generation任务，通过两阶段管道StorytellingPainter结合LLM和T2I模型生成具有丰富语义和推理链的叙事图像，并开发专用评估框架和轻量级Mini-Storytellers模型。


<details>
  <summary>Details</summary>
Motivation: 叙事图像能通过丰富的视觉线索传达复杂故事，具有广泛的应用价值，但由于其复杂的语义特性，这类图像难以创建且数量稀少。需要探索如何利用生成式AI模型来创建这类图像。

Method: 提出两阶段管道StorytellingPainter：1）利用大型语言模型（LLMs）进行创造性推理生成故事；2）使用文本到图像（T2I）模型进行视觉合成。同时开发包含三个主要评估器的专用评估框架：语义复杂性评估器、基于KNN的多样性评估器和故事-图像对齐评估器。针对开源与专有LLM的性能差距，探索定制化训练策略，开发轻量级Mini-Storytellers模型。

Result: 实验结果表明所提方法的可行性和有效性。StorytellingPainter能够生成具有丰富语义连接的叙事图像，评估框架能全面评估生成质量，Mini-Storytellers模型有效缩小了开源与专有LLM的性能差距。

Conclusion: 成功定义了Storytelling Image Generation任务，提出了有效的生成管道和评估框架，并通过轻量级模型解决了故事生成中的性能差距问题，为叙事图像的自动生成提供了可行方案。

Abstract: An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.

</details>


### [11] [CADE: Continual Weakly-supervised Video Anomaly Detection with Ensembles](https://arxiv.org/abs/2512.06840)
*Satoshi Hashimoto,Tatsuya Konishi,Tomoya Kaichi,Kazunori Matsumoto,Mori Kurokawa*

Main category: cs.CV

TL;DR: CADE是首个将持续学习与弱监督视频异常检测相结合的方法，通过双生成器和多判别器集成来解决数据不平衡、标签不确定性和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测方法主要处理静态数据集，忽视了数据域可能变化的问题。当数据域发生变化时，仅用新数据训练会导致对先前数据的性能下降（遗忘），因此需要持续学习视角。

Method: 提出CADE方法：1）使用双生成器（DG）处理WVAD中的数据不平衡和标签不确定性；2）提出多判别器（MD）集成，捕捉因遗忘而错过的过去场景中的异常模式。

Result: 在ShanghaiTech和Charlotte Anomaly等多场景VAD数据集上的广泛实验表明，CADE显著优于现有的VAD方法。

Conclusion: CADE是首个结合持续学习和弱监督视频异常检测的方法，有效解决了数据域变化、遗忘和异常检测不完整性问题，在公共安全和犯罪预防领域具有重要应用价值。

Abstract: Video anomaly detection (VAD) has long been studied as a crucial problem in public security and crime prevention. In recent years, weakly-supervised VAD (WVAD) have attracted considerable attention due to their easy annotation process and promising research results. While existing WVAD methods tackle mainly on static datasets, the possibility that the domain of data can vary has been neglected. To adapt such domain-shift, the continual learning (CL) perspective is required because otherwise additional training only with new coming data could easily cause performance degradation for previous data, i.e., forgetting. Therefore, we propose a brand-new approach, called Continual Anomaly Detection with Ensembles (CADE) that is the first work combining CL and WVAD viewpoints. Specifically, CADE uses the Dual-Generator(DG) to address data imbalance and label uncertainty in WVAD. We also found that forgetting exacerbates the "incompleteness'' where the model becomes biased towards certain anomaly modes, leading to missed detections of various anomalies. To address this, we propose to ensemble Multi-Discriminator (MD) that capture missed anomalies in past scenes due to forgetting, using multiple models. Extensive experiments show that CADE significantly outperforms existing VAD methods on the common multi-scene VAD datasets, such as ShanghaiTech and Charlotte Anomaly datasets.

</details>


### [12] [DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection](https://arxiv.org/abs/2512.07078)
*Bo Gao,Jingcheng Tong,Xingsheng Chen,Han Yu,Zichen Li*

Main category: cs.CV

TL;DR: DFIR-DETR：一种用于无人机遥感图像小目标检测和工业表面缺陷检测的轻量级检测器，通过动态特征聚合和频域处理解决特征退化、长距离依赖和特征膨胀问题。


<details>
  <summary>Details</summary>
Motivation: 无人机遥感图像小目标检测和工业表面缺陷检测面临共同挑战：特征稀疏且弱、背景杂乱、目标尺度变化大。现有基于Transformer的检测器存在三个关键问题：特征随网络下采样严重退化、空间卷积无法有效捕获长距离依赖、标准上采样方法导致特征图不必要膨胀。

Method: 提出DFIR-DETR架构，包含三个核心组件：1) DCFA模块使用动态K稀疏注意力将复杂度从O(N²)降至O(NK)，并采用空间门控线性单元增强非线性建模；2) DFPN模块应用幅度归一化上采样防止特征膨胀，使用双路径洗牌卷积保留跨尺度空间细节；3) FIRC3模块在频域操作，实现全局感受野而不牺牲效率。

Result: 在NEU-DET和VisDrone数据集上分别达到92.9%和51.6%的mAP50分数，均为当前最优。模型轻量级，仅11.7M参数和41.2 GFLOPs，在资源受限环境下表现出色。

Conclusion: DFIR-DETR通过动态特征聚合和频域处理有效解决了小目标检测中的关键挑战，在两个不同领域都表现出强大的泛化能力和实际应用价值，特别适合资源受限的跨场景小目标检测任务。

Abstract: Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencies effectively. Third, standard upsampling methods inflate feature maps unnecessarily.
  We introduce DFIR-DETR to tackle these problems through dynamic feature aggregation combined with frequency-domain processing. Our architecture builds on three novel components. The DCFA module uses dynamic K-sparse attention, cutting complexity from O(N2) down to O(NK), and employs spatial gated linear units for better nonlinear modeling. The DFPN module applies amplitude-normalized upsampling to prevent feature inflation and uses dual-path shuffle convolution to retain spatial details across scales. The FIRC3 module operates in the frequency domain, achieving global receptive fields without sacrificing efficiency.
  We tested our method extensively on NEU-DET and VisDrone datasets. Results show mAP50 scores of 92.9% and 51.6% respectively-both state-of-the-art. The model stays lightweight with just 11.7M parameters and 41.2 GFLOPs. Strong performance across two very different domains confirms that DFIR-DETR generalizes well and works effectively in resource-limited settings for cross-scene small object detection.

</details>


### [13] [ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328)
*Ziyang Mai,Yu-Wing Tai*

Main category: cs.CV

TL;DR: ContextAnyone是一个上下文感知的扩散框架，通过单张参考图像实现角色一致性的文本到视频生成，解决了现有方法在保持发型、服装、体型等上下文特征方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在保持角色一致性方面存在局限，通常只关注面部身份，而忽略了发型、服装、体型等关键上下文特征，这些特征对于视觉连贯性至关重要。

Method: 提出ContextAnyone框架，采用DiT-based扩散主干，通过Emphasize-Attention模块选择性强化参考感知特征，防止身份漂移；使用双引导损失结合扩散和参考重建目标；提出Gap-RoPE位置嵌入分离参考和视频token以稳定时序建模。

Result: 实验表明ContextAnyone在身份一致性和视觉质量方面优于现有参考到视频方法，能够生成跨不同动作和场景的连贯且保持上下文特征的角色视频。

Conclusion: ContextAnyone通过上下文感知的扩散框架有效解决了角色一致性视频生成的挑战，在保持广泛上下文特征的同时实现了高质量的视频生成。

Abstract: Text-to-video (T2V) generation has advanced rapidly, yet maintaining consistent character identities across scenes remains a major challenge. Existing personalization methods often focus on facial identity but fail to preserve broader contextual cues such as hairstyle, outfit, and body shape, which are critical for visual coherence. We propose \textbf{ContextAnyone}, a context-aware diffusion framework that achieves character-consistent video generation from text and a single reference image. Our method jointly reconstructs the reference image and generates new video frames, enabling the model to fully perceive and utilize reference information. Reference information is effectively integrated into a DiT-based diffusion backbone through a novel Emphasize-Attention module that selectively reinforces reference-aware features and prevents identity drift across frames. A dual-guidance loss combines diffusion and reference reconstruction objectives to enhance appearance fidelity, while the proposed Gap-RoPE positional embedding separates reference and video tokens to stabilize temporal modeling. Experiments demonstrate that ContextAnyone outperforms existing reference-to-video methods in identity consistency and visual quality, generating coherent and context-preserving character videos across diverse motions and scenes. Project page: \href{https://github.com/ziyang1106/ContextAnyone}{https://github.com/ziyang1106/ContextAnyone}.

</details>


### [14] [AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing](https://arxiv.org/abs/2512.07247)
*Ziming Hong,Tianyu Huang,Runnan Chen,Shanshan Ye,Mingming Gong,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: AdLift是首个针对3D高斯泼溅（3DGS）的编辑保护方法，通过将严格有界的2D对抗扰动提升到3D高斯表示中，防止任意视角和维度的指令驱动编辑。


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散的指令驱动2D图像编辑扩展到3DGS，虽然促进了3D内容创作，但也使3DGS资产面临未经授权编辑和恶意篡改的风险。现有针对扩散模型的不可感知对抗扰动方法在保护2D图像上有效，但应用于3DGS面临两个主要挑战：视角通用性保护，以及平衡不可见性与保护能力。

Method: 提出AdLift方法，通过提升严格有界的2D对抗扰动到3D高斯表示的保护层。使用定制的Lifted PGD进行渐进优化：在训练视角上进行梯度截断，从编辑模型反向传播到渲染图像，应用投影梯度严格约束图像级扰动；然后通过图像到高斯拟合操作将扰动反向传播到保护高斯参数。交替进行梯度截断和图像到高斯拟合，实现跨不同视角的一致对抗保护性能。

Result: 定性和定量实验结果表明，AdLift能有效防止最先进的指令驱动2D图像和3DGS编辑，在不同视角下提供一致的对抗保护性能，并能泛化到新视角。

Conclusion: AdLift是首个针对3DGS的编辑保护框架，成功解决了视角通用性保护和平衡不可见性与保护能力的挑战，为3DGS资产提供了有效的安全保障。

Abstract: Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.

</details>


### [15] [Data-driven Exploration of Mobility Interaction Patterns](https://arxiv.org/abs/2512.07415)
*Gabriele Galatolo,Mirco Nanni*

Main category: cs.CV

TL;DR: 提出基于数据挖掘的方法，直接从数据中发现个体间相互作用的移动事件模式，用于改进人群模拟模型


<details>
  <summary>Details</summary>
Motivation: 现有解决方案通常基于预设的行为模型，但需要直接从数据中理解个体移动行为及其相互影响，特别是在人群模拟和应急管理等应用中

Method: 采用数据挖掘视角，从数据中搜索可能反映个体间相互作用的移动事件，并在此基础上寻找复杂、持久的事件模式和随时间演化的配置

Result: 在两个真实案例研究（汽车和行人）上实例化了该方法，进行了全面的实验评估，包括性能、参数敏感性和结果解释

Conclusion: 对这些模式的研究可以提供关于个体间移动相互作用机制的新见解，有助于改进现有的模拟模型

Abstract: Understanding the movement behaviours of individuals and the way they react to the external world is a key component of any problem that involves the modelling of human dynamics at a physical level. In particular, it is crucial to capture the influence that the presence of an individual can have on the others. Important examples of applications include crowd simulation and emergency management, where the simulation of the mass of people passes through the simulation of the individuals, taking into consideration the others as part of the general context. While existing solutions basically start from some preconceived behavioural model, in this work we propose an approach that starts directly from the data, adopting a data mining perspective. Our method searches the mobility events in the data that might be possible evidences of mutual interactions between individuals, and on top of them looks for complex, persistent patterns and time evolving configurations of events. The study of these patterns can provide new insights on the mechanics of mobility interactions between individuals, which can potentially help in improving existing simulation models. We instantiate the general methodology on two real case studies, one on cars and one on pedestrians, and a full experimental evaluation is performed, both in terms of performances, parameter sensitivity and interpretation of sample results.

</details>


### [16] [Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation](https://arxiv.org/abs/2512.07568)
*Xuecheng Li,Weikuan Jia,Alisher Kurbonaliev,Qurbonaliev Alisher,Khudzhamkulov Rustam,Ismoilov Shuhratjon,Eshmatov Javhariddin,Yuanjie Zheng*

Main category: cs.CV

TL;DR: 提出DSRSD-Net框架，通过残差分解和语义解相关约束来解耦模态特定和模态共享信息，解决多模态学习中的模态主导、冗余耦合和虚假相关等问题。


<details>
  <summary>Details</summary>
Motivation: 多模态表示存在模态主导、冗余信息耦合和虚假跨模态相关性问题，导致次优泛化和有限可解释性。高方差模态会掩盖较弱但语义重要的信号，而简单的融合策略会以不受控制的方式纠缠模态共享和模态特定因素。

Method: 提出双流残差语义解相关网络(DSRSD-Net)：1) 双流表示学习模块通过残差投影分离模态内(私有)和模态间(共享)潜在因子；2) 残差语义对齐头使用对比和回归式目标将不同模态的共享因子映射到共同空间；3) 解相关和正交性损失正则化共享空间的协方差结构，同时强制共享流和私有流之间的正交性。

Result: 在两个大规模教育基准测试上的实验结果表明，DSRSD-Net在下一步预测和最终结果预测方面持续优于强单模态、早期融合、晚期融合和协同注意力基线。

Conclusion: DSRSD-Net通过解耦模态特定和模态共享信息，有效解决了多模态学习中的关键挑战，提高了预测性能和模型可解释性，同时增强了对噪声或缺失模态的鲁棒性。

Abstract: Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it difficult to understand which modality actually drives a prediction and to maintain robustness when some modalities are noisy or missing. To address these challenges, we propose a Dual-Stream Residual Semantic Decorrelation Network (DSRSD-Net), a simple yet effective framework that disentangles modality-specific and modality-shared information through residual decomposition and explicit semantic decorrelation constraints. DSRSD-Net introduces: (1) a dual-stream representation learning module that separates intra-modal (private) and inter-modal (shared) latent factors via residual projection; (2) a residual semantic alignment head that maps shared factors from different modalities into a common space using a combination of contrastive and regression-style objectives; and (3) a decorrelation and orthogonality loss that regularizes the covariance structure of the shared space while enforcing orthogonality between shared and private streams, thereby suppressing cross-modal redundancy and preventing feature collapse. Experimental results on two large-scale educational benchmarks demonstrate that DSRSD-Net consistently improves next-step prediction and final outcome prediction over strong single-modality, early-fusion, late-fusion, and co-attention baselines.

</details>


### [17] [All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs](https://arxiv.org/abs/2512.07580)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Longzhen Yang,Yihang Liu,Chengmei Yang,Ying Wen,Xianfeng Tang,Hui Liu,Yuyin Zhou,Lianghua He*

Main category: cs.CV

TL;DR: 研究发现视觉大语言模型中深层视觉token信息逐渐消失，提出"信息地平线"概念，发现在深层随机剪枝效果与现有方法相当，结合随机剪枝能提升现有方法性能。


<details>
  <summary>Details</summary>
Motivation: 视觉大语言模型依赖大量视觉token导致计算成本高，现有训练无关的token剪枝方法在深层表现不佳，甚至不如随机剪枝。研究发现这是由于视觉token信息随网络深度增加而逐渐消失。

Method: 提出通过移除token后模型输出概率变化来量化token信息含量。分析发现"信息地平线"现象，即视觉token信息在中间层后变得均匀并最终消失。基于此，在深层采用随机剪枝，并与现有方法结合。

Result: DivPrune结合随机剪枝达到SOTA效果，在剪枝50%视觉token时仍能保持Qwen-2.5-VL-7B模型96.9%的性能。随机剪枝在深层能有效平衡性能与效率。

Conclusion: 视觉token信息随网络深度增加而逐渐消失，形成"信息地平线"。在深层采用随机剪枝是有效策略，结合现有方法能显著提升剪枝效果，为VLLM加速提供新思路。

Abstract: Vision Large Language Models (VLLMs) incur high computational costs due to their reliance on hundreds of visual tokens to represent images. While token pruning offers a promising solution for accelerating inference, this paper, however, identifies a key observation: in deeper layers (e.g., beyond the 20th), existing training-free pruning methods perform no better than random pruning. We hypothesize that this degradation is caused by "vanishing token information", where visual tokens progressively lose their salience with increasing network depth. To validate this hypothesis, we quantify a token's information content by measuring the change in the model output probabilities upon its removal. Using this proposed metric, our analysis of the information of visual tokens across layers reveals three key findings: (1) As layers deepen, the information of visual tokens gradually becomes uniform and eventually vanishes at an intermediate layer, which we term as "information horizon", beyond which the visual tokens become redundant; (2) The position of this horizon is not static; it extends deeper for visually intensive tasks, such as Optical Character Recognition (OCR), compared to more general tasks like Visual Question Answering (VQA); (3) This horizon is also strongly correlated with model capacity, as stronger VLLMs (e.g., Qwen2.5-VL) employ deeper visual tokens than weaker models (e.g., LLaVA-1.5). Based on our findings, we show that simple random pruning in deep layers efficiently balances performance and efficiency. Moreover, integrating random pruning consistently enhances existing methods. Using DivPrune with random pruning achieves state-of-the-art results, maintaining 96.9% of Qwen-2.5-VL-7B performance while pruning 50% of visual tokens. The code will be publicly available at https://github.com/YahongWang1/Information-Horizon.

</details>


### [18] [Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661)
*Shiaho Li,Naisheng Ye,Tianyu Li,Kashyap Chitta,Tuo An,Peng Su,Boyang Wang,Haiou Liu,Chen Lv,Hongyang Li*

Main category: cs.CV

TL;DR: OMEGA是一个优化引导的无训练框架，通过约束优化在扩散采样中增强场景生成的结构一致性和交互感知，能生成更真实、可控的安全关键驾驶场景。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶评估需要真实多样的多智能体驾驶场景，但现有驾驶数据集中安全关键事件稀少且代表性不足。现有数据驱动场景生成模型缺乏可控性或产生违反物理/社会约束的样本，限制了实用性。

Method: 提出OMEGA框架：在扩散模型的反向扩散步骤中通过约束优化重新锚定，引导生成物理合理和行为一致的轨迹。在此基础上，将自我车辆-攻击者交互建模为分布空间的博弈论优化，近似纳什均衡以生成真实的安全关键对抗场景。

Result: 在nuPlan和Waymo数据集上，OMEGA将物理和行为有效场景比例从32.35%提升到72.27%（自由探索），从11%提升到80%（可控生成）。能生成5倍多的碰撞前帧（碰撞时间小于3秒）同时保持场景真实性。

Conclusion: OMEGA通过优化引导的扩散采样显著提升了驾驶场景生成的真实性、一致性和可控性，为自动驾驶系统评估提供了更有效的安全关键场景生成能力。

Abstract: Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.

</details>


### [19] [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720)
*Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出结合3D重建模型和视频扩散模型的方法，从单张图像生成高质量上身3D虚拟形象，解决现有方法在纹理模糊、运动僵硬和结构不稳定等问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D虚拟形象生成存在两难：基于重建的方法能产生稳定结构但纹理模糊、运动僵硬；基于视频生成的方法能产生逼真动态但结构不稳定、身份漂移。需要结合两者优势。

Method: 使用3D重建模型提供结构和外观先验，引导实时自回归视频扩散模型进行渲染，融合几何稳定性和生成能力，实现实时高质量虚拟形象生成。

Result: 实验表明该方法显著减少伪影，在视觉质量上大幅超越现有方法，能生成具有逼真外观和连贯动态的高保真数字虚拟形象。

Conclusion: 通过结合3D重建的几何稳定性和视频模型的生成能力，提出了一种高效实时的高质量上身3D虚拟形象生成方案，适用于游戏和虚拟现实等应用。

Abstract: Generating high-fidelity upper-body 3D avatars from one-shot input image remains a significant challenge. Current 3D avatar generation methods, which rely on large reconstruction models, are fast and capable of producing stable body structures, but they often suffer from artifacts such as blurry textures and stiff, unnatural motion. In contrast, generative video models show promising performance by synthesizing photorealistic and dynamic results, but they frequently struggle with unstable behavior, including body structural errors and identity drift. To address these limitations, we propose a novel approach that combines the strengths of both paradigms. Our framework employs a 3D reconstruction model to provide robust structural and appearance priors, which in turn guides a real-time autoregressive video diffusion model for rendering. This process enables the model to synthesize high-frequency, photorealistic details and fluid dynamics in real time, effectively reducing texture blur and motion stiffness while preventing the structural inconsistencies common in video generation methods. By uniting the geometric stability of 3D reconstruction with the generative capabilities of video models, our method produces high-fidelity digital avatars with realistic appearance and dynamic, temporally coherent motion. Experiments demonstrate that our approach significantly reduces artifacts and achieves substantial improvements in visual quality over leading methods, providing a robust and efficient solution for real-time applications such as gaming and virtual reality. Project page: https://lhyfst.github.io/visa

</details>


### [20] [DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07745)
*Jialv Zou,Shaoyu Chen,Bencheng Liao,Zhiyu Zheng,Yuehao Song,Lefei Zhang,Qian Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionDriveV2使用强化学习解决端到端自动驾驶中扩散模型的模态坍缩问题，通过尺度自适应噪声和分层GRPO方法，在保持多样性的同时提升轨迹质量，在NAVSIM数据集上创下新记录。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式扩散模型在端到端自动驾驶中容易发生模态坍缩，倾向于生成保守和同质化的行为。虽然DiffusionDrive使用预定义锚点来划分动作空间并生成多样化轨迹，但其基于模仿学习的方法缺乏足够约束，导致多样性与一致高质量之间的困境。

Method: 提出DiffusionDriveV2，利用强化学习来约束低质量模态并探索更优轨迹。采用尺度自适应乘法噪声促进广泛探索；使用锚内GRPO管理单个锚点内样本的优势估计，以及锚间截断GRPO整合不同锚点的全局视角，防止不同意图间的不当优势比较。

Result: 在NAVSIM v1数据集上获得91.2 PDMS，在NAVSIM v2数据集上获得85.5 EPDMS（使用对齐的ResNet-34骨干网络），创下新记录。实验验证该方法解决了截断扩散模型中多样性与一致高质量之间的困境，实现了最佳权衡。

Conclusion: DiffusionDriveV2通过强化学习约束和探索机制，显著提升了端到端自动驾驶扩散模型的输出质量，同时保持了高斯混合模型固有的多模态特性，解决了多样性与高质量之间的根本矛盾。

Abstract: Generative diffusion models for end-to-end autonomous driving often suffer from mode collapse, tending to generate conservative and homogeneous behaviors. While DiffusionDrive employs predefined anchors representing different driving intentions to partition the action space and generate diverse trajectories, its reliance on imitation learning lacks sufficient constraints, resulting in a dilemma between diversity and consistent high quality. In this work, we propose DiffusionDriveV2, which leverages reinforcement learning to both constrain low-quality modes and explore for superior trajectories. This significantly enhances the overall output quality while preserving the inherent multimodality of its core Gaussian Mixture Model. First, we use scale-adaptive multiplicative noise, ideal for trajectory planning, to promote broad exploration. Second, we employ intra-anchor GRPO to manage advantage estimation among samples generated from a single anchor, and inter-anchor truncated GRPO to incorporate a global perspective across different anchors, preventing improper advantage comparisons between distinct intentions (e.g., turning vs. going straight), which can lead to further mode collapse. DiffusionDriveV2 achieves 91.2 PDMS on the NAVSIM v1 dataset and 85.5 EPDMS on the NAVSIM v2 dataset in closed-loop evaluation with an aligned ResNet-34 backbone, setting a new record. Further experiments validate that our approach resolves the dilemma between diversity and consistent high quality for truncated diffusion models, achieving the best trade-off. Code and model will be available at https://github.com/hustvl/DiffusionDriveV2

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [21] [A new initialisation to Control Gradients in Sinusoidal Neural network](https://arxiv.org/abs/2512.06427)
*Andrea Combette,Antoine Venaille,Nelly Pustelnik*

Main category: cs.LG

TL;DR: 提出一种针对正弦激活函数网络（如SIREN）的新初始化方法，通过控制梯度和预激活分布来改善训练稳定性和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 初始化策略对缓解神经网络训练中的梯度爆炸或消失至关重要，但对于某些成熟架构（如SIREN）的初始化参数影响仍缺乏精确的理论理解。

Method: 通过预激活分布收敛和雅可比矩阵序列方差的固定点，推导出参数初始化的闭式表达式，控制梯度并针对预激活消失，防止不适当频率的出现。

Result: 新初始化方法在函数拟合和图像重建任务中一致优于原始SIREN方案和其他基线方法，包括涉及物理信息神经网络的广泛重建任务。

Conclusion: 提出的初始化策略通过控制梯度和预激活分布，改善了SIREN网络的训练动态和泛化性能，在多种重建任务中表现优异。

Abstract: Proper initialisation strategy is of primary importance to mitigate gradient explosion or vanishing when training neural networks. Yet, the impact of initialisation parameters still lacks a precise theoretical understanding for several well-established architectures. Here, we propose a new initialisation for networks with sinusoidal activation functions such as \texttt{SIREN}, focusing on gradients control, their scaling with network depth, their impact on training and on generalization. To achieve this, we identify a closed-form expression for the initialisation of the parameters, differing from the original \texttt{SIREN} scheme. This expression is derived from fixed points obtained through the convergence of pre-activation distribution and the variance of Jacobian sequences. Controlling both gradients and targeting vanishing pre-activation helps preventing the emergence of inappropriate frequencies during estimation, thereby improving generalization. We further show that this initialisation strongly influences training dynamics through the Neural Tangent Kernel framework (NTK). Finally, we benchmark \texttt{SIREN} with the proposed initialisation against the original scheme and other baselines on function fitting and image reconstruction. The new initialisation consistently outperforms state-of-the-art methods across a wide range of reconstruction tasks, including those involving physics-informed neural networks.

</details>


### [22] [Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets](https://arxiv.org/abs/2512.06752)
*Chang Liu,Vivian Li,Linus Leong,Vladimir Radenkovic,Pietro Liò,Chaitanya K. Joshi*

Main category: cs.LG

TL;DR: 提出Geometric Graph U-Nets，一种新的几何图神经网络架构，通过递归粗化和细化蛋白质图来学习多尺度表示，在蛋白质折叠分类任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的几何图神经网络和Transformer依赖消息传递机制，无法捕捉蛋白质功能中的层次交互（如全局域和长程变构调节）。作者认为网络架构本身应该反映这种生物层次结构。

Method: 引入Geometric Graph U-Nets，这是一种新的模型类别，通过递归粗化和细化蛋白质图来学习多尺度表示。该层次化设计理论上比标准几何GNN更具表达力。

Result: 在蛋白质折叠分类任务上，Geometric U-Nets显著优于不变和等变基线模型，证明了它们学习定义蛋白质折叠的全局结构模式的能力。

Conclusion: 这项工作为设计能够学习生物分子多尺度结构的几何深度学习架构提供了原则性基础。

Abstract: Geometric Graph Neural Networks (GNNs) and Transformers have become state-of-the-art for learning from 3D protein structures. However, their reliance on message passing prevents them from capturing the hierarchical interactions that govern protein function, such as global domains and long-range allosteric regulation. In this work, we argue that the network architecture itself should mirror this biological hierarchy. We introduce Geometric Graph U-Nets, a new class of models that learn multi-scale representations by recursively coarsening and refining the protein graph. We prove that this hierarchical design can theoretically more expressive than standard Geometric GNNs. Empirically, on the task of protein fold classification, Geometric U-Nets substantially outperform invariant and equivariant baselines, demonstrating their ability to learn the global structural patterns that define protein folds. Our work provides a principled foundation for designing geometric deep learning architectures that can learn the multi-scale structure of biomolecules.

</details>


### [23] [Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse](https://arxiv.org/abs/2512.07400)
*Giulia Lanzillotta,Damiano Meier,Thomas Hofmann*

Main category: cs.LG

TL;DR: 论文揭示了持续学习中特征空间与分类器层面遗忘的不对称性，发现小缓冲区足以防止深度特征遗忘，但需要大缓冲区才能缓解浅层分类器遗忘。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中的一个持久悖论：神经网络即使输出预测失败，仍能保留过去任务的线性可分表示。作者希望形式化特征空间与分类器层面遗忘的区别，并解释经验回放中缓冲区容量的不对称需求。

Method: 将神经崩溃框架扩展到序列设置，分析深度遗忘作为向分布外子空间的几何漂移，证明任何非零回放分数都能保证线性可分性的保留。同时识别小缓冲区引起的"强崩溃"导致协方差秩不足和类别均值膨胀，使分类器无法识别真实群体边界。

Result: 揭示了经验回放中的关键不对称性：最小缓冲区成功锚定特征几何并防止深度遗忘，但缓解浅层遗忘通常需要更大的缓冲区容量。证明了非零回放分数能保证线性可分性的保留，而小缓冲区会导致统计伪影。

Conclusion: 通过将持续学习与分布外检测统一，挑战了对大缓冲区的普遍依赖，表明显式纠正这些统计伪影可能以最小回放实现鲁棒性能。

Abstract: A persistent paradox in continual learning (CL) is that neural networks often retain linearly separable representations of past tasks even when their output predictions fail. We formalize this distinction as the gap between deep feature-space and shallow classifier-level forgetting. We reveal a critical asymmetry in Experience Replay: while minimal buffers successfully anchor feature geometry and prevent deep forgetting, mitigating shallow forgetting typically requires substantially larger buffer capacities. To explain this, we extend the Neural Collapse framework to the sequential setting. We characterize deep forgetting as a geometric drift toward out-of-distribution subspaces and prove that any non-zero replay fraction asymptotically guarantees the retention of linear separability. Conversely, we identify that the "strong collapse" induced by small buffers leads to rank-deficient covariances and inflated class means, effectively blinding the classifier to true population boundaries. By unifying CL with out-of-distribution detection, our work challenges the prevailing reliance on large buffers, suggesting that explicitly correcting these statistical artifacts could unlock robust performance with minimal replay.

</details>


### [24] [Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.07417)
*Giray Önür,Azita Dabiri,Bart De Schutter*

Main category: cs.LG

TL;DR: 提出一个多智能体强化学习框架，通过自适应调整状态反馈交通控制器的参数，结合状态反馈控制器的反应性和强化学习的适应性，提高交通控制效果和系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统交通管理策略（如路线引导、匝道控制、交通信号控制）通常依赖状态反馈控制器，虽然简单反应快，但缺乏适应性，难以应对复杂多变的交通动态。

Method: 提出多智能体强化学习框架，每个智能体自适应调整状态反馈交通控制器的参数（而非直接高频控制），以较低频率调整参数，结合状态反馈控制器的反应性和强化学习的适应性。多智能体结构增强系统鲁棒性，局部控制器在部分故障时可独立运行。

Result: 在模拟的多类别交通网络中进行评估，结果显示：提出的多智能体框架优于无控制和固定参数状态反馈控制，与单智能体RL自适应状态反馈控制性能相当，但对部分故障的恢复能力更强。

Conclusion: 提出的多智能体强化学习框架成功结合了状态反馈控制器的反应性和强化学习的适应性，通过参数调整而非直接控制实现了训练效率提升，多智能体结构增强了系统鲁棒性和故障恢复能力。

Abstract: Effective traffic control is essential for mitigating congestion in transportation networks. Conventional traffic management strategies, including route guidance, ramp metering, and traffic signal control, often rely on state feedback controllers, used for their simplicity and reactivity; however, they lack the adaptability required to cope with complex and time-varying traffic dynamics. This paper proposes a multi-agent reinforcement learning framework in which each agent adaptively tunes the parameters of a state feedback traffic controller, combining the reactivity of state feedback controllers with the adaptability of reinforcement learning. By tuning parameters at a lower frequency rather than directly determining control actions at a high frequency, the reinforcement learning agents achieve improved training efficiency while maintaining adaptability to varying traffic conditions. The multi-agent structure further enhances system robustness, as local controllers can operate independently in the event of partial failures. The proposed framework is evaluated on a simulated multi-class transportation network under varying traffic conditions. Results show that the proposed multi-agent framework outperforms the no control and fixed-parameter state feedback control cases, while performing on par with the single-agent RL-based adaptive state feedback control, with a much better resilience to partial failures.

</details>


### [25] [MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.07430)
*Yangle Li,Danli Luo,Haifeng Hu*

Main category: cs.LG

TL;DR: 提出MIDG框架，通过混合不变专家模型提取域不变特征增强模态间协同关系，并设计跨模态适配器通过知识注入丰富多模态表示，在领域泛化任务上取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析领域泛化方法在提取不变特征时忽略了模态间的协同作用，无法准确捕捉多模态数据的丰富语义信息。同时，知识注入技术存在跨模态知识碎片化问题，忽视了超越单模态界限的特定表示。

Method: 1. 混合不变专家模型：提取域不变特征，增强模型学习模态间协同关系的能力。2. 跨模态适配器：通过跨模态知识注入增强多模态表示的语义丰富度。

Result: 在三个数据集上进行的广泛领域实验表明，所提出的MIDG框架取得了优越的性能。

Conclusion: 提出的MIDG框架通过有效提取域不变特征和跨模态知识注入，解决了多模态情感分析领域泛化中的关键挑战，显著提升了模型性能。

Abstract: Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.

</details>


### [26] [Time Series Foundation Models for Process Model Forecasting](https://arxiv.org/abs/2512.07624)
*Yongbo Yu,Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFMs）在过程模型预测（PMF）中表现优于传统方法，零样本使用即可获得良好效果，微调提升有限。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在过程模型预测中表现有限，主要由于直接跟随关系时间序列的稀疏性和异质性。研究探索时间序列基础模型作为替代方案，评估其在PMF任务中的泛化能力。

Method: 使用真实事件日志生成的直接跟随关系时间序列，比较时间序列基础模型的零样本使用（无需额外训练）与在PMF数据上微调的变体，并与从头训练的传统和专门模型进行对比。

Result: 时间序列基础模型通常比传统和专门模型获得更低的预测误差（MAE和RMSE），表明其能有效从非过程领域迁移时间结构知识。微调虽能进一步提高准确性，但增益通常较小，在较小或更复杂的数据集上可能消失。

Conclusion: 时间序列基础模型在过程相关时间序列预测中展现出强大的泛化能力和数据效率，零样本使用是有效的默认方法。本研究首次系统评估了时间基础模型在过程模型预测中的应用。

Abstract: Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.

</details>


### [27] [Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity](https://arxiv.org/abs/2512.07723)
*Yonggeon Lee,Jibin Hwang,Alfred Malengo Kondoro,Juhyun Song,Youngtae Noh*

Main category: cs.LG

TL;DR: 提出基于Transformer的时间到事件模型，用于准确预测电动汽车用户的出发时间，以优化充电策略并延长电池寿命。


<details>
  <summary>Details</summary>
Motivation: 电动汽车锂电池在高电量状态下会加速退化，可以通过延迟充满电至出发前缓解此问题，但需要准确预测用户出发时间。

Method: 采用Transformer-based实时到事件模型，将每天的时间离散化为网格化token序列，利用流式上下文信息而非仅依赖历史模式来预测出发时间。

Result: 在93名用户的真实世界研究中，使用被动智能手机数据进行评估，该方法能有效捕捉个人日常中的不规则出发模式，性能优于基线模型。

Conclusion: 该方法展示了实际部署潜力，有助于可持续交通系统，通过优化充电策略延长电池寿命。

Abstract: Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \ours algorithm and its contribution to sustainable transportation systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [28] [VIGIL: A Reflective Runtime for Self-Healing Agents](https://arxiv.org/abs/2512.07094)
*Christopher Cruz*

Main category: cs.AI

TL;DR: VIGIL是一个可验证的检查和防护迭代学习框架，作为反射运行时监督兄弟代理，通过情感分析、行为诊断和自动修复实现自主维护，而非任务执行。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理框架脆弱，缺乏运行时自省能力，无法诊断自身故障模式，需要人工干预才能改进。大多数代理系统退化为装饰性的LLM调用链，没有可靠性的结构机制。

Method: VIGIL作为反射运行时，摄入行为日志，将事件评估为结构化情感表示，维护具有衰减和上下文策略的持久情感银行，生成RBT诊断（优势、机会、失败），并产生防护性提示更新和只读代码提案。采用状态门控管道，非法转换会产生显式错误。

Result: 在提醒延迟案例研究中，VIGIL识别出延迟升高，提出提示和代码修复方案。当自身诊断工具因模式冲突失败时，能暴露内部错误，生成备用诊断并发出修复计划，展示了部署代理运行时的元级自我修复能力。

Conclusion: VIGIL实现了代理运行时的自主维护和元级自我修复，解决了现有LLM代理框架缺乏自省和改进能力的问题，为构建更可靠的自主系统提供了新方法。

Abstract: Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime that supervises a sibling agent and performs autonomous maintenance rather than task execution. VIGIL ingests behavioral logs, appraises each event into a structured emotional representation, maintains a persistent EmoBank with decay and contextual policies, and derives an RBT diagnosis that sorts recent behavior into strengths, opportunities, and failures. From this analysis, VIGIL generates both guarded prompt updates that preserve core identity semantics and read only code proposals produced by a strategy engine that operates on log evidence and code hotspots. VIGIL functions as a state gated pipeline. Illegal transitions produce explicit errors rather than allowing the LLM to improvise. In a reminder latency case study, VIGIL identified elevated lag, proposed prompt and code repairs, and when its own diagnostic tool failed due to a schema conflict, it surfaced the internal error, produced a fallback diagnosis, and emitted a repair plan. This demonstrates meta level self repair in a deployed agent runtime.

</details>


### [29] [Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE](https://arxiv.org/abs/2512.07710)
*Anxiang Zeng,Haibo Zhang,Hailing Zhang,Kaixiang Mo,Liang Yao,Ling Hu,Long Zhang,Shuman Liu,Shuyi Xie,Yanshi Li,Yizhang Chen,Yuepeng Sheng,Yuwei Huang,Zhaochen Xu,Zhiqiang Zhou,Ziqin Liew*

Main category: cs.AI

TL;DR: CompassMax-V3-Thinking是一个千亿规模的MoE推理模型，采用新的RL框架训练，核心原则是"每个提示都必须重要"。通过多项技术创新解决了大规模RL训练中的效率问题，实现了稳定高效的大规模MoE模型训练。


<details>
  <summary>Details</summary>
Motivation: 将强化学习扩展到千亿规模时暴露了关键效率问题：零方差提示浪费rollout资源、长时域重要性采样不稳定、标准奖励模型导致的优势反转，以及rollout处理的系统性瓶颈。需要新的方法来使大规模MoE模型的RL训练稳定高效。

Method: 1. 多阶段零方差消除：过滤非信息性提示，稳定基于组的策略优化
2. ESPO：熵自适应优化方法，平衡token级和序列级重要性采样
3. Router Replay策略：对齐训练时MoE路由器和推理时行为，防止优势反转
4. 高吞吐RL系统：FP8精度rollout、重叠奖励计算、长度感知调度

Result: 模型在内部和公开评估中都表现出强大的性能，形成了使千亿规模MoE模型RL训练稳定高效的整体管道。

Conclusion: 这些创新构成了一个连贯的管道，使千亿规模MoE模型的强化学习变得稳定高效。CompassMax-V3-Thinking模型展示了在大规模推理模型中应用强化学习的可行性。

Abstract: We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long horizons, advantage inversion from standard reward models, and systemic bottlenecks in rollout processing. To overcome these challenges, we introduce several unified innovations: (1) Multi-Stage Zero-Variance Elimination, which filters out non-informative prompts and stabilizes group-based policy optimization (e.g. GRPO) by removing wasted rollouts; (2) ESPO, an entropy-adaptive optimization method that balances token-level and sequence-level importance sampling to maintain stable learning dynamics; (3) a Router Replay strategy that aligns training-time MoE router decisions with inference-time behavior to mitigate train-infer discrepancies, coupled with a reward model adjustment to prevent advantage inversion; (4) a high-throughput RL system with FP8-precision rollouts, overlapped reward computation, and length-aware scheduling to eliminate performance bottlenecks. Together, these contributions form a cohesive pipeline that makes RL on hundred-billion-scale MoE models stable and efficient. The resulting model delivers strong performance across both internal and public evaluations.

</details>


### [30] [RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2512.07761)
*Xiqiao Xiong,Ouxiang Li,Zhuo Liu,Moxin Li,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: 该论文提出了一种基于强化学习的多轮越狱攻击方法，通过训练攻击者LLM来从黑盒模型中引出有害内容，相比单轮优化方法显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型容易受到越狱攻击的威胁，影响其在现实应用中的安全部署。现有方法通常依赖单轮优化，不足以学习长期攻击策略，需要更有效的多轮攻击方法。

Method: 将问题建模为多轮强化学习任务，直接优化最终轮输出的有害性作为结果奖励。提出两种启发式过程奖励：1)控制中间输出的有害性以避免触发黑盒模型的拒绝机制；2)保持中间输出的语义相关性以避免偏离主题。

Result: 在多个基准测试上的实验结果显示，该方法在多个模型上持续提高了攻击成功率，证明了方法的有效性。

Conclusion: 通过强化学习框架和多轮攻击策略，能够更有效地实施黑盒多轮越狱攻击，为大语言模型的安全防御提供了重要参考。

Abstract: Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box models through a sequence of prompt-output interactions. Existing approaches typically rely on single turn optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate the problem as a multi-turn reinforcement learning task, directly optimizing the harmfulness of the final-turn output as the outcome reward. To mitigate sparse supervision and promote long-term attack strategies, we propose two heuristic process rewards: (1) controlling the harmfulness of intermediate outputs to prevent triggering the black-box model's rejection mechanisms, and (2) maintaining the semantic relevance of intermediate outputs to avoid drifting into irrelevant content. Experimental results on multiple benchmarks show consistently improved attack success rates across multiple models, highlighting the effectiveness of our approach. The code is available at https://github.com/xxiqiao/RL-MTJail. Warning: This paper contains examples of harmful content.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [Automated Data Enrichment using Confidence-Aware Fine-Grained Debate among Open-Source LLMs for Mental Health and Online Safety](https://arxiv.org/abs/2512.06227)
*Junyu Mao,Anthony Hills,Talia Tseriotou,Maria Liakata,Aya Shamir,Dan Sayda,Dana Atzil-Slonim,Natalie Djohari,Arpan Mandal,Silke Roth,Pamela Ugwudike,Mahesan Niranjan,Stuart E. Middleton*

Main category: cs.CL

TL;DR: 本文提出了一种置信感知细粒度辩论（CFD）框架，通过多个LLM代理模拟人类标注员交换细粒度证据达成共识，用于数据增强，在两个新数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界指标（如心理健康事件、在线安全风险）对NLP任务很重要，但由于这类事件的动态性，在训练数据中标注这些信息成本高且困难。

Method: 提出置信感知细粒度辩论（CFD）框架：多个LLM代理模拟人类标注员，交换细粒度证据达成共识；创建了两个专家标注数据集：心理健康Reddit幸福数据集和在线安全Facebook分享风险数据集。

Result: CFD框架相比多个基线方法表现出最稳健的数据增强性能；数据增强能持续改善下游任务；通过辩论记录整合的增强特征带来最大提升，在线安全任务上比非增强基线提高10.1%。

Conclusion: CFD框架为现实世界指标的数据增强提供了有效解决方案，通过多代理辩论机制显著提升了数据质量和下游任务性能。

Abstract: Real-world indicators are important for improving natural language processing (NLP) tasks such as life events for mental health analysis and risky behaviour for online safety, yet labelling such information in NLP training datasets is often costly and/or difficult given the dynamic nature of such events. This paper compares several LLM-based data enrichment methods and introduces a novel Confidence-Aware Fine-Grained Debate (CFD) framework in which multiple LLM agents simulate human annotators and exchange fine-grained evidence to reach consensus. We describe two new expert-annotated datasets, a mental health Reddit wellbeing dataset and an online safety Facebook sharenting risk dataset. Our CFD framework achieves the most robust data enrichment performance compared to a range of baselines and we show that this type of data enrichment consistently improves downstream tasks. Enriched features incorporated via debate transcripts yield the largest gains, outperforming the non-enriched baseline by 10.1% for the online safety task.

</details>


### [32] [AquaFusionNet: Lightweight VisionSensor Fusion Framework for Real-Time Pathogen Detection and Water Quality Anomaly Prediction on Edge Devices](https://arxiv.org/abs/2512.06848)
*Sepyan Purnama Kristanto,Lutfi Hakim,Hermansyah*

Main category: cs.CL

TL;DR: AquaFusionNet是一个轻量级跨模态框架，将显微成像与水质传感器数据融合，用于小型饮用水系统的实时微生物污染监测，在边缘设备上实现高精度检测。


<details>
  <summary>Details</summary>
Motivation: 现有监测工具只能捕获微生物污染的片段信息，显微成像和物理化学传感器数据需要分开解读，导致实时决策不可靠。在饮用水领域，公开可用的显微数据集稀缺。

Method: 提出AquaFusionNet框架，通过门控交叉注意力机制学习微生物外观与传感器动态之间的统计依赖关系。创建AquaMicro12K数据集（12,846张标注显微图像），专门针对饮用水环境。

Result: 在印度尼西亚东爪哇7个设施部署6个月，处理184万帧图像，污染事件检测mAP@0.5达94.8%，异常预测准确率96.3%，功耗仅4.8W。跨模态耦合减少了单模态检测器的常见故障模式。

Conclusion: AquaFusionNet在可比或更低功耗下提供更高精度，公开所有模型、数据和硬件设计，促进分散式水安全基础设施的复制和适应。

Abstract: Evidence from many low and middle income regions shows that microbial contamination in small scale drinking water systems often fluctuates rapidly, yet existing monitoring tools capture only fragments of this behaviour. Microscopic imaging provides organism level visibility, whereas physicochemical sensors reveal shortterm changes in water chemistry; in practice, operators must interpret these streams separately, making realtime decision-making unreliable. This study introduces AquaFusionNet, a lightweight cross-modal framework that unifies both information sources inside a single edge deployable model. Unlike prior work that treats microscopic detection and water quality prediction as independent tasks, AquaFusionNet learns the statistical dependencies between microbial appearance and concurrent sensor dynamics through a gated crossattention mechanism designed specifically for lowpower hardware. The framework is trained on AquaMicro12K, a new dataset comprising 12,846 annotated 1000 micrographs curated for drinking water contexts, an area where publicly accessible microscopic datasets are scarce. Deployed for six months across seven facilities in East Java, Indonesia, the system processed 1.84 million frames and consistently detected contamination events with 94.8% mAP@0.5 and 96.3% anomaly prediction accuracy, while operating at 4.8 W on a Jetson Nano. Comparative experiments against representative lightweight detectors show that AquaFusionNet provides higher accuracy at comparable or lower power, and field results indicate that cross-modal coupling reduces common failure modes of unimodal detectors, particularly under fouling, turbidity spikes, and inconsistent illumination. All models, data, and hardware designs are released openly to facilitate replication and adaptation in decentralized water safety infrastructures.

</details>


### [33] [Automated PRO-CTCAE Symptom Selection based on Prior Adverse Event Profiles](https://arxiv.org/abs/2512.06919)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla*

Main category: cs.CL

TL;DR: 开发自动化方法从历史安全数据中选择最小但全面的PRO-CTCAE症状子集，平衡信号覆盖与患者负担


<details>
  <summary>Details</summary>
Motivation: PRO-CTCAE系统包含大量症状项目，选择过多会增加患者负担降低依从性，选择过少可能遗漏重要安全信号，需要客观方法优化项目选择

Method: 将PRO-CTCAE症状映射到MedDRA术语，编码到Safeterm语义空间，结合相关性和发生率计算效用函数，通过谱分析识别正交医学概念集，按重要性排序并基于信息解释确定截断点

Result: 开发了集成到Safeterm试验安全应用中的工具，通过模拟和肿瘤学案例研究验证性能，提供客观可重复的方法

Conclusion: 自动化方法利用MedDRA语义和历史数据简化PRO-CTCAE设计，平衡信号覆盖与患者负担，提高临床试验效率

Abstract: The PRO-CTCAE is an NCI-developed patient-reported outcome system for capturing symptomatic adverse events in oncology trials. It comprises a large library drawn from the CTCAE vocabulary, and item selection for a given trial is typically guided by expected toxicity profiles from prior data. Selecting too many PRO-CTCAE items can burden patients and reduce compliance, while too few may miss important safety signals. We present an automated method to select a minimal yet comprehensive PRO-CTCAE subset based on historical safety data. Each candidate PRO-CTCAE symptom term is first mapped to its corresponding MedDRA Preferred Terms (PTs), which are then encoded into Safeterm, a high-dimensional semantic space capturing clinical and contextual diversity in MedDRA terminology. We score each candidate PRO item for relevance to the historical list of adverse event PTs and combine relevance and incidence into a utility function. Spectral analysis is then applied to the combined utility and diversity matrix to identify an orthogonal set of medical concepts that balances relevance and diversity. Symptoms are rank-ordered by importance, and a cut-off is suggested based on the explained information. The tool is implemented as part of the Safeterm trial-safety app. We evaluate its performance using simulations and oncology case studies in which PRO-CTCAE was employed. This automated approach can streamline PRO-CTCAE design by leveraging MedDRA semantics and historical data, providing an objective and reproducible method to balance signal coverage against patient burden.

</details>


### [34] [Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization](https://arxiv.org/abs/2512.07478)
*Zhuoran Zhuang,Ye Chen,Jianghao Su,Chao Luo,Luhui Liu,Xia Zeng*

Main category: cs.CL

TL;DR: 论文提出PRS和VSPO两种技术解决工具集成推理LLM的强化学习问题：PRS通过渐进式奖励塑造提供密集的阶段反馈，VSPO通过基于价值的采样策略优化提升训练稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 工具集成推理LLM在复杂长程任务中面临两个关键挑战：1) 稀疏的二元奖励信号对中间步骤指导有限且收敛慢；2) GRPO中相同奖励组导致零优势估计，降低样本效率并破坏训练稳定性。

Method: 提出两种互补技术：PRS（渐进式奖励塑造）采用课程式奖励设计，分阶段提供密集反馈；VSPO（基于价值的采样策略优化）是GRPO的增强变体，通过价值度量平衡难度和不确定性来筛选提示，并应用价值平滑裁剪稳定梯度更新。

Result: 在多个短形式和长形式QA基准测试中，PRS持续优于传统二元奖励，VSPO相比PPO、GRPO、CISPO和SFT基线展现出更好的稳定性、更快的收敛速度和更高的最终性能。

Conclusion: PRS和VSPO共同产生了能够更好跨领域泛化的基于LLM的工具集成推理智能体，解决了稀疏奖励和梯度退化问题，提升了强化学习训练效果。

Abstract: Large Language Models (LLMs) empowered with Tool-Integrated Reasoning (TIR) can iteratively plan, call external tools, and integrate returned information to solve complex, long-horizon reasoning tasks. Agentic Reinforcement Learning (Agentic RL) optimizes such models over full tool-interaction trajectories, but two key challenges hinder effectiveness: (1) Sparse, non-instructive rewards, such as binary 0-1 verifiable signals, provide limited guidance for intermediate steps and slow convergence; (2) Gradient degradation in Group Relative Policy Optimization (GRPO), where identical rewards within a rollout group yield zero advantage, reducing sample efficiency and destabilizing training. To address these challenges, we propose two complementary techniques: Progressive Reward Shaping (PRS) and Value-based Sampling Policy Optimization (VSPO). PRS is a curriculum-inspired reward design that introduces dense, stage-wise feedback - encouraging models to first master parseable and properly formatted tool calls, then optimize for factual correctness and answer quality. We instantiate PRS for short-form QA (with a length-aware BLEU to fairly score concise answers) and long-form QA (with LLM-as-a-Judge scoring to prevent reward hacking). VSPO is an enhanced GRPO variant that replaces low-value samples with prompts selected by a task-value metric balancing difficulty and uncertainty, and applies value-smoothing clipping to stabilize gradient updates. Experiments on multiple short-form and long-form QA benchmarks show that PRS consistently outperforms traditional binary rewards, and VSPO achieves superior stability, faster convergence, and higher final performance compared to PPO, GRPO, CISPO, and SFT-only baselines. Together, PRS and VSPO yield LLM-based TIR agents that generalize better across domains.

</details>


### [35] [Performance of the SafeTerm AI-Based MedDRA Query System Against Standardised MedDRA Queries](https://arxiv.org/abs/2512.07552)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: SafeTerm AMQ系统通过AI自动检索与医学查询相关的MedDRA术语，在药物安全审查中表现良好，平衡了召回率和精确率。


<details>
  <summary>Details</summary>
Motivation: 在药物上市前安全审查中，将相关不良事件术语分组到SMQs或OCMQs对信号检测至关重要。需要评估自动化系统在MedDRA SMQs上的性能，以辅助人工审查。

Method: SafeTerm AMQ是一个定量AI系统，将医学查询术语和MedDRA PT嵌入多维向量空间，应用余弦相似度和极值聚类生成排名PT列表。在110个SMQs上进行验证，计算不同相似度阈值下的精确率、召回率和F1分数。

Result: 在中等相似度阈值下获得高召回率(94%)，更高阈值可提高精确率(达89%)。最优阈值(0.70)下总体召回率48%、精确率45%。窄术语在更高阈值下表现更好。自动阈值选择(0.66)优先召回率(0.58)而非精确率(0.29)。

Conclusion: SafeTerm AMQ在SMQs和OCMQs上表现相当且令人满意，是自动生成MedDRA查询的可行补充方法，能平衡召回率和精确率。建议使用合适的MedDRA PT术语并应用自动阈值方法优化召回率。

Abstract: In pre-market drug safety review, grouping related adverse event terms into SMQs or OCMQs is critical for signal detection. We assess the performance of SafeTerm Automated Medical Query (AMQ) on MedDRA SMQs. The AMQ is a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score (0-1) using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity, and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against tier-1 SMQs (110 queries, v28.1). Precision, recall and F1 were computed at multiple similarity-thresholds, defined either manually or using an automated method. High recall (94%)) is achieved at moderate similarity thresholds, indicative of good retrieval sensitivity. Higher thresholds filter out more terms, resulting in improved precision (up to 89%). The optimal threshold (0.70)) yielded an overall recall of (48%) and precision of (45%) across all 110 queries. Restricting to narrow-term PTs achieved slightly better performance at an increased (+0.05) similarity threshold, confirming increased relatedness of narrow versus broad terms. The automatic threshold (0.66) selection prioritizes recall (0.58) to precision (0.29). SafeTerm AMQ achieves comparable, satisfactory performance on SMQs and sanitized OCMQs. It is therefore a viable supplementary method for automated MedDRA query generation, balancing recall and precision. We recommend using suitable MedDRA PT terminology in query formulation and applying the automated threshold method to optimise recall. Increasing similarity scores allows refined, narrow terms selection.

</details>


### [36] [Automated Generation of Custom MedDRA Queries Using SafeTerm Medical Map](https://arxiv.org/abs/2512.07694)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: SafeTerm是一个AI驱动的系统，通过向量嵌入和相似度计算自动从MedDRA术语中检索相关不良反应术语，为药物安全审查提供自动化查询生成方法。


<details>
  <summary>Details</summary>
Motivation: 在药物上市前安全审查中，将相关不良事件术语分组到标准化MedDRA查询或FDA OCMQs中对于信号检测至关重要。传统方法需要人工操作，效率较低且可能存在主观偏差。

Method: 系统将医学查询术语和MedDRA首选术语嵌入到多维向量空间中，然后应用余弦相似度和极值聚类方法，生成按相关性分数排名的术语列表。

Result: 在FDA OCMQ v3.0（104个查询）上进行验证，高召回率（>95%）在中等阈值下实现，更高阈值可将精确度提高到86%。最佳阈值（~0.70-0.75）产生约50%的召回率和33%的精确度。

Conclusion: SafeTerm AI驱动系统为自动化MedDRA查询生成提供了可行的补充方法。建议初始使用约0.60的相似度阈值，对于精炼术语选择可增加阈值。

Abstract: In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against the FDA OCMQ v3.0 (104 queries), restricted to valid MedDRA PTs. Precision, recall and F1 were computed across similarity-thresholds. High recall (>95%) is achieved at moderate thresholds. Higher thresholds improve precision (up to 86%). The optimal threshold (~0.70 - 0.75) yielded recall ~50% and precision ~33%. Narrow-term PT subsets performed similarly but required slightly higher similarity thresholds. The SafeTerm AI-driven system provides a viable supplementary method for automated MedDRA query generation. A similarity threshold of ~0.60 is recommended initially, with increased thresholds for refined term selection.

</details>


### [37] [Mary, the Cheeseburger-Eating Vegetarian: Do LLMs Recognize Incoherence in Narratives?](https://arxiv.org/abs/2512.07777)
*Karin de Langis,Püren Öncel,Ryan Peters,Andrew Elfenbein,Laura Kristen Allen,Andreas Schramm,Dongyeop Kang*

Main category: cs.CL

TL;DR: LLMs能识别不连贯故事但无法可靠区分连贯与不连贯叙事，对违反世界知识的错误更敏感，表明对叙事连贯性理解不完整


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能可靠区分连贯与不连贯的故事，探索其叙事理解能力

Method: 使用配对叙事数据集，通过探测研究分析LLMs内部表征，测试不同提示变体下的回答表现

Result: LLMs内部表征能识别不连贯叙事，但生成回答无法可靠区分；对违反设定的错误比对违反角色特质的错误更敏感；思维链无法完全解决内部状态与行为差异

Conclusion: LLMs对叙事连贯性理解不完整，更依赖原型世界知识而非基于意义的叙事连贯性构建

Abstract: Leveraging a dataset of paired narratives, we investigate the extent to which large language models (LLMs) can reliably separate incoherent and coherent stories. A probing study finds that LLMs' internal representations can reliably identify incoherent narratives. However, LLMs generate responses to rating questions that fail to satisfactorily separate the coherent and incoherent narratives across several prompt variations, hinting at a gap in LLM's understanding of storytelling. The reasoning LLMs tested do not eliminate these deficits, indicating that thought strings may not be able to fully address the discrepancy between model internal state and behavior. Additionally, we find that LLMs appear to be more sensitive to incoherence resulting from an event that violates the setting (e.g., a rainy day in the desert) than to incoherence arising from a character violating an established trait (e.g., Mary, a vegetarian, later orders a cheeseburger), suggesting that LLMs may rely more on prototypical world knowledge than building meaning-based narrative coherence. The consistent asymmetry found in our results suggests that LLMs do not have a complete grasp on narrative coherence.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [38] [A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator](https://arxiv.org/abs/2512.07032)
*Runcong Wang,Fengyi Wang,Gordon Cheng*

Main category: cs.RO

TL;DR: 提出一种用于移动机械臂的异联想序列记忆系统，通过神经形态绑定学习关节状态与触觉观测的紧凑表示，实现低计算内存成本的逐步动作决策。


<details>
  <summary>Details</summary>
Motivation: 移动机械臂需要能够快速学习、经济高效地响应触觉输入并执行复杂动作序列的系统。现有方法通常计算成本高或缺乏触觉几何信息的有效整合。

Method: 使用群体位置编码表示关节角度，通过Izhikevich神经元模型将皮肤测得的力转换为脉冲率特征，转化为双极二进制向量后逐元素绑定创建关联，存储在大型容量序列记忆中。引入3D旋转位置嵌入，根据感知力方向旋转子空间，通过softmax加权召回实现模糊检索。

Result: 在丰田HSR机器人上实现了伪柔顺控制器，能够根据施加力的大小和方向移动连杆，并通过持续触觉输入检索多关节抓取序列。系统设置快速，训练同步状态和观测流，具有一定泛化能力且保持经济性。

Conclusion: 该系统通过联想召回实现了单关节和全臂行为，展示了在模仿学习、运动规划和多模态集成方面的扩展潜力，为机器人提供了一种高效、经济的触觉引导行为生成方法。

Abstract: This paper presents a hetero-associative sequential memory system for mobile manipulators that learns compact, neuromorphic bindings between robot joint states and tactile observations to produce step-wise action decisions with low compute and memory cost. The method encodes joint angles via population place coding and converts skin-measured forces into spike-rate features using an Izhikevich neuron model; both signals are transformed into bipolar binary vectors and bound element-wise to create associations stored in a large-capacity sequential memory. To improve separability in binary space and inject geometry from touch, we introduce 3D rotary positional embeddings that rotate subspaces as a function of sensed force direction, enabling fuzzy retrieval through a softmax weighted recall over temporally shifted action patterns. On a Toyota Human Support Robot covered by robot skin, the hetero-associative sequential memory system realizes a pseudocompliance controller that moves the link under touch in the direction and with speed correlating to the amplitude of applied force, and it retrieves multi-joint grasp sequences by continuing tactile input. The system sets up quickly, trains from synchronized streams of states and observations, and exhibits a degree of generalization while remaining economical. Results demonstrate single-joint and full-arm behaviors executed via associative recall, and suggest extensions to imitation learning, motion planning, and multi-modal integration.

</details>


### [39] [SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks](https://arxiv.org/abs/2512.07266)
*Florian Tretter,Daniel Flögel,Alexandru Vasilache,Max Grobbel,Jürgen Becker,Sören Hohmann*

Main category: cs.RO

TL;DR: 提出一种混合社会集成DRL方法，结合SNN和ANN，用于机器人社会导航，显著降低能耗


<details>
  <summary>Details</summary>
Motivation: 将自主移动机器人集成到人类环境中需要类人决策和节能的事件驱动计算。尽管有进展，但神经形态方法很少应用于DRL导航方法，因为训练不稳定。

Method: 采用混合社会集成DRL演员-评论家方法：演员使用SNN，评论家使用ANN，并配备神经形态特征提取器来捕捉时间人群动态和人机交互。

Result: 提高了社会导航性能，并将估计能耗降低了约1.69个数量级（约98%）。

Conclusion: 该方法成功解决了神经形态方法在DRL导航中的训练稳定性问题，实现了节能高效的社会导航。

Abstract: Integrating autonomous mobile robots into human environments requires human-like decision-making and energy-efficient, event-based computation. Despite progress, neuromorphic methods are rarely applied to Deep Reinforcement Learning (DRL) navigation approaches due to unstable training. We address this gap with a hybrid socially integrated DRL actor-critic approach that combines Spiking Neural Networks (SNNs) in the actor with Artificial Neural Networks (ANNs) in the critic and a neuromorphic feature extractor to capture temporal crowd dynamics and human-robot interactions. Our approach enhances social navigation performance and reduces estimated energy consumption by approximately 1.69 orders of magnitude.

</details>


### [40] [Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation](https://arxiv.org/abs/2512.07472)
*Siyu Xu,Zijian Wang,Yunke Wang,Chenghao Xia,Tao Huang,Chang Xu*

Main category: cs.RO

TL;DR: 提出Affordance Field Intervention (AFI)框架，通过3D空间可操作性场引导VLA模型，解决其在分布偏移下的记忆陷阱问题，提升机器人操作鲁棒性。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人操作中表现良好，但在分布偏移场景下容易陷入"记忆陷阱"——重复记忆轨迹而非适应新环境。这源于端到端设计缺乏显式3D空间推理能力，无法可靠识别陌生环境中的可操作区域。

Method: 提出AFI混合框架：1) 使用3D空间可操作性场(SAFs)作为按需插件提供几何表示；2) 通过本体感知检测记忆陷阱；3) 将机器人重新定位到高可操作性区域；4) 提出可操作性驱动的路径点来锚定VLA生成的动作；5) 基于SAF的评分器选择累积可操作性最高的轨迹。

Result: 在真实机器人平台上，不同VLA骨干网络(π₀和π₀.₅)在分布外场景下平均提升23.5%；在LIBERO-Pro基准测试上提升20.2%，显著增强了VLA对分布偏移的鲁棒性。

Conclusion: AFI框架通过整合3D空间可操作性场，有效解决了VLA模型的记忆陷阱问题，提供了一种轻量级混合方法，在不改变VLA架构的情况下显著提升了其在分布偏移场景下的适应能力和鲁棒性。

Abstract: Vision-Language-Action (VLA) models have shown great performance in robotic manipulation by mapping visual observations and language instructions directly to actions. However, they remain brittle under distribution shifts: when test scenarios change, VLAs often reproduce memorized trajectories instead of adapting to the updated scene, which is a failure mode we refer to as the "Memory Trap". This limitation stems from the end-to-end design, which lacks explicit 3D spatial reasoning and prevents reliable identification of actionable regions in unfamiliar environments. To compensate for this missing spatial understanding, 3D Spatial Affordance Fields (SAFs) can provide a geometric representation that highlights where interactions are physically feasible, offering explicit cues about regions the robot should approach or avoid. We therefore introduce Affordance Field Intervention (AFI), a lightweight hybrid framework that uses SAFs as an on-demand plug-in to guide VLA behavior. Our system detects memory traps through proprioception, repositions the robot to recent high-affordance regions, and proposes affordance-driven waypoints that anchor VLA-generated actions. A SAF-based scorer then selects trajectories with the highest cumulative affordance. Extensive experiments demonstrate that our method achieves an average improvement of 23.5% across different VLA backbones ($π_{0}$ and $π_{0.5}$) under out-of-distribution scenarios on real-world robotic platforms, and 20.2% on the LIBERO-Pro benchmark, validating its effectiveness in enhancing VLA robustness to distribution shifts.

</details>
