{"id": "2510.19886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19886", "abs": "https://arxiv.org/abs/2510.19886", "authors": ["Artur Donaldson", "Bharathan Balaji", "Cajetan Oriekezie", "Manish Kumar", "Laure Patouillard"], "title": "An Expert-grounded benchmark of General Purpose LLMs in LCA", "comment": null, "summary": "Purpose: Artificial intelligence (AI), and in particular large language\nmodels (LLMs), are increasingly being explored as tools to support life cycle\nassessment (LCA). While demonstrations exist across environmental and social\ndomains, systematic evidence on their reliability, robustness, and usability\nremains limited. This study provides the first expert-grounded benchmark of\nLLMs in LCA, addressing the absence of standardized evaluation frameworks in a\nfield where no clear ground truth or consensus protocols exist.\n  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial\nand open-source families, across 22 LCA-related tasks. Seventeen experienced\npractitioners reviewed model outputs against criteria directly relevant to LCA\npractice, including scientific accuracy, explanation quality, robustness,\nverifiability, and adherence to instructions. We collected 168 expert reviews.\n  Results: Experts judged 37% of responses to contain inaccurate or misleading\ninformation. Ratings of accuracy and quality of explanation were generally\nrated average or good on many models even smaller models, and format adherence\nwas generally rated favourably. Hallucination rates varied significantly, with\nsome models producing hallucinated citations at rates of up to 40%. There was\nno clear-cut distinction between ratings on open-weight versus closed-weight\nLLMs, with open-weight models outperforming or competing on par with\nclosed-weight models on criteria such as accuracy and quality of explanation.\n  Conclusion: These findings highlight the risks of applying LLMs na\\\"ively in\nLCA, such as when LLMs are treated as free-form oracles, while also showing\nbenefits especially around quality of explanation and alleviating labour\nintensiveness of simple tasks. The use of general-purpose LLMs without\ngrounding mechanisms presents ...", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u901a\u8fc7\u4e13\u5bb6\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e8611\u4e2a\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u547d\u5468\u671f\u8bc4\u4f30(LCA)\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b037%\u7684\u54cd\u5e94\u5305\u542b\u4e0d\u51c6\u786e\u4fe1\u606f\uff0c\u5e7b\u89c9\u7387\u9ad8\u8fbe40%\uff0c\u4f46\u67d0\u4e9b\u6a21\u578b\u5728\u89e3\u91ca\u8d28\u91cf\u548c\u683c\u5f0f\u9075\u5faa\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u547d\u5468\u671f\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u7528\u6027\u7684\u7cfb\u7edf\u6027\u8bc1\u636e\uff0c\u9700\u8981\u5efa\u7acb\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u8bc4\u4f30\u4e8611\u4e2a\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u572822\u4e2aLCA\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u753117\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u4ece\u4e1a\u8005\u6839\u636e\u79d1\u5b66\u51c6\u786e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\u3001\u9c81\u68d2\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u6307\u4ee4\u9075\u5faa\u7b49\u6807\u51c6\u8fdb\u884c\u8bc4\u5ba1\uff0c\u5171\u6536\u96c6168\u4efd\u4e13\u5bb6\u8bc4\u5ba1\u3002", "result": "\u4e13\u5bb6\u5224\u5b9a37%\u7684\u54cd\u5e94\u5305\u542b\u4e0d\u51c6\u786e\u6216\u8bef\u5bfc\u6027\u4fe1\u606f\uff1b\u51c6\u786e\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u8bc4\u5206\u666e\u904d\u4e2d\u7b49\u6216\u826f\u597d\uff1b\u5e7b\u89c9\u7387\u5dee\u5f02\u663e\u8457\uff0c\u67d0\u4e9b\u6a21\u578b\u5e7b\u89c9\u5f15\u7528\u7387\u9ad8\u8fbe40%\uff1b\u5f00\u6e90\u6a21\u578b\u4e0e\u95ed\u6e90\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u7b49\u6807\u51c6\u4e0a\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u5728LCA\u4e2d\u5929\u771f\u5e94\u7528LLM\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u5c06\u5176\u89c6\u4e3a\u81ea\u7531\u5f62\u5f0f\u7684\u795e\u8c15\u65f6\uff0c\u4f46\u4e5f\u663e\u793a\u51fa\u5728\u89e3\u91ca\u8d28\u91cf\u548c\u51cf\u8f7b\u7b80\u5355\u4efb\u52a1\u52b3\u52a8\u5f3a\u5ea6\u65b9\u9762\u7684\u76ca\u5904\uff0c\u65e0\u57fa\u7840\u673a\u5236\u5730\u4f7f\u7528\u901a\u7528LLM\u5b58\u5728\u98ce\u9669\u3002"}}
{"id": "2510.20071", "categories": ["cs.CV", "I.4.1"], "pdf": "https://arxiv.org/pdf/2510.20071", "abs": "https://arxiv.org/abs/2510.20071", "authors": ["Bernd Pfrommer"], "title": "Filter-Based Reconstruction of Images from Events", "comment": null, "summary": "Reconstructing an intensity image from the events of a moving event camera is\na challenging task that is typically approached with neural networks deployed\non graphics processing units. This paper presents a much simpler, FIlter Based\nAsynchronous Reconstruction method (FIBAR). First, intensity changes signaled\nby events are integrated with a temporal digital IIR filter. To reduce\nreconstruction noise, stale pixels are detected by a novel algorithm that\nregulates a window of recently updated pixels. Arguing that for a moving\ncamera, the absence of events at a pixel location likely implies a low image\ngradient, stale pixels are then blurred with a Gaussian filter. In contrast to\nmost existing methods, FIBAR is asynchronous and permits image read-out at an\narbitrary time. It runs on a modern laptop CPU at about 42(140) million\nevents/s with (without) spatial filtering enabled. A few simple qualitative\nexperiments are presented that show the difference in image reconstruction\nbetween FIBAR and a neural network-based approach (FireNet). FIBAR's\nreconstruction is noisier than neural network-based methods and suffers from\nghost images. However, it is sufficient for certain tasks such as the detection\nof fiducial markers. Code is available at\nhttps://github.com/ros-event-camera/event_image_reconstruction_fibar", "AI": {"tldr": "\u63d0\u51faFIBAR\u65b9\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u6ee4\u6ce2\u5668\u7684\u5f02\u6b65\u91cd\u5efa\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u79fb\u52a8\u4e8b\u4ef6\u76f8\u673a\u7684\u4e8b\u4ef6\u4e2d\u91cd\u5efa\u5f3a\u5ea6\u56fe\u50cf\uff0c\u65e0\u9700\u795e\u7ecf\u7f51\u7edc\uff0c\u53ef\u5728CPU\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u5f3a\u5ea6\u56fe\u50cf\u91cd\u5efa\u65b9\u6cd5\u901a\u5e38\u90e8\u7f72\u5728GPU\u4e0a\uff0c\u8ba1\u7b97\u590d\u6742\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u5f02\u6b65\u4e14\u80fd\u5728CPU\u4e0a\u9ad8\u6548\u8fd0\u884c\u7684\u91cd\u5efa\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u6570\u5b57IIR\u6ee4\u6ce2\u5668\u79ef\u5206\u4e8b\u4ef6\u5f3a\u5ea6\u53d8\u5316\uff0c\u901a\u8fc7\u65b0\u9896\u7b97\u6cd5\u68c0\u6d4b\u9648\u65e7\u50cf\u7d20\u5e76\u8c03\u8282\u6700\u8fd1\u66f4\u65b0\u50cf\u7d20\u7a97\u53e3\uff0c\u5bf9\u9648\u65e7\u50cf\u7d20\u5e94\u7528\u9ad8\u65af\u6ee4\u6ce2\u4ee5\u51cf\u5c11\u91cd\u5efa\u566a\u58f0\u3002", "result": "FIBAR\u5728\u7b14\u8bb0\u672c\u7535\u8111CPU\u4e0a\u8fd0\u884c\u901f\u5ea6\u7ea642-140\u767e\u4e07\u4e8b\u4ef6/\u79d2\uff0c\u91cd\u5efa\u56fe\u50cf\u6bd4\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u66f4\u5608\u6742\u4e14\u5b58\u5728\u91cd\u5f71\uff0c\u4f46\u8db3\u4ee5\u5b8c\u6210\u67d0\u4e9b\u4efb\u52a1\u5982\u68c0\u6d4b\u57fa\u51c6\u6807\u8bb0\u3002", "conclusion": "FIBAR\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u5f02\u6b65\u56fe\u50cf\u91cd\u5efa\u66ff\u4ee3\u65b9\u6848\uff0c\u867d\u7136\u91cd\u5efa\u8d28\u91cf\u4e0d\u5982\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u4f46\u5728\u67d0\u4e9b\u5e94\u7528\u573a\u666f\u4e0b\u8db3\u591f\u5b9e\u7528\u3002"}}
{"id": "2510.20033", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20033", "abs": "https://arxiv.org/abs/2510.20033", "authors": ["David Duki\u0107"], "title": "Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models", "comment": null, "summary": "This doctoral thesis improves the transfer learning for sequence labeling\ntasks by adapting pre-trained neural language models. The proposed improvements\nin transfer learning involve introducing a multi-task model that incorporates\nan additional signal, a method based on architectural modifications in\nautoregressive large language models, and a sequence labeling framework for\nautoregressive large language models utilizing supervised in-context\nfine-tuning combined with response-oriented adaptation strategies. The first\nimprovement is given in the context of domain transfer for the event trigger\ndetection task. The domain transfer of the event trigger detection task can be\nimproved by incorporating an additional signal obtained from a\ndomain-independent text processing system into a multi-task model. The second\nimprovement involves modifying the model's architecture. For that purpose, a\nmethod is proposed to enable bidirectional information flow across layers of\nautoregressive large language models. The third improvement utilizes\nautoregressive large language models as text generators through a generative\nsupervised in-context fine-tuning framework. The proposed model, method, and\nframework demonstrate that pre-trained neural language models achieve their\nbest performance on sequence labeling tasks when adapted through targeted\ntransfer learning paradigms.", "AI": {"tldr": "\u8be5\u535a\u58eb\u8bba\u6587\u901a\u8fc7\u6539\u8fdb\u9884\u8bad\u7ec3\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u7684\u6027\u80fd\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a\u5f15\u5165\u591a\u4efb\u52a1\u6a21\u578b\u6574\u5408\u989d\u5916\u4fe1\u53f7\u3001\u4fee\u6539\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u5b9e\u73b0\u53cc\u5411\u4fe1\u606f\u6d41\u3001\u4ee5\u53ca\u4f7f\u7528\u751f\u6210\u5f0f\u76d1\u7763\u4e0a\u4e0b\u6587\u5fae\u8c03\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u8fc1\u79fb\u5b66\u4e60\u6548\u679c\u6709\u5f85\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u9886\u57df\u8fc1\u79fb\u3001\u6a21\u578b\u67b6\u6784\u9002\u5e94\u6027\u548c\u751f\u6210\u5f0f\u65b9\u6cd5\u5e94\u7528\u65b9\u9762\u5b58\u5728\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "1) \u591a\u4efb\u52a1\u6a21\u578b\u6574\u5408\u9886\u57df\u65e0\u5173\u6587\u672c\u5904\u7406\u7cfb\u7edf\u7684\u989d\u5916\u4fe1\u53f7\uff1b2) \u4fee\u6539\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u5b9e\u73b0\u5c42\u95f4\u53cc\u5411\u4fe1\u606f\u6d41\uff1b3) \u751f\u6210\u5f0f\u76d1\u7763\u4e0a\u4e0b\u6587\u5fae\u8c03\u6846\u67b6\u7ed3\u5408\u54cd\u5e94\u5bfc\u5411\u9002\u5e94\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u3001\u65b9\u6cd5\u548c\u6846\u67b6\u8868\u660e\uff0c\u9884\u8bad\u7ec3\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9488\u5bf9\u6027\u8fc1\u79fb\u5b66\u4e60\u8303\u5f0f\uff0c\u5728\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u4e0a\u80fd\u8fbe\u5230\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u67b6\u6784\u4fee\u6539\u548c\u751f\u6210\u5f0f\u5fae\u8c03\u7b49\u9488\u5bf9\u6027\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2510.20036", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20036", "abs": "https://arxiv.org/abs/2510.20036", "authors": ["Marianne Menglin Liu", "Daniel Garcia", "Fjona Parllaku", "Vikas Upadhyay", "Syed Fahad Allam Shah", "Dan Roth"], "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "comment": "Preprint under review", "summary": "Large language model (LLM) agents rely on external tools to solve complex\ntasks, but real-world toolsets often contain redundant tools with overlapping\nnames and descriptions, introducing ambiguity and reducing selection accuracy.\nLLMs also face strict input context limits, preventing efficient consideration\nof large toolsets. To address these challenges, we propose ToolScope, which\nincludes: (1) ToolScopeMerger with Auto-Correction to automatically audit and\nfix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and\nselect only the most relevant tools for each query, compressing toolsets to fit\nwithin context limits without sacrificing accuracy. Evaluations on three\nstate-of-the-art LLMs and three open-source tool-use benchmarks show gains of\n8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's\neffectiveness in enhancing LLM tool use.", "AI": {"tldr": "ToolScope\u901a\u8fc7\u5408\u5e76\u5197\u4f59\u5de5\u5177\u548c\u68c0\u7d22\u76f8\u5173\u5de5\u5177\uff0c\u63d0\u5347LLM\u5728\u5927\u578b\u5de5\u5177\u96c6\u4e0a\u7684\u9009\u62e9\u51c6\u786e\u7387\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b08.38%\u81f338.6%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u5de5\u5177\u96c6\u5e38\u5305\u542b\u5197\u4f59\u5de5\u5177\uff0c\u5de5\u5177\u540d\u79f0\u548c\u63cf\u8ff0\u91cd\u53e0\u5bfc\u81f4\u9009\u62e9\u6b67\u4e49\uff0c\u4e14LLM\u53d7\u9650\u4e8e\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5927\u578b\u5de5\u5177\u96c6\u3002", "method": "ToolScope\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1aToolScopeMerger\u901a\u8fc7\u81ea\u52a8\u6821\u6b63\u81ea\u52a8\u5ba1\u8ba1\u548c\u4fee\u590d\u5de5\u5177\u5408\u5e76\u4ee5\u51cf\u5c11\u5197\u4f59\uff1bToolScopeRetriever\u5bf9\u5de5\u5177\u8fdb\u884c\u6392\u5e8f\u548c\u9009\u62e9\uff0c\u4ec5\u4fdd\u7559\u6700\u76f8\u5173\u5de5\u5177\u4ee5\u538b\u7f29\u5de5\u5177\u96c6\u3002", "result": "\u5728\u4e09\u4e2a\u6700\u5148\u8fdbLLM\u548c\u4e09\u4e2a\u5f00\u6e90\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5de5\u5177\u9009\u62e9\u51c6\u786e\u7387\u63d0\u53478.38%\u81f338.6%\u3002", "conclusion": "ToolScope\u80fd\u6709\u6548\u589e\u5f3aLLM\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u901a\u8fc7\u51cf\u5c11\u5197\u4f59\u548c\u538b\u7f29\u5de5\u5177\u96c6\u6765\u89e3\u51b3\u5de5\u5177\u9009\u62e9\u6b67\u4e49\u548c\u4e0a\u4e0b\u6587\u9650\u5236\u95ee\u9898\u3002"}}
{"id": "2510.20019", "categories": ["cs.LG", "cs.CR", "2020: Primary 68T05, Secondary 68T10", "I.2.6; I.6.4; C.3"], "pdf": "https://arxiv.org/pdf/2510.20019", "abs": "https://arxiv.org/abs/2510.20019", "authors": ["Curtis Lee Shull", "Merrick Green"], "title": "Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications", "comment": "10 pages, 5 figures. Submitted to the Journal of Defense Modeling and\n  Simulation (JDMS) for the Special Issue Integrating AI/ML Into Modeling and\n  Simulation (J22-4). This work evaluates machine learning-based RFID\n  localization for defense logistics environments using CAD-modeled simulations\n  and RSSI-driven decision tree classification", "summary": "Radio Frequency Identification (RFID) tracking may be a viable solution for\ndefense assets that must be stored in accordance with security guidelines.\nHowever, poor sensor specificity (vulnerabilities include long range detection,\nspoofing, and counterfeiting) can lead to erroneous detection and operational\nsecurity events. We present a supervised learning simulation with realistic\nReceived Signal Strength Indicator (RSSI) data and Decision Tree classification\nin a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some\nof the challenges encountered in defense storage. In this work, we focused on\nclassifying 12 lab zones (LabZoneA-L) to perform location inference. The raw\ndataset had approximately 980,000 reads. Class frequencies were imbalanced, and\nclass weights were calculated to account for class imbalance in this\nmulti-class setting. The model, trained on stratified subsamples to 5,000\nbalanced observations, yielded an overall accuracy of 34.2% and F1-scores\ngreater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare\nclasses (most notably LabZoneC) were often misclassified, even with the use of\nclass weights. An adjacency-aware confusion matrix was calculated to allow\nbetter interpretation of physically adjacent zones. These results suggest that\nRSSI-based decision trees can be applied in realistic simulations to enable\nzone-level anomaly detection or misplacement monitoring for defense supply\nlogistics. Reliable classification performance in low-coverage and low-signal\nzones could be improved with better antenna placement or additional sensors and\nsensor fusion with other modalities.", "AI": {"tldr": "\u4f7f\u7528\u76d1\u7763\u5b66\u4e60\u548c\u51b3\u7b56\u6811\u5206\u7c7b\u5668\uff0c\u57fa\u4e8eRFID\u7684RSSI\u6570\u636e\u8fdb\u884c\u4f4d\u7f6e\u63a8\u65ad\uff0c\u5728\u6a21\u62df\u56fd\u9632\u5b58\u50a8\u73af\u5883\u4e2d\u5bf912\u4e2a\u5b9e\u9a8c\u5ba4\u533a\u57df\u8fdb\u884c\u5206\u7c7b\uff0c\u603b\u4f53\u51c6\u786e\u738734.2%\uff0c\u90e8\u5206\u533a\u57dfF1\u5206\u6570\u8d85\u8fc70.40\u3002", "motivation": "\u89e3\u51b3RFID\u8ddf\u8e2a\u5728\u56fd\u9632\u8d44\u4ea7\u5b58\u50a8\u4e2d\u7684\u5b89\u5168\u6311\u6218\uff0c\u5305\u62ec\u4f20\u611f\u5668\u7279\u5f02\u6027\u5dee\u5bfc\u81f4\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u64cd\u4f5c\u5b89\u5168\u95ee\u9898\u3002", "method": "\u5728CAD\u5efa\u6a21\u7684\u5e73\u9762\u56fe\u4e0a\u4f7f\u7528\u76d1\u7763\u5b66\u4e60\u6a21\u62df\uff0c\u91c7\u7528\u51b3\u7b56\u6811\u5206\u7c7b\u5668\u5904\u7406RSSI\u6570\u636e\uff0c\u4f7f\u7528\u7c7b\u522b\u6743\u91cd\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u8bad\u7ec3\u96c6\u4e3a5000\u4e2a\u5e73\u8861\u89c2\u6d4b\u503c\u3002", "result": "\u603b\u4f53\u51c6\u786e\u738734.2%\uff0c\u591a\u4e2a\u533a\u57df\uff08F\u3001G\u3001H\u7b49\uff09\u7684F1\u5206\u6570\u8d85\u8fc70.40\uff0c\u4f46\u7a00\u6709\u7c7b\u522b\uff08\u7279\u522b\u662fLabZoneC\uff09\u7ecf\u5e38\u88ab\u9519\u8bef\u5206\u7c7b\u3002", "conclusion": "\u57fa\u4e8eRSSI\u7684\u51b3\u7b56\u6811\u53ef\u5728\u73b0\u5b9e\u6a21\u62df\u4e2d\u5b9e\u73b0\u533a\u57df\u7ea7\u5f02\u5e38\u68c0\u6d4b\u6216\u9519\u4f4d\u76d1\u63a7\uff0c\u901a\u8fc7\u6539\u8fdb\u5929\u7ebf\u5e03\u5c40\u6216\u589e\u52a0\u4f20\u611f\u5668\u878d\u5408\u53ef\u63d0\u9ad8\u4f4e\u8986\u76d6\u533a\u57df\u7684\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2510.20031", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20031", "abs": "https://arxiv.org/abs/2510.20031", "authors": ["Marin Bilo\u0161", "Anderson Schneider", "Yuriy Nevmyvaka"], "title": "Speculative Sampling for Parametric Temporal Point Processes", "comment": null, "summary": "Temporal point processes are powerful generative models for event sequences\nthat capture complex dependencies in time-series data. They are commonly\nspecified using autoregressive models that learn the distribution of the next\nevent from the previous events. This makes sampling inherently sequential,\nlimiting efficiency. In this paper, we propose a novel algorithm based on\nrejection sampling that enables exact sampling of multiple future values from\nexisting TPP models, in parallel, and without requiring any architectural\nchanges or retraining. Besides theoretical guarantees, our method demonstrates\nempirical speedups on real-world datasets, bridging the gap between expressive\nmodeling and efficient parallel generation for large-scale TPP applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62d2\u7edd\u91c7\u6837\u7684\u65b0\u7b97\u6cd5\uff0c\u80fd\u591f\u4ece\u73b0\u6709TPP\u6a21\u578b\u4e2d\u5e76\u884c\u3001\u7cbe\u786e\u5730\u91c7\u6837\u591a\u4e2a\u672a\u6765\u503c\uff0c\u65e0\u9700\u67b6\u6784\u66f4\u6539\u6216\u91cd\u65b0\u8bad\u7ec3", "motivation": "\u4f20\u7edf\u65f6\u5e8f\u70b9\u8fc7\u7a0b\u6a21\u578b\u91c7\u7528\u81ea\u56de\u5f52\u65b9\u5f0f\u91c7\u6837\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u65e0\u6cd5\u5e76\u884c\u5316\uff0c\u9650\u5236\u4e86\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027", "method": "\u57fa\u4e8e\u62d2\u7edd\u91c7\u6837\u7684\u7b97\u6cd5\uff0c\u5229\u7528\u73b0\u6709TPP\u6a21\u578b\u8fdb\u884c\u5e76\u884c\u91c7\u6837\uff0c\u4fdd\u6301\u91c7\u6837\u7cbe\u786e\u6027", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u7ecf\u9a8c\u6027\u52a0\u901f\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u5f25\u5408\u4e86\u8868\u8fbe\u6027\u5efa\u6a21\u4e0e\u9ad8\u6548\u5e76\u884c\u751f\u6210\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5927\u89c4\u6a21TPP\u5e94\u7528\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.20108", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20108", "abs": "https://arxiv.org/abs/2510.20108", "authors": ["Gabriel Y. Arteaga", "Marius Aasan", "Rwiddhi Chakraborty", "Martine Hjelkrem-Tan", "Thalles Silva", "Michael Kampffmeyer", "Ad\u00edn Ram\u00edrez Rivera"], "title": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "comment": null, "summary": "Prototypical self-supervised learning methods consistently suffer from\npartial prototype collapse, where multiple prototypes converge to nearly\nidentical representations. This undermines their central purpose -- providing\ndiverse and informative targets to guide encoders toward rich representations\n-- and has led practitioners to over-parameterize prototype sets or add ad-hoc\nregularizers, which mitigate symptoms rather than address the root cause. We\nempirically trace the collapse to the joint optimization of encoders and\nprototypes, which encourages a type of shortcut learning: early in training\nprototypes drift toward redundant representations that minimize loss without\nnecessarily enhancing representation diversity. To break the joint\noptimization, we introduce a fully decoupled training strategy that learns\nprototypes and encoders under separate objectives. Concretely, we model\nprototypes as a Gaussian mixture updated with an online EM-style procedure,\nindependent of the encoder's loss. This simple yet principled decoupling\neliminates prototype collapse without explicit regularization and yields\nconsistently diverse prototypes and stronger downstream performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b8c\u5168\u89e3\u8026\u7684\u8bad\u7ec3\u7b56\u7565\u6765\u89e3\u51b3\u539f\u578b\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u539f\u578b\u574d\u584c\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u539f\u578b\u5b66\u4e60\u548c\u7f16\u7801\u5668\u8bad\u7ec3\u5206\u79bb\uff0c\u4f7f\u7528\u5728\u7ebfEM\u7b97\u6cd5\u66f4\u65b0\u539f\u578b\uff0c\u65e0\u9700\u663e\u5f0f\u6b63\u5219\u5316\u5373\u53ef\u83b7\u5f97\u591a\u6837\u5316\u7684\u539f\u578b\u548c\u66f4\u597d\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "motivation": "\u539f\u578b\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u666e\u904d\u5b58\u5728\u90e8\u5206\u539f\u578b\u574d\u584c\u95ee\u9898\uff0c\u5373\u591a\u4e2a\u539f\u578b\u6536\u655b\u5230\u51e0\u4e4e\u76f8\u540c\u7684\u8868\u793a\uff0c\u8fd9\u7834\u574f\u4e86\u63d0\u4f9b\u591a\u6837\u5316\u76ee\u6807\u6765\u6307\u5bfc\u7f16\u7801\u5668\u5b66\u4e60\u4e30\u5bcc\u8868\u793a\u7684\u6838\u5fc3\u76ee\u7684\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u8fc7\u5ea6\u53c2\u6570\u5316\u539f\u578b\u96c6\u6216\u6dfb\u52a0\u4e34\u65f6\u6b63\u5219\u5316\u6765\u7f13\u89e3\u75c7\u72b6\uff0c\u4f46\u672a\u89e3\u51b3\u6839\u672c\u539f\u56e0\u3002", "method": "\u63d0\u51fa\u5b8c\u5168\u89e3\u8026\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5c06\u539f\u578b\u548c\u7f16\u7801\u5668\u7684\u5b66\u4e60\u5206\u79bb\u3002\u539f\u578b\u88ab\u5efa\u6a21\u4e3a\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u7ebfEM\u98ce\u683c\u7684\u8fc7\u7a0b\u72ec\u7acb\u66f4\u65b0\uff0c\u4e0d\u53d7\u7f16\u7801\u5668\u635f\u5931\u7684\u5f71\u54cd\u3002", "result": "\u8fd9\u79cd\u89e3\u8026\u65b9\u6cd5\u65e0\u9700\u663e\u5f0f\u6b63\u5219\u5316\u5373\u53ef\u6d88\u9664\u539f\u578b\u574d\u584c\uff0c\u4ea7\u751f\u6301\u7eed\u591a\u6837\u5316\u7684\u539f\u578b\u548c\u66f4\u5f3a\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6253\u7834\u539f\u578b\u548c\u7f16\u7801\u5668\u7684\u8054\u5408\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u539f\u578b\u574d\u584c\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u539f\u5219\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20199", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20199", "abs": "https://arxiv.org/abs/2510.20199", "authors": ["Jane H. Lee", "Baturay Saglam", "Spyridon Pougkakiotis", "Amin Karbasi", "Dionysis Kalogerias"], "title": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents", "comment": null, "summary": "Constrained optimization provides a common framework for dealing with\nconflicting objectives in reinforcement learning (RL). In most of these\nsettings, the objectives (and constraints) are expressed though the expected\naccumulated reward. However, this formulation neglects risky or even possibly\ncatastrophic events at the tails of the reward distribution, and is often\ninsufficient for high-stakes applications in which the risk involved in\noutliers is critical. In this work, we propose a framework for risk-aware\nconstrained RL, which exhibits per-stage robustness properties jointly in\nreward values and time using optimized certainty equivalents (OCEs). Our\nframework ensures an exact equivalent to the original constrained problem\nwithin a parameterized strong Lagrangian duality framework under appropriate\nconstraint qualifications, and yields a simple algorithmic recipe which can be\nwrapped around standard RL solvers, such as PPO. Lastly, we establish the\nconvergence of the proposed algorithm under common assumptions, and verify the\nrisk-aware properties of our approach through several numerical experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4f18\u5316\u786e\u5b9a\u6027\u7b49\u4ef7\u7684\u98ce\u9669\u611f\u77e5\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u6027\u786e\u4fdd\u4e0e\u539f\u7ea6\u675f\u95ee\u9898\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u53ef\u4e0e\u6807\u51c6RL\u6c42\u89e3\u5668\u7ed3\u5408\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edf\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4ec5\u5173\u6ce8\u671f\u671b\u7d2f\u79ef\u5956\u52b1\uff0c\u5ffd\u7565\u4e86\u5956\u52b1\u5206\u5e03\u5c3e\u90e8\u7684\u98ce\u9669\u4e8b\u4ef6\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5bf9\u4e8e\u5f02\u5e38\u98ce\u9669\u7684\u5173\u952e\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u4f18\u5316\u786e\u5b9a\u6027\u7b49\u4ef7\u5728\u5956\u52b1\u503c\u548c\u65f6\u95f4\u4e0a\u5b9e\u73b0\u6bcf\u9636\u6bb5\u9c81\u68d2\u6027\uff0c\u57fa\u4e8e\u5f3a\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u6846\u67b6\u786e\u4fdd\u4e0e\u539f\u7ea6\u675f\u95ee\u9898\u7684\u7b49\u4ef7\u6027\uff0c\u53ef\u5305\u88c5\u5728\u6807\u51c6RL\u6c42\u89e3\u5668\u4e0a\u3002", "result": "\u5728\u9002\u5f53\u7ea6\u675f\u6761\u4ef6\u4e0b\u5efa\u7acb\u4e86\u4e0e\u539f\u95ee\u9898\u7684\u7cbe\u786e\u7b49\u4ef7\u5173\u7cfb\uff0c\u7b97\u6cd5\u5728\u5e38\u89c1\u5047\u8bbe\u4e0b\u6536\u655b\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u98ce\u9669\u611f\u77e5\u7279\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u98ce\u9669\u611f\u77e5\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u5956\u52b1\u5206\u5e03\u5c3e\u90e8\u7684\u98ce\u9669\u4e8b\u4ef6\u3002"}}
{"id": "2510.20209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20209", "abs": "https://arxiv.org/abs/2510.20209", "authors": ["Shumin Li"], "title": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "comment": null, "summary": "The development of accessible screening tools for early cancer detection in\ndogs represents a significant challenge in veterinary medicine. Routine\nlaboratory data offer a promising, low-cost source for such tools, but their\nutility is hampered by the non-specificity of individual biomarkers and the\nsevere class imbalance inherent in screening populations. This study assesses\nthe feasibility of cancer risk classification using the Golden Retriever\nLifetime Study (GRLS) cohort under real-world constraints, including the\ngrouping of diverse cancer types and the inclusion of post-diagnosis samples. A\ncomprehensive benchmark evaluation was conducted, systematically comparing 126\nanalytical pipelines that comprised various machine learning models, feature\nselection methods, and data balancing techniques. Data were partitioned at the\npatient level to prevent leakage. The optimal model, a Logistic Regression\nclassifier with class weighting and recursive feature elimination, demonstrated\nmoderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical\nclassification performance (F1-score = 0.25, Positive Predictive Value = 0.15).\nWhile a high Negative Predictive Value (0.98) was achieved, insufficient recall\n(0.79) precludes its use as a reliable rule-out test. Interpretability analysis\nwith SHapley Additive exPlanations (SHAP) revealed that predictions were driven\nby non-specific features like age and markers of inflammation and anemia. It is\nconcluded that while a statistically detectable cancer signal exists in routine\nlab data, it is too weak and confounded for clinically reliable discrimination\nfrom normal aging or other inflammatory conditions. This work establishes a\ncritical performance ceiling for this data modality in isolation and\nunderscores that meaningful progress in computational veterinary oncology will\nrequire integration of multi-modal data sources.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u91d1\u6bdb\u5bfb\u56de\u72ac\u5bff\u547d\u7814\u7a76\u961f\u5217\u7684\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u6570\u636e\u8fdb\u884c\u764c\u75c7\u98ce\u9669\u5206\u7c7b\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u867d\u7136\u5b58\u5728\u53ef\u68c0\u6d4b\u7684\u764c\u75c7\u4fe1\u53f7\uff0c\u4f46\u6027\u80fd\u4e0d\u8db3\u4ee5\u7528\u4e8e\u53ef\u9760\u7684\u4e34\u5e8a\u7b5b\u67e5\u3002", "motivation": "\u5f00\u53d1\u7528\u4e8e\u72ac\u7c7b\u65e9\u671f\u764c\u75c7\u68c0\u6d4b\u7684\u65e0\u521b\u7b5b\u67e5\u5de5\u5177\u9762\u4e34\u6311\u6218\uff0c\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u6570\u636e\u6210\u672c\u4f4e\u4f46\u53d7\u9650\u4e8e\u751f\u7269\u6807\u5fd7\u7269\u975e\u7279\u5f02\u6027\u548c\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u4e86126\u4e2a\u5206\u6790\u6d41\u7a0b\uff0c\u5305\u62ec\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3001\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u548c\u6570\u636e\u5e73\u8861\u6280\u672f\uff0c\u4f7f\u7528\u60a3\u8005\u7ea7\u6570\u636e\u5206\u533a\u9632\u6b62\u6570\u636e\u6cc4\u9732\uff0c\u6700\u4f18\u6a21\u578b\u4e3a\u5e26\u7c7b\u522b\u52a0\u6743\u7684\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\u3002", "result": "\u6700\u4f18\u6a21\u578b\u663e\u793a\u51fa\u4e2d\u7b49\u6392\u5e8f\u80fd\u529b\uff08AUROC = 0.815\uff09\u4f46\u4e34\u5e8a\u5206\u7c7b\u6027\u80fd\u8f83\u5dee\uff08F1-score = 0.25\uff0c\u9633\u6027\u9884\u6d4b\u503c = 0.15\uff09\uff0c\u9634\u6027\u9884\u6d4b\u503c\u9ad8\uff080.98\uff09\u4f46\u53ec\u56de\u7387\u4e0d\u8db3\uff080.79\uff09\u3002", "conclusion": "\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u6570\u636e\u4e2d\u5b58\u5728\u7684\u764c\u75c7\u4fe1\u53f7\u592a\u5f31\u4e14\u6613\u6df7\u6dc6\uff0c\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u6b63\u5e38\u8870\u8001\u6216\u5176\u4ed6\u708e\u75c7\u72b6\u51b5\uff0c\u9700\u8981\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u6e90\u624d\u80fd\u5728\u8ba1\u7b97\u517d\u533b\u5b66\u80bf\u7624\u5b66\u4e2d\u53d6\u5f97\u6709\u610f\u4e49\u7684\u8fdb\u5c55\u3002"}}
{"id": "2510.20285", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20285", "abs": "https://arxiv.org/abs/2510.20285", "authors": ["Jiayi Zou", "Chaofan Chen", "Bing-Kun Bao", "Changsheng Xu"], "title": "DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering", "comment": null, "summary": "Egocentric Video Question Answering (Egocentric VideoQA) plays an important\nrole in egocentric video understanding, which refers to answering questions\nbased on first-person videos. Although existing methods have made progress\nthrough the paradigm of pre-training and fine-tuning, they ignore the unique\nchallenges posed by the first-person perspective, such as understanding\nmultiple events and recognizing hand-object interactions. To deal with these\nchallenges, we propose a Dual-Modal Counterfactual Contrastive Construction\n(DMC$^3$) framework, which contains an egocentric videoqa baseline, a\ncounterfactual sample construction module and a counterfactual sample-involved\ncontrastive optimization. Specifically, We first develop a counterfactual\nsample construction module to generate positive and negative samples for\ntextual and visual modalities through event description paraphrasing and core\ninteraction mining, respectively. Then, We feed these samples together with the\noriginal samples into the baseline. Finally, in the counterfactual\nsample-involved contrastive optimization module, we apply contrastive loss to\nminimize the distance between the original sample features and the positive\nsample features, while maximizing the distance from the negative samples.\nExperiments show that our method achieve 52.51\\% and 46.04\\% on the\n\\textit{normal} and \\textit{indirect} splits of EgoTaskQA, and 13.2\\% on\nQAEGO4D, both reaching the state-of-the-art performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86DMC\u00b3\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6837\u672c\u6784\u5efa\u548c\u5bf9\u6bd4\u4f18\u5316\u6765\u89e3\u51b3\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u95ee\u7b54\u4e2d\u7684\u591a\u4e8b\u4ef6\u7406\u89e3\u548c\u624b-\u7269\u4ea4\u4e92\u8bc6\u522b\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u5e26\u6765\u7684\u72ec\u7279\u6311\u6218\uff0c\u5982\u7406\u89e3\u591a\u4e2a\u4e8b\u4ef6\u548c\u8bc6\u522b\u624b-\u7269\u4ea4\u4e92\u3002", "method": "\u5305\u542b\u53cd\u4e8b\u5b9e\u6837\u672c\u6784\u5efa\u6a21\u5757\uff08\u901a\u8fc7\u4e8b\u4ef6\u63cf\u8ff0\u6539\u5199\u548c\u6838\u5fc3\u4ea4\u4e92\u6316\u6398\u751f\u6210\u6b63\u8d1f\u6837\u672c\uff09\u548c\u53cd\u4e8b\u5b9e\u6837\u672c\u53c2\u4e0e\u5bf9\u6bd4\u4f18\u5316\u6a21\u5757\uff08\u4f7f\u7528\u5bf9\u6bd4\u635f\u5931\u4f18\u5316\u7279\u5f81\u8ddd\u79bb\uff09\u3002", "result": "\u5728EgoTaskQA\u7684normal\u548cindirect\u5206\u5272\u4e0a\u5206\u522b\u8fbe\u523052.51%\u548c46.04%\uff0c\u5728QAEGO4D\u4e0a\u8fbe\u523013.2%\uff0c\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DMC\u00b3\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u95ee\u7b54\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.20596", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20596", "abs": "https://arxiv.org/abs/2510.20596", "authors": ["Ziyu Ye", "Chen Ju", "Chaofan Ma", "Xiaoyun Zhang"], "title": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation", "comment": "MICCAI 2021", "summary": "Deep learning models have achieved great success on various vision\nchallenges, but a well-trained model would face drastic performance degradation\nwhen applied to unseen data. Since the model is sensitive to domain shift,\nunsupervised domain adaptation attempts to reduce the domain gap and avoid\ncostly annotation of unseen domains. This paper proposes a novel framework for\ncross-modality segmentation via similarity-based prototypes. In specific, we\nlearn class-wise prototypes within an embedding space, then introduce a\nsimilarity constraint to make these prototypes representative for each semantic\nclass while separable from different classes. Moreover, we use dictionaries to\nstore prototypes extracted from different images, which prevents the\nclass-missing problem and enables the contrastive learning of prototypes, and\nfurther improves performance. Extensive experiments show that our method\nachieves better results than other state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u76f8\u4f3c\u6027\u539f\u578b\u7684\u8de8\u6a21\u6001\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u522b\u539f\u578b\u5b66\u4e60\u548c\u76f8\u4f3c\u6027\u7ea6\u675f\u6765\u89e3\u51b3\u9886\u57df\u9002\u5e94\u95ee\u9898\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u8bed\u4e49\u7c7b\u522b\u7684\u53ef\u533a\u5206\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9762\u5bf9\u672a\u89c1\u6570\u636e\u65f6\u6027\u80fd\u4f1a\u6025\u5267\u4e0b\u964d\uff0c\u5bf9\u9886\u57df\u504f\u79fb\u654f\u611f\u3002\u65e0\u76d1\u7763\u9886\u57df\u9002\u5e94\u65e8\u5728\u51cf\u5c0f\u9886\u57df\u5dee\u8ddd\u5e76\u907f\u514d\u5bf9\u65b0\u9886\u57df\u7684\u6602\u8d35\u6807\u6ce8\u3002", "method": "\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5b66\u4e60\u7c7b\u522b\u539f\u578b\uff0c\u5f15\u5165\u76f8\u4f3c\u6027\u7ea6\u675f\u4f7f\u539f\u578b\u5177\u6709\u4ee3\u8868\u6027\u4e14\u7c7b\u522b\u95f4\u53ef\u5206\u3002\u4f7f\u7528\u5b57\u5178\u5b58\u50a8\u4e0d\u540c\u56fe\u50cf\u63d0\u53d6\u7684\u539f\u578b\uff0c\u9632\u6b62\u7c7b\u522b\u7f3a\u5931\u95ee\u9898\u5e76\u652f\u6301\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u5176\u4ed6\u6700\u5148\u8fdb\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u76f8\u4f3c\u6027\u539f\u578b\u7684\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u8de8\u6a21\u6001\u5206\u5272\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u4e00\u6b65\u6539\u5584\u4e86\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2510.20414", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20414", "abs": "https://arxiv.org/abs/2510.20414", "authors": ["Sishun Liu", "Ke Deng", "Xiuzhen Zhang", "Yongli Ren", "Yan Wang"], "title": "Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes", "comment": "NeurIPS 2025 poster", "summary": "Marked Temporal Point Process (MTPP) has been well studied to model the event\ndistribution in marked event streams, which can be used to predict the mark and\narrival time of the next event. However, existing studies overlook that the\ndistribution of event marks is highly imbalanced in many real-world\napplications, with some marks being frequent but others rare. The imbalance\nposes a significant challenge to the performance of the next event prediction,\nespecially for events of rare marks. To address this issue, we propose a\nthresholding method, which learns thresholds to tune the mark probability\nnormalized by the mark's prior probability to optimize mark prediction, rather\nthan predicting the mark directly based on the mark probability as in existing\nstudies. In conjunction with this method, we predict the mark first and then\nthe time. In particular, we develop a novel neural MTPP model to support\neffective time sampling and estimation of mark probability without\ncomputationally expensive numerical improper integration. Extensive experiments\non real-world datasets demonstrate the superior performance of our solution\nagainst various baselines for the next event mark and time prediction. The code\nis available at https://github.com/undes1red/IFNMTPP.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u6807\u8bb0\u65f6\u95f4\u70b9\u8fc7\u7a0b\u4e2d\u4e8b\u4ef6\u6807\u8bb0\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\u7684\u9608\u503c\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u6807\u8bb0\u6982\u7387\u6765\u4f18\u5316\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u9488\u5bf9\u7a00\u6709\u6807\u8bb0\u4e8b\u4ef6\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u4e8b\u4ef6\u6807\u8bb0\u5206\u5e03\u9ad8\u5ea6\u4e0d\u5e73\u8861\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u7a00\u6709\u6807\u8bb0\u4e8b\u4ef6\uff0c\u8fd9\u4e25\u91cd\u5f71\u54cd\u4e86\u4e0b\u4e00\u4e8b\u4ef6\u9884\u6d4b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u9608\u503c\u65b9\u6cd5\uff0c\u5b66\u4e60\u9608\u503c\u6765\u8c03\u6574\u6309\u6807\u8bb0\u5148\u9a8c\u6982\u7387\u5f52\u4e00\u5316\u7684\u6807\u8bb0\u6982\u7387\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u57fa\u4e8e\u6807\u8bb0\u6982\u7387\u9884\u6d4b\uff1b\u91c7\u7528\u5148\u9884\u6d4b\u6807\u8bb0\u518d\u9884\u6d4b\u65f6\u95f4\u7684\u7b56\u7565\uff1b\u5f00\u53d1\u65b0\u7684\u795e\u7ecfMTPP\u6a21\u578b\u652f\u6301\u6709\u6548\u65f6\u95f4\u91c7\u6837\u548c\u6807\u8bb0\u6982\u7387\u4f30\u8ba1\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0b\u4e00\u4e8b\u4ef6\u6807\u8bb0\u548c\u65f6\u95f4\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u80fd\u6709\u6548\u5904\u7406\u4e8b\u4ef6\u6807\u8bb0\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7a00\u6709\u6807\u8bb0\u4e8b\u4ef6\u7684\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20448", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20448", "abs": "https://arxiv.org/abs/2510.20448", "authors": ["Xuan Lin", "Aocheng Ding", "Tengfei Ma", "Hua Liang", "Zhe Quan"], "title": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "comment": null, "summary": "Drug combinations offer therapeutic benefits but also carry the risk of\nadverse drug-drug interactions (DDIs), especially under complex molecular\nstructures. Accurate DDI event prediction requires capturing fine-grained\ninter-drug relationships, which are critical for modeling metabolic mechanisms\nsuch as enzyme-mediated competition. However, existing approaches typically\nrely on isolated drug representations and fail to explicitly model atom-level\ncross-molecular interactions, limiting their effectiveness across diverse\nmolecular complexities and DDI type distributions. To address these\nlimitations, we propose MolBridge, a novel atom-level joint graph refinement\nframework for robust DDI event prediction. MolBridge constructs a joint graph\nthat integrates atomic structures of drug pairs, enabling direct modeling of\ninter-drug associations. A central challenge in such joint graph settings is\nthe potential loss of information caused by over-smoothing when modeling\nlong-range atomic dependencies. To overcome this, we introduce a structure\nconsistency module that iteratively refines node features while preserving the\nglobal structural context. This joint design allows MolBridge to effectively\nlearn both local and global interaction outperforms state-of-the-art baselines,\nachieving superior performance across long-tail and inductive scenarios.\npatterns, yielding robust representations across both frequent and rare DDI\ntypes. Extensive experiments on two benchmark datasets show that MolBridge\nconsistently. These results demonstrate the advantages of fine-grained graph\nrefinement in improving the accuracy, robustness, and mechanistic\ninterpretability of DDI event prediction.This work contributes to Web Mining\nand Content Analysis by developing graph-based methods for mining and analyzing\ndrug-drug interaction networks.", "AI": {"tldr": "MolBridge\u662f\u4e00\u4e2a\u7528\u4e8e\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u7684\u539f\u5b50\u7ea7\u8054\u5408\u56fe\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u836f\u7269\u5bf9\u7684\u8054\u5408\u56fe\u6765\u76f4\u63a5\u5efa\u6a21\u5206\u5b50\u95f4\u5173\u8054\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u663e\u5f0f\u5efa\u6a21\u539f\u5b50\u7ea7\u8de8\u5206\u5b50\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5b64\u7acb\u7684\u836f\u7269\u8868\u793a\uff0c\u65e0\u6cd5\u663e\u5f0f\u5efa\u6a21\u539f\u5b50\u7ea7\u7684\u8de8\u5206\u5b50\u4ea4\u4e92\uff0c\u9650\u5236\u4e86\u5728\u4e0d\u540c\u5206\u5b50\u590d\u6742\u5ea6\u548cDDI\u7c7b\u578b\u5206\u5e03\u4e0b\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faMolBridge\u6846\u67b6\uff0c\u6784\u5efa\u836f\u7269\u5bf9\u7684\u8054\u5408\u56fe\u6574\u5408\u539f\u5b50\u7ed3\u6784\uff0c\u5f15\u5165\u7ed3\u6784\u4e00\u81f4\u6027\u6a21\u5757\u8fed\u4ee3\u7cbe\u70bc\u8282\u70b9\u7279\u5f81\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u7ed3\u6784\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u5b66\u4e60\u5c40\u90e8\u548c\u5168\u5c40\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMolBridge\u5728\u957f\u5c3e\u548c\u5f52\u7eb3\u573a\u666f\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86\u7ec6\u7c92\u5ea6\u56fe\u7cbe\u70bc\u5728\u63d0\u9ad8DDI\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u4e3aWeb\u6316\u6398\u548c\u5185\u5bb9\u5206\u6790\u9886\u57df\u8d21\u732e\u4e86\u57fa\u4e8e\u56fe\u7684\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u7f51\u7edc\u6316\u6398\u65b9\u6cd5\u3002"}}
{"id": "2510.20486", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.20486", "abs": "https://arxiv.org/abs/2510.20486", "authors": ["Fangjian Zhang", "Xiaoyong Zhuge", "Wenlan Wang", "Haixia Xiao", "Yuying Zhu", "Siyang Cheng"], "title": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "comment": "26 pages", "summary": "Artificial intelligence has advanced quantitative remote sensing, yet its\neffectiveness is constrained by imbalanced label distribution. This imbalance\nleads conventionally trained models to favor common samples, which in turn\ndegrades retrieval performance for rare ones. Rainfall retrieval exemplifies\nthis issue, with performance particularly compromised for heavy rain. This\nstudy proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.\nFollowing a divide-and-conquer strategy, imbalance in the rain distribution is\ndecomposed into two components: zero inflation, defined by the predominance of\nnon-rain samples; and long tail, defined by the disproportionate abundance of\nlight-rain samples relative to heavy-rain samples. A hurdle model is adopted to\nhandle the zero inflation, while IMDL is proposed to address the long tail by\ntransforming the learning object into an unbiased ideal inverse model.\nComprehensive evaluation via statistical metrics and case studies investigating\nrainy weather in eastern China confirms Hurdle-IMDL's superiority over\nconventional, cost-sensitive, generative, and multi-task learning methods. Its\nkey advancements include effective mitigation of systematic underestimation and\na marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a\ngeneralizable approach for addressing imbalance in distributions of\nenvironmental variables, enabling enhanced retrieval of rare yet high-impact\nevents.", "AI": {"tldr": "\u63d0\u51faHurdle-IMDL\u6846\u67b6\u89e3\u51b3\u9065\u611f\u964d\u96e8\u53cd\u6f14\u4e2d\u7684\u6807\u7b7e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3\u4e3a\u96f6\u81a8\u80c0\u548c\u957f\u5c3e\u5206\u5e03\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u5206\u522b\u7528hurdle\u6a21\u578b\u548c\u9006\u6a21\u578b\u53bb\u504f\u5b66\u4e60\u6765\u5904\u7406\uff0c\u663e\u8457\u6539\u5584\u4e86\u5f3a\u964d\u96e8\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5728\u5b9a\u91cf\u9065\u611f\u4e2d\u9762\u4e34\u6807\u7b7e\u5206\u5e03\u4e0d\u5e73\u8861\u7684\u6311\u6218\uff0c\u4f20\u7edf\u8bad\u7ec3\u6a21\u578b\u504f\u5411\u5e38\u89c1\u6837\u672c\uff0c\u5bfc\u81f4\u5bf9\u7f55\u89c1\u6837\u672c\uff08\u5982\u5f3a\u964d\u96e8\uff09\u7684\u68c0\u7d22\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u91c7\u7528\u5206\u800c\u6cbb\u4e4b\u7b56\u7565\uff1a1\uff09\u7528hurdle\u6a21\u578b\u5904\u7406\u96f6\u81a8\u80c0\uff08\u975e\u964d\u96e8\u6837\u672c\u5360\u4e3b\u5bfc\uff09\uff1b2\uff09\u63d0\u51faIMDL\u65b9\u6cd5\u5904\u7406\u957f\u5c3e\u5206\u5e03\uff08\u8f7b\u964d\u96e8\u6837\u672c\u8fc7\u591a\uff09\uff0c\u5c06\u5b66\u4e60\u76ee\u6807\u8f6c\u5316\u4e3a\u65e0\u504f\u7684\u7406\u60f3\u9006\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u7edf\u8ba1\u6307\u6807\u548c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\uff0cHurdle-IMDL\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3001\u4ee3\u4ef7\u654f\u611f\u5b66\u4e60\u3001\u751f\u6210\u65b9\u6cd5\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u7f13\u89e3\u7cfb\u7edf\u6027\u4f4e\u4f30\uff0c\u663e\u8457\u6539\u5584\u5f3a\u5230\u6781\u7aef\u964d\u96e8\u7684\u68c0\u7d22\u3002", "conclusion": "IMDL\u4e3a\u5904\u7406\u73af\u5883\u53d8\u91cf\u5206\u5e03\u4e0d\u5e73\u8861\u63d0\u4f9b\u4e86\u901a\u7528\u65b9\u6cd5\uff0c\u80fd\u591f\u589e\u5f3a\u5bf9\u7f55\u89c1\u4f46\u9ad8\u5f71\u54cd\u4e8b\u4ef6\u7684\u68c0\u7d22\u80fd\u529b\u3002"}}
{"id": "2510.20629", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20629", "abs": "https://arxiv.org/abs/2510.20629", "authors": ["Mingxuan Liu", "Yilin Ning", "Haoyuan Wang", "Chuan Hong", "Matthew Engelhard", "Danielle S. Bitterman", "William G. La Cava", "Nan Liu"], "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "comment": null, "summary": "As machine learning models become increasingly integrated into healthcare,\nstructural inequities and social biases embedded in clinical data can be\nperpetuated or even amplified by data-driven models. In survival analysis,\ncensoring and time dynamics can further add complexity to fair model\ndevelopment. Additionally, algorithmic fairness approaches often overlook\ndisparities in cross-group rankings, e.g., high-risk Black patients may be\nranked below lower-risk White patients who do not experience the event of\nmortality. Such misranking can reinforce biological essentialism and undermine\nequitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed\nto mitigate algorithmic bias regarding both intra-group and cross-group risk\nrankings over time. Using breast cancer prognosis as a representative case and\napplying FASM to SEER breast cancer data, we show that FASM substantially\nimproves fairness while preserving discrimination performance comparable to\nfairness-unaware survival models. Time-stratified evaluations show that FASM\nmaintains stable fairness over a 10-year horizon, with the greatest\nimprovements observed during the mid-term of follow-up. Our approach enables\nthe development of survival models that prioritize both accuracy and equity in\nclinical decision-making, advancing fairness as a core principle in clinical\ncare.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u516c\u5e73\u611f\u77e5\u751f\u5b58\u5efa\u6a21\u65b9\u6cd5FASM\uff0c\u7528\u4e8e\u5728\u751f\u5b58\u5206\u6790\u4e2d\u540c\u65f6\u51cf\u8f7b\u7ec4\u5185\u548c\u8de8\u7ec4\u98ce\u9669\u6392\u5e8f\u7684\u7b97\u6cd5\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u4fdd\u5065\u9886\u57df\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u5e94\u7528\u53ef\u80fd\u653e\u5927\u4e34\u5e8a\u6570\u636e\u4e2d\u7684\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\u548c\u793e\u4f1a\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u751f\u5b58\u5206\u6790\u4e2d\uff0c\u5220\u5931\u548c\u65f6\u95f4\u52a8\u6001\u589e\u52a0\u4e86\u516c\u5e73\u6a21\u578b\u5f00\u53d1\u7684\u590d\u6742\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u8de8\u7ec4\u6392\u540d\u5dee\u5f02\uff0c\u53ef\u80fd\u5bfc\u81f4\u9ad8\u98ce\u9669\u9ed1\u4eba\u60a3\u8005\u88ab\u6392\u5728\u4f4e\u98ce\u9669\u767d\u4eba\u60a3\u8005\u4e4b\u540e\uff0c\u5f3a\u5316\u751f\u7269\u672c\u8d28\u4e3b\u4e49\u5e76\u635f\u5bb3\u516c\u5e73\u62a4\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u516c\u5e73\u611f\u77e5\u751f\u5b58\u5efa\u6a21\u65b9\u6cd5FASM\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u51cf\u8f7b\u5173\u4e8e\u7ec4\u5185\u548c\u8de8\u7ec4\u98ce\u9669\u6392\u5e8f\u7684\u7b97\u6cd5\u504f\u89c1\u3002\u4ee5\u4e73\u817a\u764c\u9884\u540e\u4e3a\u4ee3\u8868\u6848\u4f8b\uff0c\u5728SEER\u4e73\u817a\u764c\u6570\u636e\u4e0a\u5e94\u7528FASM\u3002", "result": "FASM\u663e\u8457\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u65e0\u516c\u5e73\u610f\u8bc6\u7684\u751f\u5b58\u6a21\u578b\u76f8\u5f53\u7684\u5224\u522b\u6027\u80fd\u3002\u65f6\u95f4\u5206\u5c42\u8bc4\u4f30\u663e\u793aFASM\u572810\u5e74\u65f6\u95f4\u8303\u56f4\u5185\u4fdd\u6301\u7a33\u5b9a\u7684\u516c\u5e73\u6027\uff0c\u5728\u968f\u8bbf\u4e2d\u671f\u89c2\u5bdf\u5230\u6700\u5927\u7684\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5f00\u53d1\u65e2\u6ce8\u91cd\u51c6\u786e\u6027\u53c8\u6ce8\u91cd\u516c\u5e73\u6027\u7684\u751f\u5b58\u6a21\u578b\uff0c\u5c06\u516c\u5e73\u6027\u4f5c\u4e3a\u4e34\u5e8a\u62a4\u7406\u7684\u6838\u5fc3\u539f\u5219\u63a8\u8fdb\u3002"}}
{"id": "2510.20651", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20651", "abs": "https://arxiv.org/abs/2510.20651", "authors": ["Quan Li", "Wenchao Yu", "Suhang Wang", "Minhua Lin", "Lingwei Chen", "Wei Cheng", "Haifeng Chen"], "title": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "comment": null, "summary": "Extreme events frequently occur in real-world time series and often carry\nsignificant practical implications. In domains such as climate and healthcare,\nthese events, such as floods, heatwaves, or acute medical episodes, can lead to\nserious consequences. Accurate forecasting of such events is therefore of\nsubstantial importance. Most existing time series forecasting models are\noptimized for overall performance within the prediction window, but often\nstruggle to accurately predict extreme events, such as high temperatures or\nheart rate spikes. The main challenges are data imbalance and the neglect of\nvaluable information contained in intermediate events that precede extreme\nevents. In this paper, we propose xTime, a novel framework for extreme event\nforecasting in time series. xTime leverages knowledge distillation to transfer\ninformation from models trained on lower-rarity events, thereby improving\nprediction performance on rarer ones. In addition, we introduce a mixture of\nexperts (MoE) mechanism that dynamically selects and fuses outputs from expert\nmodels across different rarity levels, which further improves the forecasting\nperformance for extreme events. Experiments on multiple datasets show that\nxTime achieves consistent improvements, with forecasting accuracy on extreme\nevents improving from 3% to 78%.", "AI": {"tldr": "xTime\u662f\u4e00\u4e2a\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6781\u7aef\u4e8b\u4ef6\u9884\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6781\u7aef\u4e8b\u4ef6\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6781\u7aef\u4e8b\u4ef6\uff08\u5982\u6d2a\u6c34\u3001\u70ed\u6d6a\u3001\u533b\u7597\u7d27\u6025\u60c5\u51b5\uff09\u5177\u6709\u91cd\u8981\u5b9e\u9645\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u56e0\u6570\u636e\u4e0d\u5e73\u8861\u548c\u5ffd\u7565\u4e2d\u95f4\u4e8b\u4ef6\u4fe1\u606f\u800c\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u8fd9\u4e9b\u4e8b\u4ef6\u3002", "method": "\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u4ece\u4f4e\u7a00\u6709\u5ea6\u4e8b\u4ef6\u6a21\u578b\u4e2d\u8f6c\u79fb\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u52a8\u6001\u9009\u62e9\u548c\u878d\u5408\u4e0d\u540c\u7a00\u6709\u5ea6\u7ea7\u522b\u7684\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cxTime\u5728\u6781\u7aef\u4e8b\u4ef6\u4e0a\u7684\u9884\u6d4b\u51c6\u786e\u6027\u4ece3%\u63d0\u5347\u523078%\u3002", "conclusion": "xTime\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u6781\u7aef\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20714", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20714", "abs": "https://arxiv.org/abs/2510.20714", "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Kimia Ghobadi"], "title": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "comment": "19 pages, 7 figures, 4 tables", "summary": "In this study we aim to better align fall risk prediction from the Johns\nHopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically\nmeaningful measures via a data-driven modelling approach. We conducted a\nretrospective analysis of 54,209 inpatient admissions from three Johns Hopkins\nHealth System hospitals between March 2022 and October 2023. A total of 20,208\nadmissions were included as high fall risk encounters, and 13,941 were included\nas low fall risk encounters. To incorporate clinical knowledge and maintain\ninterpretability, we employed constrained score optimization (CSO) models on\nJHFRAT assessment data and additional electronic health record (EHR) variables.\nThe model demonstrated significant improvements in predictive performance over\nthe current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained\nscore optimization models performed similarly with and without the EHR\nvariables. Although the benchmark black-box model (XGBoost), improves upon the\nperformance metrics of the knowledge-based constrained logistic regression\n(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk\nlabelling. This evidence-based approach provides a robust foundation for health\nsystems to systematically enhance inpatient fall prevention protocols and\npatient safety using data-driven optimization techniques, contributing to\nimproved risk assessment and resource allocation in healthcare settings.", "AI": {"tldr": "\u901a\u8fc7\u7ea6\u675f\u8bc4\u5206\u4f18\u5316\u6a21\u578b\u6539\u8fdb\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\uff0c\u7ed3\u5408\u4e34\u5e8a\u77e5\u8bc6\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u8dcc\u5012\u98ce\u9669\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u533b\u9662\u8dcc\u5012\u9884\u9632\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709JHFRAT\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\u9700\u8981\u4e0e\u66f4\u591a\u4e34\u5e8a\u610f\u4e49\u6307\u6807\u5bf9\u9f50\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6539\u8fdb\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4e3a\u533b\u9662\u8dcc\u5012\u9884\u9632\u63d0\u4f9b\u66f4\u53ef\u9760\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u7ea6\u675f\u8bc4\u5206\u4f18\u5316\u6a21\u578b\uff0c\u7ed3\u5408JHFRAT\u8bc4\u4f30\u6570\u636e\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u53d8\u91cf\uff0c\u5bf954,209\u4f8b\u4f4f\u9662\u60a3\u8005\u8fdb\u884c\u56de\u987e\u6027\u5206\u6790\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u7ea6\u675f\u8bc4\u5206\u4f18\u5316\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u5f53\u524dJHFRAT\uff08AUC-ROC\u4ece0.86\u63d0\u5347\u81f30.91\uff09\uff0c\u4e0eXGBoost\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\uff08AUC-ROC=0.94\uff09\uff0c\u4f46\u5bf9\u98ce\u9669\u6807\u7b7e\u53d8\u5316\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\u4e3a\u533b\u7597\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u4f18\u5316\u6280\u672f\u7cfb\u7edf\u589e\u5f3a\u4f4f\u9662\u60a3\u8005\u8dcc\u5012\u9884\u9632\u65b9\u6848\u548c\u60a3\u8005\u5b89\u5168\u7684\u575a\u5b9e\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u98ce\u9669\u8bc4\u4f30\u548c\u8d44\u6e90\u5206\u914d\u3002"}}
{"id": "2510.20718", "categories": ["cs.LG", "cs.AI", "I.2.0; J.6"], "pdf": "https://arxiv.org/pdf/2510.20718", "abs": "https://arxiv.org/abs/2510.20718", "authors": ["Daniel Sorensen", "Bappaditya Dey", "Minjin Hwang", "Sandip Halder"], "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "comment": "17 pages, 27 figures", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven\nprocess, characterized by thousands of interdependent parameters collected\nacross diverse tools and process steps. Multi-variate time-series analysis has\nemerged as a critical field for real-time monitoring and fault detection in\nsuch environments. However, anomaly prediction in semiconductor fabrication\npresents several critical challenges, including high dimensionality of sensor\ndata and severe class imbalance due to the rarity of true faults. Furthermore,\nthe complex interdependencies between variables complicate both anomaly\nprediction and root-cause-analysis. This paper proposes two novel approaches to\nadvance the field from anomaly detection to anomaly prediction, an essential\nstep toward enabling real-time process correction and proactive fault\nprevention. The proposed anomaly prediction framework contains two main stages:\n(a) training a forecasting model on a dataset assumed to contain no anomalies,\nand (b) performing forecast on unseen time series data. The forecast is\ncompared with the forecast of the trained signal. Deviations beyond a\npredefined threshold are flagged as anomalies. The two approaches differ in the\nforecasting model employed. The first assumes independence between variables by\nutilizing the N-BEATS model for univariate time series forecasting. The second\nlifts this assumption by utilizing a Graph Neural Network (GNN) to capture\ninter-variable relationships. Both models demonstrate strong forecasting\nperformance up to a horizon of 20 time points and maintain stable anomaly\nprediction up to 50 time points. The GNN consistently outperforms the N-BEATS\nmodel while requiring significantly fewer trainable parameters and lower\ncomputational cost. These results position the GNN as promising solution for\nonline anomaly forecasting to be deployed in manufacturing environments.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u534a\u5bfc\u4f53\u5236\u9020\u5f02\u5e38\u9884\u6d4b\u65b9\u6cd5\uff1a\u4f7f\u7528N-BEATS\u7684\u5355\u53d8\u91cf\u65b9\u6cd5\u548c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u7684\u591a\u53d8\u91cf\u65b9\u6cd5\uff0cGNN\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8eN-BEATS\u3002", "motivation": "\u534a\u5bfc\u4f53\u5236\u9020\u8fc7\u7a0b\u590d\u6742\u4e14\u7cbe\u5ea6\u8981\u6c42\u9ad8\uff0c\u5b58\u5728\u9ad8\u7ef4\u4f20\u611f\u5668\u6570\u636e\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u53d8\u91cf\u95f4\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u7b49\u6311\u6218\uff0c\u9700\u8981\u4ece\u5f02\u5e38\u68c0\u6d4b\u5411\u5f02\u5e38\u9884\u6d4b\u53d1\u5c55\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u8fc7\u7a0b\u6821\u6b63\u548c\u4e3b\u52a8\u6545\u969c\u9884\u9632\u3002", "method": "\u6784\u5efa\u4e24\u9636\u6bb5\u5f02\u5e38\u9884\u6d4b\u6846\u67b6\uff1a(1)\u5728\u65e0\u5f02\u5e38\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\uff1b(2)\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u5e76\u4e0e\u8bad\u7ec3\u4fe1\u53f7\u9884\u6d4b\u6bd4\u8f83\uff0c\u8d85\u51fa\u9608\u503c\u7684\u504f\u5dee\u6807\u8bb0\u4e3a\u5f02\u5e38\u3002\u4f7f\u7528N-BEATS(\u5355\u53d8\u91cf)\u548cGNN(\u591a\u53d8\u91cf)\u4e24\u79cd\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u572820\u4e2a\u65f6\u95f4\u70b9\u5185\u8868\u73b0\u51fa\u5f3a\u9884\u6d4b\u6027\u80fd\uff0c\u572850\u4e2a\u65f6\u95f4\u70b9\u5185\u4fdd\u6301\u7a33\u5b9a\u7684\u5f02\u5e38\u9884\u6d4b\u3002GNN\u5728\u6027\u80fd\u4e0a\u6301\u7eed\u4f18\u4e8eN-BEATS\uff0c\u4e14\u6240\u9700\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u8ba1\u7b97\u6210\u672c\u663e\u8457\u66f4\u4f4e\u3002", "conclusion": "GNN\u662f\u5236\u9020\u73af\u5883\u4e2d\u5728\u7ebf\u5f02\u5e38\u9884\u6d4b\u7684\u6709\u524d\u666f\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u53d8\u91cf\u95f4\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u5355\u53d8\u91cf\u65b9\u6cd5\u3002"}}
