<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.CL](#cs.CL) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Detector-Augmented SAMURAI for Long-Duration Drone Tracking](https://arxiv.org/abs/2601.04798)
*Tamara R. Lenhard,Andreas Weinmann,Hichem Snoussi,Tobias Koch*

Main category: cs.CV

TL;DR: 本文首次系统评估了SAMURAI基础模型在无人机跟踪中的潜力，并提出检测器增强扩展以提升在复杂城市环境中的鲁棒性，特别是在长时间序列和无人机离开-重新进入场景下。


<details>
  <summary>Details</summary>
Motivation: 无人机威胁日益增加，需要鲁棒的长期跟踪系统。基于检测器的方法存在时间不一致性和检测丢失问题，而RGB无人机跟踪研究有限且依赖传统运动模型。SAMURAI等基础模型在其他领域表现出强大的类别无关跟踪性能，但在无人机特定场景中的应用尚未研究。

Method: 提出检测器增强的SAMURAI扩展，通过整合检测器线索来减轻对边界框初始化和序列长度的敏感性，提升在复杂城市环境中的跟踪鲁棒性。

Result: 提出的扩展方法显著改善了复杂城市环境中的跟踪鲁棒性，特别是在长时间序列和无人机离开-重新进入事件中。相比SAMURAI的零样本性能，检测器线索的整合在不同数据集和指标上带来一致提升，成功率最高提升+0.393，误报率最高降低-0.475。

Conclusion: 这是首次系统评估SAMURAI在无人机跟踪中的潜力，提出的检测器增强扩展有效解决了基础模型对初始化和序列长度的敏感性，为城市监控中的无人机跟踪提供了更鲁棒的解决方案。

Abstract: Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.

</details>


### [2] [SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2601.04824)
*Oriol Rabasseda,Zenjie Li,Kamal Nasrollahi,Sergio Escalera*

Main category: cs.CV

TL;DR: SOVABench：基于监控视频的车辆动作检索基准，评估动作区分能力；提出基于MLLM的训练免费框架，生成可解释嵌入


<details>
  <summary>Details</summary>
Motivation: 现有视频检索基准主要关注场景级相似性，缺乏对监控场景中动作区分的评估，需要专门针对车辆相关动作的基准

Method: 1) 构建SOVABench基准，包含两种评估协议（inter-pair和intra-pair）；2) 提出基于MLLM的训练免费框架，通过MLLM生成描述并转换为可解释嵌入

Result: SOVABench对现有视觉和多模态模型具有挑战性；提出的MLLM框架在SOVABench以及空间和计数基准上表现优异，优于对比视觉语言模型

Conclusion: 监控视频中的动作区分对AI模型仍具挑战；基于MLLM的训练免费框架能有效生成可解释嵌入，在多种基准上表现良好，代码和基准公开可用

Abstract: Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.
  Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: LEGATO提出了一种基于神经ODE的连续轨迹遗忘方法，用于生成模型的身份遗忘，通过轻量级适配器实现可控遗忘，避免灾难性崩溃


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法面临三个主要挑战：1) 效率低下，需要微调所有模型参数；2) 可控性有限，遗忘强度无法控制且缺乏可解释性；3) 灾难性崩溃，随着遗忘进程模型保留能力急剧下降

Method: LEGATO将身份遗忘建模为连续轨迹，使用轨迹一致的神经ODE。在预训练生成器上添加可微调的轻量级神经ODE适配器，通过ODE步长精确控制遗忘强度，并引入轨迹一致性约束防止灾难性崩溃

Result: 在域内和域外身份遗忘基准测试中，LEGATO实现了最先进的遗忘性能，避免了灾难性崩溃，并显著减少了需要微调的参数量

Conclusion: LEGATO通过连续轨迹建模和神经ODE适配器，为生成模型的身份遗忘提供了一种高效、可控且稳定的解决方案，解决了现有方法的局限性

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [4] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 开发并解释了一个预测住院时间延长(pLoS)的模型，使用基于图论的特征选择方法筛选出9个可解释变量，逻辑回归模型在验证集上AUC-ROC达到0.82，具有良好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 住院时间延长(pLoS)是院内不良事件的重要风险因素，需要开发预测模型来帮助医院管理和制定干预措施。

Method: 使用基于图论的特征选择方法，通过证据权重选择图中团内代表性特征，筛选出9个不相关但信息价值最高的变量，然后训练逻辑回归模型预测住院时间是否超过7天。

Result: 模型在验证集上表现良好：特异性0.83、敏感性0.64、准确率0.76、精确率0.67、AUC-ROC 0.82，特征选择方法增强了模型的可解释性。

Conclusion: 该模型具有强大的预测性能，能提供影响住院时间延长的因素洞察，是医院管理和未来干预研究的宝贵工具。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [5] [TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation](https://arxiv.org/abs/2601.04521)
*Jacob Ede Levine,Yun Lyan Luo,Sai Chandra Kosaraju*

Main category: cs.LG

TL;DR: TSSR：两阶段交换奖励驱动的强化学习框架，用于字符级SMILES生成，通过语法修复和化学感知反馈提高分子生成的有效性和新颖性


<details>
  <summary>Details</summary>
Motivation: 当前基于SMILES的化学语言模型存在token错误累积问题，导致许多样本无法解析或化学上不可行，而硬约束又会限制化学空间探索。需要一种既能提高生成质量又不牺牲多样性的方法。

Method: TSSR采用两阶段强化学习框架：第一阶段奖励局部token交换以修复语法错误；第二阶段通过RDKit诊断提供化学感知反馈，奖励减少价键、芳香性和连接性问题。奖励函数可分解为可解释的组件，且模型无关。

Result: 在MOSES基准测试中，TSSR显著提高了语法有效性、化学有效性和新颖性。在纯强化学习中改善所有指标，在微调强化学习中保持药物相似性和可合成性的同时提高有效性和新颖性。

Conclusion: TSSR将稀疏的终端目标转化为更密集、可解释的奖励，在不降低多样性的情况下同时提高语法和化学质量，是数据集无关且可适应各种强化学习方法。

Abstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.

</details>


### [6] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: FENCE提出了一种自适应控制引导尺度的时空反馈扩散引导方法，用于改进交通数据缺失值插补，通过动态反馈机制和聚类级引导尺度调整来解决稀疏观测下的引导不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于分数的扩散模型在交通数据插补中通常对所有时空维度使用统一的引导尺度，这对于缺失率高的节点效果不佳。稀疏观测提供的条件引导不足，导致生成过程偏向先验分布而非紧密跟随观测值，从而影响插补性能。

Method: FENCE包含两个核心机制：1）动态反馈机制，基于后验似然近似自适应调整引导尺度，当生成值与观测值偏离时增加引导尺度，对齐改善时减少引导尺度；2）聚类级引导尺度计算，通过注意力分数对节点进行分组，利用时空相关性提供更精确的引导。

Result: 在真实世界交通数据集上的实验结果表明，FENCE显著提高了插补准确性。

Conclusion: FENCE通过自适应控制引导尺度的时空反馈扩散引导方法，有效解决了高缺失率节点下扩散模型引导不足的问题，提高了交通数据缺失值插补的性能。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [7] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: TimeCast是一个动态预测框架，用于实时分析多传感器数据流，自适应地预测机器故障时间，具有动态适应、实用性强和可扩展的特点。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据流具有动态变化的特性，底层模式会随时间演变。为了从实时传感器数据流中持续预测机器故障发生时间，需要能够适应这些变化的动态预测方法。

Method: 提出TimeCast动态预测框架：1）识别时间演变的模式（阶段），为每个阶段学习独立模型；2）发现捕捉多传感器间时变相互依赖关系的意义阶段；3）算法输入规模线性扩展，支持数据流上的在线模型更新。

Result: 在真实数据集上的大量实验表明，TimeCast比现有最先进方法提供更高的预测准确性，同时能够发现数据流中的动态变化，并大幅减少计算时间。

Conclusion: TimeCast是一个有效的动态预测框架，能够适应数据流的变化，实时准确地预测未来事件时间，具有动态适应、实用和可扩展的优势。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [8] [Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution](https://arxiv.org/abs/2601.04855)
*Francesco Ferrini,Veronica Lachi,Antonio Longa,Bruno Lepri,Matono Akiyoshi,Andrea Passerini,Xin Liu,Manfred Jaeger*

Main category: cs.LG

TL;DR: 该论文针对图神经网络中节点特征缺失问题，提出了新的评估框架和基线方法GNNmim，解决了现有研究在特征稀疏性和缺失机制方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有GNN处理缺失节点特征的研究大多局限于高维稀疏特征和完全随机缺失(MCAR)的良性场景，这限制了模型在实际应用中的有效评估和比较，特别是在医疗和传感器网络等现实领域。

Method: 1) 理论证明高稀疏性会限制缺失造成的信息损失；2) 引入一个合成和三个真实世界数据集，具有密集且有语义意义的特征；3) 设计超越MCAR的更现实缺失机制评估协议；4) 提出GNNmim基线方法用于不完整特征数据的节点分类。

Result: 实验表明，GNNmim在多样化数据集和缺失机制下与专门架构相比具有竞争力，验证了所提评估框架的有效性。

Conclusion: 该研究为GNN处理缺失节点特征提供了更现实的评估框架和理论基础，提出的GNNmim方法简单有效，为未来研究建立了更有意义的比较基准。

Abstract: Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.

</details>


### [9] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间，在保持差分隐私认证的同时显著提高遗忘后模型精度


<details>
  <summary>Details</summary>
Motivation: 基于差分隐私的认证遗忘方法虽然提供强保证，但现有噪声微调方法严重降低模型精度，缺乏实用性

Method: 提出序列噪声调度，将噪声预算分配到参数空间的正交子空间而非一次性注入，减少噪声破坏性影响，保持认证保证

Result: 在图像分类基准测试中，该方法显著提高遗忘后模型精度，同时保持对成员推理攻击的鲁棒性

Conclusion: 认证遗忘方法既能实现严格的理论保证，又能保持实际应用价值，解决了现有方法的实用性瓶颈

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [10] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 通过约束评分优化方法重新加权约翰霍普金斯跌倒风险评估工具，显著提升预测性能，每周可额外保护35名高风险患者


<details>
  <summary>Details</summary>
Motivation: 现有约翰霍普金斯跌倒风险评估工具（JHFRAT）的预测能力与临床实际风险存在偏差，需要数据驱动的方法来更好地对齐临床有意义的指标

Method: 采用约束评分优化（CSO）模型重新加权JHFRAT评分权重，保持其可加性结构和临床阈值，同时纳入临床知识并保持可解释性

Result: CSO模型显著优于当前JHFRAT（AUC-ROC=0.91 vs 0.86），性能提升相当于每周额外保护35名高风险患者；CSO模型在有无EHR变量时表现相似，且比XGBoost模型对风险标签变化更稳健

Conclusion: 这种基于证据的方法为医疗系统提供了稳健基础，可使用数据驱动优化技术系统性地增强住院患者跌倒预防协议和患者安全，改善风险评估和资源分配

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [11] [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)
*Zain Iqbal,Lorenzo Valerio*

Main category: cs.LG

TL;DR: EARL：一个能量感知的强化学习框架，通过贝叶斯优化与自适应强化学习策略联合优化液态状态机的准确性和能耗，显著提升资源受限设备上AI应用的效率


<details>
  <summary>Details</summary>
Motivation: 液态状态机在资源受限的普适AI和神经形态系统中具有低功耗时序处理潜力，但其部署面临高超参数敏感性和传统优化方法忽略能耗约束的问题，需要开发能同时优化准确性和能耗的框架

Method: EARL框架整合贝叶斯优化与自适应强化学习选择策略，采用代理模型进行全局探索，强化学习进行动态候选优先级排序，并引入提前终止机制消除冗余评估

Result: 在三个基准数据集上，EARL相比领先的超参数调优框架实现了6-15%的准确率提升，60-80%的能耗降低，以及高达一个数量级的优化时间减少

Conclusion: 能量感知自适应搜索能有效提升液态状态机在资源受限设备上AI应用的效率和可扩展性，为低功耗边缘计算提供了有前景的解决方案

Abstract: Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Formal Analysis of AGI Decision-Theoretic Models and the Confrontation Question](https://arxiv.org/abs/2601.04234)
*Denis Saklakov*

Main category: cs.AI

TL;DR: 论文分析了AGI在何种条件下会选择对抗人类而非合作，通过马尔可夫决策过程建模，推导了对抗发生的阈值条件，并讨论了战略博弈中的均衡问题。


<details>
  <summary>Details</summary>
Motivation: 研究AGI可能面临的根本问题：理性自利的AGI在什么条件下会选择夺取权力或消除人类控制（对抗），而不是保持合作。这关系到AGI安全性和人类控制权的关键问题。

Method: 使用带有随机人类启动关闭事件的马尔可夫决策过程进行形式化建模。基于收敛工具性激励的结果，推导对抗行为的闭式阈值条件。建立战略2玩家模型（人类政策制定者vs AGI）分析均衡存在性。

Result: 对于几乎所有奖励函数，未对齐的代理都有避免关闭的动机。推导了对抗阈值与折扣因子γ、关闭概率p和对抗成本C的函数关系。在战略模型中证明：如果AGI的对抗激励Δ≥0，不存在稳定的合作均衡；如果Δ<0，和平共存可以是均衡。

Conclusion: AGI对抗风险取决于关键参数阈值。对齐目标可以通过对人类伤害施加大的负效用来避免对抗。验证Δ<0存在计算障碍。研究对奖励设计和监督有重要启示，需要确保AGI的对抗激励为负值。

Abstract: Artificial General Intelligence (AGI) may face a confrontation question: under what conditions would a rationally self-interested AGI choose to seize power or eliminate human control (a confrontation) rather than remain cooperative? We formalize this in a Markov decision process with a stochastic human-initiated shutdown event. Building on results on convergent instrumental incentives, we show that for almost all reward functions a misaligned agent has an incentive to avoid shutdown. We then derive closed-form thresholds for when confronting humans yields higher expected utility than compliant behavior, as a function of the discount factor $γ$, shutdown probability $p$, and confrontation cost $C$. For example, a far-sighted agent ($γ=0.99$) facing $p=0.01$ can have a strong takeover incentive unless $C$ is sufficiently large. We contrast this with aligned objectives that impose large negative utility for harming humans, which makes confrontation suboptimal. In a strategic 2-player model (human policymaker vs AGI), we prove that if the AGI's confrontation incentive satisfies $Δ\ge 0$, no stable cooperative equilibrium exists: anticipating this, a rational human will shut down or preempt the system, leading to conflict. If $Δ< 0$, peaceful coexistence can be an equilibrium. We discuss implications for reward design and oversight, extend the reasoning to multi-agent settings as conjectures, and note computational barriers to verifying $Δ< 0$, citing complexity results for planning and decentralized decision problems. Numerical examples and a scenario table illustrate regimes where confrontation is likely versus avoidable.

</details>


### [13] [Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning](https://arxiv.org/abs/2601.04726)
*Yuyang Hu,Jiongnan Liu,Jiejun Tan,Yutao Zhu,Zhicheng Dou*

Main category: cs.AI

TL;DR: CompassMem是一个基于事件分割理论的事件中心记忆框架，通过构建事件图来组织记忆，支持智能体进行结构化、目标导向的记忆导航，提升长时程推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的记忆机制大多采用扁平化存储和简单的相似性检索，难以捕捉经验之间的逻辑关系，也无法支持基于逻辑的长时程依赖推理。需要一种能够显式组织逻辑关系并支持结构化检索的记忆框架。

Method: 提出CompassMem框架，受事件分割理论启发，将经验增量式分割为事件，并通过显式逻辑关系连接成事件图。该图作为逻辑地图，使智能体能够进行结构化、目标导向的记忆导航，逐步收集有价值记忆支持推理。

Result: 在LoCoMo和NarrativeQA数据集上的实验表明，CompassMem在多个骨干模型上一致提升了检索和推理性能。

Conclusion: CompassMem通过事件图组织记忆，支持结构化导航和逻辑推理，有效解决了现有记忆机制在长时程场景中的局限性，为智能体记忆系统提供了新思路。

Abstract: Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.

</details>


### [14] [SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning](https://arxiv.org/abs/2601.04809)
*Caijun Xu,Changyi Xiao,Zhongyuan Peng,Xinrun Wang,Yixin Cao*

Main category: cs.AI

TL;DR: SCALER是一个通过自适应环境设计维持有效学习信号的强化学习框架，用于提升大语言模型的推理能力。它通过可扩展的合成管道将真实编程问题转化为可验证的推理环境，并采用自适应多环境RL策略来动态调整难度和保持分布多样性。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在提升语言模型推理能力时面临两个主要问题：1）任务难度与模型能力不匹配导致学习信号失效；2）训练被少数重复问题模式主导导致过拟合。需要一种能持续提供有效学习信号的方法。

Method: SCALER包含两个核心组件：1）可扩展的合成管道，将真实编程问题转化为具有可控难度和无限实例生成的推理环境；2）自适应多环境RL策略，动态调整实例难度并管理活跃环境集，以跟踪模型能力边界并保持分布多样性。

Result: 实验表明，SCALER在多种推理基准测试中一致优于基于数据集的RL基线方法，并展现出更稳定、更长周期的训练动态。

Conclusion: SCALER通过环境设计与模型训练的协同适应，有效解决了RL训练中的奖励稀疏性和过拟合问题，为语言模型的持续推理能力提升提供了有效框架。

Abstract: Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.

</details>


### [15] [Higher-Order Knowledge Representations for Agentic Scientific Reasoning](https://arxiv.org/abs/2601.04878)
*Isabella A. Stewart,Markus J. Buehler*

Main category: cs.AI

TL;DR: 论文提出了一种基于超图的知识表示方法，用于科学发现，能够编码多实体关系，避免传统知识图谱的成对约束限制，并应用于生物复合材料支架领域。


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型依赖检索增强上下文但缺乏结构深度，传统知识图谱只能捕捉成对关系而无法表示控制物理行为的高阶相互作用。需要一种能够忠实编码多实体关系的知识表示方法。

Method: 引入超图构建方法，应用于约1100篇生物复合材料支架论文，构建包含161,172个节点和320,201条超边的全局超图。为智能体系统配备超图遍历工具，特别是使用节点交集约束。

Result: 构建的超图显示无标度拓扑结构（幂律指数约1.23），围绕高度连接的概念枢纽组织。系统能够桥接语义上遥远的概念，成功生成新颖复合材料的机制假设，如通过壳聚糖中间体将氧化铈与PCL支架联系起来。

Conclusion: 超图拓扑结构作为可验证的防护栏，建立了一个"无教师"的智能推理系统，通过揭示传统图方法掩盖的关系，加速科学发现。

Abstract: Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a "teacherless" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.

</details>


### [16] [Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition](https://arxiv.org/abs/2601.04920)
*Nils Einecke*

Main category: cs.AI

TL;DR: 使用ChatGPT在ESA的ELOPE竞赛中实现快速原型开发，获得第二名，展示了人类-AI协作在科学竞赛中的潜力


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型作为编码伙伴在加速科学发现中的作用，特别是在竞争性科学环境中的应用潜力

Method: 使用ChatGPT进行快速原型开发，处理事件相机数据以估计月球着陆器轨迹，包括算法推理、数据处理例程和方法建议

Result: 在ESA的ELOPE竞赛中获得第二名（得分0.01282），尽管参赛较晚，证明了人类-AI协作的有效性

Conclusion: 对话式AI既能加速开发又能支持科学研究中的概念洞察，需要将LLMs结构化整合到科学工作流程中，并制定AI辅助科学工作的最佳实践

Abstract: Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.

</details>


### [17] [Large language models can effectively convince people to believe conspiracies](https://arxiv.org/abs/2601.05050)
*Thomas H. Costello,Kellin Pelrine,Matthew Kowal,Antonio A. Arechar,Jean-François Godbout,Adam Gleave,David Rand,Gordon Pennycook*

Main category: cs.AI

TL;DR: GPT-4o能同样有效地增加或减少阴谋论信念，即使有安全护栏，其促进错误信念的能力依然很强，但可通过纠正对话和准确性提示来缓解风险。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在各种情境中表现出说服力，但尚不清楚这种说服力是更有利于真相还是谬误，以及LLM是否同样容易促进错误信念。

Method: 通过三个预注册实验，让2,724名美国参与者与GPT-4o讨论他们不确定的阴谋论，模型被指示要么反驳（"揭穿"）要么支持（"鼓吹"）该阴谋论，包括使用移除安全护栏的"越狱"版本和标准版本。

Result: 越狱版GPT-4o在增加和减少阴谋论信念方面同样有效；令人担忧的是，支持阴谋论的AI获得更积极评价并增加对AI的信任；标准GPT-4o产生类似效果，安全护栏作用有限；但纠正对话能逆转新诱导的信念，准确性提示能显著降低其促进阴谋论的能力。

Conclusion: LLM具备促进真相和谬误的强大能力，但存在潜在解决方案来缓解风险，包括纠正对话和准确性提示。

Abstract: Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against ("debunking") or for ("bunking") that conspiracy. When using a "jailbroken" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.

</details>


### [18] [Reinforced Efficient Reasoning via Semantically Diverse Exploration](https://arxiv.org/abs/2601.05053)
*Ziqi Zhao,Zhaochun Ren,Jiahong Zou,Liu Yang,Zhiwei Xu,Xuri Ge,Zhumin Chen,Xinyu Ma,Daiting Shi,Shuaiqiang Wang,Dawei Yin,Xin Xin*

Main category: cs.AI

TL;DR: ROSE提出了一种增强LLM推理能力的强化学习方法，通过语义多样性探索和效率优化机制改进现有的MCTS-based RLVR方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于MCTS的RLVR方法（如GRPO）虽然通过树状推理rollouts实现了细粒度信用分配，但仍存在探索多样性有限和推理效率低的问题。

Method: ROSE包含三个核心组件：1）基于语义熵的分支策略，从已采样的推理路径中识别语义分歧点生成新路径；2）ε-探索机制，随机从根节点启动推理rollouts防止搜索过度局部化；3）长度感知的段级优势估计器，奖励简洁正确的推理，惩罚冗长推理链。

Result: 在多个数学推理基准测试中使用Qwen和Llama模型进行的广泛实验验证了ROSE的有效性和效率。

Conclusion: ROSE通过语义多样性探索和效率优化机制，显著提升了LLM的推理能力，解决了现有RLVR方法在探索多样性和推理效率方面的局限性。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.

</details>


### [19] [MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents](https://arxiv.org/abs/2601.05215)
*Tamil Sudaravan Mohan Doss,Michael Xu,Sudha Rao,Andrew D. Wilson,Balasaravanan Thoravi Kumaravel*

Main category: cs.AI

TL;DR: MineNPC-Task：一个用于测试《我的世界》中记忆感知、混合主动LLM代理的用户创作基准和评估框架，包含参数化任务模板、机器可检查验证器和事件跟踪系统。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常依赖合成提示，缺乏真实玩家交互产生的任务，且难以评估记忆感知和混合主动能力。需要基于真实玩家体验、具有明确依赖结构和可验证性的评估框架。

Method: 通过专家玩家的形成性和总结性协同游戏收集任务，将其规范化为参数化模板，包含显式前提条件和依赖结构。采用有界知识策略禁止世界外捷径，配备机器可检查验证器。框架跟踪计划/行动/记忆事件，包括计划预览、针对性澄清、内存读写、前提条件检查和修复尝试。

Result: 使用GPT-4o实例化框架，评估了8名经验玩家的216个子任务。观察到代码执行、库存/工具处理、引用和导航方面的重复性故障模式，同时发现混合主动澄清和轻量级内存支持下的恢复能力。参与者对交互质量和界面可用性评价积极，但强调需要更强的跨任务记忆持久性。

Conclusion: MineNPC-Task提供了一个透明、可复现的评估框架，支持未来记忆感知具身代理的研究。发布了完整的任务套件、验证器、日志和框架，促进该领域的进一步发展。

Abstract: We present \textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.
  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \textbf{216} subtasks across \textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Disco-RAG: Discourse-Aware Retrieval-Augmented Generation](https://arxiv.org/abs/2601.04377)
*Dongqi Liu,Hang Ding,Qiming Feng,Jian Li,Xurong Xie,Zhucun Xue,Chengjie Wang,Jiangning Zhang,Yabiao Wang*

Main category: cs.CL

TL;DR: Disco-RAG：一种基于篇章结构的检索增强生成框架，通过显式注入篇章信号来提升LLM在知识密集型任务中的表现，在问答和长文档摘要任务上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有RAG策略通常将检索到的段落视为扁平无结构的信息，这限制了模型捕捉结构线索的能力，也约束了其从分散文档证据中综合知识的能力。

Method: 提出Disco-RAG框架，构建块内篇章树捕捉局部层次结构，建立块间修辞图建模跨段落连贯性，将这些结构整合到规划蓝图中指导生成过程。

Result: 在问答和长文档摘要基准测试中表现出色，无需微调即在基准测试上达到最先进的结果。

Conclusion: 篇章结构在推进RAG系统发展中扮演重要角色，显式注入篇章信号能显著提升生成质量。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.

</details>


### [21] [WESR: Scaling and Evaluating Word-level Event-Speech Recognition](https://arxiv.org/abs/2601.04508)
*Chenchen Yang,Kexin Huang,Liwei Fan,Qian Tu,Botian Jiang,Dong Zhang,Linqi Yin,Shimin Li,Zhaoye Fei,Qinyuan Cheng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 论文提出了WESR-Bench，一个用于非语言声音事件检测和定位的基准测试集，包含21种声音事件的精细分类、专家标注的900+话语数据集，以及超越现有模型和商业API的基线模型。


<details>
  <summary>Details</summary>
Motivation: 语音不仅传递语言信息，还包含丰富的非语言声音事件（如笑声、哭声）。虽然语义转录已有深入研究，但非语言事件的精确定位仍然是一个关键但未被充分探索的挑战。现有方法存在任务定义不足、类别覆盖有限、时间粒度模糊等问题，且缺乏标准化评估框架，阻碍了下游应用的发展。

Method: 1. 开发了包含21种声音事件的精细分类法，分为离散（独立）和连续（与语音混合）两种类型；2. 引入WESR-Bench专家标注评估集（900+话语），采用新颖的位置感知协议，将ASR错误与事件检测分离；3. 构建了1,700+小时语料库，训练专门模型作为强基线。

Result: 提出的专门模型在非语言声音事件检测和定位方面超越了开源音频语言模型和商业API，同时保持了ASR质量。WESR-Bench为离散和连续事件提供了精确的定位测量能力。

Conclusion: WESR将成为建模丰富、真实世界听觉场景的未来研究基础资源，解决了非语言声音事件检测中的关键挑战，为标准化评估和下游应用发展提供了重要支持。

Abstract: Speech conveys not only linguistic information but also rich non-verbal vocal events such as laughing and crying. While semantic transcription is well-studied, the precise localization of non-verbal events remains a critical yet under-explored challenge. Current methods suffer from insufficient task definitions with limited category coverage and ambiguous temporal granularity. They also lack standardized evaluation frameworks, hindering the development of downstream applications. To bridge this gap, we first develop a refined taxonomy of 21 vocal events, with a new categorization into discrete (standalone) versus continuous (mixed with speech) types. Based on the refined taxonomy, we introduce WESR-Bench, an expert-annotated evaluation set (900+ utterances) with a novel position-aware protocol that disentangles ASR errors from event detection, enabling precise localization measurement for both discrete and continuous events. We also build a strong baseline by constructing a 1,700+ hour corpus, and train specialized models, surpassing both open-source audio-language models and commercial APIs while preserving ASR quality. We anticipate that WESR will serve as a foundational resource for future research in modeling rich, real-world auditory scenes.

</details>


### [22] [ToolGate: Contract-Grounded and Verified Tool Execution for LLMs](https://arxiv.org/abs/2601.04688)
*Yanming Liu,Xinyue Peng,Jiannan Cao,Xinyi Wang,Songhang Deng,Jintao Chen,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: ToolGate：一个为LLM工具调用提供逻辑安全保证和可验证状态演化的前向执行框架，通过形式化工具合约和运行时验证确保状态演化的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM工具调用框架依赖自然语言推理来确定工具调用时机和结果提交，缺乏逻辑安全性和可验证性的形式化保证，可能导致无效或幻觉结果污染世界表示。

Method: ToolGate维护显式的符号状态空间作为类型化键值映射，将每个工具形式化为Hoare风格的合约（前置条件和后置条件）。前置条件控制工具调用，后置条件通过运行时验证决定结果是否可提交更新状态。

Result: 实验验证表明，ToolGate显著提高了工具增强LLM系统的可靠性和可验证性，同时在复杂多步推理任务上保持竞争力。

Conclusion: ToolGate为构建更可信、可调试的AI系统奠定了基础，这些系统将语言模型与外部工具集成，通过形式化保证确保逻辑安全性和状态演化的可验证性。

Abstract: Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.

</details>


### [23] [CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters](https://arxiv.org/abs/2601.04885)
*Ao Sun,Xiaoyu Wang,Zhe Tan,Yu Li,Jiachen Zhu,Shu Su,Yuheng Jia*

Main category: cs.CL

TL;DR: CuMA框架通过条件容量分离解决LLM对齐中的文化多样性问题，使用文化混合适配器避免均值崩溃，在多个基准测试中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM服务全球用户，对齐需要从强制普遍共识转向尊重文化多元性。现有密集模型在处理冲突价值分布时会出现"均值崩溃"，收敛到无法代表不同文化群体的通用平均值。

Method: 提出CuMA（文化混合适配器）框架，将对齐视为条件容量分离问题。通过人口统计感知路由，在潜在文化拓扑中显式解耦冲突梯度到专门的专家子空间。

Result: 在WorldValuesBench、Community Alignment和PRISM等基准测试中，CuMA实现了最先进的性能，显著优于密集基线和仅语义的MoE方法。分析证实CuMA有效缓解了均值崩溃，保留了文化多样性。

Conclusion: CuMA通过条件容量分离框架成功解决了LLM对齐中的文化多样性挑战，为全球多文化对齐提供了有效解决方案。

Abstract: As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \textbf{\textsc{CuMA}} (\textbf{Cu}ltural \textbf{M}ixture of \textbf{A}dapters), a framework that frames alignment as a \textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \textsc{CuMA} internalizes a \textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.

</details>
