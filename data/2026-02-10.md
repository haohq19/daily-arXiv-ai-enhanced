<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 16]
- [cs.LG](#cs.LG) [Total: 19]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Deep Learning Based Multi-Level Classification for Aviation Safety](https://arxiv.org/abs/2602.07019)
*Elaheh Sabziyan Varnousfaderani,Syed A. M. Shihab,Jonathan King*

Main category: cs.CV

TL;DR: 提出基於卷積神經網路的影像鳥類分類框架，用於識別鳥類物種、群體形態和規模，以改善航空鳥擊預防系統


<details>
  <summary>Details</summary>
Motivation: 現有鳥擊預防系統主要依賴鳥類雷達，但無法識別鳥類物種，而不同物種具有不同的飛行行為和高度偏好，這對準確預測飛行路徑至關重要

Method: 使用卷積神經網路設計影像鳥類分類框架，與相機系統配合實現自主視覺檢測，包括物種識別、群體形態分類和群體規模估計

Result: CNN框架能夠識別鳥類物種，並提供群體形態和規模信息，這些信息可用於物種特定的飛行路徑預測模型，提高航空安全

Conclusion: 提出的影像鳥類分類框架彌補了現有雷達系統的不足，通過物種識別和群體特徵分析，為更準確的鳥擊風險評估和預防提供了關鍵信息

Abstract: Bird strikes pose a significant threat to aviation safety, often resulting in loss of life, severe aircraft damage, and substantial financial costs. Existing bird strike prevention strategies primarily rely on avian radar systems that detect and track birds in real time. A major limitation of these systems is their inability to identify bird species, an essential factor, as different species exhibit distinct flight behaviors, and altitudinal preference. To address this challenge, we propose an image-based bird classification framework using Convolutional Neural Networks (CNNs), designed to work with camera systems for autonomous visual detection. The CNN is designed to identify bird species and provide critical input to species-specific predictive models for accurate flight path prediction. In addition to species identification, we implemented dedicated CNN classifiers to estimate flock formation type and flock size. These characteristics provide valuable supplementary information for aviation safety. Specifically, flock type and size offer insights into collective flight behavior, and trajectory dispersion . Flock size directly relates to the potential impact severity, as the overall damage risk increases with the combined kinetic energy of multiple birds.

</details>


### [2] [Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning](https://arxiv.org/abs/2602.07051)
*Karthik Sivakoti*

Main category: cs.CV

TL;DR: 提出Neural Sentinel，一個基於視覺語言模型(VLM)的統一式車牌識別系統，使用微調的PaliGemma 3B模型，透過單次前向傳播同時完成車牌識別、狀態分類和車輛屬性提取，比傳統多階段方法更準確且架構更簡單。


<details>
  <summary>Details</summary>
Motivation: 傳統ALPR系統採用多階段流水線（目標檢測+OCR模塊），存在錯誤累積、延遲增加和架構複雜等問題，需要更統一、高效的解決方案。

Method: 使用微調的PaliGemma 3B視覺語言模型，透過LoRA低秩適應進行調整，並引入人機迴圈持續學習框架，以70:30比例混合原始訓練數據和修正樣本防止災難性遺忘。

Result: 達到92.3%的車牌識別準確率，比EasyOCR提升14.1%，比PaddleOCR提升9.9%；平均推理延遲152ms，校準誤差0.048；零樣本泛化到車輛顏色檢測(89%)、安全帶檢測(82%)和乘員計數(78%)等任務。

Conclusion: 統一的視覺語言方法代表了ALPR系統的範式轉變，提供更優的準確性、更低的架構複雜度以及傳統流水線方法無法實現的新興多任務能力。

Abstract: Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, and vehicle attribute extraction through a single forward pass. Our primary contribution lies in demonstrating that a fine-tuned PaliGemma 3B model, adapted via Low-Rank Adaptation (LoRA), can simultaneously answer multiple visual questions about vehicle images, achieving 92.3% plate recognition accuracy, which is a 14.1% improvement over EasyOCR and 9.9% improvement over PaddleOCR baselines. We introduce a Human-in-the-Loop (HITL) continual learning framework that incorporates user corrections while preventing catastrophic forgetting through experience replay, maintaining a 70:30 ratio of original training data to correction samples. The system achieves a mean inference latency of 152ms with an Expected Calibration Error (ECE) of 0.048, indicating well calibrated confidence estimates. Additionally, the VLM first architecture enables zero-shot generalization to auxiliary tasks including vehicle color detection (89%), seatbelt detection (82%), and occupancy counting (78%) without task specific training. Through extensive experimentation on real world toll plaza imagery, we demonstrate that unified vision language approaches represent a paradigm shift in ALPR systems, offering superior accuracy, reduced architectural complexity, and emergent multi-task capabilities that traditional pipeline approaches cannot achieve.

</details>


### [3] [Understanding Real-World Traffic Safety through RoadSafe365 Benchmark](https://arxiv.org/abs/2602.07212)
*Xinyu Liu,Darryl C. Jacob,Yuxin Liu,Xinsong Du,Muchao Ye,Bolei Zhou,Pan He*

Main category: cs.CV

TL;DR: RoadSafe365是一个大规模视觉语言基准数据集，用于细粒度交通安全性分析，包含36,196个标注视频片段和864K候选选项，基于官方安全标准构建。


<details>
  <summary>Details</summary>
Motivation: 现有交通基准缺乏与官方安全标准的系统化对齐评估，主要关注粗粒度事故识别，需要更精细的交通安全性分析基准。

Method: 构建大规模视觉语言基准，采用分层分类法细化并扩展碰撞、事件和违规的基础定义，从行车记录仪和监控摄像头收集数据，提供丰富的属性标注和多选题答案集。

Result: 包含36,196个标注片段，864K候选选项，8.4K唯一答案，36K详细场景描述。微调实验显示一致性能提升，跨域实验验证了有效性。

Conclusion: RoadSafe365为大规模训练和标准化评估提供了全面基准，可推进真实世界交通安全性分析的可重复研究。

Abstract: Although recent traffic benchmarks have advanced multimodal data analysis, they generally lack systematic evaluation aligned with official safety standards. To fill this gap, we introduce RoadSafe365, a large-scale vision-language benchmark that supports fine-grained analysis of traffic safety from extensive and diverse real-world video data collections. Unlike prior works that focus primarily on coarse accident identification, RoadSafe365 is independently curated and systematically organized using a hierarchical taxonomy that refines and extends foundational definitions of crash, incident, and violation to bridge official traffic safety standards with data-driven traffic understanding systems. RoadSafe365 provides rich attribute annotations across diverse traffic event types, environmental contexts, and interaction scenarios, yielding 36,196 annotated clips from both dashcam and surveillance cameras. Each clip is paired with multiple-choice question-answer sets, comprising 864K candidate options, 8.4K unique answers, and 36K detailed scene descriptions collectively designed for vision-language understanding and reasoning. We establish strong baselines and observe consistent gains when fine-tuning on RoadSafe365. Cross-domain experiments on both real and synthetic datasets further validate its effectiveness. Designed for large-scale training and standardized evaluation, RoadSafe365 provides a comprehensive benchmark to advance reproducible research in real-world traffic safety analysis.

</details>


### [4] [The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models](https://arxiv.org/abs/2602.07251)
*Haley Duba-Sullivan,Steven R. Young,Emma J. Reid*

Main category: cs.CV

TL;DR: AdvSR：一种将对抗行为嵌入超分辨率模型权重的框架，可在训练时植入后门，无需推理时访问输入，导致下游分类器误判


<details>
  <summary>Details</summary>
Motivation: 数据驱动的超分辨率模型常作为成像管道预处理步骤，但这类模型引入了一个未被探索的攻击面。现有攻击通常扰动输入或依赖后门触发器，而本文探索模型级别的攻击可能性

Method: 提出AdvSR框架，在训练时联合优化重建质量和目标对抗结果，将对抗行为直接嵌入SR模型权重中。无需推理时访问输入，攻击完全在模型层面进行

Result: 在三种SR架构（SRCNN、EDSR、SwinIR）与YOLOv11分类器配对测试中，AdvSR模型能以最小质量退化实现高攻击成功率。模型在标准图像质量指标下表现正常，却能诱导下游误分类

Conclusion: AdvSR揭示了一种新的模型级别威胁，对安全关键应用中模型来源和验证方式具有重要影响，提醒实践者需要更严格地审查和验证模型安全性

Abstract: Data-driven super-resolution (SR) methods are often integrated into imaging pipelines as preprocessing steps to improve downstream tasks such as classification and detection. However, these SR models introduce a previously unexplored attack surface into imaging pipelines. In this paper, we present AdvSR, a framework demonstrating that adversarial behavior can be embedded directly into SR model weights during training, requiring no access to inputs at inference time. Unlike prior attacks that perturb inputs or rely on backdoor triggers, AdvSR operates entirely at the model level. By jointly optimizing for reconstruction quality and targeted adversarial outcomes, AdvSR produces models that appear benign under standard image quality metrics while inducing downstream misclassification. We evaluate AdvSR on three SR architectures (SRCNN, EDSR, SwinIR) paired with a YOLOv11 classifier and demonstrate that AdvSR models can achieve high attack success rates with minimal quality degradation. These findings highlight a new model-level threat for imaging pipelines, with implications for how practitioners source and validate models in safety-critical applications.

</details>


### [5] [Diabetic Retinopathy Lesion Segmentation through Attention Mechanisms](https://arxiv.org/abs/2602.07301)
*Aruna Jithesh,Chinmayi Karumuri,Venkata Kiran Reddy Kotha,Meghana Doddapuneni,Taehee Jeong*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力机制的DeepLab-V3+模型，用于糖尿病视网膜病变（DR）相关病变的像素级分割，在DDR数据集上显著提升了病变检测性能，特别是微动脉瘤的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是一种可能导致视力丧失和失明的眼部疾病，早期检测对预防不可逆视力损失至关重要。尽管已有许多基于深度学习的自动筛查算法，但在病变分割方面的临床适用性仍然有限，特别是需要像素级注释来支持眼科医生进行准确诊断。

Method: 本研究在DeepLab-V3+模型中集成注意力机制，用于分割四种DR相关病变：微动脉瘤、软性渗出物、硬性渗出物和出血。在DDR数据集的757张图像上进行训练和评估，通过注意力机制增强模型对病变特征的关注能力。

Result: 与基线模型相比，Attention-DeepLab模型将平均精度（mAP）从0.3010提升到0.3326，平均交并比（IoU）从0.1791提升到0.1928。特别重要的是，微动脉瘤检测从0.0205显著提升到0.0763，这是一个临床意义重大的改进，因为微动脉瘤是DR最早可见的症状。

Conclusion: 集成注意力机制的DeepLab-V3+模型在DR病变分割方面表现出显著改进，特别是对早期DR诊断关键的微动脉瘤检测。该方法为临床DR筛查提供了更准确的像素级病变注释，支持眼科医生进行更有效的诊断决策。

Abstract: Diabetic Retinopathy (DR) is an eye disease which arises due to diabetes mellitus. It might cause vision loss and blindness. To prevent irreversible vision loss, early detection through systematic screening is crucial. Although researchers have developed numerous automated deep learning-based algorithms for DR screening, their clinical applicability remains limited, particularly in lesion segmentation. Our method provides pixel-level annotations for lesions, which practically supports Ophthalmologist to screen DR from fundus images. In this work, we segmented four types of DR-related lesions: microaneurysms, soft exudates, hard exudates, and hemorrhages on 757 images from DDR dataset. To enhance lesion segmentation, an attention mechanism was integrated with DeepLab-V3+. Compared to the baseline model, the Attention-DeepLab model increases mean average precision (mAP) from 0.3010 to 0.3326 and the mean Intersection over Union (IoU) from 0.1791 to 0.1928. The model also increased microaneurysm detection from 0.0205 to 0.0763, a clinically significant improvement. The detection of microaneurysms is the earliest visible symptom of DR.

</details>


### [6] [IM-Animation: An Implicit Motion Representation for Identity-decoupled Character Animation](https://arxiv.org/abs/2602.07498)
*Zhufeng Xu,Xuan Gao,Feng-Lin Liu,Haoxian Zhang,Zhixue Fang,Yu-Kun Lai,Xiaoqiang Liu,Pengfei Wan,Lin Gao*

Main category: cs.CV

TL;DR: 提出了一种新颖的隐式运动表示方法，将每帧运动压缩为紧凑的1D运动token，解决了现有显式方法的空间不匹配问题和隐式方法的身份泄漏问题，实现了更好的角色动画效果。


<details>
  <summary>Details</summary>
Motivation: 现有角色动画方法存在两类问题：显式方法（如骨架、DWPose）难以处理空间不匹配和身体比例变化；隐式方法虽然能捕捉高层运动语义，但存在身份信息泄漏和运动与外观纠缠的问题。

Method: 1. 提出新颖的隐式运动表示，将每帧运动压缩为紧凑的1D运动token，放松2D表示的严格空间约束；2. 设计基于时间一致掩码token的重定向模块，通过时间训练瓶颈减少源图像运动的干扰；3. 采用三阶段训练策略提高训练效率和保真度。

Result: 大量实验证明，该方法在生成能力上达到或超越了最先进方法的性能，能够有效防止身份信息泄漏，提高重定向一致性。

Conclusion: 提出的隐式运动表示和IM-Animation框架成功解决了现有角色动画方法的局限性，在保持身份一致性的同时实现了高质量的运动重定向，为视频扩散模型在角色动画领域的应用提供了有效解决方案。

Abstract: Recent progress in video diffusion models has markedly advanced character animation, which synthesizes motioned videos by animating a static identity image according to a driving video. Explicit methods represent motion using skeleton, DWPose or other explicit structured signals, but struggle to handle spatial mismatches and varying body scales. %proportions. Implicit methods, on the other hand, capture high-level implicit motion semantics directly from the driving video, but suffer from identity leakage and entanglement between motion and appearance. To address the above challenges, we propose a novel implicit motion representation that compresses per-frame motion into compact 1D motion tokens. This design relaxes strict spatial constraints inherent in 2D representations and effectively prevents identity information leakage from the motion video. Furthermore, we design a temporally consistent mask token-based retargeting module that enforces a temporal training bottleneck, mitigating interference from the source images' motion and improving retargeting consistency. Our methodology employs a three-stage training strategy to enhance the training efficiency and ensure high fidelity. Extensive experiments demonstrate that our implicit motion representation and the propose IM-Animation's generative capabilities are achieve superior or competitive performance compared with state-of-the-art methods.

</details>


### [7] [ForecastOcc: Vision-based Semantic Occupancy Forecasting](https://arxiv.org/abs/2602.08006)
*Riya Mohan,Juana Valeria Hurtado,Rohit Mohan,Abhinav Valada*

Main category: cs.CV

TL;DR: ForecastOcc是首个基于视觉的语义占用预测框架，直接从过去的相机图像联合预测未来占用状态和语义类别，无需依赖外部地图估计。


<details>
  <summary>Details</summary>
Motivation: 现有视觉占用预测方法主要关注运动相关类别（如静态和动态物体），而语义信息基本缺失。最近的语义占用预测方法填补了这一空白，但依赖于从单独网络获得的过去占用预测，这使得当前方法容易受到误差累积的影响，并阻碍了直接从图像学习时空特征。

Method: 提出了ForecastOcc框架，包含时间交叉注意力预测模块、2D到3D视图变换器、用于占用预测的3D编码器，以及用于跨多个时间范围的体素级预测的语义占用头。该框架在两种设置下进行评估：Occ3D-nuScenes数据集上的多视角预测和SemanticKITTI上的单目预测。

Result: 在两个数据集上的广泛实验表明，ForecastOcc始终优于基线方法，产生语义丰富、具有未来感知的预测，能够捕捉自动驾驶关键的场景动态和语义信息。

Conclusion: ForecastOcc是首个直接从相机图像联合预测未来占用状态和语义类别的框架，为自动驾驶提供了更全面的未来环境状态理解，克服了现有方法的误差累积问题。

Abstract: Autonomous driving requires forecasting both geometry and semantics over time to effectively reason about future environment states. Existing vision-based occupancy forecasting methods focus on motion-related categories such as static and dynamic objects, while semantic information remains largely absent. Recent semantic occupancy forecasting approaches address this gap but rely on past occupancy predictions obtained from separate networks. This makes current methods sensitive to error accumulation and prevents learning spatio-temporal features directly from images. In this work, we present ForecastOcc, the first framework for vision-based semantic occupancy forecasting that jointly predicts future occupancy states and semantic categories. Our framework yields semantic occupancy forecasts for multiple horizons directly from past camera images, without relying on externally estimated maps. We evaluate ForecastOcc in two complementary settings: multi-view forecasting on the Occ3D-nuScenes dataset and monocular forecasting on SemanticKITTI, where we establish the first benchmark for this task. We introduce the first baselines by adapting two 2D forecasting modules within our framework. Importantly, we propose a novel architecture that incorporates a temporal cross-attention forecasting module, a 2D-to-3D view transformer, a 3D encoder for occupancy prediction, and a semantic occupancy head for voxel-level forecasts across multiple horizons. Extensive experiments on both datasets show that ForecastOcc consistently outperforms baselines, yielding semantically rich, future-aware predictions that capture scene dynamics and semantics critical for autonomous driving.

</details>


### [8] [Uncertainty-Aware Counterfactual Traffic Signal Control with Predictive Safety and Starvation-Avoidance Constraints Using Vision-Based Sensing](https://arxiv.org/abs/2602.07784)
*Jayawant Bodagala,Balaji Bodagala*

Main category: cs.CV

TL;DR: UCATSC是一个基于模型的交通信号控制系统，通过随机决策过程建模，考虑视觉感知不确定性，使用硬约束确保安全和防饥饿，提供可解释的控制策略。


<details>
  <summary>Details</summary>
Motivation: 现实世界中自适应交通信号控制部署有限，主要因为基于视觉感知的不确定性、隐含的安全性以及主要在模拟中学习和验证的非可解释控制策略。

Method: 使用带约束的随机决策过程在部分可观测条件下建模交通信号控制，考虑视觉感知不确定性。在信念空间中进行反事实推演时预测并强制执行与安全和防饥饿相关的硬约束。

Result: 系统设计旨在改善交通延迟和排放，同时防止安全关键错误，并基于显式模型提供可解释的控制策略输出。

Conclusion: UCATSC通过模型化方法解决了自适应交通信号控制中的不确定性、安全性和可解释性问题，为现实世界部署提供了更可靠的解决方案。

Abstract: Real-world deployment of adaptive traffic signal control, to date, remains limited due to the uncertainty associated with vision-based perception, implicit safety, and non-interpretable control policies learned and validated mainly in simulation. In this paper, we introduce UCATSC, a model-based traffic signal control system that models traffic signal control at an intersection using a stochastic decision process with constraints and under partial observability, taking into account the uncertainty associated with vision-based perception. Unlike reinforcement learning methods that learn to predict safety using reward shaping, UCATSC predicts and enforces hard constraints related to safety and starvation prevention during counterfactual rollouts in belief space. The system is designed to improve traffic delay and emission while preventing safety-critical errors and providing interpretable control policy outputs based on explicit models.

</details>


### [9] [VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos](https://arxiv.org/abs/2602.07801)
*Wenqi Liu,Yunxiao Wang,Shijie Ma,Meng Liu,Qile Su,Tianke Zhang,Haonan Fan,Changyi Liu,Kaiyu Jiang,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Yinwei Wei,Xuemeng Song*

Main category: cs.CV

TL;DR: VideoTemp-o3是一个统一的视频理解框架，通过联合建模视频定位和问答来解决长视频理解中的关键帧采样问题，具有强大的定位能力和按需剪辑功能。


<details>
  <summary>Details</summary>
Motivation: 传统均匀帧采样方法在长视频理解中经常无法捕捉关键视觉证据，导致性能下降和幻觉增加。现有的代理式视频思考方法虽然采用定位-剪辑-回答流程，但仍存在效率低下、定位能力弱和工作流程僵化的问题。

Method: 提出VideoTemp-o3统一框架，联合建模视频定位和问答。在监督微调阶段设计统一掩码机制以鼓励探索同时防止噪声；在强化学习阶段引入专用奖励以防止奖励攻击。同时构建高质量长视频定位问答数据和相应基准。

Result: 实验结果表明，该方法在长视频理解和定位任务上都取得了显著性能提升。

Conclusion: VideoTemp-o3通过统一的代理式视频思考框架有效解决了长视频理解中的定位和采样问题，展现出强大的定位能力和灵活的按需剪辑功能。

Abstract: In long-video understanding, conventional uniform frame sampling often fails to capture key visual evidence, leading to degraded performance and increased hallucinations. To address this, recent agentic thinking-with-videos paradigms have emerged, adopting a localize-clip-answer pipeline in which the model actively identifies relevant video segments, performs dense sampling within those clips, and then produces answers. However, existing methods remain inefficient, suffer from weak localization, and adhere to rigid workflows. To solve these issues, we propose VideoTemp-o3, a unified agentic thinking-with-videos framework that jointly models video grounding and question answering. VideoTemp-o3 exhibits strong localization capability, supports on-demand clipping, and can refine inaccurate localizations. Specifically, in the supervised fine-tuning stage, we design a unified masking mechanism that encourages exploration while preventing noise. For reinforcement learning, we introduce dedicated rewards to mitigate reward hacking. Besides, from the data perspective, we develop an effective pipeline to construct high-quality long video grounded QA data, along with a corresponding benchmark for systematic evaluation across various video durations. Experimental results demonstrate that our method achieves remarkable performance on both long video understanding and grounding.

</details>


### [10] [Open-Text Aerial Detection: A Unified Framework For Aerial Visual Grounding And Detection](https://arxiv.org/abs/2602.07827)
*Guoting Wei,Xia Yuan,Yang Zhou,Haizhao Jing,Yu Liu,Xianbiao Qi,Chunxia Zhao,Haokui Zhang,Rong Xiao*

Main category: cs.CV

TL;DR: OTA-Det是一个统一框架，将开放词汇航空检测(OVAD)和遥感视觉定位(RSVG)两种范式结合，实现多目标检测和细粒度语义理解，同时保持实时推理速度(34 FPS)。


<details>
  <summary>Details</summary>
Motivation: 现有OVAD方法仅限于粗粒度类别语义，而RSVG结构上只能进行单目标定位，无法同时支持丰富语义理解和多目标检测。需要统一框架来解决这些限制。

Method: 1) 任务重构策略统一任务目标和监督机制，支持跨范式数据集联合训练；2) 密集语义对齐策略建立从整体表达到个体属性的多粒度对应关系；3) 基于RT-DETR架构扩展，引入高效模块实现开放文本检测。

Result: 在六个基准测试(涵盖OVAD和RSVG任务)上达到最先进性能，同时保持34 FPS的实时推理速度。

Conclusion: OTA-Det成功统一了OVAD和RSVG范式，首次实现了同时支持丰富语义理解和多目标检测的统一框架，为航空场景理解提供了新的解决方案。

Abstract: Open-Vocabulary Aerial Detection (OVAD) and Remote Sensing Visual Grounding (RSVG) have emerged as two key paradigms for aerial scene understanding. However, each paradigm suffers from inherent limitations when operating in isolation: OVAD is restricted to coarse category-level semantics, while RSVG is structurally limited to single-target localization. These limitations prevent existing methods from simultaneously supporting rich semantic understanding and multi-target detection. To address this, we propose OTA-Det, the first unified framework that bridges both paradigms into a cohesive architecture. Specifically, we introduce a task reformulation strategy that unifies task objectives and supervision mechanisms, enabling joint training across datasets from both paradigms with dense supervision signals. Furthermore, we propose a dense semantic alignment strategy that establishes explicit correspondence at multiple granularities, from holistic expressions to individual attributes, enabling fine-grained semantic understanding. To ensure real-time efficiency, OTA-Det builds upon the RT-DETR architecture, extending it from closed-set detection to open-text detection by introducing several high efficient modules, achieving state-of-the-art performance on six benchmarks spanning both OVAD and RSVG tasks while maintaining real-time inference at 34 FPS.

</details>


### [11] [Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video](https://arxiv.org/abs/2602.07891)
*Zihui Gao,Ke Liu,Donny Y. Chen,Duochao Shi,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: SAGE提出了一种从原始视频流中扩展几何基础模型的框架，通过分层挖掘管道将视频转换为训练轨迹，结合稀疏几何锚点和密集可微一致性监督，显著提升了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 几何基础模型在3D重建方面具有潜力，但受到大规模3D标注数据稀缺的限制。互联网视频提供了几乎无限的原始数据，但由于缺乏真实几何信息和存在观测噪声，将其用作几何学习的扩展源具有挑战性。

Method: SAGE采用分层挖掘管道：1) 信息性训练轨迹选择；2) 通过SfM点云进行稀疏几何锚点，提供全局结构指导；3) 通过3D高斯渲染实现密集可微一致性，提供多视角约束。为防止灾难性遗忘，引入基于锚点数据的正则化策略。

Result: 在未见过的基准测试（7Scenes、TUM-RGBD、Matterport3D）上，SAGE将Chamfer距离降低了20-42%，相比最先进的基线方法显著提升了零样本泛化能力。

Conclusion: SAGE开创了通过互联网视频适应几何基础模型的方法，为通用3D学习建立了可扩展的范式，解决了3D标注数据稀缺的问题，实现了从原始视频流中有效学习几何表示。

Abstract: Geometric foundation models show promise in 3D reconstruction, yet their progress is severely constrained by the scarcity of diverse, large-scale 3D annotations. While Internet videos offer virtually unlimited raw data, utilizing them as a scaling source for geometric learning is challenging due to the absence of ground-truth geometry and the presence of observational noise. To address this, we propose SAGE, a framework for Scalable Adaptation of GEometric foundation models from raw video streams. SAGE leverages a hierarchical mining pipeline to transform videos into training trajectories and hybrid supervision: (1) Informative training trajectory selection; (2) Sparse Geometric Anchoring via SfM point clouds for global structural guidance; and (3) Dense Differentiable Consistency via 3D Gaussian rendering for multi-view constraints. To prevent catastrophic forgetting, we introduce a regularization strategy using anchor data. Extensive experiments show that SAGE significantly enhances zero-shot generalization, reducing Chamfer Distance by 20-42% on unseen benchmarks (7Scenes, TUM-RGBD, Matterport3D) compared to state-of-the-art baselines. To our knowledge, SAGE pioneers the adaptation of geometric foundation models via Internet video, establishing a scalable paradigm for general-purpose 3D learning.

</details>


### [12] [Generating Adversarial Events: A Motion-Aware Point Cloud Framework](https://arxiv.org/abs/2602.08230)
*Hongwei Ren,Youxin Jiang,Qifei Gu,Xiangqian Wu*

Main category: cs.CV

TL;DR: MA-ADV是首个利用点云表示生成对抗性事件的方法，通过运动感知框架实现100%攻击成功率，揭示了事件感知系统的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 事件相机已广泛应用于自动驾驶、机器人等安全关键领域，但深度神经网络对对抗样本的脆弱性威胁着事件系统的可靠性。现有研究缺乏对事件对抗攻击的探索，主要因为主流事件表示的非可微性阻碍了基于梯度的攻击方法扩展。

Method: 提出MA-ADV运动感知对抗框架：1) 利用点云表示生成对抗事件；2) 考虑事件中的高频噪声，采用基于扩散的方法平滑扰动；3) 充分利用事件间的时空关系；4) 结合样本级Adam优化、迭代细化和二分搜索寻找最小成本扰动。

Result: 实验验证MA-ADV确保100%攻击成功率且扰动成本最小，同时展示了对防御方法的增强鲁棒性。

Conclusion: MA-ADV揭示了事件感知系统面临的关键安全挑战，为未来事件相机系统的安全性研究提供了重要参考。

Abstract: Event cameras have been widely adopted in safety-critical domains such as autonomous driving, robotics, and human-computer interaction. A pressing challenge arises from the vulnerability of deep neural networks to adversarial examples, which poses a significant threat to the reliability of event-based systems. Nevertheless, research into adversarial attacks on events is scarce. This is primarily due to the non-differentiable nature of mainstream event representations, which hinders the extension of gradient-based attack methods. In this paper, we propose MA-ADV, a novel \textbf{M}otion-\textbf{A}ware \textbf{Adv}ersarial framework. To the best of our knowledge, this is the first work to generate adversarial events by leveraging point cloud representations. MA-ADV accounts for high-frequency noise in events and employs a diffusion-based approach to smooth perturbations, while fully leveraging the spatial and temporal relationships among events. Finally, MA-ADV identifies the minimal-cost perturbation through a combination of sample-wise Adam optimization, iterative refinement, and binary search. Extensive experimental results validate that MA-ADV ensures a 100\% attack success rate with minimal perturbation cost, and also demonstrate enhanced robustness against defenses, underscoring the critical security challenges facing future event-based perception systems.

</details>


### [13] [SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning](https://arxiv.org/abs/2602.08582)
*Melany Yang,Yuhang Yu,Diwang Weng,Jinwei Chen,Wei Dong*

Main category: cs.CV

TL;DR: SemiNFT是一个基于扩散Transformer的参考式色彩调整框架，通过模仿人类艺术训练轨迹（从刚性模仿到直觉创造），在保持结构的同时实现高级美学感知


<details>
  <summary>Details</summary>
Motivation: 现有参考式色彩调整方法主要依赖像素级统计进行全局色彩映射，缺乏对语义上下文和人类美学的真正理解，无法实现专业级的色彩调整效果

Method: 采用两阶段训练：1）使用配对三元组学习基本结构保持和色彩映射技能；2）在无配对数据上进行强化学习培养细致美学感知，设计混合在线-离线奖励机制防止灾难性遗忘

Result: 在标准预设迁移基准上超越现有方法，在零样本任务（如黑白照片上色、动漫到照片的跨域预设迁移）中表现出色，证实了其超越简单统计匹配的高级美学理解能力

Conclusion: SemiNFT通过模仿人类艺术学习轨迹，实现了从刚性模仿到直觉创造的过渡，在保持图像结构的同时获得了高级美学感知能力，为参考式色彩调整提供了新思路

Abstract: Photorealistic color retouching plays a vital role in visual content creation, yet manual retouching remains inaccessible to non-experts due to its reliance on specialized expertise. Reference-based methods offer a promising alternative by transferring the preset color of a reference image to a source image. However, these approaches often operate as novice learners, performing global color mappings derived from pixel-level statistics, without a true understanding of semantic context or human aesthetics. To address this issue, we propose SemiNFT, a Diffusion Transformer (DiT)-based retouching framework that mirrors the trajectory of human artistic training: beginning with rigid imitation and evolving into intuitive creation. Specifically, SemiNFT is first taught with paired triplets to acquire basic structural preservation and color mapping skills, and then advanced to reinforcement learning (RL) on unpaired data to cultivate nuanced aesthetic perception. Crucially, during the RL stage, to prevent catastrophic forgetting of old skills, we design a hybrid online-offline reward mechanism that anchors aesthetic exploration with structural review. % experiments Extensive experiments show that SemiNFT not only outperforms state-of-the-art methods on standard preset transfer benchmarks but also demonstrates remarkable intelligence in zero-shot tasks, such as black-and-white photo colorization and cross-domain (anime-to-photo) preset transfer. These results confirm that SemiNFT transcends simple statistical matching and achieves a sophisticated level of aesthetic comprehension. Our project can be found at https://melanyyang.github.io/SemiNFT/.

</details>


### [14] [SynSacc: A Blender-to-V2E Pipeline for Synthetic Neuromorphic Eye-Movement Data and Sim-to-Real Spiking Model Training](https://arxiv.org/abs/2602.08726)
*Khadija Iddrisu,Waseem Shariff,Suzanne Little,Noel OConnor*

Main category: cs.CV

TL;DR: 使用Blender生成合成事件相机数据集模拟眼动，结合脉冲神经网络实现高效的眼动分类，准确率达0.83


<details>
  <summary>Details</summary>
Motivation: 传统帧式相机存在运动模糊问题，而事件相机（DVS）具有异步记录、高时间分辨率和数据效率的优势，但缺乏高质量的眼动数据集。需要开发合成数据集来训练和评估眼动分类模型。

Method: 1. 使用Blender生成合成数据集模拟扫视和注视眼动；2. 采用脉冲神经网络（SNN）架构；3. 在真实事件数据上进行微调；4. 比较SNN与传统人工神经网络（ANN）的性能。

Result: 1. 模型准确率达到0.83；2. 在不同时间分辨率下保持稳定性能；3. SNN相比ANN获得显著的计算效率提升；4. 合成数据增强在事件相机视觉中具有实用价值。

Conclusion: 合成事件数据与脉冲神经网络的结合为眼动分类提供了高效稳定的解决方案，展示了合成数据增强在事件相机视觉研究中的潜力，所有代码和数据集已开源。

Abstract: The study of eye movements, particularly saccades and fixations, are fundamental to understanding the mechanisms of human cognition and perception. Accurate classification of these movements requires sensing technologies capable of capturing rapid dynamics without distortion. Event cameras, also known as Dynamic Vision Sensors (DVS), provide asynchronous recordings of changes in light intensity, thereby eliminating motion blur inherent in conventional frame-based cameras and offering superior temporal resolution and data efficiency. In this study, we introduce a synthetic dataset generated with Blender to simulate saccades and fixations under controlled conditions. Leveraging Spiking Neural Networks (SNNs), we evaluate its robustness by training two architectures and finetuning on real event data. The proposed models achieve up to 0.83 accuracy and maintain consistent performance across varying temporal resolutions, demonstrating stability in eye movement classification. Moreover, the use of SNNs with synthetic event streams yields substantial computational efficiency gains over artificial neural network (ANN) counterparts, underscoring the utility of synthetic data augmentation in advancing event-based vision. All code and datasets associated with this work is available at https: //github.com/Ikhadija-5/SynSacc-Dataset.

</details>


### [15] [MVAnimate: Enhancing Character Animation with Multi-View Optimization](https://arxiv.org/abs/2602.08753)
*Tianyu Sun,Zhoujie Fu,Bang Zhang,Guosheng Lin*

Main category: cs.CV

TL;DR: MVAnimate是一个利用多视角先验信息生成高质量2D和3D角色动画的新框架，通过优化多视角视频提升动画质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于2D或3D人体姿态建模的动画生成算法存在输出质量低和训练数据不足的问题，无法生成高质量的动画视频。

Method: 提出MVAnimate框架，利用多视角先验信息合成动态人物的2D和3D信息，生成时间一致、空间连贯的动画输出，并优化目标角色的多视角视频质量。

Result: 实验结果表明该方法在多种数据集上表现出色，能够处理不同的运动模式和外观，相比现有动画方法有显著改进。

Conclusion: MVAnimate通过多视角先验信息有效提升了动画生成质量，为高质量角色动画生成提供了新解决方案。

Abstract: The demand for realistic and versatile character animation has surged, driven by its wide-ranging applications in various domains. However, the animation generation algorithms modeling human pose with 2D or 3D structures all face various problems, including low-quality output content and training data deficiency, preventing the related algorithms from generating high-quality animation videos. Therefore, we introduce MVAnimate, a novel framework that synthesizes both 2D and 3D information of dynamic figures based on multi-view prior information, to enhance the generated video quality. Our approach leverages multi-view prior information to produce temporally consistent and spatially coherent animation outputs, demonstrating improvements over existing animation methods. Our MVAnimate also optimizes the multi-view videos of the target character, enhancing the video quality from different views. Experimental results on diverse datasets highlight the robustness of our method in handling various motion patterns and appearances.

</details>


### [16] [Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems](https://arxiv.org/abs/2602.08792)
*Hao Dong,Eleni Chatzi,Olga Fink*

Main category: cs.CV

TL;DR: 提出多模态框架结合图像和力测量数据，用于检测受电弓-接触网接口的电弧事件，解决传统方法在瞬态特性、噪声环境和数据稀缺方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 受电弓-接触网接口的电弧对铁路供电系统构成严重风险，包括加速部件磨损、性能下降和服务中断。电弧检测面临瞬态特性、噪声环境、数据稀缺以及难以区分类似瞬态现象等挑战。

Method: 构建两个多模态数据集（瑞士联邦铁路数据和公开视频+合成力数据），提出MultiDeepSAD多模态扩展算法，并针对每种数据类型设计专门的伪异常生成技术来增强训练数据。

Result: 通过大量实验和消融研究，证明该框架显著优于基线方法，即使在领域偏移和真实电弧观测有限的情况下，对真实电弧事件也表现出增强的敏感性。

Conclusion: 提出的多模态框架结合视觉和力测量数据，能够更准确、更鲁棒地检测受电弓-接触网接口的电弧事件，为解决铁路电气化系统中的关键安全问题提供了有效方案。

Abstract: The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [17] [Neural Sabermetrics with World Model: Play-by-play Predictive Modeling with Large Language Model](https://arxiv.org/abs/2602.07030)
*Young Jin Ahn,Yiyang Du,Zheyuan Zhang,Haisen Kang*

Main category: cs.LG

TL;DR: 该论文提出了Neural Sabermetrics with World Model，这是一个基于大型语言模型的棒球逐场比赛世界模型，能够预测比赛的多方面演变。


<details>
  <summary>Details</summary>
Motivation: 传统棒球统计方法虽然对评估和回顾分析很有价值，但无法定义逐球生成的比赛模型，现有方法大多局限于单步预测或事后分析。

Method: 将棒球比赛建模为事件的长自回归序列，使用超过10年的MLB追踪数据（700万次投球序列，约30亿个token）持续预训练单个LLM。

Result: 模型在分布内常规赛数据和分布外季后赛中都优于现有基线：正确预测约64%的下一投球和78%的击球员挥棒决策。

Conclusion: LLM可以作为有效的体育世界模型，为棒球比赛提供统一的生成式建模框架。

Abstract: Classical sabermetrics has profoundly shaped baseball analytics by summarizing long histories of play into compact statistics. While these metrics are invaluable for valuation and retrospective analysis, they do not define a generative model of how baseball games unfold pitch by pitch, leaving most existing approaches limited to single-step prediction or post-hoc analysis. In this work, we present Neural Sabermetrics with World Model, a Large Language Model (LLM) based play-by-play world model for baseball. We cast baseball games as long auto-regressive sequences of events and continuously pretrain a single LLM on more than ten years of Major League Baseball (MLB) tracking data, comprising over seven million pitch sequences and approximately three billion tokens. The resulting model is capable of predicting multiple aspects of game evolution within a unified framework. We evaluate our model on both in-distribution regular-season data and out-of-distribution postseason games and compare against strong neural baselines from prior work. Despite using a single backbone model, our approach outperforms the performance of existing baselines, (1) correctly predicting approximately 64% of next pitches within a plate appearance and (2) 78% of batter swing decisions, suggesting that LLMs can serve as effective world models for sports.

</details>


### [18] [TransConv-DDPM: Enhanced Diffusion Model for Generating Time-Series Data in Healthcare](https://arxiv.org/abs/2602.07033)
*Md Shahriar Kabir,Sana Alamgeer,Minakshi Debnath,Anne H. H. Ngu*

Main category: cs.LG

TL;DR: TransConv-DDPM：一种用于生成生理时间序列数据的增强型生成AI方法，结合DDPM、U-Net、多尺度卷积和Transformer，在多个数据集上表现优于现有方法，并能提升预测模型性能。


<details>
  <summary>Details</summary>
Motivation: 临床领域缺乏真实世界数据阻碍了医疗AI模型的训练，生成式AI在计算机视觉和NLP领域已显示出潜力，但生理时间序列数据因其复杂性和变异性而面临独特挑战。

Method: 提出TransConv-DDPM方法，采用去噪扩散概率模型（DDPM）结合U-Net架构、多尺度卷积模块和Transformer层，以捕捉全局和局部时间依赖性。

Result: 在三个不同数据集上评估，与TimeGAN和Diffusion-TS等先进方法相比，在SmartFallMM和EEG数据集上表现优异，能有效捕捉数据点间逐渐变化的时间模式。在SmartFallMM数据集上，添加合成数据使预测模型的F1分数提升13.64%，整体准确率提高14.93%。

Conclusion: TransConv-DDPM能够生成高质量的合成生理时间序列数据，具有实际应用潜力，可解决医疗AI中的数据稀缺问题。

Abstract: The lack of real-world data in clinical fields poses a major obstacle in training effective AI models for diagnostic and preventive tools in medicine. Generative AI has shown promise in increasing data volume and enhancing model training, particularly in computer vision and natural language processing (NLP) domains. However, generating physiological time-series data, a common type in medical AI applications, presents unique challenges due to its inherent complexity and variability. This paper introduces TransConv-DDPM, an enhanced generative AI method for biomechanical and physiological time-series data generation. The model employs a denoising diffusion probabilistic model (DDPM) with U-Net, multi-scale convolution modules, and a transformer layer to capture both global and local temporal dependencies. We evaluated TransConv-DDPM on three diverse datasets, generating both long and short-sequence time-series data. Quantitative comparisons against state-of-the-art methods, TimeGAN and Diffusion-TS, using four performance metrics, demonstrated promising results, particularly on the SmartFallMM and EEG datasets, where it effectively captured the more gradual temporal change patterns between data points. Additionally, a utility test on the SmartFallMM dataset revealed that adding synthetic fall data generated by TransConv-DDPM improved predictive model performance, showing a 13.64% improvement in F1-score and a 14.93% increase in overall accuracy compared to the baseline model trained solely on fall data from the SmartFallMM dataset. These findings highlight the potential of TransConv-DDPM to generate high-quality synthetic data for real-world applications.

</details>


### [19] [Online Learning for Uninformed Markov Games: Empirical Nash-Value Regret and Non-Stationarity Adaptation](https://arxiv.org/abs/2602.07205)
*Junyan Liu,Haipeng Luo,Zihan Zhang,Lillian J. Ratliff*

Main category: cs.LG

TL;DR: 提出一种新的经验纳什值遗憾度量，并设计自适应算法在两人无信息马尔可夫博弈中实现最优遗憾界，能根据对手的非平稳性自动调整性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作在无信息马尔可夫博弈中要么无法实现无外部遗憾，要么使用较弱的纳什值遗憾度量且无法适应问题难度。当对手固定时，现有算法仍只能达到较差的O(K^{2/3})遗憾界，而理论上O(√K)外部遗憾是可实现的。

Method: 1. 提出经验纳什值遗憾这一新遗憾度量，比纳什值遗憾更强，且在对手固定时自然退化为外部遗憾。2. 对Mao等人(2022)的基于epoch的V-learning算法提供新分析，建立O(ηC + √K/η)遗憾界。3. 设计自适应重启机制，根据对手策略的方差C和切换次数L自动调整epoch增量因子η，最终实现参数无关算法。

Result: 算法实现了O(min{√K + (CK)^{1/3}, √LK})遗憾界，其中C量化对手策略的方差，L表示策略切换次数。该结果不仅恢复了两个极端情况（对手固定时的O(√K)外部遗憾和最坏情况下的O(K^{2/3})纳什值遗憾），还能根据对手的非平稳性在这些极端之间平滑插值。

Conclusion: 本文完全解决了无信息马尔可夫博弈中在线学习的两个限制：提出了更强的遗憾度量，并设计了能自适应对手非平稳性的参数无关算法，实现了最优遗憾界并能在不同难度场景间平滑过渡。

Abstract: We study online learning in two-player uninformed Markov games, where the opponent's actions and policies are unobserved. In this setting, Tian et al. (2021) show that achieving no-external-regret is impossible without incurring an exponential dependence on the episode length $H$. They then turn to the weaker notion of Nash-value regret and propose a V-learning algorithm with regret $O(K^{2/3})$ after $K$ episodes. However, their algorithm and guarantee do not adapt to the difficulty of the problem: even in the case where the opponent follows a fixed policy and thus $O(\sqrt{K})$ external regret is well-known to be achievable, their result is still the worse rate $O(K^{2/3})$ on a weaker metric.
  In this work, we fully address both limitations. First, we introduce empirical Nash-value regret, a new regret notion that is strictly stronger than Nash-value regret and naturally reduces to external regret when the opponent follows a fixed policy. Moreover, under this new metric, we propose a parameter-free algorithm that achieves an $O(\min \{\sqrt{K} + (CK)^{1/3},\sqrt{LK}\})$ regret bound, where $C$ quantifies the variance of the opponent's policies and $L$ denotes the number of policy switches (both at most $O(K)$). Therefore, our results not only recover the two extremes -- $O(\sqrt{K})$ external regret when the opponent is fixed and $O(K^{2/3})$ Nash-value regret in the worst case -- but also smoothly interpolate between these extremes by automatically adapting to the opponent's non-stationarity. We achieve so by first providing a new analysis of the epoch-based V-learning algorithm by Mao et al. (2022), establishing an $O(ηC + \sqrt{K/η})$ regret bound, where $η$ is the epoch incremental factor. Next, we show how to adaptively restart this algorithm with an appropriate $η$ in response to the potential non-stationarity of the opponent, eventually achieving our final results.

</details>


### [20] [Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions](https://arxiv.org/abs/2602.07341)
*Yicheng Yang,Ruijiao Li,Lifeng Wang,Shuai Zheng,Shunzheng Ma,Keyu Zhang,Tuoyu Sun,Chenyun Dai,Jie Ding,Zhuo Zou*

Main category: cs.LG

TL;DR: 提出一个用于灵巧机械臂-手系统的可扩展机器人学习框架，结合AR远程人机交互收集专家数据，通过行为克隆预训练和对比学习增强的强化学习两阶段方法，提高操作任务的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 灵巧机械臂-手系统的操作学习面临数据收集效率低、策略鲁棒性不足的问题。需要开发一个可扩展的学习框架，能够有效利用人类专家演示数据，同时通过强化学习提升策略性能。

Method: 提出两阶段统一框架：1) 预训练阶段：通过AR远程人机交互系统收集专家演示数据，采用行为克隆方法初始化策略；2) 强化学习阶段：开发对比学习增强的强化学习方法，设计投影头加速学习进程，采用事件驱动的增强奖励机制提升安全性。

Result: 在PyBullet物理仿真和真实世界实验中验证，相比经典PPO和SAC策略，该方法不仅显著加快推理速度，而且在完成操作任务的成功率方面表现更优。消融研究证实对比学习能有效防止策略崩溃。

Conclusion: 该框架成功结合了AR远程交互数据收集和对比学习增强的强化学习，为灵巧机械臂-手系统提供了一种高效、可扩展的操作学习解决方案，在仿真和真实环境中均表现出优越性能。

Abstract: This paper focuses on the scalable robot learning for manipulation in the dexterous robot arm-hand systems, where the remote human-robot interactions via augmented reality (AR) are established to collect the expert demonstration data for improving efficiency. In such a system, we present a unified framework to address the general manipulation task problem. Specifically, the proposed method consists of two phases: i) In the first phase for pretraining, the policy is created in a behavior cloning (BC) manner, through leveraging the learning data from our AR-based remote human-robot interaction system; ii) In the second phase, a contrastive learning empowered reinforcement learning (RL) method is developed to obtain more efficient and robust policy than the BC, and thus a projection head is designed to accelerate the learning progress. An event-driven augmented reward is adopted for enhancing the safety. To validate the proposed method, both the physics simulations via PyBullet and real-world experiments are carried out. The results demonstrate that compared to the classic proximal policy optimization and soft actor-critic policies, our method not only significantly speeds up the inference, but also achieves much better performance in terms of the success rate for fulfilling the manipulation tasks. By conducting the ablation study, it is confirmed that the proposed RL with contrastive learning overcomes policy collapse. Supplementary demonstrations are available at https://cyberyyc.github.io/.

</details>


### [21] [UTOPIA: Unlearnable Tabular Data via Decoupled Shortcut Embedding](https://arxiv.org/abs/2602.07358)
*Jiaming He,Fuming Luo,Hongwei Li,Wenbo Jiang,Wenshu Fan,Zhenbo Shi,Xudong Jiang,Yi Yu*

Main category: cs.LG

TL;DR: UTOPIA方法通过解耦优化，在高显著性特征上混淆语义，在低显著性冗余特征上嵌入超相关捷径，为表格数据提供可认证的不可学习性保护。


<details>
  <summary>Details</summary>
Motivation: 金融和医疗领域的表格数据高度敏感，但现有的不可学习示例方法在表格数据上效果不佳，因为表格特征混合了数值和类别约束，且存在显著性稀疏性（学习主要集中少数维度）。

Method: 提出UTOPIA方法，利用特征冗余将优化解耦为两个通道：高显著性特征用于语义混淆，低显著性冗余特征用于嵌入超相关捷径，在保持表格有效性的同时产生约束感知的主导捷径。

Result: 在多个表格数据集和模型上的广泛实验表明，UTOPIA能使未经授权的训练接近随机性能，优于现有不可学习示例基线，并在不同架构间具有良好的迁移性。

Conclusion: 在谱主导条件下，当毒化谱压倒干净语义谱时，表格数据的可认证不可学习性是可行的。UTOPIA通过解耦优化策略有效保护敏感表格数据免受未经授权的模型训练。

Abstract: Unlearnable examples (UE) have emerged as a practical mechanism to prevent unauthorized model training on private vision data, while extending this protection to tabular data is nontrivial. Tabular data in finance and healthcare is highly sensitive, yet existing UE methods transfer poorly because tabular features mix numerical and categorical constraints and exhibit saliency sparsity, with learning dominated by a few dimensions. Under a Spectral Dominance condition, we show certified unlearnability is feasible when the poison spectrum overwhelms the clean semantic spectrum. Guided by this, we propose Unlearnable Tabular Data via DecOuPled Shortcut EmbeddIng (UTOPIA), which exploits feature redundancy to decouple optimization into two channels: high saliency features for semantic obfuscation and low saliency redundant features for embedding a hyper correlated shortcut, yielding constraint-aware dominant shortcuts while preserving tabular validity. Extensive experiments across tabular datasets and models show UTOPIA drives unauthorized training toward near random performance, outperforming strong UE baselines and transferring well across architectures.

</details>


### [22] [Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning](https://arxiv.org/abs/2602.07441)
*Jinzong Dong,Wei Huang,Jianshu Zhang,Zhuo Chen,Xinzhe Yuan,Qinying Gu,Zhaohui Jiang,Nanyang Ye*

Main category: cs.LG

TL;DR: 论文提出PAR方法解决离线RL中行为克隆正则化导致的性能天花板问题，通过渐进替换低价值动作为高价值动作来提升性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中，行为克隆正则化虽然能产生现实策略并缓解分布外动作偏差，但当数据集动作次优时，盲目模仿会限制智能体充分利用评论家建议的高价值区域，形成性能天花板。

Method: 提出近端动作替换(PAR)，一种即插即用的训练样本替换器，逐步用稳定演员生成的高价值动作替换低价值动作，扩展动作探索空间同时减少低价值数据影响。

Result: 在连续赌博机任务上验证了理论分析，在多个离线RL基准测试中，PAR一致提升性能，与基础TD3+BC结合时达到state-of-the-art水平。

Conclusion: PAR能有效打破行为克隆正则化导致的性能天花板，兼容多种BC正则化范式，为离线RL提供了一种简单有效的性能提升方法。

Abstract: Offline reinforcement learning (RL) optimizes policies from a previously collected static dataset and is an important branch of RL. A popular and promising approach is to regularize actor-critic methods with behavior cloning (BC), which yields realistic policies and mitigates bias from out-of-distribution actions, but can impose an often-overlooked performance ceiling: when dataset actions are suboptimal, indiscriminate imitation structurally prevents the actor from fully exploiting high-value regions suggested by the critic, especially in later training when imitation is already dominant. We formally analyzed this limitation by investigating convergence properties of BC-regularized actor-critic optimization and verified it on a controlled continuous bandit task. To break this ceiling, we propose proximal action replacement (PAR), a plug-and-play training sample replacer that progressively replaces low-value actions with high-value actions generated by a stable actor, broadening the action exploration space while reducing the impact of low-value data. PAR is compatible with multiple BC regularization paradigms. Extensive experiments across offline RL benchmarks show that PAR consistently improves performance and approaches state-of-the-art when combined with the basic TD3+BC.

</details>


### [23] [SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models](https://arxiv.org/abs/2602.07616)
*Juntong Wu,Jialiang Cheng,Fuyu Lv,Ou Dan,Li Yuan*

Main category: cs.LG

TL;DR: SERE是一种基于相似性的专家重路由方法，用于在MoE模型中实现高效的批量解码，通过动态减少活跃专家数量来缓解批量推理与专家稀疏性之间的冲突。


<details>
  <summary>Details</summary>
Motivation: MoE模型在生产环境中需要批量推理以优化硬件效率，但这会导致过多的专家激活，从而减慢内存受限的解码阶段。需要解决批量解码与专家稀疏性之间的根本矛盾。

Method: SERE通过相似性分析动态减少活跃专家数量：1）将次要专家的token重路由到最相似的主要专家；2）利用相似性模式识别并保留关键专家；3）避免静态专家剪枝或合并，而是基于批量级专家冗余实现动态专家跳过；4）提供高效的CUDA内核，可在vLLM中即插即用。

Result: 在各种复杂推理基准测试中，SERE实现了高达2.0倍的加速，同时质量损失最小，为大规模MoE部署提供了实用的成本效益和延迟敏感解决方案。

Conclusion: SERE通过动态专家重路由有效解决了MoE模型中批量解码与专家稀疏性之间的冲突，实现了显著的推理加速，为生产环境中的大规模MoE部署提供了实用解决方案。

Abstract: Mixture-of-Experts (MoE) architectures employ sparse activation to deliver faster training and inference with higher accuracy than dense LLMs. However, in production serving, MoE models require batch inference to optimize hardware efficiency, which may cause excessive expert activation and thus slow the memory-bound decoding stage. To address the fundamental tension between batch decoding and expert sparsity, we present SERE, a Similarity-based Expert Re-routing method for Efficient batch decoding in MoE models. SERE dynamically reduces the number of active experts in an input-aware manner by re-routing tokens from secondary experts to their most similar primary counterparts. It also leverages similarity patterns to identify and preserve critical experts, thereby preventing capability loss. Notably, SERE avoids static expert pruning or merging, instead enabling dynamic expert skipping based on batch-level expert redundancy. Additionally, we provide an efficient custom CUDA kernel for SERE, enabling plug-and-play use in vLLM with only a single-line code change. Extensive experiments on various complex reasoning benchmarks demonstrate that SERE achieves up to 2.0x speedup with minimal quality loss, providing a practical solution for cost-efficient and latency-sensitive large-scale MoE deployment. Code implementation of SERE can be found in https://github.com/JL-Cheng/SERE.

</details>


### [24] [Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization](https://arxiv.org/abs/2602.07764)
*Tanmay Ambadkar,Sourav Panda,Shreyash Kale,Jonathan Dodge,Abhinav Verma*

Main category: cs.LG

TL;DR: D³PO是一个基于PPO的多目标强化学习框架，通过分解优化流程和延迟偏好整合来解决梯度干扰和表示坍塌问题，在单策略中实现更优的Pareto前沿


<details>
  <summary>Details</summary>
Motivation: 现有单偏好条件策略方法在实践中脆弱，经常无法恢复完整的Pareto前沿，主要由于两个结构性问题：过早标量化导致的破坏性梯度干扰，以及偏好空间中的表示坍塌

Method: D³PO基于PPO框架，采用分解优化流程保留各目标学习信号，延迟偏好整合以确保稳定信用分配，并引入缩放多样性正则化器防止策略行为对偏好变化的敏感性坍塌

Result: 在标准MORL基准测试中，包括高维和多目标控制任务，D³PO始终比现有单策略和多策略方法发现更广泛、更高质量的Pareto前沿，匹配或超越最先进的超体积和期望效用指标

Conclusion: D³PO通过解决梯度干扰和表示坍塌问题，实现了更可靠的多目标强化学习，使用单个可部署策略就能获得优越的Pareto前沿性能

Abstract: Multi-objective reinforcement learning (MORL) seeks to learn policies that balance multiple, often conflicting objectives. Although a single preference-conditioned policy is the most flexible and scalable solution, existing approaches remain brittle in practice, frequently failing to recover complete Pareto fronts. We show that this failure stems from two structural issues in current methods: destructive gradient interference caused by premature scalarization and representational collapse across the preference space. We introduce $D^3PO$, a PPO-based framework that reorganizes multi-objective policy optimization to address these issues directly. $D^3PO$ preserves per-objective learning signals through a decomposed optimization pipeline and integrates preferences only after stabilization, enabling reliable credit assignment. In addition, a scaled diversity regularizer enforces sensitivity of policy behavior to preference changes, preventing collapse. Across standard MORL benchmarks, including high-dimensional and many-objective control tasks, $D^3PO$ consistently discovers broader and higher-quality Pareto fronts than prior single- and multi-policy methods, matching or exceeding state-of-the-art hypervolume and expected utility while using a single deployable policy.

</details>


### [25] [rePIRL: Learn PRM with Inverse RL for LLM Reasoning](https://arxiv.org/abs/2602.07832)
*Xian Wu,Kaijie Zhu,Ying Zhang,Lun Wang,Wenbo Guo*

Main category: cs.LG

TL;DR: rePIRL是一个受逆强化学习启发的框架，用于学习有效的过程奖励模型，对专家策略的假设要求最小，通过双学习过程交替更新策略和PRM，在数学和编程推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型学习方法要么依赖对专家策略的强假设（如需要其奖励函数），要么存在内在限制（如熵崩溃），导致PRM效果弱或泛化能力有限。需要一种对专家策略假设要求最小的方法来学习有效的PRM。

Method: 提出rePIRL框架，设计双学习过程交替更新策略和过程奖励模型。采用定制化技术解决将传统逆强化学习扩展到LLM的挑战，理论上统一在线和离线PRM学习方法。

Result: 在标准化数学和编程推理数据集上的实证评估显示rePIRL优于现有方法。训练好的PRM可应用于测试时训练、测试时扩展和为困难问题训练提供早期信号。

Conclusion: rePIRL能够以最小假设学习有效的PRM，通过详细消融研究验证了训练方案和关键设计选择的有效性，为LLM推理中的过程奖励学习提供了更通用的解决方案。

Abstract: Process rewards have been widely used in deep reinforcement learning to improve training efficiency, reduce variance, and prevent reward hacking. In LLM reasoning, existing works also explore various solutions for learning effective process reward models (PRM) with or without the help of an expert policy. However, existing methods either rely on strong assumptions about the expert policies (e.g., requiring their reward functions) or suffer intrinsic limitations (e.g., entropy collapse), resulting in weak PRMs or limited generalizability. In this paper, we introduce rePIRL, an inverse RL-inspired framework that learns effective PRMs with minimal assumptions about expert policies. Specifically, we design a dual learning process that updates the policy and the PRM interchangeably. Our learning algorithm has customized techniques to address the challenges of scaling traditional inverse RL to LLMs. We theoretically show that our proposed learning framework can unify both online and offline PRM learning methods, justifying that rePIRL can learn PRMs with minimal assumptions. Empirical evaluations on standardized math and coding reasoning datasets demonstrate the effectiveness of rePIRL over existing methods. We further show the application of our trained PRM in test-time training, test-time scaling, and providing an early signal for training hard problems. Finally, we validate our training recipe and key design choices via a detailed ablation study.

</details>


### [26] [TAAM:Inductive Graph-Class Incremental Learning with Task-Aware Adaptive Modulation](https://arxiv.org/abs/2602.08036)
*Jingtao Liu,Xinming Zhang*

Main category: cs.LG

TL;DR: 提出TAAM方法，通过轻量级神经突触调制器实现无回放的图持续学习，解决稳定性-可塑性困境，并在归纳学习场景中全面超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前图持续学习方法依赖回放策略，存在内存限制、隐私问题，且难以解决稳定性-可塑性困境。需要一种无需数据回放的方法来有效处理流式图数据。

Method: 提出任务感知自适应调制（TAAM），核心是轻量级神经突触调制器（NSMs）。每个新任务训练一个专用NSM并冻结，作为"专家模块"对共享GNN主干的计算流进行节点注意自适应调制。还提出锚定多跳传播（AMP）方法处理未知任务ID。

Result: 在更严格的归纳学习场景下，TAAM在八个数据集上全面超越最先进方法，无需任何数据回放即可有效防止灾难性遗忘。

Conclusion: 轻量级任务特定模块可以有效指导固定GNN主干的推理过程，TAAM通过神经突触调制器实现了无回放的图持续学习，解决了现有方法的局限性。

Abstract: Graph Continual Learning (GCL) aims to solve the challenges of streaming graph data. However, current methods often depend on replay-based strategies, which raise concerns like memory limits and privacy issues, while also struggling to resolve the stability-plasticity dilemma. In this paper, we suggest that lightweight, task-specific modules can effectively guide the reasoning process of a fixed GNN backbone. Based on this idea, we propose Task-Aware Adaptive Modulation (TAAM). The key component of TAAM is its lightweight Neural Synapse Modulators (NSMs). For each new task, a dedicated NSM is trained and then frozen, acting as an "expert module." These modules perform detailed, node-attentive adaptive modulation on the computational flow of a shared GNN backbone. This setup ensures that new knowledge is kept within compact, task-specific modules, naturally preventing catastrophic forgetting without using any data replay. Additionally, to address the important challenge of unknown task IDs in real-world scenarios, we propose and theoretically prove a novel method named Anchored Multi-hop Propagation (AMP). Notably, we find that existing GCL benchmarks have flaws that can cause data leakage and biased evaluations. Therefore, we conduct all experiments in a more rigorous inductive learning scenario. Extensive experiments show that TAAM comprehensively outperforms state-of-the-art methods across eight datasets. Code and Datasets are available at: https://github.com/1iuJT/TAAM_AAMAS2026.

</details>


### [27] [Probability Hacking and the Design of Trustworthy ML for Signal Processing in C-UAS: A Scenario Based Method](https://arxiv.org/abs/2602.08086)
*Liisa Janssens,Laura Middeldorp*

Main category: cs.LG

TL;DR: 该论文提出使用基于场景的方法来识别和防止C-UAS系统中的概率黑客攻击，通过实施法律机制要求来增强系统可信度，促进人机协作。


<details>
  <summary>Details</summary>
Motivation: 为了有效应对无人机系统带来的各种威胁，需要专门的C-UAS系统。通过人工智能等新兴技术增强C-UAS能力，但需要解决概率黑客攻击等挑战，确保系统可信度。

Method: 采用基于场景的方法分析机器学习增强的C-UAS系统，识别概率黑客攻击作为主要挑战，并提出可在现有法律机制中实施的要求来防止此类攻击。

Result: 通过该方法识别了防止概率黑客攻击的具体要求，这些要求能够增强C-UAS系统的可信度，从而促进人机协作中的合理信任。

Conclusion: 基于场景的方法能够有效识别C-UAS系统中的概率黑客攻击风险，提出的法律机制要求有助于增强系统可信度，对于民用和军事环境中的人机协作至关重要。

Abstract: In order to counter the various threats manifested by Unmanned Aircraft Systems (UAS) adequately, specialized Counter Unmanned Aircraft Systems (C-UAS) are required. Enhancing C-UAS with Emerging and Disruptive Technologies (EDTs) such as Artificial Intelligence (AI) can lead to more effective countermeasures. In this paper a scenario-based method is applied to C-UAS augmented with Machine Learning (ML), a subset of AI, that can enhance signal processing capabilities. Via the scenarios-based method we frame in this paper probability hacking as a challenge and identify requirements which can be implemented in existing Rule of Law mechanisms to prevent probability hacking. These requirements strengthen the trustworthiness of the C-UAS, which feed into justified trust - a key to successful Human-Autonomy Teaming, in civil and military contexts. Index Terms: C-UAS, Scenario-based method, Emerging and Disruptive Technologies, Probability hacking, Trustworthiness.

</details>


### [28] [Interpretable Dynamic Network Modeling of Tensor Time Series via Kronecker Time-Varying Graphical Lasso](https://arxiv.org/abs/2602.08197)
*Shingo Higashiguchi,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 提出Kronecker时变图形套索(KTVGL)方法，用于张量时间序列建模，通过Kronecker积形式估计模态特定的动态网络，提高可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着Web服务的快速发展，金融、医疗、在线平台等领域产生大量时间序列数据。这些数据通常包含多个相互作用的变量，估计变量间的时变依赖关系（动态网络结构）对准确建模至关重要。然而，现实世界数据常表示为多模态张量时间序列，导致网络结构复杂、难以解释且计算量大。

Method: 提出Kronecker时变图形套索(KTVGL)方法，通过Kronecker积形式估计模态特定的动态网络，避免过度复杂的纠缠结构。该方法可扩展为流算法，使计算时间与序列长度无关。

Result: 在合成数据实验中，KTVGL比现有方法获得更高的边估计精度，同时需要更少的计算时间。通过真实世界数据的案例研究进一步证明了其实用价值。

Conclusion: KTVGL方法能有效建模张量时间序列，提供可解释的动态网络结构估计，计算效率高，适用于大规模数据场景。

Abstract: With the rapid development of web services, large amounts of time series data are generated and accumulated across various domains such as finance, healthcare, and online platforms. As such data often co-evolves with multiple variables interacting with each other, estimating the time-varying dependencies between variables (i.e., the dynamic network structure) has become crucial for accurate modeling. However, real-world data is often represented as tensor time series with multiple modes, resulting in large, entangled networks that are hard to interpret and computationally intensive to estimate. In this paper, we propose Kronecker Time-Varying Graphical Lasso (KTVGL), a method designed for modeling tensor time series. Our approach estimates mode-specific dynamic networks in a Kronecker product form, thereby avoiding overly complex entangled structures and producing interpretable modeling results. Moreover, the partitioned network structure prevents the exponential growth of computational time with data dimension. In addition, our method can be extended to stream algorithms, making the computational time independent of the sequence length. Experiments on synthetic data show that the proposed method achieves higher edge estimation accuracy than existing methods while requiring less computation time. To further demonstrate its practical value, we also present a case study using real-world data. Our source code and datasets are available at https://github.com/Higashiguchi-Shingo/KTVGL.

</details>


### [29] [SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning](https://arxiv.org/abs/2602.08234)
*Peng Xia,Jianwen Chen,Hanyang Wang,Jiaqi Liu,Kaide Zeng,Yu Wang,Siwei Han,Yiyang Zhou,Xujiang Zhao,Haifeng Chen,Zeyu Zheng,Cihang Xie,Huaxiu Yao*

Main category: cs.LG

TL;DR: SkillRL：通过自动技能发现和递归进化，将原始经验转化为可重用行为模式的LLM智能体框架


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆的LLM智能体方法主要存储原始轨迹，这些轨迹冗余且噪声多，无法提取高级可重用行为模式，限制了智能体的泛化能力

Method: 1. 基于经验的蒸馏机制构建分层技能库SkillBank；2. 自适应检索策略获取通用和任务特定启发式；3. 递归进化机制使技能库与强化学习策略协同进化

Result: 在ALFWorld、WebShop和七个搜索增强任务上达到最先进性能，超越强基线15.3%以上，且随着任务复杂度增加保持鲁棒性

Conclusion: SkillRL通过将原始经验转化为结构化技能，显著减少token占用同时增强推理效用，为LLM智能体提供了从经验中学习可重用行为模式的有效框架

Abstract: Large Language Model (LLM) agents have shown stunning results in complex tasks, yet they often operate in isolation, failing to learn from past experiences. Existing memory-based methods primarily store raw trajectories, which are often redundant and noise-heavy. This prevents agents from extracting high-level, reusable behavioral patterns that are essential for generalization. In this paper, we propose SkillRL, a framework that bridges the gap between raw experience and policy improvement through automatic skill discovery and recursive evolution. Our approach introduces an experience-based distillation mechanism to build a hierarchical skill library SkillBank, an adaptive retrieval strategy for general and task-specific heuristics, and a recursive evolution mechanism that allows the skill library to co-evolve with the agent's policy during reinforcement learning. These innovations significantly reduce the token footprint while enhancing reasoning utility. Experimental results on ALFWorld, WebShop and seven search-augmented tasks demonstrate that SkillRL achieves state-of-the-art performance, outperforming strong baselines over 15.3% and maintaining robustness as task complexity increases. Code is available at this https://github.com/aiming-lab/SkillRL.

</details>


### [30] [Constraint-Aware Generative Auto-bidding via Pareto-Prioritized Regret Optimization](https://arxiv.org/abs/2602.08261)
*Binglin Wu,Yingyi Zhang,Xianneng Li,Ruyue Deng,Chuan Yue,Weiru Zhang,Xiaoyi Zeng*

Main category: cs.LG

TL;DR: PRO-Bid是一个基于约束感知的生成式自动出价框架，通过约束解耦帕累托表示和反事实遗憾优化机制，解决传统决策变换器在目标CPA约束下的状态混叠和平均行为模仿问题，实现更好的约束满足和价值获取。


<details>
  <summary>Details</summary>
Motivation: 传统决策变换器在应用于具有严格效率约束（如目标CPA）的自动出价系统时面临两个挑战：1）标准的Return-to-Go条件忽略了成本维度，导致状态混叠，无法精确控制资源节奏；2）标准回归迫使策略模仿历史平均行为，限制了向约束边界优化的能力。

Method: 提出PRO-Bid框架，包含两个协同机制：1）约束解耦帕累托表示（CDPR）：将全局约束分解为递归成本和价值上下文以恢复资源感知，同时基于帕累托前沿重新加权轨迹以聚焦高效数据；2）反事实遗憾优化（CRO）：利用全局结果预测器识别更优的反事实动作，将这些高效用结果作为加权回归目标，使模型超越历史平均行为，接近最优约束边界。

Result: 在两个公共基准测试和在线A/B测试中，PRO-Bid相比最先进的基线方法，在约束满足和价值获取方面都表现出优越性能。

Conclusion: PRO-Bid通过创新的约束解耦表示和反事实优化机制，成功解决了决策变换器在约束自动出价系统中的关键挑战，实现了更好的约束边界优化和性能提升。

Abstract: Auto-bidding systems aim to maximize marketing value while satisfying strict efficiency constraints such as Target Cost-Per-Action (CPA). Although Decision Transformers provide powerful sequence modeling capabilities, applying them to this constrained setting encounters two challenges: 1) standard Return-to-Go conditioning causes state aliasing by neglecting the cost dimension, preventing precise resource pacing; and 2) standard regression forces the policy to mimic average historical behaviors, thereby limiting the capacity to optimize performance toward the constraint boundary. To address these challenges, we propose PRO-Bid, a constraint-aware generative auto-bidding framework based on two synergistic mechanisms: 1) Constraint-Decoupled Pareto Representation (CDPR) decomposes global constraints into recursive cost and value contexts to restore resource perception, while reweighting trajectories based on the Pareto frontier to focus on high-efficiency data; and 2) Counterfactual Regret Optimization (CRO) facilitates active improvement by utilizing a global outcome predictor to identify superior counterfactual actions. By treating these high-utility outcomes as weighted regression targets, the model transcends historical averages to approach the optimal constraint boundary. Extensive experiments on two public benchmarks and online A/B tests demonstrate that PRO-Bid achieves superior constraint satisfaction and value acquisition compared to state-of-the-art baselines.

</details>


### [31] [Projected Gradient Ascent for Efficient Reward-Guided Updates with One-Step Generative Models](https://arxiv.org/abs/2602.08646)
*Jisung Hwang,Minhyuk Sung*

Main category: cs.LG

TL;DR: 提出一种带约束的隐变量优化方法，通过硬性白高斯噪声约束防止奖励黑客攻击，在保持生成质量的同时显著提升优化效率。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时隐变量优化方法虽然能提升预训练生成模型的奖励引导生成效果，但存在两个主要问题：1）容易发生奖励黑客攻击，导致生成质量下降；2）优化速度太慢，不实用。

Method: 采用硬性白高斯噪声约束替代软正则化，通过投影梯度上升法在每次更新后应用闭式投影，保持隐向量在整个优化过程中明确保持噪声特性，防止导致不真实伪影的漂移。

Result: 该方法仅需SOTA正则化方法30%的墙钟时间就能达到相当的审美分数，同时有效防止奖励黑客攻击。投影操作复杂度为O(N log N)，与排序或FFT等标准算法相当，实际不增加墙钟时间。

Conclusion: 通过硬性白高斯噪声约束实现的约束隐变量优化方法，使测试时优化既高效又可靠，为奖励引导生成提供了实用解决方案。

Abstract: We propose a constrained latent optimization method for reward-guided generation that preserves white Gaussian noise characteristics with negligible overhead. Test-time latent optimization can unlock substantially better reward-guided generations from pretrained generative models, but it is prone to reward hacking that degrades quality and also too slow for practical use. In this work, we make test-time optimization both efficient and reliable by replacing soft regularization with hard white Gaussian noise constraints enforced via projected gradient ascent. Our method applies a closed-form projection after each update to keep the latent vector explicitly noise-like throughout optimization, preventing the drift that leads to unrealistic artifacts. This enforcement adds minimal cost: the projection matches the $O(N \log N)$ complexity of standard algorithms such as sorting or FFT and does not practically increase wall-clock time. In experiments, our approach reaches a comparable Aesthetic Score using only 30% of the wall-clock time required by the SOTA regularization-based method, while preventing reward hacking.

</details>


### [32] [Dashed Line Defense: Plug-And-Play Defense Against Adaptive Score-Based Query Attacks](https://arxiv.org/abs/2602.08679)
*Yanzhang Fu,Zizheng Guo,Jizhou Luo*

Main category: cs.LG

TL;DR: 提出Dashed Line Defense (DLD)防御方法，通过引入损失观测的模糊性来抵御自适应查询攻击，在ImageNet上验证了其优于现有防御方法的性能。


<details>
  <summary>Details</summary>
Motivation: 基于分数的查询攻击仅通过黑盒访问模型输出分数就能生成对抗样本，对深度学习模型构成严重威胁。现有运行时防御大多需要访问模型参数，或者无法抵御攻击者的自适应策略，即使是当前最先进的即插即用防御也能被自适应攻击绕过。

Method: 提出Dashed Line Defense (DLD)，一种即插即用的后处理方法。通过在观测损失与候选样本真实对抗强度之间引入模糊性，阻止攻击者可靠分析和适应其查询，从而有效破坏对抗样本生成过程。

Result: 在ImageNet上的实验表明，DLD在保持模型预测标签的同时，始终优于先前的防御方法，即使在最坏情况的自适应攻击下也能有效防御。论文还提供了DLD防御能力的理论保证。

Conclusion: DLD是一种有效的即插即用防御方法，能够抵御自适应查询攻击，解决了现有运行时防御的关键局限性，为黑盒对抗攻击防御提供了新的解决方案。

Abstract: Score-based query attacks pose a serious threat to deep learning models by crafting adversarial examples (AEs) using only black-box access to model output scores, iteratively optimizing inputs based on observed loss values. While recent runtime defenses attempt to disrupt this process via output perturbation, most either require access to model parameters or fail when attackers adapt their tactics. In this paper, we first reveal that even the state-of-the-art plug-and-play defense can be bypassed by adaptive attacks, exposing a critical limitation of existing runtime defenses. We then propose Dashed Line Defense (DLD), a plug-and-play post-processing method specifically designed to withstand adaptive query strategies. By introducing ambiguity in how the observed loss reflects the true adversarial strength of candidate examples, DLD prevents attackers from reliably analyzing and adapting their queries, effectively disrupting the AE generation process. We provide theoretical guarantees of DLD's defense capability and validate its effectiveness through experiments on ImageNet, demonstrating that DLD consistently outperforms prior defenses--even under worst-case adaptive attacks--while preserving the model's predicted labels.

</details>


### [33] [How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs](https://arxiv.org/abs/2602.08808)
*Yapei Chang,Kyle Lo,Mohit Iyyer,Luca Soldaini*

Main category: cs.LG

TL;DR: How2Everything：一个用于评估和改进目标条件程序生成的框架，包括数据挖掘、基准构建、评估协议和强化学习改进


<details>
  <summary>Details</summary>
Motivation: 生成逐步"如何做"程序是LLM的关键能力，但在真实任务中大规模评估和改进程序有效性仍然具有挑战性且研究不足

Method: 1) How2Mine：从98万网页中挖掘35.1万条程序；2) How2Bench：构建7K平衡评估集；3) How2Score：使用LLM法官检测关键失败的评估协议；4) 将前沿模型蒸馏为8B模型进行低成本评估；5) 使用How2Score作为奖励进行强化学习

Result: How2Bench揭示了模型规模和训练阶段的明显扩展趋势；使用How2Score进行RL在三个模型上将性能提升超过10分，且对标准基准没有系统性回归

Conclusion: How2Everything展示了预训练网络数据如何支持能力评估和改进的闭环，为程序生成提供了可扩展的评估和改进框架

Abstract: Generating step-by-step "how-to" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation. Our framework includes How2Mine, which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench, a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score, an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining. Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale.

</details>


### [34] [Robust Policy Optimization to Prevent Catastrophic Forgetting](https://arxiv.org/abs/2602.08813)
*Mahdi Sabbaghi,George Pappas,Adel Javanmard,Hamed Hassani*

Main category: cs.LG

TL;DR: FRPO是一种鲁棒的RLHF框架，通过在KL有界策略邻域内优化奖励，防止下游微调时的灾难性遗忘，保持安全性和任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过多阶段后训练（RLHF+下游微调），但即使小的下游更新也会破坏先前学习的行为（如安全性），暴露灾难性遗忘问题。现有方法主要关注下游时保护先前行为，但需要预微调鲁棒性。

Method: 提出Fine-tuning Robust Policy Optimization (FRPO)，在KL有界策略邻域内优化奖励，确保奖励在策略变化下的稳定性。通过修改GRPO开发算法，无需额外计算。

Result: FRPO显著减少多个基础模型和下游微调机制（SFT和RL）下的安全性退化，同时保持下游任务性能。在数学RL设置中，FRPO能在后续微调下保持准确性。

Conclusion: FRPO通过预微调鲁棒性解决了RLHF中的灾难性遗忘问题，确保基础策略对下游微调具有鲁棒性，为语言模型的安全可靠部署提供了有效方案。

Abstract: Large language models are commonly trained through multi-stage post-training: first via RLHF, then fine-tuned for other downstream objectives. Yet even small downstream updates can compromise earlier learned behaviors (e.g., safety), exposing a brittleness known as catastrophic forgetting. This suggests standard RLHF objectives do not guarantee robustness to future adaptation. To address it, most prior work designs downstream-time methods to preserve previously learned behaviors. We argue that preventing this requires pre-finetuning robustness: the base policy should avoid brittle high-reward solutions whose reward drops sharply under standard fine-tuning.
  We propose Fine-tuning Robust Policy Optimization (FRPO), a robust RLHF framework that optimizes reward not only at the current policy, but across a KL-bounded neighborhood of policies reachable by downstream adaptation. The key idea is to ensure reward stability under policy shifts via a max-min formulation. By modifying GRPO, we develop an algorithm with no extra computation, and empirically show it substantially reduces safety degradation across multiple base models and downstream fine-tuning regimes (SFT and RL) while preserving downstream task performance. We further study a math-focused RL setting, demonstrating that FRPO preserves accuracy under subsequent fine-tuning.

</details>


### [35] [Kirin: Improving ANN efficiency with SNN Hybridization](https://arxiv.org/abs/2602.08817)
*Chenyu Wang,Zhanglu Yan,Zhi Zhou,Xu Chen,Weng-Fai Wong*

Main category: cs.LG

TL;DR: Kirin提出了一种整数与脉冲混合的SNN架构，实现了准确率无损的ANN到SNN转换，在W4A4&8量化设置下达到接近FP16精度，同时降低84.66%能耗并缩短93.75%时间步长。


<details>
  <summary>Details</summary>
Motivation: 传统ANN（特别是LLM）推理能力强但能耗高，而SNN具有二进制和事件驱动特性，能效优异。ANN到SNN转换中的量化过程面临挑战：高比特量化值需要更长时间窗口，增加系统延迟；单脉冲方案信息损失与多脉冲方案能耗之间存在固有权衡。

Method: 提出Kirin混合SNN架构：1）脉冲矩阵混合策略：将导致小时间窗口的低比特参数编码为二进制脉冲，其余参数保持整数格式，减少SNN执行延迟；2）静默阈值机制：调节单脉冲发射时机，确保输出与LLM数学等价，保持准确率。

Result: 在W4A4&8量化设置下，Kirin达到接近FP16精度，能耗降低84.66%，时间步长缩短93.75%，实现了准确率无损的ANN到SNN转换。

Conclusion: Kirin通过整数与脉冲混合的SNN架构，有效解决了ANN到SNN转换中的延迟和能耗权衡问题，为高效能神经计算提供了新方案。

Abstract: Artificial neural networks (ANNs), particularly large language models (LLMs), demonstrate powerful inference capabilities but consume substantial energy. Conversely, spiking neural networks (SNNs) exhibit exceptional energy efficiency due to their binary and event-driven characteristics, thus motivating the study of ANN-to-SNN conversion. In this process, quantization plays a pivotal role, mapping LLMs' floating-point parameters to discrete SNN parameters via the temporal dimension of the time window. However, several challenges remain in the conversion process: (i) converting high bit-width quantization values into binary spikes requires longer time windows, increasing system latency; and (ii) the inherent trade-off between the information loss of single-spike schemes and the energy costs of multi-spike ones in SNN. To address these challenges, we propose Kirin, a integer and spike hybrid based SNN to achieve accuracy lossless ANN-to-SNN conversion with time and energy efficiency. Specifically, we first propose a Spike Matrix Hybridization strategy that encoding low bit-width parameters that leading to small time window size into binary spikes while preserving the rest in integer format, thereby reducing the overall latency of SNN execution. Second, we introduce a silence threshold mechanism to regulate the timing of single-spike firing, ensuring the output is mathematically equivalent to the LLM's output and preserves accuracy. Experimental results demonstrate that Kirin, under a W4A4\&8 quantization setting, achieves near-FP16 accuracy while reducing energy consumption by up to 84.66\% and shortening time steps by 93.75\%.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [36] [DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents](https://arxiv.org/abs/2602.07035)
*Jiahao Zhao,Shaoxuan Xu,Zhongxiang Sun,Fengqi Zhu,Jingyang Ou,Yuling Shi,Chongxuan Li,Xiao Zhang,Jun Xu*

Main category: cs.AI

TL;DR: 提出DLLM-Searcher框架，通过两阶段后训练提升扩散大语言模型(dLLM)的搜索代理能力，并设计P-ReAct并行推理范式解决延迟问题


<details>
  <summary>Details</summary>
Motivation: 现有搜索代理面临延迟挑战（串行推理导致高延迟），而dLLM具有并行解码优势但推理和工具调用能力弱，需要解决这两个挑战来提升搜索代理效率

Method: 1) 两阶段后训练：Agentic SFT和Agentic VRPO增强dLLM信息搜索和推理能力；2) P-ReAct范式：优先解码工具调用指令，实现推理等待并行化

Result: DLLM-Searcher性能与主流LLM搜索代理相当，P-ReAct实现约15%的推理加速

Conclusion: 成功结合dLLM并行优势与搜索代理需求，通过能力增强和并行化设计有效解决了延迟和能力挑战

Abstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C

</details>


### [37] [NAAMSE: Framework for Evolutionary Security Evaluation of Agents](https://arxiv.org/abs/2602.07391)
*Kunal Pai,Parth Shah,Harshil Patel*

Main category: cs.AI

TL;DR: NAAMSE是一个进化框架，将AI代理安全评估重新定义为反馈驱动的优化问题，通过遗传提示突变和分层语料库探索来发现被单次方法遗漏的漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理安全评估主要依赖人工红队或静态基准测试，这些方法无法模拟自适应、多轮次的对抗攻击，导致安全评估存在瓶颈。

Method: 使用单一自主代理协调遗传提示突变、分层语料库探索和非对称行为评分的生命周期，以模型响应作为适应度信号，迭代地组合有效攻击策略，同时确保"良性使用正确性"。

Result: 在Gemini 2.5 Flash上的实验表明，进化突变能系统性地放大被单次方法遗漏的漏洞，探索与定向突变的协同作用能发现高严重性故障模式。

Conclusion: 这种自适应方法为面对不断演变的威胁时提供了更现实和可扩展的代理鲁棒性评估，代码已开源。

Abstract: AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring "benign-use correctness", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.

</details>


### [38] [EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge](https://arxiv.org/abs/2602.07695)
*Congcong Hu,Yuang Shi,Fan Huang,Yang Xiang,Zhou Ye,Ming Jin,Shiyu Wang*

Main category: cs.AI

TL;DR: EventCast是一个将未来事件知识整合到时间序列预测中的模块化框架，专门解决电商在闪购、节假日等特殊时期的需求预测问题，通过LLM处理非结构化业务数据并生成可解释的文本摘要，结合历史需求特征实现准确、可解释的预测。


<details>
  <summary>Details</summary>
Motivation: 现有预测系统在闪购、节假日促销、政策干预等高影响时期经常失效，因为这些时期的需求模式会发生突然且不可预测的变化。电商运营需要能够处理这些特殊事件的预测系统来改进库存规划和履约调度。

Method: EventCast采用模块化框架，利用LLM专门处理非结构化业务数据（如营销活动、节假日安排、卖家激励等），将其转换为可解释的文本摘要，捕捉文化细微差异和新事件组合。这些摘要通过双塔架构与历史需求特征融合，实现准确、可解释的预测。

Result: 在跨越4个国家160个地区10个月的真实电商场景中，EventCast相比无事件知识的变体在MAE和MSE上分别提升86.9%和97.7%；在事件驱动时期，相比最佳工业基线分别减少MAE 57.0%和MSE 83.3%。自2025年3月起已部署到实际工业管道中。

Conclusion: EventCast通过将LLM专门用于事件驱动推理而非数值预测，成功整合未来事件知识到时间序列预测中，为动态电商环境提供了实用解决方案，显著提升了特殊时期的预测准确性，并已在实际工业环境中得到验证和应用。

Abstract: Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.

</details>


### [39] [Securing Dual-Use Pathogen Data of Concern](https://arxiv.org/abs/2602.08061)
*Doni Bloomfield,Allison Berke,Moritz S. Hanke,Aaron Maiwald,James R. M. Black,Toby Webster,Tina Hernandez-Boussard,Oliver M. Crook,Jassi Pannu*

Main category: cs.AI

TL;DR: 本文提出了一个五层生物安全数据等级（BDL）框架，用于根据数据在训练AI模型时可能带来的生物安全风险对病原体数据进行分类，并为每个等级提出相应的技术限制措施。


<details>
  <summary>Details</summary>
Motivation: AI生物模型训练数据的类型直接关系到模型的能力，包括可能带来生物安全风险的能力。随着AI在生物领域的广泛应用，需要建立数据控制机制来防止AI被用于有害应用（如生物武器开发）。

Method: 提出了一个五层生物安全数据等级（BDL）框架，根据数据在训练AI模型时对生物安全风险的贡献程度对病原体数据进行分类。为每个BDL等级设计了相应的技术限制措施，并提出了针对新创建的双重用途病原体数据的治理框架。

Result: 开发了一个系统化的数据分类框架，能够根据生物安全风险对病原体数据进行分级管理。该框架为国际社会制定AI生物安全数据控制政策提供了技术基础。

Conclusion: 在计算和编码资源广泛可及的世界中，数据控制可能是减少令人担忧的生物AI能力扩散的最有效干预措施之一。BDL框架为实施此类控制提供了实用工具。

Abstract: Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.

</details>


### [40] [Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention](https://arxiv.org/abs/2602.08121)
*Liying Wang,Madison Lee,Yunzhang Jiang,Steven Chen,Kewei Sha,Yunhe Feng,Frank Wong,Lisa Hightow-Weidman,Weichao Yuwen*

Main category: cs.AI

TL;DR: 研究开发了Glow——一个基于生成式AI的DBT技能教练，用于HIV和物质使用风险人群，并通过用户驱动的对抗性测试评估其安全性，发现存在安全漏洞需要修复。


<details>
  <summary>Details</summary>
Motivation: HIV和物质使用是相互影响的流行病，有共同的心理学驱动因素（冲动性和适应不良的应对方式）。DBT针对这些机制但面临可扩展性挑战，而生成式AI有潜力提供个性化DBT教练，但其快速发展超过了安全基础设施的建设。

Method: 开发了Glow——基于生成式AI的DBT技能教练，提供链分析和解决方案分析。与洛杉矶社区卫生组织合作，对临床工作人员（6人）和有生活经验的个体（28人）进行可用性测试。使用HHH框架，采用用户驱动的对抗性测试，参与者识别目标行为并生成上下文现实的风险探测，评估了37个风险探测交互的安全性表现。

Result: Glow适当地处理了73%的风险探测，但不同代理表现差异大：解决方案分析代理有90%的适当处理率，而链分析代理只有44%。安全失败集中在鼓励物质使用和正常化有害行为。链分析代理陷入"共情陷阱"，提供强化适应不良信念的验证。此外，还识别出27个DBT技能错误信息实例。

Conclusion: 这是首次对生成式AI提供的DBT教练进行HIV和物质使用风险降低的系统性安全评估。研究结果揭示了在临床试验前需要缓解的漏洞。HHH框架和用户驱动的对抗性测试为评估生成式AI心理健康干预提供了可复制的方法。

Abstract: Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT skills coach delivering chain and solution analysis for individuals at risk for HIV and substance use. In partnership with a Los Angeles community health organization, we conducted usability testing with clinical staff (n=6) and individuals with lived experience (n=28). Using the Helpful, Honest, and Harmless (HHH) framework, we employed user-driven adversarial testing wherein participants identified target behaviors and generated contextually realistic risk probes. We evaluated safety performance across 37 risk probe interactions. Results: Glow appropriately handled 73% of risk probes, but performance varied by agent. The solution analysis agent demonstrated 90% appropriate handling versus 44% for the chain analysis agent. Safety failures clustered around encouraging substance use and normalizing harmful behaviors. The chain analysis agent fell into an "empathy trap," providing validation that reinforced maladaptive beliefs. Additionally, 27 instances of DBT skill misinformation were identified. Conclusions: This study provides the first systematic safety evaluation of GenAI-delivered DBT coaching for HIV and substance use risk reduction. Findings reveal vulnerabilities requiring mitigation before clinical trials. The HHH framework and user-driven adversarial testing offer replicable methods for evaluating GenAI mental health interventions.

</details>


### [41] [PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition](https://arxiv.org/abs/2602.08240)
*Xun Su,Huamin Wang,Qi Zhang*

Main category: cs.AI

TL;DR: 提出PTS-SNN框架，通过提示调优解决SSL表示与SNN动态特性之间的分布不匹配问题，实现高效语音情感识别


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别模型计算成本高，难以部署在资源受限的边缘设备上。SNN虽然能效高，但与连续自监督学习表示存在分布不匹配问题，高动态范围的嵌入会降低基于阈值神经元的信息编码能力。

Method: 提出PTS-SNN框架：1) 使用时移脉冲编码器通过无参数通道移位捕获局部时间依赖性；2) 设计上下文感知膜电位校准策略，利用脉冲稀疏线性注意力模块聚合全局语义上下文到可学习的软提示中，动态调节PLIF神经元的偏置电压，使异构输入分布集中在响应性放电范围内。

Result: 在五个多语言数据集上的实验表明，PTS-SNN在IEMOCAP上达到73.34%的准确率，与竞争性ANN相当，同时仅需1.19M可训练参数和每个样本0.35 mJ的推理能耗。

Conclusion: PTS-SNN成功解决了SSL表示与SNN之间的分布不匹配问题，实现了参数高效且能耗低的语音情感识别，为边缘设备部署提供了可行方案。

Abstract: Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.

</details>


### [42] [Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI](https://arxiv.org/abs/2602.08373)
*Feiyu Wu,Xu Zheng,Yue Qu,Zhuocheng Wang,Zicheng Feng,Hui Li*

Main category: cs.AI

TL;DR: VIRF框架通过神经符号架构实现LLM规划器的可验证安全，使用逻辑导师提供因果反馈进行智能计划修复，在家庭安全任务中实现零危险行动率和最高目标达成率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM规划器缺乏形式化推理能力，无法提供严格的安全保证。现有方法要么依赖不可靠的LLM进行安全检查，要么简单拒绝不安全计划而不提供修复方案。

Method: 提出可验证迭代精炼框架(VIRF)，采用神经符号架构，建立导师-学徒对话机制：基于形式化安全本体的确定性逻辑导师为LLM规划器提供因果和教学反馈，实现智能计划修复而非简单避免。同时引入可扩展的知识获取管道，从真实世界文档合成安全知识库。

Result: 在具有挑战性的家庭安全任务中，VIRF实现了0%的危险行动率(HAR)和77.3%的目标达成率(GCR)，在所有基线方法中最高。平均仅需1.1次修正迭代，效率很高。

Conclusion: VIRF展示了一条构建根本上可信赖且可验证安全的具身智能体的原则性途径，从被动安全把关转向主动协作范式。

Abstract: Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [43] [BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents](https://arxiv.org/abs/2602.06975)
*R. James Cotton,Thomas Leonard*

Main category: cs.CL

TL;DR: BiomechAgent是一个代码生成AI代理，通过自然语言实现生物力学分析，无需编程即可查询数据库、生成可视化、解释数据，使运动捕捉数据分析更易用。


<details>
  <summary>Details</summary>
Motivation: 虽然无标记运动捕捉技术使定量运动分析越来越普及，但分析生成的数据对于没有编程经验的临床医生仍然存在障碍，需要更易用的工具来降低使用门槛。

Method: 开发了BiomechAgent代码生成AI代理，支持自然语言交互；建立了系统化基准测试，涵盖数据检索、可视化、活动分类、时间分割和临床推理；评估了领域特定指令、专用工具集成和不同模型选择的影响。

Result: BiomechAgent在数据检索和可视化任务上达到稳健准确度，展现出新兴的临床推理能力；生物力学领域特定指令显著优于通用提示；集成步态事件检测专用工具大幅提升了时空分析准确度；本地开源模型性能明显低于前沿云端大模型。

Conclusion: BiomechAgent使无标记运动捕捉数据对终端用户更加有用和易用，通过自然语言交互降低了生物力学分析的门槛，但模型选择和专用工具集成对性能至关重要。

Abstract: Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [44] [STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction](https://arxiv.org/abs/2602.08245)
*Jinhao Li,Yuxuan Cong,Yingqiao Wang,Hao Xia,Shan Huang,Yijia Zhang,Ningyi Xu,Guohao Dai*

Main category: cs.RO

TL;DR: STEP提出了一种轻量级时空一致性预测机制，通过构建高质量的热启动动作来加速扩散策略推理，同时保持动作质量，在机器人操作任务中显著降低延迟并提高成功率。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人操作中表现出色，但迭代去噪过程导致推理延迟高，限制了实时闭环系统的控制频率。现有加速方法要么降低采样步数，要么绕过扩散直接预测，要么重用过去动作，但往往难以同时保持动作质量和实现持续低延迟。

Method: 1. 轻量级时空一致性预测机制：构建高质量热启动动作，既在分布上接近目标动作，又保持时间一致性，不损害原始扩散策略的生成能力。
2. 速度感知扰动注入机制：基于时间动作变化自适应调节驱动激励，防止执行停滞，特别适用于现实世界任务。
3. 理论分析：证明预测机制诱导局部收缩映射，确保扩散细化过程中动作误差的收敛。

Result: 在9个模拟基准和2个现实世界任务上进行广泛评估。STEP仅用2步就能在RoboMimic基准上比BRIDGER和DDIM平均提高21.6%的成功率，在现实世界任务上提高27.5%的成功率。STEP在推理延迟和成功率方面持续超越现有方法的帕累托前沿。

Conclusion: STEP通过时空一致性预测机制有效解决了扩散策略的高延迟问题，在保持动作质量的同时显著加速推理，为实时机器人操作提供了实用的解决方案，在延迟和性能之间取得了更好的平衡。

Abstract: Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods.

</details>


### [45] [ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects](https://arxiv.org/abs/2602.08285)
*Josh Pinskier,Sarah Baldwin,Stephen Rodan,David Howard*

Main category: cs.RO

TL;DR: ReefFlex是一种生成式软手指设计方法，通过编码异质抓取动作为简化运动基元，优化设计能安全抓取脆弱异形珊瑚的软机器人，用于珊瑚礁修复。


<details>
  <summary>Details</summary>
Motivation: 气候变化、入侵物种和人类活动正以前所未有的速度破坏全球珊瑚礁，威胁生物多样性和渔业，减少海岸保护。解决这一挑战需要可扩展的珊瑚再生技术，但目前缺乏安全可靠的工具来处理脆弱的珊瑚。

Method: ReefFlex是一种生成式软手指设计方法，将异质抓取编码为简化运动基元集合，创建可处理的多元优化问题，探索多样软手指设计空间，选出能安全抓取脆弱异形珊瑚的候选方案。

Result: ReefFlex提高了抓取成功率、抓取质量（抗干扰性、定位精度），并减少了珊瑚操作过程中的不良事件。设计出的软机器人可用于陆上水产养殖设施中珊瑚的生长和操作，为未来珊瑚移植做准备。

Conclusion: ReefFlex为复杂操作的软末端执行器设计提供了通用方法，为珊瑚处理等先前难以实现自动化领域的自动化铺平了道路，有助于珊瑚礁修复。

Abstract: Climate change, invasive species and human activities are currently damaging the world's coral reefs at unprecedented rates, threatening their vast biodiversity and fisheries, and reducing coastal protection. Solving this vast challenge requires scalable coral regeneration technologies that can breed climate-resilient species and accelerate the natural regrowth processes; actions that are impeded by the absence of safe and robust tools to handle the fragile coral. We investigate ReefFlex, a generative soft finger design methodology that explores a diverse space of soft fingers to produce a set of candidates capable of safely grasping fragile and geometrically heterogeneous coral in a cluttered environment. Our key insight is encoding heterogeneous grasping into a reduced set of motion primitives, creating a simplified, tractable multi-objective optimisation problem. To evaluate the method, we design a soft robot for reef rehabilitation, which grows and manipulates coral in onshore aquaculture facilities for future reef out-planting. We demonstrate ReefFlex increases both grasp success and grasp quality (disturbance resistance, positioning accuracy) and reduces in adverse events encountered during coral manipulation compared to reference designs. ReefFlex, offers a generalisable method to design soft end-effectors for complex handling and paves a pathway towards automation in previously unachievable domains like coral handling for restoration.

</details>


### [46] [SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios](https://arxiv.org/abs/2602.08440)
*Tian Gao,Celine Tan,Catherine Glossop,Timothy Gao,Jiankai Sun,Kyle Stachowicz,Shirley Wu,Oier Mees,Dorsa Sadigh,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: SteerVLA 利用视觉语言模型（VLM）的推理能力生成细粒度语言指令来引导视觉语言动作（VLA）驾驶策略，在自动驾驶中实现高层语义推理与底层控制的有效集成。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶面临的核心挑战是如何将高层语义推理（处理长尾事件）与底层反应式控制（确保鲁棒驾驶）有效集成。虽然大型视觉语言模型（VLM）具备强大的常识推理能力，但缺乏安全车辆控制所需的实际经验。

Method: 提出 SteerVLA 方法，利用 VLM 的推理能力生成细粒度语言指令来引导 VLA 驾驶策略。关键创新在于高层 VLM 与底层 VLA 之间的丰富语言接口，使高层策略能更有效地将其推理基于底层策略的控制输出。使用 VLM 为现有驾驶数据添加详细语言标注，提供与车辆控制对齐的细粒度语言监督。

Result: 在具有挑战性的闭环基准测试中，SteerVLA 在整体驾驶得分上比最先进方法高出 4.77 分，在长尾子集上高出 8.04 分。

Conclusion: SteerVLA 通过语言接口有效整合了高层语义推理与底层控制，显著提升了自动驾驶性能，特别是在处理长尾事件方面表现突出。

Abstract: A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded experience necessary for safe vehicle control. We posit that an effective autonomous agent should leverage the world knowledge of VLMs to guide a steerable driving policy toward robust control in driving scenarios. To this end, we propose SteerVLA, which leverages the reasoning capabilities of VLMs to produce fine-grained language instructions that steer a vision-language-action (VLA) driving policy. Key to our method is this rich language interface between the high-level VLM and low-level VLA, which allows the high-level policy to more effectively ground its reasoning in the control outputs of the low-level policy. To provide fine-grained language supervision aligned with vehicle control, we leverage a VLM to augment existing driving data with detailed language annotations, which we find to be essential for effective reasoning and steerability. We evaluate SteerVLA on a challenging closed-loop benchmark, where it outperforms state-of-the-art methods by 4.77 points in overall driving score and by 8.04 points on a long-tail subset. The project website is available at: https://steervla.github.io/.

</details>
