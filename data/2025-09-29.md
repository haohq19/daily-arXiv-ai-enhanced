<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 6]
- [cs.LG](#cs.LG) [Total: 14]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Dynamic Novel View Synthesis in High Dynamic Range](https://arxiv.org/abs/2509.21853)
*Kaixuan Zhang,Zhipeng Xiong,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: 提出了HDR动态新视角合成（HDR DNVS）问题，并开发了HDR-4DGS方法，通过动态色调映射模块在LDR和HDR域之间建立连接，实现动态场景的高质量HDR渲染。


<details>
  <summary>Details</summary>
Motivation: 现有HDR新视角合成方法主要关注静态场景，但真实世界场景常包含动态元素（移动物体、变化光照等），需要同时建模时间辐射变化和3D转换。

Method: 基于高斯泼溅的HDR-4DGS架构，包含创新的动态色调映射模块，根据时间维度上辐射分布的变化动态调整色调映射函数。

Result: HDR-4DGS在定量性能和视觉保真度方面均优于现有最先进方法，实现了时间辐射一致性和空间准确的颜色转换。

Conclusion: 该方法能够从任意视角和时间实例生成逼真的HDR渲染，解决了动态场景HDR新视角合成的挑战。

Abstract: High Dynamic Range Novel View Synthesis (HDR NVS) seeks to learn an HDR 3D
model from Low Dynamic Range (LDR) training images captured under conventional
imaging conditions. Current methods primarily focus on static scenes,
implicitly assuming all scene elements remain stationary and non-living.
However, real-world scenarios frequently feature dynamic elements, such as
moving objects, varying lighting conditions, and other temporal events, thereby
presenting a significantly more challenging scenario. To address this gap, we
propose a more realistic problem named HDR Dynamic Novel View Synthesis (HDR
DNVS), where the additional dimension ``Dynamic'' emphasizes the necessity of
jointly modeling temporal radiance variations alongside sophisticated 3D
translation between LDR and HDR. To tackle this complex, intertwined challenge,
we introduce HDR-4DGS, a Gaussian Splatting-based architecture featured with an
innovative dynamic tone-mapping module that explicitly connects HDR and LDR
domains, maintaining temporal radiance coherence by dynamically adapting
tone-mapping functions according to the evolving radiance distributions across
the temporal dimension. As a result, HDR-4DGS achieves both temporal radiance
consistency and spatially accurate color translation, enabling photorealistic
HDR renderings from arbitrary viewpoints and time instances. Extensive
experiments demonstrate that HDR-4DGS surpasses existing state-of-the-art
methods in both quantitative performance and visual fidelity. Source code will
be released.

</details>


### [2] [Joint graph entropy knowledge distillation for point cloud classification and robustness against corruptions](https://arxiv.org/abs/2509.22150)
*Zhiqiang Tian,Weigang Li,Junwei Hu,Chunhua Deng*

Main category: cs.CV

TL;DR: 提出JGEKD方法，通过联合图熵知识蒸馏处理非独立同分布的3D点云分类问题，捕获类别间相关性并提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统3D点云分类假设类别独立同分布，这破坏了类别间的相关性。现实中的点云数据往往是非独立同分布的，需要考虑类别间的关联性。

Method: 使用联合图捕获类别间隐藏关系，基于联合图熵构建损失函数进行知识蒸馏。构建孪生结构处理空间变换不变性，开发自知识蒸馏和教师知识蒸馏两种框架。

Result: 在ScanObject、ModelNet40、ScanntV2_cls和ModelNet-C等数据集上的广泛实验表明，该方法能取得有竞争力的结果。

Conclusion: JGEKD策略通过联合图熵知识蒸馏有效处理非独立同分布的3D点云分类问题，实现了类别相关性的知识转移，并提升了模型对数据损坏的鲁棒性。

Abstract: Classification tasks in 3D point clouds often assume that class events
\replaced{are }{follow }independent and identically distributed (IID), although
this assumption destroys the correlation between classes. This \replaced{study
}{paper }proposes a classification strategy, \textbf{J}oint \textbf{G}raph
\textbf{E}ntropy \textbf{K}nowledge \textbf{D}istillation (JGEKD), suitable for
non-independent and identically distributed 3D point cloud data,
\replaced{which }{the strategy } achieves knowledge transfer of class
correlations through knowledge distillation by constructing a loss function
based on joint graph entropy. First\deleted{ly}, we employ joint graphs to
capture add{the }hidden relationships between classes\replaced{ and}{,}
implement knowledge distillation to train our model by calculating the entropy
of add{add }graph.\replaced{ Subsequently}{ Then}, to handle 3D point clouds
\deleted{that is }invariant to spatial transformations, we construct
\replaced{S}{s}iamese structures and develop two frameworks, self-knowledge
distillation and teacher-knowledge distillation, to facilitate information
transfer between different transformation forms of the same data. \replaced{In
addition}{ Additionally}, we use the above framework to achieve knowledge
transfer between point clouds and their corrupted forms, and increase the
robustness against corruption of model. Extensive experiments on ScanObject,
ModelNet40, ScanntV2\_cls and ModelNet-C demonstrate that the proposed strategy
can achieve competitive results.

</details>


### [3] [Polysemous Language Gaussian Splatting via Matching-based Mask Lifting](https://arxiv.org/abs/2509.22225)
*Jiayu Ding,Xinpeng Liu,Zhiyi Pan,Shiqiang Long,Ge Li*

Main category: cs.CV

TL;DR: MUSplat是一个无需训练的开源框架，通过将2D多粒度掩码提升到3D高斯泼溅场景，实现开放词汇的3D语义理解，解决了现有方法依赖逐场景训练、单语义表示和跨视图语义不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个关键缺陷：(i)依赖昂贵的逐场景重新训练，无法即插即用；(ii)限制性的单语义设计无法表示复杂的多概念语义；(iii)易受跨视图语义不一致影响，破坏最终语义表示。

Method: 利用预训练的2D分割模型生成多粒度2D掩码并提升到3D，估计每个高斯点的前景概率形成初始对象组，通过语义熵和几何不透明度优化模糊边界，使用视觉语言模型从最具代表性的视角解释对象外观，提取鲁棒的文本特征。

Result: MUSplat将场景适应时间从数小时减少到几分钟，在开放词汇3D对象选择和语义分割基准任务中优于已建立的基于训练的框架，同时解决了它们的单语义限制。

Conclusion: 通过完全放弃特征优化，MUSplat提供了一个训练免费的解决方案，能够处理复杂的多概念语义，并在开放词汇查询中实现鲁棒的语义匹配。

Abstract: Lifting 2D open-vocabulary understanding into 3D Gaussian Splatting (3DGS)
scenes is a critical challenge. However, mainstream methods suffer from three
key flaws: (i) their reliance on costly per-scene retraining prevents
plug-and-play application; (ii) their restrictive monosemous design fails to
represent complex, multi-concept semantics; and (iii) their vulnerability to
cross-view semantic inconsistencies corrupts the final semantic representation.
To overcome these limitations, we introduce MUSplat, a training-free framework
that abandons feature optimization entirely. Leveraging a pre-trained 2D
segmentation model, our pipeline generates and lifts multi-granularity 2D masks
into 3D, where we estimate a foreground probability for each Gaussian point to
form initial object groups. We then optimize the ambiguous boundaries of these
initial groups using semantic entropy and geometric opacity. Subsequently, by
interpreting the object's appearance across its most representative viewpoints,
a Vision-Language Model (VLM) distills robust textual features that reconciles
visual inconsistencies, enabling open-vocabulary querying via semantic
matching. By eliminating the costly per-scene training process, MUSplat reduces
scene adaptation time from hours to mere minutes. On benchmark tasks for
open-vocabulary 3D object selection and semantic segmentation, MUSplat
outperforms established training-based frameworks while simultaneously
addressing their monosemous limitations.

</details>


### [4] [Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph Learning](https://arxiv.org/abs/2509.22331)
*Xiao Wang,Shujuan Wu,Xiaoxia Cheng,Changwei Bi,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: 提出了一种基于多模态知识图谱的行人属性识别方法，通过构建视觉特征与文本属性之间的关系图谱，提升属性识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有行人属性识别方法未能充分利用属性知识和上下文信息，虽然近期工作开始使用属性文本作为额外输入，但这些方法仍处于初级阶段。

Method: 构建多模态知识图谱，挖掘局部视觉特征与文本之间的关系，以及属性与广泛视觉上下文样本之间的关系。提出知识图谱引导的跨模态超图学习框架。

Result: 在多个PAR基准数据集上的综合实验充分证明了所提知识图谱对PAR任务的有效性。

Conclusion: 为知识引导的行人属性识别建立了坚实基础，提出的多模态知识图谱方法能够有效提升属性识别性能。

Abstract: Current Pedestrian Attribute Recognition (PAR) algorithms typically focus on
mapping visual features to semantic labels or attempt to enhance learning by
fusing visual and attribute information. However, these methods fail to fully
exploit attribute knowledge and contextual information for more accurate
recognition. Although recent works have started to consider using attribute
text as additional input to enhance the association between visual and semantic
information, these methods are still in their infancy. To address the above
challenges, this paper proposes the construction of a multi-modal knowledge
graph, which is utilized to mine the relationships between local visual
features and text, as well as the relationships between attributes and
extensive visual context samples. Specifically, we propose an effective
multi-modal knowledge graph construction method that fully considers the
relationships among attributes and the relationships between attributes and
vision tokens. To effectively model these relationships, this paper introduces
a knowledge graph-guided cross-modal hypergraph learning framework to enhance
the standard pedestrian attribute recognition framework. Comprehensive
experiments on multiple PAR benchmark datasets have thoroughly demonstrated the
effectiveness of our proposed knowledge graph for the PAR task, establishing a
strong foundation for knowledge-guided pedestrian attribute recognition. The
source code of this paper will be released on
https://github.com/Event-AHU/OpenPAR

</details>


### [5] [PSTTS: A Plug-and-Play Token Selector for Efficient Event-based Spatio-temporal Representation Learning](https://arxiv.org/abs/2509.22481)
*Xiangmo Zhao,Nan Yang,Yang Wang,Zhanwen Liu*

Main category: cs.CV

TL;DR: 提出PSTTS模块，利用事件数据的时空分布特性识别和丢弃冗余token，在保持精度的同时显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 现有事件表示学习方法将事件流转换为事件帧序列，但忽略了事件帧序列的高空间稀疏性和帧间运动冗余，导致计算开销大。现有的RGB视频token稀疏化方法依赖不可靠的中间token表示且忽略事件噪声影响

Method: PSTTS包含两个阶段：空间token净化（通过评估事件帧内事件的时空一致性来丢弃噪声和非事件区域）和时间token选择（评估相邻事件帧间运动模式相似性来识别和移除冗余时间信息）

Result: 在HARDVS、DailyDVS-200和SeACT数据集上测试，PSTTS显著提升效率：在DailyDVS-200数据集上减少FLOPs 29-43.6%，提升FPS 21.6-41.3%，同时保持任务精度

Conclusion: PSTTS是一个无需额外参数的即插即用模块，能够有效识别事件数据中的时空冗余token，实现精度和效率的最佳平衡

Abstract: Mainstream event-based spatio-temporal representation learning methods
typically process event streams by converting them into sequences of event
frames, achieving remarkable performance. However, they neglect the high
spatial sparsity and inter-frame motion redundancy inherent in event frame
sequences, leading to significant computational overhead. Existing token
sparsification methods for RGB videos rely on unreliable intermediate token
representations and neglect the influence of event noise, making them
ineffective for direct application to event data. In this paper, we propose
Progressive Spatio-Temporal Token Selection (PSTTS), a Plug-and-Play module for
event data without introducing any additional parameters. PSTTS exploits the
spatio-temporal distribution characteristics embedded in raw event data to
effectively identify and discard spatio-temporal redundant tokens, achieving an
optimal trade-off between accuracy and efficiency. Specifically, PSTTS consists
of two stages, Spatial Token Purification and Temporal Token Selection. Spatial
Token Purification discards noise and non-event regions by assessing the
spatio-temporal consistency of events within each event frame to prevent
interference with subsequent temporal redundancy evaluation. Temporal Token
Selection evaluates the motion pattern similarity between adjacent event
frames, precisely identifying and removing redundant temporal information. We
apply PSTTS to four representative backbones UniformerV2, VideoSwin, EVMamba,
and ExACT on the HARDVS, DailyDVS-200, and SeACT datasets. Experimental results
demonstrate that PSTTS achieves significant efficiency improvements.
Specifically, PSTTS reduces FLOPs by 29-43.6% and increases FPS by 21.6-41.3%
on the DailyDVS-200 dataset, while maintaining task accuracy. Our code will be
available.

</details>


### [6] [HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection](https://arxiv.org/abs/2509.22544)
*Mohammad Mahdi Hemmatyar,Mahdi Jafari,Mohammad Amin Yousefi,Mohammad Reza Nemati,Mobin Azadani,Hamid Reza Rastad,Amirmohammad Akbari*

Main category: cs.CV

TL;DR: HyCoVAD是一个混合SSL-LLM模型，结合自监督学习和大型语言模型来检测复杂视频异常，在ComplexVAD数据集上达到72.5%的帧级AUC，比现有基线提升12.5%


<details>
  <summary>Details</summary>
Motivation: 传统自监督学习方法难以理解复杂异常中的语义交互关系，而大型语言模型虽然具备强大的上下文推理能力，但计算成本高且缺乏细粒度空间定位

Method: 使用基于nnFormer的多任务SSL时序分析器识别可疑异常帧，然后通过LLM验证器应用结构化、基于规则的推理来验证异常存在

Result: 在ComplexVAD数据集上达到72.5%的帧级AUC，比现有基线提升12.5%，同时减少了LLM计算量

Conclusion: HyCoVAD成功结合了SSL和LLM的优势，为复杂视频异常检测提供了有效解决方案，并发布了交互异常分类法、自适应阈值协议和代码

Abstract: Video anomaly detection (VAD) is crucial for intelligent surveillance, but a
significant challenge lies in identifying complex anomalies, which are events
defined by intricate relationships and temporal dependencies among multiple
entities rather than by isolated actions. While self-supervised learning (SSL)
methods effectively model low-level spatiotemporal patterns, they often
struggle to grasp the semantic meaning of these interactions. Conversely, large
language models (LLMs) offer powerful contextual reasoning but are
computationally expensive for frame-by-frame analysis and lack fine-grained
spatial localization. We introduce HyCoVAD, Hybrid Complex Video Anomaly
Detection, a hybrid SSL-LLM model that combines a multi-task SSL temporal
analyzer with LLM validator. The SSL module is built upon an nnFormer backbone
which is a transformer-based model for image segmentation. It is trained with
multiple proxy tasks, learns from video frames to identify those suspected of
anomaly. The selected frames are then forwarded to the LLM, which enriches the
analysis with semantic context by applying structured, rule-based reasoning to
validate the presence of anomalies. Experiments on the challenging ComplexVAD
dataset show that HyCoVAD achieves a 72.5% frame-level AUC, outperforming
existing baselines by 12.5% while reducing LLM computation. We release our
interaction anomaly taxonomy, adaptive thresholding protocol, and code to
facilitate future research in complex VAD scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail](https://arxiv.org/abs/2509.21322)
*Anna Kalenkova,Lu Xia,Dirk Neumann*

Main category: cs.LG

TL;DR: 提出了一种结合对象中心流程挖掘与随机过程发现的新方法，用于分析食品零售流程以减少食物浪费。


<details>
  <summary>Details</summary>
Motivation: 解决食品零售中的食物浪费问题，通过优化供应策略与顾客购买行为之间的平衡来防止过度供应导致的浪费和产品短缺。

Method: 首先从杂货店销售数据中发现连续时间马尔可夫链形式的随机过程模型，然后扩展供应活动，最后进行假设分析评估产品数量随时间的变化。

Result: 能够识别顾客购买行为与供应策略之间的最优平衡点，有效防止因过度供应导致的食物浪费和产品短缺。

Conclusion: 该方法为食品零售流程分析提供了有效工具，有助于减少食物浪费并优化库存管理。

Abstract: This paper proposes a novel method for analyzing food retail processes with a
focus on reducing food waste. The approach integrates object-centric process
mining (OCPM) with stochastic process discovery and analysis. First, a
stochastic process in the form of a continuous-time Markov chain is discovered
from grocery store sales data. This model is then extended with supply
activities. Finally, a what-if analysis is conducted to evaluate how the
quantity of products in the store evolves over time. This enables the
identification of an optimal balance between customer purchasing behavior and
supply strategies, helping to prevent both food waste due to oversupply and
product shortages.

</details>


### [8] [Wav2Arrest 2.0: Long-Horizon Cardiac Arrest Prediction with Time-to-Event Modeling, Identity-Invariance, and Pseudo-Lab Alignment](https://arxiv.org/abs/2509.21695)
*Saurabh Kataria,Davood Fattahi,Minxiao Wang,Ran Xiao,Matthew Clark,Timothy Ruchti,Mark Mai,Xiao Hu*

Main category: cs.LG

TL;DR: 本文提出了三种正交改进方法来提升仅使用PPG信号的心脏骤停预测系统：时间到事件建模、患者身份不变性特征学习、以及基于预训练辅助网络的伪标签回归。这些方法可将24小时时间平均AUC从0.74提升至0.78-0.80范围。


<details>
  <summary>Details</summary>
Motivation: 现有的生理基础模型如PPG-GPT虽然能够预测心脏骤停等关键事件，但其强大表示能力在下游数据/标签稀缺时未能充分利用。需要开发在最小辅助信息下改进PPG-only心脏骤停系统的方法。

Method: 1. 时间到事件建模：通过简单回归到事件发生时间或精细离散生存建模
2. 患者身份不变性特征学习：训练大规模去识别生物特征识别模型(p-vector)，并对其使用对抗性训练来消除可能导致过拟合的患者身份线索
3. 伪标签回归：使用预训练辅助网络进行零样本预测，生成伪连续估计作为目标，丰富心脏骤停波形标签

Result: 提出的方法可将24小时时间平均AUC从0.74独立提升至0.78-0.80范围。主要改进体现在较长的时间范围内，在事件附近仅有最小程度的性能下降，从而推动了早期预警系统的研究。

Conclusion: 通过时间到事件建模、患者身份不变性学习和伪标签回归这三种正交方法，显著提升了仅使用PPG信号的心脏骤停预测性能。同时使用PCGrad优化技术缓解了多任务学习中竞争损失间的高梯度冲突问题。

Abstract: High-frequency physiological waveform modality offers deep, real-time
insights into patient status. Recently, physiological foundation models based
on Photoplethysmography (PPG), such as PPG-GPT, have been shown to predict
critical events, including Cardiac Arrest (CA). However, their powerful
representation still needs to be leveraged suitably, especially when the
downstream data/label is scarce. We offer three orthogonal improvements to
improve PPG-only CA systems by using minimal auxiliary information. First, we
propose to use time-to-event modeling, either through simple regression to the
event onset time or by pursuing fine-grained discrete survival modeling.
Second, we encourage the model to learn CA-focused features by making them
patient-identity invariant. This is achieved by first training the
largest-scale de-identified biometric identification model, referred to as the
p-vector, and subsequently using it adversarially to deconfound cues, such as
person identity, that may cause overfitting through memorization. Third, we
propose regression on the pseudo-lab values generated by pre-trained auxiliary
estimator networks. This is crucial since true blood lab measurements, such as
lactate, sodium, troponin, and potassium, are collected sparingly. Via
zero-shot prediction, the auxiliary networks can enrich cardiac arrest waveform
labels and generate pseudo-continuous estimates as targets. Our proposals can
independently improve the 24-hour time-averaged AUC from the 0.74 to the
0.78-0.80 range. We primarily improve over longer time horizons with minimal
degradation near the event, thus pushing the Early Warning System research.
Finally, we pursue multi-task formulation and diagnose it with a high gradient
conflict rate among competing losses, which we alleviate via the PCGrad
optimization technique.

</details>


### [9] [Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization](https://arxiv.org/abs/2509.22115)
*Chao Wang,Tao Yang,Hongtao Tian,Yunsheng Shi,Qiyao Ma,Xiaotao Liu,Ting Yao,Wenbo Ding*

Main category: cs.LG

TL;DR: 提出了D³S框架，通过动态双级下采样策略优化无评论者RL方法的效率，在样本级选择优势方差最大的rollouts，在token级选择优势幅度与策略熵乘积高的tokens，显著提升收敛速度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决无评论者方法如GRPO因使用大量无信息样本和token导致收敛缓慢的问题，通过优先选择信息量最大的样本和token来提高策略优化的效率。

Method: D³S框架包含两个层级：样本级选择优势方差最大的rollouts子集，token级选择优势幅度与策略熵乘积高的tokens。采用动态下采样调度，从激进下采样逐步过渡到宽松采样。

Result: 在Qwen2.5和Llama3.1上的实验表明，D³S集成到先进RL算法中实现了最先进的性能和泛化能力，同时需要更少的样本和tokens。

Conclusion: D³S框架通过动态双级下采样有效提升了无评论者RL方法的效率和性能，在多个推理基准测试中表现出色。

Abstract: Critic-free methods like GRPO reduce memory demands by estimating advantages
from multiple rollouts but tend to converge slowly, as critical learning
signals are diluted by an abundance of uninformative samples and tokens. To
tackle this challenge, we propose the \textbf{Dynamic Dual-Level Down-Sampling
(D$^3$S)} framework that prioritizes the most informative samples and tokens
across groups to improve the efficient of policy optimization. D$^3$S operates
along two levels: (1) the sample-level, which selects a subset of rollouts to
maximize advantage variance ($\text{Var}(A)$). We theoretically proven that
this selection is positively correlated with the upper bound of the policy
gradient norms, yielding higher policy gradients. (2) the token-level, which
prioritizes tokens with a high product of advantage magnitude and policy
entropy ($|A_{i,t}|\times H_{i,t}$), focusing updates on tokens where the
policy is both uncertain and impactful. Moreover, to prevent overfitting to
high-signal data, D$^3$S employs a dynamic down-sampling schedule inspired by
curriculum learning. This schedule starts with aggressive down-sampling to
accelerate early learning and gradually relaxes to promote robust
generalization. Extensive experiments on Qwen2.5 and Llama3.1 demonstrate that
integrating D$^3$S into advanced RL algorithms achieves state-of-the-art
performance and generalization while requiring \textit{fewer} samples and
tokens across diverse reasoning benchmarks. Our code is added in the
supplementary materials and will be made publicly available.

</details>


### [10] [Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization](https://arxiv.org/abs/2509.22161)
*Takashi Morita*

Main category: cs.LG

TL;DR: 提出一种新的向量量化平滑正则化方法，通过最小化每个码本向量与其K个最近邻平滑量化器之间的距离，同时实现紧致近似和码本利用。


<details>
  <summary>Details</summary>
Motivation: 向量量化在现代机器学习中广泛应用，但非可微的量化步骤阻碍了梯度反向传播。现有平滑方法通常分别处理紧致近似和码本利用两个需求。

Method: 引入简单直观的正则化方法，通过最小化每个码本向量与其K个最近邻平滑量化器之间的距离，同时促进紧致近似和码本利用。

Result: 在离散图像自编码和对比语音表示学习等基准测试中，该方法实现了更可靠的码本利用，性能优于现有方法。

Conclusion: 提出的正则化方法能同时满足向量量化平滑的两个关键需求，在多个任务中表现出优越性能。

Abstract: Vector quantization, which discretizes a continuous vector space into a
finite set of representative vectors (a codebook), has been widely adopted in
modern machine learning. Despite its effectiveness, vector quantization poses a
fundamental challenge: the non-differentiable quantization step blocks gradient
backpropagation. Smoothed vector quantization addresses this issue by relaxing
the hard assignment of a codebook vector into a weighted combination of
codebook entries, represented as the matrix product of a simplex vector and the
codebook. Effective smoothing requires two properties: (1) smoothed quantizers
should remain close to a onehot vector, ensuring tight approximation, and (2)
all codebook entries should be utilized, preventing code collapse. Existing
methods typically address these desiderata separately. By contrast, the present
study introduces a simple and intuitive regularization that promotes both
simultaneously by minimizing the distance between each simplex vertex and its
$K$-nearest smoothed quantizers. Experiments on representative benchmarks,
including discrete image autoencoding and contrastive speech representation
learning, demonstrate that the proposed method achieves more reliable codebook
utilization and improves performance compared to prior approaches.

</details>


### [11] [ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity](https://arxiv.org/abs/2509.22246)
*Xiaoyang Liu,Tao Zhu,Zineng Dong,Yuntian Liu,Qingfeng Guo,Zhaoxuan Liu,Yu Chen,Tao Luo*

Main category: cs.LG

TL;DR: 提出了ASSESS框架，通过TransTED相似度度量结合语义和结构信息来评估形式化语句相似度，并在EPLA基准测试中取得最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有形式化语句相似度度量方法无法平衡语义和结构信息，字符串方法忽略语义，证明方法缺乏分级相似度评分。

Method: 将形式化语句转换为操作符树捕获语法结构，使用TransTED相似度度量（增强的树编辑距离，包含语义转换）计算相似度。

Result: 在EPLA基准测试中，TransTED相似度优于现有方法，达到最先进的准确率和最高的Kappa系数。

Conclusion: ASSESS框架有效整合语义和结构信息，为形式化语句相似度评估提供了连续评分，解决了现有方法的局限性。

Abstract: Statement autoformalization, the automated translation of statements from
natural language into formal languages, has seen significant advancements, yet
the development of automated evaluation metrics remains limited. Existing
metrics for formal statement similarity often fail to balance semantic and
structural information. String-based approaches capture syntactic structure but
ignore semantic meaning, whereas proof-based methods validate semantic
equivalence but disregard structural nuances and, critically, provide no graded
similarity score in the event of proof failure. To address these issues, we
introduce ASSESS (A Semantic and Structural Evaluation Framework for Statement
Similarity), which comprehensively integrates semantic and structural
information to provide a continuous similarity score. Our framework first
transforms formal statements into Operator Trees to capture their syntactic
structure and then computes a similarity score using our novel TransTED
(Transformation Tree Edit Distance) Similarity metric, which enhances
traditional Tree Edit Distance by incorporating semantic awareness through
transformations. For rigorous validation, we present EPLA (Evaluating
Provability and Likeness for Autoformalization), a new benchmark of 524
expert-annotated formal statement pairs derived from miniF2F and ProofNet, with
labels for both semantic provability and structural likeness. Experiments on
EPLA demonstrate that TransTED Similarity outperforms existing methods,
achieving state-of-the-art accuracy and the highest Kappa coefficient. The
benchmark, and implementation code will be made public soon.

</details>


### [12] [Erase or Hide? Suppressing Spurious Unlearning Neurons for Robust Unlearning](https://arxiv.org/abs/2509.22263)
*Nakyeong Yang,Dong-Kyum Kim,Jea Kwon,Minsung Kim,Kyomin Jung,Meeyoung Cha*

Main category: cs.LG

TL;DR: 本文提出Ssiuu方法，通过归因引导的正则化防止虚假负影响，实现忠实的目标知识遗忘，解决了现有遗忘方法存在的浅层对齐和重新学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型遗忘方法存在"浅层对齐"问题，仅通过产生虚假遗忘神经元来隐藏目标知识而非真正删除，导致在后续训练中容易重新学习被遗忘的知识，存在隐私风险。

Method: 引入Ssiuu遗忘方法，采用归因引导的正则化技术，防止产生虚假的负影响，确保目标知识被忠实移除。

Result: 实验结果表明，该方法能可靠地擦除目标知识，在两种实际重训练场景（敌对数据注入和良性攻击）中均优于强基线方法。

Conclusion: 研究强调了开发鲁棒且忠实的遗忘方法对于语言模型安全部署的必要性。

Abstract: Large language models trained on web-scale data can memorize private or
sensitive knowledge, raising significant privacy risks. Although some
unlearning methods mitigate these risks, they remain vulnerable to "relearning"
during subsequent training, allowing a substantial portion of forgotten
knowledge to resurface. In this paper, we show that widely used unlearning
methods cause shallow alignment: instead of faithfully erasing target
knowledge, they generate spurious unlearning neurons that amplify negative
influence to hide it. To overcome this limitation, we introduce Ssiuu, a new
class of unlearning methods that employs attribution-guided regularization to
prevent spurious negative influence and faithfully remove target knowledge.
Experimental results confirm that our method reliably erases target knowledge
and outperforms strong baselines across two practical retraining scenarios: (1)
adversarial injection of private data, and (2) benign attack using an
instruction-following benchmark. Our findings highlight the necessity of robust
and faithful unlearning methods for safe deployment of language models.

</details>


### [13] [Towards a more realistic evaluation of machine learning models for bearing fault diagnosis](https://arxiv.org/abs/2509.22267)
*João Paulo Vieira,Victor Afonso Bauler,Rodrigo Kobashikawa Rosa,Danilo Silva*

Main category: cs.LG

TL;DR: 该论文研究了轴承故障诊断中的数据泄露问题，提出了一种基于轴承划分的无泄漏评估方法，并重新定义了多标签分类任务，以提升模型在工业应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的轴承故障诊断方法在受控环境下表现良好，但由于数据泄露等方​​法论缺陷，难以泛化到实际工业应用。论文旨在解决这一关键问题。

Method: 提出基于轴承划分的数据分割策略，确保训练和测试集使用不同的物理轴承组件；将分类任务重新定义为多标签问题；使用Macro AUROC等与流行度无关的指标进行评估。

Result: 在CWRU、Paderborn University和University of Ottawa三个数据集上的评估表明，轴承划分策略能有效防止数据泄露，训练轴承数量对模型泛化性能有决定性影响。

Conclusion: 研究强调了泄漏感知评估协议的重要性，为数据集划分、模型选择和验证提供了实用指南，有助于开发更可靠的工业故障诊断ML系统。

Abstract: Reliable detection of bearing faults is essential for maintaining the safety
and operational efficiency of rotating machinery. While recent advances in
machine learning (ML), particularly deep learning, have shown strong
performance in controlled settings, many studies fail to generalize to
real-world applications due to methodological flaws, most notably data leakage.
This paper investigates the issue of data leakage in vibration-based bearing
fault diagnosis and its impact on model evaluation. We demonstrate that common
dataset partitioning strategies, such as segment-wise and condition-wise
splits, introduce spurious correlations that inflate performance metrics. To
address this, we propose a rigorous, leakage-free evaluation methodology
centered on bearing-wise data partitioning, ensuring no overlap between the
physical components used for training and testing. Additionally, we reformulate
the classification task as a multi-label problem, enabling the detection of
co-occurring fault types and the use of prevalence-independent metrics such as
Macro AUROC. Beyond preventing leakage, we also examine the effect of dataset
diversity on generalization, showing that the number of unique training
bearings is a decisive factor for achieving robust performance. We evaluate our
methodology on three widely adopted datasets: CWRU, Paderborn University (PU),
and University of Ottawa (UORED-VAFCLS). This study highlights the importance
of leakage-aware evaluation protocols and provides practical guidelines for
dataset partitioning, model selection, and validation, fostering the
development of more trustworthy ML systems for industrial fault diagnosis
applications.

</details>


### [14] [EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning](https://arxiv.org/abs/2509.22576)
*Xu Wujiang,Wentian Zhao,Zhenting Wang,Li Yu-Jhe,Jin Can,Jin Mingyu,Mei Kai,Wan Kun,Metaxas Dimitris*

Main category: cs.LG

TL;DR: 提出了EPO框架来解决多轮稀疏奖励环境中LLM智能体的探索-利用级联失败问题，通过熵正则化、熵平滑和自适应权重机制，在ScienceWorld和ALFWorld上分别实现了152%和19.8%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 多轮稀疏奖励环境中，智能体面临探索-利用级联失败：早期策略过早收敛到低熵策略，后期熵正则化反而导致策略崩溃和训练不稳定。

Method: EPO框架包含三个机制：(1)多轮环境中的熵正则化增强探索；(2)熵平滑正则化器限制策略熵在历史平均值范围内；(3)自适应阶段权重平衡训练过程中的探索与利用。

Result: EPO在ScienceWorld上实现最高152%性能提升，在ALFWorld上实现19.8%性能提升，证明能有效解决多轮稀疏奖励环境中的训练问题。

Conclusion: 多轮稀疏奖励环境需要与传统RL不同的熵控制方法，EPO框架通过系统性的熵管理机制成功解决了探索-利用级联失败问题。

Abstract: Training LLM agents in multi-turn environments with sparse rewards, where
completing a single task requires 30+ turns of interaction within an episode,
presents a fundamental challenge for reinforcement learning. We identify a
critical failure mode unique to this setting: the exploration-exploitation
cascade failure. This cascade begins with early-stage policy premature
convergence, where sparse feedback causes agents to commit to flawed,
low-entropy strategies. Subsequently, agents enter late-stage policy collapse,
where conventional entropy regularization becomes counterproductive, promoting
chaotic exploration that destabilizes training. We propose Entropy-regularized
Policy Optimization (EPO), a general framework that breaks this failure cycle
through three synergistic mechanisms: (1) adopting entropy regularization in
multi-turn settings to enhance exploration, (2) an entropy smoothing
regularizer that bounds policy entropy within historical averages to prevent
abrupt fluctuations, and (3) adaptive phase-based weighting that balances
exploration and exploitation across training. Our analysis justifies that EPO
guarantees monotonically decreasing entropy variance while maintaining
convergence. EPO achieves up to 152% performance improvement on ScienceWorld
and up to 19.8% on ALFWorld. Our work demonstrates that multi-turn
sparse-reward settings require fundamentally different entropy control than
traditional RL, with broad implications for LLM agent training.

</details>


### [15] [SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis](https://arxiv.org/abs/2509.22352)
*Marie Brockschmidt,Maresa Schröder,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: SurvDiff是一个专门为生存分析设计的端到端扩散模型，能够联合生成混合类型协变量、事件时间和右删失数据，通过生存导向的损失函数确保生成数据的分布保真度和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 生存分析数据常因失访等原因存在不完整的事件信息，这给合成数据生成带来独特挑战。需要同时忠实重现事件时间分布和删失机制，以支持临床研究。

Method: 提出SurvDiff扩散模型，使用生存导向的损失函数联合生成混合类型协变量、事件时间和右删失数据，直接优化下游生存任务性能。

Result: 在多个数据集上，SurvDiff在分布保真度和下游评估指标上持续优于最先进的生成基线模型。

Conclusion: SurvDiff是首个专门为生成生存分析合成数据设计的扩散模型，能够有效重现事件时间分布并保持删失机制。

Abstract: Survival analysis is a cornerstone of clinical research by modeling
time-to-event outcomes such as metastasis, disease relapse, or patient death.
Unlike standard tabular data, survival data often come with incomplete event
information due to dropout, or loss to follow-up. This poses unique challenges
for synthetic data generation, where it is crucial for clinical research to
faithfully reproduce both the event-time distribution and the censoring
mechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model
specifically designed for generating synthetic data in survival analysis.
SurvDiff is tailored to capture the data-generating mechanism by jointly
generating mixed-type covariates, event times, and right-censoring, guided by a
survival-tailored loss function. The loss encodes the time-to-event structure
and directly optimizes for downstream survival tasks, which ensures that
SurvDiff (i) reproduces realistic event-time distributions and (ii) preserves
the censoring mechanism. Across multiple datasets, we show that \survdiff
consistently outperforms state-of-the-art generative baselines in both
distributional fidelity and downstream evaluation metrics across multiple
medical datasets. To the best of our knowledge, SurvDiff is the first diffusion
model explicitly designed for generating synthetic survival data.

</details>


### [16] [Stochastic activations](https://arxiv.org/abs/2509.22358)
*Maria Lomeli,Matthijs Douze,Gergely Szilvasy,Loic Cabannes,Jade Copet,Sainbayar Sukhbaatar,Jason Weston,Gabriel Synnaeve,Pierre-Emmanuel Mazaré,Hervé Jégou*

Main category: cs.LG

TL;DR: 提出随机激活策略，在LLM前馈层中随机选择SILU或RELU激活函数，解决了RELU的梯度流问题，可用于预训练和生成任务。


<details>
  <summary>Details</summary>
Motivation: 解决RELU激活函数在负输入区域梯度为零的问题，同时利用RELU的稀疏性优势来减少推理计算量。

Method: 在预训练阶段使用伯努利分布随机选择SILU或RELU激活函数，推理时固定使用RELU以获得稀疏性和计算效率。

Result: 相比从头训练RELU模型，该方法在推理时显著减少FLOPs并加速CPU推理；在生成任务中表现接近最佳确定性非线性函数。

Conclusion: 随机激活策略有效解决了RELU的优化问题，同时提供了控制生成多样性的新方法，在效率和性能间取得良好平衡。

Abstract: We introduce stochastic activations. This novel strategy randomly selects
between several non-linear functions in the feed-forward layer of a large
language model. In particular, we choose between SILU or RELU depending on a
Bernoulli draw. This strategy circumvents the optimization problem associated
with RELU, namely, the constant shape for negative inputs that prevents the
gradient flow. We leverage this strategy in two ways:
  (1) We use stochastic activations during pre-training and fine-tune the model
with RELU, which is used at inference time to provide sparse latent vectors.
This reduces the inference FLOPs and translates into a significant speedup in
the CPU. Interestingly, this leads to much better results than training from
scratch with the RELU activation function.
  (2) We evaluate stochastic activations for generation. This strategy performs
reasonably well: it is only slightly inferior to the best deterministic
non-linearity, namely SILU combined with temperature scaling. This offers an
alternative to existing strategies by providing a controlled way to increase
the diversity of the generated text.

</details>


### [17] [Enhancing Credit Risk Prediction: A Meta-Learning Framework Integrating Baseline Models, LASSO, and ECOC for Superior Accuracy](https://arxiv.org/abs/2509.22381)
*Haibo Wang,Lutfu S. Sua,Jun Huang,Figen Balo,Burak Dolar*

Main category: cs.LG

TL;DR: 提出一个综合元学习框架，结合多种机器学习方法来解决信用风险评估中的高维数据、可解释性差、罕见事件检测和多类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在信用风险评估中面临高维数据、可解释性差、罕见事件检测和多类别不平衡等挑战，需要更鲁棒和全面的解决方案。

Method: 构建元学习框架，整合监督学习算法（XGBoost、随机森林、SVM、决策树）、无监督方法（KNN）、深度学习架构（多层感知机）、LASSO正则化特征选择，以及纠错输出码作为元分类器处理不平衡多类别问题。

Result: 在包含2,029家美国上市公司信用评级的数据集上验证，该框架显著提高了信用评级迁移（升级和降级）和违约概率估计的准确性。

Conclusion: 该元学习框架为信用风险建模提供了更准确可靠的计算模型，能够更好地支持战略金融决策。

Abstract: Effective credit risk management is fundamental to financial decision-making,
necessitating robust models for default probability prediction and financial
entity classification. Traditional machine learning approaches face significant
challenges when confronted with high-dimensional data, limited
interpretability, rare event detection, and multi-class imbalance problems in
risk assessment. This research proposes a comprehensive meta-learning framework
that synthesizes multiple complementary models: supervised learning algorithms,
including XGBoost, Random Forest, Support Vector Machine, and Decision Tree;
unsupervised methods such as K-Nearest Neighbors; deep learning architectures
like Multilayer Perceptron; alongside LASSO regularization for feature
selection and dimensionality reduction; and Error-Correcting Output Codes as a
meta-classifier for handling imbalanced multi-class problems. We implement
Permutation Feature Importance analysis for each prediction class across all
constituent models to enhance model transparency. Our framework aims to
optimize predictive performance while providing a more holistic approach to
credit risk assessment. This research contributes to the development of more
accurate and reliable computational models for strategic financial decision
support by addressing three fundamental challenges in credit risk modeling. The
empirical validation of our approach involves an analysis of the Corporate
Credit Ratings dataset with credit ratings for 2,029 publicly listed US
companies. Results demonstrate that our meta-learning framework significantly
enhances the accuracy of financial entity classification regarding credit
rating migrations (upgrades and downgrades) and default probability estimation.

</details>


### [18] [JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation](https://arxiv.org/abs/2509.22522)
*Guillem Capellera,Luis Ferraz,Antonio Rubio,Alexandre Alahi,Antonio Agudo*

Main category: cs.LG

TL;DR: JointDiff是一个新颖的扩散框架，统一生成连续时空数据和同步离散事件，在体育领域验证了同时建模多智能体轨迹和关键控球事件的有效性。


<details>
  <summary>Details</summary>
Motivation: 生成模型通常将连续数据和离散事件视为独立过程，这限制了建模复杂系统中两者同步交互的能力。

Method: 提出JointDiff扩散框架，引入CrossGuid条件操作实现多智能体领域的有效条件控制，支持弱控球者引导和文本引导两种可控生成场景。

Result: 在足球和美式足球数据集上实现了最先进的性能，证明了联合建模对于构建真实可控的交互系统生成模型至关重要。

Conclusion: 联合建模连续和离散过程对于构建真实且可控的交互系统生成模型是必要的，JointDiff框架为此提供了有效解决方案。

Abstract: Generative models often treat continuous data and discrete events as separate
processes, creating a gap in modeling complex systems where they interact
synchronously. To bridge this gap, we introduce JointDiff, a novel diffusion
framework designed to unify these two processes by simultaneously generating
continuous spatio-temporal data and synchronous discrete events. We demonstrate
its efficacy in the sports domain by simultaneously modeling multi-agent
trajectories and key possession events. This joint modeling is validated with
non-controllable generation and two novel controllable generation scenarios:
weak-possessor-guidance, which offers flexible semantic control over game
dynamics through a simple list of intended ball possessors, and text-guidance,
which enables fine-grained, language-driven generation. To enable the
conditioning with these guidance signals, we introduce CrossGuid, an effective
conditioning operation for multi-agent domains. We also share a new unified
sports benchmark enhanced with textual descriptions for soccer and football
datasets. JointDiff achieves state-of-the-art performance, demonstrating that
joint modeling is crucial for building realistic and controllable generative
models for interactive systems.

</details>


### [19] [Machine learning approaches to seismic event classification in the Ostrava region](https://arxiv.org/abs/2509.22574)
*Marek Pecha,Michael Skotnica,Jana Rušajová,Bohdan Rieznikov,Vít Wandrol,Markéta Rösnerová,Jaromír Knejzlík*

Main category: cs.LG

TL;DR: 该研究使用机器学习方法区分捷克东北部的地震事件类型（构造地震与采矿诱发地震），在SPF数据集上LSTM和XGBoost模型取得了0.94-0.95的F1分数。


<details>
  <summary>Details</summary>
Motivation: 捷克东北部是地震活跃区，既有采矿诱发地震也有构造地震，尽管采矿活动已停止，但采矿诱发地震仍会发生，因此需要快速区分不同类型的地震事件。

Method: 应用机器学习方法（长短期记忆循环神经网络和XGBoost）对SPF数据集中的构造地震和采矿诱发地震记录进行二元分类。

Result: LSTM和XGBoost模型在二元分类任务中取得了0.94-0.95的F1分数，表明现代机器学习技术在快速事件特征识别方面具有潜力。

Conclusion: 机器学习方法能够有效区分构造地震和采矿诱发地震，为快速事件表征提供了可行的技术方案。

Abstract: The northeastern region of the Czech Republic is among the most seismically
active areas in the country. The most frequent seismic events are
mining-induced since there used to be strong mining activity in the past.
However, natural tectonic events may also occur. In addition, seismic stations
often record explosions in quarries in the region. Despite the cessation of
mining activities, mine-induced seismic events still occur. Therefore, a rapid
differentiation between tectonic and anthropogenic events is still important.
  The region is currently monitored by the OKC seismic station in
Ostrava-Kr\'{a}sn\'{e} Pole built in 1983 which is a part of the Czech Regional
Seismic Network. The station has been providing digital continuous waveform
data at 100 Hz since 2007. In the years 1992--2002, the region was co-monitored
by the Seismic Polygon Fren\v{s}t\'{a}t (SPF) which consisted of five seismic
stations using a triggered STA/LTA system.
  In this study, we apply and compare machine learning methods to the SPF
dataset, which contains labeled records of tectonic and mining-induced events.
For binary classification, a Long Short-Term Memory recurrent neural network
and XGBoost achieved an F1-score of 0.94 -- 0.95, demonstrating the potential
of modern machine learning techniques for rapid event characterization.

</details>


### [20] [Quantile Advantage Estimation for Entropy-Safe Reasoning](https://arxiv.org/abs/2509.22611)
*Junkang Wu,Kexin Huang,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He*

Main category: cs.LG

TL;DR: 提出了Quantile Advantage Estimation (QAE)方法，通过使用分位数基线替代均值基线来解决RLVR训练中的熵崩溃和熵爆炸问题，实现了双面熵安全，在多个基准测试中取得了稳定的性能提升。


<details>
  <summary>Details</summary>
Motivation: 强化学习与可验证奖励(RLVR)虽然能增强LLM推理能力，但训练过程中经常在熵崩溃和熵爆炸之间振荡。研究发现这两种风险都源于无价值RL中使用的均值基线在奖励异常值下对负优势样本的不当惩罚。

Method: 提出分位数优势估计(QAE)，用分组K分位数基线替代均值基线。QAE在困难查询(p <= 1-K)时强化罕见成功，在简单查询(p > 1-K)时针对剩余失败。在一阶softmax更新下证明了两面熵安全性。

Result: 这一最小修改稳定了熵，稀疏化了信用分配(调优K后约80%响应获得零优势)，并在Qwen3-8B/14B-Base模型上对AIME 2024/2025和AMC 2023实现了持续的pass@1增益。

Conclusion: 这些结果表明基线设计——而非token级启发式方法——是扩展RLVR的主要机制。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) strengthens LLM
reasoning, but training often oscillates between {entropy collapse} and
{entropy explosion}. We trace both hazards to the mean baseline used in
value-free RL (e.g., GRPO and DAPO), which improperly penalizes
negative-advantage samples under reward outliers. We propose {Quantile
Advantage Estimation} (QAE), replacing the mean with a group-wise K-quantile
baseline. QAE induces a response-level, two-regime gate: on hard queries (p <=
1 - K) it reinforces rare successes, while on easy queries (p > 1 - K) it
targets remaining failures. Under first-order softmax updates, we prove
{two-sided entropy safety}, giving lower and upper bounds on one-step entropy
change that curb explosion and prevent collapse. Empirically, this minimal
modification stabilizes entropy, sparsifies credit assignment (with tuned K,
roughly 80% of responses receive zero advantage), and yields sustained pass@1
gains on Qwen3-8B/14B-Base across AIME 2024/2025 and AMC 2023. These results
identify {baseline design} -- rather than token-level heuristics -- as the
primary mechanism for scaling RLVR.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [21] [TRACE: Learning to Compute on Graphs](https://arxiv.org/abs/2509.21886)
*Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu*

Main category: cs.AI

TL;DR: TRACE是一种新的图表示学习范式，通过层次化Transformer架构和函数偏移学习目标，解决传统方法在计算图建模中的架构不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递神经网络和Transformer在图计算建模中存在架构不匹配，无法捕捉计算的位置感知和层次化特性。

Method: 使用层次化Transformer模拟逐步计算流程，引入函数偏移学习目标，将复杂全局函数预测分解为预测真实函数与局部近似之间的差异。

Result: 在电子电路等复杂计算图上，TRACE在全面基准测试中显著优于所有现有架构。

Conclusion: 架构对齐的骨干网络和解耦学习目标为图计算学习提供了更鲁棒的范式。

Abstract: Learning to compute, the ability to model the functional behavior of a
computational graph, is a fundamental challenge for graph representation
learning. Yet, the dominant paradigm is architecturally mismatched for this
task. This flawed assumption, central to mainstream message passing neural
networks (MPNNs) and their conventional Transformer-based counterparts,
prevents models from capturing the position-aware, hierarchical nature of
computation. To resolve this, we introduce \textbf{TRACE}, a new paradigm built
on an architecturally sound backbone and a principled learning objective.
First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step
flow of computation, providing a faithful architectural backbone that replaces
the flawed permutation-invariant aggregation. Second, we introduce
\textbf{function shift learning}, a novel objective that decouples the learning
problem. Instead of predicting the complex global function directly, our model
is trained to predict only the \textit{function shift}, the discrepancy between
the true global function and a simple local approximation that assumes input
independence. We validate this paradigm on electronic circuits, one of the most
complex and economically critical classes of computational graphs. Across a
comprehensive suite of benchmarks, TRACE substantially outperforms all prior
architectures. These results demonstrate that our architecturally-aligned
backbone and decoupled learning objective form a more robust paradigm for the
fundamental challenge of learning to compute on graphs.

</details>


### [22] [DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling](https://arxiv.org/abs/2509.21902)
*Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang*

Main category: cs.AI

TL;DR: 提出DyRo-MCTS方法，将动作鲁棒性估计集成到MCTS中，用于动态作业车间调度问题，在保持快速在线规划的同时显著提升离线学习策略的性能。


<details>
  <summary>Details</summary>
Motivation: 动态作业车间调度面临新作业频繁到达的干扰，现有离线学习策略存在不完美性，而在线规划由于问题信息不完整容易受到扰动影响。

Method: DyRo-MCTS方法在MCTS中集成动作鲁棒性估计，引导生产环境走向既能产生良好调度结果又易于适应未来作业到达的状态。

Result: 实验表明DyRo-MCTS显著提升离线学习策略性能，在线规划时间增加可忽略，在各种调度场景下持续优于普通MCTS。

Conclusion: DyRo-MCTS通过做出鲁棒调度决策，在扰动下实现长期可持续的性能提升。

Abstract: Dynamic job shop scheduling, a fundamental combinatorial optimisation problem
in various industrial sectors, poses substantial challenges for effective
scheduling due to frequent disruptions caused by the arrival of new jobs.
State-of-the-art methods employ machine learning to learn scheduling policies
offline, enabling rapid responses to dynamic events. However, these offline
policies are often imperfect, necessitating the use of planning techniques such
as Monte Carlo Tree Search (MCTS) to improve performance at online decision
time. The unpredictability of new job arrivals complicates online planning, as
decisions based on incomplete problem information are vulnerable to
disturbances. To address this issue, we propose the Dynamic Robust MCTS
(DyRo-MCTS) approach, which integrates action robustness estimation into MCTS.
DyRo-MCTS guides the production environment toward states that not only yield
good scheduling outcomes but are also easily adaptable to future job arrivals.
Extensive experiments show that DyRo-MCTS significantly improves the
performance of offline-learned policies with negligible additional online
planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across
various scheduling scenarios. Further analysis reveals that its ability to make
robust scheduling decisions leads to long-term, sustainable performance gains
under disturbances.

</details>


### [23] [Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective](https://arxiv.org/abs/2509.22613)
*Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen*

Main category: cs.AI

TL;DR: 本文通过图抽象分析强化学习对LLM规划能力的影响，发现监督微调会产生伪解，而RL通过探索实现正确规划，但PG存在多样性崩溃问题，Q学习则能保持多样性。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习显著提升了大型语言模型的规划能力，但其有效性缺乏理论基础，需要系统分析RL方法的优势和局限。

Method: 采用基于图的抽象模型，分析策略梯度和Q学习方法，并在Blocksworld基准上进行实际验证。

Result: 监督微调会产生基于共现的伪解；策略梯度存在多样性崩溃问题；Q学习能保持输出多样性但需要精心设计奖励函数防止奖励黑客攻击。

Conclusion: 探索是RL实现更好泛化的关键，Q学习在保持多样性方面优于策略梯度，但需要谨慎的奖励设计。

Abstract: Recent reinforcement learning (RL) methods have substantially enhanced the
planning capabilities of Large Language Models (LLMs), yet the theoretical
basis for their effectiveness remains elusive. In this work, we investigate
RL's benefits and limitations through a tractable graph-based abstraction,
focusing on policy gradient (PG) and Q-learning methods. Our theoretical
analyses reveal that supervised fine-tuning (SFT) may introduce
co-occurrence-based spurious solutions, whereas RL achieves correct planning
primarily through exploration, underscoring exploration's role in enabling
better generalization. However, we also show that PG suffers from diversity
collapse, where output diversity decreases during training and persists even
after perfect accuracy is attained. By contrast, Q-learning provides two key
advantages: off-policy learning and diversity preservation at convergence. We
further demonstrate that careful reward design is necessary to prevent reward
hacking in Q-learning. Finally, applying our framework to the real-world
planning benchmark Blocksworld, we confirm that these behaviors manifest in
practice.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [24] [Debiasing Large Language Models in Thai Political Stance Detection via Counterfactual Calibration](https://arxiv.org/abs/2509.21946)
*Kasidit Sermsri,Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: 提出ThaiFACTUAL框架，通过反事实数据增强和基于理由的监督来减轻泰语政治立场检测中的偏见，无需微调即可提高公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在资源匮乏和文化复杂的泰语政治环境中，大语言模型存在系统性偏见（如情感泄漏和实体偏袒），影响公平性和可靠性。

Method: 使用反事实数据增强和基于理由的监督来解耦情感与立场，并减少偏见。同时发布了首个高质量的泰语政治立场数据集。

Result: 实验表明ThaiFACTUAL显著减少了虚假相关性，增强了零样本泛化能力，并在多个大语言模型中提高了公平性。

Conclusion: 这项工作强调了针对代表性不足语言的文化基础去偏见技术的重要性。

Abstract: Political stance detection in low-resource and culturally complex settings
poses a critical challenge for large language models (LLMs). In the Thai
political landscape - marked by indirect language, polarized figures, and
entangled sentiment and stance - LLMs often display systematic biases such as
sentiment leakage and favoritism toward entities. These biases undermine
fairness and reliability. We present ThaiFACTUAL, a lightweight, model-agnostic
calibration framework that mitigates political bias without requiring
fine-tuning. ThaiFACTUAL uses counterfactual data augmentation and
rationale-based supervision to disentangle sentiment from stance and reduce
bias. We also release the first high-quality Thai political stance dataset,
annotated with stance, sentiment, rationales, and bias markers across diverse
entities and events. Experimental results show that ThaiFACTUAL significantly
reduces spurious correlations, enhances zero-shot generalization, and improves
fairness across multiple LLMs. This work highlights the importance of
culturally grounded debiasing techniques for underrepresented languages.

</details>


### [25] [FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding](https://arxiv.org/abs/2509.22237)
*Haorui Chen,Chengze Li,Jia Li*

Main category: cs.CL

TL;DR: 提出了FeatBench基准测试，专注于评估大语言模型在"氛围编程"范式下的功能实现能力，通过纯自然语言提示和全面测试用例来弥补现有代码生成基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准测试与"氛围编程"范式不匹配，它们要么需要代码级规范，要么只关注问题解决，而忽略了功能实现这一关键场景。

Method: 构建FeatBench基准，具有纯自然语言提示、严格的数据收集流程、全面的测试用例（F2P和P2P测试）以及多样化的应用领域。

Result: 在FeatBench上评估两个最先进的代理框架和四个领先的LLM，最高成功率仅为29.94%，发现存在"激进实现"倾向。

Conclusion: 氛围编程范式下的功能实现是一个重大挑战，FeatBench为社区研究提供了基准测试、自动化收集流程和实验结果。

Abstract: The rapid advancement of Large Language Models (LLMs) has given rise to a
novel software development paradigm known as "vibe coding," where users
interact with coding agents through high-level natural language. However,
existing evaluation benchmarks for code generation inadequately assess an
agent's vibe coding capabilities. Existing benchmarks are misaligned, as they
either require code-level specifications or focus narrowly on issue-solving,
neglecting the critical scenario of feature implementation within the vibe
coding paradiam. To address this gap, we propose FeatBench, a novel benchmark
for vibe coding that focuses on feature implementation. Our benchmark is
distinguished by several key features: 1. Pure Natural Language Prompts. Task
inputs consist solely of abstract natural language descriptions, devoid of any
code or structural hints. 2. A Rigorous & Evolving Data Collection Process.
FeatBench is built on a multi-level filtering pipeline to ensure quality and a
fully automated pipeline to evolve the benchmark, mitigating data
contamination. 3. Comprehensive Test Cases. Each task includes Fail-to-Pass
(F2P) and Pass-to-Pass (P2P) tests to verify correctness and prevent
regressions. 4. Diverse Application Domains. The benchmark includes
repositories from diverse domains to ensure it reflects real-world scenarios.
We evaluate two state-of-the-art agent frameworks with four leading LLMs on
FeatBench. Our evaluation reveals that feature implementation within the vibe
coding paradigm is a significant challenge, with the highest success rate of
only 29.94%. Our analysis also reveals a tendency for "aggressive
implementation," a strategy that paradoxically leads to both critical failures
and superior software design. We release FeatBench, our automated collection
pipeline, and all experimental results to facilitate further community
research.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [26] [Beyond Detection -- Orchestrating Human-Robot-Robot Assistance via an Internet of Robotic Things Paradigm](https://arxiv.org/abs/2509.22296)
*Joseph Hunt,Koyo Fujii,Aly Magassouba,Praminda Caleb-Solly*

Main category: cs.RO

TL;DR: 提出基于物联网机器人技术的主动式患者防跌倒系统，通过热感测预测患者离床意图，协调多个机器人提供个性化协助


<details>
  <summary>Details</summary>
Motivation: 传统跌倒预防系统存在高误报率且无法解决患者离床的根本需求，需要从被动检测转向主动预防

Method: 采用隐私保护的热感测模型实时预测离床意图，结合两个协调的机器人代理根据预测意图和患者输入动态响应

Result: 系统能够准确预测离床行为，通过多机器人协调提供及时有意义的协助，创造更安全、响应更快的护理环境

Conclusion: 交互式连接的机器人系统可以超越被动监测，提供及时有效的协助，为医院环境带来更安全的护理方案

Abstract: Hospital patient falls remain a critical and costly challenge worldwide.
While conventional fall prevention systems typically rely on post-fall
detection or reactive alerts, they also often suffer from high false positive
rates and fail to address the underlying patient needs that lead to bed-exit
attempts. This paper presents a novel system architecture that leverages the
Internet of Robotic Things (IoRT) to orchestrate human-robot-robot interaction
for proactive and personalized patient assistance. The system integrates a
privacy-preserving thermal sensing model capable of real-time bed-exit
prediction, with two coordinated robotic agents that respond dynamically based
on predicted intent and patient input. This orchestrated response could not
only reduce fall risk but also attend to the patient's underlying motivations
for movement, such as thirst, discomfort, or the need for assistance, before a
hazardous situation arises. Our contributions with this pilot study are
three-fold: (1) a modular IoRT-based framework enabling distributed sensing,
prediction, and multi-robot coordination; (2) a demonstration of low-resolution
thermal sensing for accurate, privacy-preserving preemptive bed-exit detection;
and (3) results from a user study and systematic error analysis that inform the
design of situationally aware, multi-agent interactions in hospital settings.
The findings highlight how interactive and connected robotic systems can move
beyond passive monitoring to deliver timely, meaningful assistance, empowering
safer, more responsive care environments.

</details>
