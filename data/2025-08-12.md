<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

TL;DR: 论文提出ContextGuard-LVLM框架，利用视觉-语言大模型和多阶段上下文推理机制，解决数字新闻中视觉与文本信息的细粒度一致性验证问题。


<details>
  <summary>Details</summary>
Motivation: 数字新闻媒体的普及需要验证内容真实性，尤其是视觉与文本信息的深层一致性，传统方法难以满足需求。

Method: 基于视觉-语言大模型（LVLMs），结合多阶段上下文推理机制，并通过强化或对抗学习增强模型能力。

Result: ContextGuard-LVLM在细粒度一致性任务上显著优于现有零样本基线模型，并在复杂逻辑推理和上下文理解上表现优异。

Conclusion: 该框架在检测上下文一致性方面高效且鲁棒，能够识别复杂的情境脱离，并与人类专家判断高度一致。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [2] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

TL;DR: SafePLUG是一种新型多模态大语言模型框架，专注于交通事故的细粒度分析，支持像素级理解和时间定位。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在交通领域主要关注粗粒度理解，难以处理细粒度视觉细节或局部场景，限制了在复杂事故场景中的应用。

Method: 提出SafePLUG框架，支持任意形状视觉提示的区域感知问答、基于语言指令的像素级分割及时间锚定事件识别。

Result: 实验表明，SafePLUG在区域问答、像素分割、时间事件定位和事故理解等任务中表现优异。

Conclusion: SafePLUG为复杂交通场景的细粒度理解奠定基础，有望提升驾驶安全和智能交通系统的情境感知能力。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [3] [EventRR: Event Referential Reasoning for Referring Video Object Segmentation](https://arxiv.org/abs/2508.07171)
*Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: EventRR框架通过解耦视频对象分割为对象摘要和引用推理两部分，利用Referential Event Graph（REG）和Temporal Concept-Role Reasoning（TCRR）提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法忽略表达式的语义结构，而视频引用表达式比图像更复杂，包含事件属性和时序关系，传统方法难以处理。

Method: EventRR分为对象摘要和引用推理两部分：摘要阶段生成瓶颈令牌并聚合全局跨模态时序上下文；推理阶段通过REG和TCRR进行语义推理。

Result: 在四个基准数据集上，EventRR在定量和定性上均优于现有方法。

Conclusion: EventRR通过结构化语义推理显著提升了RVOS任务的性能。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in
a video referred by an expression. Current RVOS methods view referring
expressions as unstructured sequences, neglecting their crucial semantic
structure essential for referent reasoning. Besides, in contrast to
image-referring expressions whose semantics focus only on object attributes and
object-object relations, video-referring expressions also encompass event
attributes and event-event temporal relations. This complexity challenges
traditional structured reasoning image approaches. In this paper, we propose
the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS
into object summarization part and referent reasoning part. The summarization
phase begins by summarizing each frame into a set of bottleneck tokens, which
are then efficiently aggregated in the video-level summarization step to
exchange the global cross-modal temporal context. For reasoning part, EventRR
extracts semantic eventful structure of a video-referring expression into
highly expressive Referential Event Graph (REG), which is a single-rooted
directed acyclic graph. Guided by topological traversal of REG, we propose
Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of
each temporal query from REG leaf nodes to root node. Each reasoning step can
be interpreted as a question-answer pair derived from the concept-role
relations in REG. Extensive experiments across four widely recognized benchmark
datasets, show that EventRR quantitatively and qualitatively outperforms
state-of-the-art RVOS methods. Code is available at
https://github.com/bio-mlhui/EventRR

</details>


### [4] [Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM](https://arxiv.org/abs/2508.07260)
*Sihan Yang,Huitong Ji,Shaolin Lu,Jiayi Chen,Binxiao Xu,Ming Lu,Yuanxing Zhang,Wenhui Dong,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为SLC的小型与大型视觉语言模型协作框架，用于个性化大型模型，同时保持训练高效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型（VLMs）个性化成本高且访问受限，而小型VLMs虽易个性化但推理能力不足的问题。

Method: 通过小型VLM生成个性化信息，大型VLM整合信息并提供准确响应，采用测试时反射策略防止小型VLM的幻觉问题。

Result: 实验证明SLC框架在多种基准测试和大型VLMs中有效，支持开源和闭源模型。

Conclusion: SLC是首个训练高效且支持广泛个性化应用的框架，代码将开源。

Abstract: Personalizing Vision-Language Models (VLMs) to transform them into daily
assistants has emerged as a trending research direction. However, leading
companies like OpenAI continue to increase model size and develop complex
designs such as the chain of thought (CoT). While large VLMs are proficient in
complex multi-modal understanding, their high training costs and limited access
via paid APIs restrict direct personalization. Conversely, small VLMs are
easily personalized and freely available, but they lack sufficient reasoning
capabilities. Inspired by this, we propose a novel collaborative framework
named Small-Large Collaboration (SLC) for large VLM personalization, where the
small VLM is responsible for generating personalized information, while the
large model integrates this personalized information to deliver accurate
responses. To effectively incorporate personalized information, we develop a
test-time reflection strategy, preventing the potential hallucination of the
small VLM. Since SLC only needs to train a meta personalized small VLM for the
large VLMs, the overall process is training-efficient. To the best of our
knowledge, this is the first training-efficient framework that supports both
open-source and closed-source large VLMs, enabling broader real-world
personalized applications. We conduct thorough experiments across various
benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC
framework. The code will be released at https://github.com/Hhankyangg/SLC.

</details>


### [5] [LET-US: Long Event-Text Understanding of Scenes](https://arxiv.org/abs/2508.07401)
*Rui Chen,Xingyu Chen,Shaoan Wang,Shihan Kong,Junzhi Yu*

Main category: cs.CV

TL;DR: LET-US框架通过自适应压缩机制处理长事件流，结合两阶段优化和跨模态查询，提升了事件流与文本的对齐能力，并在多任务基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在处理事件流时效果不佳或仅支持短序列，LET-US旨在解决这一问题，实现长事件流与文本的跨模态理解。

Method: 采用自适应压缩机制减少事件量，两阶段优化提升事件流理解能力，结合文本引导的跨模态查询和分层聚类提取关键特征。

Result: 实验显示LET-US在长事件流的描述准确性和语义理解上优于现有MLLM。

Conclusion: LET-US为长事件流与文本的跨模态理解设立了新标准，代码和数据集将公开。

Abstract: Event cameras output event streams as sparse, asynchronous data with
microsecond-level temporal resolution, enabling visual perception with low
latency and a high dynamic range. While existing Multimodal Large Language
Models (MLLMs) have achieved significant success in understanding and analyzing
RGB video content, they either fail to interpret event streams effectively or
remain constrained to very short sequences. In this paper, we introduce LET-US,
a framework for long event-stream--text comprehension that employs an adaptive
compression mechanism to reduce the volume of input events while preserving
critical visual details. LET-US thus establishes a new frontier in cross-modal
inferential understanding over extended event sequences. To bridge the
substantial modality gap between event streams and textual representations, we
adopt a two-stage optimization paradigm that progressively equips our model
with the capacity to interpret event-based scenes. To handle the voluminous
temporal information inherent in long event streams, we leverage text-guided
cross-modal queries for feature reduction, augmented by hierarchical clustering
and similarity computation to distill the most representative event features.
Moreover, we curate and construct a large-scale event-text aligned dataset to
train our model, achieving tighter alignment of event features within the LLM
embedding space. We also develop a comprehensive benchmark covering a diverse
set of tasks -- reasoning, captioning, classification, temporal localization
and moment retrieval. Experimental results demonstrate that LET-US outperforms
prior state-of-the-art MLLMs in both descriptive accuracy and semantic
comprehension on long-duration event streams. All datasets, codes, and models
will be publicly available.

</details>


### [6] [VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding](https://arxiv.org/abs/2508.07493)
*Jian Chen,Ming Li,Jihyung Kil,Chenguang Wang,Tong Yu,Ryan Rossi,Tianyi Zhou,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: VisR-Bench是一个多语言基准测试，用于长文档中的问题驱动多模态检索，覆盖16种语言和3种问题类型，评估了多种检索模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注英文文档检索或单页图像的多语言问答，缺乏对多语言长文档多模态检索的支持。

Method: 引入VisR-Bench，包含35K QA对和1.2K文档，支持细粒度多模态检索评估，涵盖多种语言和问题类型。

Result: MLLMs显著优于基于文本和多模态编码器的模型，但在结构化表格和低资源语言上仍有挑战。

Conclusion: VisR-Bench填补了多语言长文档多模态检索的空白，并揭示了现有模型的局限性。

Abstract: Most organizational data in this world are stored as documents, and visual
retrieval plays a crucial role in unlocking the collective intelligence from
all these documents. However, existing benchmarks focus on English-only
document retrieval or only consider multilingual question-answering on a
single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual
benchmark designed for question-driven multimodal retrieval in long documents.
Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents,
enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans
sixteen languages with three question types (figures, text, and tables),
offering diverse linguistic and question coverage. Unlike prior datasets, we
include queries without explicit answers, preventing models from relying on
superficial keyword matching. We evaluate various retrieval models, including
text-based methods, multimodal encoders, and MLLMs, providing insights into
their strengths and limitations. Our results show that while MLLMs
significantly outperform text-based and multimodal encoder models, they still
struggle with structured tables and low-resource languages, highlighting key
challenges in multilingual visual retrieval.

</details>


### [7] [Commentary Generation for Soccer Highlights](https://arxiv.org/abs/2508.07543)
*Chidaksh Ravuru*

Main category: cs.CV

TL;DR: 论文扩展了MatchVoice模型，用于足球集锦的实时解说生成，实验验证了其性能，并探讨了窗口大小对零样本性能的影响。


<details>
  <summary>Details</summary>
Motivation: 解决现有系统在视频内容与解说之间的细粒度对齐问题，提升足球集锦的实时解说生成能力。

Method: 扩展MatchVoice模型，利用GOAL数据集进行实验，评估不同训练配置和硬件限制的影响，并探索窗口大小对零样本性能的作用。

Result: MatchVoice展现出良好的泛化能力，但需结合更广泛的视频-语言领域技术以进一步提升性能。

Conclusion: 研究为足球集锦解说生成提供了改进方向，强调了跨领域技术整合的重要性。

Abstract: Automated soccer commentary generation has evolved from template-based
systems to advanced neural architectures, aiming to produce real-time
descriptions of sports events. While frameworks like SoccerNet-Caption laid
foundational work, their inability to achieve fine-grained alignment between
video content and commentary remains a significant challenge. Recent efforts
such as MatchTime, with its MatchVoice model, address this issue through coarse
and fine-grained alignment techniques, achieving improved temporal
synchronization. In this paper, we extend MatchVoice to commentary generation
for soccer highlights using the GOAL dataset, which emphasizes short clips over
entire games. We conduct extensive experiments to reproduce the original
MatchTime results and evaluate our setup, highlighting the impact of different
training configurations and hardware limitations. Furthermore, we explore the
effect of varying window sizes on zero-shot performance. While MatchVoice
exhibits promising generalization capabilities, our findings suggest the need
for integrating techniques from broader video-language domains to further
enhance performance. Our code is available at
https://github.com/chidaksh/SoccerCommentary.

</details>


### [8] [Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake](https://arxiv.org/abs/2508.07795)
*Hongrui Zheng,Yuezun Li,Liejun Wang,Yunfeng Diao,Zhiqing Guo*

Main category: cs.CV

TL;DR: 论文提出了一种双阶段防御框架（TSDF），通过双功能对抗扰动直接扭曲伪造结果并破坏攻击者的数据准备过程，以提高主动防御的持久性。


<details>
  <summary>Details</summary>
Motivation: 现有主动防御策略缺乏持久性，攻击者可通过收集受保护样本并重新训练模型绕过防御，限制了实际应用。

Method: 提出TSDF框架，利用强度分离机制设计双功能对抗扰动，直接扭曲伪造结果并破坏攻击者的数据准备过程。

Result: 实验表明，传统防御方法在对抗性重新训练下性能急剧下降，而TSDF展现出强大的双重防御能力。

Conclusion: TSDF通过双功能扰动有效阻止攻击者模型适应防御，显著提升了主动防御的持久性。

Abstract: Active defense strategies have been developed to counter the threat of
deepfake technology. However, a primary challenge is their lack of persistence,
as their effectiveness is often short-lived. Attackers can bypass these
defenses by simply collecting protected samples and retraining their models.
This means that static defenses inevitably fail when attackers retrain their
models, which severely limits practical use. We argue that an effective defense
not only distorts forged content but also blocks the model's ability to adapt,
which occurs when attackers retrain their models on protected images. To
achieve this, we propose an innovative Two-Stage Defense Framework (TSDF).
Benefiting from the intensity separation mechanism designed in this paper, the
framework uses dual-function adversarial perturbations to perform two roles.
First, it can directly distort the forged results. Second, it acts as a
poisoning vehicle that disrupts the data preparation process essential for an
attacker's retraining pipeline. By poisoning the data source, TSDF aims to
prevent the attacker's model from adapting to the defensive perturbations, thus
ensuring the defense remains effective long-term. Comprehensive experiments
show that the performance of traditional interruption methods degrades sharply
when it is subjected to adversarial retraining. However, our framework shows a
strong dual defense capability, which can improve the persistence of active
defense. Our code will be available at https://github.com/vpsg-research/TSDF.

</details>


### [9] [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981)
*Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: Omni-Effects提出了一种统一框架，支持提示引导的效果生成和空间可控的复合效果，解决了多VFX联合训练中的干扰和空间不可控问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在VFX制作中受限于单效果训练，无法实现多效果的空间可控复合生成。

Method: 提出了LoRA-MoE和SAP两项创新，前者整合多样效果并减少干扰，后者通过空间掩码信息实现精确控制。

Result: 实验表明Omni-Effects能精确控制效果类别和位置，支持多样化效果生成。

Conclusion: Omni-Effects为VFX制作提供了高效、可控的解决方案，推动了多效果统一生成的研究。

Abstract: Visual effects (VFX) are essential visual enhancements fundamental to modern
cinematic production. Although video generation models offer cost-efficient
solutions for VFX production, current methods are constrained by per-effect
LoRA training, which limits generation to single effects. This fundamental
limitation impedes applications that require spatially controllable composite
effects, i.e., the concurrent generation of multiple effects at designated
locations. However, integrating diverse effects into a unified framework faces
major challenges: interference from effect variations and spatial
uncontrollability during multi-VFX joint training. To tackle these challenges,
we propose Omni-Effects, a first unified framework capable of generating
prompt-guided effects and spatially controllable composite effects. The core of
our framework comprises two key innovations: (1) LoRA-based Mixture of Experts
(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects
within a unified model while effectively mitigating cross-task interference.
(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the
text token, enabling precise spatial control. Furthermore, we introduce an
Independent-Information Flow (IIF) module integrated within the SAP, isolating
the control signals corresponding to individual effects to prevent any unwanted
blending. To facilitate this research, we construct a comprehensive VFX dataset
Omni-VFX via a novel data collection pipeline combining image editing and
First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX
evaluation framework for validating model performance. Extensive experiments
demonstrate that Omni-Effects achieves precise spatial control and diverse
effect generation, enabling users to specify both the category and location of
desired effects.

</details>


### [10] [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2508.08248)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAvatar是一种端到端的视频扩散变换器，能够生成无限长度的高质量视频，解决了现有模型在音频同步和身份一致性上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动虚拟化身视频生成模型难以生成长视频且音频同步和身份一致性差。

Method: 提出StableAvatar，结合定制训练和推理模块，引入时间步感知音频适配器和音频原生引导机制，以及动态加权滑动窗口策略。

Result: 实验证明StableAvatar在质量和数量上均优于现有模型。

Conclusion: StableAvatar通过创新方法解决了长视频生成中的音频同步和一致性难题。

Abstract: Current diffusion models for audio-driven avatar video generation struggle to
synthesize long videos with natural audio synchronization and identity
consistency. This paper presents StableAvatar, the first end-to-end video
diffusion transformer that synthesizes infinite-length high-quality videos
without post-processing. Conditioned on a reference image and audio,
StableAvatar integrates tailored training and inference modules to enable
infinite-length video generation. We observe that the main reason preventing
existing models from generating long videos lies in their audio modeling. They
typically rely on third-party off-the-shelf extractors to obtain audio
embeddings, which are then directly injected into the diffusion model via
cross-attention. Since current diffusion backbones lack any audio-related
priors, this approach causes severe latent distribution error accumulation
across video clips, leading the latent distribution of subsequent segments to
drift away from the optimal distribution gradually. To address this,
StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents
error accumulation via time-step-aware modulation. During inference, we propose
a novel Audio Native Guidance Mechanism to further enhance the audio
synchronization by leveraging the diffusion's own evolving joint audio-latent
prediction as a dynamic guidance signal. To enhance the smoothness of the
infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy
that fuses latent over time. Experiments on benchmarks show the effectiveness
of StableAvatar both qualitatively and quantitatively.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

TL;DR: 论文探讨了通过过滤训练数据中的双用途主题文本来增强开放权重AI系统的抗篡改能力，并提出了一种多阶段数据过滤方法。实验表明，该方法能显著减少模型对生物威胁知识的掌握，并在对抗性微调攻击中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开放权重AI系统虽具有透明性和开放性等优势，但易受篡改攻击，现有安全微调方法难以抵御多步攻击。因此，研究如何通过数据过滤增强系统安全性。

Method: 提出一种多阶段数据过滤管道，用于从训练数据中移除双用途主题文本，并预训练多个6.9B参数模型。

Result: 过滤后的模型在对抗性微调攻击中表现优异（可抵御10,000步攻击），且不影响其他能力。但模型仍可通过上下文利用危险知识，表明需多层次防御。

Conclusion: 预训练数据过滤是开放权重AI系统的一种有效防御层，但需结合其他防御措施以实现全面保护。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [12] [Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning](https://arxiv.org/abs/2508.07114)
*Atakan Azakli,Bernd Stelzer*

Main category: cs.LG

TL;DR: 提出了一种新的机器学习方法，通过多实例学习（MIL）提高假设检验中参数预测的精度和判别力，并系统减少预测误差。


<details>
  <summary>Details</summary>
Motivation: 在现有分类器难以准确预测的情况下，提升机器学习模型的判别力和预测精度。

Method: 利用多实例学习（MIL）的数学优势，分析其在不同实例数量下的缩放行为。

Result: 在标准模型有效场论（SMEFT）中约束Wilson系数，展示了在某些情况下可能提取数据集中的最大Fisher信息。

Conclusion: MIL方法在复杂假设检验问题中具有更高的预测能力和理论优势。

Abstract: In this work, we propose a new machine learning (ML) methodology to obtain
more precise predictions for some parameters of interest in a given hypotheses
testing problem. Our proposed method also allows ML models to have more
discriminative power in cases where it is extremely challenging for
state-of-the-art classifiers to have any level of accurate predictions. This
method can also allow us to systematically decrease the error from ML models in
their predictions. In this paper, we provide a mathematical motivation why
Multiple Instance Learning (MIL) would have more predictive power over their
single-instance counterparts. We support our theoretical claims by analyzing
the behavior of the MIL models through their scaling behaviors with respect to
the number of instances on which the model makes predictions. As a concrete
application, we constrain Wilson coefficients of the Standard Model Effective
Field Theory (SMEFT) using kinematic information from subatomic particle
collision events at the Large Hadron Collider (LHC). We show that under certain
circumstances, it might be possible to extract the theoretical maximum Fisher
Information latent in a dataset.

</details>


### [13] [A Stable and Principled Loss Function for Direct Language Model Alignment](https://arxiv.org/abs/2508.07137)
*Yuandong Tan*

Main category: cs.LG

TL;DR: 论文提出了一种新的损失函数，解决了Direct Preference Optimization (DPO) 中因无限最大化对数差而导致的训练不稳定和奖励攻击问题。


<details>
  <summary>Details</summary>
Motivation: DPO的损失函数与其理论推导不一致，可能导致训练不稳定和奖励攻击，因此需要改进。

Method: 从RLHF最优条件直接推导出新的损失函数，目标是对数差的特定有限值，而非最大化。

Result: 新方法避免了DPO中的大梯度问题，提升了训练稳定性，并在实验中显著优于标准DPO基线。

Conclusion: 提出的损失函数更稳定且有效，在模型对齐中表现优异。

Abstract: The alignment of large language models (LLMs) with human preferences is
commonly achieved through Reinforcement Learning from Human Feedback (RLHF).
Direct Preference Optimization (DPO) simplified this paradigm by establishing a
direct mapping between the optimal policy and a reward function, eliminating
the need for an explicit reward model. However, we argue that the DPO loss
function is theoretically misaligned with its own derivation, as it promotes
the indefinite maximization of a logits difference, which can lead to training
instability and reward hacking. In this paper, we propose a novel loss function
derived directly from the RLHF optimality condition. Our proposed loss targets
a specific, finite value for the logits difference, which is dictated by the
underlying reward, rather than its maximization. We provide a theoretical
analysis, including a gradient-based comparison, to demonstrate that our method
avoids the large gradients that plague DPO when the probability of dispreferred
responses approaches zero. This inherent stability prevents reward hacking and
leads to more effective alignment. We validate our approach by fine-tuning a
Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO
baseline and achieving competitive performance against larger models like
Llama-3.1-8B.

</details>


### [14] [Lightning Prediction under Uncertainty: DeepLight with Hazy Loss](https://arxiv.org/abs/2508.07428)
*Md Sultanul Arifin,Abu Nowshed Sakib,Yeasir Rayhan,Tanzima Hashem*

Main category: cs.LG

TL;DR: DeepLight是一种新型深度学习架构，用于预测闪电发生，通过多源气象数据和双编码器架构，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 闪电对人和经济造成重大风险，现有预测模型在动态空间上下文捕捉和不确定性处理上存在不足，且依赖昂贵的数值天气预报系统。

Method: DeepLight利用雷达反射率、云属性和历史闪电数据，采用双编码器架构和多分支卷积技术，动态捕捉空间相关性，并使用Hazy Loss函数处理时空不确定性。

Result: 实验表明，DeepLight的公平威胁评分（ETS）比现有方法提高了18%-30%。

Conclusion: DeepLight为闪电预测提供了更鲁棒的解决方案，显著优于现有方法。

Abstract: Lightning, a common feature of severe meteorological conditions, poses
significant risks, from direct human injuries to substantial economic losses.
These risks are further exacerbated by climate change. Early and accurate
prediction of lightning would enable preventive measures to safeguard people,
protect property, and minimize economic losses. In this paper, we present
DeepLight, a novel deep learning architecture for predicting lightning
occurrences. Existing prediction models face several critical limitations: they
often struggle to capture the dynamic spatial context and inherent uncertainty
of lightning events, underutilize key observational data, such as radar
reflectivity and cloud properties, and rely heavily on Numerical Weather
Prediction (NWP) systems, which are both computationally expensive and highly
sensitive to parameter settings. To overcome these challenges, DeepLight
leverages multi-source meteorological data, including radar reflectivity, cloud
properties, and historical lightning occurrences through a dual-encoder
architecture. By employing multi-branch convolution techniques, it dynamically
captures spatial correlations across varying extents. Furthermore, its novel
Hazy Loss function explicitly addresses the spatio-temporal uncertainty of
lightning by penalizing deviations based on proximity to true events, enabling
the model to better learn patterns amidst randomness. Extensive experiments
show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over
state-of-the-art methods, establishing it as a robust solution for lightning
prediction.

</details>


### [15] [Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer](https://arxiv.org/abs/2508.07710)
*Jingya Wang,Xin Deng,Wenjie Wei,Dehao Zhang,Shuai Wang,Qian Sun,Jieyuan Zhang,Hanwen Liu,Ning Xie,Malu Zhang*

Main category: cs.LG

TL;DR: 提出了一种无需训练的高性能ANN-to-SNN转换框架，通过MBE神经元有效处理Transformer中的非线性操作，实现近无损转换。


<details>
  <summary>Details</summary>
Motivation: 现有ANN-to-SNN转换方法无法有效处理Transformer中的非线性操作且需额外微调，限制了Spiking Transformers的高效部署。

Method: 引入多基指数衰减（MBE）神经元，采用指数衰减策略和多基编码方法，无需修改预训练ANN的权重。

Result: 在多种任务（CV、NLU、NLG）和主流Transformer架构（ViT、RoBERTa、GPT-2）上实现近无损转换，延迟显著降低。

Conclusion: 为Spiking Transformers的高效和可扩展部署提供了可行路径。

Abstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a
promising approach for constructing energy-efficient Transformer architectures.
Compared to directly trained Spiking Transformers, ANN-to-SNN conversion
methods bypass the high training costs. However, existing methods still suffer
from notable limitations, failing to effectively handle nonlinear operations in
Transformer architectures and requiring additional fine-tuning processes for
pre-trained ANNs. To address these issues, we propose a high-performance and
training-free ANN-to-SNN conversion framework tailored for Transformer
architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)
neuron, which employs an exponential decay strategy and multi-basis encoding
method to efficiently approximate various nonlinear operations. It removes the
requirement for weight modifications in pre-trained ANNs. Extensive experiments
across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures
(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless
conversion accuracy with significantly lower latency. This provides a promising
pathway for the efficient and scalable deployment of Spiking Transformers in
real-world applications.

</details>


### [16] [Sparse Probabilistic Graph Circuits](https://arxiv.org/abs/2508.07763)
*Martin Rektoris,Milan Papež,Václav Šmídl,Tomáš Pevný*

Main category: cs.LG

TL;DR: 论文提出了一种稀疏概率图电路（SPGCs），解决了传统深度生成模型（DGMs）在概率推断上的不可解问题，同时降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统DGMs因非线性特性导致概率推断不可解，而现有的PGCs虽解决了可解性问题，但计算复杂度高（O(n^2)），限制了其在大规模稀疏图上的应用。

Method: 提出稀疏概率图电路（SPGCs），直接操作稀疏图表示，将复杂度降至O(n + m)，适用于边数远小于节点数平方的稀疏图。

Result: 在药物设计中，SPGCs保持了精确推断能力，提高了内存效率和推断速度，并在关键指标上匹配了不可解DGMs的性能。

Conclusion: SPGCs是一种高效且可扩展的生成模型，适用于稀疏图场景，解决了传统DGMs和PGCs的局限性。

Abstract: Deep generative models (DGMs) for graphs achieve impressively high expressive
power thanks to very efficient and scalable neural networks. However, these
networks contain non-linearities that prevent analytical computation of many
standard probabilistic inference queries, i.e., these DGMs are considered
\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)
address this issue by enabling \emph{tractable} probabilistic inference, they
operate on dense graph representations with $\mathcal{O}(n^2)$ complexity for
graphs with $n$ nodes and \emph{$m$ edges}. To address this scalability issue,
we introduce Sparse PGCs, a new class of tractable generative models that
operate directly on sparse graph representation, reducing the complexity to
$\mathcal{O}(n + m)$, which is particularly beneficial for $m \ll n^2$. In the
context of de novo drug design, we empirically demonstrate that SPGCs retain
exact inference capabilities, improve memory efficiency and inference speed,
and match the performance of intractable DGMs in key metrics.

</details>


### [17] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 本文提出了一种基于迁移学习的预测性过程监控（PPM）技术，帮助缺乏足够事件数据的组织实现有效的决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有PPM技术需要大量事件数据或其他资源，而许多组织无法满足这一条件，限制了PPM的应用。

Method: 提出了一种迁移学习技术，允许将一个业务流程的知识迁移到相似的目标业务流程中，支持跨组织或组织内的PPM实现。

Result: 实验结果表明，迁移学习可以在相同或不同组织的相似业务流程中实现有效的PPM。

Conclusion: 该技术为组织提供了在资源有限情况下实施PPM的可行方案，支持跨组织知识迁移。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [18] [Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles](https://arxiv.org/abs/2508.08034)
*Roksana Yahyaabadi,Ghazal Farhani,Taufiq Rahman,Soodeh Nikan,Abdullah Jirjees,Fadi Araji*

Main category: cs.LG

TL;DR: 提出了一种基于数据驱动的方法，结合传统机器学习和深度神经网络，用于预测内燃机、电动汽车和混合动力汽车的瞬时和累积功率消耗，效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖专业仪器或物理模型，难以大规模部署，因此需要一种更实用的解决方案。

Method: 使用动力系统动态特征集，结合传统机器学习和深度神经网络（如Transformer和LSTM）进行预测。

Result: 内燃机模型的瞬时误差低至10^-3，累积误差低于3%；电动汽车和混合动力汽车的累积误差分别低于4.1%和2.1%。

Conclusion: 该方法在不同车型中均表现有效，但电动汽车和混合动力汽车的数据变异性更高，需要更鲁棒的模型。

Abstract: Accurate power consumption prediction is crucial for improving efficiency and
reducing environmental impact, yet traditional methods relying on specialized
instruments or rigid physical models are impractical for large-scale,
real-world deployment. This study introduces a scalable data-driven method
using powertrain dynamic feature sets and both traditional machine learning and
deep neural networks to estimate instantaneous and cumulative power consumption
in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric
vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with
mean absolute error and root mean squared error on the order of $10^{-3}$, and
cumulative errors under 3%. Transformer and long short-term memory models
performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,
respectively. Results confirm the approach's effectiveness across vehicles and
models. Uncertainty analysis revealed greater variability in EV and HEV
datasets than ICE, due to complex power management, emphasizing the need for
robust models for advanced powertrains.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction](https://arxiv.org/abs/2508.06859)
*Shuo Tang,Jian Xu,Jiadong Zhang,Yi Chen,Qizhao Jin,Lingdong Shen,Chenglin Liu,Shiming Xiang*

Main category: cs.AI

TL;DR: 论文提出了一种基于AI的端到端天气预警系统，通过构建大规模多模态数据集MP-Bench和开发气象多模态大模型（MMLM），解决了现有系统依赖人工、数据不足和对高维气象数据处理能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 当前天气预警系统依赖人工专家解释，存在主观性和操作负担。AI技术的发展为自动化天气预测提供了新机遇，但面临数据稀缺、高维数据对齐困难和多模态模型能力不足等挑战。

Method: 构建MP-Bench数据集（包含421,363对气象数据与文本描述），开发MMLM模型，通过三个自适应融合模块处理4D气象数据。

Result: MMLM在MP-Bench上表现优异，验证了其在天气理解任务中的有效性，推动了AI驱动的自动化天气预测系统的发展。

Conclusion: MMLM和MP-Bench为自动化天气预警系统提供了关键技术支持，未来将进一步公开代码和数据集。

Abstract: Timely and accurate severe weather warnings are critical for disaster
mitigation. However, current forecasting systems remain heavily reliant on
manual expert interpretation, introducing subjectivity and significant
operational burdens. With the rapid development of AI technologies, the
end-to-end "AI weather station" is gradually emerging as a new trend in
predicting severe weather events. Three core challenges impede the development
of end-to-end AI severe weather system: (1) scarcity of severe weather event
samples; (2) imperfect alignment between high-dimensional meteorological data
and textual warnings; (3) existing multimodal language models are unable to
handle high-dimensional meteorological data and struggle to fully capture the
complex dependencies across temporal sequences, vertical pressure levels, and
spatial dimensions. To address these challenges, we introduce MP-Bench, the
first large-scale temporal multimodal dataset for severe weather events
prediction, comprising 421,363 pairs of raw multi-year meteorological data and
corresponding text caption, covering a wide range of severe weather scenarios
across China. On top of this dataset, we develop a meteorology multimodal large
model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is
designed to accommodate the unique characteristics of 4D meteorological data
flow, incorporating three plug-and-play adaptive fusion modules that enable
dynamic feature extraction and integration across temporal sequences, vertical
pressure layers, and spatial dimensions. Extensive experiments on MP-Bench
demonstrate that MMLM performs exceptionally well across multiple tasks,
highlighting its effectiveness in severe weather understanding and marking a
key step toward realizing automated, AI-driven weather forecasting systems. Our
source code and dataset will be made publicly available.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements](https://arxiv.org/abs/2508.07598)
*Ziheng Li,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: KeyCP++通过关键词驱动的链式思维提示方法，解决了LLM在事件检测中的过解释问题，显著提升了一样本事件检测性能。


<details>
  <summary>Details</summary>
Motivation: LLM在事件检测中因缺乏对事件触发词的准确理解而容易过解释，仅通过上下文示例难以纠正。

Method: 提出KeyCP++，通过自动标注输入文本与检测结果间的逻辑差距，构建触发词判别提示模板，结合关键词生成候选触发词并验证。

Result: 实验证明KeyCP++在一样本事件检测中表现显著提升。

Conclusion: KeyCP++通过减少对关键词的过度依赖并促进检测规则学习，有效改进了LLM在事件检测中的性能。

Abstract: Although the LLM-based in-context learning (ICL) paradigm has demonstrated
considerable success across various natural language processing tasks, it
encounters challenges in event detection. This is because LLMs lack an accurate
understanding of event triggers and tend to make over-interpretation, which
cannot be effectively corrected through in-context examples alone. In this
paper, we focus on the most challenging one-shot setting and propose KeyCP++, a
keyword-centric chain-of-thought prompting approach. KeyCP++ addresses the
weaknesses of conventional ICL by automatically annotating the logical gaps
between input text and detection results for the demonstrations. Specifically,
to generate in-depth and meaningful rationale, KeyCP++ constructs a trigger
discrimination prompting template. It incorporates the exemplary triggers
(a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let
LLM propose candidate triggers, and justify each candidate. These
propose-and-judge rationales help LLMs mitigate over-reliance on the keywords
and promote detection rule learning. Extensive experiments demonstrate the
effectiveness of our approach, showcasing significant advancements in one-shot
event detection.

</details>


### [21] [SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling](https://arxiv.org/abs/2508.08211)
*Zhuohao Yu,Xingru Jiang,Weizheng Gu,Yidong Wang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: SAEMark是一种后处理多比特水印框架，通过推理时基于特征的拒绝采样嵌入个性化消息，无需修改模型逻辑或训练，适用于多语言和封闭源LLM。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法会降低文本质量，且需要白盒模型访问和逻辑操作，限制了API模型和多语言场景的应用。

Method: SAEMark利用生成文本的确定性特征，选择特征统计与密钥目标一致的输出，通过采样而非修改实现水印嵌入。

Result: 在4个数据集上，SAEMark实现了99.7%的F1分数（英语）和强大的多比特检测准确率。

Conclusion: SAEMark为可扩展水印提供了新范式，适用于封闭源LLM，同时支持内容溯源。

Abstract: Watermarking LLM-generated text is critical for content attribution and
misinformation prevention. However, existing methods compromise text quality,
require white-box model access and logit manipulation. These limitations
exclude API-based models and multilingual scenarios. We propose SAEMark, a
general framework for post-hoc multi-bit watermarking that embeds personalized
messages solely via inference-time, feature-based rejection sampling without
altering model logits or requiring training. Our approach operates on
deterministic features extracted from generated text, selecting outputs whose
feature statistics align with key-derived targets. This framework naturally
generalizes across languages and domains while preserving text quality through
sampling LLM outputs instead of modifying. We provide theoretical guarantees
relating watermark success probability and compute budget that hold for any
suitable feature extractor. Empirically, we demonstrate the framework's
effectiveness using Sparse Autoencoders (SAEs), achieving superior detection
accuracy and text quality. Experiments across 4 datasets show SAEMark's
consistent performance, with 99.7% F1 on English and strong multi-bit detection
accuracy. SAEMark establishes a new paradigm for scalable watermarking that
works out-of-the-box with closed-source LLMs while enabling content
attribution.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [22] [AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance](https://arxiv.org/abs/2508.06554)
*Abdelhaleem Saad,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: AquaChat++是一种基于大型语言模型的多ROV检查框架，用于水产养殖网箱的自适应任务规划和容错控制。


<details>
  <summary>Details</summary>
Motivation: 传统水产养殖网箱检查方法适应性差，无法应对实时约束（如能耗、硬件故障和动态水下环境）。

Method: 采用两层架构：高层使用LLM生成多智能体检查计划，低层实现轨迹跟踪和故障补偿。

Result: 模拟实验显示提高了检查覆盖率、能效和容错能力。

Conclusion: LLM驱动的框架有望支持水产养殖中可扩展、智能和自主的水下机器人操作。

Abstract: Inspection of aquaculture net pens is essential for ensuring the structural
integrity and sustainable operation of offshore fish farming systems.
Traditional methods, typically based on manually operated or single-ROV
systems, offer limited adaptability to real-time constraints such as energy
consumption, hardware faults, and dynamic underwater conditions. This paper
introduces AquaChat++, a novel multi-ROV inspection framework that uses Large
Language Models (LLMs) to enable adaptive mission planning, coordinated task
execution, and fault-tolerant control in complex aquaculture environments. The
proposed system consists of a two-layered architecture. The high-level plan
generation layer employs an LLM, such as ChatGPT-4, to translate natural
language user commands into symbolic, multi-agent inspection plans. A task
manager dynamically allocates and schedules actions among ROVs based on their
real-time status and operational constraints, including thruster faults and
battery levels. The low-level control layer ensures accurate trajectory
tracking and integrates thruster fault detection and compensation mechanisms.
By incorporating real-time feedback and event-triggered replanning, AquaChat++
enhances system robustness and operational efficiency. Simulated experiments in
a physics-based aquaculture environment demonstrate improved inspection
coverage, energy-efficient behavior, and resilience to actuator failures. These
findings highlight the potential of LLM-driven frameworks to support scalable,
intelligent, and autonomous underwater robotic operations within the
aquaculture sector.

</details>


### [23] [EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events](https://arxiv.org/abs/2508.07003)
*Siyu Chen,Shenghai Yuan,Thien-Minh Nguyen,Zhuyu Huang,Chenyang Shi,Jin Jing,Lihua Xie*

Main category: cs.RO

TL;DR: EGS-SLAM通过融合事件数据和RGB-D输入，解决了传统GS-SLAM在运动模糊下的性能问题，实现了更鲁棒的跟踪和高保真3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有GS-SLAM系统在严重运动模糊场景下表现不佳，导致跟踪精度和重建质量下降。

Method: 提出EGS-SLAM框架，结合事件数据和RGB-D输入，建模相机连续轨迹，引入可学习的相机响应函数和无事件损失。

Result: 在合成和真实数据集上验证，EGS-SLAM在轨迹精度和3D重建质量上优于现有系统。

Conclusion: EGS-SLAM显著提升了在运动模糊场景下的性能，为高保真3D重建提供了新方法。

Abstract: Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over
traditional SLAM methods, enabling photorealistic 3D reconstruction that
conventional approaches often struggle to achieve. However, existing GS-SLAM
systems perform poorly under persistent and severe motion blur commonly
encountered in real-world scenarios, leading to significantly degraded tracking
accuracy and compromised 3D reconstruction quality. To address this limitation,
we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D
inputs to simultaneously reduce motion blur in images and compensate for the
sparse and discrete nature of event streams, enabling robust tracking and
high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system
explicitly models the camera's continuous trajectory during exposure,
supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian
Splatting scene. Furthermore, we introduce a learnable camera response function
to align the dynamic ranges of events and images, along with a no-event loss to
suppress ringing artifacts during reconstruction. We validate our approach on a
new dataset comprising synthetic and real-world sequences with significant
motion blur. Extensive experimental results demonstrate that EGS-SLAM
consistently outperforms existing GS-SLAM systems in both trajectory accuracy
and photorealistic 3D Gaussian Splatting reconstruction. The source code will
be available at https://github.com/Chensiyu00/EGS-SLAM.

</details>


### [24] [MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control](https://arxiv.org/abs/2508.07387)
*Basant Sharma,Prajyot Jadhav,Pranjal Paul,K. Madhava Krishna,Arun Kumar Singh*

Main category: cs.RO

TL;DR: 论文提出了一种基于学习碰撞模型的方法，利用噪声深度估计作为上下文输入，通过风险感知MPC规划器提高机器人在未知环境中的导航成功率。


<details>
  <summary>Details</summary>
Motivation: 单RGB相机在未知环境中导航时缺乏深度信息，导致碰撞检测不可靠。现有的深度估计方法噪声过大，无法直接用于零样本导航。

Method: 提出一种学习碰撞模型的方法，利用噪声深度估计作为上下文输入，预测机器人控制序列的最小障碍物间隙分布，并通过风险感知MPC规划器优化导航。

Result: 实验表明，该方法在真实环境中比NoMaD和ROS堆栈分别提高了9倍和7倍的成功率。

Conclusion: 联合学习碰撞模型和风险度量的方法显著提高了在高度杂乱环境中的导航性能，并通过消融研究验证了设计选择的有效性。

Abstract: Navigating unknown environments with a single RGB camera is challenging, as
the lack of depth information prevents reliable collision-checking. While some
methods use estimated depth to build collision maps, we found that depth
estimates from vision foundation models are too noisy for zero-shot navigation
in cluttered environments.
  We propose an alternative approach: instead of using noisy estimated depth
for direct collision-checking, we use it as a rich context input to a learned
collision model. This model predicts the distribution of minimum obstacle
clearance that the robot can expect for a given control sequence. At inference,
these predictions inform a risk-aware MPC planner that minimizes estimated
collision risk. Our joint learning pipeline co-trains the collision model and
risk metric using both safe and unsafe trajectories. Crucially, our
joint-training ensures optimal variance in our collision model that improves
navigation in highly cluttered environments. Consequently, real-world
experiments show 9x and 7x improvements in success rates over NoMaD and the ROS
stack, respectively. Ablation studies further validate the effectiveness of our
design choices.

</details>


### [25] [MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration under Restricted Communication](https://arxiv.org/abs/2508.07657)
*Zhuoli Tian,Yuyang Zhang,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: MoRoCo是一个多操作者多机器人系统的统一框架，用于在通信受限环境下实现双边、上下文感知的交互和高效探索。


<details>
  <summary>Details</summary>
Motivation: 在通信受限的环境中，现有研究多忽视人类操作者与机器人团队的实时互动需求，而MoRoCo旨在填补这一空白。

Method: MoRoCo通过分布式算法管理三种协调模式（spread、migrate、chain），仅依赖局部通信实现自适应切换。

Result: 大规模仿真和硬件实验验证了MoRoCo在通信受限下的高效、可靠协调能力。

Conclusion: MoRoCo为复杂环境中的人机协同多机器人自主性提供了重要进展。

Abstract: Fleets of autonomous robots are increasingly deployed alongside multiple
human operators to explore unknown environments, identify salient features, and
perform complex tasks in scenarios such as subterranean exploration,
reconnaissance, and search-and-rescue missions. In these contexts,
communication is often severely limited to short-range exchanges via ad-hoc
networks, posing challenges to coordination. While recent studies have
addressed multi-robot exploration under communication constraints, they largely
overlook the essential role of human operators and their real-time interaction
with robotic teams. Operators may demand timely updates on the exploration
progress and robot status, reprioritize or cancel tasks dynamically, or request
live video feeds and control access. Conversely, robots may seek human
confirmation for anomalous events or require help recovering from motion or
planning failures. To enable such bilateral, context-aware interactions under
restricted communication, this work proposes MoRoCo, a unified framework for
online coordination and exploration in multi-operator, multi-robot systems.
MoRoCo enables the team to adaptively switch among three coordination modes:
spread mode for parallelized exploration with intermittent data sharing,
migrate mode for coordinated relocation, and chain mode for maintaining
high-bandwidth connectivity through multi-hop links. These transitions are
managed through distributed algorithms via only local communication. Extensive
large-scale human-in-the-loop simulations and hardware experiments validate the
necessity of incorporating human robot interactions and demonstrate that MoRoCo
enables efficient, reliable coordination under limited communication, marking a
significant step toward robust human-in-the-loop multi-robot autonomy in
challenging environments.

</details>


### [26] [Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning](https://arxiv.org/abs/2508.07686)
*Mingyue Lei,Zewei Zhou,Hongchen Li,Jiaqi Ma,Jia Hu*

Main category: cs.RO

TL;DR: 提出了一种基于风险地图中间件（RiskMM）的可解释协作端到端驾驶框架，解决了单智能体端到端驾驶的遮挡、感知范围限制及黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 现有单智能体端到端驾驶系统因遮挡和感知范围受限导致危险驾驶，且缺乏可解释性。

Method: 通过风险地图学习驾驶数据，构建多智能体时空表示，利用注意力建模环境交互，并结合基于学习的模型预测控制（MPC）模块。

Result: 在V2XPnP-Seq数据集上验证了RiskMM在风险感知轨迹规划和可解释性方面的优越性能。

Conclusion: RiskMM显著提升了协作端到端驾驶框架的性能和可解释性，代码将开源以促进未来研究。

Abstract: End-to-end paradigm has emerged as a promising approach to autonomous
driving. However, existing single-agent end-to-end pipelines are often
constrained by occlusion and limited perception range, resulting in hazardous
driving. Furthermore, their black-box nature prevents the interpretability of
the driving behavior, leading to an untrustworthiness system. To address these
limitations, we introduce Risk Map as Middleware (RiskMM) and propose an
interpretable cooperative end-to-end driving framework. The risk map learns
directly from the driving data and provides an interpretable spatiotemporal
representation of the scenario from the upstream perception and the
interactions between the ego vehicle and the surrounding environment for
downstream planning. RiskMM first constructs a multi-agent spatiotemporal
representation with unified Transformer-based architecture, then derives
risk-aware representations by modeling interactions among surrounding
environments with attention. These representations are subsequently fed into a
learning-based Model Predictive Control (MPC) module. The MPC planner
inherently accommodates physical constraints and different vehicle types and
can provide interpretation by aligning learned parameters with explicit MPC
elements. Evaluations conducted on the real-world V2XPnP-Seq dataset confirm
that RiskMM achieves superior and robust performance in risk-aware trajectory
planning, significantly enhancing the interpretability of the cooperative
end-to-end driving framework. The codebase will be released to facilitate
future research in this field.

</details>


### [27] [Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain](https://arxiv.org/abs/2508.08108)
*Wei Zhang,Yinchuan Wang,Wangtao Lu,Pengyu Zhang,Xiang Zhang,Yue Wang,Chaoqun Wang*

Main category: cs.RO

TL;DR: 提出了一种防倾覆轨迹规划器（CAP），用于在崎岖地形上实现安全高效的导航。


<details>
  <summary>Details</summary>
Motivation: 地面机器人在复杂环境中自主导航时，面临非平凡障碍和崎岖地形的挑战，需平衡安全性和效率。

Method: 分析机器人倾覆稳定性，定义可穿越方向，将其融入轨迹优化的防倾覆安全约束中，并采用图求解器计算轨迹。

Result: 仿真和实验验证了CAP的有效性和鲁棒性，其性能优于现有方法。

Conclusion: CAP显著提升了机器人在崎岖地形上的导航性能。

Abstract: It is a challenging task for ground robots to autonomously navigate in harsh
environments due to the presence of non-trivial obstacles and uneven terrain.
This requires trajectory planning that balances safety and efficiency. The
primary challenge is to generate a feasible trajectory that prevents robot from
tip-over while ensuring effective navigation. In this paper, we propose a
capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the
uneven terrain. The tip-over stability of the robot on rough terrain is
analyzed. Based on the tip-over stability, we define the traversable
orientation, which indicates the safe range of robot orientations. This
orientation is then incorporated into a capsizing-safety constraint for
trajectory optimization. We employ a graph-based solver to compute a robust and
feasible trajectory while adhering to the capsizing-safety constraint.
Extensive simulation and real-world experiments validate the effectiveness and
robustness of the proposed method. The results demonstrate that CAP outperforms
existing state-of-the-art approaches, providing enhanced navigation performance
on uneven terrains.

</details>
