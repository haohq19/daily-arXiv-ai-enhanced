<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 9]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation](https://arxiv.org/abs/2507.01367)
*Tianrui Lou,Xiaojun Jia,Siyuan Liang,Jiawei Liang,Ming Zhang,Yanjun Xiao,Xiaochun Cao*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D高斯溅射（3DGS）的物理攻击框架PGA，用于生成多视角鲁棒的对抗性伪装，解决了现有方法在复杂物理环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于网格先验和虚拟环境的物理攻击方法耗时且与现实世界存在差异，且在多视角鲁棒性和对抗效果上表现不佳。

Method: 利用3DGS快速精确重建目标物体，并通过防止高斯相互遮挡和自遮挡，结合min-max优化调整背景，提升对抗效果和跨视角鲁棒性。

Result: 实验验证了PGA在对抗效果和多视角鲁棒性上的优越性。

Conclusion: PGA框架为物理对抗攻击提供了一种高效且鲁棒的解决方案。

Abstract: Physical adversarial attack methods expose the vulnerabilities of deep neural
networks and pose a significant threat to safety-critical scenarios such as
autonomous driving. Camouflage-based physical attack is a more promising
approach compared to the patch-based attack, offering stronger adversarial
effectiveness in complex physical environments. However, most prior work relies
on mesh priors of the target object and virtual environments constructed by
simulators, which are time-consuming to obtain and inevitably differ from the
real world. Moreover, due to the limitations of the backgrounds in training
images, previous methods often fail to produce multi-view robust adversarial
camouflage and tend to fall into sub-optimal solutions. Due to these reasons,
prior work lacks adversarial effectiveness and robustness across diverse
viewpoints and physical environments. We propose a physical attack framework
based on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and
precise reconstruction with few images, along with photo-realistic rendering
capabilities. Our framework further enhances cross-view robustness and
adversarial effectiveness by preventing mutual and self-occlusion among
Gaussians and employing a min-max optimization approach that adjusts the
imaging background of each viewpoint, helping the algorithm filter out
non-robust adversarial features. Extensive experiments validate the
effectiveness and superiority of PGA. Our code is available
at:https://github.com/TRLou/PGA.

</details>


### [2] [MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing](https://arxiv.org/abs/2507.01384)
*Langyu Wang,Bingke Zhu,Yingying Chen,Yiyuan Zhang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于伪标签增强的音频视觉Mamba网络（MUG），用于改进弱监督音频视觉视频解析任务中的段级和事件级预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在弱监督和模型架构限制下，难以同时提升段级和事件级预测性能。

Method: 通过伪标签增强生成新数据，并采用音频视觉Mamba网络处理特征和模态交互。

Result: 在LLP数据集上，MUG在所有指标上均优于现有方法（如视觉段级和音频段级指标分别提升2.1%和1.2%）。

Conclusion: MUG通过伪标签增强和Mamba网络有效提升了音频视觉视频解析的性能。

Abstract: The weakly-supervised audio-visual video parsing (AVVP) aims to predict all
modality-specific events and locate their temporal boundaries. Despite
significant progress, due to the limitations of the weakly-supervised and the
deficiencies of the model architecture, existing methods are lacking in
simultaneously improving both the segment-level prediction and the event-level
prediction. In this work, we propose a audio-visual Mamba network with pseudo
labeling aUGmentation (MUG) for emphasising the uniqueness of each segment and
excluding the noise interference from the alternate modalities. Specifically,
we annotate some of the pseudo-labels based on previous work. Using unimodal
pseudo-labels, we perform cross-modal random combinations to generate new data,
which can enhance the model's ability to parse various segment-level event
combinations. For feature processing and interaction, we employ a audio-visual
mamba network. The AV-Mamba enhances the ability to perceive different segments
and excludes additional modal noise while sharing similar modal information.
Our extensive experiments demonstrate that MUG improves state-of-the-art
results on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of
visual Segment-level and audio Segment-level metrics). Our code is available at
https://github.com/WangLY136/MUG.

</details>


### [3] [Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware](https://arxiv.org/abs/2507.01472)
*Jonáš Herec,Vít Růžička,Rado Pitoňák*

Main category: cs.CV

TL;DR: 论文提出了一种高效、低功耗的甲烷泄漏检测算法，适用于星载硬件，显著提升了检测速度。


<details>
  <summary>Details</summary>
Motivation: 甲烷是强效温室气体，早期检测有助于减缓气候变化。现有方法计算量大，难以在资源有限的星载硬件上实现。

Method: 测试了快速目标检测方法（ACE、CEM），并提出Mag1c-SAS算法，结合机器学习模型（U-Net、LinkNet）进行验证。

Result: Mag1c-SAS和CEM在检测强羽流时表现良好，计算速度分别比原Mag1c快约100倍和230倍。

Conclusion: 研究为星载甲烷检测提供了高效算法，代码和数据已开源。

Abstract: Methane is a potent greenhouse gas, and detecting its leaks early via
hyperspectral satellite imagery can help mitigate climate change. Meanwhile,
many existing missions operate in manual tasking regimes only, thus missing
potential events of interest. To overcome slow downlink rates cost-effectively,
onboard detection is a viable solution. However, traditional methane
enhancement methods are too computationally demanding for resource-limited
onboard hardware. This work accelerates methane detection by focusing on
efficient, low-power algorithms. We test fast target detection methods (ACE,
CEM) that have not been previously used for methane detection and propose a
Mag1c-SAS - a significantly faster variant of the current state-of-the-art
algorithm for methane detection: Mag1c. To explore their true detection
potential, we integrate them with a machine learning model (U-Net, LinkNet).
Our results identify two promising candidates (Mag1c-SAS and CEM), both
acceptably accurate for the detection of strong plumes and computationally
efficient enough for onboard deployment: one optimized more for accuracy, the
other more for speed, achieving up to ~100x and ~230x faster computation than
original Mag1c on resource-limited hardware. Additionally, we propose and
evaluate three band selection strategies. One of them can outperform the method
traditionally used in the field while using fewer channels, leading to even
faster processing without compromising accuracy. This research lays the
foundation for future advancements in onboard methane detection with minimal
hardware requirements, improving timely data delivery. The produced code, data,
and models are open-sourced and can be accessed from
https://github.com/zaitra/methane-filters-benchmark.

</details>


### [4] [Interpolation-Based Event Visual Data Filtering Algorithms](https://arxiv.org/abs/2507.01557)
*Marcin Kowlaczyk,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种基于无限脉冲响应（IIR）滤波器矩阵的方法，能去除事件相机数据中约99%的噪声，同时保留有效信号，适用于嵌入式设备。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据流中存在显著噪声，影响应用效果，需高效去噪方法。

Method: 提出四种基于IIR滤波器矩阵的算法，并在添加人工噪声和动态视觉传感器噪声的数据集上进行比较。

Result: 方法能去除约99%噪声，内存占用约30KB（1280x720分辨率），适合嵌入式设备。

Conclusion: 该方法高效去噪且资源占用低，适用于事件相机的嵌入式应用。

Abstract: The field of neuromorphic vision is developing rapidly, and event cameras are
finding their way into more and more applications. However, the data stream
from these sensors is characterised by significant noise. In this paper, we
propose a method for event data that is capable of removing approximately 99\%
of noise while preserving the majority of the valid signal. We have proposed
four algorithms based on the matrix of infinite impulse response (IIR) filters
method. We compared them on several event datasets that were further modified
by adding artificially generated noise and noise recorded with dynamic vision
sensor. The proposed methods use about 30KB of memory for a sensor with a
resolution of 1280 x 720 and is therefore well suited for implementation in
embedded devices.

</details>


### [5] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
*Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet*

Main category: cs.CV

TL;DR: Snake-NeRF是一种扩展到大场景的NeRF框架，通过分块处理和优化采样策略，解决了内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法因内存限制仅适用于小场景，无法处理大尺度卫星图像。

Method: 将场景划分为无重叠的3D块，裁剪图像以保留重叠像素，采用2×2 3D块渐进策略和分段采样器。

Result: 实验表明，该方法在单GPU上线性时间处理大卫星图像，且质量无损失。

Conclusion: Snake-NeRF成功扩展了NeRF的应用范围，适用于大场景3D重建。

Abstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D
reconstruction from multiview satellite imagery. However, state-of-the-art NeRF
methods are typically constrained to small scenes due to the memory footprint
during training, which we study in this paper. Previous work on large-scale
NeRFs palliate this by dividing the scene into NeRFs. This paper introduces
Snake-NeRF, a framework that scales to large scenes. Our out-of-core method
eliminates the need to load all images and networks simultaneously, and
operates on a single device. We achieve this by dividing the region of interest
into NeRFs that 3D tile without overlap. Importantly, we crop the images with
overlap to ensure each NeRFs is trained with all the necessary pixels. We
introduce a novel $2\times 2$ 3D tile progression strategy and segmented
sampler, which together prevent 3D reconstruction errors along the tile edges.
Our experiments conclude that large satellite images can effectively be
processed with linear time complexity, on a single GPU, and without compromise
in quality.

</details>


### [6] [SPoT: Subpixel Placement of Tokens in Vision Transformers](https://arxiv.org/abs/2507.01654)
*Martine Hjelkrem-Tan,Marius Aasan,Gabriel Y. Arteaga,Adín Ramírez Rivera*

Main category: cs.CV

TL;DR: SPoT是一种新的标记化策略，通过连续放置标记避免网格限制，显著减少推理所需的标记数量，提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准标记化方法将特征限制在离散的补丁网格中，阻碍了模型在稀疏场景下的潜力。

Method: 提出Subpixel Placement of Tokens (SPoT)，通过连续放置标记并结合oracle-guided搜索优化位置。

Result: SPoT显著减少了推理所需的标记数量，同时提升了性能。

Conclusion: SPoT为ViT架构提供了灵活、高效且可解释的新方向，将稀疏性转化为战略优势。

Abstract: Vision Transformers naturally accommodate sparsity, yet standard tokenization
methods confine features to discrete patch grids. This constraint prevents
models from fully exploiting sparse regimes, forcing awkward compromises. We
propose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that
positions tokens continuously within images, effectively sidestepping
grid-based limitations. With our proposed oracle-guided search, we uncover
substantial performance gains achievable with ideal subpixel token positioning,
drastically reducing the number of tokens necessary for accurate predictions
during inference. SPoT provides a new direction for flexible, efficient, and
interpretable ViT architectures, redefining sparsity as a strategic advantage
rather than an imposed limitation.

</details>


### [7] [HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion](https://arxiv.org/abs/2507.01737)
*Lin Wu,Zhixiang Chen,Jianglin Lan*

Main category: cs.CV

TL;DR: HOI-Dyn框架通过驱动-响应系统生成3D人-物交互，利用轻量级Transformer模型预测物体响应，并通过残差动力学损失提升一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法独立处理人与物运动，导致物理不合理和因果不一致的行为，需改进。

Method: 提出HOI-Dyn框架，将人-物交互建模为驱动-响应系统，使用Transformer预测物体响应，并引入残差动力学损失。

Result: 实验表明，该方法提升了交互生成质量，并提供了可行的评估指标。

Conclusion: HOI-Dyn有效解决了现有方法的不足，提升了3D人-物交互的真实性和一致性。

Abstract: Generating realistic 3D human-object interactions (HOIs) remains a
challenging task due to the difficulty of modeling detailed interaction
dynamics. Existing methods treat human and object motions independently,
resulting in physically implausible and causally inconsistent behaviors. In
this work, we present HOI-Dyn, a novel framework that formulates HOI generation
as a driver-responder system, where human actions drive object responses. At
the core of our method is a lightweight transformer-based interaction dynamics
model that explicitly predicts how objects should react to human motion. To
further enforce consistency, we introduce a residual-based dynamics loss that
mitigates the impact of dynamics prediction errors and prevents misleading
optimization signals. The dynamics model is used only during training,
preserving inference efficiency. Through extensive qualitative and quantitative
experiments, we demonstrate that our approach not only enhances the quality of
HOI generation but also establishes a feasible metric for evaluating the
quality of generated interactions.

</details>


### [8] [Future Slot Prediction for Unsupervised Object Discovery in Surgical Video](https://arxiv.org/abs/2507.01882)
*Guiqiu Liao,Matjaz Jogan,Marcel Hussing,Edward Zhang,Eric Eaton,Daniel A. Hashimoto*

Main category: cs.CV

TL;DR: 提出动态时序槽变换器（DTST）模块，用于解决手术视频中对象中心表示学习的挑战，并在多个手术数据库中实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用（如手术视频）中的异构场景难以解析为有意义的一组槽，现有自适应槽计数方法在手术视频上表现不佳。

Method: 提出动态时序槽变换器（DTST）模块，结合时序推理和预测未来槽初始化的能力。

Result: 在多个手术数据库中实现最先进的性能。

Conclusion: 无监督对象中心方法可应用于真实世界数据，成为医疗应用中的重要工具。

Abstract: Object-centric slot attention is an emerging paradigm for unsupervised
learning of structured, interpretable object-centric representations (slots).
This enables effective reasoning about objects and events at a low
computational cost and is thus applicable to critical healthcare applications,
such as real-time interpretation of surgical video. The heterogeneous scenes in
real-world applications like surgery are, however, difficult to parse into a
meaningful set of slots. Current approaches with an adaptive slot count perform
well on images, but their performance on surgical videos is low. To address
this challenge, we propose a dynamic temporal slot transformer (DTST) module
that is trained both for temporal reasoning and for predicting the optimal
future slot initialization. The model achieves state-of-the-art performance on
multiple surgical databases, demonstrating that unsupervised object-centric
methods can be applied to real-world data and become part of the common arsenal
in healthcare applications.

</details>


### [9] [evMLP: An Efficient Event-Driven MLP Architecture for Vision](https://arxiv.org/abs/2507.01927)
*Zhentan Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种名为evMLP的模型，通过事件驱动的局部更新机制，选择性处理图像或特征图中的变化区域，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 探索多层感知机（MLPs）在视觉模型架构中的应用，并解决视频处理中的冗余计算问题。

Method: 提出evMLP模型，利用事件驱动机制仅处理连续帧间发生变化的图像块。

Result: 在ImageNet分类任务中表现优异，在视频数据集上显著降低计算成本且保持输出一致性。

Conclusion: evMLP通过事件驱动机制有效提升计算效率，为视觉模型架构研究提供了新思路。

Abstract: Deep neural networks have achieved remarkable results in computer vision
tasks. In the early days, Convolutional Neural Networks (CNNs) were the
mainstream architecture. In recent years, Vision Transformers (ViTs) have
become increasingly popular. In addition, exploring applications of multi-layer
perceptrons (MLPs) has provided new perspectives for research into vision model
architectures. In this paper, we present evMLP accompanied by a simple
event-driven local update mechanism. The proposed evMLP can independently
process patches on images or feature maps via MLPs. We define changes between
consecutive frames as "events". Under the event-driven local update mechanism,
evMLP selectively processes patches where events occur. For sequential image
data (e.g., video processing), this approach improves computational performance
by avoiding redundant computations. Through ImageNet image classification
experiments, evMLP attains accuracy competitive with state-of-the-art models.
More significantly, experimental results on multiple video datasets demonstrate
that evMLP reduces computational cost via its event-driven local update
mechanism while maintaining output consistency with its non-event-driven
baseline. The code and trained models are available at
https://github.com/i-evi/evMLP.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals](https://arxiv.org/abs/2507.01045)
*Xiao Gu,Wei Tang,Jinpei Han,Veer Sangha,Fenglin Liu,Shreyank N Gowda,Antonio H. Ribeiro,Patrick Schwab,Kim Branson,Lei Clifton,Antonio Luiz P. Ribeiro,Zhangdaihong Liu,David A. Clifton*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer架构的心脏感知基础模型（CSFM），通过生成式掩码预训练策略从多模态数据中学习统一表示，显著提升了心脏信号分析的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在心脏信号分析中依赖同质数据集和静态定制模型，限制了其在不同临床环境和采集协议中的鲁棒性和泛化能力。

Method: 利用Transformer架构和生成式掩码预训练策略，从多模态数据集（如MIMIC-III-WDB、MIMIC-IV-ECG和CODE）中学习统一表示。

Result: CSFM在诊断任务、人口统计信息识别、生命体征测量、临床结果预测和ECG问答等任务中表现优于传统单模态单任务方法，且在不同传感器配置下均表现出鲁棒性。

Conclusion: CSFM作为一种多功能、可扩展的解决方案，为全面心脏监测提供了潜力。

Abstract: Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms
(PPG), are of paramount importance for the diagnosis, prevention, and
management of cardiovascular diseases, and have been extensively used in a
variety of clinical tasks. Conventional deep learning approaches for analyzing
these signals typically rely on homogeneous datasets and static bespoke models,
limiting their robustness and generalizability across diverse clinical settings
and acquisition protocols. In this study, we present a cardiac sensing
foundation model (CSFM) that leverages advanced transformer architectures and a
generative, masked pretraining strategy to learn unified representations from
vast, heterogeneous health records. Our model is pretrained on an innovative
multi-modal integration of data from multiple large-scale datasets (including
MIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the
corresponding clinical or machine-generated text reports from approximately 1.7
million individuals. We demonstrate that the embeddings derived from our CSFM
not only serve as effective feature extractors across diverse cardiac sensing
scenarios, but also enable seamless transfer learning across varying input
configurations and sensor modalities. Extensive evaluations across diagnostic
tasks, demographic information recognition, vital sign measurement, clinical
outcome prediction, and ECG question answering reveal that CSFM consistently
outperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits
robust performance across multiple ECG lead configurations from standard
12-lead systems to single-lead setups, and in scenarios where only ECG, only
PPG, or a combination thereof is available. These findings highlight the
potential of CSFM as a versatile and scalable solution, for comprehensive
cardiac monitoring.

</details>


### [11] [3W Dataset 2.0.0: a realistic and public dataset with rare undesirable real events in oil wells](https://arxiv.org/abs/2507.01048)
*Ricardo Emanuel Vaz Vargas,Afrânio José de Melo Junior,Celso José Munaro,Cláudio Benevenuto de Campos Lima,Eduardo Toledo de Lima Junior,Felipe Muntzberg Barrocas,Flávio Miguel Varejão,Guilherme Fidelis Peixer,Igor de Melo Nery Oliveira,Jader Riso Barbosa Jr.,Jaime Andrés Lozano Cadena,Jean Carlos Dias de Araújo,João Neuenschwander Escosteguy Carneiro,Lucas Gouveia Omena Lopes,Lucas Pereira de Gouveia,Mateus de Araujo Fernandes,Matheus Lima Scramignon,Patrick Marques Ciarelli,Rodrigo Castello Branco,Rogério Leite Alves Pinto*

Main category: cs.LG

TL;DR: 石油行业中的不良事件可能导致经济损失和环境事故。Petrobras开发的3W数据集为早期检测提供了公开数据支持，最新版本包含更多标注数据和结构改进。


<details>
  <summary>Details</summary>
Motivation: 石油行业不良事件的早期检测缺乏公开数据集，Petrobras开发3W数据集以填补这一空白并支持相关研究。

Method: 通过专家标注的多元时间序列数据构建3W数据集，并持续更新和改进。

Result: 3W数据集成为该领域的基础参考，支持开发新的检测方法和数字产品。

Conclusion: 3W数据集的改进鼓励社区开发更鲁棒的方法，以提前检测不良事件并采取行动。

Abstract: In the oil industry, undesirable events in oil wells can cause economic
losses, environmental accidents, and human casualties. Solutions based on
Artificial Intelligence and Machine Learning for Early Detection of such events
have proven valuable for diverse applications across industries. In 2019,
recognizing the importance and the lack of public datasets related to
undesirable events in oil wells, Petrobras developed and publicly released the
first version of the 3W Dataset, which is essentially a set of Multivariate
Time Series labeled by experts. Since then, the 3W Dataset has been developed
collaboratively and has become a foundational reference for numerous works in
the field. This data article describes the current publicly available version
of the 3W Dataset, which contains structural modifications and additional
labeled data. The detailed description provided encourages and supports the 3W
community and new 3W users to improve previous published results and to develop
new robust methodologies, digital products and services capable of detecting
undesirable events in oil wells with enough anticipation to enable corrective
or mitigating actions.

</details>


### [12] [Evaluating Pavement Deterioration Rates Due to Flooding Events Using Explainable AI](https://arxiv.org/abs/2507.01056)
*Lidan Peng,Lu Gao,Feng Hong,Jingran Sun*

Main category: cs.LG

TL;DR: 研究探讨洪水如何加速路面粗糙度（通过IRI测量）的恶化，结合20年路面数据和洪水事件，利用统计分析和XAI技术（如SHAP和LIME），发现洪水显著增加路面粗糙度，建议采取防洪措施。


<details>
  <summary>Details</summary>
Motivation: 洪水对路面基础设施造成严重损害，需量化其对路面粗糙度的影响，以制定有效的防洪策略。

Method: 结合TxDOT的PMIS数据库20年路面数据和洪水事件数据，进行统计分析，并应用XAI技术（SHAP和LIME）评估洪水影响。

Result: 洪水显著加速路面粗糙度的增加，与非洪水路段相比恶化更快。

Conclusion: 建议采取主动防洪措施（如改进排水系统、使用抗洪材料）以增强路面在易受灾区域的韧性。

Abstract: Flooding can damage pavement infrastructure significantly, causing both
immediate and long-term structural and functional issues. This research
investigates how flooding events affect pavement deterioration, specifically
focusing on measuring pavement roughness by the International Roughness Index
(IRI). To quantify these effects, we utilized 20 years of pavement condition
data from TxDOT's PMIS database, which is integrated with flood event data,
including duration and spatial extent. Statistical analyses were performed to
compare IRI values before and after flooding and to calculate the deterioration
rates influenced by flood exposure. Moreover, we applied Explainable Artificial
Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP) and
Local Interpretable Model-Agnostic Explanations (LIME), to assess the impact of
flooding on pavement performance. The results demonstrate that flood-affected
pavements experience a more rapid increase in roughness compared to non-flooded
sections. These findings emphasize the need for proactive flood mitigation
strategies, including improved drainage systems, flood-resistant materials, and
preventative maintenance, to enhance pavement resilience in vulnerable regions.

</details>


### [13] [Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services](https://arxiv.org/abs/2507.01067)
*Keun Soo Yim*

Main category: cs.LG

TL;DR: 本文优化了一种最先进的基础模型，用于预测高性能机器学习服务中的偶发性或尖峰性生产中断，并与经典随机预测模型进行了比较。


<details>
  <summary>Details</summary>
Motivation: 预测罕见且尖峰性的事件（如生产中断）是一个挑战，基础模型尚未在此类极端事件中得到应用。

Method: 优化基础模型，并与经典随机预测模型（如移动平均和自回归模型）进行比较，分析其预测误差。

Result: 基础模型在预测偶发性或尖峰性事件时表现优于随机模型，并能以小于6%的误差估计年度中断统计数据。

Conclusion: 基础模型在预测罕见事件方面具有潜力，尤其是在优化后能够显著减少预测误差。

Abstract: Time series forecasting models have diverse real world applications (e.g.,
from electricity metrics to software workload). Latest foundational models
trained for time series forecasting show strengths (e.g., for long sequences
and in zero-shot settings). However, foundational model was not yet used for
forecasting rare, spiky events, i.e., a challenging target because those are a
corner case of extreme events. In this paper, we optimize a state-of-the-art
foundational model to forecast sporadic or spiky production outages of
high-performance machine learning services powering billions of client devices.
We evaluate the forecasting errors of the foundational model compared with
classical stochastic forecasting models (e.g., moving average and
autoregressive). The analysis helps us understand how each of the evaluated
models performs for the sporadic or spiky events. For example, it identifies
the key patterns in the target data that are well tracked by the foundational
model vs. each of the stochastic models. We use the models with optimal
parameters to estimate a year-long outage statistics of a particular root cause
with less than 6% value errors.

</details>


### [14] [Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy](https://arxiv.org/abs/2507.01327)
*Xiaoyun Zhang,Jingqing Ruan,Xing Ma,Yawen Zhu,Jiansong Chen,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: 论文提出了一种名为APARL的新框架，利用大语言模型的高级推理能力检测异常事件，显著提升了模型的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决客户服务对话中异常事件检测的复杂性和动态性挑战，同时提升模型的跨领域泛化能力以最大化商业价值。

Method: 采用自适应困惑度感知强化学习（APARL）框架，结合双环动态课程学习架构，逐步提升模型对挑战性样本的处理能力。

Result: 在食品配送对话任务中，APARL显著提升了性能，F1分数平均提高17.19%，跨领域测试平均提升9.59%。

Conclusion: APARL为异常检测模型的工业部署提供了优越解决方案，有助于提升运营效率和商业效益。

Abstract: Detecting abnormal events in real-world customer service dialogues is highly
challenging due to the complexity of business data and the dynamic nature of
customer interactions. Moreover, models must demonstrate strong out-of-domain
(OOD) generalization to enable rapid adaptation across different business
scenarios and maximize commercial value. In this work, we propose a novel
Adaptive Perplexity-Aware Reinforcement Learning (APARL) framework that
leverages the advanced reasoning capabilities of large language models for
abnormal event detection. APARL introduces a dual-loop dynamic curriculum
learning architecture, enabling the model to progressively focus on more
challenging samples as its proficiency increases. This design effectively
addresses performance bottlenecks and significantly enhances OOD
transferability. Extensive evaluations on food delivery dialogue tasks show
that our model achieves significantly enhanced adaptability and robustness,
attaining the highest F1 score with an average improvement of 17.19\%, and an
average improvement of 9.59\% in OOD transfer tests. This method provides a
superior solution for industrial deployment of anomaly detection models,
contributing to improved operational efficiency and commercial benefits.

</details>


### [15] [Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling](https://arxiv.org/abs/2507.01235)
*Bara Rababa,Bilal Farooq*

Main category: cs.LG

TL;DR: 论文探讨了量子机器学习在建模皮肤电导反应（SCR）事件中的应用，比较了量子支持向量机（QSVM）和量子神经网络（QNN）的性能。


<details>
  <summary>Details</summary>
Motivation: 利用量子计算解决复杂机器学习任务，特别是智能交通系统中高维数据表示的挑战。

Method: 开发了基于Pennylane的QSVM（使用八量子位ZZ特征映射）和QNN（使用树张量网络结构和八量子位ZZ特征映射）。

Result: QSVM训练精度高但测试精度低（45%），存在过拟合问题；QNN测试精度更高（55%），优于QSVM和经典模型。

Conclusion: QNN在分类任务中表现更优，为量子机器学习在智能交通系统中的应用提供了潜力。

Abstract: Quantum computing has opened new opportunities to tackle complex machine
learning tasks, for instance, high-dimensional data representations commonly
required in intelligent transportation systems. We explore quantum machine
learning to model complex skin conductance response (SCR) events that reflect
pedestrian stress in a virtual reality road crossing experiment. For this
purpose, Quantum Support Vector Machine (QSVM) with an eight-qubit ZZ feature
map and a Quantum Neural Network (QNN) using a Tree Tensor Network ansatz and
an eight-qubit ZZ feature map, were developed on Pennylane. The dataset
consists of SCR measurements along with features such as the response amplitude
and elapsed time, which have been categorized into amplitude-based classes. The
QSVM achieved good training accuracy, but had an overfitting problem, showing a
low test accuracy of 45% and therefore impacting the reliability of the
classification model. The QNN model reached a higher test accuracy of 55%,
making it a better classification model than the QSVM and the classic versions.

</details>


### [16] [Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals](https://arxiv.org/abs/2507.01470)
*Yannick Molinghen,Tom Lenaerts*

Main category: cs.LG

TL;DR: 论文重新审视了强化学习中奖励频率作为任务难度衡量标准的常见假设，揭示了当前方法在关键子目标无直接奖励时的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是挑战现有强化学习方法的假设，即奖励频率能有效衡量任务难度，尤其是在关键子目标无直接奖励的情况下。

Method: 方法包括形式化零激励动态问题，并分析现有深度子目标算法在此类动态中的表现。

Result: 结果表明，当前算法无法有效利用零激励动态，且学习性能对子目标完成与最终奖励的时间接近性高度敏感。

Conclusion: 结论指出当前方法存在根本性局限，需要开发能推断潜在任务结构而不依赖即时奖励的机制。

Abstract: This work re-examines the commonly held assumption that the frequency of
rewards is a reliable measure of task difficulty in reinforcement learning. We
identify and formalize a structural challenge that undermines the effectiveness
of current policy learning methods: when essential subgoals do not directly
yield rewards. We characterize such settings as exhibiting zero-incentive
dynamics, where transitions critical to success remain unrewarded. We show that
state-of-the-art deep subgoal-based algorithms fail to leverage these dynamics
and that learning performance is highly sensitive to the temporal proximity
between subgoal completion and eventual reward. These findings reveal a
fundamental limitation in current approaches and point to the need for
mechanisms that can infer latent task structure without relying on immediate
incentives.

</details>


### [17] [Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning](https://arxiv.org/abs/2507.01551)
*Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua*

Main category: cs.LG

TL;DR: SPRO是一种自引导过程奖励优化框架，通过内在推导过程奖励和引入累积过程奖励与掩码步骤优势，显著提升训练效率和测试准确性。


<details>
  <summary>Details</summary>
Motivation: 解决过程强化学习中计算开销大和缺乏统一理论框架的问题。

Method: 提出SPRO框架，包括内在推导过程奖励和定义累积过程奖励与掩码步骤优势（MSA）。

Result: SPRO训练效率提高3.4倍，测试准确率提升17.5%，且减少响应长度约1/3。

Conclusion: SPRO在无需额外计算开销的情况下，实现了高效、稳定的过程强化学习。

Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential
in enhancing the reasoning capabilities of Large Language Models~(LLMs).
However, introducing additional process reward models incurs substantial
computational overhead, and there is no unified theoretical framework for
process-level advantage estimation. To bridge this gap, we propose
\textbf{S}elf-Guided \textbf{P}rocess \textbf{R}eward
\textbf{O}ptimization~(\textbf{SPRO}), a novel framework that enables
process-aware RL through two key innovations: (1) we first theoretically
demonstrate that process rewards can be derived intrinsically from the policy
model itself, and (2) we introduce well-defined cumulative process rewards and
\textbf{M}asked \textbf{S}tep \textbf{A}dvantage (\textbf{MSA}), which
facilitates rigorous step-wise action advantage estimation within shared-prompt
sampling groups. Our experimental results demonstrate that SPRO outperforms
vaniila GRPO with 3.4x higher training efficiency and a 17.5\% test accuracy
improvement. Furthermore, SPRO maintains a stable and elevated policy entropy
throughout training while reducing the average response length by approximately
$1/3$, evidencing sufficient exploration and prevention of reward hacking.
Notably, SPRO incurs no additional computational overhead compared to
outcome-supervised RL methods such as GRPO, which benefit industrial
implementation.

</details>


### [18] [Enhanced Generative Model Evaluation with Clipped Density and Coverage](https://arxiv.org/abs/2507.01761)
*Nicolas Salvy,Hugues Talbot,Bertrand Thirion*

Main category: cs.LG

TL;DR: 论文提出两种新指标（Clipped Density和Clipped Coverage），用于更可靠、可解释地评估生成模型样本质量，解决了现有指标在鲁棒性和校准方面的不足。


<details>
  <summary>Details</summary>
Motivation: 生成模型在关键应用中因无法可靠评估样本质量而受限，现有指标缺乏校准或对异常值不够鲁棒。

Method: 通过剪裁单个样本贡献和最近邻球半径，提出Clipped Density和Clipped Coverage指标，防止异常样本影响整体评估。

Result: 新指标在合成和真实数据集上表现出更高的鲁棒性、敏感性和可解释性，优于现有方法。

Conclusion: Clipped Density和Clipped Coverage为生成模型质量评估提供了更可靠和直观的工具。

Abstract: Although generative models have made remarkable progress in recent years,
their use in critical applications has been hindered by their incapacity to
reliably evaluate sample quality. Quality refers to at least two complementary
concepts: fidelity and coverage. Current quality metrics often lack reliable,
interpretable values due to an absence of calibration or insufficient
robustness to outliers. To address these shortcomings, we introduce two novel
metrics, Clipped Density and Clipped Coverage. By clipping individual sample
contributions and, for fidelity, the radii of nearest neighbor balls, our
metrics prevent out-of-distribution samples from biasing the aggregated values.
Through analytical and empirical calibration, these metrics exhibit linear
score degradation as the proportion of poor samples increases. Thus, they can
be straightforwardly interpreted as equivalent proportions of good samples.
Extensive experiments on synthetic and real-world datasets demonstrate that
Clipped Density and Clipped Coverage outperform existing methods in terms of
robustness, sensitivity, and interpretability for evaluating generative models.

</details>


### [19] [Towards Foundation Auto-Encoders for Time-Series Anomaly Detection](https://arxiv.org/abs/2507.01875)
*Gastón García González,Pedro Casas,Emilio Martínez,Alicia Fernández*

Main category: cs.LG

TL;DR: FAE是一种基于变分自编码器和扩张卷积神经网络的时间序列异常检测基础模型，通过大规模预训练实现零样本检测。


<details>
  <summary>Details</summary>
Motivation: 受大型预训练基础模型成功的启发，研究如何利用这些模型处理时间序列数据中的异常检测问题。

Method: 结合变分自编码器（VAEs）和扩张卷积神经网络（DCNNs）构建通用时间序列模型，支持零样本异常检测。

Result: 在多维时间序列数据集（包括移动ISP数据和KDD 2021数据集）上展示了初步结果。

Conclusion: FAE为时间序列异常检测提供了一种通用的基础模型，具有潜在的实际应用价值。

Abstract: We investigate a novel approach to time-series modeling, inspired by the
successes of large pretrained foundation models. We introduce FAE (Foundation
Auto-Encoders), a foundation generative-AI model for anomaly detection in
time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we
mean a model pretrained on massive amounts of time-series data which can learn
complex temporal patterns useful for accurate modeling, forecasting, and
detection of anomalies on previously unseen datasets. FAE leverages VAEs and
Dilated Convolutional Neural Networks (DCNNs) to build a generic model for
univariate time-series modeling, which could eventually perform properly in
out-of-the-box, zero-shot anomaly detection applications. We introduce the main
concepts of FAE, and present preliminary results in different multi-dimensional
time-series datasets from various domains, including a real dataset from an
operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2507.01597)
*Yuehang Si,Zefan Zeng,Jincai Huang,Qing Cheng*

Main category: cs.AI

TL;DR: 论文提出了一种新的TKG推理方法T3DM，通过分布特征建模和对抗训练生成高质量负样本，解决了事件分布偏移和低质量负样本问题。


<details>
  <summary>Details</summary>
Motivation: 现有TKG推理方法在事件分布偏移建模和负样本生成上存在不足，影响了模型的全局一致性和推理质量。

Method: 提出T3DM方法，结合测试时训练引导的分布偏移建模和对抗训练生成高质量负样本。

Result: 实验表明T3DM在多数情况下优于现有基线方法，提供更稳健的结果。

Conclusion: T3DM通过改进分布偏移建模和负样本生成，显著提升了TKG推理的性能和鲁棒性。

Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the
dynamic development of facts along a timeline. Most research on TKG reasoning
(TKGR) focuses on modelling the repetition of global facts and designing
patterns of local historical facts. However, they face two significant
challenges: inadequate modeling of the event distribution shift between
training and test samples, and reliance on random entity substitution for
generating negative samples, which often results in low-quality sampling. To
this end, we propose a novel distributional feature modeling approach for
training TKGR models, Test-Time Training-guided Distribution shift Modelling
(T3DM), to adjust the model based on distribution shift and ensure the global
consistency of model reasoning. In addition, we design a negative-sampling
strategy to generate higher-quality negative quadruples based on adversarial
training. Extensive experiments show that T3DM provides better and more robust
results than the state-of-the-art baselines in most cases.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Event-based evaluation of abstractive news summarization](https://arxiv.org/abs/2507.01160)
*Huiling You,Samia Touileb,Erik Velldal,Lilja Øvrelid*

Main category: cs.CL

TL;DR: 提出了一种基于事件重叠的抽象摘要质量评估方法，通过比较生成摘要、参考摘要和原文的事件重叠来衡量摘要质量。


<details>
  <summary>Details</summary>
Motivation: 传统摘要评估依赖人工参考摘要的相似性评分，但新闻摘要应反映事件信息，因此提出基于事件重叠的评估方法。

Method: 在挪威语数据集上实验，比较生成摘要、参考摘要和原文的事件重叠。

Result: 方法能更深入地分析摘要中的事件信息。

Conclusion: 基于事件重叠的评估方法为摘要质量提供了新视角。

Abstract: An abstractive summary of a news article contains its most important
information in a condensed version. The evaluation of automatically generated
summaries by generative language models relies heavily on human-authored
summaries as gold references, by calculating overlapping units or similarity
scores. News articles report events, and ideally so should the summaries. In
this work, we propose to evaluate the quality of abstractive summaries by
calculating overlapping events between generated summaries, reference
summaries, and the original news articles. We experiment on a richly annotated
Norwegian dataset comprising both events annotations and summaries authored by
expert human annotators. Our approach provides more insight into the event
information contained in the summaries.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [22] [A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods](https://arxiv.org/abs/2507.01143)
*Reza Jalayer,Masoud Jalayer,Amirali Baniasadi*

Main category: cs.RO

TL;DR: 本文综述了机器人领域中的声源定位（SSL）技术，重点介绍了深度学习方法的最新进展，并探讨了当前挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述多关注通用音频应用，未充分考虑机器人领域的限制和深度学习的最新发展。本文旨在填补这一空白。

Method: 回顾了经典方法（如TDOA、波束成形等）和现代深度学习方法（如CNN、CRNN等），并分析了数据与训练策略。

Result: 总结了不同机器人类型和应用领域的研究，并指出当前SSL在环境鲁棒性、多声源处理等方面的挑战。

Conclusion: 提出了未来研究方向，以实现更鲁棒、高效且可解释的深度学习SSL技术。

Abstract: Sound source localization (SSL) adds a spatial dimension to auditory
perception, allowing a system to pinpoint the origin of speech, machinery
noise, warning tones, or other acoustic events, capabilities that facilitate
robot navigation, human-machine dialogue, and condition monitoring. While
existing surveys provide valuable historical context, they typically address
general audio applications and do not fully account for robotic constraints or
the latest advancements in deep learning. This review addresses these gaps by
offering a robotics-focused synthesis, emphasizing recent progress in deep
learning methodologies. We start by reviewing classical methods such as Time
Difference of Arrival (TDOA), beamforming, Steered-Response Power (SRP), and
subspace analysis. Subsequently, we delve into modern machine learning (ML) and
deep learning (DL) approaches, discussing traditional ML and neural networks
(NNs), convolutional neural networks (CNNs), convolutional recurrent neural
networks (CRNNs), and emerging attention-based architectures. The data and
training strategy that are the two cornerstones of DL-based SSL are explored.
Studies are further categorized by robot types and application domains to
facilitate researchers in identifying relevant work for their specific
contexts. Finally, we highlight the current challenges in SSL works in general,
regarding environmental robustness, sound source multiplicity, and specific
implementation constraints in robotics, as well as data and learning strategies
in DL-based SSL. Also, we sketch promising directions to offer an actionable
roadmap toward robust, adaptable, efficient, and explainable DL-based SSL for
next-generation robots.

</details>


### [23] [LLM-based Realistic Safety-Critical Driving Video Generation](https://arxiv.org/abs/2507.01264)
*Yongjie Fu,Ruijian Zha,Pei Tian,Xuan Di*

Main category: cs.RO

TL;DR: 提出了一种利用大语言模型（LLMs）生成驾驶场景代码的框架，结合CARLA模拟器和视频生成技术，用于自动驾驶系统的安全测试。


<details>
  <summary>Details</summary>
Motivation: 设计多样且安全的驾驶场景对自动驾驶系统评估至关重要，但手动生成复杂场景效率低。

Method: 通过LLMs基于少量示例生成场景脚本，结合CARLA模拟器和视频生成技术（Cosmos-Transfer1与ControlNet）实现真实感视频转换。

Result: 实验证明该方法能生成多样、真实且安全关键的驾驶场景，尤其是罕见边缘案例。

Conclusion: 该框架为自动驾驶模拟测试提供了高效且可控的场景生成工具。

Abstract: Designing diverse and safety-critical driving scenarios is essential for
evaluating autonomous driving systems. In this paper, we propose a novel
framework that leverages Large Language Models (LLMs) for few-shot code
generation to automatically synthesize driving scenarios within the CARLA
simulator, which has flexibility in scenario scripting, efficient code-based
control of traffic participants, and enforcement of realistic physical
dynamics. Given a few example prompts and code samples, the LLM generates
safety-critical scenario scripts that specify the behavior and placement of
traffic participants, with a particular focus on collision events. To bridge
the gap between simulation and real-world appearance, we integrate a video
generation pipeline using Cosmos-Transfer1 with ControlNet, which converts
rendered scenes into realistic driving videos. Our approach enables
controllable scenario generation and facilitates the creation of rare but
critical edge cases, such as pedestrian crossings under occlusion or sudden
vehicle cut-ins. Experimental results demonstrate the effectiveness of our
method in generating a wide range of realistic, diverse, and safety-critical
scenarios, offering a promising tool for simulation-based testing of autonomous
vehicles.

</details>


### [24] [Towards Design and Development of a Concentric Tube Steerable Drilling Robot for Creating S-shape Tunnels for Pelvic Fixation Procedures](https://arxiv.org/abs/2507.01811)
*Yash Kulkarni,Susheela Sharma,Sarah Go,Jordan P. Amadio,Mohsen Khadem,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 提出了一种新型4自由度骨盆同心管可转向钻孔机器人（pelvic CT-SDR），用于解决传统刚性钻孔工具在骨盆固定中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性钻孔工具限制了螺钉的放置路径，导致手术并发症增加，如螺钉错位、手术时间延长和辐射暴露增加。

Method: 设计并开发了一种4自由度的骨盆同心管可转向钻孔机器人，能够实现S形钻孔路径。

Result: 在模拟骨模型上进行了S形钻孔实验，验证了机器人的性能。

Conclusion: 该机器人能够遵循骨盆自然曲率，优化螺钉放置路径，减少并发症。

Abstract: Current pelvic fixation techniques rely on rigid drilling tools, which
inherently constrain the placement of rigid medical screws in the complex
anatomy of pelvis. These constraints prevent medical screws from following
anatomically optimal pathways and force clinicians to fixate screws in linear
trajectories. This suboptimal approach, combined with the unnatural placement
of the excessively long screws, lead to complications such as screw
misplacement, extended surgery times, and increased radiation exposure due to
repeated X-ray images taken ensure to safety of procedure. To address these
challenges, in this paper, we present the design and development of a unique 4
degree-of-freedom (DoF) pelvic concentric tube steerable drilling robot (pelvic
CT-SDR). The pelvic CT-SDR is capable of creating long S-shaped drilling
trajectories that follow the natural curvatures of the pelvic anatomy. The
performance of the pelvic CT-SDR was thoroughly evaluated through several
S-shape drilling experiments in simulated bone phantoms.

</details>
