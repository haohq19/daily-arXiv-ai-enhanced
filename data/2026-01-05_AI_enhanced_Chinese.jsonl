{"id": "2601.00123", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00123", "abs": "https://arxiv.org/abs/2601.00123", "authors": ["Hyunho Lee", "Wenwen Li"], "title": "A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data", "comment": "50 pages, 12 figures, 6 tables", "summary": "Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.", "AI": {"tldr": "\u63d0\u51faSMAGNet\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408SAR\u548cMSI\u6570\u636e\u63d0\u5347\u6d2a\u6c34\u6df9\u6ca1\u8303\u56f4\u5236\u56fe\u7cbe\u5ea6\uff0c\u5373\u4f7f\u5728MSI\u6570\u636e\u7f3a\u5931\u65f6\u4ecd\u4fdd\u6301\u7a33\u5065\u6027\u80fd", "motivation": "\u6d2a\u6c34\u671f\u95f4\u53ca\u65f6\u51c6\u786e\u7684\u6c34\u57df\u8303\u56f4\u5236\u56fe\u5bf9\u707e\u5bb3\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136SAR\u6570\u636e\u5e38\u7528\u4e8e\u6d2a\u6c34\u54cd\u5e94\uff0c\u4f46\u7ed3\u5408MSI\u6570\u636e\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u63d0\u5347\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u6d2a\u6c34\u9ad8\u5cf0\u671f\u89c2\u6d4b\u6570\u636e\u6709\u9650\u65f6\u3002\u7136\u800c\uff0c\u5982\u4f55\u81ea\u9002\u5e94\u6574\u5408\u90e8\u5206\u53ef\u7528\u7684MSI\u6570\u636e\u5230SAR\u5236\u56fe\u6d41\u7a0b\u4e2d\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faSMAGNet\uff08\u7a7a\u95f4\u63a9\u7801\u81ea\u9002\u5e94\u95e8\u63a7\u7f51\u7edc\uff09\uff0c\u4e00\u79cd\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff1a\u4ee5SAR\u6570\u636e\u4e3a\u4e3b\u8981\u8f93\u5165\u8fdb\u884c\u6d2a\u6c34\u540e\u6c34\u57df\u8303\u56f4\u5236\u56fe\uff0c\u901a\u8fc7\u7279\u5f81\u878d\u5408\u6574\u5408\u4e92\u8865\u7684MSI\u6570\u636e\u3002\u6a21\u578b\u80fd\u81ea\u9002\u5e94\u5904\u7406\u4e0d\u540c\u53ef\u7528\u7a0b\u5ea6\u7684MSI\u6570\u636e\u3002", "result": "\u5728C2S-MS Floods\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cSMAGNet\u5728\u4e0d\u540cMSI\u6570\u636e\u53ef\u7528\u6027\u6c34\u5e73\u4e0b\u5747\u4f18\u4e8e\u5176\u4ed6\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002\u5373\u4f7fMSI\u6570\u636e\u5b8c\u5168\u7f3a\u5931\uff0cSMAGNet\u6027\u80fd\u4ecd\u4e0e\u4ec5\u4f7f\u7528SAR\u6570\u636e\u8bad\u7ec3\u7684U-Net\u6a21\u578b\u7edf\u8ba1\u76f8\u5f53\u3002", "conclusion": "SMAGNet\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u7f3a\u5931\u6570\u636e\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u5728\u771f\u5b9e\u6d2a\u6c34\u7ba1\u7406\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4e3a\u707e\u5bb3\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.00175", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00175", "abs": "https://arxiv.org/abs/2601.00175", "authors": ["Zhuqi Miao", "Sujan Ravi", "Abdulaziz Ahmed"], "title": "Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score", "comment": null, "summary": "Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.", "AI": {"tldr": "\u57fa\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u809d\u786c\u5316\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edfFIB-4\u8bc4\u5206\uff0c\u80fd\u591f\u63d0\u524d1-3\u5e74\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u98ce\u9669\u5206\u5c42\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5229\u7528\u5e38\u89c4\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u65e9\u671f\u9884\u6d4b\u809d\u786c\u5316\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u6539\u5584\u809d\u786c\u5316\u9884\u9632\u548c\u7ba1\u7406\uff0c\u5e76\u8d85\u8d8a\u4f20\u7edfFIB-4\u8bc4\u5206\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5927\u578b\u5b66\u672f\u533b\u7597\u7cfb\u7edf\u7684\u53bb\u6807\u8bc6\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u8fdb\u884c\u56de\u987e\u6027\u961f\u5217\u7814\u7a76\uff0c\u8bc6\u522b\u8102\u80aa\u809d\u60a3\u8005\u5e76\u6839\u636eICD-9/10\u7f16\u7801\u5206\u4e3a\u809d\u786c\u5316\u548c\u975e\u809d\u786c\u5316\u961f\u5217\u3002\u6784\u5efa\u89c2\u5bdf\u7a97\u53e3\u548c\u9884\u6d4b\u7a97\u53e3\u6a21\u62df\u4e34\u5e8a\u5b9e\u9645\u4f7f\u7528\u573a\u666f\uff0c\u6574\u5408\u4eba\u53e3\u7edf\u8ba1\u5b66\u3001\u8bca\u65ad\u3001\u5b9e\u9a8c\u5ba4\u7ed3\u679c\u3001\u751f\u547d\u4f53\u5f81\u548c\u5171\u75c5\u6307\u6570\u7b49\u7279\u5f81\uff0c\u8bad\u7ec3XGBoost\u6a21\u578b\u8fdb\u884c1\u5e74\u30012\u5e74\u548c3\u5e74\u9884\u6d4b\uff0c\u5e76\u4e0eFIB-4\u8bc4\u5206\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "XGBoost\u6a21\u578b\u57281\u5e74\u30012\u5e74\u548c3\u5e74\u9884\u6d4b\u4e2d\u5206\u522b\u83b7\u5f970.81\u30010.73\u548c0.69\u7684AUC\u503c\uff0c\u663e\u8457\u4f18\u4e8eFIB-4\u76840.71\u30010.63\u548c0.57\u3002\u968f\u7740\u9884\u6d4b\u65f6\u95f4\u5ef6\u957f\uff0c\u6027\u80fd\u4f18\u52bf\u66f4\u52a0\u660e\u663e\uff0c\u8868\u660e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u65e9\u671f\u98ce\u9669\u8bc6\u522b\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u5e38\u89c4\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u809d\u786c\u5316\u65e9\u671f\u9884\u6d4b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edfFIB-4\u8bc4\u5206\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u65e9\u3001\u66f4\u51c6\u786e\u7684\u98ce\u9669\u5206\u5c42\uff0c\u53ef\u4f5c\u4e3a\u81ea\u52a8\u5316\u51b3\u7b56\u652f\u6301\u5de5\u5177\u96c6\u6210\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u652f\u6301\u4e3b\u52a8\u7684\u809d\u786c\u5316\u9884\u9632\u548c\u7ba1\u7406\u3002"}}
{"id": "2601.00702", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00702", "abs": "https://arxiv.org/abs/2601.00702", "authors": ["Samuel Cerezo", "Javier Civera"], "title": "DefVINS: Visual-Inertial Odometry for Deformable Scenes", "comment": "4 figures, 3 tables. Submitted to RA-L", "summary": "Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.", "AI": {"tldr": "DefVINS\uff1a\u4e00\u79cd\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u53d8\u5f62\u56fe\u663e\u5f0f\u5206\u79bb\u521a\u6027IMU\u951a\u5b9a\u72b6\u6001\u4e0e\u975e\u521a\u6027\u53d8\u5f62\uff0c\u63d0\u9ad8\u975e\u521a\u6027\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027", "motivation": "\u53ef\u53d8\u5f62\u573a\u666f\u8fdd\u53cd\u4e86\u7ecf\u5178\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\uff08VIO\uff09\u7684\u521a\u6027\u5047\u8bbe\uff0c\u5bfc\u81f4\u5bf9\u5c40\u90e8\u975e\u521a\u6027\u8fd0\u52a8\u7684\u8fc7\u62df\u5408\u6216\u5728\u53d8\u5f62\u4e3b\u5bfc\u89c6\u89c9\u89c6\u5dee\u65f6\u4ea7\u751f\u4e25\u91cd\u6f02\u79fb", "method": "\u4f7f\u7528\u5d4c\u5165\u53d8\u5f62\u56fe\u663e\u5f0f\u5206\u79bb\u521a\u6027IMU\u951a\u5b9a\u72b6\u6001\u4e0e\u975e\u521a\u6027\u53d8\u5f62\uff0c\u901a\u8fc7\u53ef\u89c2\u6d4b\u6027\u5206\u6790\u6307\u5bfc\u53d8\u5f62\u6fc0\u6d3b\u7b56\u7565\uff0c\u6e10\u8fdb\u6fc0\u6d3b\u975e\u521a\u6027\u81ea\u7531\u5ea6", "result": "\u7ed3\u5408\u60ef\u6027\u7ea6\u675f\u4e0e\u53ef\u89c2\u6d4b\u6027\u611f\u77e5\u7684\u53d8\u5f62\u6fc0\u6d3b\u7b56\u7565\uff0c\u5728\u975e\u521a\u6027\u73af\u5883\u4e0b\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027", "conclusion": "DefVINS\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5206\u79bb\u521a\u6027\u8fd0\u52a8\u4e0e\u975e\u521a\u6027\u53d8\u5f62\uff0c\u7ed3\u5408\u60ef\u6027\u6d4b\u91cf\u4e0e\u53ef\u89c2\u6d4b\u6027\u5206\u6790\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u53d8\u5f62\u573a\u666f\u4e2d\u7684VIO\u95ee\u9898"}}
{"id": "2601.00430", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00430", "abs": "https://arxiv.org/abs/2601.00430", "authors": ["Kian Ahrabian", "Eric Boxer", "Jay Pujara"], "title": "Toward Better Temporal Structures for Geopolitical Events Forecasting", "comment": "17 pages, 13 figures, 3 tables", "summary": "Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u8868\u793a\u6846\u67b6HTKGHs\uff0c\u7528\u4e8e\u5904\u7406\u5305\u542b\u591a\u4e2a\u4e3b\u8981\u5b9e\u4f53\u7684\u590d\u6742\u65f6\u6001\u4e8b\u5b9e\uff0c\u5e76\u57fa\u4e8ePOLECAT\u6570\u636e\u5e93\u6784\u5efa\u4e86htkgh-polecat\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u9884\u6d4b\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8d85\u5173\u7cfb\u65f6\u6001\u77e5\u8bc6\u56fe(HTKGs)\u5728\u8868\u793a\u590d\u6742\u65f6\u6001\u4e8b\u5b9e\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u65e0\u6cd5\u652f\u6301\u5305\u542b\u4e24\u4e2a\u4ee5\u4e0a\u4e3b\u8981\u5b9e\u4f53\u7684\u65f6\u6001\u4e8b\u5b9e\uff0c\u800c\u8fd9\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5730\u7f18\u653f\u6cbb\u4e8b\u4ef6\u4e2d\u5f88\u5e38\u89c1\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5f3a\u5927\u7684\u8868\u793a\u6846\u67b6\u6765\u5904\u7406\u8fd9\u7c7b\u590d\u6742\u4e8b\u4ef6\u3002", "method": "1. \u63d0\u51fa\u4e86HTKGHs\uff08\u8d85\u5173\u7cfb\u65f6\u6001\u77e5\u8bc6\u5e7f\u4e49\u8d85\u56fe\uff09\u4f5c\u4e3aHTKGs\u7684\u6cdb\u5316\u5f62\u5f0f\uff0c\u652f\u6301\u5730\u7f18\u653f\u6cbb\u4e8b\u4ef6\u4e2d\u5e38\u89c1\u7684\u4e24\u79cd\u590d\u6742\u4e8b\u5b9e\u7c7b\u578b\n2. \u5efa\u7acb\u4e86HTKGHs\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u786e\u4fdd\u5411\u540e\u517c\u5bb9\u6027\n3. \u57fa\u4e8e\u5168\u7403\u4e8b\u4ef6\u6570\u636e\u5e93POLECAT\u6784\u5efa\u4e86htkgh-polecat\u6570\u636e\u96c6\n4. \u5728\u5173\u7cfb\u9884\u6d4b\u4efb\u52a1\u4e0a\u5bf9\u6d41\u884c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u548c\u5206\u6790", "result": "1. \u6210\u529f\u5f62\u5f0f\u5316\u4e86HTKGHs\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u8868\u793a\u5305\u542b\u591a\u4e2a\u4e3b\u8981\u5b9e\u4f53\u7684\u590d\u6742\u65f6\u6001\u4e8b\u5b9e\n2. \u521b\u5efa\u4e86htkgh-polecat\u6570\u636e\u96c6\uff0c\u4e3a\u590d\u6742\u65f6\u6001\u77e5\u8bc6\u8868\u793a\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\n3. \u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u83b7\u5f97\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u9884\u6d4b\u573a\u666f\u4e2d\u7684\u9002\u5e94\u6027\u548c\u80fd\u529b\u6d1e\u5bdf", "conclusion": "HTKGHs\u4e3a\u8868\u793a\u590d\u6742\u65f6\u6001\u4e8b\u5b9e\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u5730\u7f18\u653f\u6cbb\u4e8b\u4ef6\u5206\u6790\u4e2d\u3002\u901a\u8fc7\u6784\u5efahtkgh-polecat\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u590d\u6742\u65f6\u6001\u77e5\u8bc6\u8868\u793a\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.00391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00391", "abs": "https://arxiv.org/abs/2601.00391", "authors": ["Nouar AlDahoul", "Aznul Qalid Md Sabri", "Ali Mohammed Mansoor"], "title": "Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models", "comment": null, "summary": "Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u5149\u6d41\u548c\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08S-CNN\u3001\u9884\u8bad\u7ec3CNN\u7279\u5f81\u63d0\u53d6\u5668\u3001H-ELM\uff09\u7528\u4e8e\u65e0\u4eba\u673a\u89c6\u9891\u4e2d\u7684\u4eba\u4f53\u68c0\u6d4b\uff0c\u5728UCF-ARG\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u624b\u5de5\u7279\u5f81\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5bf9\u5149\u7167\u53d8\u5316\u3001\u76f8\u673a\u6296\u52a8\u7b49\u52a8\u6001\u4e8b\u4ef6\u654f\u611f\u3002\u9700\u8981\u66f4\u4fbf\u5b9c\u3001\u81ea\u52a8\u5316\u7684\u7279\u5f81\u5b66\u4e60\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u65e0\u4eba\u673a\u975e\u9759\u6001\u76f8\u673a\u62cd\u6444\u7684\u590d\u6742\u89c6\u9891\u4e2d\u68c0\u6d4b\u4eba\u4f53\u3002", "method": "\u7ed3\u5408\u5149\u6d41\u548c\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff1a1\uff09\u76d1\u7763\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08S-CNN\uff09\uff0c2\uff09\u9884\u8bad\u7ec3CNN\u7279\u5f81\u63d0\u53d6\u5668\uff0c3\uff09\u5206\u5c42\u6781\u9650\u5b66\u4e60\u673a\uff08H-ELM\uff09\u3002\u5728UCF-ARG\u65e0\u4eba\u673a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e94\u79cd\u4eba\u4f53\u52a8\u4f5c\u3002", "result": "\u9884\u8bad\u7ec3CNN\u5e73\u5747\u51c6\u786e\u738798.09%\uff0cS-CNN\u4f7f\u7528softmax\u8fbe95.6%\uff08SVM\u4e3a91.7%\uff09\uff0cH-ELM\u8fbe95.9%\u3002H-ELM\u5728CPU\u4e0a\u8bad\u7ec3445\u79d2\uff0cS-CNN\u5728GPU\u4e0a\u8bad\u7ec3770\u79d2\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u52a8\u7279\u5f81\u5b66\u4e60\u65b9\u6cd5\u5728\u65e0\u4eba\u673a\u89c6\u9891\u4eba\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u6210\u529f\uff0c\u9884\u8bad\u7ec3CNN\u6548\u679c\u6700\u4f73\uff0cH-ELM\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2601.00455", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00455", "abs": "https://arxiv.org/abs/2601.00455", "authors": ["Amit Daniely"], "title": "Deep Networks Learn Deep Hierarchical Models", "comment": null, "summary": "We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \\subseteq L_2 \\subseteq \\dots \\subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.\n  Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.\n  Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers\" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6b8b\u5dee\u7f51\u7edc\u4e2d\u5206\u5c42SGD\u5982\u4f55\u9ad8\u6548\u5b66\u4e60\u5c42\u6b21\u5316\u6807\u7b7e\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5177\u6709\u591a\u9879\u5f0f\u6df1\u5ea6\u8868\u8fbe\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u4e4b\u524d\u53ef\u5b66\u4e60\u7684\u5bf9\u6570\u6df1\u5ea6\u6a21\u578b\uff0c\u4e3a\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u5b66\u4e60\u4e3a\u4f55\u80fd\u9ad8\u6548\u5b66\u4e60\u590d\u6742\u51fd\u6570\uff0c\u7279\u522b\u662f\u63a2\u7d22\u6b8b\u5dee\u7f51\u7edc\u80fd\u5426\u5b66\u4e60\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u6807\u7b7e\u6a21\u578b\u3002\u4f5c\u8005\u8ba4\u4e3a\u4eba\u7c7b\u6559\u5e08\u63d0\u4f9b\u7684\u7ec6\u7c92\u5ea6\u6807\u7b7e\u63ed\u793a\u4e86\u5927\u8111\u5185\u90e8\u7b97\u6cd5\u7684\"\u63d0\u793a\"\uff0c\u8fd9\u79cd\u5c42\u6b21\u7ed3\u6784\u53ef\u80fd\u662f\u6df1\u5ea6\u5b66\u4e60\u6210\u529f\u7684\u5173\u952e\u3002", "method": "\u91c7\u7528\u6b8b\u5dee\u7f51\u7edc\u548c\u5206\u5c42SGD\u7b97\u6cd5\uff0c\u5b66\u4e60\u5177\u6709\u672a\u77e5\u6807\u7b7e\u5c42\u6b21\u7ed3\u6784\u7684\u6a21\u578b\uff1aL\u2081 \u2286 L\u2082 \u2286 ... \u2286 L\u1d63 = [n]\uff0c\u5176\u4e2dL\u2081\u4e2d\u7684\u6807\u7b7e\u662f\u8f93\u5165\u7684\u7b80\u5355\u51fd\u6570\uff0c\u800ci>1\u65f6\uff0cL\u1d62\u4e2d\u7684\u6807\u7b7e\u662f\u66f4\u7b80\u5355\u6807\u7b7e\u7684\u7b80\u5355\u51fd\u6570\u3002", "result": "\u8bc1\u660e\u4e86\u6b8b\u5dee\u7f51\u7edc\u4e2d\u7684\u5206\u5c42SGD\u80fd\u591f\u9ad8\u6548\u5b66\u4e60\u8fd9\u7c7b\u5c42\u6b21\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u8fbe\u5230\u4e86\u9ad8\u6548\u53ef\u5b66\u4e60\u6027\u7684\u6df1\u5ea6\u6781\u9650\uff0c\u9700\u8981\u591a\u9879\u5f0f\u6df1\u5ea6\u6765\u8868\u8fbe\uff0c\u800c\u4e4b\u524d\u7684\u6a21\u578b\u53ea\u80fd\u7531\u5bf9\u6570\u6df1\u5ea6\u7535\u8def\u8ba1\u7b97\u3002", "conclusion": "\u5c42\u6b21\u5316\u6a21\u578b\u7684\u5b66\u4e60\u80fd\u529b\u53ef\u80fd\u6700\u7ec8\u6210\u4e3a\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u7840\u3002\u4eba\u7c7b\u6559\u5e08\u7684\u5b58\u5728\u652f\u6301\u4e86\u5c42\u6b21\u7ed3\u6784\u81ea\u7136\u53ef\u7528\u7684\u5047\u8bbe\uff0c\u901a\u8fc7\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u6807\u7b7e\uff0c\u6559\u5e08\u6709\u6548\u63ed\u793a\u4e86\u5927\u8111\u5185\u90e8\u7b97\u6cd5\u7684\"\u63d0\u793a\"\uff0c\u8fd9\u79cd\u5f62\u5f0f\u5316\u7684\u76f4\u89c9\u8868\u660e\u5c42\u6b21\u7ed3\u6784\u4fc3\u8fdb\u4e86\u9ad8\u6548\u5b66\u4e60\u3002"}}
{"id": "2601.00459", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00459", "abs": "https://arxiv.org/abs/2601.00459", "authors": ["Saurav Sengupta", "Scott Kilianski", "Suchetha Sharma", "Sakina Lashkeri", "Ashley McHugh", "Mark Beenhakker", "Donald E. Brown"], "title": "Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet", "comment": null, "summary": "The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called \"Twin Peaks\". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86AugUNet1D\uff0c\u4e00\u79cd\u57fa\u4e8e1D UNet\u5e76\u91c7\u7528\u6570\u636e\u589e\u5f3a\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u52a8\u6807\u8bb0\u8111\u7535\u56fe\u4e2d\u7684\u68d8\u6162\u6ce2\u653e\u7535\uff0c\u5728961\u5c0f\u65f6\u5c0f\u9f20EEG\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u548c14\u79cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u3002", "motivation": "\u624b\u52a8\u6807\u8bb0\u8111\u7535\u56fe\u4e8b\u4ef6\uff08\u7279\u522b\u662f\u68d8\u6162\u6ce2\u653e\u7535\uff09\u8017\u65f6\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u5c24\u5176\u662f\u5728\u8fde\u7eed\u6570\u5468\u81f3\u6570\u6708\u7684\u8bb0\u5f55\u4e2d\u3002\u73b0\u6709\u81ea\u52a8\u6807\u8bb0\u65b9\u6cd5\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u51c6\u786e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u6bd4\u8f8314\u79cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u5728961\u5c0f\u65f6\u5c0f\u9f20EEG\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff1b2. \u9009\u62e9\u8868\u73b0\u6700\u4f73\u76841D UNet\u8fdb\u884c\u6539\u8fdb\uff1b3. \u901a\u8fc7\u6570\u636e\u589e\u5f3a\uff08\u7279\u522b\u662f\u7f29\u653e\u589e\u5f3a\uff09\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff1b4. \u5c06\u589e\u5f3a\u540e\u7684AugUNet1D\u4e0e\"Twin Peaks\"\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "1D UNet\u572814\u79cd\u5206\u7c7b\u5668\u4e2d\u8868\u73b0\u6700\u4f73\uff1b\u6570\u636e\u589e\u5f3a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5176\u4e2d\u7f29\u653e\u589e\u5f3a\u6548\u679c\u6700\u660e\u663e\uff1bAugUNet1D\u5728\u68c0\u6d4bSWD\u65b9\u9762\u4f18\u4e8e\"Twin Peaks\"\u7b97\u6cd5\uff0c\u68c0\u6d4b\u5230\u7684\u4e8b\u4ef6\u7279\u5f81\u66f4\u63a5\u8fd1\u4eba\u5de5\u6807\u8bb0\u3002", "conclusion": "AugUNet1D\u662f\u81ea\u52a8\u6807\u8bb0EEG\u4e2d\u68d8\u6162\u6ce2\u653e\u7535\u7684\u6709\u6548\u5de5\u5177\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u7814\u7a76\u8005\u516c\u5f00\u4e86\u9884\u8bad\u7ec3\u548c\u672a\u8bad\u7ec3\u7684\u6a21\u578b\u4f9b\u5176\u4ed6\u7528\u6237\u4f7f\u7528\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2601.00554", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00554", "abs": "https://arxiv.org/abs/2601.00554", "authors": ["Lennon Shikhman"], "title": "Entropy Production in Machine Learning Under Fokker-Planck Probability Flow", "comment": "10 pages, 3 figures. Submitted for journal review", "summary": "Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u71b5\u7684\u518d\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u6570\u636e\u6f02\u79fb\u5efa\u6a21\u4e3a\u6982\u7387\u6d41\uff0c\u901a\u8fc7\u71b5\u5e73\u8861\u5206\u89e3\u89e6\u53d1\u518d\u8bad\u7ec3\uff0c\u5728\u975e\u5e73\u7a33\u5206\u7c7b\u4efb\u52a1\u4e2d\u663e\u8457\u51cf\u5c11\u518d\u8bad\u7ec3\u6b21\u6570\u540c\u65f6\u4fdd\u6301\u6027\u80fd", "motivation": "\u73b0\u6709\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u52a8\u529b\u5b66\u539f\u7406\u89e3\u91ca\uff0c\u65e0\u6cd5\u6307\u5bfc\u518d\u8bad\u7ec3\u9891\u7387\u4e0e\u8fd0\u8425\u6210\u672c\u7684\u5e73\u8861\u3002\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u539f\u7406\u7684\u6846\u67b6\u6765\u5e94\u5bf9\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u6570\u636e\u6f02\u79fb\u95ee\u9898\u3002", "method": "\u5c06\u90e8\u7f72\u65f6\u6570\u636e\u6f02\u79fb\u5efa\u6a21\u4e3aFokker-Planck\u65b9\u7a0b\u63a7\u5236\u7684\u6982\u7387\u6d41\uff0c\u4f7f\u7528\u968f\u65f6\u95f4\u6f14\u5316\u7684KL\u6563\u5ea6\u91cf\u6a21\u578b-\u6570\u636e\u4e0d\u5339\u914d\uff0c\u901a\u8fc7\u71b5\u5e73\u8861\u5206\u89e3\uff08\u5305\u542b\u975e\u8d1f\u71b5\u4ea7\u751f\u9879\uff09\u89e6\u53d1\u518d\u8bad\u7ec3", "result": "\u5728\u53d7\u63a7\u975e\u5e73\u7a33\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u57fa\u4e8e\u71b5\u89e6\u53d1\u7684\u518d\u8bad\u7ec3\u5b9e\u73b0\u4e86\u4e0e\u9ad8\u9891\u518d\u8bad\u7ec3\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u76f8\u5bf9\u4e8e\u6bcf\u65e5\u548c\u57fa\u4e8e\u6807\u7b7e\u7684\u7b56\u7565\u51cf\u5c11\u4e86\u6570\u91cf\u7ea7\u7684\u518d\u8bad\u7ec3\u4e8b\u4ef6", "conclusion": "\u57fa\u4e8e\u71b5\u7684\u518d\u8bad\u7ec3\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u6807\u7b7e\u5e72\u9884\u7b56\u7565\uff0c\u54cd\u5e94\u7d2f\u79ef\u7684\u4e0d\u5339\u914d\u800c\u975e\u5ef6\u8fdf\u7684\u6027\u80fd\u5d29\u6e83\uff0c\u4e3a\u5e73\u8861\u518d\u8bad\u7ec3\u9891\u7387\u4e0e\u8fd0\u8425\u6210\u672c\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u6307\u5bfc"}}
{"id": "2601.00756", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00756", "abs": "https://arxiv.org/abs/2601.00756", "authors": ["Thomas Katraouras", "Dimitrios Rafailidis"], "title": "Memory Bank Compression for Continual Adaptation of Large Language Models", "comment": "Accepted to the 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26)", "summary": "Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.", "AI": {"tldr": "MBC\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7801\u672c\u4f18\u5316\u7b56\u7565\u538b\u7f29\u8bb0\u5fc6\u5e93\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u5728\u7ebf\u91cd\u7f6e\u673a\u5236\u9632\u6b62\u7801\u672c\u574d\u584c\uff0c\u5e76\u4f7f\u7528KV-LoRA\u9ad8\u6548\u5229\u7528\u538b\u7f29\u8bb0\u5fc6\u8868\u793a\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u5c06\u8bb0\u5fc6\u5e93\u5927\u5c0f\u51cf\u5c11\u5230\u57fa\u7ebf\u65b9\u6cd5\u76840.3%\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u5bb9\u6613\u8fc7\u65f6\uff0c\u9700\u8981\u6301\u7eed\u5b66\u4e60\u6765\u66f4\u65b0\u3002\u73b0\u6709\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\u867d\u7136\u80fd\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f46\u8bb0\u5fc6\u5e93\u4f1a\u968f\u6570\u636e\u6d41\u4e0d\u65ad\u589e\u957f\uff0c\u5bfc\u81f4\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u3002", "method": "1) \u901a\u8fc7\u7801\u672c\u4f18\u5316\u7b56\u7565\u538b\u7f29\u8bb0\u5fc6\u5e93\uff1b2) \u5f15\u5165\u5728\u7ebf\u91cd\u7f6e\u673a\u5236\u9632\u6b62\u7801\u672c\u574d\u584c\uff1b3) \u5728\u6ce8\u610f\u529b\u5c42\u4f7f\u7528Key-Value\u4f4e\u79e9\u9002\u914d(KV-LoRA)\u6765\u9ad8\u6548\u5229\u7528\u538b\u7f29\u8bb0\u5fc6\u8868\u793a\u3002", "result": "\u5728\u57fa\u51c6\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMBC\u5c06\u8bb0\u5fc6\u5e93\u5927\u5c0f\u538b\u7f29\u5230\u6700\u7ade\u4e89\u57fa\u7ebf\u76840.3%\uff0c\u540c\u65f6\u5728\u5728\u7ebf\u9002\u5e94\u5b66\u4e60\u4e2d\u4fdd\u6301\u9ad8\u4fdd\u7559\u51c6\u786e\u7387\u3002", "conclusion": "MBC\u901a\u8fc7\u8bb0\u5fc6\u5e93\u538b\u7f29\u548c\u7a33\u5b9a\u5b66\u4e60\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u6709\u6548\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u8bb0\u5fc6\u5e93\u65e0\u9650\u589e\u957f\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.00604", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00604", "abs": "https://arxiv.org/abs/2601.00604", "authors": ["Francisco Aguilera Moreno"], "title": "Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load", "comment": "14 pages, 22 figures", "summary": "Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u9a91\u884c\u65f6\u957f\uff0c\u7ed3\u5408\u8def\u7ebf\u62d3\u6251\u548c\u8fd0\u52a8\u5458\u4f53\u80fd\u72b6\u6001\uff0c\u76f8\u6bd4\u4ec5\u7528\u62d3\u6251\u7279\u5f81\u51cf\u5c1114%\u8bef\u5dee", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7269\u7406\u6a21\u578b\u7684\u9a91\u884c\u65f6\u957f\u9884\u6d4b\u9700\u8981\u5927\u91cf\u53c2\u6570\uff08\u5982\u7a7a\u6c14\u963b\u529b\u7cfb\u6570\u3001\u5b9e\u65f6\u98ce\u901f\uff09\uff0c\u5bf9\u4e1a\u4f59\u9a91\u624b\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u66f4\u7b80\u5355\u6709\u6548\u7684\u9884\u6d4b\u65b9\u6cd5", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u8def\u7ebf\u62d3\u6251\u7279\u5f81\u548c\u8fd0\u52a8\u5458\u5f53\u524d\u4f53\u80fd\u72b6\u6001\uff08\u4ece\u8bad\u7ec3\u8d1f\u8377\u6307\u6807\u63a8\u5bfc\uff09\uff0c\u4f7f\u7528Lasso\u56de\u5f52\u6a21\u578b\uff0c\u5728\u5355\u4eba\u6570\u636e\u96c6(N=96\u6b21\u9a91\u884c)\u4e0a\u8fdb\u884cN-of-1\u7814\u7a76\u8bbe\u8ba1", "result": "\u62d3\u6251+\u4f53\u80fd\u7279\u5f81\u7ec4\u5408\u7684Lasso\u56de\u5f52\u6a21\u578b\u8fbe\u5230MAE=6.60\u5206\u949f\uff0cR\u00b2=0.922\uff1b\u76f8\u6bd4\u4ec5\u7528\u62d3\u6251\u7279\u5f81(MAE=7.66\u5206\u949f)\uff0c\u8bef\u5dee\u51cf\u5c1114%\uff0c\u8bc1\u660e\u751f\u7406\u72b6\u6001\u5bf9\u81ea\u5b9a\u8282\u594f\u9a91\u884c\u6709\u663e\u8457\u5f71\u54cd", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u9884\u6d4b\u9a91\u884c\u65f6\u957f\uff0c\u65e0\u9700\u590d\u6742\u7269\u7406\u53c2\u6570\uff0c\u8fd0\u52a8\u5458\u4f53\u80fd\u72b6\u6001\u662f\u91cd\u8981\u9884\u6d4b\u56e0\u7d20\uff0c\u6e10\u8fdb\u5f0f\u68c0\u67e5\u70b9\u9884\u6d4b\u652f\u6301\u52a8\u6001\u6bd4\u8d5b\u89c4\u5212"}}
{"id": "2601.00607", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00607", "abs": "https://arxiv.org/abs/2601.00607", "authors": ["Sonia Khetarpaul", "P Y Sharan"], "title": "Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning", "comment": null, "summary": "In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u901a\u611f\u77e5\u51fa\u79df\u8f66\u70ed\u70b9\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u6a21\u62df\u5fb7\u91cc\u6570\u636e\u96c6\u4e0a\u51cf\u5c11\u4e58\u5ba2\u7b49\u5f85\u65f6\u95f456%\uff0c\u884c\u9a76\u8ddd\u79bb38%", "motivation": "\u4f20\u7edf\u51fa\u79df\u8f66\u70ed\u70b9\u9884\u6d4b\u6a21\u578b\u4ec5\u4f9d\u8d56\u5386\u53f2\u9700\u6c42\uff0c\u5ffd\u7565\u4e86\u4ea4\u901a\u62e5\u5835\u3001\u9053\u8def\u4e8b\u4ef6\u548c\u516c\u5171\u6d3b\u52a8\u7b49\u52a8\u6001\u56e0\u7d20\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u4f9b\u9700\u5339\u914d", "method": "\u5c06\u57ce\u5e02\u9053\u8def\u7f51\u7edc\u5efa\u6a21\u4e3a\u56fe\uff08\u8282\u70b9\u4e3a\u4ea4\u53c9\u53e3\uff0c\u8fb9\u4e3a\u8def\u6bb5\uff09\uff0c\u4f7f\u7528GNN\u7f16\u7801\u65f6\u7a7a\u4f9d\u8d56\uff0c\u7ed3\u5408Q-learning\u667a\u80fd\u4f53\u63a8\u8350\u6700\u4f18\u51fa\u79df\u8f66\u70ed\u70b9\u4f4d\u7f6e", "result": "\u5728\u6a21\u62df\u5fb7\u91cc\u51fa\u79df\u8f66\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u968f\u673a\u9009\u62e9\u65b9\u6cd5\uff0c\u4e58\u5ba2\u7b49\u5f85\u65f6\u95f4\u51cf\u5c11\u7ea656%\uff0c\u884c\u9a76\u8ddd\u79bb\u51cf\u5c1138%", "conclusion": "\u8be5\u4ea4\u901a\u611f\u77e5\u7684\u56fe\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u4f18\u5316\u51fa\u79df\u8f66\u4f9b\u9700\u5339\u914d\uff0c\u53ef\u6269\u5c55\u5230\u591a\u6a21\u5f0f\u4ea4\u901a\u7cfb\u7edf\u5e76\u96c6\u6210\u5230\u667a\u6167\u57ce\u5e02\u5e73\u53f0\u4e2d"}}
{"id": "2601.00747", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00747", "abs": "https://arxiv.org/abs/2601.00747", "authors": ["Max Ruiz Luyten", "Mihaela van der Schaar"], "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving", "comment": "56 pages, 9 figures, submitted to Twenty-Ninth Annual Conference on Artificial Intelligence and Statistics", "summary": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u5e03\u521b\u9020\u6027\u63a8\u7406\uff08DCR\uff09\u6846\u67b6\uff0c\u5206\u6790\u5f53\u524dLLM\u63a8\u7406\u5faa\u73af\u5bfc\u81f4\u591a\u6837\u6027\u8870\u51cf\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4fdd\u6301\u6b63\u786e\u6027\u548c\u521b\u9020\u6027\u7684\u7406\u8bba\u65b9\u6848\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u5faa\u73af\u4e3b\u8981\u4f18\u5316\u6b63\u786e\u6027\uff0c\u5bfc\u81f4\u63a8\u7406\u8def\u5f84\u5206\u5e03\u5d29\u6e83\uff0c\u8bed\u4e49\u71b5\u4e0b\u964d\uff0c\u635f\u5bb3\u521b\u9020\u6027\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002\u9700\u8981\u5206\u6790\u8fd9\u79cd\u5931\u8d25\u5e76\u627e\u5230\u4fdd\u6301\u591a\u6837\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5206\u5e03\u521b\u9020\u6027\u63a8\u7406\uff08DCR\uff09\u6846\u67b6\uff0c\u5c06\u8bad\u7ec3\u89c6\u4e3a\u901a\u8fc7\u89e3\u51b3\u65b9\u6848\u8f68\u8ff9\u6982\u7387\u6d4b\u5ea6\u7684\u68af\u5ea6\u6d41\u3002STaR\u3001GRPO\u3001DPO\u7b49\u65b9\u6cd5\u90fd\u662f\u8be5\u635f\u5931\u51fd\u6570\u7684\u7279\u4f8b\u3002", "result": "\u63d0\u51fa\u4e09\u4e2a\u6838\u5fc3\u6210\u679c\uff1a\u591a\u6837\u6027\u8870\u51cf\u5b9a\u7406\u63cf\u8ff0\u4e0d\u540c\u65b9\u6cd5\u5982\u4f55\u5bfc\u81f4\u591a\u6837\u6027\u8870\u51cf\uff1b\u786e\u4fdd\u6536\u655b\u5230\u7a33\u5b9a\u591a\u6837\u7b56\u7565\u7684\u8bbe\u8ba1\uff1b\u5b9e\u9645\u53ef\u884c\u7684\u5b9e\u73b0\u65b9\u6848\u3002", "conclusion": "DCR\u4e3aLLM\u63d0\u4f9b\u4e86\u9996\u4e2a\u4fdd\u6301\u6b63\u786e\u6027\u548c\u521b\u9020\u6027\u7684\u539f\u5219\u6027\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u63a8\u7406\u5faa\u73af\u7684\u5206\u5e03\u5d29\u6e83\u95ee\u9898\u3002"}}
{"id": "2601.00730", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00730", "abs": "https://arxiv.org/abs/2601.00730", "authors": ["Janez Per\u0161", "Jon Muhovi\u010d", "Andrej Ko\u0161ir", "Bo\u0161tjan Murovec"], "title": "Grading Handwritten Engineering Exams with Multimodal Large Language Models", "comment": "10 pages, 5 figures, 2 tables. Supplementary material available at https://lmi.fe.uni-lj.si/en/janez-pers-2/supplementary-material/", "summary": "Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\\approx$17% at $D_{\\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6279\u6539\u624b\u5199STEM\u8003\u8bd5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bbe\u8ba1\u786e\u4fdd\u53ef\u9760\u6027\uff0c\u5728\u771f\u5b9e\u8bfe\u7a0b\u6d4b\u9a8c\u4e2d\u8fbe\u5230\u7ea68\u5206\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u3002", "motivation": "\u624b\u5199STEM\u8003\u8bd5\u80fd\u6355\u6349\u5f00\u653e\u5f0f\u63a8\u7406\u548c\u56fe\u8868\uff0c\u4f46\u4eba\u5de5\u6279\u6539\u901f\u5ea6\u6162\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u4fdd\u6301\u6807\u51c6\u8003\u8bd5\u6d41\u7a0b\u3002", "method": "\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\uff1a\u6559\u5e08\u63d0\u4f9b\u624b\u5199\u53c2\u8003\u7b54\u6848\u548c\u8bc4\u5206\u89c4\u5219\uff0c\u53c2\u8003\u65b9\u6848\u8f6c\u6362\u4e3a\u6587\u672c\u6458\u8981\u7528\u4e8e\u6761\u4ef6\u8bc4\u5206\uff1b\u591a\u9636\u6bb5\u8bbe\u8ba1\u5305\u62ec\u683c\u5f0f/\u5b58\u5728\u6027\u68c0\u67e5\u3001\u72ec\u7acb\u8bc4\u5206\u5668\u96c6\u6210\u3001\u76d1\u7763\u805a\u5408\u548c\u786e\u5b9a\u6027\u9a8c\u8bc1\u6a21\u677f\u3002", "result": "\u4f7f\u7528GPT-5.2\u548cGemini-3 Pro\u540e\u7aef\uff0c\u5b8c\u6574\u6d41\u7a0b\u5728\u65af\u6d1b\u6587\u5c3c\u4e9a\u8bed\u771f\u5b9e\u8bfe\u7a0b\u6d4b\u9a8c\u4e2d\u8fbe\u5230\u7ea68\u5206\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff0c\u4f4e\u504f\u5dee\uff0c\u7ea617%\u7684\u624b\u52a8\u5ba1\u67e5\u89e6\u53d1\u7387\u3002", "conclusion": "\u7ed3\u6784\u5316\u63d0\u793a\u548c\u53c2\u8003\u65b9\u6848\u57fa\u7840\u5bf9\u4e8e\u51c6\u786e\u8bc4\u5206\u81f3\u5173\u91cd\u8981\uff0c\u8be5\u5de5\u4f5c\u6d41\u4e3a\u624b\u5199STEM\u8003\u8bd5\u6279\u6539\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
