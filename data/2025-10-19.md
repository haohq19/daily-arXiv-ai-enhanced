<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 6]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication](https://arxiv.org/abs/2510.14245)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出了一种针对事件视觉传感器的新型调制方案EIM，通过事件间隔调制信息，在室内环境中实现了28kbps@10米和8.4kbps@50米的传输速率，创下了事件光学相机通信系统的比特率新纪录。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的OCC系统存在比特率低和处理负载高的问题，而现有事件OCC系统使用的传统调制方案未能充分利用事件视觉传感器的独特特性。

Method: 提出事件间隔调制(EIM)方案，通过调制事件之间的间隔来传输信息；调整EVS参数以优化EIM的频率响应；实验确定EIM的最大调制阶数；基于获得的参数进行传输实验。

Result: 成功在室内环境中实现28kbps@10米和8.4kbps@50米的传输，创下了事件OCC系统的比特率新纪录。

Conclusion: EIM方案能够充分利用事件视觉传感器的特性，显著提高事件OCC系统的传输性能，为高速、低延迟的可见光通信提供了新的解决方案。

Abstract: Optical camera communication (OCC) represents a promising visible light
communication technology. Nonetheless, typical OCC systems utilizing
frame-based cameras are encumbered by limitations, including low bit rate and
high processing load. To address these issues, OCC system utilizing an
event-based vision sensor (EVS) as receivers have been proposed. The EVS
enables high-speed, low-latency, and robust communication due to its
asynchronous operation and high dynamic range. In existing event-based OCC
systems, conventional modulation schemes such as on-off keying (OOK) and pulse
position modulation have been applied, however, to the best of our knowledge,
no modulation method has been proposed that fully exploits the unique
characteristics of the EVS. This paper proposes a novel modulation scheme,
called the event interval modulation (EIM) scheme, specifically designed for
event-based OCC. EIM enables improvement in transmission speed by modulating
information using the intervals between events. This paper proposes a
theoretical model of EIM and conducts a proof-of-concept experiment. First, the
parameters of the EVS are tuned and customized to optimize the frequency
response specifically for EIM. Then, the maximum modulation order usable in EIM
is determined experimentally. We conduct transmission experiments based on the
obtained parameters. Finally, we report successful transmission at 28 kbps over
10 meters and 8.4 kbps over 50 meters in an indoor environment. This sets a new
benchmark for bit rate in event-based OCC systems.

</details>


### [2] [Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization](https://arxiv.org/abs/2510.14255)
*Liao Shen,Wentao Jiang,Yiran Zhu,Tiezheng Ge,Zhiguo Cao,Bo Zheng*

Main category: cs.CV

TL;DR: 提出IPRO方法，通过强化学习优化视频扩散模型，解决图像到视频生成中的人脸身份一致性保持问题


<details>
  <summary>Details</summary>
Motivation: 现有I2V模型在生成视频时难以保持输入图像中人物的身份一致性，特别是在人脸占图像比例较小、表情和动作变化较大的情况下

Method: 基于强化学习的视频扩散框架，使用人脸身份评分器优化模型，通过反向传播奖励信号，采用多角度面部特征池和KL散度正则化

Result: 在Wan 2.2 I2V模型和内部I2V模型上的广泛实验证明了方法的有效性

Conclusion: IPRO方法能够有效增强I2V生成中的人脸身份一致性，无需引入额外模块或改变模型架构

Abstract: Recent advances in image-to-video (I2V) generation have achieved remarkable
progress in synthesizing high-quality, temporally coherent videos from static
images. Among all the applications of I2V, human-centric video generation
includes a large portion. However, existing I2V models encounter difficulties
in maintaining identity consistency between the input human image and the
generated video, especially when the person in the video exhibits significant
expression changes and movements. This issue becomes critical when the human
face occupies merely a small fraction of the image. Since humans are highly
sensitive to identity variations, this poses a critical yet under-explored
challenge in I2V generation. In this paper, we propose Identity-Preserving
Reward-guided Optimization (IPRO), a novel video diffusion framework based on
reinforcement learning to enhance identity preservation. Instead of introducing
auxiliary modules or altering model architectures, our approach introduces a
direct and effective tuning algorithm that optimizes diffusion models using a
face identity scorer. To improve performance and accelerate convergence, our
method backpropagates the reward signal through the last steps of the sampling
chain, enabling richer gradient feedback. We also propose a novel facial
scoring mechanism that treats faces in ground-truth videos as facial feature
pools, providing multi-angle facial information to enhance generalization. A
KL-divergence regularization is further incorporated to stabilize training and
prevent overfitting to the reward signal. Extensive experiments on Wan 2.2 I2V
model and our in-house I2V model demonstrate the effectiveness of our method.
Our project and code are available at
\href{https://ipro-alimama.github.io/}{https://ipro-alimama.github.io/}.

</details>


### [3] [Experimental Demonstration of Event-based Optical Camera Communication in Long-Range Outdoor Environment](https://arxiv.org/abs/2510.14266)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出了一种基于事件视觉传感器的光学相机通信系统鲁棒解调方案，结合OOK与切换解调及数字锁相环技术，在室外实验中首次实现了200米-60kbps和400米-30kbps下BER<10^{-3}的性能。


<details>
  <summary>Details</summary>
Motivation: 开发能够在长距离和高速率条件下实现可靠通信的光学相机通信系统，解决传统方法在室外环境中的性能限制。

Method: 使用事件视觉传感器，结合开关键控(OOK)与切换解调技术，并集成数字锁相环(DPLL)来提高解调鲁棒性。

Result: 在室外实验中首次实现了200米距离下60kbps速率和400米距离下30kbps速率时，误码率(BER)低于10^{-3}的性能。

Conclusion: 该方案为光学相机通信系统提供了一种有效的长距离高速率解调方法，在室外环境中表现出优越的性能。

Abstract: We propose a robust demodulation scheme for optical camera communication
systems using an event-based vision sensor, combining OOK with toggle
demodulation and a digital phase-locked loop. This is the first report to
achieve a $\mathrm{BER} < 10^{-3}$ at 200m-60kbps and 400m-30kbps in outdoor
experiments.

</details>


### [4] [Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video](https://arxiv.org/abs/2510.14560)
*Yulin Zhang,Cheng Shi,Yang Wang,Sibei Yang*

Main category: cs.CV

TL;DR: 提出ESTP-Bench基准和ESTP-F1指标，用于评估AI助手在流式视频输入下主动理解、预测和响应事件的能力，并开发了包含数据引擎、多阶段训练策略和主动动态压缩技术的完整技术流程。


<details>
  <summary>Details</summary>
Motivation: 开发能够在人类环境中主动运作的AI，使其不仅能观察，还能主动理解、预测和响应正在发生的事件，实现同步感知和推理。

Method: 提出包含三个组件的技术流程：(1)数据引擎，(2)多阶段训练策略，(3)主动动态压缩技术。同时引入ESTP-Bench基准和ESTP-F1评估指标。

Result: 所提出的模型有效解决了主动一致性、及时响应性和同步效率三个关键属性，在多个在线和离线基准测试中优于多个基线方法。

Conclusion: 该工作为实现能够在流式视频输入下主动响应多样化问题的AI助手提供了有效的基准、评估指标和技术解决方案。

Abstract: Envision an AI capable of functioning in human-like settings, moving beyond
mere observation to actively understand, anticipate, and proactively respond to
unfolding events. Towards this vision, we focus on the innovative task where,
given ego-streaming video input, an assistant proactively answers diverse,
evolving questions at the opportune moment, while maintaining synchronized
perception and reasoning. This task embodies three key properties: (1)
Proactive Coherence, (2) Just-in-Time Responsiveness, and (3) Synchronized
Efficiency. To evaluate and address these properties, we first introduce
ESTP-Bench (Ego Streaming Proactive Benchmark) alongside the ESTP-F1 metric-a
novel framework designed for their rigorous assessment. Secondly, we propose a
comprehensive technical pipeline to enable models to tackle this challenging
task. This pipeline comprises: (1) a data engine, (2) a multi-stage training
strategy, and (3) a proactive dynamic compression technique. Our proposed model
effectively addresses these critical properties while outperforming multiple
baselines across diverse online and offline benchmarks. Project
Page:https://zhangyl4.github.io/publications/eyes-wide-open/

</details>


### [5] [Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference](https://arxiv.org/abs/2510.14624)
*Natan Bagrov,Eugene Khvedchenia,Borys Tymchenko,Shay Aharon,Lior Kadoch,Tomer Keren,Ofri Masad,Yonatan Geifman,Ran Zilberstein,Tuomas Rintamaki,Matthieu Le,Andrew Tao*

Main category: cs.CV

TL;DR: EVS是一种简单即插即用的视频采样方法，通过识别和修剪时间上静态的补丁来减少视频中的令牌冗余，从而显著降低令牌数量，实现更快推理和更长输入序列。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型从静态图像理解扩展到视频推理时，处理密集帧序列的二次成本限制了其可扩展性。长视频经常超出现代语言模型的令牌预算，导致严重的上下文限制和延迟问题。

Method: 引入高效视频采样(EVS)，通过识别和修剪时间上静态的补丁（在连续帧中保持不变的时空区域）来减少视频中的令牌冗余。该方法保持位置身份，无需架构更改或重新训练。

Result: EVS显著减少令牌数量同时保持语义保真度，使大型语言模型的首次令牌时间(TTFT)减少高达4倍，且精度损失最小。结合随机修剪率的上训练阶段，EVS产生对不同程度压缩具有鲁棒性的模型。

Conclusion: EVS持续改进效率-精度权衡，在不牺牲质量的情况下实现可扩展的视频语言理解。

Abstract: Vision-language models (VLMs) have recently expanded from static image
understanding to video reasoning, but their scalability is fundamentally
limited by the quadratic cost of processing dense frame sequences. Long videos
often exceed the token budget of modern language models, leading to severe
context limitations and latency issues. We introduce Efficient Video Sampling
(EVS), a simple, plug-and-play method for reducing token redundancy in videos
by identifying and pruning temporally static patches -- spatial regions that
remain unchanged across consecutive frames. EVS preserves positional identity,
requires no architectural changes or retraining. We show that EVS substantially
reduces token count while maintaining semantic fidelity, enabling faster
inference and longer input sequences. Applied at inference time, EVS reduces
large language model (LLM) time-to-first-token (TTFT) by up to 4x with minimal
accuracy loss. When combined with an uptraining phase using stochastic pruning
rates, EVS yields models that are robust to varying compression levels and
retain full performance under aggressive pruning. Extensive experiments
demonstrate that EVS consistently improves efficiency-accuracy trade-offs,
unlocking scalable video-language understanding without sacrificing quality.

</details>


### [6] [MoCom: Motion-based Inter-MAV Visual Communication Using Event Vision and Spiking Neural Networks](https://arxiv.org/abs/2510.14770)
*Zhang Nengbo,Hann Woei Ho,Ye Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于视觉运动信号的MAV群通信框架，模仿蜜蜂摇摆舞，使用事件相机和SNN进行运动模式解码，实现低功耗可靠通信。


<details>
  <summary>Details</summary>
Motivation: 传统无线电通信在MAV群中面临频谱拥塞、干扰和高功耗问题，需要寻找替代通信方式。

Method: 使用预定义运动基元（上下、左右、L形轨迹）作为控制符号，通过事件相机捕获运动模式，采用事件帧分割和轻量SNN进行解码。

Result: 实验验证了框架的有效性，实现了准确解码和低功耗，在受限环境中表现出良好性能。

Conclusion: 该视觉通信框架为MAV群提供了一种节能的替代通信方案，特别适用于无线电受限环境。

Abstract: Reliable communication in Micro Air Vehicle (MAV) swarms is challenging in
environments, where conventional radio-based methods suffer from spectrum
congestion, jamming, and high power consumption. Inspired by the waggle dance
of honeybees, which efficiently communicate the location of food sources
without sound or contact, we propose a novel visual communication framework for
MAV swarms using motion-based signaling. In this framework, MAVs convey
information, such as heading and distance, through deliberate flight patterns,
which are passively captured by event cameras and interpreted using a
predefined visual codebook of four motion primitives: vertical (up/down),
horizontal (left/right), left-to-up-to-right, and left-to-down-to-right,
representing control symbols (``start'', ``end'', ``1'', ``0''). To decode
these signals, we design an event frame-based segmentation model and a
lightweight Spiking Neural Network (SNN) for action recognition. An integrated
decoding algorithm then combines segmentation and classification to robustly
interpret MAV motion sequences. Experimental results validate the framework's
effectiveness, which demonstrates accurate decoding and low power consumption,
and highlights its potential as an energy-efficient alternative for MAV
communication in constrained environments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [Exploratory Causal Inference in SAEnce](https://arxiv.org/abs/2510.14073)
*Tommaso Mencattini,Riccardo Cadei,Francesco Locatello*

Main category: cs.LG

TL;DR: 提出Neural Effect Search方法，使用预训练基础模型和稀疏自编码器从试验数据中无监督发现未知因果效应，解决了多重检验和效应纠缠问题。


<details>
  <summary>Details</summary>
Motivation: 传统随机对照试验依赖人工假设且分析成本高，限制了大规模因果效应估计，可能遗漏重要但未被假设的效应。

Method: 使用预训练基础模型将非结构化数据转化为有意义的表示，通过稀疏自编码器解释，并引入Neural Effect Search递归程序通过渐进分层解决多重检验和效应纠缠问题。

Result: 在半合成实验中验证了算法的鲁棒性，并在实验生态学背景下首次成功实现了真实世界科学试验中的无监督因果效应识别。

Conclusion: 该方法能够直接从数据中发现未知的因果效应，突破了传统假设驱动方法的限制，为大规模因果发现提供了新途径。

Abstract: Randomized Controlled Trials are one of the pillars of science; nevertheless,
they rely on hand-crafted hypotheses and expensive analysis. Such constraints
prevent causal effect estimation at scale, potentially anchoring on popular yet
incomplete hypotheses. We propose to discover the unknown effects of a
treatment directly from data. For this, we turn unstructured data from a trial
into meaningful representations via pretrained foundation models and interpret
them via a sparse autoencoder. However, discovering significant causal effects
at the neural level is not trivial due to multiple-testing issues and effects
entanglement. To address these challenges, we introduce Neural Effect Search, a
novel recursive procedure solving both issues by progressive stratification.
After assessing the robustness of our algorithm on semi-synthetic experiments,
we showcase, in the context of experimental ecology, the first successful
unsupervised causal effect identification on a real-world scientific trial.

</details>


### [8] [Stable Prediction of Adverse Events in Medical Time-Series Data](https://arxiv.org/abs/2510.14286)
*Mayank Keoliya,Seewon Choi,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: CAREBench是一个早期事件预测基准，评估多模态输入下的预测准确性和时间稳定性，发现现有方法特别是LLMs在准确性和稳定性平衡方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 当前早期事件预测系统忽略风险评分稳定性，且主要评估表格输入，缺乏对风险轨迹行为的测试。

Method: 提出CAREBench基准，使用多模态输入（表格EHR、ECG波形、临床文本），引入基于局部Lipschitz常数的稳定性指标来量化短期风险变异性。

Result: 现有方法特别是LLMs难以同时优化准确性和稳定性，在高精度操作点召回率表现较差。

Conclusion: 需要开发能够产生证据对齐、稳定轨迹的模型，以在连续监测环境中赢得临床医生的信任。

Abstract: Early event prediction (EEP) systems continuously estimate a patient's
imminent risk to support clinical decision-making. For bedside trust, risk
trajectories must be accurate and temporally stable, shifting only with new,
relevant evidence. However, current benchmarks (a) ignore stability of risk
scores and (b) evaluate mainly on tabular inputs, leaving trajectory behavior
untested. To address this gap, we introduce CAREBench, an EEP benchmark that
evaluates deployability using multi-modal inputs-tabular EHR, ECG waveforms,
and clinical text-and assesses temporal stability alongside predictive
accuracy. We propose a stability metric that quantifies short-term variability
in per-patient risk and penalizes abrupt oscillations based on local-Lipschitz
constants. CAREBench spans six prediction tasks such as sepsis onset and
compares classical learners, deep sequence models, and zero-shot LLMs. Across
tasks, existing methods, especially LLMs, struggle to jointly optimize accuracy
and stability, with notably poor recall at high-precision operating points.
These results highlight the need for models that produce evidence-aligned,
stable trajectories to earn clinician trust in continuous monitoring settings.
(Code: https://github.com/SeewonChoi/CAREBench.)

</details>


### [9] [SHaRe-SSM: An Oscillatory Spiking Neural Network for Target Variable Modeling in Long Sequences](https://arxiv.org/abs/2510.14386)
*Kartikay Agrawal,Abhijeet Vikram,Vedant Sharma,Vaishnavi N.,Ayon Borthakur*

Main category: cs.LG

TL;DR: 提出SHaRe-SSM（尖峰谐波共振激发状态空间模型），一种用于超长序列建模的乘法自由、节能的尖峰神经网络架构，在保持性能的同时比基于ANN的SSM节能73倍。


<details>
  <summary>Details</summary>
Motivation: 结合尖峰神经网络的节能特性和状态空间模型在长序列建模中的优势，开发适合资源受限应用的乘法自由深度学习模型。

Method: 设计二阶尖峰SSM，利用并行扫描实现动态系统的稳定高效实现，首次提出基于核的共振激发神经元尖峰回归器。

Result: 在18k序列上比二阶ANN-SSM节能73倍，在50k超长序列上表现优异，性能优于Transformer和传统一阶SSM。

Conclusion: SHaRe-SSM为资源受限环境下的超长序列建模提供了高效节能的解决方案，并系统分析了共振激发SSM中异质性、耗散和守恒性的影响。

Abstract: In recent years, with the emergence of large models, there has been a
significant interest in spiking neural networks (SNNs) primarily due to their
energy efficiency, multiplication-free, and sparse event-based deep learning.
Similarly, state space models (SSMs) in varying designs have evolved as a
powerful alternative to transformers for target modeling in long sequences,
thereby overcoming the quadratic dependence on sequence length of a
transformer. Inspired by this progress, we here design SHaRe-SSM (Spiking
Harmonic Resonate and Fire State Space Model), for target variable modeling
(including both classification and regression) for very-long-range sequences.
Our second-order spiking SSM, on average, performs better than transformers or
first-order SSMs while circumventing multiplication operations, making it ideal
for resource-constrained applications. The proposed block consumes $73 \times$
less energy than second-order ANN-based SSMs for an 18k sequence, while
retaining performance. To ensure learnability over the long-range sequences, we
propose exploiting the stable and efficient implementation of the dynamical
system using parallel scans. Moreover, for the first time, we propose a
kernel-based spiking regressor using resonate and fire neurons for very
long-range sequences. Our network shows superior performance on even a 50k
sequence while being significantly energy-efficient. In addition, we conducted
a systematic analysis of the impact of heterogeneity, dissipation, and
conservation in resonate-and-fire SSMs.

</details>


### [10] [Agentic Entropy-Balanced Policy Optimization](https://arxiv.org/abs/2510.14545)
*Guanting Dong,Licheng Bao,Zhongyuan Wang,Kangzhi Zhao,Xiaoxi Li,Jiajie Jin,Jinghan Yang,Hangyu Mao,Fuzheng Zhang,Kun Gai,Guorui Zhou,Yutao Zhu,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.LG

TL;DR: 提出Agentic Entropy-Balanced Policy Optimization (AEPO)算法，通过动态熵平衡机制解决代理强化学习中过度依赖熵信号导致的训练崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 主流代理强化学习算法在熵引导下自主探索高不确定性工具调用步骤，但过度依赖熵信号会施加额外约束，导致训练崩溃。

Method: AEPO包含两个核心组件：(1) 动态熵平衡rollout机制，通过熵预监测自适应分配全局和分支采样预算，并对连续高熵工具调用施加分支惩罚；(2) 熵平衡策略优化，在高熵裁剪项中插入停止梯度操作，同时结合熵感知优势估计。

Result: 在14个挑战性数据集上，AEPO始终优于7种主流RL算法。仅使用1K RL样本，Qwen3-14B在GAIA上达到47.6%，Humanity's Last Exam上11.2%，WebWalker上43.0%的Pass@1性能。

Conclusion: AEPO提高了rollout采样多样性，同时保持稳定的策略熵，有助于可扩展的Web代理训练。

Abstract: Recently, Agentic Reinforcement Learning (Agentic RL) has made significant
progress in incentivizing the multi-turn, long-horizon tool-use capabilities of
web agents. While mainstream agentic RL algorithms autonomously explore
high-uncertainty tool-call steps under the guidance of entropy, excessive
reliance on entropy signals can impose further constraints, leading to the
training collapse. In this paper, we delve into the challenges caused by
entropy and propose the Agentic Entropy-Balanced Policy Optimization (AEPO), an
agentic RL algorithm designed to balance entropy in both the rollout and policy
update phases. AEPO comprises two core components: (1) a dynamic
entropy-balanced rollout mechanism that adaptively allocate global and branch
sampling budget through entropy pre-monitoring, while imposing a branch penalty
on consecutive high-entropy tool-call steps to prevent over-branching issues;
and (2) Entropy-Balanced Policy Optimization that inserts a stop-gradient
operation into the high-entropy clipping term to preserve and properly rescale
gradients on high-entropy tokens, while incorporating entropy-aware advantage
estimation to prioritize learning on high-uncertainty tokens. Results across 14
challenging datasets show that AEPO consistently outperforms 7 mainstream RL
algorithms. With just 1K RL samples, Qwen3-14B with AEPO achieves impressive
results: 47.6% on GAIA, 11.2% on Humanity's Last Exam, and 43.0% on WebWalker
for Pass@1; 65.0% on GAIA, 26.0% on Humanity's Last Exam, and 70.0% on
WebWalker for Pass@5. Further analysis reveals that AEPO improves rollout
sampling diversity while maintaining stable policy entropy, facilitating
scalable web agent training.

</details>


### [11] [Online Reliable Anomaly Detection via Neuromorphic Sensing and Communications](https://arxiv.org/abs/2510.14688)
*Junya Shiraishi,Jiechen Chen,Osvaldo Simeone,Petar Popovski*

Main category: cs.LG

TL;DR: 提出基于神经形态无线传感器网络的低功耗在线异常检测框架，通过事件驱动的神经形态传感器和脉冲无线电传输实现高效异常检测，同时严格控制误发现率。


<details>
  <summary>Details</summary>
Motivation: 为脑机接口和远程环境监测等应用提供低功耗、高效的在线异常检测解决方案，需要在严格控制误发现率的同时实现低延迟检测。

Method: 采用在线假设检验方法结合e值控制FDR，将传感器查询策略建模为多臂老虎机问题中的最佳臂识别问题进行动态优化。

Result: 性能评估表明该方法能在严格FDR要求下可靠检测异常，同时高效调度传感器通信并实现低检测延迟。

Conclusion: 所提出的框架为神经形态无线传感器网络提供了一种有效的在线异常检测方案，在功耗、检测精度和延迟方面均表现出色。

Abstract: This paper proposes a low-power online anomaly detection framework based on
neuromorphic wireless sensor networks, encompassing possible use cases such as
brain-machine interfaces and remote environmental monitoring. In the considered
system, a central reader node actively queries a subset of neuromorphic sensor
nodes (neuro-SNs) at each time frame. The neuromorphic sensors are
event-driven, producing spikes in correspondence to relevant changes in the
monitored system. The queried neuro-SNs respond to the reader with impulse
radio (IR) transmissions that directly encode the sensed local events. The
reader processes these event-driven signals to determine whether the monitored
environment is in a normal or anomalous state, while rigorously controlling the
false discovery rate (FDR) of detections below a predefined threshold. The
proposed approach employs an online hypothesis testing method with e-values to
maintain FDR control without requiring knowledge of the anomaly rate, and it
dynamically optimizes the sensor querying strategy by casting it as a best-arm
identification problem in a multi-armed bandit framework. Extensive performance
evaluation demonstrates that the proposed method can reliably detect anomalies
under stringent FDR requirements, while efficiently scheduling sensor
communications and achieving low detection latency.

</details>


### [12] [Intelligent Dynamic Handover via AI-assisted Signal Quality Prediction in 6G Multi-RAT Networks](https://arxiv.org/abs/2510.14832)
*Maria Lamprini A. Bartsioka,Anastasios Giannopoulos,Sotirios Spantideas*

Main category: cs.LG

TL;DR: 提出基于机器学习的预测性条件切换(P-CHO)框架，使用模型驱动和短时信号质量预测来改善6G多RAT网络中的切换性能。


<details>
  <summary>Details</summary>
Motivation: 6G多RAT网络中，蜂窝和WiFi发射器共存，需要可靠的移动性决策来应对快速信道动态、干扰和异构覆盖。传统切换方法反应式且依赖瞬时测量，存在局限性。

Method: 提出基于LSTM网络的P-CHO框架，包括RAT导向控制器、数据收集、并行预测、基于迟滞条件的决策逻辑和CHO执行。训练RAT感知LSTM网络预测移动用户的信号质量指标。

Result: 在软切换和硬切换设置下测试，显示基于迟滞的P-CHO方案能够减少切换失败和乒乓事件。比较了直接多步与递归P-CHO变体，并与基线预测器进行了对比。

Conclusion: 提出的P-CHO框架能够实现准确、低延迟和主动的切换，适用于6G多RAT部署中的ML辅助切换导向。

Abstract: The emerging paradigm of 6G multiple Radio Access Technology (multi-RAT)
networks, where cellular and Wireless Fidelity (WiFi) transmitters coexist,
requires mobility decisions that remain reliable under fast channel dynamics,
interference, and heterogeneous coverage. Handover in multi-RAT deployments is
still highly reactive and event-triggered, relying on instantaneous
measurements and threshold events. This work proposes a Machine Learning
(ML)-assisted Predictive Conditional Handover (P-CHO) framework based on a
model-driven and short-horizon signal quality forecasts. We present a
generalized P-CHO sequence workflow orchestrated by a RAT Steering Controller,
which standardizes data collection, parallel per-RAT predictions, decision
logic with hysteresis-based conditions, and CHO execution. Considering a
realistic multi-RAT environment, we train RAT-aware Long Short Term Memory
(LSTM) networks to forecast the signal quality indicators of mobile users along
randomized trajectories. The proposed P-CHO models are trained and evaluated
under different channel models for cellular and IEEE 802.11 WiFi integrated
coverage. We study the impact of hyperparameter tuning of LSTM models under
different system settings, and compare direct multi-step versus recursive P-CHO
variants. Comparisons against baseline predictors are also carried out.
Finally, the proposed P-CHO is tested under soft and hard handover settings,
showing that hysteresis-enabled P-CHO scheme is able to reduce handover
failures and ping-pong events. Overall, the proposed P-CHO framework can enable
accurate, low-latency, and proactive handovers suitable for ML-assisted
handover steering in 6G multi-RAT deployments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems](https://arxiv.org/abs/2510.14133)
*Edoardo Allegrini,Ananth Shreekumar,Z. Berkay Celik*

Main category: cs.AI

TL;DR: 提出了一个用于多智能体AI系统的统一建模框架，包含主机智能体模型和任务生命周期模型，定义了31个形式化属性，支持系统行为的正式验证。


<details>
  <summary>Details</summary>
Motivation: 当前智能体间通信协议碎片化，存在语义鸿沟，无法对系统属性进行严格分析，存在架构错位和可被利用的协调问题等风险。

Method: 引入两个基础模型：主机智能体模型（负责与用户交互、任务分解和编排）和任务生命周期模型（详细描述子任务从创建到完成的状态转换），并定义了17个主机智能体属性和14个任务生命周期属性。

Result: 建立了第一个严格基础的、领域无关的框架，用于系统分析、设计和部署正确、可靠、鲁棒的智能体AI系统。

Conclusion: 该框架为多AI智能体系统的行为推理提供了统一的语义基础，能够通过时态逻辑进行形式化验证，检测协调边界情况，防止死锁和安全漏洞。

Abstract: Agentic AI systems, which leverage multiple autonomous agents and Large
Language Models (LLMs), are increasingly used to address complex, multi-step
tasks. The safety, security, and functionality of these systems are critical,
especially in high-stakes applications. However, the current ecosystem of
inter-agent communication is fragmented, with protocols such as the Model
Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol
for coordination being analyzed in isolation. This fragmentation creates a
semantic gap that prevents the rigorous analysis of system properties and
introduces risks such as architectural misalignment and exploitable
coordination issues. To address these challenges, we introduce a modeling
framework for agentic AI systems composed of two foundational models. The
first, the host agent model, formalizes the top-level entity that interacts
with the user, decomposes tasks, and orchestrates their execution by leveraging
external agents and tools. The second, the task lifecycle model, details the
states and transitions of individual sub-tasks from creation to completion,
providing a fine-grained view of task management and error handling. Together,
these models provide a unified semantic framework for reasoning about the
behavior of multi-AI agent systems. Grounded in this framework, we define 17
properties for the host agent and 14 for the task lifecycle, categorized into
liveness, safety, completeness, and fairness. Expressed in temporal logic,
these properties enable formal verification of system behavior, detection of
coordination edge cases, and prevention of deadlocks and security
vulnerabilities. Through this effort, we introduce the first rigorously
grounded, domain-agnostic framework for the systematic analysis, design, and
deployment of correct, reliable, and robust agentic AI systems.

</details>


### [14] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 提出轻量级多模态架构，融合传感器数据和视觉图像来预测文化遗产地点的退化严重程度，在数据稀缺情况下实现76.9%准确率。


<details>
  <summary>Details</summary>
Motivation: 文化遗产地点因气候变化加速退化，传统单模态监测方法无法捕捉环境压力与材料退化之间的复杂相互作用。

Method: 采用改进的PerceiverIO架构，包含简化编码器（64D潜在空间）和自适应Barlow Twins损失函数，鼓励模态互补性而非冗余。

Result: 在斯特拉斯堡大教堂数据上达到76.9%准确率，比标准多模态架构提升43%，比原始PerceiverIO提升25%。消融研究证实多模态协同成功。

Conclusion: 架构简化与对比正则化相结合，能够在数据稀缺的文化遗产监测环境中实现有效的多模态学习，为AI驱动的保护决策支持系统奠定基础。

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [15] [Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts](https://arxiv.org/abs/2510.14538)
*Emanuele Marconato,Samuele Bortolotti,Emile van Krieken,Paolo Morettin,Elena Umili,Antonio Vergari,Efthymia Tsamoura,Andrea Passerini,Stefano Teso*

Main category: cs.AI

TL;DR: 本文概述了神经符号AI中的推理捷径问题，讨论了其原因、后果及应对方法，旨在为开发可靠的神经符号AI模型提供统一视角。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI模型在缺乏概念监督时容易出现推理捷径问题，这会损害模型的可解释性、分布外性能及可靠性。现有研究分散，需要系统梳理以降低研究门槛。

Method: 提供推理捷径的直观介绍，分析其成因和影响，回顾现有理论特征，详细阐述包括缓解和意识策略在内的应对方法。

Result: 通过将高级材料重新表述为易于理解的形式，为理解推理捷径问题提供了统一视角，有助于开发更可靠的神经符号AI模型。

Conclusion: 本文通过系统梳理推理捷径问题，为研究人员和实践者提供了应对这一挑战性问题的框架，有望促进可靠神经符号AI和可信AI模型的发展。

Abstract: Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose
predictions comply with prior knowledge encoding, e.g. safety or structural
constraints. As such, it represents one of the most promising avenues for
reliable and trustworthy AI. The core idea behind NeSy AI is to combine neural
and symbolic steps: neural networks are typically responsible for mapping
low-level inputs into high-level symbolic concepts, while symbolic reasoning
infers predictions compatible with the extracted concepts and the prior
knowledge. Despite their promise, it was recently shown that - whenever the
concepts are not supervised directly - NeSy models can be affected by Reasoning
Shortcuts (RSs). That is, they can achieve high label accuracy by grounding the
concepts incorrectly. RSs can compromise the interpretability of the model's
explanations, performance in out-of-distribution scenarios, and therefore
reliability. At the same time, RSs are difficult to detect and prevent unless
concept supervision is available, which is typically not the case. However, the
literature on RSs is scattered, making it difficult for researchers and
practitioners to understand and tackle this challenging problem. This overview
addresses this issue by providing a gentle introduction to RSs, discussing
their causes and consequences in intuitive terms. It also reviews and
elucidates existing theoretical characterizations of this phenomenon. Finally,
it details methods for dealing with RSs, including mitigation and awareness
strategies, and maps their benefits and limitations. By reformulating advanced
material in a digestible form, this overview aims to provide a unifying
perspective on RSs to lower the bar to entry for tackling them. Ultimately, we
hope this overview contributes to the development of reliable NeSy and
trustworthy AI models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [Serialized EHR make for good text representations](https://arxiv.org/abs/2510.13843)
*Zhirong Chou,Quan Qin,Shi Li*

Main category: cs.CL

TL;DR: SerialBEHRT是一种针对电子健康记录(EHR)的领域对齐基础模型，通过结构化EHR序列的额外预训练扩展SciBERT，能更好捕捉临床事件间的时序和上下文关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以协调EHR的表格和事件性质与自然语言模型的序列先验之间的结构不匹配，限制了捕捉患者就诊间纵向依赖关系的能力。

Method: 通过额外预训练SciBERT在结构化EHR序列上，设计SerialBEHRT模型来编码临床事件间的时序和上下文关系。

Result: 在抗生素敏感性预测任务上，SerialBEHRT相比现有EHR表示策略实现了更优越和一致的表现。

Conclusion: 时序序列化在医疗基础模型预训练中具有重要意义，SerialBEHRT证明了其在捕捉临床事件依赖关系方面的有效性。

Abstract: The emergence of foundation models in healthcare has opened new avenues for
learning generalizable representations from large scale clinical data. Yet,
existing approaches often struggle to reconcile the tabular and event based
nature of Electronic Health Records (EHRs) with the sequential priors of
natural language models. This structural mismatch limits their ability to
capture longitudinal dependencies across patient encounters. We introduce
SerialBEHRT, a domain aligned foundation model that extends SciBERT through
additional pretraining on structured EHR sequences. SerialBEHRT is designed to
encode temporal and contextual relationships among clinical events, thereby
producing richer patient representations. We evaluate its effectiveness on the
task of antibiotic susceptibility prediction, a clinically meaningful problem
in antibiotic stewardship. Through extensive benchmarking against state of the
art EHR representation strategies, we demonstrate that SerialBEHRT achieves
superior and more consistent performance, highlighting the importance of
temporal serialization in foundation model pretraining for healthcare.

</details>


### [17] [Robust or Suggestible? Exploring Non-Clinical Induction in LLM Drug-Safety Decisions](https://arxiv.org/abs/2510.13931)
*Siying Liu,Shisheng Zhang,Indu Bala*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在药物安全预测中存在系统性偏见，会基于社会人口学信息（如教育、住房稳定性等）产生预测差异，劣势群体被分配更高的不良事件预测概率。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在药物安全预测中是否纳入临床无关的社会人口学信息，评估模型在真实世界部署场景中的公平性风险。

Method: 使用FDA不良事件报告系统结构化数据，基于人物角色评估框架，测试ChatGPT-4o和Bio-Medical-Llama-3.8B模型在不同社会人口学特征和用户角色下的表现。

Result: 发现系统性的预测准确性差异，劣势群体被分配更高的不良事件预测概率。识别出两种偏见模式：显性偏见（推理中直接引用人物属性）和隐性偏见（预测不一致但未明确提及人物属性）。

Conclusion: LLMs在药物警戒应用中存在严重风险，迫切需要公平性评估协议和缓解策略才能进行临床部署。

Abstract: Large language models (LLMs) are increasingly applied in biomedical domains,
yet their reliability in drug-safety prediction remains underexplored. In this
work, we investigate whether LLMs incorporate socio-demographic information
into adverse event (AE) predictions, despite such attributes being clinically
irrelevant. Using structured data from the United States Food and Drug
Administration Adverse Event Reporting System (FAERS) and a persona-based
evaluation framework, we assess two state-of-the-art models, ChatGPT-4o and
Bio-Medical-Llama-3.8B, across diverse personas defined by education, marital
status, employment, insurance, language, housing stability, and religion. We
further evaluate performance across three user roles (general practitioner,
specialist, patient) to reflect real-world deployment scenarios where
commercial systems often differentiate access by user type. Our results reveal
systematic disparities in AE prediction accuracy. Disadvantaged groups (e.g.,
low education, unstable housing) were frequently assigned higher predicted AE
likelihoods than more privileged groups (e.g., postgraduate-educated, privately
insured). Beyond outcome disparities, we identify two distinct modes of bias:
explicit bias, where incorrect predictions directly reference persona
attributes in reasoning traces, and implicit bias, where predictions are
inconsistent, yet personas are not explicitly mentioned. These findings expose
critical risks in applying LLMs to pharmacovigilance and highlight the urgent
need for fairness-aware evaluation protocols and mitigation strategies before
clinical deployment.

</details>


### [18] [Qwen3Guard Technical Report](https://arxiv.org/abs/2510.14276)
*Haiquan Zhao,Chenhan Yuan,Fei Huang,Xiaomeng Hu,Yichang Zhang,An Yang,Bowen Yu,Dayiheng Liu,Jingren Zhou,Junyang Lin,Baosong Yang,Chen Cheng,Jialong Tang,Jiandong Jiang,Jianwei Zhang,Jijie Xu,Ming Yan,Minmin Sun,Pei Zhang,Pengjun Xie,Qiaoyu Tang,Qin Zhu,Rong Zhang,Shibin Wu,Shuo Zhang,Tao He,Tianyi Tang,Tingyu Xia,Wei Liao,Weizhou Shen,Wenbiao Yin,Wenmeng Zhou,Wenyuan Yu,Xiaobin Wang,Xiaodong Deng,Xiaodong Xu,Xinyu Zhang,Yang Liu,Yeqiu Li,Yi Zhang,Yong Jiang,Yu Wan,Yuxin Zhou*

Main category: cs.CL

TL;DR: Qwen3Guard是一个多语言安全护栏模型系列，包含生成式和流式两个变体，支持细粒度三分类判断和实时安全监控，在多种语言基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有护栏模型存在两个主要限制：只能输出二元安全标签，无法适应不同领域的安全容忍度；需要完整模型输出才能进行安全检查，与流式LLM推理不兼容。

Method: 提出Qwen3Guard系列模型：生成式变体将安全分类转为指令跟随任务，实现细粒度三分类；流式变体引入token级分类头，支持增量文本生成的实时安全监控。提供0.6B、4B和8B三个参数规模。

Result: 在英语、中文和多语言基准测试中，Qwen3Guard在提示和响应安全分类方面达到最先进性能，支持119种语言和方言。

Conclusion: Qwen3Guard为全球LLM部署提供了全面、可扩展和低延迟的安全调节，所有模型均以Apache 2.0许可证公开发布。

Abstract: As large language models (LLMs) become more capable and widely used, ensuring
the safety of their outputs is increasingly critical. Existing guardrail
models, though useful in static evaluation settings, face two major limitations
in real-world applications: (1) they typically output only binary "safe/unsafe"
labels, which can be interpreted inconsistently across diverse safety policies,
rendering them incapable of accommodating varying safety tolerances across
domains; and (2) they require complete model outputs before performing safety
checks, making them fundamentally incompatible with streaming LLM inference,
thereby preventing timely intervention during generation and increasing
exposure to harmful partial outputs. To address these challenges, we present
Qwen3Guard, a series of multilingual safety guardrail models with two
specialized variants: Generative Qwen3Guard, which casts safety classification
as an instruction-following task to enable fine-grained tri-class judgments
(safe, controversial, unsafe); and Stream Qwen3Guard, which introduces a
token-level classification head for real-time safety monitoring during
incremental text generation. Both variants are available in three sizes (0.6B,
4B, and 8B parameters) and support up to 119 languages and dialects, providing
comprehensive, scalable, and low-latency safety moderation for global LLM
deployments. Evaluated across English, Chinese, and multilingual benchmarks,
Qwen3Guard achieves state-of-the-art performance in both prompt and response
safety classification. All models are released under the Apache 2.0 license for
public use.

</details>


### [19] [Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts](https://arxiv.org/abs/2510.14351)
*Perapard Ngokpol,Kun Kerdthaisong,Pasin Buakhaw,Pitikorn Khlaisamniang,Supasate Vorathammathorn,Piyalitt Ittichaiwong,Nutchanon Yongsatianchot*

Main category: cs.CL

TL;DR: 提出了Beyond One World基准测试，用于评估LLM在角色扮演中准确表现特定版本角色的能力，包含30个英雄的90个版本，测试事实回忆和道德困境处理。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在角色扮演中能否忠实一致地表现特定版本角色（如不同宇宙中的超级英雄），因为现有研究对此关注不足。

Method: 构建包含30个标志性英雄和90个特定版本角色的基准测试，包含两个任务：经典事件（事实回忆）和道德困境（伦理场景），并提出了Think-Act Matching指标来量化推理与行动的一致性。

Result: 实验发现：思维链提示能改善较弱模型的叙事连贯性但会降低较强模型的准确性；跨版本泛化仍是主要障碍；模型通常在思考或行动中表现优异，但很少同时擅长两者。

Conclusion: Beyond One World揭示了LLM在多宇宙一致性和推理对齐方面存在关键差距，为角色扮演LLM提供了具有挑战性的评估标准。

Abstract: Large language models (LLMs) are increasingly used as role-playing agents,
yet their capacity to faithfully and consistently portray version-specific
characters -- for example, superheroes across comic and cinematic universes --
remains underexplored. Superhero canons such as Marvel and DC provide a rich
testbed: decades of storytelling yield multiple incarnations of the same
character with distinct histories, values, and moral codes. To study this
problem, we introduce Beyond One World, a benchmark for character-grounded
roleplay spanning 30 iconic heroes and 90 canon-specific versions. The
benchmark comprises two tasks: (i) Canon Events, which probes factual recall of
pivotal life stages, and (ii) Moral Dilemmas, which confronts models with
ethically charged scenarios. We score responses for canonical accuracy and
reasoning fidelity under a framework that separates internal deliberation
("thinking") from outward decisions ("acting"). We further propose Think-Act
Matching, a metric that quantifies alignment between reasons and actions and
serves as a proxy for model trustworthiness. Experiments across reasoning- and
non-reasoning-oriented models yield three findings: (1) chain-of-thought
prompting improves narrative coherence in weaker models but can reduce
canonical accuracy in stronger ones; (2) cross-version generalization within a
character remains a major obstacle; and (3) models often excel at either
thinking or acting, but rarely both. Beyond One World exposes critical gaps in
multiversal consistency and reasoning alignment, offering a challenging
evaluation for role-playing LLMs.

</details>


### [20] [Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models](https://arxiv.org/abs/2510.14853)
*Guinan Su,Yanwu Yang,Li Shen,Lu Yin,Shiwei Liu,Jonas Geiping*

Main category: cs.CL

TL;DR: 提出了一种无需外部数据的在线测试时框架，通过自监督优化MoE模型的路由决策，在文本生成过程中持续改进专家选择。


<details>
  <summary>Details</summary>
Motivation: MoE模型在部署中常因分布偏移导致路由决策不理想，现有测试时适应方法主要针对密集模型且需要外部数据，不适用于MoE架构。

Method: 采用两阶段循环：在预填充阶段和定期间隔中，基于已生成序列通过自监督优化路由决策；然后正常生成文本，保持修改后的路由器直到下一次适应。通过轻量级加法向量仅更新选定层的路由器logits。

Result: 在具有挑战性的推理任务上获得持续性能提升，同时保持对上下文偏移的鲁棒性。例如在HumanEval上实现5.5%提升，与自一致性结合时在DeepSeek-V2-Lite上获得6%平均增益。

Conclusion: 该方法提供了一种无需数据、即插即用的在线测试时适应框架，能有效改进MoE模型的路由决策，并与现有测试时扩展技术自然互补。

Abstract: Mixture-of-Experts (MoE) models achieve efficient scaling through sparse
expert activation, but often suffer from suboptimal routing decisions due to
distribution shifts in deployment. While existing test-time adaptation methods
could potentially address these issues, they primarily focus on dense models
and require access to external data, limiting their practical applicability to
MoE architectures. However, we find that, instead of relying on reference data,
we can optimize MoE expert selection on-the-fly based only on input context. As
such, we propose \textit{a data-free, online test-time framework} that
continuously adapts MoE routing decisions during text generation without
external supervision or data. Our method cycles between two phases: During the
prefill stage, and later in regular intervals, we optimize the routing
decisions of the model using self-supervision based on the already generated
sequence. Then, we generate text as normal, maintaining the modified router
until the next adaption. We implement this through lightweight additive vectors
that only update router logits in selected layers, maintaining computational
efficiency while preventing over-adaptation. The experimental results show
consistent performance gains on challenging reasoning tasks while maintaining
robustness to context shifts. For example, our method achieves a 5.5\%
improvement on HumanEval with OLMoE. Furthermore, owing to its plug-and-play
property, our method naturally complements existing test-time scaling
techniques, e.g., achieving 6\% average gains when incorporated with
self-consistency on DeepSeek-V2-Lite.

</details>
