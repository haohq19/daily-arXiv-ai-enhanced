<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 11]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.CL](#cs.CL) [Total: 7]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Semantic Event Graphs for Long-Form Video Question Answering](https://arxiv.org/abs/2601.06097)
*Aradhya Dixit,Tianxi Liang*

Main category: cs.CV

TL;DR: 提出语义事件图(SEG)作为视频与语言模型间的轻量符号接口，用紧凑的时序交互日志替代原始帧，在长视频问答中实现91.4%的token节省和65%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在处理小时级长视频时面临token和计算预算限制，现有方法通常通过降采样帧或密集视觉嵌入来权衡时间覆盖与成本，需要更高效的时序推理方法。

Method: 使用YOLOv11检测跟踪对象，将邻近模式转换为START/END人-物事件，组织成时序场景图(TSG)。推理时通过查询感知剪枝模块识别锚点实体和相关事件，返回小子图并语言化后传递给Gemini 2.5 Flash生成答案。

Result: 在5个YouTube视频(各300-500个交互)和120个自动生成长视野问题上，SEG仅用3.47k token达到65.0%准确率，接近完整日志基线(62.5%用40.39k token)，token使用减少91.4%。仅使用最后30秒的短上下文基线准确率降至2.5%。

Conclusion: 符号时序图可作为现成视觉语言模型的有效即插即用记忆层，在保持长距离推理能力的同时，显著提高长视频问答的token效率和成本效益。

Abstract: Long-form video question answering remains challenging for modern vision-language models, which struggle to reason over hour-scale footage without exceeding practical token and compute budgets. Existing systems typically downsample frames or feed dense visual embeddings to large-context language models, trading off temporal coverage against cost. We propose Semantic Event Graphs (SEG), a lightweight symbolic interface between video and language that replaces raw frames with compact temporal interaction logs. Our pipeline detects and tracks objects with YOLOv11, converts proximity patterns into START/END human-object events, and organizes them into a Temporal Scene Graph (TSG). At inference time, a query-aware pruning module identifies anchor entities and lexically relevant events, returning only a small subgraph which is verbalized and passed to Gemini 2.5 Flash for answer generation. On five YouTube videos (300-500 interactions each) and 120 automatically generated long-horizon questions, SEG achieves 65.0% accuracy using only 3.47k tokens per query, closely matching a full-log baseline (62.5% at 40.39k tokens) while reducing token usage by 91.4%. A short-context baseline restricted to the last 30 seconds collapses to 2.5% accuracy, underscoring the need for explicit temporal memory. These results show that symbolic temporal graphs can serve as an effective, plug-and-play memory layer for off-the-shelf vision-language models, preserving long-range reasoning ability while making long-form video question answering substantially more token- and cost-efficient. Code, logs, and event-extraction tools will be released for reproducibility.

</details>


### [2] [Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification](https://arxiv.org/abs/2601.06204)
*Tayyab Rehman,Giovanni De Gasperis,Aly Shmahell*

Main category: cs.CV

TL;DR: 提出一个级联多智能体框架，通过结合重建、目标检测和视觉语言推理，实现高效且可解释的视觉异常检测。


<details>
  <summary>Details</summary>
Motivation: 动态视觉环境中的智能异常检测需要平衡实时性能与语义可解释性。现有方法各有局限：重建模型缺乏上下文推理，目标检测器速度快但语义有限，视觉语言系统可解释但计算成本过高。

Method: 采用级联多智能体框架，早期模块进行重建门控过滤和目标级评估，高层推理智能体选择性激活处理语义模糊事件。系统使用自适应升级阈值和发布-订阅通信骨干，支持异步协调和异构硬件部署。

Result: 在大规模监控数据上的评估显示，相比直接视觉语言推理，级联框架延迟减少三倍，同时保持高感知保真度（PSNR = 38.3 dB, SSIM = 0.965）和一致的语义标注。

Conclusion: 该框架结合早期退出效率、自适应多智能体推理和可解释异常归因，超越了传统检测流程，为可扩展的智能视觉监控建立了可重复且节能的基础。

Abstract: Intelligent anomaly detection in dynamic visual environments requires reconciling real-time performance with semantic interpretability. Conventional approaches address only fragments of this challenge. Reconstruction-based models capture low-level deviations without contextual reasoning, object detectors provide speed but limited semantics, and large vision-language systems deliver interpretability at prohibitive computational cost. This work introduces a cascading multi-agent framework that unifies these complementary paradigms into a coherent and interpretable architecture. Early modules perform reconstruction-gated filtering and object-level assessment, while higher-level reasoning agents are selectively invoked to interpret semantically ambiguous events. The system employs adaptive escalation thresholds and a publish-subscribe communication backbone, enabling asynchronous coordination and scalable deployment across heterogeneous hardware. Extensive evaluation on large-scale monitoring data demonstrates that the proposed cascade achieves a threefold reduction in latency compared to direct vision-language inference, while maintaining high perceptual fidelity (PSNR = 38.3 dB, SSIM = 0.965) and consistent semantic labeling. The framework advances beyond conventional detection pipelines by combining early-exit efficiency, adaptive multi-agent reasoning, and explainable anomaly attribution, establishing a reproducible and energy-efficient foundation for scalable intelligent visual monitoring.

</details>


### [3] [NAS-GS: Noise-Aware Sonar Gaussian Splatting](https://arxiv.org/abs/2601.06285)
*Shida Xu,Jingqi Jiang,Jonatan Scharff Willners,Sen Wang*

Main category: cs.CV

TL;DR: NAS-GS：一种针对声纳图像的新型噪声感知高斯溅射框架，通过双向溅射技术和GMM噪声模型，显著提升3D重建和新视角合成的质量与速度。


<details>
  <summary>Details</summary>
Motivation: 水下声纳成像在自主导航、海洋考古等领域至关重要，但声纳图像特有的复杂噪声模式和缺乏高程信息给3D重建和新视角合成带来巨大挑战。

Method: 提出NAS-GS框架：1）双向溅射技术，精确建模声纳成像中的强度累积和透射率计算的双向特性；2）基于高斯混合模型的噪声模型，捕捉侧瓣、散斑和多径噪声等复杂噪声模式。

Result: 在模拟和真实世界的大规模离岸声纳场景中实现最先进性能，在新视角合成和3D重建方面取得优异结果，渲染速度显著提升且质量不降。

Conclusion: NAS-GS框架有效解决了声纳图像3D重建的挑战，通过创新的双向溅射和噪声建模技术，为水下声纳成像应用提供了高质量的解决方案。

Abstract: Underwater sonar imaging plays a crucial role in various applications, including autonomous navigation in murky water, marine archaeology, and environmental monitoring. However, the unique characteristics of sonar images, such as complex noise patterns and the lack of elevation information, pose significant challenges for 3D reconstruction and novel view synthesis. In this paper, we present NAS-GS, a novel Noise-Aware Sonar Gaussian Splatting framework specifically designed to address these challenges. Our approach introduces a Two-Ways Splatting technique that accurately models the dual directions for intensity accumulation and transmittance calculation inherent in sonar imaging, significantly improving rendering speed without sacrificing quality. Moreover, we propose a Gaussian Mixture Model (GMM) based noise model that captures complex sonar noise patterns, including side-lobes, speckle, and multi-path noise. This model enhances the realism of synthesized images while preventing 3D Gaussian overfitting to noise, thereby improving reconstruction accuracy. We demonstrate state-of-the-art performance on both simulated and real-world large-scale offshore sonar scenarios, achieving superior results in novel view synthesis and 3D reconstruction.

</details>


### [4] [ArrowGEV: Grounding Events in Video via Learning the Arrow of Time](https://arxiv.org/abs/2601.06559)
*Fangxu Yu,Ziyao Lu,Liqiang Niu,Fandong Meng,Jie Zhou*

Main category: cs.CV

TL;DR: ArrowGEV：基于强化学习的视频事件定位框架，通过建模时间方向性（前向/后向视频）提升视觉语言模型的事件定位能力和时间方向理解能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在视频事件定位任务中主要训练模型关联事件与前向视频的时间戳，这种范式限制了模型捕捉事件内在时间结构和方向性的能力，从而影响了鲁棒性和泛化性

Method: 提出ArrowGEV强化学习框架，受物理学中"时间箭头"启发，将事件分为时间敏感型（如放下包）和时间不敏感型（如左手拿毛巾）。对时间敏感事件，引入奖励机制鼓励VLM区分前向和后向视频；对时间不敏感事件，强制要求在两个方向上保持一致的定位结果

Result: 大量实验表明，ArrowGEV不仅提高了事件定位精度和时间方向性识别能力，还增强了通用的视频理解和推理能力

Conclusion: 通过显式建模事件的时间方向性，ArrowGEV框架能够显著提升视觉语言模型在视频事件定位任务中的性能，同时增强模型对时间结构的内在理解

Abstract: Grounding events in videos serves as a fundamental capability in video analysis. While Vision-Language Models (VLMs) are increasingly employed for this task, existing approaches predominantly train models to associate events with timestamps in the forward video only. This paradigm hinders VLMs from capturing the inherent temporal structure and directionality of events, thereby limiting robustness and generalization. To address this limitation, inspired by the arrow of time in physics, which characterizes the intrinsic directionality of temporal processes, we propose ArrowGEV, a reinforcement learning framework that explicitly models temporal directionality in events to improve both event grounding and temporal directionality understanding in VLMs. Specifically, we categorize events into time-sensitive (e.g., putting down a bag) and time-insensitive (e.g., holding a towel in the left hand). The former denote events whose reversal substantially alters their meaning, while the latter remain semantically unchanged under reversal. For time-sensitive events, ArrowGEV introduces a reward that encourages VLMs to discriminate between forward and backward videos, whereas for time-insensitive events, it enforces consistent grounding across both directions. Extensive experiments demonstrate that ArrowGEV not only improves grounding precision and temporal directionality recognition, but also enhances general video understanding and reasoning ability.

</details>


### [5] [eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers](https://arxiv.org/abs/2601.06647)
*Krishna Vinod,Joseph Raj Vishal,Kaustav Chanda,Prithvi Jai Ramesh,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 提出首个基于事件相机的滑雪追踪数据集eSkiTB，通过SDTrack（脉冲变压器）与RGB方法对比，证明事件相机在广播视频遮挡场景中具有更强鲁棒性，IoU提升20个百分点。


<details>
  <summary>Details</summary>
Motivation: 传统RGB广播视频中滑雪者追踪面临运动模糊、静态覆盖物和杂乱背景的挑战，而事件相机具有异步对比度感知特性，天然对这些干扰具有鲁棒性，但缺乏冬季运动追踪的基准数据集。

Method: 从SkiTB数据集通过直接视频到事件转换生成合成事件数据集eSkiTB（不使用神经插值），实现RGB和事件模态的等量信息比较。使用SDTrack（脉冲变压器）与STARK（RGB变压器）进行基准测试。

Result: 在静态覆盖物主导的场景中，事件追踪对广播杂乱具有显著鲁棒性，达到0.685 IoU，比RGB方法高出20.0个百分点。在整个数据集上，SDTrack平均IoU为0.711。

Conclusion: 时间对比度是视觉拥挤环境中追踪弹道运动的可靠线索。eSkiTB建立了冬季运动事件追踪的首个受控设置，展示了事件相机在滑雪追踪中的潜力。

Abstract: Tracking skiers in RGB broadcast footage is challenging due to motion blur, static overlays, and clutter that obscure the fast-moving athlete. Event cameras, with their asynchronous contrast sensing, offer natural robustness to such artifacts, yet a controlled benchmark for winter-sport tracking has been missing. We introduce event SkiTB (eSkiTB), a synthetic event-based ski tracking dataset generated from SkiTB using direct video-to-event conversion without neural interpolation, enabling an iso-informational comparison between RGB and event modalities. Benchmarking SDTrack (spiking transformer) against STARK (RGB transformer), we find that event-based tracking is substantially resilient to broadcast clutter in scenes dominated by static overlays, achieving 0.685 IoU, outperforming RGB by +20.0 points. Across the dataset, SDTrack attains a mean IoU of 0.711, demonstrating that temporal contrast is a reliable cue for tracking ballistic motion in visually congested environments. eSkiTB establishes the first controlled setting for event-based tracking in winter sports and highlights the promise of event cameras for ski tracking. The dataset and code will be released at https://github.com/eventbasedvision/eSkiTB.

</details>


### [6] [Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models](https://arxiv.org/abs/2601.06843)
*Junyan Lin,Junlong Tong,Hao Wu,Jialiang Zhang,Jinming Liu,Xin Jin,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 提出并行流式框架解决MLLMs实时视频理解中的位置连续性约束瓶颈，通过三种设计实现感知与生成的并行处理，显著降低延迟


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs大多限于离线推理，需要完整输入才能生成输出。流式方法虽然减少延迟，但仍强制顺序的感知-生成循环，限制了实时交互。特别是标准位置编码方案施加的全局位置连续性约束，在实时视频理解中成为瓶颈

Method: 提出并行流式框架，通过三种设计放松位置连续性约束：重叠式、组解耦式和间隔隔离式。这些设计使模型能够同时处理输入和生成响应，实现感知与生成的并行

Result: 实验表明组解耦式设计在效率与性能间达到最佳平衡，保持高流畅度和准确性的同时显著降低延迟。在平衡的感知-生成工作负载下，框架可实现高达2倍的加速

Conclusion: 提出的并行流式框架有效解决了MLLMs实时视频理解中的位置连续性约束问题，为实现"边看边说"的实时系统建立了原则性路径

Abstract: Multimodal Large Language Models (MLLMs) have achieved strong performance across many tasks, yet most systems remain limited to offline inference, requiring complete inputs before generating outputs. Recent streaming methods reduce latency by interleaving perception and generation, but still enforce a sequential perception-generation cycle, limiting real-time interaction. In this work, we target a fundamental bottleneck that arises when extending MLLMs to real-time video understanding: the global positional continuity constraint imposed by standard positional encoding schemes. While natural in offline inference, this constraint tightly couples perception and generation, preventing effective input-output parallelism. To address this limitation, we propose a parallel streaming framework that relaxes positional continuity through three designs: Overlapped, Group-Decoupled, and Gap-Isolated. These designs enable simultaneous perception and generation, allowing the model to process incoming inputs while producing responses in real time. Extensive experiments reveal that Group-Decoupled achieves the best efficiency-performance balance, maintaining high fluency and accuracy while significantly reducing latency. We further show that the proposed framework yields up to 2x acceleration under balanced perception-generation workloads, establishing a principled pathway toward speak-while-watching real-time systems. We make all our code publicly available: https://github.com/EIT-NLP/Speak-While-Watching.

</details>


### [7] [MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.07107)
*Meng Lu,Yuxing Lu,Yuchen Zhuang,Megan Mullins,Yang Xie,Guanghua Xiao,Charles Fleming,Wenqi Shi,Xuan Wang*

Main category: cs.CV

TL;DR: MedVistaGym是一个用于医学视觉语言模型的可扩展交互训练环境，通过强化学习训练模型在医学图像分析中进行工具集成的视觉推理，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在医学图像理解上表现不佳，特别是缺乏多步推理和迭代视觉交互能力。医学VLM通常依赖静态视觉嵌入和单次推理，无法在推理过程中重新检查、验证或细化视觉证据。虽然工具集成推理提供了有前景的路径，但开源VLM缺乏学习有效工具选择、调用和协调的训练基础设施。

Method: 提出MedVistaGym训练环境，激励医学图像分析中的工具集成视觉推理。该系统训练VLM决定何时调用哪些工具、定位任务相关图像区域，并将单个或多个子图像证据集成到交错的多模态推理中。通过轨迹采样和端到端强化学习训练MedVistaGym-R1模型，实现工具使用与代理推理的交错。

Result: 在六个医学VQA基准测试中，MedVistaGym-R1-8B模型比同等规模工具增强基线提升了19.10%到24.21%，表明结构化代理训练（不仅仅是工具访问）能够有效解锁医学图像分析中的工具集成推理能力。

Conclusion: MedVistaGym通过提供可扩展的交互训练环境，成功解决了医学VLM在工具集成推理方面的训练基础设施缺失问题，证明了结构化代理训练对于解锁医学图像分析中有效工具集成推理的关键作用。

Abstract: Vision language models (VLMs) achieve strong performance on general image understanding but struggle to think with medical images, especially when performing multi-step reasoning through iterative visual interaction. Medical VLMs often rely on static visual embeddings and single-pass inference, preventing models from re-examining, verifying, or refining visual evidence during reasoning. While tool-integrated reasoning offers a promising path forward, open-source VLMs lack the training infrastructure to learn effective tool selection, invocation, and coordination in multi-modal medical reasoning. We introduce MedVistaGym, a scalable and interactive training environment that incentivizes tool-integrated visual reasoning for medical image analysis. MedVistaGym equips VLMs to determine when and which tools to invoke, localize task-relevant image regions, and integrate single or multiple sub-image evidence into interleaved multimodal reasoning within a unified, executable interface for agentic training. Using MedVistaGym, we train MedVistaGym-R1 to interleave tool use with agentic reasoning through trajectory sampling and end-to-end reinforcement learning. Across six medical VQA benchmarks, MedVistaGym-R1-8B exceeds comparably sized tool-augmented baselines by 19.10% to 24.21%, demonstrating that structured agentic training--not tool access alone--unlocks effective tool-integrated reasoning for medical image analysis.

</details>


### [8] [Inference-Time Scaling for Visual AutoRegressive modeling by Searching Representative Samples](https://arxiv.org/abs/2601.07293)
*Weidong Tang,Xinyan Wan,Siyu Li,Xiumei Wang*

Main category: cs.CV

TL;DR: 本文提出了VAR-Scaling框架，首次将推理时间缩放应用于向量量化视觉自回归模型，通过核密度估计将离散潜在空间映射到准连续特征空间，并采用密度自适应混合采样策略优化生成质量。


<details>
  <summary>Details</summary>
Motivation: 虽然推理时间缩放在大语言模型和扩散模型中显著提升了生成质量，但在向量量化视觉自回归模型中的应用尚未探索。主要挑战在于离散潜在空间阻碍了连续路径搜索，需要解决这一技术障碍。

Method: 通过核密度估计将离散采样空间映射到准连续特征空间，识别VAR缩放中的两种模式类型（通用模式和特定模式），并提出密度自适应混合采样策略：Top-k采样关注高密度区域保持质量，Random-k采样探索低密度区域维持多样性。

Result: 在类别条件和文本到图像的评估实验中，VAR-Scaling在推理过程中表现出显著改进，优化了关键尺度上的样本保真度，从而提升了输出质量。

Conclusion: VAR-Scaling是首个用于向量量化视觉自回归模型的推理时间缩放框架，成功克服了离散潜在空间的挑战，通过准连续特征空间映射和混合采样策略有效提升了生成质量。

Abstract: While inference-time scaling has significantly enhanced generative quality in large language and diffusion models, its application to vector-quantized (VQ) visual autoregressive modeling (VAR) remains unexplored. We introduce VAR-Scaling, the first general framework for inference-time scaling in VAR, addressing the critical challenge of discrete latent spaces that prohibit continuous path search. We find that VAR scales exhibit two distinct pattern types: general patterns and specific patterns, where later-stage specific patterns conditionally optimize early-stage general patterns. To overcome the discrete latent space barrier in VQ models, we map sampling spaces to quasi-continuous feature spaces via kernel density estimation (KDE), where high-density samples approximate stable, high-quality solutions. This transformation enables effective navigation of sampling distributions. We propose a density-adaptive hybrid sampling strategy: Top-k sampling focuses on high-density regions to preserve quality near distribution modes, while Random-k sampling explores low-density areas to maintain diversity and prevent premature convergence. Consequently, VAR-Scaling optimizes sample fidelity at critical scales to enhance output quality. Experiments in class-conditional and text-to-image evaluations demonstrate significant improvements in inference process. The code is available at https://github.com/WD7ang/VAR-Scaling.

</details>


### [9] [HiVid-Narrator: Hierarchical Video Narrative Generation with Scene-Primed ASR-anchored Compression](https://arxiv.org/abs/2601.07366)
*Haoxuan Li,Mengyan Li,Junjun Zheng*

Main category: cs.CV

TL;DR: 本文提出E-HVC数据集和HiVid-Narrator框架，用于生成电商视频的结构化叙事，通过双粒度标注和分层压缩方法提升叙事质量并减少输入token。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以统一感知细粒度视觉细节并将其组织成连贯高级故事的能力，电商视频节奏快、信息密集，视觉token主导输入序列，需要更有效的处理方法。

Method: 1) 构建E-HVC数据集，包含时间链式思维和章节摘要双粒度标注；2) 采用分阶段构建方法，先收集ASR和帧级描述证据，再基于时间链式思维精炼章节边界；3) 提出SPA-Compressor压缩多模态token为分层场景和事件表示；4) 建立HiVid-Narrator框架。

Result: HiVid-Narrator框架相比现有方法，以更少的输入token实现了更优的叙事质量。

Conclusion: 通过双粒度标注、分阶段构建和分层压缩方法，能够有效生成事实基础、时间对齐的电商视频结构化叙事，解决了现有方法在感知细节和组织故事方面的不足。

Abstract: Generating structured narrations for real-world e-commerce videos requires models to perceive fine-grained visual details and organize them into coherent, high-level stories--capabilities that existing approaches struggle to unify. We introduce the E-commerce Hierarchical Video Captioning (E-HVC) dataset with dual-granularity, temporally grounded annotations: a Temporal Chain-of-Thought that anchors event-level observations and Chapter Summary that compose them into concise, story-centric summaries. Rather than directly prompting chapters, we adopt a staged construction that first gathers reliable linguistic and visual evidence via curated ASR and frame-level descriptions, then refines coarse annotations into precise chapter boundaries and titles conditioned on the Temporal Chain-of-Thought, yielding fact-grounded, time-aligned narratives. We also observe that e-commerce videos are fast-paced and information-dense, with visual tokens dominating the input sequence. To enable efficient training while reducing input tokens, we propose the Scene-Primed ASR-anchored Compressor (SPA-Compressor), which compresses multimodal tokens into hierarchical scene and event representations guided by ASR semantic cues. Built upon these designs, our HiVid-Narrator framework achieves superior narrative quality with fewer input tokens compared to existing methods.

</details>


### [10] [Anatomy Aware Cascade Network: Bridging Epistemic Uncertainty and Geometric Manifold for 3D Tooth Segmentation](https://arxiv.org/abs/2601.07499)
*Bing Yu,Liu Shi,Haitao Wang,Deran Qi,Xiang Cai,Wei Zhong,Qiegen Liu*

Main category: cs.CV

TL;DR: AACNet是一个用于CBCT图像中牙齿三维分割的级联网络，通过引入边界细化器和符号距离图注意力机制，有效解决了牙齿粘连和边界模糊问题，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: CBCT图像中牙齿的三维分割是数字化牙科工作流程的前提，但由于低对比度和不清晰的牙弓边界导致的粘连伪影，实现高保真分割仍然具有挑战性。

Method: 提出AACNet（Anatomy Aware Cascade Network），这是一个从粗到细的框架，包含两个关键机制：1) Ambiguity Gated Boundary Refiner (AGBR)：使用基于熵的门控机制在高度不确定的过渡区域进行有针对性的特征校正；2) Signed Distance Map guided Anatomical Attention (SDMAA)：通过符号距离图集成隐式几何约束，强制执行拓扑一致性，防止标准池化操作导致的空间细节丢失。

Result: 在125个CBCT体积数据集上，AACNet实现了90.17%的Dice相似系数和3.63mm的95% Hausdorff距离，显著优于现有最先进方法。在外部数据集上表现出强大的泛化能力，HD95为2.19mm。

Conclusion: AACNet通过解决边界模糊和保持全局结构一致性，有效提升了CBCT牙齿分割的准确性，验证了其在手术规划等下游临床应用中的可靠性。

Abstract: Accurate three-dimensional (3D) tooth segmentation from Cone-Beam Computed Tomography (CBCT) is a prerequisite for digital dental workflows. However, achieving high-fidelity segmentation remains challenging due to adhesion artifacts in naturally occluded scans, which are caused by low contrast and indistinct inter-arch boundaries. To address these limitations, we propose the Anatomy Aware Cascade Network (AACNet), a coarse-to-fine framework designed to resolve boundary ambiguity while maintaining global structural consistency. Specifically, we introduce two mechanisms: the Ambiguity Gated Boundary Refiner (AGBR) and the Signed Distance Map guided Anatomical Attention (SDMAA). The AGBR employs an entropy based gating mechanism to perform targeted feature rectification in high uncertainty transition zones. Meanwhile, the SDMAA integrates implicit geometric constraints via signed distance map to enforce topological consistency, preventing the loss of spatial details associated with standard pooling. Experimental results on a dataset of 125 CBCT volumes demonstrate that AACNet achieves a Dice Similarity Coefficient of 90.17 \% and a 95\% Hausdorff Distance of 3.63 mm, significantly outperforming state-of-the-art methods. Furthermore, the model exhibits strong generalization on an external dataset with an HD95 of 2.19 mm, validating its reliability for downstream clinical applications such as surgical planning. Code for AACNet is available at https://github.com/shiliu0114/AACNet.

</details>


### [11] [Diffusion in SPAD Signals](https://arxiv.org/abs/2601.07599)
*Lior Dvir,Nadav Torem,Yoav Y. Schechner*

Main category: cs.CV

TL;DR: 该论文推导了单光子雪崩二极管(SPAD)原始信号的似然函数，建立了光子通量与检测事件时序之间的非线性随机关系，并基于此开发了用于逆问题求解的扩散模型方法。


<details>
  <summary>Details</summary>
Motivation: SPAD信号包含检测事件的时序信息，这些信息与光子通量呈非线性关系且具有随机性。需要建立准确的似然模型来有效利用这些信号解决逆问题，特别是在低光子计数条件下。

Method: 推导了SPAD原始信号的似然函数，建立了光子通量与检测事件时序之间的数学关系。进一步推导了信号的评分函数，并采用扩散模型来表达图像先验，从而解决基于SPAD信号的逆问题。

Result: 成功建立了SPAD信号的完整概率模型，开发了基于扩散模型的逆问题求解框架。展示了在不同光子计数条件下（低/高）的性能，并验证了利用检测事件时序信息的重要性。

Conclusion: 该研究为SPAD信号处理提供了严格的概率基础，所提出的扩散模型框架能够有效利用时序信息解决逆问题，特别是在低光子计数条件下表现出优势。

Abstract: We derive the likelihood of a raw signal in a single photon avalanche diode (SPAD), given a fixed photon flux. The raw signal comprises timing of detection events, which are nonlinearly related to the flux. Moreover, they are naturally stochastic. We then derive a score function of the signal. This is a key for solving inverse problems based on SPAD signals. We focus on deriving solutions involving a diffusion model, to express image priors. We demonstrate the effect of low or high photon counts, and the consequence of exploiting timing of detection events.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [CrossTrafficLLM: A Human-Centric Framework for Interpretable Traffic Intelligence via Large Language Model](https://arxiv.org/abs/2601.06042)
*Zeming Du,Qitan Shao,Hongfei Liu,Yong Zhang*

Main category: cs.LG

TL;DR: CrossTrafficLLM是一个统一的GenAI框架，同时预测交通状态并生成自然语言描述，特别针对异常事件摘要，通过LLM对齐定量数据与定性语义。


<details>
  <summary>Details</summary>
Motivation: 当前ITS中交通预测与自然语言描述通常是分开处理的，缺乏统一的框架来同时提供准确预测和人类可理解的解释，特别是针对异常事件的描述。

Method: 提出CrossTrafficLLM框架，利用LLM在统一架构中对齐定量交通数据与定性文本语义，采用文本引导的自适应图卷积网络融合高层语义信息与交通网络结构。

Result: 在BJTT数据集上评估，CrossTrafficLLM在交通预测性能和文本生成质量方面均超越现有最先进方法。

Conclusion: 通过统一预测和描述生成，CrossTrafficLLM提供了更可解释、可操作的生成式交通智能方法，为现代ITS应用带来显著优势。

Abstract: While accurate traffic forecasting is vital for Intelligent Transportation Systems (ITS), effectively communicating predicted conditions via natural language for human-centric decision support remains a challenge and is often handled separately. To address this, we propose CrossTrafficLLM, a novel GenAI-driven framework that simultaneously predicts future spatiotemporal traffic states and generates corresponding natural language descriptions, specifically targeting conditional abnormal event summaries. We tackle the core challenge of aligning quantitative traffic data with qualitative textual semantics by leveraging Large Language Models (LLMs) within a unified architecture. This design allows generative textual context to improve prediction accuracy while ensuring generated reports are directly informed by the forecast. Technically, a text-guided adaptive graph convolutional network is employed to effectively merge high-level semantic information with the traffic network structure. Evaluated on the BJTT dataset, CrossTrafficLLM demonstrably surpasses state-of-the-art methods in both traffic forecasting performance and text generation quality. By unifying prediction and description generation, CrossTrafficLLM delivers a more interpretable, and actionable approach to generative traffic intelligence, offering significant advantages for modern ITS applications.

</details>


### [13] [Australian Bushfire Intelligence with AI-Driven Environmental Analytics](https://arxiv.org/abs/2601.06105)
*Tanvi Jois,Hussain Ahmad,Fatima Noor,Faheem Ullah*

Main category: cs.LG

TL;DR: 该研究整合多源环境数据，使用机器学习模型预测澳大利亚高火灾风险区域，集成分类器达到87%准确率。


<details>
  <summary>Details</summary>
Motivation: 澳大利亚丛林火灾破坏性极强，准确预测火灾强度对灾害准备和响应至关重要，需要利用时空环境数据进行风险识别。

Method: 整合NASA FIRMS历史火灾数据、Meteostat气象观测和Google Earth Engine植被指数（NDVI），通过时空连接统一数据集，评估随机森林、XGBoost、LightGBM、MLP和集成分类器等多种机器学习模型。

Result: 在区分"低"和"高"火灾风险的二元分类框架下，集成方法达到87%的准确率，证明多源环境特征与先进机器学习技术结合能产生可靠的火灾强度预测。

Conclusion: 结合多源环境数据和机器学习技术可以为丛林火灾强度提供可靠预测，支持更明智和及时的灾害管理决策。

Abstract: Bushfires are among the most destructive natural hazards in Australia, causing significant ecological, economic, and social damage. Accurate prediction of bushfire intensity is therefore essential for effective disaster preparedness and response. This study examines the predictive capability of spatio-temporal environmental data for identifying high-risk bushfire zones across Australia. We integrated historical fire events from NASA FIRMS, daily meteorological observations from Meteostat, and vegetation indices such as the Normalized Difference Vegetation Index (NDVI) from Google Earth Engine for the period 2015-2023. After harmonizing the datasets using spatial and temporal joins, we evaluated several machine learning models, including Random Forest, XGBoost, LightGBM, a Multi-Layer Perceptron (MLP), and an ensemble classifier. Under a binary classification framework distinguishing 'low' and 'high' fire risk, the ensemble approach achieved an accuracy of 87%. The results demonstrate that combining multi-source environmental features with advanced machine learning techniques can produce reliable bushfire intensity predictions, supporting more informed and timely disaster management.

</details>


### [14] [RainBalance: Alleviating Dual Imbalance in GNSS-based Precipitation Nowcasting via Continuous Probability Modeling](https://arxiv.org/abs/2601.06137)
*Yifang Zhang,Shengwu Xiong,Henan Wang,Wenjie Yin,Jiawang Peng,Duan Zhou,Yuqiang Zhang,Chen Zhou,Hua Chen,Qile Zhao,Pengfei Duan*

Main category: cs.LG

TL;DR: RainBalance：基于连续概率建模的框架，通过VAE将聚类概率分布映射到连续潜在空间，解决降水临近预报中的双重不平衡问题（非降雨事件主导和极端降水样本稀缺）。


<details>
  <summary>Details</summary>
Motivation: GNSS站基降水临近预报面临双重不平衡问题：时间分布高度不平衡，不仅非降雨事件占主导，极端降水样本也极其稀缺，这严重限制了模型在实际应用中的性能。

Method: 提出RainBalance框架，这是一个即插即用模块。对每个输入样本进行聚类得到聚类概率分布，然后通过变分自编码器（VAE）将其映射到连续潜在空间。在这个连续概率空间中学习，将任务从拟合单一且易受不平衡影响的降水标签重新表述为建模连续概率标签分布。

Result: 将该模块集成到多个最先进模型中，观察到一致的性能提升。全面的统计分析和消融研究进一步验证了该方法的有效性。

Conclusion: RainBalance框架通过连续概率建模有效缓解了降水临近预报中的双重不平衡问题，提高了模型性能，为GNSS站基降水预报提供了实用解决方案。

Abstract: Global navigation satellite systems (GNSS) station-based Precipitation Nowcasting aims to predict rainfall within the next 0-6 hours by leveraging a GNSS station's historical observations of precipitation, GNSS-PWV, and related meteorological variables, which is crucial for disaster mitigation and real-time decision-making. In recent years, time-series forecasting approaches have been extensively applied to GNSS station-based precipitation nowcasting. However, the highly imbalanced temporal distribution of precipitation, marked not only by the dominance of non-rainfall events but also by the scarcity of extreme precipitation samples, significantly limits model performance in practical applications. To address the dual imbalance problem in precipitation nowcasting, we propose a continuous probability modeling-based framework, RainBalance. This plug-and-play module performs clustering for each input sample to obtain its cluster probability distribution, which is further mapped into a continuous latent space via a variational autoencoder (VAE). By learning in this continuous probabilistic space, the task is reformulated from fitting single and imbalance-prone precipitation labels to modeling continuous probabilistic label distributions, thereby alleviating the imbalance issue. We integrate this module into multiple state-of-the-art models and observe consistent performance gains. Comprehensive statistical analysis and ablation studies further validate the effectiveness of our approach.

</details>


### [15] [SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion](https://arxiv.org/abs/2601.06320)
*Zhe Jia,Xiaotian Zhang,Junpeng Li*

Main category: cs.LG

TL;DR: SourceNet：基于Transformer的地震源表征框架，通过物理结构域随机化(PSDR)解决传感器阵列不规则几何和物理模拟与现实的差距问题，在少量真实数据微调后达到最先进精度。


<details>
  <summary>Details</summary>
Motivation: 从稀疏、不规则几何分布的传感器阵列推断高维物理状态是AI for Science的核心挑战，传统CNN需要固定网格，而基于池化的架构难以捕捉波动物理关系，且存在显著的模拟与现实差距。

Method: 提出SourceNet框架：1) 将传感器阵列视为灵活集合的Transformer架构，处理任意几何；2) 物理结构域随机化(PSDR)，通过随机化速度结构、传播效应和传感器可用性，迫使模型学习对未建模环境异质性不变的鲁棒表示。

Result: 在10万合成事件预训练和约2000个真实事件微调后，SourceNet在真实数据上达到最先进精度，展示卓越的数据效率，匹配经典求解器同时支持实时处理。可解释性分析显示模型自主发现几何信息瓶颈，学习优先考虑稀疏传感器放置的注意力策略。

Conclusion: SourceNet成功解决了传感器阵列不规则几何和模拟与现实差距的挑战，通过PSDR实现鲁棒表示学习，展示了类似科学智能体的特征，能够从数据中自主恢复最优实验设计原则。

Abstract: Inferring high-dimensional physical states from sparse, ad-hoc sensor arrays is a fundamental challenge across AI for Science, as they are complicated by irregular geometries and the profound Sim-to-Real gap in physical modeling. Taking earthquake source characterization as a representative challenge, we address limitations in conventional deep learning: CNNs demand fixed grids, while pooling-based architectures (e.g., DeepSets) struggle to capture the relational wave physics. Here, we propose SourceNet, a Transformer-based framework that treats the sensor array as a flexible set to model arbitrary geometries. To bridge the reality gap, we introduce Physics-Structured Domain Randomization (PSDR). Instead of forcing feature alignment, PSDR randomizes the governing physical dynamics by varying velocity structures, propagation effects, and sensor availability, to force the model to learn robust representations invariant to unmodeled environmental heterogeneity. By pre-training on 100,000 synthetic events and fine-tuning on ~2,000 real world events, SourceNet achieves state-of-the-art precision on held-out real data. This demonstrates exceptional data efficiency, and matches classical solvers while enabling real-time processing. Remarkably, interpretability analysis reveals that the model shows scientific-agent-like features: it autonomously discovers geometric information bottlenecks and learns an attention policy that prioritizes sparse sensor placements, effectively recovering principles of optimal experimental design from data alone.

</details>


### [16] [Future-as-Label: Scalable Supervision from Real-World Outcomes](https://arxiv.org/abs/2601.06336)
*Benjamin Turtel,Paul Wilczewski,Danny Franklin,Kris Skothiem*

Main category: cs.LG

TL;DR: 提出Foresight Learning方法，用强化学习处理现实世界预测中标签延迟的问题，通过回顾性评估训练语言模型进行概率预测


<details>
  <summary>Details</summary>
Motivation: 现实世界预测问题存在预测时标签不可见的挑战，预测结果与真实结果之间存在时间差，只能在事件结束后获得监督信号

Method: 扩展强化学习中的可验证奖励机制，应用于时间分辨的现实世界预测，训练语言模型在因果信息屏蔽下进行概率预测，使用回顾性评估和适当评分规则

Result: Qwen3-32B使用Foresight Learning训练后，Brier分数提升27%，校准误差减半，在构造的未来事件预测任务和Metaculus基准测试中超越Qwen3-235B，尽管参数少7倍

Conclusion: Foresight Learning能有效处理延迟监督的预测问题，显著提升语言模型的预测性能和校准度，在参数效率方面表现优异

Abstract: Many real-world prediction problems lack labels observable at prediction time, creating a temporal gap between prediction and outcome that yields supervision only after events resolve. To address this setting, we extend reinforcement learning with verifiable rewards to temporally resolved real-world prediction, and use it to train language models to make probabilistic forecasts under causally masked information with retrospective evaluation using proper scoring rules. Supervision is derived solely from post-resolution outcomes, preserving delayed-reward semantics. On real-world forecasting benchmarks, Qwen3-32B trained using Foresight Learning improves Brier score by 27% and halves calibration error relative to its pretrained baseline, and outperforms Qwen3-235B on both constructed future-event prediction tasks and the Metaculus benchmark despite a 7x parameter disadvantage.

</details>


### [17] [Deriving Decoder-Free Sparse Autoencoders from First Principles](https://arxiv.org/abs/2601.06478)
*Alan Oursland*

Main category: cs.LG

TL;DR: 梯度下降在log-sum-exp目标上执行隐式期望最大化，理论预测需要体积控制防止坍缩，实验验证了梯度-责任恒等式


<details>
  <summary>Details</summary>
Motivation: 研究log-sum-exp目标函数的梯度下降行为，揭示其与期望最大化算法的隐式联系，并探讨如何防止组件坍缩和冗余

Method: 使用单层编码器配合log-sum-exp目标和InfoMax正则化进行体积控制，通过实验验证理论预测

Result: 梯度-责任恒等式精确成立；log-sum-exp单独使用会导致坍缩；方差防止死组件；去相关防止冗余；模型表现出类似EM的优化动态

Conclusion: 隐式EM理论可以指导架构设计，产生的无解码器模型能够学习可解释的混合组件，自适应优化器没有优势

Abstract: Gradient descent on log-sum-exp (LSE) objectives performs implicit expectation--maximization (EM): the gradient with respect to each component output equals its responsibility. The same theory predicts collapse without volume control analogous to the log-determinant in Gaussian mixture models. We instantiate the theory in a single-layer encoder with an LSE objective and InfoMax regularization for volume control. Experiments confirm the theory's predictions. The gradient--responsibility identity holds exactly; LSE alone collapses; variance prevents dead components; decorrelation prevents redundancy. The model exhibits EM-like optimization dynamics in which lower loss does not correspond to better features and adaptive optimizers offer no advantage. The resulting decoder-free model learns interpretable mixture components, confirming that implicit EM theory can prescribe architectures.

</details>


### [18] [Improving Day-Ahead Grid Carbon Intensity Forecasting by Joint Modeling of Local-Temporal and Cross-Variable Dependencies Across Different Frequencies](https://arxiv.org/abs/2601.06530)
*Bowen Zhang,Hongda Tian,Adam Berry,A. Craig Roussac*

Main category: cs.LG

TL;DR: 提出一种用于电网碳强度因子预测的新型模型，通过并行模块分别捕获多频率下的局部时间依赖性和动态跨变量依赖性，在多个电力市场数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电网碳强度因子预测对需求侧管理和减排至关重要，但现有方法难以同时捕捉细粒度局部时间依赖性、动态高阶跨变量依赖性和复杂多频率模式。

Method: 提出包含两个并行模块的模型：1) 使用多小波卷积核对不同长度重叠块处理以增强多频率下的局部时间依赖性提取；2) 捕获多频率下的动态跨变量依赖性以建模变量间关系在时频域的演化。

Result: 在澳大利亚四个具有不同可再生能源渗透水平的代表性电力市场数据集上评估，该方法优于现有最先进模型。消融研究验证了两个模块的互补效益。

Conclusion: 所提模型不仅预测性能优越，还具备内置可解释性，能更好地理解预测行为，如在干扰事件中自适应地将注意力转移到相关变量和时间区间。

Abstract: Accurate forecasting of the grid carbon intensity factor (CIF) is critical for enabling demand-side management and reducing emissions in modern electricity systems. Leveraging multiple interrelated time series, CIF prediction is typically formulated as a multivariate time series forecasting problem. Despite advances in deep learning-based methods, it remains challenging to capture the fine-grained local-temporal dependencies, dynamic higher-order cross-variable dependencies, and complex multi-frequency patterns for CIF forecasting. To address these issues, we propose a novel model that integrates two parallel modules: 1) one enhances the extraction of local-temporal dependencies under multi-frequency by applying multiple wavelet-based convolutional kernels to overlapping patches of varying lengths; 2) the other captures dynamic cross-variable dependencies under multi-frequency to model how inter-variable relationships evolve across the time-frequency domain. Evaluations on four representative electricity markets from Australia, featuring varying levels of renewable penetration, demonstrate that the proposed method outperforms the state-of-the-art models. An ablation study further validates the complementary benefits of the two proposed modules. Designed with built-in interpretability, the proposed model also enables better understanding of its predictive behavior, as shown in a case study where it adaptively shifts attention to relevant variables and time intervals during a disruptive event.

</details>


### [19] [Computing patient similarity based on unstructured clinical notes](https://arxiv.org/abs/2601.07385)
*Petr Zelina,Marko Řeháček,Jana Halámková,Lucia Bohovicová,Martin Rusinko,Vít Nováček*

Main category: cs.LG

TL;DR: 提出一种基于临床笔记的患者矩阵表示方法，通过聚合笔记嵌入构建患者矩阵，利用低秩表示计算患者相似度，并在乳腺癌患者数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富的非结构化诊断、治疗和结果信息，对精准医疗至关重要，但难以大规模利用。需要一种能够有效提取和利用这些信息的方法来支持临床决策。

Method: 将每个患者表示为从所有临床笔记聚合嵌入构建的矩阵，基于潜在低秩表示进行稳健的患者相似度计算。在4,267名捷克乳腺癌患者的临床笔记上，使用多个矩阵相似度度量方法，并分析其在临床历史、治疗和不良事件等不同相似度维度上的表现。

Result: 结果表明该方法在下游任务中具有实用性，如个性化治疗推荐或毒性预警。使用Masaryk纪念癌症研究所的专家相似度标签进行评估，验证了不同相似度度量方法的优势和局限性。

Conclusion: 提出的患者矩阵表示方法能够有效利用临床笔记中的非结构化信息，为精准医疗应用如个性化治疗推荐和毒性预警提供了可行的技术方案。

Abstract: Clinical notes hold rich yet unstructured details about diagnoses, treatments, and outcomes that are vital to precision medicine but hard to exploit at scale. We introduce a method that represents each patient as a matrix built from aggregated embeddings of all their notes, enabling robust patient similarity computation based on their latent low-rank representations. Using clinical notes of 4,267 Czech breast-cancer patients and expert similarity labels from Masaryk Memorial Cancer Institute, we evaluate several matrix-based similarity measures and analyze their strengths and limitations across different similarity facets, such as clinical history, treatment, and adverse events. The results demonstrate the usefulness of the presented method for downstream tasks, such as personalized therapy recommendations or toxicity warnings.

</details>


### [20] [AntiPaSTO: Self-Supervised Steering of Moral Reasoning](https://arxiv.org/abs/2601.07473)
*Michael J. Clark*

Main category: cs.LG

TL;DR: AntiPaSTO是一种新的可扩展监督方法，通过反平行轴分离表示，仅需少量人类输入（两个对比词），在Gemma-3-1B上显著优于提示基线


<details>
  <summary>Details</summary>
Motivation: 随着模型能力增强，人类监督面临挑战：标签无法扩展、输出可能被操控、训练缺乏泛化性。需要满足内部性、自监督性和分布外迁移性的可扩展监督方法

Method: AntiPaSTO方法：沿反平行轴分离表示（α=±1产生相反偏移），通过一致性约束防止崩溃。人类输入极少：只需在模板句子中插入两个对比词，无需偏好标签

Result: 使用800个词对在Gemma-3-1B上，AntiPaSTO在DailyDilemmas上比提示基线提升6.9倍，并保持双向控制能力（提示会触发拒绝）

Conclusion: AntiPaSTO提供了一种高效的可扩展监督方法，仅需极少人类输入即可实现有效的表示分离和双向控制，为大型模型监督提供了新思路

Abstract: As models grow more capable, human supervision breaks down: labels don't scale, outputs can be gamed, and training doesn't generalize. Scalable oversight requires steering methods that are internal, self-supervised, and transfer out-of-distribution; existing methods satisfy some but not all three. We introduce AntiPaSTO, which separates representations along an anti-parallel axis ($α=\pm1$ produce opposite shifts), with coherence constraints preventing collapse. Human input is minimal: two contrasting words inserted into template sentences, no preference labels. Using 800 such pairs on Gemma-3-1B, AntiPaSTO beats prompting baselines by $6.9\times$ on DailyDilemmas and maintains bidirectional control where prompting triggers refusal.
  Code is available at https://github.com/wassname/AntiPaSTO.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [21] [Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions](https://arxiv.org/abs/2601.06115)
*V. Cheung*

Main category: cs.AI

TL;DR: 提出基于荣格心理学的人工集体无意识概念，为LLM伴侣设计离线"梦境层"，将受控幻觉转化为学习资源和关系构建工具


<details>
  <summary>Details</summary>
Motivation: 受到个人梦境中知识共享障碍的启发，旨在重新定义LLM中的幻觉问题：将受控离线幻觉从可靠性缺陷转变为学习和关系构建的资源

Method: 引入人工集体无意识作为共享梦境池，代理贡献去标识化的抽象交互模板，离线运行时放松逻辑约束并提高采样温度，生成安全但奇特的梦境叙事，通过严格抽象、时间延迟和短暂记忆的治理栈控制风险

Result: 行为模拟显示梦境层实现了关键解耦：代理在安全约束上保持坚定，在叙事策略上变得灵活，能够使用共享原型隐喻解决僵局，为合成场景和深化伴侣关系提供资源

Conclusion: 重新定义了幻觉的概念：在线未标记的幻觉仍然是缺陷，而有界、标记和延迟的幻觉成为合成场景和深化伴侣关系的宝贵资源，呼应了当代神经科学中防止过拟合的梦境机制

Abstract: Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired "Dream Layer" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.

</details>


### [22] [PCoKG: Personality-aware Commonsense Reasoning with Debate](https://arxiv.org/abs/2601.06234)
*Weijie Li,Zhongqing Wang,Guodong Zhou*

Main category: cs.AI

TL;DR: 论文提出了PCoKG（个性感知常识知识图谱），包含521,316个四元组，通过LLM角色扮演和辩论机制构建，用于提升个性化系统的常识推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有常识推理模型忽视了人格特质的影响，限制了在个性化系统（如对话生成）中的有效性，需要构建能够考虑个体认知差异的常识知识资源。

Method: 1) 从ATOMIC数据集中筛选可能引发不同人格类型多样推理模式的事件；2) 利用LLM的角色扮演能力进行推理任务；3) 引入包含支持者、反对者和裁判的辩论机制，通过反馈循环迭代优化生成的知识质量。

Result: 构建了包含521,316个四元组的PCoKG数据集，LoRA微调实验显示模型性能与基础模型参数规模呈正相关，在基于人设的对话生成中提高了生成响应与参考输出的一致性。

Conclusion: PCoKG填补了常识推理与个体认知差异之间的空白，能够开发更个性化和上下文感知的AI系统，为个性化AI应用提供了有价值的资源。

Abstract: Most commonsense reasoning models overlook the influence of personality traits, limiting their effectiveness in personalized systems such as dialogue generation. To address this limitation, we introduce the Personality-aware Commonsense Knowledge Graph (PCoKG), a structured dataset comprising 521,316 quadruples. We begin by employing three evaluators to score and filter events from the ATOMIC dataset, selecting those that are likely to elicit diverse reasoning patterns across different personality types. For knowledge graph construction, we leverage the role-playing capabilities of large language models (LLMs) to perform reasoning tasks. To enhance the quality of the generated knowledge, we incorporate a debate mechanism consisting of a proponent, an opponent, and a judge, which iteratively refines the outputs through feedback loops. We evaluate the dataset from multiple perspectives and conduct fine-tuning and ablation experiments using multiple LLM backbones to assess PCoKG's robustness and the effectiveness of its construction pipeline. Our LoRA-based fine-tuning results indicate a positive correlation between model performance and the parameter scale of the base models. Finally, we apply PCoKG to persona-based dialogue generation, where it demonstrates improved consistency between generated responses and reference outputs. This work bridges the gap between commonsense reasoning and individual cognitive differences, enabling the development of more personalized and context-aware AI systems.

</details>


### [23] [HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents](https://arxiv.org/abs/2601.06377)
*Ningning Zhang,Xingxing Yang,Zhizhong Tan,Weiping Deng,Wenyong Wang*

Main category: cs.AI

TL;DR: HiMem是一个用于长对话的分层长期记忆框架，通过事件记忆和笔记记忆的双层结构，支持记忆构建、检索和动态更新，实现持续自我演化。


<details>
  <summary>Details</summary>
Motivation: 现有长期记忆系统在适应性、可扩展性和持续交互下的自我演化方面存在明显局限，需要更符合认知理论的记忆框架来支持长对话场景。

Method: 提出分层记忆框架：1) 通过主题感知事件-惊喜双通道分割构建情节记忆；2) 通过多阶段信息提取构建笔记记忆；3) 语义链接形成分层结构；4) 支持混合和尽力而为检索策略；5) 引入冲突感知记忆再巩固机制。

Result: 在长对话基准测试中，HiMem在准确性、一致性和长期推理方面持续优于代表性基线方法，同时保持良好的效率。

Conclusion: HiMem为构建自适应、自我演化的LLM对话代理提供了原则性和可扩展的设计范式，代码已开源。

Abstract: Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.

</details>


### [24] [GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning](https://arxiv.org/abs/2601.06795)
*Zhengqing Yan,Xinyang Liu,Yi Zhang,Fan Guo,Yao Liu,Junchen Wan,Kang Song*

Main category: cs.AI

TL;DR: 提出GDEPO方法解决ATP中GRPO算法的两个关键问题：复合奖励下相对优势估计与形式验证器二进制反馈的冲突，以及静态采样策略导致数据浪费的问题。


<details>
  <summary>Details</summary>
Motivation: 在自动定理证明任务中，GRPO算法面临两个关键限制：1）使用复合奖励时，相对优势估计可能与形式验证器的二进制反馈冲突；2）静态采样策略可能导致整批数据因未找到有效证明而被丢弃，造成数据浪费。

Method: 提出GDEPO方法，包含三个核心机制：1）动态额外采样：对无效批次重新采样直到发现有效证明；2）平等权利优势：将优势函数的符号（基于正确性）与幅度（由辅助奖励调节）解耦；3）动态额外迭代：对初始失败但最终成功的样本应用额外梯度步骤。

Result: 在三个不同难度的数据集（MinF2F-test、MathOlympiadBench、PutnamBench）上的实验证实了GDEPO的有效性，消融研究验证了其协同组件的必要性。

Conclusion: GDEPO提高了数据利用率和优化效率，为ATP提供了一种新的训练范式。

Abstract: Automated Theorem Proving (ATP) represents a fundamental challenge in Artificial Intelligence (AI), requiring the construction of machine-verifiable proofs in formal languages such as Lean to evaluate AI reasoning capabilities. Reinforcement learning (RL), particularly the high-performance Group Relative Policy Optimization (GRPO) algorithm, has emerged as a mainstream approach for this task. However, in ATP scenarios, GRPO faces two critical issues: when composite rewards are used, its relative advantage estimation may conflict with the binary feedback from the formal verifier; meanwhile, its static sampling strategy may discard entire batches of data if no valid proof is found, resulting in zero contribution to model updates and significant data waste. To address these limitations, we propose Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO), a method incorporating three core mechanisms: 1) dynamic additional sampling, which resamples invalid batches until a valid proof is discovered; 2) equal-right advantage, decoupling the sign of the advantage function (based on correctness) from its magnitude (modulated by auxiliary rewards) to ensure stable and correct policy updates; and 3) dynamic additional iterations, applying extra gradient steps to initially failed but eventually successful samples to accelerate learning on challenging cases. Experiments conducted on three datasets of varying difficulty (MinF2F-test, MathOlympiadBench, PutnamBench) confirm the effectiveness of GDEPO, while ablation studies validate the necessity of its synergistic components. The proposed method enhances data utilization and optimization efficiency, offering a novel training paradigm for ATP.

</details>


### [25] [Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling](https://arxiv.org/abs/2601.07149)
*Zhaoyan Li,Hang Lei,Yujia Wang,Lanbo Liu,Hao Liu,Liang Yu*

Main category: cs.AI

TL;DR: RLCS框架通过生成式奖励模型和多维度故事质量评估，结合基于熵的奖励塑造策略，解决了创意故事生成中奖励信号设计和训练稳定性问题，显著提升了故事质量。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能生成流畅文本，但创作高质量创意故事仍具挑战性。强化学习虽有望解决此问题，但面临两个关键障碍：为主观故事质量设计可靠奖励信号，以及缓解训练不稳定性。

Method: 提出RLCS框架：1) 开发生成式奖励模型(GenRM)，通过监督微调从强教师模型蒸馏推理链的演示，并在扩展偏好数据上进行GRPO精炼，提供多维度分析和显式推理；2) 引入基于熵的奖励塑造策略，动态优先学习自信错误和不确定的正确预测。

Result: GenRM与人类创意判断的匹配度达到68%，RLCS在整体故事质量上显著优于包括Gemini-2.5-Pro在内的强基线模型。

Conclusion: 该工作为将强化学习应用于创意领域提供了实用流程，有效解决了奖励建模和训练稳定性的双重挑战。

Abstract: While Large Language Models (LLMs) can generate fluent text, producing high-quality creative stories remains challenging. Reinforcement Learning (RL) offers a promising solution but faces two critical obstacles: designing reliable reward signals for subjective storytelling quality and mitigating training instability. This paper introduces the Reinforcement Learning for Creative Storytelling (RLCS) framework to systematically address both challenges. First, we develop a Generative Reward Model (GenRM) that provides multi-dimensional analysis and explicit reasoning about story preferences, trained through supervised fine-tuning on demonstrations with reasoning chains distilled from strong teacher models, followed by GRPO-based refinement on expanded preference data. Second, we introduce an entropy-based reward shaping strategy that dynamically prioritizes learning on confident errors and uncertain correct predictions, preventing overfitting on already-mastered patterns. Experiments demonstrate that GenRM achieves 68\% alignment with human creativity judgments, and RLCS significantly outperforms strong baselines including Gemini-2.5-Pro in overall story quality. This work provides a practical pipeline for applying RL to creative domains, effectively navigating the dual challenges of reward modeling and training stability.

</details>


### [26] [Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning](https://arxiv.org/abs/2601.07238)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Fei Mi,Lifeng Shang*

Main category: cs.AI

TL;DR: GPSO通过强化学习框架，让大型推理模型学习根据问题特征选择最优推理模式，显著提升数学和科学基准测试性能


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然展现出多种高级推理模式，但现有训练方法会偏向有限的几种主导模式，导致模型默认推理模式对特定问题往往不是最优的

Method: 提出Group Pattern Selection Optimization (GPSO)强化学习框架，扩展GRPO方法，包含多模式rollout、基于验证器的问题级最优模式选择，以及优化过程中的注意力掩码防止模式后缀泄露

Result: GPSO在各种模型架构和基准测试中带来一致且显著的性能提升，有效缓解模式次优问题，促进更鲁棒、适应性更强的推理能力

Conclusion: 通过探索多样化推理策略组合并优化最有效策略，GPSO使模型能够内化从问题特征到最优推理模式的映射，提升推理性能

Abstract: Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns (e.g., direct solution, reflection-and-verification, and exploring multiple solutions), yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, we identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model's default reasoning pattern is often sub-optimal for a given problem. To address this, we introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO.

</details>


### [27] [Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure](https://arxiv.org/abs/2601.07342)
*Nicolas Tacheny*

Main category: cs.AI

TL;DR: 提出基于LLM的智能诊断框架，通过MCP协议访问工具空间，自主导航基础设施模型进行根因分析，替代传统硬编码的图遍历算法


<details>
  <summary>Details</summary>
Motivation: 传统根因分析方法依赖硬编码的图遍历算法或基于规则的关联引擎，维护成本高且与基础设施模型紧密耦合，难以适应大规模电信和数据中心基础设施的多层服务资源模型

Method: 引入基于LLM的智能诊断框架，通过Model Context Protocol (MCP)暴露约束工具空间，让LLM代理自主调用服务查找、依赖检索、结构化/非结构化数据分析、事件分析和影响发现等工具进行逐步调查

Result: 定义了结构化调查协议，确保代理推理的接地性、可重现性，并能安全处理缺失或模糊信息，为自主事件解决和变更影响缓解奠定基础

Conclusion: 该框架为自主事件解决和变更影响缓解奠定基础，未来系统不仅能诊断和修复基础设施故障，还能预测计划变更对服务和客户的影响，使运维人员能在执行维护操作前缓解风险

Abstract: Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model.
  In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information.
  This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.

</details>


### [28] [Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents](https://arxiv.org/abs/2601.07577)
*Yunfan Li,Bingbing Xu,Xueyun Tian,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: TDP提出任务解耦规划框架，通过将复杂任务分解为有向无环图，使用监督器、规划器和执行器进行局部推理和重规划，避免错误传播，提高长时域任务的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理规划方法存在两种范式：逐步规划短视，一次性规划脆弱。两者都面临上下文纠缠问题，导致认知负荷高、局部错误传播、恢复计算成本高。

Method: TDP框架包含三个组件：监督器将任务分解为有向无环图(DAG)子目标；规划器在限定上下文中为当前子任务制定计划；执行器执行计划。这种任务解耦将推理和重规划限制在活跃子任务内。

Result: 在TravelPlanner、ScienceWorld和HotpotQA三个基准测试中，TDP优于强基线方法，同时将token消耗减少高达82%，表明子任务解耦能同时提高长时域代理的鲁棒性和效率。

Conclusion: 任务解耦规划通过将复杂任务分解为隔离的子任务，避免上下文纠缠和错误传播，显著提升LLM代理在长时域任务中的性能和效率，且无需额外训练。

Abstract: Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [29] [Structured Episodic Event Memory](https://arxiv.org/abs/2601.06411)
*Zhengxuan Lu,Dongfang Li,Yukun Shi,Beilun Wang,Longyue Wang,Baotian Hu*

Main category: cs.CL

TL;DR: SEEM提出了一种结构化情景事件记忆框架，通过图记忆层和动态情景记忆层的协同工作，解决LLM中静态RAG方法在复杂推理中缺乏结构依赖性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM中的记忆方法主要依赖静态检索增强生成(RAG)，这种方法检索分散且无法捕捉复杂推理所需的结构依赖关系。对于自主智能体来说，这些被动扁平架构缺乏对长期交互动态关联性的认知组织能力。

Method: 提出结构化情景事件记忆(SEEM)框架，包含图记忆层（用于关系事实）和动态情景记忆层（用于叙事进展）。基于认知框架理论，将交互流转化为结构化情景事件框架(EEFs)，并引入智能体关联融合和反向溯源扩展(RPE)机制，从碎片化证据重建连贯叙事上下文。

Result: 在LoCoMo和LongMemEval基准测试中，SEEM显著优于基线方法，使智能体能够保持更好的叙事连贯性和逻辑一致性。

Conclusion: SEEM框架通过结构化分层记忆系统，有效解决了LLM在复杂推理和长期交互中的记忆组织问题，为自主智能体提供了更接近人类认知的记忆机制。

Abstract: Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.

</details>


### [30] [Efficient Aspect Term Extraction using Spiking Neural Network](https://arxiv.org/abs/2601.06637)
*Abhishek Kumar Mishra,Arya Somasundaram,Anup Das,Nagarajan Kandasamy*

Main category: cs.CL

TL;DR: 本文提出SpikeATE，一种基于脉冲神经网络（SNN）的方面术语提取方法，相比传统深度神经网络（DNN）在保持性能的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有方面术语提取（ATE）方法大多使用能耗高的深度神经网络进行序列标注，需要更节能的替代方案。脉冲神经网络（SNN）具有稀疏激活和事件驱动推理特性，适合捕捉词语间的时序依赖关系。

Method: 提出SpikeATE架构，采用三元脉冲神经元和直接脉冲训练方法，通过伪梯度进行微调，利用SNN的稀疏激活特性实现高效方面术语提取。

Result: 在四个SemEval基准数据集上评估，SpikeATE达到与最先进DNN相当的性能，同时显著降低能耗，验证了SNN在ATE任务中的实用性。

Conclusion: SNN可作为ATE任务的实用且可持续选择，在保持性能的同时大幅降低能耗，为情感分析领域提供了更环保的解决方案。

Abstract: Aspect Term Extraction (ATE) identifies aspect terms in review sentences, a key subtask of sentiment analysis. While most existing approaches use energy-intensive deep neural networks (DNNs) for ATE as sequence labeling, this paper proposes a more energy-efficient alternative using Spiking Neural Networks (SNNs). Using sparse activations and event-driven inferences, SNNs capture temporal dependencies between words, making them suitable for ATE. The proposed architecture, SpikeATE, employs ternary spiking neurons and direct spike training fine-tuned with pseudo-gradients. Evaluated on four benchmark SemEval datasets, SpikeATE achieves performance comparable to state-of-the-art DNNs with significantly lower energy consumption. This highlights the use of SNNs as a practical and sustainable choice for ATE tasks.

</details>


### [31] [Codified Foreshadowing-Payoff Text Generation](https://arxiv.org/abs/2601.07033)
*Longfei Yun,Kun Zhou,Yupeng Hou,Letian Peng,Jingbo Shang*

Main category: cs.CL

TL;DR: CFPG框架通过将叙事连续性转化为可执行的因果谓词，显著提升LLM在长程叙事依赖上的表现，确保伏笔得到逻辑和时间上的兑现。


<details>
  <summary>Details</summary>
Motivation: 尽管故事生成技术有所进步，但大型语言模型经常无法处理长程叙事依赖关系，导致"契诃夫之枪"未被触发。现有评估主要关注表面连贯性而非叙事设置的逻辑实现。

Method: 提出Codified Foreshadowing-Payoff Generation (CFPG)框架，将叙事连续性转化为可执行的因果谓词。从BookSum语料库中挖掘和编码"伏笔-触发-兑现"三元组，提供结构化监督。

Result: 实验表明CFPG在兑现准确性和叙事对齐方面显著优于标准提示基线。该框架能确保伏笔承诺不仅在文本中被提及，而且在时间和逻辑上得到实现。

Conclusion: 明确编码叙事机制对于推动LLM从表面流畅性转向真正的叙事能力至关重要。结构化监督能有效解决长程叙事依赖问题。

Abstract: Foreshadowing and payoff are ubiquitous narrative devices through which authors introduce commitments early in a story and resolve them through concrete, observable outcomes. However, despite advances in story generation, large language models (LLMs) frequently fail to bridge these long-range narrative dependencies, often leaving "Chekhov's guns" unfired even when the necessary context is present. Existing evaluations largely overlook this structural failure, focusing on surface-level coherence rather than the logical fulfillment of narrative setups. In this paper, we introduce Codified Foreshadowing-Payoff Generation (CFPG), a novel framework that reframes narrative quality through the lens of payoff realization. Recognizing that LLMs struggle to intuitively grasp the "triggering mechanism" of a foreshadowed event, CFPG transforms narrative continuity into a set of executable causal predicates. By mining and encoding Foreshadow-Trigger-Payoff triples from the BookSum corpus, we provide structured supervision that ensures foreshadowed commitments are not only mentioned but also temporally and logically fulfilled. Experiments demonstrate that CFPG significantly outperforms standard prompting baselines in payoff accuracy and narrative alignment. Our findings suggest that explicitly codifying narrative mechanics is essential for moving LLMs from surface-level fluency to genuine narrative competence.

</details>


### [32] [Fine-Tuning vs. RAG for Multi-Hop Question Answering with Novel Knowledge](https://arxiv.org/abs/2601.07054)
*Zhuoyi Yang,Yurun Song,Iftekhar Ahmed,Ian Harris*

Main category: cs.CL

TL;DR: 本文系统比较了参数化与非参数化知识注入方法在开放域多跳问答中的效果，发现监督微调效果最佳，检索增强生成对时序新知识最有效，而无监督微调改进有限。


<details>
  <summary>Details</summary>
Motivation: 多跳问答需要整合多个知识片段，是评估大语言模型推理能力的重要任务。现有研究探索了微调和检索增强生成等知识注入机制，但它们在多跳问答中的相对有效性，特别是对于时序新知识的处理，尚未得到充分理解。

Method: 系统比较参数化（无监督微调、监督微调）和非参数化（检索增强生成）知识注入方法。在三个7B参数开源LLM上评估，使用QASC标准科学问答数据集和新构建的2024年维基百科事件数据集（包含10,000+多跳问题）。

Result: 无监督微调相比基础模型仅提供有限改进，表明持续预训练本身不足以提升多跳推理准确性。检索增强生成带来显著且一致的改进，特别是在依赖时序新信息的问题上。监督微调在模型和数据集上达到最高总体准确率。

Conclusion: 不同知识注入机制支持多跳问答的方式存在根本差异，当需要外部或组合知识时，检索增强方法尤为重要。监督微调效果最佳，但检索增强生成在时序新知识处理上表现突出。

Abstract: Multi-hop question answering is widely used to evaluate the reasoning capabilities of large language models (LLMs), as it requires integrating multiple pieces of supporting knowledge to arrive at a correct answer. While prior work has explored different mechanisms for providing knowledge to LLMs, such as finetuning and retrieval-augmented generation (RAG), their relative effectiveness for multi-hop question answering remains insufficiently understood, particularly when the required knowledge is temporally novel.
  In this paper, we systematically compare parametric and non-parametric knowledge injection methods for open-domain multi-hop question answering. We evaluate unsupervised fine-tuning (continual pretraining), supervised fine-tuning, and retrieval-augmented generation across three 7B-parameter open-source LLMs. Experiments are conducted on two benchmarks: QASC, a standard multi-hop science question answering dataset, and a newly constructed dataset of over 10,000 multi-hop questions derived from Wikipedia events in 2024, designed to test knowledge beyond the models' pretraining cutoff.
  Our results show that unsupervised fine-tuning provides only limited gains over base models, suggesting that continual pretraining alone is insufficient for improving multi-hop reasoning accuracy. In contrast, retrieval-augmented generation yields substantial and consistent improvements, particularly when answering questions that rely on temporally novel information. Supervised fine-tuning achieves the highest overall accuracy across models and datasets. These findings highlight fundamental differences in how knowledge injection mechanisms support multi-hop question answering and underscore the importance of retrieval-based methods when external or compositional knowledge is required.

</details>


### [33] [ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation](https://arxiv.org/abs/2601.07121)
*Makoto Sato*

Main category: cs.CL

TL;DR: ReMIND是一个受REM睡眠启发的模块化框架，用于在LLM中实现创造性构思，通过分离探索和整合阶段来平衡新颖性和一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在创造性构思中难以同时实现新颖性和内部一致性，随机采样虽然能促进新颖性但会降低一致性，需要一种系统方法来平衡这两者。

Method: ReMIND采用四阶段模块化框架：wake阶段生成稳定的低温语义基线；dream阶段进行高温探索性生成；judge阶段应用粗略评估过滤不连贯输出并提取候选想法；re-wake阶段将选定想法重新表述为连贯的最终输出。每个阶段由独立的LLM实例化，实现功能分离。

Result: 参数扫描显示ReMIND能可靠地诱导语义探索同时保持下游稳定性。嵌入分析确认dream阶段存在显著的语义位移，外部评估显示高质量想法是零星出现的，而非沿任何单一指标的极端值。

Conclusion: LLM中的偶然性构思是一个罕见事件过程，最好通过系统级设计来塑造有价值想法出现和稳定的条件。ReMIND为研究偶然性的计算基础提供了通用框架，展示了模块化LLM编排如何桥接探索和稳定化。

Abstract: Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.

</details>


### [34] [ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents](https://arxiv.org/abs/2601.07582)
*Huhai Zou,Tianhao Sun,Chuanjiang He,Yu Tian,Zhenyang Li,Li Jin,Nayu Liu,Jiang Zhong,Kaiwen Wei*

Main category: cs.CL

TL;DR: ES-Mem是一个基于事件分割理论的对话记忆框架，通过动态事件分割和分层记忆架构解决现有记忆机制在语义完整性和检索精度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆机制存在两个主要限制：1）僵化的记忆粒度破坏语义完整性，导致记忆单元碎片化；2）扁平的检索范式仅依赖表层语义相似性，忽略了对话结构线索，难以精确定位特定情景记忆。

Method: 受事件分割理论启发，提出ES-Mem框架，包含两个核心组件：1）动态事件分割模块，将长期交互划分为语义连贯的事件并识别边界；2）分层记忆架构，构建多层记忆并利用边界语义锚定特定情景记忆以实现精确上下文定位。

Result: 在两个记忆基准测试中，ES-Mem相比基线方法取得了一致的性能提升。此外，提出的事件分割模块在对话分割数据集上展现出强大的适用性。

Conclusion: ES-Mem通过事件分割和分层记忆架构有效解决了现有对话记忆机制的局限性，提升了记忆的语义完整性和检索精度，为长期对话交互提供了更有效的记忆支持。

Abstract: Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.

</details>


### [35] [Contrastive Learning with Narrative Twins for Modeling Story Salience](https://arxiv.org/abs/2601.07765)
*Igor Sterner,Alex Lascarides,Frank Keller*

Main category: cs.CL

TL;DR: 提出一个对比学习框架，通过叙事孪生（相同情节不同表面形式的故事）学习故事嵌入，用于建模叙事显著性，并评估四种叙事学操作来识别关键句子。


<details>
  <summary>Details</summary>
Motivation: 理解叙事需要识别对故事进展最关键的事件，但现有方法难以有效建模叙事显著性。

Method: 使用对比学习框架，训练模型区分故事与其叙事孪生（相同情节不同表面形式）以及表面相似但情节不同的干扰项，学习故事嵌入，并评估删除、移位、破坏和摘要四种叙事学操作。

Result: 对比学习的故事嵌入优于掩码语言模型基线，摘要操作是识别显著句子最可靠的方法；当叙事孪生不可用时，随机丢弃可生成孪生，LLM提示或同一故事的不同部分可生成有效干扰项。

Conclusion: 对比学习框架能有效建模叙事显著性，摘要操作是最可靠的显著性识别方法，且该方法在缺乏叙事孪生时仍具实用性。

Abstract: Understanding narratives requires identifying which events are most salient for a story's progression. We present a contrastive learning framework for modeling narrative salience that learns story embeddings from narrative twins: stories that share the same plot but differ in surface form. Our model is trained to distinguish a story from both its narrative twin and a distractor with similar surface features but different plot. Using the resulting embeddings, we evaluate four narratologically motivated operations for inferring salience (deletion, shifting, disruption, and summarization). Experiments on short narratives from the ROCStories corpus and longer Wikipedia plot summaries show that contrastively learned story embeddings outperform a masked-language-model baseline, and that summarization is the most reliable operation for identifying salient sentences. If narrative twins are not available, random dropout can be used to generate the twins from a single story. Effective distractors can be obtained either by prompting LLMs or, in long-form narratives, by using different parts of the same story.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [36] [Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna](https://arxiv.org/abs/2601.07362)
*Julia Richter,Turcan Tuna,Manthan Patel,Takahiro Miki,Devon Higgins,James Fox,Cesar Cadena,Andres Diaz,Marco Hutter*

Main category: cs.RO

TL;DR: 开发四足机器人系统用于火山气体自主分析，在埃特纳火山成功进行气体源检测，自主率达到93-100%


<details>
  <summary>Details</summary>
Motivation: 火山气体排放是喷发活动的重要前兆，但近地表测量危险且具有挑战性。轮式系统在崎岖火山地形中移动能力有限，无法进行可靠的现场气体测量，需要自主解决方案。

Method: 使用四足机器人ANYmal，配备四极杆质谱仪系统。开发模块化自主堆栈，集成任务规划界面、全局规划器、定位框架和地形感知局部导航。在埃特纳火山进行三次自主任务评估。

Result: 在埃特纳火山不同地形中成功进行气体源检测，自主率达到93-100%。通过遥操作任务测量天然喷气孔，检测到二氧化硫和二氧化碳。

Conclusion: 需要自适应传感策略、全局与局部规划的更紧密集成以及改进的硬件设计。四足机器人系统为危险火山环境中的自主气体分析提供了可行方案。

Abstract: Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.

</details>


### [37] [Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids](https://arxiv.org/abs/2601.07718)
*Shaoting Zhu,Ziwen Zhuang,Mengjie Zhao,Kun-Ying Lee,Hang Zhao*

Main category: cs.RO

TL;DR: 提出一个可扩展的端到端感知框架"Hiking in the Wild"，用于人形机器人在复杂非结构化环境中的稳健徒步，通过单阶段强化学习直接从原始深度输入和本体感知映射到关节动作，无需外部状态估计。


<details>
  <summary>Details</summary>
Motivation: 在复杂非结构化环境中实现稳健的人形机器人徒步需要从反应式本体感知转向主动感知。现有方法存在挑战：基于地图的方法存在状态估计漂移问题（如LiDAR方法对躯干抖动处理不佳），而端到端方法通常面临可扩展性和训练复杂性挑战（如基于虚拟障碍的方法需要逐案实现）。

Method: 提出一个可扩展的端到端感知框架，包含两个关键机制：1) 结合可扩展的"地形边缘检测"和"足部体积点"的立足点安全机制，防止在边缘发生灾难性滑倒；2) "平坦补丁采样"策略，通过生成可行的导航目标来缓解奖励黑客问题。采用单阶段强化学习方案，直接将原始深度输入和本体感知映射到关节动作，不依赖外部状态估计。

Result: 在全尺寸人形机器人上进行的大量现场实验表明，该策略能够在复杂地形上实现稳健穿越，速度高达2.5米/秒。训练和部署代码已开源，便于可重复研究和对真实机器人的最小硬件修改部署。

Conclusion: 提出的"Hiking in the Wild"框架成功解决了人形机器人在复杂非结构化环境中徒步的感知挑战，通过创新的安全机制和采样策略实现了稳健的端到端控制，为实际部署提供了可行的解决方案。

Abstract: Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \textit{Terrain Edge Detection} with \textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.

</details>


### [38] [Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation](https://arxiv.org/abs/2601.07821)
*Huanyu Li,Kun Lei,Sheng Zang,Kaizhe Hu,Yongyuan Liang,Bo An,Xiaoli Li,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出FARL框架，通过离线训练的安全评估器和恢复策略，显著减少机器人后训练中需要人工干预的故障，在真实世界RL后训练中减少73.1%的故障同时提升11.3%的性能。


<details>
  <summary>Details</summary>
Motivation: 基于深度强化学习的后训练算法虽然能提升机器人模型的泛化性、准确性和鲁棒性，但在真实世界探索中不可避免会出现需要人工干预的故障（如机器人打翻水或打碎玻璃），这阻碍了该范式的实际部署。

Method: 提出FARL（Failure-Aware Offline-to-Online RL）新范式，创建FailureBench基准测试包含常见需要人工干预的故障场景，提出算法整合基于世界模型的安全评估器和离线训练的恢复策略，在在线探索中预防故障发生。

Result: 大量仿真和真实世界实验证明FARL在在线强化学习后训练中能显著减少需要人工干预的故障，同时提升性能和泛化能力。在真实世界RL后训练中，FARL减少73.1%的IR故障，平均提升11.3%的性能。

Conclusion: FARL为机器人后训练提供了一种有效减少故障的新范式，通过整合离线训练的安全机制和恢复策略，实现了在真实世界部署中更安全、更高效的强化学习后训练。

Abstract: Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.

</details>
