<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MIS-LSTM: Multichannel Image-Sequence LSTM for Sleep Quality and Stress Prediction](https://arxiv.org/abs/2509.11232)
*Seongwan Park,Jieun Woo,Siheon Yang*

Main category: cs.CV

TL;DR: MIS-LSTM是一个混合框架，结合CNN编码器和LSTM序列模型，从多模态生活日志数据预测睡眠质量和压力。通过注意力模块融合连续传感器和离散事件数据，并使用不确定性感知集成提升鲁棒性，在ETRI数据集上取得0.647的Macro-F1分数。


<details>
  <summary>Details</summary>
Motivation: 需要从多模态生活日志数据中准确预测睡眠质量和压力水平，传统方法在处理连续传感器流和稀疏离散事件的融合方面存在挑战。

Method: 将连续传感器流分割为N小时块并渲染为多通道图像，稀疏离散事件用1D-CNN编码，通过注意力模块融合两种模态，LSTM捕获长期时间依赖，并使用不确定性感知集成(UALRE)提升鲁棒性。

Result: 基础MIS-LSTM达到Macro-F1 0.615，加入UALRE集成后提升至0.647，优于LSTM、1D-CNN和CNN基线。消融实验证实多通道成像、4小时块粒度和模态特定编码的有效性。

Conclusion: MIS-LSTM框架有效融合多模态生活日志数据，UALRE集成显著提升预测性能，为睡眠质量和压力预测提供了有效的解决方案。

Abstract: This paper presents MIS-LSTM, a hybrid framework that joins CNN encoders with
an LSTM sequence model for sleep quality and stress prediction at the day level
from multimodal lifelog data. Continuous sensor streams are first partitioned
into N-hour blocks and rendered as multi-channel images, while sparse discrete
events are encoded with a dedicated 1D-CNN. A Convolutional Block Attention
Module fuses the two modalities into refined block embeddings, which an LSTM
then aggregates to capture long-range temporal dependencies. To further boost
robustness, we introduce UALRE, an uncertainty-aware ensemble that overrides
lowconfidence majority votes with high-confidence individual predictions.
Experiments on the 2025 ETRI Lifelog Challenge dataset show that Our base
MISLSTM achieves Macro-F1 0.615; with the UALRE ensemble, the score improves to
0.647, outperforming strong LSTM, 1D-CNN, and CNN baselines. Ablations confirm
(i) the superiority of multi-channel over stacked-vertical imaging, (ii) the
benefit of a 4-hour block granularity, and (iii) the efficacy of
modality-specific discrete encoding.

</details>


### [2] [Layout-Conditioned Autoregressive Text-to-Image Generation via Structured Masking](https://arxiv.org/abs/2509.12046)
*Zirui Zheng,Takashi Isobe,Tong Shen,Xu Jia,Jianbin Zhao,Xiaomin Li,Mengmeng Ge,Baolu Li,Qinghe Wang,Dong Li,Dong Zhou,Yunzhi Zhuge,Huchuan Lu,Emad Barsoum*

Main category: cs.CV

TL;DR: SMARLI是一个基于自回归模型的新框架，通过结构化掩码策略和GRPO后训练方案，有效解决了布局条件图像生成中的特征纠缠问题，实现了高质量的布局控制图像生成。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在图像生成方面表现出色，但扩展到布局条件生成面临挑战，主要原因是布局条件的稀疏性和特征纠缠风险。需要一种能够有效整合空间布局约束的方法。

Method: 提出结构化掩码策略来控制全局提示、布局和图像token之间的交互，防止不同区域与其描述之间的错误关联。同时采用基于Group Relative Policy Optimization的后训练方案，配合专门设计的布局奖励函数来提升生成质量和布局准确性。

Result: 实验结果表明，SMARLI能够无缝整合布局token与文本和图像token，在不影响生成质量的前提下实现卓越的布局感知控制，同时保持自回归模型的结构简单性和生成效率。

Conclusion: SMARLI框架成功解决了布局条件图像生成中的关键挑战，为自回归模型在布局控制图像生成领域的应用提供了有效的解决方案，在保持模型简洁性的同时实现了高质量的布局控制生成。

Abstract: While autoregressive (AR) models have demonstrated remarkable success in
image generation, extending them to layout-conditioned generation remains
challenging due to the sparse nature of layout conditions and the risk of
feature entanglement. We present Structured Masking for AR-based
Layout-to-Image (SMARLI), a novel framework for layoutto-image generation that
effectively integrates spatial layout constraints into AR-based image
generation. To equip AR model with layout control, a specially designed
structured masking strategy is applied to attention computation to govern the
interaction among the global prompt, layout, and image tokens. This design
prevents mis-association between different regions and their descriptions while
enabling sufficient injection of layout constraints into the generation
process. To further enhance generation quality and layout accuracy, we
incorporate Group Relative Policy Optimization (GRPO) based post-training
scheme with specially designed layout reward functions for next-set-based AR
models. Experimental results demonstrate that SMARLI is able to seamlessly
integrate layout tokens with text and image tokens without compromising
generation quality. It achieves superior layoutaware control while maintaining
the structural simplicity and generation efficiency of AR models.

</details>


### [3] [End-to-End Learning of Multi-Organ Implicit Surfaces from 3D Medical Imaging Data](https://arxiv.org/abs/2509.12068)
*Farahdiba Zarin,Nicolas Padoy,Jérémy Dana,Vinkle Srivastav*

Main category: cs.CV

TL;DR: ImplMORe是一种基于隐式表面表示的深度学习端到端方法，用于从3D医学图像进行多器官重建，通过连续域特征学习和多尺度插值实现比输入图像分辨率更高的精细表面重建。


<details>
  <summary>Details</summary>
Motivation: 医学影像中器官的精细表面重建对诊断和手术规划至关重要，但传统方法受限于分辨率和计算资源。虽然计算机视觉领域提出了隐式表示方法，但由于架构和数据差异，这些方法无法直接应用于医学图像。

Method: 使用3D CNN编码器提取局部特征，通过多尺度插值在连续域中学习特征，采用占据函数表示器官表面，实现端到端的深度学习重建。

Result: 在totalsegmentator数据集上的实验表明，该方法在单器官和多器官重建任务中均优于基于离散显式表示的方法，能够提供比输入图像分辨率更高的精细表面细节。

Conclusion: ImplMORe通过隐式表面表示成功解决了医学图像器官重建中的分辨率限制问题，为精细表面重建提供了有效的解决方案，代码将公开提供。

Abstract: The fine-grained surface reconstruction of different organs from 3D medical
imaging can provide advanced diagnostic support and improved surgical planning.
However, the representation of the organs is often limited by the resolution,
with a detailed higher resolution requiring more memory and computing
footprint. Implicit representations of objects have been proposed to alleviate
this problem in general computer vision by providing compact and differentiable
functions to represent the 3D object shapes. However, architectural and
data-related differences prevent the direct application of these methods to
medical images. This work introduces ImplMORe, an end-to-end deep learning
method using implicit surface representations for multi-organ reconstruction
from 3D medical images. ImplMORe incorporates local features using a 3D CNN
encoder and performs multi-scale interpolation to learn the features in the
continuous domain using occupancy functions. We apply our method for single and
multiple organ reconstructions using the totalsegmentator dataset. By
leveraging the continuous nature of occupancy functions, our approach
outperforms the discrete explicit representation based surface reconstruction
approaches, providing fine-grained surface details of the organ at a resolution
higher than the given input image. The source code will be made publicly
available at: https://github.com/CAMMA-public/ImplMORe

</details>


### [4] [Open-ended Hierarchical Streaming Video Understanding with Vision Language Models](https://arxiv.org/abs/2509.12145)
*Hyolim Kang,Yunsu Park,Youngbeom Yoo,Yeeun Choi,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出了分层流式视频理解任务，结合在线时序动作定位和自由形式描述生成，开发了OpenHOUSE系统来提升流式动作感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏分层和细粒度时序标注，需要将原子动作组合成高级事件，并扩展流式动作感知超越动作分类的范畴。

Method: 利用LLMs将原子动作分组为高级事件来丰富数据集，提出OpenHOUSE系统，包含专门的流式模块来准确检测相邻动作边界。

Result: OpenHOUSE系统在检测相邻动作边界方面性能接近翻倍，显著优于现有方法的直接扩展。

Conclusion: 流式动作感知的未来在于集成强大的生成模型，OpenHOUSE是向这个方向迈出的关键一步。

Abstract: We introduce Hierarchical Streaming Video Understanding, a task that combines
online temporal action localization with free-form description generation.
Given the scarcity of datasets with hierarchical and fine-grained temporal
annotations, we demonstrate that LLMs can effectively group atomic actions into
higher-level events, enriching existing datasets. We then propose OpenHOUSE
(Open-ended Hierarchical Online Understanding System for Events), which extends
streaming action perception beyond action classification. OpenHOUSE features a
specialized streaming module that accurately detects boundaries between closely
adjacent actions, nearly doubling the performance of direct extensions of
existing methods. We envision the future of streaming action perception in the
integration of powerful generative models, with OpenHOUSE representing a key
step in that direction.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [From Noise to Precision: A Diffusion-Driven Approach to Zero-Inflated Precipitation Prediction](https://arxiv.org/abs/2509.10501)
*Wentao Gao,Jiuyong Li,Lin Liu,Thuc Duy Le,Xiongren Chen,Xiaojing Du,Jixue Liu,Yanchang Zhao,Yun Chen*

Main category: cs.LG

TL;DR: 提出了Zero Inflation Diffusion Framework (ZIDF)来处理降水预测中的零膨胀数据问题，通过高斯扰动、Transformer预测和扩散去噪技术，在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 降水预测中零膨胀数据（大量零值和稀疏非零事件）带来了重大挑战，需要专门的方法来处理这种特殊的数据分布。

Method: ZIDF框架整合了三个关键技术：高斯扰动用于平滑零膨胀分布、基于Transformer的预测用于捕捉时间模式、基于扩散的去噪用于恢复原始数据结构。

Result: 实验使用南澳大利亚的观测降水数据和合成零膨胀数据，结果显示ZIDF相比多个最先进的降水预测模型有显著性能提升，相对于基准Non-stationary Transformer，MSE降低56.7%，MAE降低21.1%。

Conclusion: ZIDF能够鲁棒地处理稀疏时间序列数据，并显示出在其他零膨胀问题领域的潜在通用性。

Abstract: Zero-inflated data pose significant challenges in precipitation forecasting
due to the predominance of zeros with sparse non-zero events. To address this,
we propose the Zero Inflation Diffusion Framework (ZIDF), which integrates
Gaussian perturbation for smoothing zero-inflated distributions,
Transformer-based prediction for capturing temporal patterns, and
diffusion-based denoising to restore the original data structure. In our
experiments, we use observational precipitation data collected from South
Australia along with synthetically generated zero-inflated data. Results show
that ZIDF demonstrates significant performance improvements over multiple
state-of-the-art precipitation forecasting models, achieving up to 56.7\%
reduction in MSE and 21.1\% reduction in MAE relative to the baseline
Non-stationary Transformer. These findings highlight ZIDF's ability to robustly
handle sparse time series data and suggest its potential generalizability to
other domains where zero inflation is a key challenge.

</details>


### [6] [STM-Graph: A Python Framework for Spatio-Temporal Mapping and Graph Neural Network Predictions](https://arxiv.org/abs/2509.10528)
*Amirhossein Ghaffari,Huong Nguyen,Lauri Lovén,Ekaterina Gilman*

Main category: cs.LG

TL;DR: STM-Graph是一个开源Python框架，用于将城市时空事件数据转换为适合GNN训练的图表示，包含空间映射方法、OpenStreetMap特征、多种GNN模型和可视化工具。


<details>
  <summary>Details</summary>
Motivation: 城市时空数据具有动态性和复杂性，传统方法难以有效处理，需要专门的框架来支持图神经网络在城市计算中的应用。

Method: 开发了STM-Graph框架，整合了多种空间映射方法、OpenStreetMap城市特征、多个GNN模型、可视化工具和图形用户界面，采用模块化可扩展设计。

Result: 提供了一个完整的开源框架，支持快速实验和基准测试，允许集成新的映射方法和自定义模型，为城市计算研究者和实践者提供有价值的资源。

Conclusion: STM-Graph是一个功能全面、易于使用的框架，能够有效处理城市时空数据，促进图神经网络在城市计算领域的应用和发展。

Abstract: Urban spatio-temporal data present unique challenges for predictive analytics
due to their dynamic and complex nature. We introduce STM-Graph, an open-source
Python framework that transforms raw spatio-temporal urban event data into
graph representations suitable for Graph Neural Network (GNN) training and
prediction. STM-Graph integrates diverse spatial mapping methods, urban
features from OpenStreetMap, multiple GNN models, comprehensive visualization
tools, and a graphical user interface (GUI) suitable for professional and
non-professional users. This modular and extensible framework facilitates rapid
experimentation and benchmarking. It allows integration of new mapping methods
and custom models, making it a valuable resource for researchers and
practitioners in urban computing. The source code of the framework and GUI are
available at: https://github.com/Ahghaffari/stm_graph and
https://github.com/tuminguyen/stm_graph_gui.

</details>


### [7] [California Wildfire Inventory (CAWFI): An Extensive Dataset for Predictive Techniques based on Artificial Intelligence](https://arxiv.org/abs/2509.11015)
*Rohan Tan Bhowmik,Youn Soo Jung,Juan Aguilera,Mary Prunicki,Kari Nadeau*

Main category: cs.LG

TL;DR: 本文介绍了加州野火数据库(CAWFI)，这是一个包含3700多万数据点的野火预测数据集，整合了2012-2018年的历史野火数据和2012-2022年的指标数据，用于训练机器学习模型进行野火预测。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化和生态系统破坏，全球野火对环境、基础设施和人类生命的影响日益严重。现有解决方案主要关注火灾发生后的检测，缺乏有效的预测技术来预防火灾发生。

Method: 构建加州野火数据库(CAWFI)，包含历史野火数据和三类指标数据：领先指标(气象数据)、滞后指标(环境数据)和地质指标(植被和海拔数据)。

Result: 使用2012-2017年数据训练的时空AI模型成功预测了85.7%的未来超过30万英亩的大型野火。

Conclusion: CAWFI数据集为野火预测研究提供了重要资源，并为其他地区建立类似数据库树立了先例，有助于预防特大野火和突发火灾。

Abstract: Due to climate change and the disruption of ecosystems worldwide, wildfires
are increasingly impacting environment, infrastructure, and human lives
globally. Additionally, an exacerbating climate crisis means that these losses
would continue to grow if preventative measures are not implemented. Though
recent advancements in artificial intelligence enable wildfire management
techniques, most deployed solutions focus on detecting wildfires after
ignition. The development of predictive techniques with high accuracy requires
extensive datasets to train machine learning models. This paper presents the
California Wildfire Inventory (CAWFI), a wildfire database of over 37 million
data points for building and training wildfire prediction solutions, thereby
potentially preventing megafires and flash fires by addressing them before they
spark. The dataset compiles daily historical California wildfire data from 2012
to 2018 and indicator data from 2012 to 2022. The indicator data consists of
leading indicators (meteorological data correlating to wildfire-prone
conditions), trailing indicators (environmental data correlating to prior and
early wildfire activity), and geological indicators (vegetation and elevation
data dictating wildfire risk and spread patterns). CAWFI has already
demonstrated success when used to train a spatio-temporal artificial
intelligence model, predicting 85.7% of future wildfires larger than 300,000
acres when trained on 2012-2017 indicator data. This dataset is intended to
enable wildfire prediction research and solutions as well as set a precedent
for future wildfire databases in other regions.

</details>


### [8] [BiLSTM-VHP: BiLSTM-Powered Network for Viral Host Prediction](https://arxiv.org/abs/2509.11345)
*Azher Ahmed Efat,Farzana Islam,Annajiat Alim Rasel,Munima Haque*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于双向LSTM的轻量级模型BiLSTM-VHP，能够根据核酸序列准确预测病毒的宿主来源，以防止人兽共患病的传播。


<details>
  <summary>Details</summary>
Motivation: 人兽共患病如SARS-CoV-2、猴痘和猪流感等对人类生命造成严重威胁，快速准确预测病毒宿主来源可以有效防止病毒传播。

Method: 使用双向长短期记忆网络(BiLSTM)构建轻量级模型，处理400个基因长度的核酸序列，对汉坤病毒、旋病毒A和狼痃病毒进行宿主预测。

Result: 模型在三种病毒数据集上分别达到89.62%、96.58%和77.22%的预测准确率，超过以往研究。使用混淆矩阵、F1分数、精确度、召回率等指标评估性能。

Conclusion: BiLSTM-VHP模型能够高效准确地预测病毒宿主来源，为人兽共患病防控提供了有力工具，同时公开了三个经过精心整理的病毒序列数据集。

Abstract: Recorded history shows the long coexistence of humans and animals, suggesting
it began much earlier. Despite some beneficial interdependence, many animals
carry viral diseases that can spread to humans. These diseases are known as
zoonotic diseases. Recent outbreaks of SARS-CoV-2, Monkeypox and swine flu
viruses have shown how these viruses can disrupt human life and cause death.
Fast and accurate predictions of the host from which the virus spreads can help
prevent these diseases from spreading. This work presents BiLSTM-VHP, a
lightweight bidirectional long short-term memory (LSTM)-based architecture that
can predict the host from the nucleotide sequence of orthohantavirus, rabies
lyssavirus, and rotavirus A with high accuracy. The proposed model works with
nucleotide sequences of 400 bases in length and achieved a prediction accuracy
of 89.62% for orthohantavirus, 96.58% for rotavirus A, and 77.22% for rabies
lyssavirus outperforming previous studies. Moreover, performance of the model
is assessed using the confusion matrix, F-1 score, precision, recall,
microaverage AUC. In addition, we introduce three curated datasets of
orthohantavirus, rotavirus A, and rabies lyssavirus containing 8,575, 95,197,
and 22,052 nucleotide sequences divided into 9, 12, and 29 host classes,
respectively. The codes and dataset are available at
https://doi.org/10.17605/OSF.IO/ANFKR

</details>


### [9] [Tabular Data with Class Imbalance: Predicting Electric Vehicle Crash Severity with Pretrained Transformers (TabPFN) and Mamba-Based Models](https://arxiv.org/abs/2509.11449)
*Shriyank Somvanshi,Pavan Hebli,Gaurab Chhetri,Subasish Das*

Main category: cs.LG

TL;DR: 使用深度表格学习框架预测电动车碰撞严重程度，通过SMOTEENN处理类别不平衡，模型比较显示MambaAttention在严重伤害分类上表现最优


<details>
  <summary>Details</summary>
Motivation: 体现深度表格学习模型在电动车碰撞严重程度预测中的潜力，以支持数据驱动的安全干预策略

Method: 使用得元州2017-2023年电动车碰撞数据，通过XGBoost和随机森林识别关键特征，采用SMOTEENN重采样处理类别不平衡，比较TabPFN、MambaNet和MambaAttention三种深度表格模型的表现

Result: 交叉口关系、首次有害事件、年龄、碰撞速度限制和星期几是最重要预测因素，MambaAttention模型在严重伤害分类上表现最优，TabPFN显示良好的普遍化能力

Conclusion: 深度表格学习框架能够显著提高电动车碰撞严重程度预测的准确性，为安全干预提供了数据支撑

Abstract: This study presents a deep tabular learning framework for predicting crash
severity in electric vehicle (EV) collisions using real-world crash data from
Texas (2017-2023). After filtering for electric-only vehicles, 23,301
EV-involved crash records were analyzed. Feature importance techniques using
XGBoost and Random Forest identified intersection relation, first harmful
event, person age, crash speed limit, and day of week as the top predictors,
along with advanced safety features like automatic emergency braking. To
address class imbalance, Synthetic Minority Over-sampling Technique and Edited
Nearest Neighbors (SMOTEENN) resampling was applied. Three state-of-the-art
deep tabular models, TabPFN, MambaNet, and MambaAttention, were benchmarked for
severity prediction. While TabPFN demonstrated strong generalization,
MambaAttention achieved superior performance in classifying severe injury cases
due to its attention-based feature reweighting. The findings highlight the
potential of deep tabular architectures for improving crash severity prediction
and enabling data-driven safety interventions in EV crash contexts.

</details>


### [10] [Know What You Don't Know: Selective Prediction for Early Exit DNNs](https://arxiv.org/abs/2509.11520)
*Divya Jyoti Bajpai,Manjesh Kumar Hanawal*

Main category: cs.LG

TL;DR: SPEED是一种结合选择性预测和早期退出的新方法，通过延迟分类器在中间层检测困难样本，提高DNN推理的准确性和延迟性能


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在关键应用中存在的推理延迟和可信度问题，特别是早期退出策略因模型过度自信而导致的不可靠预测问题

Method: 在每一层使用延迟分类器(DCs)来检查样本的难度，识别难以预测的样本并将其推迟到专家层处理，避免早期退出导致的错误预测

Result: 方法将错误预测风险降低了50%，相比最终层实现了2.05倍的加速，同时提高了准确性和延迟性能

Conclusion: 选择性预测与早期退出相结合的方法能够有效提高深度神经网络的可信度和推理效率，特别适用于关键应用场景

Abstract: Inference latency and trustworthiness of Deep Neural Networks (DNNs) are the
bottlenecks in deploying them in critical applications like sensitive tasks.
Early Exit (EE) DNNs overcome the latency issues by allowing samples to exit
from intermediary layers if they attain `high' confidence scores on the
predicted class. However, the DNNs are known to exhibit overconfidence, which
can lead to many samples exiting early and render EE strategies untrustworthy.
We use Selective Prediction (SP) to overcome this issue by checking the
`hardness' of the samples rather than just relying on the confidence score
alone. We propose SPEED, a novel approach that uses Deferral Classifiers (DCs)
at each layer to check the hardness of samples before performing EEs.
Specifically, the DCs identify if a sample is hard to predict at an
intermediary layer, leading to hallucination, and defer it to an expert. Early
detection of hard samples for inference prevents the wastage of computational
resources and improves trust by deferring the hard samples to the expert. We
demonstrate that EE aided with SP improves both accuracy and latency. Our
method minimizes the risk of wrong prediction by $50\%$ with a speedup of
$2.05\times$ as compared to the final layer. The anonymized source code is
available at https://github.com/Div290/SPEED

</details>


### [11] [Event2Vec: A Geometric Approach to Learning Composable Representations of Event Sequences](https://arxiv.org/abs/2509.12188)
*Antonin Sulc*

Main category: cs.LG

TL;DR: Event2Vec是一个学习离散事件序列表示的新框架，使用加法循环结构学习可组合、可解释的嵌入。在欧几里得空间中收敛到理想加法结构，序列表示是其组成事件的向量和。还提出了双曲空间变体，更适合分层数据。


<details>
  <summary>Details</summary>
Motivation: 受神经表示中几何和拓扑结构重要性的启发，需要为离散事件序列开发能够捕捉其内在结构的表示学习方法。

Method: 使用简单的加法循环结构学习可组合嵌入，在欧几里得和双曲空间中分别实现，理论分析证明在特定训练目标下收敛到线性加法结构。

Result: 实验验证了线性加法假设，双曲空间模型在分层事件序列上表现更好，展示了不同几何空间的优势。

Conclusion: Event2Vec框架成功学习了离散事件序列的有效表示，欧几里得空间适合一般序列，双曲空间更适合分层结构，几何选择对表示质量至关重要。

Abstract: The study of neural representations, both in biological and artificial
systems, is increasingly revealing the importance of geometric and topological
structures. Inspired by this, we introduce Event2Vec, a novel framework for
learning representations of discrete event sequences. Our model leverages a
simple, additive recurrent structure to learn composable, interpretable
embeddings. We provide a theoretical analysis demonstrating that, under
specific training objectives, our model's learned representations in a
Euclidean space converge to an ideal additive structure. This ensures that the
representation of a sequence is the vector sum of its constituent events, a
property we term the linear additive hypothesis. To address the limitations of
Euclidean geometry for hierarchical data, we also introduce a variant of our
model in hyperbolic space, which is naturally suited to embedding tree-like
structures with low distortion. We present experiments to validate our
hypothesis and demonstrate the benefits of each geometry, highlighting the
improved performance of the hyperbolic model on hierarchical event sequences.

</details>


### [12] [SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching](https://arxiv.org/abs/2509.11628)
*Jiacheng Liu,Chang Zou,Yuanhuiyi Lyu,Fei Ren,Shaobo Wang,Kaixin Li,Linfeng Zhang*

Main category: cs.LG

TL;DR: SpeCa是一个基于推测采样的扩散模型加速框架，通过预测中间特征和验证机制实现6-7倍加速，同时保持生成质量


<details>
  <summary>Details</summary>
Motivation: 扩散模型计算需求大，存在严格的时间依赖性和计算密集型前向传递问题，无法满足实时应用需求

Method: 引入推测采样预测后续时间步特征，采用参数无关验证机制评估预测可靠性，并实现样本自适应计算分配

Result: 在FLUX上实现6.34倍加速（质量下降5.5%），DiT上7.3倍加速保持保真度，HunyuanVideo上6.1倍加速获得79.84% VBench分数

Conclusion: SpeCa为扩散模型推理建立了高效新范式，在激进加速比下仍能保持生成质量，验证机制开销极小（1.67%-3.5%）

Abstract: Diffusion models have revolutionized high-fidelity image and video synthesis,
yet their computational demands remain prohibitive for real-time applications.
These models face two fundamental challenges: strict temporal dependencies
preventing parallelization, and computationally intensive forward passes
required at each denoising step. Drawing inspiration from speculative decoding
in large language models, we present SpeCa, a novel 'Forecast-then-verify'
acceleration framework that effectively addresses both limitations. SpeCa's
core innovation lies in introducing Speculative Sampling to diffusion models,
predicting intermediate features for subsequent timesteps based on fully
computed reference timesteps. Our approach implements a parameter-free
verification mechanism that efficiently evaluates prediction reliability,
enabling real-time decisions to accept or reject each prediction while
incurring negligible computational overhead. Furthermore, SpeCa introduces
sample-adaptive computation allocation that dynamically modulates resources
based on generation complexity, allocating reduced computation for simpler
samples while preserving intensive processing for complex instances.
Experiments demonstrate 6.34x acceleration on FLUX with minimal quality
degradation (5.5% drop), 7.3x speedup on DiT while preserving generation
fidelity, and 79.84% VBench score at 6.1x acceleration for HunyuanVideo. The
verification mechanism incurs minimal overhead (1.67%-3.5% of full inference
costs), establishing a new paradigm for efficient diffusion model inference
while maintaining generation quality even at aggressive acceleration ratios.
Our codes have been released in Github:
\textbf{https://github.com/Shenyi-Z/Cache4Diffusion}

</details>


### [13] [Watch Your Step: A Cost-Sensitive Framework for Accelerometer-Based Fall Detection in Real-World Streaming Scenarios](https://arxiv.org/abs/2509.11789)
*Timilehin B. Aderinola,Luca Palmerini,Ilaria D'Ascanio,Lorenzo Chiari,Jochen Klenk,Clemens Becker,Brian Caulfield,Georgiana Ifrim*

Main category: cs.LG

TL;DR: 基于IMU数据的实时軌候检测框架，通过成本敏感学习策略调整决策阈值，在FARSEEING数据集上实现了1.00的召回率和0.84的精确度，每次检测平均耗时5毫秒以内。


<details>
  <summary>Details</summary>
Motivation: 现有軌候检测方法多依赖仿真数据或假设知道軌候事件，限制了实际部署的可用性，需要高效计算和稳健评估指标来支持连续监测。

Method: 使用FARSEEING实际軌候数据集的60小时IMU数据，采用高效分类器进行流式軌候概率计算，并通过成本敏感学习策略调整决策阈值，以反映漏检軌候比假报警的高风险。

Result: 在FARSEEING数据集上实现了召回率1.00、精确度0.84、F1分0.91，检测所有軌候事件的同时保持低假报警率，平均推理时间小于5毫秒。

Conclusion: 成本敏感阈值调整提高了加速计基础的軌候检测系统的稳健性，该高效计算框架有潜力部署于实时可穿戴传感器系统中进行连续监测。

Abstract: Real-time fall detection is crucial for enabling timely interventions and
mitigating the severe health consequences of falls, particularly in older
adults. However, existing methods often rely on simulated data or assumptions
such as prior knowledge of fall events, limiting their real-world
applicability. Practical deployment also requires efficient computation and
robust evaluation metrics tailored to continuous monitoring. This paper
presents a real-time fall detection framework for continuous monitoring without
prior knowledge of fall events. Using over 60 hours of inertial measurement
unit (IMU) data from the FARSEEING real-world falls dataset, we employ recent
efficient classifiers to compute fall probabilities in streaming mode. To
enhance robustness, we introduce a cost-sensitive learning strategy that tunes
the decision threshold using a cost function reflecting the higher risk of
missed falls compared to false alarms. Unlike many methods that achieve high
recall only at the cost of precision, our framework achieved Recall of 1.00,
Precision of 0.84, and an F1 score of 0.91 on FARSEEING, detecting all falls
while keeping false alarms low, with average inference time below 5 ms per
sample. These results demonstrate that cost-sensitive threshold tuning enhances
the robustness of accelerometer-based fall detection. They also highlight the
potential of our computationally efficient framework for deployment in
real-time wearable sensor systems for continuous monitoring.

</details>


### [14] [Do machine learning climate models work in changing climate dynamics?](https://arxiv.org/abs/2509.12147)
*Maria Conchita Agana Navarro,Geng Li,Theo Wolf,María Pérez-Ortiz*

Main category: cs.LG

TL;DR: 本研究系统评估了机器学习模型在气候变化预测中的分布外通用性，发现当前模型在极端事件预测中存在显著性能波动


<details>
  <summary>Details</summary>
Motivation: 气候变化加速引发无前例的极端事件，预测这些分布外事件对风险评估和适应措施至关重要

Method: 通过适配分布外评估方法到气候数据，系统测试各种分布外场景下的机器学习模型表现

Result: 大规模数据集实验显示，不同场景下模型性能存在显著差异，揭示了当前模型的优缺点

Conclusion: 建立健壮的评估框架对于机器学习在气候风险预测中的可靠应用至关重要，提供了可操作的指导见解

Abstract: Climate change is accelerating the frequency and severity of unprecedented
events, deviating from established patterns. Predicting these
out-of-distribution (OOD) events is critical for assessing risks and guiding
climate adaptation. While machine learning (ML) models have shown promise in
providing precise, high-speed climate predictions, their ability to generalize
under distribution shifts remains a significant limitation that has been
underexplored in climate contexts. This research systematically evaluates
state-of-the-art ML-based climate models in diverse OOD scenarios by adapting
established OOD evaluation methodologies to climate data. Experiments on
large-scale datasets reveal notable performance variability across scenarios,
shedding light on the strengths and limitations of current models. These
findings underscore the importance of robust evaluation frameworks and provide
actionable insights to guide the reliable application of ML for climate risk
forecasting.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions](https://arxiv.org/abs/2509.10707)
*Sajjad Abdoli,Rudi Cilibrasi,Rima Al-Shikh*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As AI systems increasingly evaluate other AI outputs, understanding their
assessment behavior becomes crucial for preventing cascading biases. This study
analyzes vision-language descriptions generated by NVIDIA's Describe Anything
Model and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to
uncover distinct "evaluation personalities" the underlying assessment
strategies and biases each model demonstrates. GPT-4o-mini exhibits systematic
consistency with minimal variance, GPT-4o excels at error detection, while
GPT-5 shows extreme conservatism with high variability. Controlled experiments
using Gemini 2.5 Pro as an independent question generator validate that these
personalities are inherent model properties rather than artifacts. Cross-family
analysis through semantic similarity of generated questions reveals significant
divergence: GPT models cluster together with high similarity while Gemini
exhibits markedly different evaluation strategies. All GPT models demonstrate a
consistent 2:1 bias favoring negative assessment over positive confirmation,
though this pattern appears family-specific rather than universal across AI
architectures. These findings suggest that evaluation competence does not scale
with general capability and that robust AI assessment requires diverse
architectural perspectives.

</details>


### [16] [BuildingGym: An open-source toolbox for AI-based building energy management using reinforcement learning](https://arxiv.org/abs/2509.11922)
*Xilei Dai,Ruotian Chen,Songze Guan,Wen-Tai Li,Chau Yuen*

Main category: cs.AI

TL;DR: BuildingGym是一个开源框架，用于训练建筑能源管理中的强化学习控制策略，集成EnergyPlus模拟器，支持系统级和房间级控制，并能接受外部信号输入。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏灵活的框架来在各种建筑能源管理控制问题中实施强化学习，需要一种研究友好且通用的工具。

Method: 开发BuildingGym开源工具，集成EnergyPlus作为核心模拟器，提供内置RL算法，支持外部信号输入，允许轻松配置和替换算法、模拟器和控制环境。

Result: 在冷却负荷管理任务中，内置算法表现出色，验证了BuildingGym在优化冷却策略方面的有效性。

Conclusion: BuildingGym填补了建筑管理人员与AI专家之间的鸿沟，为建筑能源管理领域提供了灵活高效的RL控制策略训练平台。

Abstract: Reinforcement learning (RL) has proven effective for AI-based building energy
management. However, there is a lack of flexible framework to implement RL
across various control problems in building energy management. To address this
gap, we propose BuildingGym, an open-source tool designed as a
research-friendly and flexible framework for training RL control strategies for
common challenges in building energy management. BuildingGym integrates
EnergyPlus as its core simulator, making it suitable for both system-level and
room-level control. Additionally, BuildingGym is able to accept external
signals as control inputs instead of taking the building as a stand-alone
entity. This feature makes BuildingGym applicable for more flexible
environments, e.g. smart grid and EVs community. The tool provides several
built-in RL algorithms for control strategy training, simplifying the process
for building managers to obtain optimal control strategies. Users can achieve
this by following a few straightforward steps to configure BuildingGym for
optimization control for common problems in the building energy management
field. Moreover, AI specialists can easily implement and test state-of-the-art
control algorithms within the platform. BuildingGym bridges the gap between
building managers and AI specialists by allowing for the easy configuration and
replacement of RL algorithms, simulators, and control environments or problems.
With BuildingGym, we efficiently set up training tasks for cooling load
management, targeting both constant and dynamic cooling load management. The
built-in algorithms demonstrated strong performance across both tasks,
highlighting the effectiveness of BuildingGym in optimizing cooling strategies.

</details>


### [17] [Neuromorphic Intelligence](https://arxiv.org/abs/2509.11940)
*Marcel van Gerven*

Main category: cs.AI

TL;DR: 神经形态计算通过动力学系统理论提供统一框架，利用脑启发原理实现高能效智能系统，将噪声作为学习资源，推动可持续AI发展


<details>
  <summary>Details</summary>
Motivation: 寻求复制人脑高效能、灵活性和适应性的计算方式，解决传统数字方法计算和能源消耗巨大的问题，需要建立跨学科的统一理论框架

Method: 采用动力学系统理论作为理论基础，利用微分计算建模推理、学习和控制过程，通过微分遗传编程发现实现自适应行为的动力学系统

Result: 提出了基于动力学系统理论的神经形态计算框架，能够将噪声转化为学习资源，在物理基底中实现智能行为的涌现

Conclusion: 动力学系统理论为神经形态计算提供了统一的跨学科框架，推动了可持续AI的发展，使智能行为能够从物理系统的动力学中自然涌现

Abstract: Neuromorphic computing seeks to replicate the remarkable efficiency,
flexibility, and adaptability of the human brain in artificial systems. Unlike
conventional digital approaches, which depend on massive computational and
energy resources, neuromorphic systems exploit brain-inspired principles of
computation to achieve orders of magnitude greater energy efficiency. By
drawing on insights from artificial intelligence, neuroscience, physics,
chemistry, and materials science, neuromorphic computing promises to deliver
intelligent systems that are sustainable, transparent, and widely accessible. A
central challenge, however, is to identify a unifying theoretical framework
capable of bridging these diverse disciplines. We argue that dynamical systems
theory provides such a foundation. Rooted in differential calculus, it offers a
principled language for modeling inference, learning, and control in both
natural and artificial substrates. Within this framework, noise can be
harnessed as a resource for learning, while differential genetic programming
enables the discovery of dynamical systems that implement adaptive behaviors.
Embracing this perspective paves the way toward emergent neuromorphic
intelligence, where intelligent behavior arises from the dynamics of physical
substrates, advancing both the science and sustainability of AI.

</details>


### [18] [Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics](https://arxiv.org/abs/2509.11943)
*Antonin Sulc,Thorsten Hellert*

Main category: cs.AI

TL;DR: 本文提出了一种神经符号多智能体架构，使用Kripke模型形式化表示智能体信念状态，结合模态逻辑进行可能性与必然性推理，在粒子加速器环境中成功诊断复杂级联故障


<details>
  <summary>Details</summary>
Motivation: 当前智能体研究主要关注模型和数据规模的扩展，但忽略了智能体在环境中推理结构、保真度和逻辑一致性的扩展需求，这是AI研究中关键但未被充分探索的维度

Method: 采用神经符号多智能体架构，将个体智能体信念状态表示为Kripke模型，使用模态逻辑形式语言进行可能性与必然性推理，利用不可变的领域特定知识作为逻辑约束来指导语言模型的假设生成

Result: 在高保真模拟粒子加速器环境中，系统成功诊断了复杂的级联故障，结合了语言模型的强大语义直觉与模态逻辑的严格可验证性

Conclusion: 该方法展示了构建更鲁棒、可靠和可验证的自主智能体的可行路径，通过形式化逻辑约束有效防止语言模型得出物理或逻辑上不可行的结论

Abstract: The development of intelligent agents, particularly those powered by language
models (LMs), has shown the critical role in various environments that require
intelligent and autonomous decision. Environments are not passive testing
grounds and they represent the data required for agents to learn and exhibit
very challenging conditions that require adaptive, complex and autonomous
capacity to make decisions. While the paradigm of scaling models and datasets
has led to remarkable emergent capabilities, we argue that scaling the
structure, fidelity, and logical consistency of agent reasoning within these
environments is a crucial, yet underexplored, dimension of AI research. This
paper introduces a neuro-symbolic multi-agent architecture where the belief
states of individual agents are formally represented as Kripke models. This
foundational choice enables them to reason about known concepts of
\emph{possibility} and \emph{necessity} using the formal language of modal
logic. In this work, we use of immutable, domain-specific knowledge to make
infere information, which is encoded as logical constraints essential for
proper diagnosis. In the proposed model, we show constraints that actively
guide the hypothesis generation of LMs, effectively preventing them from
reaching physically or logically untenable conclusions. In a high-fidelity
simulated particle accelerator environment, our system successfully diagnoses
complex, cascading failures by combining the powerful semantic intuition of LMs
with the rigorous, verifiable validation of modal logic and a factual world
model and showcasing a viable path toward more robust, reliable, and verifiable
autonomous agents.

</details>


### [19] [Advancing Medical Artificial Intelligence Using a Century of Cases](https://arxiv.org/abs/2509.12194)
*Thomas A. Buckley,Riccardo Conci,Peter G. Brodeur,Jason Gusdorf,Sourik Beltrán,Bita Behrouzi,Byron Crowe,Jacob Dockterman,Muzzammil Muhammad,Sarah Ohnigian,Andrew Sanchez,James A. Diao,Aashna P. Shah,Daniel Restrepo,Eric S. Rosenberg,Andrew S. Lea,Marinka Zitnik,Scott H. Podolsky,Zahir Kanjee,Raja-Elie E. Abdulnour,Jacob M. Koshy,Adam Rodman,Arjun K. Manrai*

Main category: cs.AI

TL;DR: LLM在复杂文本诊断方面超越医生表现，能有效模拟专家医学演示，但在图像解读和文献检索方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 测试AI在医学诊断推理和演示方面的能力，超越以往仅关注最终诊断的评估方式。

Method: 使用7102个临床病理会议案例和1021个图像挑战创建CPC-Bench基准，评估领先LLM并开发Dr. CaBot AI讨论系统。

Result: o3模型在60%案例中排名第一诊断，84%进入前十，优于20名医生基线；图像任务准确率67%；CaBot生成内容74%被医生误认为人类专家所写。

Conclusion: LLM在文本诊断方面表现优异，能有效模拟专家演示，但图像和文献检索仍需改进。CPC-Bench和CaBot有助于持续追踪医学AI进展。

Abstract: BACKGROUND: For over a century, the New England Journal of Medicine
Clinicopathological Conferences (CPCs) have tested the reasoning of expert
physicians and, recently, artificial intelligence (AI). However, prior AI
evaluations have focused on final diagnoses without addressing the multifaceted
reasoning and presentation skills required of expert discussants.
  METHODS: Using 7102 CPCs (1923-2025) and 1021 Image Challenges (2006-2025),
we conducted extensive physician annotation and automated processing to create
CPC-Bench, a physician-validated benchmark spanning 10 text-based and
multimodal tasks, against which we evaluated leading large language models
(LLMs). Then, we developed "Dr. CaBot," an AI discussant designed to produce
written and slide-based video presentations using only the case presentation,
modeling the role of the human expert in these cases.
  RESULTS: When challenged with 377 contemporary CPCs, o3 (OpenAI) ranked the
final diagnosis first in 60% of cases and within the top ten in 84% of cases,
outperforming a 20-physician baseline; next-test selection accuracy reached
98%. Event-level physician annotations quantified AI diagnostic accuracy per
unit of information. Performance was lower on literature search and image
tasks; o3 and Gemini 2.5 Pro (Google) achieved 67% accuracy on image
challenges. In blinded comparisons of CaBot vs. human expert-generated text,
physicians misclassified the source of the differential in 46 of 62 (74%) of
trials, and scored CaBot more favorably across quality dimensions. To promote
research, we are releasing CaBot and CPC-Bench.
  CONCLUSIONS: LLMs exceed physician performance on complex text-based
differential diagnosis and convincingly emulate expert medical presentations,
but image interpretation and literature retrieval remain weaker. CPC-Bench and
CaBot may enable transparent and continued tracking of progress in medical AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Towards Automated Error Discovery: A Study in Conversational AI](https://arxiv.org/abs/2509.10833)
*Dominic Petrak,Thy Thy Tran,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出了SEEED框架，使用基于编码器的方法检测对话AI中的错误，通过改进Soft Nearest Neighbor Loss和标签样本排序来提升未知错误检测性能，在多个数据集上超越GPT-4o等基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的对话代理虽然流畅连贯，但仍会产生难以预防的错误行为。现有LLM难以检测指令中未明确指定的错误，特别是当生成模型更新或用户行为变化时。

Method: 提出Automated Error Discovery框架和SEEED实现方法：改进Soft Nearest Neighbor Loss（增强负样本距离权重），引入Label-Based Sample Ranking选择高对比度样本以改善表示学习。

Result: SEEED在多个错误标注对话数据集上超越GPT-4o和Phi-4等基线模型，未知错误检测准确率提升高达8个百分点，在未知意图检测方面表现出强泛化能力。

Conclusion: SEEED框架有效解决了对话AI中未知错误的检测问题，通过改进的表示学习方法实现了比大型语言模型更好的错误检测性能，具有良好的泛化能力。

Abstract: Although LLM-based conversational agents demonstrate strong fluency and
coherence, they still produce undesirable behaviors (errors) that are
challenging to prevent from reaching users during deployment. Recent research
leverages large language models (LLMs) to detect errors and guide
response-generation models toward improvement. However, current LLMs struggle
to identify errors not explicitly specified in their instructions, such as
those arising from updates to the response-generation model or shifts in user
behavior. In this work, we introduce Automated Error Discovery, a framework for
detecting and defining errors in conversational AI, and propose SEEED (Soft
Clustering Extended Encoder-Based Error Detection), as an encoder-based
approach to its implementation. We enhance the Soft Nearest Neighbor Loss by
amplifying distance weighting for negative samples and introduce Label-Based
Sample Ranking to select highly contrastive examples for better representation
learning. SEEED outperforms adapted baselines -- including GPT-4o and Phi-4 --
across multiple error-annotated dialogue datasets, improving the accuracy for
detecting unknown errors by up to 8 points and demonstrating strong
generalization to unknown intent detection.

</details>


### [21] [Aligning ESG Controversy Data with International Guidelines through Semi-Automatic Ontology Construction](https://arxiv.org/abs/2509.10922)
*Tsuyoshi Iwata,Guillaume Comte,Melissa Flores,Ryoma Kondo,Ryohei Hisano*

Main category: cs.CL

TL;DR: 提出了一种半自动方法，使用轻量级本体设计、形式化模式建模和大语言模型，将ESG新闻事件转化为结构化知识图谱，以解决非财务风险数据与规范性框架对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 环境、社会和治理数据在监管和投资中日益重要，但将新闻中的争议相关数据与联合国全球契约等原则性规范框架对齐存在重大挑战，因为这些框架语言抽象、缺乏标准化分类法。

Method: 使用轻量级本体设计、形式化模式建模和大语言模型，将规范性原则转化为可重用的RDF模板，从新闻内容中提取相关信息并构建结构化知识图谱。

Result: 开发了一个可扩展且透明的框架，用于识别和解释与国际可持续发展指南的不合规情况。

Conclusion: 该方法能够有效解决ESG事件数据与规范性框架的对齐问题，为可持续发展监管和投资决策提供支持。

Abstract: The growing importance of environmental, social, and governance data in
regulatory and investment contexts has increased the need for accurate,
interpretable, and internationally aligned representations of non-financial
risks, particularly those reported in unstructured news sources. However,
aligning such controversy-related data with principle-based normative
frameworks, such as the United Nations Global Compact or Sustainable
Development Goals, presents significant challenges. These frameworks are
typically expressed in abstract language, lack standardized taxonomies, and
differ from the proprietary classification systems used by commercial data
providers. In this paper, we present a semi-automatic method for constructing
structured knowledge representations of environmental, social, and governance
events reported in the news. Our approach uses lightweight ontology design,
formal pattern modeling, and large language models to convert normative
principles into reusable templates expressed in the Resource Description
Framework. These templates are used to extract relevant information from news
content and populate a structured knowledge graph that links reported incidents
to specific framework principles. The result is a scalable and transparent
framework for identifying and interpreting non-compliance with international
sustainability guidelines.

</details>


### [22] [A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection](https://arxiv.org/abs/2509.11687)
*Di Jin,Jun Yang,Xiaobao Wang,Junwei Zhang,Shuqi Li,Dongxiao He*

Main category: cs.CL

TL;DR: 提出了DYNAMO模型，通过知识图谱动态更新和大型语言模型结合，解决假新闻检测中知识真实性验证和语义深度挖掘两个关键问题


<details>
  <summary>Details</summary>
Motivation: 互联网和社交媒体快速发展，海量复杂信息中区分可信新闻面临挑战。新闻事件的突发性和不稳定性导致真实性标签可能变化，需要获取最新事件更新

Method: 1. 构建新闻领域特定知识图谱 2. 使用蒙特卡洛树搜索分解复杂新闻并逐步验证 3. 从已验证的真实新闻文本和推理路径中提取更新新知识

Result: 在两个真实世界数据集上取得了最佳性能

Conclusion: DYNAMO模型通过动态知识更新机制有效解决了假新闻检测中的知识真实性和语义挖掘问题

Abstract: As the Internet and social media evolve rapidly, distinguishing credible news
from a vast amount of complex information poses a significant challenge. Due to
the suddenness and instability of news events, the authenticity labels of news
can potentially shift as events develop, making it crucial for fake news
detection to obtain the latest event updates. Existing methods employ
retrieval-augmented generation to fill knowledge gaps, but they suffer from
issues such as insufficient credibility of retrieved content and interference
from noisy information. We propose a dynamic knowledge update-driven model for
fake news detection (DYNAMO), which leverages knowledge graphs to achieve
continuous updating of new knowledge and integrates with large language models
to fulfill dual functions: news authenticity detection and verification of new
knowledge correctness, solving the two key problems of ensuring the
authenticity of new knowledge and deeply mining news semantics. Specifically,
we first construct a news-domain-specific knowledge graph. Then, we use Monte
Carlo Tree Search to decompose complex news and verify them step by step.
Finally, we extract and update new knowledge from verified real news texts and
reasoning paths. Experimental results demonstrate that DYNAMO achieves the best
performance on two real-world datasets.

</details>


### [23] [When Curiosity Signals Danger: Predicting Health Crises Through Online Medication Inquiries](https://arxiv.org/abs/2509.11802)
*Dvora Goncharok,Arbel Shifman,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 该研究创建了一个标注的药物相关在线论坛问题数据集，用于检测可能预示严重健康风险的关键问题，并比较了传统机器学习方法和大型语言模型在分类性能上的表现。


<details>
  <summary>Details</summary>
Motivation: 在线医疗论坛包含大量未被充分利用的患者用药问题信息，其中一些问题可能预示着药物误用或健康危机，需要及时检测这些关键问题以进行干预并提高患者安全。

Method: 研究构建了一个手动标注临床风险等级的药物相关问题数据集，使用TF-IDF文本表示的传统机器学习分类器（6种）和基于大型语言模型的深度上下文理解分类方法（3种）进行性能基准测试。

Result: 研究结果表明传统方法和现代方法在支持数字健康空间实时分诊和警报系统方面都具有潜力，相关数据集已公开供进一步研究使用。

Conclusion: 该研究为患者生成数据、自然语言处理和关键健康事件早期预警系统的交叉研究提供了有价值的资源和基准，有助于推动数字健康干预系统的发展。

Abstract: Online medical forums are a rich and underutilized source of insight into
patient concerns, especially regarding medication use. Some of the many
questions users pose may signal confusion, misuse, or even the early warning
signs of a developing health crisis. Detecting these critical questions that
may precede severe adverse events or life-threatening complications is vital
for timely intervention and improving patient safety. This study introduces a
novel annotated dataset of medication-related questions extracted from online
forums. Each entry is manually labelled for criticality based on clinical risk
factors. We benchmark the performance of six traditional machine learning
classifiers using TF-IDF textual representations, alongside three
state-of-the-art large language model (LLM)-based classification approaches
that leverage deep contextual understanding. Our results highlight the
potential of classical and modern methods to support real-time triage and alert
systems in digital health spaces. The curated dataset is made publicly
available to encourage further research at the intersection of
patient-generated data, natural language processing, and early warning systems
for critical health events. The dataset and benchmark are available at:
https://github.com/Dvora-coder/LLM-Medication-QA-Risk-Classifier-MediGuard.

</details>


### [24] [PledgeTracker: A System for Monitoring the Fulfilment of Pledges](https://arxiv.org/abs/2509.11804)
*Yulong Chen,Michael Sejr Schlichtkrull,Zhenyun Deng,David Corney,Nasim Asl,Joshua Salisbury,Andrew Dudfield,Andreas Vlachos*

Main category: cs.CL

TL;DR: PledgeTracker是一个将政治承诺验证重新构建为结构化事件时间线构建的系统，通过多步骤证据检索、时间线构建和履行过滤模块来跟踪承诺的履行情况。


<details>
  <summary>Details</summary>
Motivation: 现有的方法将政治承诺验证简化为文档分类任务，忽略了其动态性、时序性和多文档特性，需要一种能够处理增量证据和动态更新的方法。

Method: 系统包含三个核心组件：(1)多步骤证据检索模块；(2)时间线构建模块；(3)履行过滤模块，通过构建结构化事件时间线来捕捉承诺履行的演变过程。

Result: 与专业事实核查人员在真实工作流程中合作评估，证明系统在检索相关证据和减少人工验证工作量方面具有有效性。

Conclusion: PledgeTracker通过结构化时间线构建方法，能够更好地处理政治承诺验证的动态性和多文档特性，提供可解释的验证结果。

Abstract: Political pledges reflect candidates' policy commitments, but tracking their
fulfilment requires reasoning over incremental evidence distributed across
multiple, dynamically updated sources. Existing methods simplify this task into
a document classification task, overlooking its dynamic, temporal and
multi-document nature. To address this issue, we introduce
\textsc{PledgeTracker}, a system that reformulates pledge verification into
structured event timeline construction. PledgeTracker consists of three core
components: (1) a multi-step evidence retrieval module; (2) a timeline
construction module and; (3) a fulfilment filtering module, allowing the
capture of the evolving nature of pledge fulfilment and producing interpretable
and structured timelines. We evaluate PledgeTracker in collaboration with
professional fact-checkers in real-world workflows, demonstrating its
effectiveness in retrieving relevant evidence and reducing human verification
effort.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [25] [STL-Based Motion Planning and Uncertainty-Aware Risk Analysis for Human-Robot Collaboration with a Multi-Rotor Aerial Vehicle](https://arxiv.org/abs/2509.10692)
*Giuseppe Silano,Amr Afifi,Martin Saska,Antonio Franchi*

Main category: cs.RO

TL;DR: 一种基于信号时态逻辑的方法，通过优化框架生成动态可行轨迹，并结合不确定性风险分析和事件触发重新规划策略，提高人机协作的安全性和弹性。


<details>
  <summary>Details</summary>
Motivation: 提高多旋翼航空器与人类协作的安全性、效率和弹性，特别是在运维护等复杂场景中保障人机交互的安全与舒适性。

Method: 使用信号时态逻辑(STL)编码安全、时间和人类偏好等任务目标，通过优化框架生成动态可行轨迹，采用充分平滑近似和梯度基础技术处理非线性非凸问题，并结合不确定性风险分析和事件触发重新规划策略。

Result: 通过MATLAB和Gazebo模拟验证，在仿真运维维护场景中进行物体交接任务，结果显示方法能够实现安全、高效和具有弹性的人机协作。

Conclusion: 该方法为人机协作提供了一种有效的轨迹规划和风险分析框架，能够在复杂环境中确保任务的安全完成和人机交互的舒适性。

Abstract: This paper presents a novel approach to motion planning and risk analysis for
enhancing human-robot collaboration using a Multi-Rotor Aerial Vehicle (MRAV).
The proposed method uses Signal Temporal Logic (STL) to encode key mission
objectives, such as safety, timing, and human preferences, with a strong focus
on ergonomics and comfort. An optimization framework generates dynamically
feasible trajectories while considering the MRAV's physical constraints. Given
the nonlinear and non-convex nature of the problem, smooth approximations and
gradient-based techniques assist in handling the problem's computational
complexity. Additionally, an uncertainty-aware risk analysis is incorporated to
assess potential deviations from the mission specifications, providing insights
into the likelihood of mission success under uncertain conditions. Further, an
event-triggered replanning strategy is implemented to respond to unforeseen
events and external disturbances. The approach is validated through MATLAB and
Gazebo simulations, using an object handover task in a mock-up environment
inspired by power line maintenance scenarios. The results highlight the
method's effectiveness in achieving safe, efficient, and resilient human-robot
collaboration.

</details>


### [26] [Tensor Invariant Data-Assisted Control and Dynamic Decomposition of Multibody Systems](https://arxiv.org/abs/2509.11688)
*Mostafa Eslami,Maryam Babazadeh*

Main category: cs.RO

TL;DR: 本文提出了一种基于张量力学的坐标无关多体动力学框架，结合数据辅助控制架构，解决了机器人系统在复杂协作空间中学习的数据效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 传统坐标依赖模型无法在不同参考系间泛化物理交互，导致学习算法需要为每个新方向重新发现物理原理，造成数据效率低下和复杂性增加。

Method: 开发了非递归闭式牛顿-欧拉模型的增强矩阵形式，采用张量不变性建模和控制管道，将系统分解为结构确定部分和不确定交互部分，通过虚拟端口变量连接。

Result: 通过李雅普诺夫分析证明了稳定性和抽象命令接口，仿真验证了模型和闭环系统的有效性。

Conclusion: 该框架为数据高效的帧不变学习算法提供了理想输入，直接解决了数据效率问题，提高了可解释性，为交互环境中更鲁棒和可泛化的机器人控制铺平了道路。

Abstract: The control of robotic systems in complex, shared collaborative workspaces
presents significant challenges in achieving robust performance and safety when
learning from experienced or simulated data is employed in the pipeline. A
primary bottleneck is the reliance on coordinate-dependent models, which leads
to profound data inefficiency by failing to generalize physical interactions
across different frames of reference. This forces learning algorithms to
rediscover fundamental physical principles in every new orientation,
artificially inflating the complexity of the learning task. This paper
introduces a novel framework that synergizes a coordinate-free, unreduced
multibody dynamics and kinematics model based on tensor mechanics with a
Data-Assisted Control (DAC) architecture. A non-recursive, closed-form
Newton-Euler model in an augmented matrix form is derived that is optimized for
tensor-based control design. This structure enables a principled decomposition
of the system into a structurally certain, physically grounded part and an
uncertain, empirical, and interaction-focused part, mediated by a virtual port
variable. Then, a complete, end-to-end tensor-invariant pipeline for modeling,
control, and learning is proposed. The coordinate-free control laws for the
structurally certain part provide a stable and abstract command interface,
proven via Lyapunov analysis. Eventually, the model and closed-loop system are
validated through simulations. This work provides a naturally ideal input for
data-efficient, frame-invariant learning algorithms, such as equivariant
learning, designed to learn the uncertain interaction. The synergy directly
addresses the data-inefficiency problem, increases explainability and
interpretability, and paves the way for more robust and generalizable robotic
control in interactive environments.

</details>


### [27] [From Pixels to Shelf: End-to-End Algorithmic Control of a Mobile Manipulator for Supermarket Stocking and Fronting](https://arxiv.org/abs/2509.11740)
*Davide Peron,Victor Nan Fernandez-Ayala,Lukas Segelmark*

Main category: cs.RO

TL;DR: 这篇论文提出了一种基于商业硬件的端到端机器人系统，用于超市自主货架补货和前置操作，通过实验验证了其高可靠性，但仍不如人工效率。


<details>
  <summary>Details</summary>
Motivation: 解决超市环境中的自主补货挑战，包括动态人类交互、空间约束和多样化商品形状等问题。

Method: 集成商业硬件和ROS2基础的感知、规划和控制系统，采用行为树做任务规划，精调视觉模型进行物体检测，以及两步模型预测控制框架实现精确货架导航。

Result: 在模拟超市环境的实验中，系统在700多次补货操作中达到了超过98%的成功率，但综合性能和成本效益仍低于人工水平。

Conclusion: 虽然系统表现可靠，但当前自主补货系统在性能和成本方面仍不及人类，需要进一步改进才能实现商业化部署。

Abstract: Autonomous stocking in retail environments, particularly supermarkets,
presents challenges due to dynamic human interactions, constrained spaces, and
diverse product geometries. This paper introduces an efficient end-to-end
robotic system for autonomous shelf stocking and fronting, integrating
commercially available hardware with a scalable algorithmic architecture. A
major contribution of this work is the system integration of off-the-shelf
hardware and ROS2-based perception, planning, and control into a single
deployable platform for retail environments. Our solution leverages Behavior
Trees (BTs) for task planning, fine-tuned vision models for object detection,
and a two-step Model Predictive Control (MPC) framework for precise shelf
navigation using ArUco markers. Laboratory experiments replicating realistic
supermarket conditions demonstrate reliable performance, achieving over 98%
success in pick-and-place operations across a total of more than 700 stocking
events. However, our comparative benchmarks indicate that the performance and
cost-effectiveness of current autonomous systems remain inferior to that of
human workers, which we use to highlight key improvement areas and quantify the
progress still required before widespread commercial deployment can
realistically be achieved.

</details>
