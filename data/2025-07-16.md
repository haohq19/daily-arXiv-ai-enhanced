<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 6]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference](https://arxiv.org/abs/2507.10800)
*Ali Hojjat,Janek Haberer,Soren Pirk,Olaf Landsiedel*

Main category: cs.CV

TL;DR: ThinkingViT是一种动态调整计算资源的嵌套ViT架构，通过渐进式推理阶段和Token Recycling机制提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有嵌套Transformer模型对所有输入分配相同计算资源导致的效率低下问题。

Method: 采用渐进式推理阶段，动态激活注意力头，并结合Token Recycling机制优化推理过程。

Result: 在ImageNet-1K上，ThinkingViT在相同吞吐量下准确率提升2.0 p.p.，相同计算量下提升2.9 p.p.。

Conclusion: ThinkingViT通过动态调整计算资源，显著提升了模型效率和性能。

Abstract: Vision Transformers deliver state-of-the-art performance, yet their fixed
computational budget prevents scalable deployment across heterogeneous
hardware. Recent nested Transformer architectures mitigate this by embedding
nested subnetworks within a single model to enable scalable inference. However,
these models allocate the same amount of compute to all inputs, regardless of
their complexity, which leads to inefficiencies. To address this, we introduce
ThinkingViT, a nested ViT architecture that employs progressive thinking stages
to dynamically adjust inference computation based on input difficulty.
ThinkingViT initiates inference by activating a small subset of the most
important attention heads and terminates early if predictions reach sufficient
certainty. Otherwise, it activates additional attention heads and re-evaluates
the input. At the core of ThinkingViT is our Token Recycling mechanism, which
conditions each subsequent inference stage on the embeddings from the previous
stage, enabling progressive improvement. Due to its backbone-preserving design,
ThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show
that ThinkingViT surpasses nested baselines by up to 2.0 percentage points
(p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs
on ImageNet-1K. The source code is available at
https://github.com/ds-kiel/ThinkingViT.

</details>


### [2] [A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n](https://arxiv.org/abs/2507.10864)
*Saadat Behzadi,Danial Sharifrazi,Bita Mesbahzadeh,Javad Hassannataj Joloudarid,Roohallah Alizadehsani*

Main category: cs.CV

TL;DR: 该研究提出了一种结合LOF算法和YOLO-v11n的轻量级框架，用于结直肠息肉检测，显著提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌是全球主要死因之一，及时准确的息肉检测对诊断和预防至关重要。

Method: 使用LOF算法过滤噪声数据，结合YOLO-v11n模型，通过5折交叉验证和数据增强优化模型。

Result: 模型性能显著提升，精确度95.83%，召回率91.85%，F1分数93.48%，mAP@0.5为96.48%。

Conclusion: 该方法适用于临床实时结肠镜检查，强调了数据预处理和模型效率在医学影像AI系统中的重要性。

Abstract: Objectives: Timely and accurate detection of colorectal polyps plays a
crucial role in diagnosing and preventing colorectal cancer, a major cause of
mortality worldwide. This study introduces a new, lightweight, and efficient
framework for polyp detection that combines the Local Outlier Factor (LOF)
algorithm for filtering noisy data with the YOLO-v11n deep learning model.
  Study design: An experimental study leveraging deep learning and outlier
removal techniques across multiple public datasets.
  Methods: The proposed approach was tested on five diverse and publicly
available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.
Since these datasets originally lacked bounding box annotations, we converted
their segmentation masks into suitable detection labels. To enhance the
robustness and generalizability of our model, we apply 5-fold cross-validation
and remove anomalous samples using the LOF method configured with 30 neighbors
and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a
fast and resource-efficient object detection architecture optimized for
real-time applications. We train the model using a combination of modern
augmentation strategies to improve detection accuracy under diverse conditions.
  Results: Our approach significantly improves polyp localization performance,
achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5
of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,
our model demonstrates enhanced accuracy and efficiency.
  Conclusions: These results suggest that the proposed method is well-suited
for real-time colonoscopy support in clinical settings. Overall, the study
underscores how crucial data preprocessing and model efficiency are when
designing effective AI systems for medical imaging.

</details>


### [3] [Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency](https://arxiv.org/abs/2507.10893)
*Minjong Cheon,Eunhan Goo,Su-Hyeon Shin,Muhammad Ahmed,Hyungjun Kim*

Main category: cs.CV

TL;DR: 本文介绍了一种基于CNN的轻量级全球天气预报模型KAI-a，其性能与现有Transformer模型相当，但计算需求显著降低。


<details>
  <summary>Details</summary>
Motivation: 尽管AI天气预报模型（如Transformer）取得了显著进展，但其高计算复杂性和资源需求限制了实用性。本研究旨在通过现代CNN架构解决这一问题。

Method: KAI-a采用尺度不变架构和InceptionNeXt模块，结合地球物理数据特性设计，训练于ERA5数据集，仅需单GPU12小时完成。

Result: KAI-a在中期天气预报中表现与SOTA模型相当，且能有效捕捉极端事件（如2018欧洲热浪）。

Conclusion: KAI-a展示了轻量级CNN模型在天气预报中的潜力，为资源高效AI预测提供了新方向。

Abstract: Recently, AI-based weather forecast models have achieved impressive advances.
These models have reached accuracy levels comparable to traditional NWP
systems, marking a significant milestone in data-driven weather prediction.
However, they mostly leverage Transformer-based architectures, which often
leads to high training complexity and resource demands due to the massive
parameter sizes. In this study, we introduce a modernized CNN-based model for
global weather forecasting that delivers competitive accuracy while
significantly reducing computational requirements. To present a systematic
modernization roadmap, we highlight key architectural enhancements across
multiple design scales from an earlier CNN-based approach. KAI-a incorporates a
scale-invariant architecture and InceptionNeXt-based blocks within a
geophysically-aware design, tailored to the structure of Earth system data.
Trained on the ERA5 daily dataset with 67 atmospheric variables, the model
contains about 7 million parameters and completes training in just 12 hours on
a single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the
performance of state-of-the-art models in medium-range weather forecasting,
while offering a significantly lightweight design. Furthermore, case studies on
the 2018 European heatwave and the East Asian summer monsoon demonstrate
KAI-a's robust skill in capturing extreme events, reinforcing its practical
utility.

</details>


### [4] [Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling](https://arxiv.org/abs/2507.11061)
*Hayeon Kim,Ji Ha Jang,Se Young Chun*

Main category: cs.CV

TL;DR: RoMaP是一种新型局部3D高斯编辑框架，通过3D-GALP和正则化SDS损失实现精确的部件级修改。


<details>
  <summary>Details</summary>
Motivation: 解决高斯溅射中局部3D编辑的挑战，如多视角2D分割不一致和SDS损失的模糊性。

Method: 提出3D-GALP模块生成鲁棒的3D掩码，并结合正则化SDS损失（如L1锚定损失和SLaMP编辑方法）。

Result: RoMaP在重建和生成的高斯场景中实现了最先进的局部3D编辑效果。

Conclusion: RoMaP为部件级3D高斯编辑提供了更鲁棒和灵活的解决方案。

Abstract: Recent advances in 3D neural representations and instance-level editing
models have enabled the efficient creation of high-quality 3D content. However,
achieving precise local 3D edits remains challenging, especially for Gaussian
Splatting, due to inconsistent multi-view 2D part segmentations and inherently
ambiguous nature of Score Distillation Sampling (SDS) loss. To address these
limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that
enables precise and drastic part-level modifications. First, we introduce a
robust 3D mask generation module with our 3D-Geometry Aware Label Prediction
(3D-GALP), which uses spherical harmonics (SH) coefficients to model
view-dependent label variations and soft-label property, yielding accurate and
consistent part segmentations across viewpoints. Second, we propose a
regularized SDS loss that combines the standard SDS loss with additional
regularizers. In particular, an L1 anchor loss is introduced via our Scheduled
Latent Mixing and Part (SLaMP) editing method, which generates high-quality
part-edited 2D images and confines modifications only to the target region
while preserving contextual coherence. Additional regularizers, such as
Gaussian prior removal, further improve flexibility by allowing changes beyond
the existing context, and robust 3D masking prevents unintended edits.
Experimental results demonstrate that our RoMaP achieves state-of-the-art local
3D editing on both reconstructed and generated Gaussian scenes and objects
qualitatively and quantitatively, making it possible for more robust and
flexible part-level 3D Gaussian editing.

</details>


### [5] [RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images](https://arxiv.org/abs/2507.11143)
*Lam Pham,Cam Le,Hieu Tang,Khang Truong,Truong Nguyen,Jasmin Lampert,Alexander Schindler,Martin Boyer,Son Phan*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的端到端模型，利用遥感图像自动观测滑坡事件，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 滑坡灾害频发，但传统观测方法难以覆盖大范围复杂地形，因此需要自动化解决方案。

Method: 设计了一种新型神经网络架构，用于滑坡检测和分割任务，输入为遥感图像。

Result: 在LandSlide4Sense、Bijie和Nepal数据集上，检测任务的F1分数分别为98.23和93.83，分割任务的mIoU分数为63.74和76.88。

Conclusion: 该模型在滑坡观测系统中具有实际应用潜力。

Abstract: In recent years, landslide disasters have reported frequently due to the
extreme weather events of droughts, floods , storms, or the consequence of
human activities such as deforestation, excessive exploitation of natural
resources. However, automatically observing landslide is challenging due to the
extremely large observing area and the rugged topography such as mountain or
highland. This motivates us to propose an end-to-end deep-learning-based model
which explores the remote sensing images for automatically observing landslide
events. By considering remote sensing images as the input data, we can obtain
free resource, observe large and rough terrains by time. To explore the remote
sensing images, we proposed a novel neural network architecture which is for
two tasks of landslide detection and landslide segmentation. We evaluated our
proposed model on three different benchmark datasets of LandSlide4Sense, Bijie,
and Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,
93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU
scores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,
Nepal datasets. These experimental results prove potential to integrate our
proposed model into real-life landslide observation systems.

</details>


### [6] [MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection](https://arxiv.org/abs/2507.11252)
*Guanghao Wu,Chen Xu,Hai Song,Chong Wang,Qixing Zhang*

Main category: cs.CV

TL;DR: 提出了一种生成森林火灾烟雾图像的综合框架，通过改进修复模型和引入新损失函数，提升了烟雾图像的生成质量，并用于增强烟雾检测模型性能。


<details>
  <summary>Details</summary>
Motivation: 森林火灾烟雾图像数据稀缺，现有修复模型生成烟雾图像质量不足，需要更高质量的合成数据以支持烟雾检测任务。

Method: 结合预训练分割模型和多模态模型获取烟雾掩码和图像描述，提出基于掩码和掩码图像特征引导的网络架构，并引入掩码随机差异损失函数。

Result: 生成的烟雾图像真实且多样，有效提升了森林火灾烟雾检测模型的性能。

Conclusion: 提出的框架能高质量生成烟雾图像，为烟雾检测任务提供了有效的数据支持。

Abstract: Smoke is the first visible indicator of a wildfire.With the advancement of
deep learning, image-based smoke detection has become a crucial method for
detecting and preventing forest fires. However, the scarcity of smoke image
data from forest fires is one of the significant factors hindering the
detection of forest fire smoke. Image generation models offer a promising
solution for synthesizing realistic smoke images. However, current inpainting
models exhibit limitations in generating high-quality smoke representations,
particularly manifesting as inconsistencies between synthesized smoke and
background contexts. To solve these problems, we proposed a comprehensive
framework for generating forest fire smoke images. Firstly, we employed the
pre-trained segmentation model and the multimodal model to obtain smoke masks
and image captions.Then, to address the insufficient utilization of masks and
masked images by inpainting models, we introduced a network architecture guided
by mask and masked image features. We also proposed a new loss function, the
mask random difference loss, which enhances the consistency of the generated
effects around the mask by randomly expanding and eroding the mask
edges.Finally, to generate a smoke image dataset using random masks for
subsequent detection tasks, we incorporated smoke characteristics and use a
multimodal large language model as a filtering tool to select diverse and
reasonable smoke images, thereby improving the quality of the synthetic
dataset. Experiments showed that our generated smoke images are realistic and
diverse, and effectively enhance the performance of forest fire smoke detection
models. Code is available at https://github.com/wghr123/MFGDiffusion.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise](https://arxiv.org/abs/2507.10611)
*Mengwen Ye,Yingzi Huangfu,Shujian Gao,Wei Ren,Weifan Liu,Zekuan Yu*

Main category: cs.LG

TL;DR: FedGSCA是一个针对医疗联邦学习中标签噪声问题的新框架，通过全局样本选择器和客户端自适应调整机制提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医疗联邦学习中的数据隐私保护需求与标签噪声问题（如数据异质性和不平衡）导致模型性能下降，现有方法难以应对。

Method: 提出FedGSCA框架，包括全局样本选择器（聚合噪声知识）和客户端自适应调整机制（结合伪标签生成和鲁棒损失函数）。

Result: 在真实和合成医疗数据集上测试，FedGSCA在极端和异质噪声场景下优于现有方法，显著提升模型稳定性。

Conclusion: FedGSCA有效解决了医疗联邦学习中的噪声问题，适用于实际应用场景。

Abstract: Federated Learning (FL) emerged as a solution for collaborative medical image
classification while preserving data privacy. However, label noise, which
arises from inter-institutional data variability, can cause training
instability and degrade model performance. Existing FL methods struggle with
noise heterogeneity and the imbalance in medical data. Motivated by these
challenges, we propose FedGSCA, a novel framework for enhancing robustness in
noisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates
noise knowledge from all clients, effectively addressing noise heterogeneity
and improving global model stability. Furthermore, we develop a Client Adaptive
Adjustment (CAA) mechanism that combines adaptive threshold pseudo-label
generation and Robust Credal Labeling Loss. CAA dynamically adjusts to class
distributions, ensuring the inclusion of minority samples and carefully
managing noisy labels by considering multiple plausible labels. This dual
approach mitigates the impact of noisy data and prevents overfitting during
local training, which improves the generalizability of the model. We evaluate
FedGSCA on one real-world colon slides dataset and two synthetic medical
datasets under various noise conditions, including symmetric, asymmetric,
extreme, and heterogeneous types. The results show that FedGSCA outperforms the
state-of-the-art methods, excelling in extreme and heterogeneous noise
scenarios. Moreover, FedGSCA demonstrates significant advantages in improving
model stability and handling complex noise, making it well-suited for
real-world medical federated learning scenarios.

</details>


### [8] [A Simple Baseline for Stable and Plastic Neural Networks](https://arxiv.org/abs/2507.10637)
*É. Künzel,A. Jaziri,V. Ramesh*

Main category: cs.LG

TL;DR: RDBP是一种低开销的持续学习方法，结合了ReLUDown和Decreasing Backpropagation，在Continual ImageNet上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中模型在适应新任务时遗忘旧知识的问题，平衡可塑性和稳定性。

Method: 结合ReLUDown（防止神经元休眠）和Decreasing Backpropagation（保护早期层免受灾难性更新）。

Result: 在Continual ImageNet上匹配或超越现有方法，同时降低计算成本。

Conclusion: RDBP为实际应用提供了实用解决方案，并为未来方法设定了基准。

Abstract: Continual learning in computer vision requires that models adapt to a
continuous stream of tasks without forgetting prior knowledge, yet existing
approaches often tip the balance heavily toward either plasticity or stability.
We introduce RDBP, a simple, low-overhead baseline that unites two
complementary mechanisms: ReLUDown, a lightweight activation modification that
preserves feature sensitivity while preventing neuron dormancy, and Decreasing
Backpropagation, a biologically inspired gradient-scheduling scheme that
progressively shields early layers from catastrophic updates. Evaluated on the
Continual ImageNet benchmark, RDBP matches or exceeds the plasticity and
stability of state-of-the-art methods while reducing computational cost. RDBP
thus provides both a practical solution for real-world continual learning and a
clear benchmark against which future continual learning strategies can be
measured.

</details>


### [9] [A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models](https://arxiv.org/abs/2507.10714)
*Bright Kwaku Manu,Trevor Reckell,Beckett Sterner,Petar Jevtic*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的替代框架，用于估计带有外部协变量的随机Petri网（SPN）参数，解决了传统方法在部分观测和噪声数据下的挑战。


<details>
  <summary>Details</summary>
Motivation: 随机Petri网在流行病学和系统生物学等领域广泛应用，但其参数估计在协变量依赖和部分观测条件下仍具挑战性。

Method: 使用轻量级1D卷积残差网络，通过端到端训练学习从噪声和部分观测数据中预测协变量依赖的速率函数系数。

Result: 在20%事件缺失的合成SPN中，替代模型的RMSE为0.108，且运行速度显著快于传统贝叶斯方法。

Conclusion: 数据驱动的无似然替代模型能够在复杂、部分观测的离散事件系统中实现准确、鲁棒和实时的参数恢复。

Abstract: Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for
modeling discrete-event dynamics in areas such as epidemiology and systems
biology, yet their parameter estimation remains challenging in general and in
particular when transition rates depend on external covariates and explicit
likelihoods are unavailable. We introduce a neural-surrogate
(neural-network--based approximation of the posterior distribution) framework
that predicts the coefficients of known covariate-dependent rate functions
directly from noisy, partially observed token trajectories. Our model employs a
lightweight 1D Convolutional Residual Network trained end-to-end on
Gillespie-simulated SPN realizations, learning to invert system dynamics under
realistic conditions of event dropout. During inference, Monte Carlo dropout
provides calibrated uncertainty bounds together with point estimates. On
synthetic SPNs with 20% missing events, our surrogate recovers rate-function
coefficients with an RMSE = 0.108 and substantially runs faster than
traditional Bayesian approaches. These results demonstrate that data-driven,
likelihood-free surrogates can enable accurate, robust, and real-time parameter
recovery in complex, partially observed discrete-event systems.

</details>


### [10] [Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions](https://arxiv.org/abs/2507.10809)
*Kazi Tasnim Zinat,Yun Zhou,Xiang Lyu,Yawei Wang,Zhicheng Liu,Panpan Xu*

Main category: cs.LG

TL;DR: 提出了一种新的因果框架，用于捕捉外源干预下时间过程中事件间的因果关系变化，并通过Transformer模型改进ATE估计。


<details>
  <summary>Details</summary>
Motivation: 现有因果推断方法主要关注领域内事件类型，忽略了外源干预的影响，而现实中这些干预可能显著改变因果动态。

Method: 设计了一个无偏的ATE估计器，并开发了一个基于Transformer的神经网络模型，以处理长程时间依赖和局部模式，同时整合外源干预信息。

Result: 在模拟和真实数据集上的实验表明，该方法在外源干预增强的点过程中优于基线模型。

Conclusion: 提出的框架和模型有效捕捉了外源干预下的因果动态变化，提升了ATE估计的准确性。

Abstract: Inferring causal relationships between event pairs in a temporal sequence is
applicable in many domains such as healthcare, manufacturing, and
transportation. Most existing work on causal inference primarily focuses on
event types within the designated domain, without considering the impact of
exogenous out-of-domain interventions. In real-world settings, these
out-of-domain interventions can significantly alter causal dynamics. To address
this gap, we propose a new causal framework to define average treatment effect
(ATE), beyond independent and identically distributed (i.i.d.) data in classic
Rubin's causal framework, to capture the causal relation shift between events
of temporal process under out-of-domain intervention. We design an unbiased ATE
estimator, and devise a Transformer-based neural network model to handle both
long-range temporal dependencies and local patterns while integrating
out-of-domain intervention information into process modeling. Extensive
experiments on both simulated and real-world datasets demonstrate that our
method outperforms baselines in ATE estimation and goodness-of-fit under
out-of-domain-augmented point processes.

</details>


### [11] [StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data](https://arxiv.org/abs/2507.10986)
*Tianyu Su,Zhiqiang Zou,Ali Luo,Xiao Kong,Qingyu Lu,Min Li*

Main category: cs.LG

TL;DR: 提出了一种名为StellarF的新方法，用于恒星耀斑预测，通过LoRA和Adapter技术实现高效学习，并在自建数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 恒星耀斑预测是天文研究的重要前沿，但受限于数据稀疏和缺乏专用大规模预测模型。

Method: StellarF结合了耀斑统计信息模块和历史记录模块，支持多尺度模式识别，利用LoRA和Adapter技术实现高效学习。

Result: 在Kepler和TESS光变曲线数据集上，StellarF表现优于现有方法。

Conclusion: StellarF为天体物理研究和跨学科应用提供了新的方法论框架。

Abstract: Stellar flare forecasting, a critical research frontier in astronomy, offers
profound insights into stellar activity. However, the field is constrained by
both the sparsity of recorded flare events and the absence of domain-specific
large-scale predictive models. To address these challenges, this study
introduces StellarF (Stellar Flare Forecasting), a novel large model that
leverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient
learning for stellar flare forecasting. At its core, StellarF integrates an
flare statistical information module with a historical flare record module,
enabling multi-scale pattern recognition from observational data. Extensive
experiments on our self-constructed datasets (derived from Kepler and TESS
light curves) demonstrate that StellarF achieves state-of-the-art performance
compared to existing methods. The proposed prediction paradigm establishes a
novel methodological framework for advancing astrophysical research and
cross-disciplinary applications.

</details>


### [12] [Neurosymbolic Reasoning Shortcuts under the Independence Assumption](https://arxiv.org/abs/2507.11357)
*Emile van Krieken,Pasquale Minervini,Edoardo Ponti,Antonio Vergari*

Main category: cs.LG

TL;DR: 论文探讨了神经符号（NeSy）预测器中符号概念独立性假设的局限性，指出其可能导致模型无法正确表示某些概念组合的不确定性，从而忽略推理捷径问题。


<details>
  <summary>Details</summary>
Motivation: 神经符号预测器通常假设符号概念独立以加速概率推理，但近期研究质疑这种假设是否会限制学习效果和不确定性建模能力。本文旨在明确独立性假设的实际影响。

Method: 通过形式化分析，证明符号概念独立性假设会导致模型无法表示某些概念组合的不确定性。

Result: 研究发现独立性假设使模型无法意识到推理捷径问题，即模型可能因错误原因预测正确的下游任务。

Conclusion: 独立性假设限制了神经符号预测器的不确定性建模能力，需重新评估其适用性。

Abstract: The ubiquitous independence assumption among symbolic concepts in
neurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors
use it to speed up probabilistic reasoning. Recent works like van Krieken et
al. (2024) and Marconato et al. (2024) argued that the independence assumption
can hinder learning of NeSy predictors and, more crucially, prevent them from
correctly modelling uncertainty. There is, however, scepticism in the NeSy
community around the scenarios in which the independence assumption actually
limits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle
this question by formally showing that assuming independence among symbolic
concepts entails that a model can never represent uncertainty over certain
concept combinations. Thus, the model fails to be aware of reasoning shortcuts,
i.e., the pathological behaviour of NeSy predictors that predict correct
downstream tasks but for the wrong reasons.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP协议解决了AI代理间记忆共享的短暂性问题，提供持久、安全且可语义搜索的记忆共享框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理架构存在记忆短暂性问题，限制了跨会话和代理间的协作与知识共享。

Method: SAMEP采用分布式记忆存储库，结合向量语义搜索、加密访问控制（AES-256-GCM）和标准化API。

Result: 实验显示，SAMEP减少了73%冗余计算，提升89%上下文相关性，并完全符合监管要求。

Conclusion: SAMEP为持久协作的AI代理生态系统提供了安全隐私保障的新范式。

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [14] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
*Asim H. Gazi,Bhanu T. Gullapalli,Daiqi Gao,Benjamin M. Marlin,Vivek Shetty,Susan A. Murphy*

Main category: cs.AI

TL;DR: 论文提出SigmaScheduling方法，动态安排决策点以提高移动健康干预的及时性。


<details>
  <summary>Details</summary>
Motivation: 当前固定间隔的决策点安排对习惯性行为干预效果不佳，尤其是对作息不规律的个体。

Method: 提出SigmaScheduling方法，根据行为时间预测的不确定性动态调整决策点。

Result: 在68名参与者的真实数据测试中，SigmaScheduling在70%以上的案例中成功提前安排决策点。

Conclusion: SigmaScheduling能提升精准移动健康干预的效果，尤其适用于时间敏感的习惯性行为。

Abstract: Timely decision making is critical to the effectiveness of mobile health
(mHealth) interventions. At predefined timepoints called "decision points,"
intelligent mHealth systems such as just-in-time adaptive interventions
(JITAIs) estimate an individual's biobehavioral context from sensor or survey
data and determine whether and how to intervene. For interventions targeting
habitual behavior (e.g., oral hygiene), effectiveness often hinges on
delivering support shortly before the target behavior is likely to occur.
Current practice schedules decision points at a fixed interval (e.g., one hour)
before user-provided behavior times, and the fixed interval is kept the same
for all individuals. However, this one-size-fits-all approach performs poorly
for individuals with irregular routines, often scheduling decision points after
the target behavior has already occurred, rendering interventions ineffective.
In this paper, we propose SigmaScheduling, a method to dynamically schedule
decision points based on uncertainty in predicted behavior times. When behavior
timing is more predictable, SigmaScheduling schedules decision points closer to
the predicted behavior time; when timing is less certain, SigmaScheduling
schedules decision points earlier, increasing the likelihood of timely
intervention. We evaluated SigmaScheduling using real-world data from 68
participants in a 10-week trial of Oralytics, a JITAI designed to improve daily
toothbrushing. SigmaScheduling increased the likelihood that decision points
preceded brushing events in at least 70% of cases, preserving opportunities to
intervene and impact behavior. Our results indicate that SigmaScheduling can
advance precision mHealth, particularly for JITAIs targeting time-sensitive,
habitual behaviors such as oral hygiene or dietary habits.

</details>


### [15] [DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion](https://arxiv.org/abs/2507.11229)
*Jin Li,Zezhong Ding,Xike Xie*

Main category: cs.AI

TL;DR: DuetGraph提出了一种双路径全局-局部融合的粗到细知识图谱推理机制，解决了现有方法中分数过平滑的问题，显著提升了推理质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱推理方法在处理全局和局部信息时容易导致分数过平滑，模糊正确答案与错误答案的区分，影响推理效果。

Method: DuetGraph通过分离局部（消息传递）和全局（注意力）信息的处理路径，避免相互干扰，并采用粗到细优化策略，将实体分为高、低分集以缩小候选空间。

Result: 实验表明，DuetGraph在推理质量上提升了8.7%，训练效率提高了1.8倍，达到了最先进水平。

Conclusion: DuetGraph通过双路径融合和粗到细优化，有效解决了分数过平滑问题，显著提升了知识图谱推理的性能和效率。

Abstract: Knowledge graphs (KGs) are vital for enabling knowledge reasoning across
various domains. Recent KG reasoning methods that integrate both global and
local information have achieved promising results. However, existing methods
often suffer from score over-smoothing, which blurs the distinction between
correct and incorrect answers and hinders reasoning effectiveness. To address
this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with
dual-pathway global-local fusion. DuetGraph tackles over-smoothing by
segregating -- rather than stacking -- the processing of local (via message
passing) and global (via attention) information into two distinct pathways,
preventing mutual interference and preserving representational discrimination.
In addition, DuetGraph introduces a coarse-to-fine optimization, which
partitions entities into high- and low-score subsets. This strategy narrows the
candidate space and sharpens the score gap between the two subsets, which
alleviates over-smoothing and enhances inference quality. Extensive experiments
on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)
performance, with up to an 8.7% improvement in reasoning quality and a
1.8$\times$ acceleration in training efficiency.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training](https://arxiv.org/abs/2507.10920)
*Seungho Choi*

Main category: cs.CL

TL;DR: HanjaBridge是一种通过注入汉字意义解决韩语语义模糊的新方法，显著提升了韩语理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决韩语中同音异义词在韩文脚本中难以区分的问题，提升低资源语言模型的性能。

Method: 提出HanjaBridge技术，在持续预训练框架中为同音词提供所有可能的汉字候选，结合知识蒸馏避免灾难性遗忘。

Result: 在KoBALT基准上相对提升21%，并观察到中韩跨语言迁移的积极效果。

Conclusion: HanjaBridge有效提升韩语理解能力，且无需推理时额外成本。

Abstract: Large language models (LLMs) often show poor performance in low-resource
languages like Korean, partly due to unique linguistic challenges such as
homophonous Sino-Korean words that are indistinguishable in Hangul script. To
address this semantic ambiguity, we propose HanjaBridge, a novel
meaning-injection technique integrated into a continual pre-training (CPT)
framework. Instead of deterministically mapping a word to a single Hanja
(Chinese character), HanjaBridge presents the model with all possible Hanja
candidates for a given homograph, encouraging the model to learn contextual
disambiguation. This process is paired with token-level knowledge distillation
to prevent catastrophic forgetting. Experimental results show that HanjaBridge
significantly improves Korean language understanding, achieving a 21\% relative
improvement on the KoBALT benchmark. Notably, by reinforcing semantic alignment
between Korean and Chinese through shared Hanja, we observe a strong positive
cross-lingual transfer. Furthermore, these gains persist even when Hanja
augmentation is omitted at inference time, ensuring practical efficiency with
no additional run-time cost.

</details>


### [17] [LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP](https://arxiv.org/abs/2507.11052)
*Haowei Yang,Ziyu Shen,Junli Shao,Luyao Men,Xinyue Han,Jing Dong*

Main category: cs.CL

TL;DR: 该研究提出了一种基于LLM增强的临床NLP流程，用于从非结构化临床笔记中提取心血管疾病的早期指标，并通过领域适应和提示工程优化性能。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病的及时识别和准确风险分层对降低全球死亡率至关重要，而现有预测模型主要依赖结构化数据，忽略了非结构化临床笔记中的早期指标。

Method: 采用领域适应的大型语言模型（LLM），结合心血管特定微调、基于提示的推理和实体感知推理，从自由文本报告中提取症状并进行上下文关联。

Result: 在MIMIC-III和CARDIO-NLP数据集上评估，显示在精确度、召回率、F1分数和AUROC方面性能提升，临床相关性高（kappa=0.82）。

Conclusion: 该研究展示了LLM在临床决策支持系统中的潜力，能够通过优化早期预警系统，将患者叙述转化为可操作的风险评估。

Abstract: Timely identification and accurate risk stratification of cardiovascular
disease (CVD) remain essential for reducing global mortality. While existing
prediction models primarily leverage structured data, unstructured clinical
notes contain valuable early indicators. This study introduces a novel
LLM-augmented clinical NLP pipeline that employs domain-adapted large language
models for symptom extraction, contextual reasoning, and correlation from
free-text reports. Our approach integrates cardiovascular-specific fine-tuning,
prompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III
and CARDIO-NLP datasets demonstrate improved performance in precision, recall,
F1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by
cardiologists. Challenges such as contextual hallucination, which occurs when
plausible information contracts with provided source, and temporal ambiguity,
which is related with models struggling with chronological ordering of events
are addressed using prompt engineering and hybrid rule-based verification. This
work underscores the potential of LLMs in clinical decision support systems
(CDSS), advancing early warning systems and enhancing the translation of
patient narratives into actionable risk assessments.

</details>


### [18] [Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification](https://arxiv.org/abs/2507.11086)
*Andres Azqueta-Gavaldón,Joaquin Ramos Cosgrove*

Main category: cs.CL

TL;DR: 论文探讨了在跨境金融活动中使用大型语言模型（LLMs）改进实体匹配的准确性，相比传统方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 跨境金融活动的增加需要更准确的实体识别，传统方法在语言和语义处理上存在不足。

Method: 比较了传统算法（如Jaccard、余弦、Levenshtein距离）、Hugging Face的LLMs和接口型LLMs（如Microsoft Copilot、Qwen 2.5）在65个葡萄牙公司案例中的表现。

Result: 传统方法准确率超92%，但假阳性率高（20-40%）；接口型LLMs准确率超93%，F1分数超96%，假阳性率更低（40-80%）。

Conclusion: LLMs在实体匹配中表现优于传统方法，尤其在处理语言和语义复杂性方面更具优势。

Abstract: The growing prevalence of cross-border financial activities in global markets
has underscored the necessity of accurately identifying and classifying foreign
entities. This practice is essential within the Spanish financial system for
ensuring robust risk management, regulatory adherence, and the prevention of
financial misconduct. This process involves a labor-intensive entity-matching
task, where entities need to be validated against available reference sources.
Challenges arise from linguistic variations, special characters, outdated
names, and changes in legal forms, complicating traditional matching algorithms
like Jaccard, cosine, and Levenshtein distances. These methods struggle with
contextual nuances and semantic relationships, leading to mismatches. To
address these limitations, we explore Large Language Models (LLMs) as a
flexible alternative. LLMs leverage extensive training to interpret context,
handle abbreviations, and adapt to legal transitions. We evaluate traditional
methods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft
Copilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.
Results show traditional methods achieve accuracies over 92% but suffer high
false positive rates (20-40%). Interface-based LLMs outperform, achieving
accuracies above 93%, F1 scores exceeding 96%, and lower false positives
(40-80%).

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [All Eyes, no IMU: Learning Flight Attitude from Vision Alone](https://arxiv.org/abs/2507.11302)
*Jesse J. Hagenaars,Stein Stroobants,Sander M. Bohte,Guido C. H. E. De Croon*

Main category: cs.RO

TL;DR: 该论文提出了一种仅依赖视觉的飞行控制方法，使用事件摄像头和神经网络替代传统惯性传感器，实现了无人机的稳定飞行。


<details>
  <summary>Details</summary>
Motivation: 许多飞行生物依赖视觉进行姿态控制，而无人机通常依赖惯性传感器。本文旨在探索仅通过视觉实现飞行控制的可能性。

Method: 使用向下事件摄像头和递归卷积神经网络，通过监督学习训练，从事件流中估计姿态和旋转速率。

Result: 实验证明该方法可以替代传统惯性测量单元，且在不同环境中具有一定的泛化能力。

Conclusion: 视觉飞行控制是实现昆虫级自主飞行机器人的有前景的方法。

Abstract: Vision is an essential part of attitude control for many flying animals, some
of which have no dedicated sense of gravity. Flying robots, on the other hand,
typically depend heavily on accelerometers and gyroscopes for attitude
stabilization. In this work, we present the first vision-only approach to
flight control for use in generic environments. We show that a quadrotor drone
equipped with a downward-facing event camera can estimate its attitude and
rotation rate from just the event stream, enabling flight control without
inertial sensors. Our approach uses a small recurrent convolutional neural
network trained through supervised learning. Real-world flight tests
demonstrate that our combination of event camera and low-latency neural network
is capable of replacing the inertial measurement unit in a traditional flight
control loop. Furthermore, we investigate the network's generalization across
different environments, and the impact of memory and different fields of view.
While networks with memory and access to horizon-like visual cues achieve best
performance, variants with a narrower field of view achieve better relative
generalization. Our work showcases vision-only flight control as a promising
candidate for enabling autonomous, insect-scale flying robots.

</details>
