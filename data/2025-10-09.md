<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation](https://arxiv.org/abs/2510.06231)
*Mingzhe Zheng,Dingjie Song,Guanyu Zhou,Jun You,Jiahao Zhan,Xuran Ma,Xinyuan Song,Ser-Nam Lim,Qifeng Chen,Harry Yang*

Main category: cs.CV

TL;DR: 该论文提出了CML-Bench基准和CML-Instruction提示策略，用于评估和改进LLMs在生成电影剧本时的质量，重点关注对话连贯性、角色一致性和情节合理性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs能够生成结构良好的文本，但在创作需要细腻叙事和情感深度的电影剧本时，往往缺乏电影的灵魂。

Method: 首先构建了CML数据集，分析真实剧本的内在连续性结构，提出三个关键评估维度；然后开发CML-Bench量化指标和CML-Instruction提示策略。

Result: CML-Bench能有效区分人类创作和LLMs生成的剧本质量，使用CML-Instruction指导的LLMs能生成更高质量的剧本，结果与人类偏好一致。

Conclusion: 提出的基准和提示策略能有效评估和改进LLMs在电影剧本生成方面的能力，填补了现有评估方法的空白。

Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in
generating highly structured texts. However, while exhibiting a high degree of
structural organization, movie scripts demand an additional layer of nuanced
storytelling and emotional depth-the 'soul' of compelling cinema-that LLMs
often fail to capture. To investigate this deficiency, we first curated
CML-Dataset, a dataset comprising (summary, content) pairs for Cinematic Markup
Language (CML), where 'content' consists of segments from esteemed,
high-quality movie scripts and 'summary' is a concise description of the
content. Through an in-depth analysis of the intrinsic multi-shot continuity
and narrative structures within these authentic scripts, we identified three
pivotal dimensions for quality assessment: Dialogue Coherence (DC), Character
Consistency (CC), and Plot Reasonableness (PR). Informed by these findings, we
propose the CML-Bench, featuring quantitative metrics across these dimensions.
CML-Bench effectively assigns high scores to well-crafted, human-written
scripts while concurrently pinpointing the weaknesses in screenplays generated
by LLMs. To further validate our benchmark, we introduce CML-Instruction, a
prompting strategy with detailed instructions on character dialogue and event
logic, to guide LLMs to generate more structured and cinematically sound
scripts. Extensive experiments validate the effectiveness of our benchmark and
demonstrate that LLMs guided by CML-Instruction generate higher-quality
screenplays, with results aligned with human preferences.

</details>


### [2] [Enhanced Self-Distillation Framework for Efficient Spiking Neural Network Training](https://arxiv.org/abs/2510.06254)
*Xiaochen Zhao,Chengting Yu,Kairong Yu,Lei Liu,Aili Wang*

Main category: cs.CV

TL;DR: 提出了一种增强的自蒸馏框架，结合基于速率的反向传播，通过将SNN中间层的发放率投影到轻量级ANN分支上，利用高质量自生成知识优化子结构，减少训练复杂度并实现高性能SNN训练。


<details>
  <summary>Details</summary>
Motivation: 传统SNN训练方法基于替代梯度和BPTT，不仅性能落后于ANN，还产生随时间维度线性增长的计算和内存开销。为了在有限计算资源下实现高性能SNN训练，需要新的训练方法。

Method: 增强的自蒸馏框架，将SNN中间层发放率投影到轻量级ANN分支，使用高质量自生成知识通过ANN路径优化子结构。通过将教师信号解耦为可靠和不可靠组件，确保仅使用可靠知识指导模型优化。

Result: 在CIFAR-10、CIFAR-100、CIFAR10-DVS和ImageNet上的广泛实验表明，该方法在减少训练复杂度的同时实现了高性能SNN训练。

Conclusion: 所提出的增强自蒸馏框架能够有效降低SNN训练的计算复杂度，同时保持高性能，为资源受限环境下的SNN训练提供了可行解决方案。

Abstract: Spiking Neural Networks (SNNs) exhibit exceptional energy efficiency on
neuromorphic hardware due to their sparse activation patterns. However,
conventional training methods based on surrogate gradients and Backpropagation
Through Time (BPTT) not only lag behind Artificial Neural Networks (ANNs) in
performance, but also incur significant computational and memory overheads that
grow linearly with the temporal dimension. To enable high-performance SNN
training under limited computational resources, we propose an enhanced
self-distillation framework, jointly optimized with rate-based backpropagation.
Specifically, the firing rates of intermediate SNN layers are projected onto
lightweight ANN branches, and high-quality knowledge generated by the model
itself is used to optimize substructures through the ANN pathways. Unlike
traditional self-distillation paradigms, we observe that low-quality
self-generated knowledge may hinder convergence. To address this, we decouple
the teacher signal into reliable and unreliable components, ensuring that only
reliable knowledge is used to guide the optimization of the model. Extensive
experiments on CIFAR-10, CIFAR-100, CIFAR10-DVS, and ImageNet demonstrate that
our method reduces training complexity while achieving high-performance SNN
training. Our code is available at
https://github.com/Intelli-Chip-Lab/enhanced-self-distillation-framework-for-snn.

</details>


### [3] [Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis](https://arxiv.org/abs/2510.06260)
*Sher Khan,Raz Muhammad,Adil Hussain,Muhammad Sajjad,Muhammad Rashid*

Main category: cs.CV

TL;DR: 提出一个统一的皮肤病AI诊断框架，通过异构神经网络集成和语言模型集成，提高诊断可靠性并改善医患沟通。


<details>
  <summary>Details</summary>
Motivation: 解决当前皮肤病诊断中存在的观察者间差异、访问不平等问题，以及现有AI系统的架构同质性、数据集偏见和碎片化方法等局限性。

Method: 1. 使用架构多样化的卷积神经网络异构集成，提供互补诊断视角，内置不确定性机制标记不一致病例；2. 将大语言模型能力直接嵌入诊断工作流，将分类输出转化为临床评估。

Result: 开发了一个能够生成结构化报告的系统，包含精确病变特征描述、可理解的诊断推理和可操作的监测指导，同时满足医疗文档要求和患者教育需求。

Conclusion: 该框架通过同时解决诊断可靠性和沟通障碍，弥合了阻碍先前AI系统实现临床影响的关键转化差距，代表了可部署皮肤病AI的重要进展。

Abstract: Cutaneous malignancies demand early detection for favorable outcomes, yet
current diagnostics suffer from inter-observer variability and access
disparities. While AI shows promise, existing dermatological systems are
limited by homogeneous architectures, dataset biases across skin tones, and
fragmented approaches that treat natural language processing as separate
post-hoc explanations rather than integral to clinical decision-making. We
introduce a unified framework that fundamentally reimagines AI integration for
dermatological diagnostics through two synergistic innovations. First, a
purposefully heterogeneous ensemble of architecturally diverse convolutional
neural networks provides complementary diagnostic perspectives, with an
intrinsic uncertainty mechanism flagging discordant cases for specialist review
-- mimicking clinical best practices. Second, we embed large language model
capabilities directly into the diagnostic workflow, transforming classification
outputs into clinically meaningful assessments that simultaneously fulfill
medical documentation requirements and deliver patient-centered education. This
seamless integration generates structured reports featuring precise lesion
characterization, accessible diagnostic reasoning, and actionable monitoring
guidance -- empowering patients to recognize early warning signs between
visits. By addressing both diagnostic reliability and communication barriers
within a single cohesive system, our approach bridges the critical
translational gap that has prevented previous AI implementations from achieving
clinical impact. The framework represents a significant advancement toward
deployable dermatological AI that enhances diagnostic precision while actively
supporting the continuum of care from initial detection through patient
education, ultimately improving early intervention rates for skin lesions.

</details>


### [4] [Vision Transformer for Transient Noise Classification](https://arxiv.org/abs/2510.06273)
*Divyansh Srivastava,Andrzej Niedzielski*

Main category: cs.CV

TL;DR: 使用Vision Transformer模型对LIGO数据中的瞬态噪声进行分类，将22个现有类别和O3a运行中的2个新类别进行分类，达到92.26%的分类效率。


<details>
  <summary>Details</summary>
Motivation: LIGO数据中的瞬态噪声（glitches）阻碍了引力波的检测，随着O3运行的进行，需要训练新模型来有效分类新增的噪声类别。

Method: 在包含Gravity Spy数据集和LIGO O3a运行中两个新增类别的组合数据集上，训练预训练的Vision Transformer（ViT-B/32）模型。

Result: 实现了92.26%的分类效率，表明Vision Transformer在有效区分瞬态噪声方面具有潜力。

Conclusion: Vision Transformer模型能够提高引力波检测的准确性，通过有效区分瞬态噪声来改善检测性能。

Abstract: Transient noise (glitches) in LIGO data hinders the detection of
gravitational waves (GW). The Gravity Spy project has categorized these noise
events into various classes. With the O3 run, there is the inclusion of two
additional noise classes and thus a need to train new models for effective
classification. We aim to classify glitches in LIGO data into 22 existing
classes from the first run plus 2 additional noise classes from O3a using the
Vision Transformer (ViT) model. We train a pre-trained Vision Transformer
(ViT-B/32) model on a combined dataset consisting of the Gravity Spy dataset
with the additional two classes from the LIGO O3a run. We achieve a
classification efficiency of 92.26%, demonstrating the potential of Vision
Transformer to improve the accuracy of gravitational wave detection by
effectively distinguishing transient noise.
  Key words: gravitational waves --vision transformer --machine learning

</details>


### [5] [Road Surface Condition Detection with Machine Learning using New York State Department of Transportation Camera Images and Weather Forecast Data](https://arxiv.org/abs/2510.06440)
*Carly Sutter,Kara J. Sulia,Nick P. Bassill,Christopher D. Wirz,Christopher D. Thorncroft,Jay C. Rothenberger,Vanessa Przybylo,Mariana G. Cains,Jacob Radford,David Aaron Evans*

Main category: cs.CV

TL;DR: 使用卷积神经网络和随机森林结合摄像头图像和天气数据，自动分类道路表面状况，为纽约州交通部门提供决策支持。


<details>
  <summary>Details</summary>
Motivation: 纽约州交通部门目前通过人工驾驶观察和实时摄像头评估道路状况，这些任务劳动密集但又是冬季天气事件中做出关键运营决策所必需的。机器学习模型可以提供额外支持。

Method: 在约22,000张人工标记的道路摄像头图像上训练卷积神经网络和随机森林模型，将图像分类为六种道路表面状况：严重积雪、积雪、潮湿、干燥、能见度差或被遮挡。

Result: 模型在完全未见过的摄像头上实现了81.5%的准确率，优先考虑模型的泛化能力以满足NYSDOT决策者的运营需求。

Conclusion: 机器学习模型能够有效自动分类道路表面状况，为交通部门的冬季运营决策提供可靠支持。

Abstract: The New York State Department of Transportation (NYSDOT) has a network of
roadside traffic cameras that are used by both the NYSDOT and the public to
observe road conditions. The NYSDOT evaluates road conditions by driving on
roads and observing live cameras, tasks which are labor-intensive but necessary
for making critical operational decisions during winter weather events.
However, machine learning models can provide additional support for the NYSDOT
by automatically classifying current road conditions across the state. In this
study, convolutional neural networks and random forests are trained on camera
images and weather data to predict road surface conditions. Models are trained
on a hand-labeled dataset of ~22,000 camera images, each classified by human
labelers into one of six road surface conditions: severe snow, snow, wet, dry,
poor visibility, or obstructed. Model generalizability is prioritized to meet
the operational needs of the NYSDOT decision makers, and the weather-related
road surface condition model in this study achieves an accuracy of 81.5% on
completely unseen cameras.

</details>


### [6] [LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval](https://arxiv.org/abs/2510.06512)
*Avishree Khare,Hideki Okamoto,Bardh Hoxha,Georgios Fainekos,Rajeev Alur*

Main category: cs.CV

TL;DR: 提出LogSTOP评分函数，用于计算时间属性在序列上的得分，基于线性时序逻辑，在视频和音频分析中优于大型视觉/音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 将YOLO、HuBERT等神经模型检测的局部属性得分提升到时间属性层面，支持下游应用如查询匹配和排序检索。

Method: 提出LogSTOP评分函数，能高效计算线性时序逻辑表示的时间属性得分，处理可能含有噪声的局部属性预测器。

Result: 在视频对象和语音情感的时间属性查询匹配中，LogSTOP比大型视觉/音频语言模型和其他时序逻辑基线至少提升16%；在视频对象和动作的排序检索中，比零样本文本到视频检索基线在平均精度和召回率上分别提升至少19%和16%。

Conclusion: LogSTOP能有效提升时间属性在序列上的评分性能，在多种应用中显著优于现有方法。

Abstract: Neural models such as YOLO and HuBERT can be used to detect local properties
such as objects ("car") and emotions ("angry") in individual frames of videos
and audio clips respectively. The likelihood of these detections is indicated
by scores in [0, 1]. Lifting these scores to temporal properties over sequences
can be useful for several downstream applications such as query matching (e.g.,
"does the speaker eventually sound happy in this audio clip?"), and ranked
retrieval (e.g., "retrieve top 5 videos with a 10 second scene where a car is
detected until a pedestrian is detected"). In this work, we formalize this
problem of assigning Scores for TempOral Properties (STOPs) over sequences,
given potentially noisy score predictors for local properties. We then propose
a scoring function called LogSTOP that can efficiently compute these scores for
temporal properties represented in Linear Temporal Logic. Empirically, LogSTOP,
with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and
other Temporal Logic-based baselines by at least 16% on query matching with
temporal properties over objects-in-videos and emotions-in-speech respectively.
Similarly, on ranked retrieval with temporal properties over objects and
actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a
19% and 16% increase in mean average precision and recall over zero-shot
text-to-video retrieval baselines respectively.

</details>


### [7] [Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking](https://arxiv.org/abs/2510.06820)
*Mitchell Keren Taraday,Shahaf Wagner,Chaim Baskin*

Main category: cs.CV

TL;DR: EDJE是一种高效的判别性联合编码器，通过预计算视觉token并使用轻量级注意力适配器压缩，显著降低了多模态检索的存储和计算成本，同时保持强大的检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态检索主要依赖CLIP等嵌入模型进行向量搜索，但缺乏类似文本检索中的联合编码器重排序器。现有联合编码器如BLIP由于昂贵的视觉特征提取阶段而存在瓶颈，无法在实际规模部署。

Method: EDJE预计算视觉token离线，通过轻量级注意力适配器压缩，在线推理时仅运行紧凑的联合编码器处理少量视觉token和文本。

Result: EDJE处理速度达50k图像-文本对/秒，每张图像仅需49kB磁盘存储，在Flickr（零样本）和COCO（微调）检索任务上达到先进水平。

Conclusion: EDJE在保持强大检索性能的同时大幅降低了存储和在线计算需求，实现了高吞吐量推理，为多模态检索提供了实用的解决方案。

Abstract: Multimodal retrieval still leans on embedding-based models like CLIP for fast
vector search over pre-computed image embeddings. Yet, unlike text retrieval,
where joint-encoder rerankers are standard, comparable vision--language
rerankers are largely absent. We find that seminal joint encoders such as BLIP
are severely bottlenecked by an expensive visual feature-extraction stage,
preventing practical deployment at scale. Motivated by this bottleneck, we
introduce EDJE, an Efficient Discriminative Joint Encoder that precomputes
vision tokens offline and compresses them via a lightweight attention-based
adapter, so online inference runs only a compact joint encoder over a small set
of visual tokens plus the text. EDJE preserves strong retrieval performance
while drastically reducing storage and online compute, enabling high-throughput
inference. Specifically, EDJE processes 50k image--text pairs/second while
requiring 49kB of disk storage per image, matching prior art on Flickr
(zero-shot) and COCO (fine-tuned) retrieval. The implementation and checkpoints
will be made publicly available shortly.

</details>


### [8] [StyleKeeper: Prevent Content Leakage using Negative Visual Query Guidance](https://arxiv.org/abs/2510.06827)
*Jaeseok Jeong,Junho Kim,Gayoung Lee,Yunjey Choi,Youngjung Uh*

Main category: cs.CV

TL;DR: 提出了一种名为负视觉查询指导（NVQG）的新方法，通过扩展无分类器引导并引入负分数来减少文本到图像生成中的内容泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉提示方法在控制风格和内容时经常出现内容泄漏问题，即视觉风格提示中不希望的元素被意外转移到生成图像中。

Method: 1）扩展无分类器引导（CFG）以利用交换自注意力；2）提出负视觉查询指导（NVQG），通过故意模拟内容泄漏场景来减少不需要内容的传输。

Result: 该方法在各种风格和文本提示的广泛评估中表现出优于现有方法的性能，能够准确反映参考图像的风格，同时确保生成图像与文本提示匹配。

Conclusion: NVQG是一种简单而有效的方法，显著减少了内容泄漏问题，为使用真实图像作为视觉风格提示提供了解决方案。

Abstract: In the domain of text-to-image generation, diffusion models have emerged as
powerful tools. Recently, studies on visual prompting, where images are used as
prompts, have enabled more precise control over style and content. However,
existing methods often suffer from content leakage, where undesired elements of
the visual style prompt are transferred along with the intended style. To
address this issue, we 1) extend classifier-free guidance (CFG) to utilize
swapping self-attention and propose 2) negative visual query guidance (NVQG) to
reduce the transfer of unwanted contents. NVQG employs negative score by
intentionally simulating content leakage scenarios that swap queries instead of
key and values of self-attention layers from visual style prompts. This simple
yet effective method significantly reduces content leakage. Furthermore, we
provide careful solutions for using a real image as visual style prompts.
Through extensive evaluation across various styles and text prompts, our method
demonstrates superiority over existing approaches, reflecting the style of the
references, and ensuring that resulting images match the text prompts. Our code
is available \href{https://github.com/naver-ai/StyleKeeper}{here}.

</details>


### [9] [Lattice-allocated Real-time Line Segment Feature Detection and Tracking Using Only an Event-based Camera](https://arxiv.org/abs/2510.06829)
*Mikihiro Ikura,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi*

Main category: cs.CV

TL;DR: 提出了一种仅使用高分辨率事件相机实时检测和跟踪线段的方法，通过速度不变事件表示、基于拟合得分的线段检测和端点扰动的线段跟踪，在实时性和精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机能有效捕捉人造环境的几何特征，但现有方法要么依赖额外的帧相机，要么难以处理高事件率。本研究旨在仅使用现代高分辨率事件相机实现实时线段检测和跟踪。

Method: 采用格点分配流水线，包括：(i)速度不变事件表示，(ii)基于拟合得分的线段检测，(iii)通过端点扰动进行线段跟踪。

Result: 在专门记录的数据集和公共数据集上的评估显示，该方法具有实时性能，且比最先进的事件专用和事件-帧混合基线方法精度更高。

Conclusion: 该方法实现了完全独立的事件相机操作，能够在真实世界环境中实时运行。

Abstract: Line segment extraction is effective for capturing geometric features of
human-made environments. Event-based cameras, which asynchronously respond to
contrast changes along edges, enable efficient extraction by reducing redundant
data. However, recent methods often rely on additional frame cameras or
struggle with high event rates. This research addresses real-time line segment
detection and tracking using only a modern, high-resolution (i.e., high event
rate) event-based camera. Our lattice-allocated pipeline consists of (i)
velocity-invariant event representation, (ii) line segment detection based on a
fitting score, (iii) and line segment tracking by perturbating endpoints.
Evaluation using ad-hoc recorded dataset and public datasets demonstrates
real-time performance and higher accuracy compared to state-of-the-art
event-only and event-frame hybrid baselines, enabling fully stand-alone event
camera operation in real-world settings.

</details>


### [10] [Online Generic Event Boundary Detection](https://arxiv.org/abs/2510.06855)
*Hyungrok Jung,Daneul Kim,Seunggyun Lim,Jeany Son,Jonghyun Choi*

Main category: cs.CV

TL;DR: 提出在线通用事件边界检测任务(On-GEBD)，开发Estimator框架实时检测流媒体视频中的事件边界，无需未来帧信息。


<details>
  <summary>Details</summary>
Motivation: 现有GEBD方法需要处理完整视频帧，而人类能够在线实时处理数据。为弥合这一差距，引入在线检测任务。

Method: 基于事件分割理论，提出Estimator框架，包含一致性事件预测器(CEA)和在线边界判别器(OBD)。CEA基于历史帧预测未来帧，OBD测量预测误差并通过统计测试自适应调整阈值。

Result: 在Kinetics-GEBD和TAPOS数据集上，Estimator优于所有在线视频理解基线方法，性能与离线GEBD方法相当。

Conclusion: 提出的On-GEBD任务和Estimator框架成功实现了实时事件边界检测，填补了现有方法的空白。

Abstract: Generic Event Boundary Detection (GEBD) aims to interpret long-form videos
through the lens of human perception. However, current GEBD methods require
processing complete video frames to make predictions, unlike humans processing
data online and in real-time. To bridge this gap, we introduce a new task,
Online Generic Event Boundary Detection (On-GEBD), aiming to detect boundaries
of generic events immediately in streaming videos. This task faces unique
challenges of identifying subtle, taxonomy-free event changes in real-time,
without the access to future frames. To tackle these challenges, we propose a
novel On-GEBD framework, Estimator, inspired by Event Segmentation Theory (EST)
which explains how humans segment ongoing activity into events by leveraging
the discrepancies between predicted and actual information. Our framework
consists of two key components: the Consistent Event Anticipator (CEA), and the
Online Boundary Discriminator (OBD). Specifically, the CEA generates a
prediction of the future frame reflecting current event dynamics based solely
on prior frames. Then, the OBD measures the prediction error and adaptively
adjusts the threshold using statistical tests on past errors to capture
diverse, subtle event transitions. Experimental results demonstrate that
Estimator outperforms all baselines adapted from recent online video
understanding models and achieves performance comparable to prior offline-GEBD
methods on the Kinetics-GEBD and TAPOS datasets.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [RareGraph-Synth: Knowledge-Guided Diffusion Models for Generating Privacy-Preserving Synthetic Patient Trajectories in Ultra-Rare Diseases](https://arxiv.org/abs/2510.06267)
*Khartik Uppalapati,Shakeel Abdulkareem,Bora Yimenicioglu*

Main category: cs.LG

TL;DR: RareGraph-Synth是一个基于知识图谱的连续时间扩散框架，用于生成真实且保护隐私的超罕见疾病电子健康记录轨迹。该方法通过整合多个生物医学知识资源，在扩散过程中引导生成生物可信的数据，同时保持隐私保护。


<details>
  <summary>Details</summary>
Motivation: 为超罕见疾病研究生成合成电子健康记录数据，解决真实数据稀缺和隐私保护的问题，同时确保生成数据的生物可信度。

Method: 整合五个公共资源构建异质知识图谱（约800万条边），使用元路径分数调节扩散模型的前向随机微分方程中的噪声调度，引导生成生物可信的实验室-药物-不良事件共现模式。

Result: 在模拟超罕见疾病队列中，相比无引导扩散基线降低分类最大均值差异40%，相比GAN方法降低60%以上，同时保持下游预测效用。黑盒成员推理攻击评估显示AUROC约0.53，远低于安全发布阈值0.55。

Conclusion: 将生物医学知识图谱直接整合到扩散噪声调度中可以同时提高保真度和隐私保护，为罕见疾病研究实现更安全的数据共享。

Abstract: We propose RareGraph-Synth, a knowledge-guided, continuous-time diffusion
framework that generates realistic yet privacy-preserving synthetic
electronic-health-record (EHR) trajectories for ultra-rare diseases.
RareGraph-Synth unifies five public resources: Orphanet/Orphadata, the Human
Phenotype Ontology (HPO), the GARD rare-disease KG, PrimeKG, and the FDA
Adverse Event Reporting System (FAERS) into a heterogeneous knowledge graph
comprising approximately 8 M typed edges. Meta-path scores extracted from this
8-million-edge KG modulate the per-token noise schedule in the forward
stochastic differential equation, steering generation toward biologically
plausible lab-medication-adverse-event co-occurrences while retaining
score-based diffusion model stability. The reverse denoiser then produces
timestamped sequences of lab-code, medication-code, and adverse-event-flag
triples that contain no protected health information. On simulated
ultra-rare-disease cohorts, RareGraph-Synth lowers categorical Maximum Mean
Discrepancy by 40 percent relative to an unguided diffusion baseline and by
greater than 60 percent versus GAN counterparts, without sacrificing downstream
predictive utility. A black-box membership-inference evaluation using the
DOMIAS attacker yields AUROC approximately 0.53, well below the 0.55
safe-release threshold and substantially better than the approximately 0.61
plus or minus 0.03 observed for non-KG baselines, demonstrating strong
resistance to re-identification. These results suggest that integrating
biomedical knowledge graphs directly into diffusion noise schedules can
simultaneously enhance fidelity and privacy, enabling safer data sharing for
rare-disease research.

</details>


### [12] [BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression](https://arxiv.org/abs/2510.06293)
*Cristian Meo,Varun Sarathchandran,Avijit Majhi,Shao Hung,Carlo Saccardi,Ruben Imhoff,Roberto Deidda,Remko Uijlenhoet,Justin Dauwels*

Main category: cs.LG

TL;DR: BlockGPT是一种用于降水临近预报的生成式自回归Transformer模型，通过批量标记化方法预测完整二维场，在准确性和推理速度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有降水临近预报方法存在的归纳偏差问题、推理速度慢和计算复杂度高的问题，需要既准确又高效实时应用的模型。

Method: 提出BlockGPT模型，采用批量标记化方法，在每个时间步预测完整二维场，通过帧内自注意力和帧间因果注意力分解时空关系。

Result: 在KNMI和SEVIR两个降水数据集上评估，BlockGPT在准确性、事件定位和推理速度方面均优于现有基准模型，推理速度比可比基准快达31倍。

Conclusion: BlockGPT为降水临近预报提供了一种高效准确的解决方案，在保持高精度的同时显著提升了推理速度。

Abstract: Predicting precipitation maps is a highly complex spatiotemporal modeling
task, critical for mitigating the impacts of extreme weather events. Short-term
precipitation forecasting, or nowcasting, requires models that are not only
accurate but also computationally efficient for real-time applications. Current
methods, such as token-based autoregressive models, often suffer from flawed
inductive biases and slow inference, while diffusion models can be
computationally intensive. To address these limitations, we introduce BlockGPT,
a generative autoregressive transformer using batched tokenization (Block)
method that predicts full two-dimensional fields (frames) at each time step.
Conceived as a model-agnostic paradigm for video prediction, BlockGPT
factorizes space-time by using self-attention within each frame and causal
attention across frames; in this work, we instantiate it for precipitation
nowcasting. We evaluate BlockGPT on two precipitation datasets, viz. KNMI
(Netherlands) and SEVIR (U.S.), comparing it to state-of-the-art baselines
including token-based (NowcastingGPT) and diffusion-based (DiffCast+Phydnet)
models. The results show that BlockGPT achieves superior accuracy, event
localization as measured by categorical metrics, and inference speeds up to 31x
faster than comparable baselines.

</details>


### [13] [Function regression using the forward forward training and inferring paradigm](https://arxiv.org/abs/2510.06762)
*Shivam Padmani,Akshay Joshi*

Main category: cs.LG

TL;DR: 提出了一种使用Forward-Forward算法进行函数回归的新方法，并评估了其在单变量和多变量函数上的性能，还初步研究了将该方法扩展到Kolmogorov Arnold网络和深度物理神经网络。


<details>
  <summary>Details</summary>
Motivation: 函数回归是机器学习的基本应用，传统神经网络需要大量神经元和训练周期。Forward-Forward算法是一种无需反向传播的新训练方法，但目前仅限于分类任务，需要将其扩展到函数回归领域。

Method: 开发了基于Forward-Forward算法的函数回归方法，在单变量和多变量函数上进行评估，并探索了该方法在Kolmogorov Arnold网络和深度物理神经网络中的扩展应用。

Result: 成功实现了使用Forward-Forward算法进行函数回归，验证了该方法在函数近似任务中的有效性。

Conclusion: Forward-Forward算法可以成功应用于函数回归任务，为在神经形态计算和物理神经网络中实现函数近似提供了新的可能性。

Abstract: Function regression/approximation is a fundamental application of machine
learning. Neural networks (NNs) can be easily trained for function regression
using a sufficient number of neurons and epochs. The forward-forward learning
algorithm is a novel approach for training neural networks without
backpropagation, and is well suited for implementation in neuromorphic
computing and physical analogs for neural networks. To the best of the authors'
knowledge, the Forward Forward paradigm of training and inferencing NNs is
currently only restricted to classification tasks. This paper introduces a new
methodology for approximating functions (function regression) using the
Forward-Forward algorithm. Furthermore, the paper evaluates the developed
methodology on univariate and multivariate functions, and provides preliminary
studies of extending the proposed Forward-Forward regression to Kolmogorov
Arnold Networks, and Deep Physical Neural Networks.

</details>


### [14] [Early wind turbine alarm prediction based on machine learning: AlarmForecasting](https://arxiv.org/abs/2510.06831)
*Syed Shazaib Shah,Daoliang Tan*

Main category: cs.LG

TL;DR: 提出了一个警报预测和分类框架，能够提前预测风力涡轮机警报，防止警报触发和故障发生。


<details>
  <summary>Details</summary>
Motivation: 传统研究仅将警报数据用作诊断工具，本研究旨在实现警报预防，在警报触发前进行干预，避免故障发生。

Method: 基于LSTM的回归模块进行时间序列警报预测，然后使用分类模块对预测的警报进行标记，实现完整警报分类体系的预测。

Result: 在14台Senvion MM82涡轮机5年运行数据上测试，10、20、30分钟警报预测准确率分别为82%、52%和41%。

Conclusion: 该框架能够有效预测和避免警报，显著降低警报频率，通过主动干预提高运行效率。

Abstract: Alarm data is pivotal in curbing fault behavior in Wind Turbines (WTs) and
forms the backbone for advancedpredictive monitoring systems. Traditionally,
research cohorts have been confined to utilizing alarm data solelyas a
diagnostic tool, merely indicative of unhealthy status. However, this study
aims to offer a transformativeleap towards preempting alarms, preventing alarms
from triggering altogether, and consequently avertingimpending failures. Our
proposed Alarm Forecasting and Classification (AFC) framework is designed on
twosuccessive modules: first, the regression module based on long short-term
memory (LSTM) for time-series alarmforecasting, and thereafter, the
classification module to implement alarm tagging on the forecasted alarm.
Thisway, the entire alarm taxonomy can be forecasted reliably rather than a few
specific alarms. 14 Senvion MM82turbines with an operational period of 5 years
are used as a case study; the results demonstrated 82%, 52%,and 41% accurate
forecasts for 10, 20, and 30 min alarm forecasts, respectively. The results
substantiateanticipating and averting alarms, which is significant in curbing
alarm frequency and enhancing operationalefficiency through proactive
intervention.

</details>


### [15] [Vacuum Spiker: A Spiking Neural Network-Based Model for Efficient Anomaly Detection in Time Series](https://arxiv.org/abs/2510.06910)
*Iago Xabier Vázquez,Javier Sedano,Muhammad Afzal,Ángel Miguel García-Vico*

Main category: cs.LG

TL;DR: 提出了一种基于脉冲神经网络的新型异常检测方法Vacuum Spiker算法，通过全局神经活动变化进行检测，相比深度学习模型显著降低能耗，在多个数据集上表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在时间序列异常检测中能耗过高的问题，特别是在资源受限环境（如IoT设备、边缘计算平台）中的部署限制。

Method: 采用脉冲神经网络，引入新的检测标准（基于全局神经活动变化而非重构或预测误差），使用脉冲时间依赖可塑性训练，并提出高效编码方案将输入空间离散化为非重叠区间。

Result: 在公开数据集上取得竞争性性能，同时显著降低能耗；在太阳能逆变器功率削减事件检测的实际案例中验证了实用性。

Conclusion: 该方法具有可持续和高效的异常检测潜力，特别适合资源受限环境。

Abstract: Anomaly detection is a key task across domains such as industry, healthcare,
and cybersecurity. Many real-world anomaly detection problems involve analyzing
multiple features over time, making time series analysis a natural approach for
such problems. While deep learning models have achieved strong performance in
this field, their trend to exhibit high energy consumption limits their
deployment in resource-constrained environments such as IoT devices, edge
computing platforms, and wearables. To address this challenge, this paper
introduces the \textit{Vacuum Spiker algorithm}, a novel Spiking Neural
Network-based method for anomaly detection in time series. It incorporates a
new detection criterion that relies on global changes in neural activity rather
than reconstruction or prediction error. It is trained using Spike
Time-Dependent Plasticity in a novel way, intended to induce changes in neural
activity when anomalies occur. A new efficient encoding scheme is also
proposed, which discretizes the input space into non-overlapping intervals,
assigning each to a single neuron. This strategy encodes information with a
single spike per time step, improving energy efficiency compared to
conventional encoding methods. Experimental results on publicly available
datasets show that the proposed algorithm achieves competitive performance
while significantly reducing energy consumption, compared to a wide set of deep
learning and machine learning baselines. Furthermore, its practical utility is
validated in a real-world case study, where the model successfully identifies
power curtailment events in a solar inverter. These results highlight its
potential for sustainable and efficient anomaly detection.

</details>


### [16] [Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration](https://arxiv.org/abs/2510.07035)
*Tengwei Song,Min Wu,Yuan Fang*

Main category: cs.LG

TL;DR: FlexMol是一个灵活的分子预训练框架，支持单模态输入，通过参数共享和解码器生成缺失模态特征，在多种分子性质预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要配对的2D和3D分子数据进行训练，这在某些模态不可用或计算成本高时存在限制。

Method: 采用分离的2D和3D模型，通过参数共享提高计算效率，使用解码器生成缺失模态特征，实现多阶段连续学习。

Result: 在广泛的分子性质预测任务中取得优异性能，并在不完整数据下验证了有效性。

Conclusion: FlexMol能够学习统一的分子表示，支持单模态输入，解决了现有方法对配对数据的依赖问题。

Abstract: Molecular representation learning plays a crucial role in advancing
applications such as drug discovery and material design. Existing work
leverages 2D and 3D modalities of molecular information for pre-training,
aiming to capture comprehensive structural and geometric insights. However,
these methods require paired 2D and 3D molecular data to train the model
effectively and prevent it from collapsing into a single modality, posing
limitations in scenarios where a certain modality is unavailable or
computationally expensive to generate. To overcome this limitation, we propose
FlexMol, a flexible molecule pre-training framework that learns unified
molecular representations while supporting single-modality input. Specifically,
inspired by the unified structure in vision-language models, our approach
employs separate models for 2D and 3D molecular data, leverages parameter
sharing to improve computational efficiency, and utilizes a decoder to generate
features for the missing modality. This enables a multistage continuous
learning process where both modalities contribute collaboratively during
training, while ensuring robustness when only one modality is available during
inference. Extensive experiments demonstrate that FlexMol achieves superior
performance across a wide range of molecular property prediction tasks, and we
also empirically demonstrate its effectiveness with incomplete data. Our code
and data are available at https://github.com/tewiSong/FlexMol.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning](https://arxiv.org/abs/2510.07038)
*Wenxun Wu,Yuanyang Li,Guhan Chen,Linyue Wang,Hongyang Chen*

Main category: cs.AI

TL;DR: 提出TAPO框架，通过强化学习将多跳推理与自适应工具调用能力相结合，在需要外部知识和数学计算的任务上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需要最新知识或计算工具（如计算器和代码解释器）的复杂算术运算任务上表现不佳，需要克服这些限制。

Method: 基于动态采样策略优化（DAPO）的改进版本，专门针对工具调用场景进行适配，使模型能够动态交织复杂推理与按需工具使用（包括搜索API和Python解释器）。

Result: 在Qwen2.5-3B和Qwen2.5-7B模型上的实验表明，该方法在需要外部知识和数学计算的任务上实现了最先进性能，比基线方法更有效地利用工具，同时防止因奖励黑客行为导致的过度调用。

Conclusion: 结合高级推理与工具使用在知识密集型和计算密集型任务中具有显著潜力，能够有效增强模型性能。

Abstract: Recent advances in large language models (LLMs) have popularized test-time
scaling, where models generate additional reasoning tokens before producing
final answers. These approaches have demonstrated significant performance
improvements on benchmarks involving mathematical reasoning. However, language
models relying solely on direct inference still struggle with tasks demanding
up-to-date knowledge or computational tools such as calculators and code
interpreters for complex arithmetic operations. To overcome these limitations,
we propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement
learning framework that systematically integrates multi-hop reasoning with
adaptive tool-calling capabilities. Our approach employs a modified version of
Dynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,
which we adapt specifically for tool invocation scenarios, enabling models to
dynamically interleave complex reasoning with on-demand tool usage (including
search APIs and Python interpreters).
  To support this research, we introduce two new datasets: TAPO-easy-60K and
TAPO-hard-18K, specifically designed to train and evaluate both fact-based
reasoning and mathematical calculation capabilities. Our experiments on
Qwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,
with both models achieving state-of-the-art performance on tasks requiring
external knowledge and mathematical computation among methods with comparable
parameters. Notably, TAPO achieves more efficient tool utilization than
baseline methods while preventing excessive calls caused by reward hacking.
These results highlight the significant potential of combining advanced
reasoning with tool usage to enhance model performance in knowledge-intensive
and computationally demanding tasks.

</details>


### [18] [Integrating Domain Knowledge into Process Discovery Using Large Language Models](https://arxiv.org/abs/2510.07161)
*Ali Norouzifar,Humam Kourani,Marcus Dees,Wil van der Aalst*

Main category: cs.AI

TL;DR: 提出一个交互式流程发现框架，利用大语言模型从领域专家的自然语言描述中提取声明性规则，指导流程模型发现过程，提高模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 仅基于事件日志的流程发现模型可能不准确，因为事件日志通常不完整或包含噪声，且忽略了领域知识这一重要补充资源。

Method: 使用LLM从领域专家的文本描述中提取声明性规则，指导IMr发现算法递归构建流程模型，结合事件日志和提取的规则避免与领域知识冲突的问题结构。

Result: 开发了完全实现的工具支持该工作流，对多个LLM和提示工程策略进行了广泛评估，包括基于真实事件日志的案例研究。

Conclusion: 该框架通过整合领域知识提高了流程发现模型的可靠性，领域专家评估证实了其可用性和有效性。

Abstract: Process discovery aims to derive process models from event logs, providing
insights into operational behavior and forming a foundation for conformance
checking and process improvement. However, models derived solely from event
data may not accurately reflect the real process, as event logs are often
incomplete or affected by noise, and domain knowledge, an important
complementary resource, is typically disregarded. As a result, the discovered
models may lack reliability for downstream tasks. We propose an interactive
framework that incorporates domain knowledge, expressed in natural language,
into the process discovery pipeline using Large Language Models (LLMs). Our
approach leverages LLMs to extract declarative rules from textual descriptions
provided by domain experts. These rules are used to guide the IMr discovery
algorithm, which recursively constructs process models by combining insights
from both the event log and the extracted rules, helping to avoid problematic
process structures that contradict domain knowledge. The framework coordinates
interactions among the LLM, domain experts, and a set of backend services. We
present a fully implemented tool that supports this workflow and conduct an
extensive evaluation of multiple LLMs and prompt engineering strategies. Our
empirical study includes a case study based on a real-life event log with the
involvement of domain experts, who assessed the usability and effectiveness of
the framework.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Protecting De-identified Documents from Search-based Linkage Attacks](https://arxiv.org/abs/2510.06383)
*Pierre Lison,Mark Anderson*

Main category: cs.CL

TL;DR: 提出了一种防止基于搜索的链接攻击的方法，通过识别文档中罕见的N-gram并使用LLM重写器迭代重构这些片段，在保持语义完整性的同时防止将去标识化文本映射回原始数据源。


<details>
  <summary>Details</summary>
Motivation: 现有的去标识化模型虽然能隐藏文档中个人的身份信息，但无法应对链接风险，即攻击者可能通过提取去标识化文档中的短语并将其与原始数据集进行匹配来重新识别源文档。

Method: 方法分为两步：首先构建文档集合中N-gram的倒排索引，识别出现在少于k个文档中的罕见N-gram；然后使用基于LLM的重写器迭代重构这些片段，直到无法进行链接为止。

Result: 在法院案例集合上的实验结果表明，该方法能有效防止基于搜索的链接攻击，同时保持对原始内容的忠实度。

Conclusion: 该方法提供了一种有效的解决方案，能够在保护隐私的同时维持文本的语义完整性，成功解决了去标识化中的链接风险问题。

Abstract: While de-identification models can help conceal the identity of the
individual(s) mentioned in a document, they fail to address linkage risks,
defined as the potential to map the de-identified text back to its source. One
straightforward way to perform such linkages is to extract phrases from the
de-identified document and then check their presence in the original dataset.
This paper presents a method to counter search-based linkage attacks while
preserving the semantic integrity of the text. The method proceeds in two
steps. We first construct an inverted index of the N-grams occurring in the
document collection, making it possible to efficiently determine which N-grams
appear in less than $k$ documents (either alone or in combination with other
N-grams). An LLM-based rewriter is then iteratively queried to reformulate
those spans until linkage is no longer possible. Experimental results on a
collection of court cases show that the method is able to effectively prevent
search-based linkages while remaining faithful to the original content.

</details>


### [20] [Reward Model Perspectives: Whose Opinions Do Reward Models Reward?](https://arxiv.org/abs/2510.06391)
*Elle*

Main category: cs.CL

TL;DR: 该研究分析了奖励模型(RMs)在语言模型对齐中的社会人口统计偏见问题，发现RMs与多个群体偏好不一致，会系统性奖励有害刻板印象，且提示引导无法完全解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 理解奖励模型的行为局限性，特别是它们在社会人口统计偏见方面的表现，以及如何通过提示引导来改善模型与目标群体偏好的对齐。

Method: 建立衡量奖励模型观点对齐的框架，研究RMs的社会人口统计偏见程度，探索通过提示引导将奖励导向目标群体偏好的效果。

Result: RMs与多个社会人口统计群体的偏好对齐度差，会系统性奖励有害刻板印象，仅靠提示引导无法克服这些局限性。

Conclusion: 在偏好学习中需要更仔细地考虑奖励模型行为，以防止在语言技术中传播不需要的社会偏见。

Abstract: Reward models (RMs) are central to the alignment of language models (LMs). An
RM often serves as a proxy for human preferences to guide downstream LM
behavior. However, our understanding of RM behavior is limited. Our work (i)
formalizes a framework for measuring the alignment of opinions captured by RMs,
(ii) investigates the extent to which RMs demonstrate sociodemographic biases,
and (iii) explores the effects of prompting to steer rewards towards the
preferences of a target group. We study the subjective and diverse perspectives
on controversial topics, which allows us to quantify RM perspectives in terms
of their opinions, attitudes, and values. We show that RMs are poorly aligned
with several demographic groups and can systematically reward harmful
stereotypes, and steering alone is not enough to overcome these limitations.
Our findings underscore the need for more careful consideration of RM behavior
in model alignment during preference learning to prevent the propagation of
unwanted social biases in the language technologies that we use.

</details>


### [21] [WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives](https://arxiv.org/abs/2510.05336)
*Yongan Yu,Xianda Du,Qingchen Hu,Jiahao Liang,Jingwei Ni,Dan Qiang,Kaiyu Huang,Grant McKenzie,Renee Sieber,Fengran Mo*

Main category: cs.CL

TL;DR: 提出了WeatherArchive-Bench，这是首个用于评估历史天气档案检索增强生成系统的基准，包含检索和评估两个任务，揭示了当前方法在历史术语和社会指标理解方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 历史天气档案包含丰富的社会脆弱性和韧性信息，但由于规模庞大、数字化质量差和语言古旧，难以转化为结构化知识用于气候研究。

Method: 构建WeatherArchive-Bench基准，包含WeatherArchive-Retrieval（从百万档案新闻段落中检索相关段落）和WeatherArchive-Assessment（评估LLM对社会脆弱性和韧性指标的分类能力）两个任务。

Result: 实验发现稠密检索器在历史术语上表现不佳，而LLM经常误解脆弱性和韧性概念，揭示了在复杂社会指标推理方面的关键局限性。

Conclusion: 该研究为设计更稳健的气候导向RAG系统提供了见解，构建的数据集和评估框架已公开可用。

Abstract: Historical archives on weather events are collections of enduring primary
source records that offer rich, untapped narratives of how societies have
experienced and responded to extreme weather events. These qualitative accounts
provide insights into societal vulnerability and resilience that are largely
absent from meteorological records, making them valuable for climate scientists
to understand societal responses. However, their vast scale, noisy digitized
quality, and archaic language make it difficult to transform them into
structured knowledge for climate research. To address this challenge, we
introduce WeatherArchive-Bench, the first benchmark for evaluating
retrieval-augmented generation (RAG) systems on historical weather archives.
WeatherArchive-Bench comprises two tasks: WeatherArchive-Retrieval, which
measures a system's ability to locate historically relevant passages from over
one million archival news segments, and WeatherArchive-Assessment, which
evaluates whether Large Language Models (LLMs) can classify societal
vulnerability and resilience indicators from extreme weather narratives.
Extensive experiments across sparse, dense, and re-ranking retrievers, as well
as a diverse set of LLMs, reveal that dense retrievers often fail on historical
terminology, while LLMs frequently misinterpret vulnerability and resilience
concepts. These findings highlight key limitations in reasoning about complex
societal indicators and provide insights for designing more robust
climate-focused RAG systems from archival contexts. The constructed dataset and
evaluation framework are publicly available at
https://anonymous.4open.science/r/WeatherArchive-Bench/.

</details>


### [22] [SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models](https://arxiv.org/abs/2510.06917)
*Cheng-Han Chiang,Xiaofei Wang,Linjie Li,Chung-Ching Lin,Kevin Lin,Shujie Liu,Zhendong Wang,Zhengyuan Yang,Hung-yi Lee,Lijuan Wang*

Main category: cs.CL

TL;DR: SHANKS是一个推理框架，让语音语言模型在用户说话时就能生成无声的思维链推理，实现实时低延迟的语音交互。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型和语音语言模型只在用户说完后才开始思考和行动，导致高延迟，不适合需要实时交互的语音对话场景。

Method: 将输入语音流式分块处理，每收到一个语音块就基于之前所有语音和推理生成无声推理，同时决定是否打断用户或调用工具。

Result: 在数学问题场景中，打断准确率比无思考基线高37.1%；在工具增强对话中，56.9%的工具调用能在用户说完前完成。

Conclusion: SHANKS实现了模型在整个对话过程中持续思考，而不仅是在用户回合结束后思考，推动了实时语音交互的发展。

Abstract: Current large language models (LLMs) and spoken language models (SLMs) begin
thinking and taking actions only after the user has finished their turn. This
prevents the model from interacting during the user's turn and can lead to high
response latency while it waits to think. Consequently, thinking after
receiving the full input is not suitable for speech-to-speech interaction,
where real-time, low-latency exchange is important. We address this by noting
that humans naturally "think while listening." In this paper, we propose
SHANKS, a general inference framework that enables SLMs to generate unspoken
chain-of-thought reasoning while listening to the user input. SHANKS streams
the input speech in fixed-duration chunks and, as soon as a chunk is received,
generates unspoken reasoning based on all previous speech and reasoning, while
the user continues speaking. SHANKS uses this unspoken reasoning to decide
whether to interrupt the user and to make tool calls to complete the task. We
demonstrate that SHANKS enhances real-time user-SLM interaction in two
scenarios: (1) when the user is presenting a step-by-step solution to a math
problem, SHANKS can listen, reason, and interrupt when the user makes a
mistake, achieving 37.1% higher interruption accuracy than a baseline that
interrupts without thinking; and (2) in a tool-augmented dialogue, SHANKS can
complete 56.9% of the tool calls before the user finishes their turn. Overall,
SHANKS moves toward models that keep thinking throughout the conversation, not
only after a turn ends. Animated illustrations of Shanks can be found at
https://d223302.github.io/SHANKS/

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [23] [What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?](https://arxiv.org/abs/2510.06492)
*Matthew Kim,Kensuke Nakamura,Andrea Bajcsy*

Main category: cs.RO

TL;DR: 本文研究了基于潜在空间的安全控制方法，发现仅使用RGB观测可能导致短视的安全行为，提出了基于互信息的度量方法来识别观测是否捕获安全相关特征，并提出了多模态监督训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有潜在空间安全控制方法假设安全关键特征可在学习的潜在状态中观察到，但实际中RGB观测可能无法充分捕捉安全相关信息，导致短视的安全行为。

Method: 引入基于互信息的度量方法识别观测缺陷，提出多模态监督训练策略，在训练时使用额外传感器输入塑造潜在状态，但部署时无需额外模态。

Result: 在仿真和Franka Research 3机械臂硬件实验中验证了方法有效性，成功防止蜡锅过热。

Conclusion: 多模态监督训练能够改善潜在状态对安全相关特征的表示，提高安全控制性能，而无需在部署时增加额外传感器。

Abstract: Safe control techniques, such as Hamilton-Jacobi reachability, provide
principled methods for synthesizing safety-preserving robot policies but
typically assume hand-designed state spaces and full observability. Recent work
has relaxed these assumptions via latent-space safe control, where state
representations and dynamics are learned jointly through world models that
reconstruct future high-dimensional observations (e.g., RGB images) from
current observations and actions. This enables safety constraints that are
difficult to specify analytically (e.g., spilling) to be framed as
classification problems in latent space, allowing controllers to operate
directly from raw observations. However, these methods assume that
safety-critical features are observable in the learned latent state. We ask:
when are latent state spaces sufficient for safe control? To study this, we
examine temperature-based failures, comparable to overheating in cooking or
manufacturing tasks, and find that RGB-only observations can produce myopic
safety behaviors, e.g., avoiding seeing failure states rather than preventing
failure itself. To predict such behaviors, we introduce a mutual
information-based measure that identifies when observations fail to capture
safety-relevant features. Finally, we propose a multimodal-supervised training
strategy that shapes the latent state with additional sensory inputs during
training, but requires no extra modalities at deployment, and validate our
approach in simulation and on hardware with a Franka Research 3 manipulator
preventing a pot of wax from overheating.

</details>


### [24] [Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal Missions via Deep Reinforcement Learning](https://arxiv.org/abs/2510.06566)
*Vincent Lam,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于TD3强化学习的无模型空间机械臂轨迹规划器，通过多批评器网络和课程学习实现安全可靠的太空碎片捕获。


<details>
  <summary>Details</summary>
Motivation: 开发能够在非合作目标上安全捕获碎片的太空机械臂系统，需要同时解决轨迹跟踪、自碰撞避免和与目标意外接触等问题。

Method: 使用TD3强化学习算法，结合局部控制策略进行奇异性避免和可操作性增强，采用基于课程的多批评器网络（一个关注跟踪精度，一个关注碰撞避免），并使用优先经验回放缓冲区加速收敛。

Result: 在Matlab/Simulink中模拟的七自由度KUKA LBR iiwa机械臂上验证，能够生成安全自适应的轨迹用于碎片清除任务。

Conclusion: 所提出的框架能够为太空碎片清除任务生成安全可靠的轨迹，实现了在复杂约束条件下的自适应规划能力。

Abstract: The objective of this study is to develop a model-free workspace trajectory
planner for space manipulators using a Twin Delayed Deep Deterministic Policy
Gradient (TD3) agent to enable safe and reliable debris capture. A local
control strategy with singularity avoidance and manipulability enhancement is
employed to ensure stable execution. The manipulator must simultaneously track
a capture point on a non-cooperative target, avoid self-collisions, and prevent
unintended contact with the target. To address these challenges, we propose a
curriculum-based multi-critic network where one critic emphasizes accurate
tracking and the other enforces collision avoidance. A prioritized experience
replay buffer is also used to accelerate convergence and improve policy
robustness. The framework is evaluated on a simulated seven-degree-of-freedom
KUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating
safe and adaptive trajectory generation for debris removal missions.

</details>
