<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Colors See Colors Ignore: Clothes Changing ReID with Color Disentanglement](https://arxiv.org/abs/2507.07230)
*Priyank Pathak,Yogesh S. Rawat*

Main category: cs.CV

TL;DR: 论文提出了一种基于颜色的轻量级方法CSCI，用于解决衣物更换重识别问题，无需额外标注或模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖额外模型或标注学习衣物不变特征，资源消耗大。本文探索颜色作为轻量级代理，减少外观偏差。

Method: 提出CSCI方法，利用RGB信息分离颜色与身份特征，引入S2A自注意力防止信息泄露。

Result: 在四个CC-ReID数据集上显著提升性能，图像重识别Top-1提升2.9%-5.0%，视频重识别提升1.0%-2.5%。

Conclusion: 颜色可作为低成本解决方案，有效减少CC-ReID中的外观偏差。

Abstract: Clothes-Changing Re-Identification (CC-ReID) aims to recognize individuals
across different locations and times, irrespective of clothing. Existing
methods often rely on additional models or annotations to learn robust,
clothing-invariant features, making them resource-intensive. In contrast, we
explore the use of color - specifically foreground and background colors - as a
lightweight, annotation-free proxy for mitigating appearance bias in ReID
models. We propose Colors See, Colors Ignore (CSCI), an RGB-only method that
leverages color information directly from raw images or video frames. CSCI
efficiently captures color-related appearance bias ('Color See') while
disentangling it from identity-relevant ReID features ('Color Ignore'). To
achieve this, we introduce S2A self-attention, a novel self-attention to
prevent information leak between color and identity cues within the feature
space. Our analysis shows a strong correspondence between learned color
embeddings and clothing attributes, validating color as an effective proxy when
explicit clothing labels are unavailable. We demonstrate the effectiveness of
CSCI on both image and video ReID with extensive experiments on four CC-ReID
datasets. We improve the baseline by Top-1 2.9% on LTCC and 5.0% on PRCC for
image-based ReID, and 1.0% on CCVID and 2.5% on MeVID for video-based ReID
without relying on additional supervision. Our results highlight the potential
of color as a cost-effective solution for addressing appearance bias in
CC-ReID. Github: https://github.com/ppriyank/ICCV-CSCI-Person-ReID.

</details>


### [2] [DisenQ: Disentangling Q-Former for Activity-Biometrics](https://arxiv.org/abs/2507.07262)
*Shehreen Azad,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 提出了一种多模态语言引导框架DisenQ，用于解决活动生物识别中身份特征与运动动态和外观变化纠缠的问题，并在多个基准测试中取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 传统生物识别在多样化活动中面临身份特征与运动动态和外观变化纠缠的挑战，现有方法依赖额外视觉数据但存在提取不准确的问题。

Method: 提出DisenQ框架，利用结构化文本指导解耦生物特征、运动和非生物特征，避免依赖额外视觉数据。

Result: 在三个活动基准测试中达到最优性能，并在传统视频识别基准中表现出强泛化能力。

Conclusion: DisenQ框架通过语言指导有效解耦特征，提升了活动生物识别的准确性和泛化能力。

Abstract: In this work, we address activity-biometrics, which involves identifying
individuals across diverse set of activities. Unlike traditional person
identification, this setting introduces additional challenges as identity cues
become entangled with motion dynamics and appearance variations, making
biometrics feature learning more complex. While additional visual data like
pose and/or silhouette help, they often struggle from extraction inaccuracies.
To overcome this, we propose a multimodal language-guided framework that
replaces reliance on additional visual data with structured textual
supervision. At its core, we introduce \textbf{DisenQ} (\textbf{Disen}tangling
\textbf{Q}-Former), a unified querying transformer that disentangles
biometrics, motion, and non-biometrics features by leveraging structured
language guidance. This ensures identity cues remain independent of appearance
and motion variations, preventing misidentifications. We evaluate our approach
on three activity-based video benchmarks, achieving state-of-the-art
performance. Additionally, we demonstrate strong generalization to complex
real-world scenario with competitive performance on a traditional video-based
identification benchmark, showing the effectiveness of our framework.

</details>


### [3] [Multi-Scale Attention and Gated Shifting for Fine-Grained Event Spotting in Videos](https://arxiv.org/abs/2507.07381)
*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazeley,Sunil Aryal*

Main category: cs.CV

TL;DR: 提出了一种多尺度注意力门移位模块（MSAGSM），用于增强体育视频中的精确事件检测（PES），并通过新数据集TTA验证其性能。


<details>
  <summary>Details</summary>
Motivation: 现有PES模型的时空模块在时间感受野和空间适应性上存在局限，需改进以提升性能。

Method: MSAGSM结合多尺度时间扩张和多头空间注意力，增强时空建模能力，并引入TTA数据集。

Result: 在五个PES基准测试中，MSAGSM显著提升性能，达到新SOTA。

Conclusion: MSAGSM是一种轻量级即插即用模块，能有效提升PES任务性能。

Abstract: Precise Event Spotting (PES) in sports videos requires frame-level
recognition of fine-grained actions from single-camera footage. Existing PES
models typically incorporate lightweight temporal modules such as Gate Shift
Module (GSM) or Gate Shift Fuse (GSF) to enrich 2D CNN feature extractors with
temporal context. However, these modules are limited in both temporal receptive
field and spatial adaptability. We propose a Multi-Scale Attention Gate Shift
Module (MSAGSM) that enhances GSM with multi-scale temporal dilations and
multi-head spatial attention, enabling efficient modeling of both short- and
long-term dependencies while focusing on salient regions. MSAGSM is a
lightweight plug-and-play module that can be easily integrated with various 2D
backbones. To further advance the field, we introduce the Table Tennis
Australia (TTA) dataset-the first PES benchmark for table tennis-containing
over 4800 precisely annotated events. Extensive experiments across five PES
benchmarks demonstrate that MSAGSM consistently improves performance with
minimal overhead, setting new state-of-the-art results.

</details>


### [4] [Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking](https://arxiv.org/abs/2507.07483)
*Qiangqiang Wu,Yi Yu,Chenqi Kong,Ziquan Liu,Jia Wan,Haoliang Li,Alex C. Kot,Antoni B. Chan*

Main category: cs.CV

TL;DR: 论文提出了一种生成时间不可学习示例（TUEs）的新框架，以防止个人视频数据被未经授权用于视觉目标跟踪（VOT）模型的训练。


<details>
  <summary>Details</summary>
Motivation: 社交媒体视频数据被广泛用于VOT训练，但数据隐私问题被忽视，许多私人视频未经授权被用于商业模型训练。

Method: 提出了一种生成TUEs的生成框架，并引入时间对比损失以增强效果。

Result: 实验表明，该方法在视频数据隐私保护方面表现优异，具有强泛化能力。

Conclusion: 该框架有效防止视频数据被未经授权利用，为视频隐私保护提供了新思路。

Abstract: With the rise of social media, vast amounts of user-uploaded videos (e.g.,
YouTube) are utilized as training data for Visual Object Tracking (VOT).
However, the VOT community has largely overlooked video data-privacy issues, as
many private videos have been collected and used for training commercial models
without authorization. To alleviate these issues, this paper presents the first
investigation on preventing personal video data from unauthorized exploitation
by deep trackers. Existing methods for preventing unauthorized data use
primarily focus on image-based tasks (e.g., image classification), directly
applying them to videos reveals several limitations, including inefficiency,
limited effectiveness, and poor generalizability. To address these issues, we
propose a novel generative framework for generating Temporal Unlearnable
Examples (TUEs), and whose efficient computation makes it scalable for usage on
large-scale video datasets. The trackers trained w/ TUEs heavily rely on
unlearnable noises for temporal matching, ignoring the original data structure
and thus ensuring training video data-privacy. To enhance the effectiveness of
TUEs, we introduce a temporal contrastive loss, which further corrupts the
learning of existing trackers when using our TUEs for training. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
in video data-privacy protection, with strong transferability across VOT
models, datasets, and temporal matching tasks.

</details>


### [5] [EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream Spiking Neural Networks](https://arxiv.org/abs/2507.07734)
*Michael Neumeier,Jules Lecomte,Nils Kazinski,Soubarna Banik,Bing Li,Axel von Arnim*

Main category: cs.CV

TL;DR: 提出了一种高频率双流脉冲神经网络（SNN），用于早期人类活动识别，在THU EACT-50数据集上准确率提升2%，并展示了其在运动捕捉中的实际应用。


<details>
  <summary>Details</summary>
Motivation: 早期识别人类活动对安全和人机交互至关重要，但现有方法因低速率处理限制了早期预测能力。

Method: 采用高频率双流SNN处理事件数据，避免传统方法的低速率积累问题。

Result: 在THU EACT-50数据集上准确率提升2%，并通过早期识别框架验证了其性能。

Conclusion: 该方法在准确率和实时性上均优于现有技术，适用于实际应用如运动捕捉。

Abstract: Recognizing human activities early is crucial for the safety and
responsiveness of human-robot and human-machine interfaces. Due to their high
temporal resolution and low latency, event-based vision sensors are a perfect
match for this early recognition demand. However, most existing processing
approaches accumulate events to low-rate frames or space-time voxels which
limits the early prediction capabilities. In contrast, spiking neural networks
(SNNs) can process the events at a high-rate for early predictions, but most
works still fall short on final accuracy. In this work, we introduce a
high-rate two-stream SNN which closes this gap by outperforming previous work
by 2% in final accuracy on the large-scale THU EACT-50 dataset. We benchmark
the SNNs within a novel early event-based recognition framework by reporting
Top-1 and Top-5 recognition scores for growing observation time. Finally, we
exemplify the impact of these methods on a real-world task of early action
triggering for human motion capture in sports.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
*Deepak Kumar Panda,Weisi Guo*

Main category: cs.LG

TL;DR: 论文提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成隐蔽对抗攻击以逃避入侵检测系统（IDS），并利用条件变分自编码器（CVAE）检测此类攻击。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在民用空域的广泛应用，传统异常检测方法难以识别新型威胁，尤其是隐蔽对抗攻击。

Method: 设计了一个多类IDS分类器，训练于良性无人机遥测数据和已知网络攻击；使用cGAN生成对抗样本；利用CVAE检测对抗攻击。

Result: CVAE的负对数似然方法在检测隐蔽对抗攻击方面显著优于传统马氏距离检测器。

Conclusion: 高级概率建模对增强IDS对抗生成模型驱动的网络入侵能力至关重要。

Abstract: The growing integration of UAVs into civilian airspace underscores the need
for resilient and intelligent intrusion detection systems (IDS), as traditional
anomaly detection methods often fail to identify novel threats. A common
approach treats unfamiliar attacks as out-of-distribution (OOD) samples;
however, this leaves systems vulnerable when mitigation is inadequate.
Moreover, conventional OOD detectors struggle to distinguish stealthy
adversarial attacks from genuine OOD events. This paper introduces a
conditional generative adversarial network (cGAN)-based framework for crafting
stealthy adversarial attacks that evade IDS mechanisms. We first design a
robust multi-class IDS classifier trained on benign UAV telemetry and known
cyber-attacks, including Denial of Service (DoS), false data injection (FDI),
man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN
perturbs known attacks to generate adversarial samples that misclassify as
benign while retaining statistical resemblance to OOD distributions. These
adversarial samples are iteratively refined to achieve high stealth and success
rates. To detect such perturbations, we implement a conditional variational
autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial
inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based
regret scores significantly outperform traditional Mahalanobis distance-based
detectors in identifying stealthy adversarial threats. Our findings emphasize
the importance of advanced probabilistic modeling to strengthen IDS
capabilities against adaptive, generative-model-based cyber intrusions.

</details>


### [7] [Optimizing Model Splitting and Device Task Assignment for Deceptive Signal Assisted Private Multi-hop Split Learning](https://arxiv.org/abs/2507.07323)
*Dongyu Wei,Xiaoren Xu,Yuchen Liu,H. Vincent Poor,Mingzhe Chen*

Main category: cs.LG

TL;DR: 论文研究了在边缘设备协作训练中，通过发送欺骗信号防止窃听者获取模型和数据信息的方法，提出了一种基于深度强化学习的优化框架。


<details>
  <summary>Details</summary>
Motivation: 防止窃听者在协作训练中获取模型和数据信息，确保隐私安全。

Method: 提出了一种结合内在好奇心模块（ICM）和交叉注意力（CA）的软演员-评论家深度强化学习框架（ICM-CA），用于优化设备选择和资源分配。

Result: 仿真结果显示，该方法比传统SAC算法收敛速度提升3倍，信息泄露减少13%。

Conclusion: ICM-CA框架能有效提升隐私保护和训练效率，适用于边缘设备协作训练场景。

Abstract: In this paper, deceptive signal-assisted private split learning is
investigated. In our model, several edge devices jointly perform collaborative
training, and some eavesdroppers aim to collect the model and data information
from devices. To prevent the eavesdroppers from collecting model and data
information, a subset of devices can transmit deceptive signals. Therefore, it
is necessary to determine the subset of devices used for deceptive signal
transmission, the subset of model training devices, and the models assigned to
each model training device. This problem is formulated as an optimization
problem whose goal is to minimize the information leaked to eavesdroppers while
meeting the model training energy consumption and delay constraints. To solve
this problem, we propose a soft actor-critic deep reinforcement learning
framework with intrinsic curiosity module and cross-attention (ICM-CA) that
enables a centralized agent to determine the model training devices, the
deceptive signal transmission devices, the transmit power, and sub-models
assigned to each model training device without knowing the position and
monitoring probability of eavesdroppers. The proposed method uses an ICM module
to encourage the server to explore novel actions and states and a CA module to
determine the importance of each historical state-action pair thus improving
training efficiency. Simulation results demonstrate that the proposed method
improves the convergence rate by up to 3x and reduces the information leaked to
eavesdroppers by up to 13% compared to the traditional SAC algorithm.

</details>


### [8] [Learning Collective Variables from Time-lagged Generation](https://arxiv.org/abs/2507.07390)
*Seonghyun Park,Kiyoung Seong,Soojung Yang,Rafael Gómez-Bombarelli,Sungsoo Ahn*

Main category: cs.LG

TL;DR: TLC框架通过从生成模型的时间滞后条件中学习集体变量（CVs），解决了传统机器学习方法在动态行为捕捉上的不足，在Alanine Dipeptide系统中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 稀有事件（如状态转换）在分子动力学模拟中难以直接观察，传统CV发现方法未能充分编码动态行为。

Method: TLC通过建模时间滞后条件分布而非静态Boltzmann分布，学习CVs以捕捉慢动态行为。

Result: 在Alanine Dipeptide系统中，TLC在SMD和OPES任务中表现优于或等同于现有MLCV方法。

Conclusion: TLC提供了一种更有效的方法来捕捉动态行为，提升稀有事件采样效率。

Abstract: Rare events such as state transitions are difficult to observe directly with
molecular dynamics simulations due to long timescales. Enhanced sampling
techniques overcome this by introducing biases along carefully chosen
low-dimensional features, known as collective variables (CVs), which capture
the slow degrees of freedom. Machine learning approaches (MLCVs) have automated
CV discovery, but existing methods typically focus on discriminating
meta-stable states without fully encoding the detailed dynamics essential for
accurate sampling. We propose TLC, a framework that learns CVs directly from
time-lagged conditions of a generative model. Instead of modeling the static
Boltzmann distribution, TLC models a time-lagged conditional distribution
yielding CVs to capture the slow dynamic behavior. We validate TLC on the
Alanine Dipeptide system using two CV-based enhanced sampling tasks: (i)
steered molecular dynamics (SMD) and (ii) on-the-fly probability enhanced
sampling (OPES), demonstrating equal or superior performance compared to
existing MLCV methods in both transition path sampling and state
discrimination.

</details>


### [9] [Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series](https://arxiv.org/abs/2507.07559)
*Amirhossein Sadough,Mahyar Shahsavari,Mark Wijtvliet,Marcel van Gerven*

Main category: cs.LG

TL;DR: DAD是一种基于在线去相关学习的实时异常检测方法，适用于多变量时间序列，能高效处理高维流数据。


<details>
  <summary>Details</summary>
Motivation: 随着工业物联网的发展，实时异常检测需求激增，传统方法难以满足高维流数据的单次处理需求。

Method: DAD通过动态学习数据的相关结构，实现单次处理的实时异常检测，并提出超参数调优策略。

Result: 在多个基准数据集上，DAD表现优于现有方法，尤其在高维数据中表现稳健。

Conclusion: DAD在检测效果与计算效率间取得平衡，为实时、内存受限的异常检测设定了新标准。

Abstract: Anomaly detection (AD) plays a vital role across a wide range of real-world
domains by identifying data instances that deviate from expected patterns,
potentially signaling critical events such as system failures, fraudulent
activities, or rare medical conditions. The demand for real-time AD has surged
with the rise of the (Industrial) Internet of Things, where massive volumes of
multivariate sensor data must be processed instantaneously. Real-time AD
requires methods that not only handle high-dimensional streaming data but also
operate in a single-pass manner, without the burden of storing historical
instances, thereby ensuring minimal memory usage and fast decision-making. We
propose DAD, a novel real-time decorrelation-based anomaly detection method for
multivariate time series, based on an online decorrelation learning approach.
Unlike traditional proximity-based or reconstruction-based detectors that
process entire data or windowed instances, DAD dynamically learns and monitors
the correlation structure of data sample by sample in a single pass, enabling
efficient and effective detection. To support more realistic benchmarking
practices, we also introduce a practical hyperparameter tuning strategy
tailored for real-time anomaly detection scenarios. Extensive experiments on
widely used benchmark datasets demonstrate that DAD achieves the most
consistent and superior performance across diverse anomaly types compared to
state-of-the-art methods. Crucially, its robustness to increasing
dimensionality makes it particularly well-suited for real-time,
high-dimensional data streams. Ultimately, DAD not only strikes an optimal
balance between detection efficacy and computational efficiency but also sets a
new standard for real-time, memory-constrained anomaly detection.

</details>


### [10] [COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation](https://arxiv.org/abs/2507.07580)
*Uliana Parkina,Maxim Rakhuba*

Main category: cs.LG

TL;DR: 提出了一种基于稳定分解的无逆正则化框架，解决了现有神经网络低秩近似方法中的数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法因依赖显式Gram矩阵计算和求逆导致数值不稳定，影响近似质量或产生奇异矩阵。

Method: 采用无逆正则化框架，基于稳定分解，解决了GPU内存不足、输入激活矩阵接近奇异和数据不足等问题。

Result: 方法在多种挑战性场景下表现稳定，证明了收敛性并推导了误差界。

Conclusion: 新框架显著提升了数值稳定性，适用于大规模神经网络的压缩和微调。

Abstract: Recent studies suggest that context-aware low-rank approximation is a useful
tool for compression and fine-tuning of modern large-scale neural networks. In
this type of approximation, a norm is weighted by a matrix of input
activations, significantly improving metrics over the unweighted case.
Nevertheless, existing methods for neural networks suffer from numerical
instabilities due to their reliance on classical formulas involving explicit
Gram matrix computation and their subsequent inversion. We demonstrate that
this can degrade the approximation quality or cause numerically singular
matrices.
  To address these limitations, we propose a novel inversion-free regularized
framework that is based entirely on stable decompositions and overcomes the
numerical pitfalls of prior art. Our method can handle possible challenging
scenarios: (1) when calibration matrices exceed GPU memory capacity, (2) when
input activation matrices are nearly singular, and even (3) when insufficient
data prevents unique approximation. For the latter, we prove that our solution
converges to a desired approximation and derive explicit error bounds.

</details>


### [11] [GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing](https://arxiv.org/abs/2507.07735)
*Peiyan Zhang,Haibo Jin,Liying Kang,Haohan Wang*

Main category: cs.LG

TL;DR: 本文介绍了GuardVal，一种动态生成和优化越狱提示的新评估协议，用于更准确地评估大型语言模型（LLM）在安全关键场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以全面评估LLM的漏洞，尤其是在越狱攻击中生成有害内容的问题。

Method: 提出GuardVal协议，动态生成和优化越狱提示，并结合新的优化方法防止停滞。

Result: 应用于多种模型（如Mistral-7b和GPT-4），揭示了不同模型的行为模式及其鲁棒性。

Conclusion: GuardVal提供了对LLM行为的深入理解，为未来研究和开发更安全模型提供了参考。

Abstract: Jailbreak attacks reveal critical vulnerabilities in Large Language Models
(LLMs) by causing them to generate harmful or unethical content. Evaluating
these threats is particularly challenging due to the evolving nature of LLMs
and the sophistication required in effectively probing their vulnerabilities.
Current benchmarks and evaluation methods struggle to fully address these
challenges, leaving gaps in the assessment of LLM vulnerabilities. In this
paper, we review existing jailbreak evaluation practices and identify three
assumed desiderata for an effective jailbreak evaluation protocol. To address
these challenges, we introduce GuardVal, a new evaluation protocol that
dynamically generates and refines jailbreak prompts based on the defender LLM's
state, providing a more accurate assessment of defender LLMs' capacity to
handle safety-critical situations. Moreover, we propose a new optimization
method that prevents stagnation during prompt refinement, ensuring the
generation of increasingly effective jailbreak prompts that expose deeper
weaknesses in the defender LLMs. We apply this protocol to a diverse set of
models, from Mistral-7b to GPT-4, across 10 safety domains. Our findings
highlight distinct behavioral patterns among the models, offering a
comprehensive view of their robustness. Furthermore, our evaluation process
deepens the understanding of LLM behavior, leading to insights that can inform
future research and drive the development of more secure models.

</details>


### [12] [Deep Survival Analysis in Multimodal Medical Data: A Parametric and Probabilistic Approach with Competing Risks](https://arxiv.org/abs/2507.07804)
*Alba Garrido,Alejandro Almodóvar,Patricia A. Apellániz,Juan Parras,Santiago Zazo*

Main category: cs.LG

TL;DR: 提出了一种名为SAMVAE的多模态深度学习框架，用于肿瘤生存分析，整合六种数据模态，并在乳腺癌和低级别胶质瘤中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 传统生存预测方法依赖单一数据模态，无法全面捕捉肿瘤生物学的复杂性，因此需要多模态方法提高预测准确性。

Method: SAMVAE采用多模态变分自编码器架构，整合临床变量、分子特征和病理图像，通过共享潜在空间实现生存预测。

Result: 在乳腺癌和低级别胶质瘤数据集中，SAMVAE表现优异，支持标准生存分析和竞争风险场景。

Conclusion: SAMVAE为肿瘤学提供了可解释的多模态生存分析框架，支持临床决策。

Abstract: Accurate survival prediction is critical in oncology for prognosis and
treatment planning. Traditional approaches often rely on a single data
modality, limiting their ability to capture the complexity of tumor biology. To
address this challenge, we introduce a multimodal deep learning framework for
survival analysis capable of modeling both single and competing risks
scenarios, evaluating the impact of integrating multiple medical data sources
on survival predictions. We propose SAMVAE (Survival Analysis Multimodal
Variational Autoencoder), a novel deep learning architecture designed for
survival prediction that integrates six data modalities: clinical variables,
four molecular profiles, and histopathological images. SAMVAE leverages
modality specific encoders to project inputs into a shared latent space,
enabling robust survival prediction while preserving modality specific
information. Its parametric formulation enables the derivation of clinically
meaningful statistics from the output distributions, providing patient-specific
insights through interactive multimedia that contribute to more informed
clinical decision-making and establish a foundation for interpretable,
data-driven survival analysis in oncology. We evaluate SAMVAE on two cancer
cohorts breast cancer and lower grade glioma applying tailored preprocessing,
dimensionality reduction, and hyperparameter optimization. The results
demonstrate the successful integration of multimodal data for both standard
survival analysis and competing risks scenarios across different datasets. Our
model achieves competitive performance compared to state-of-the-art multimodal
survival models. Notably, this is the first parametric multimodal deep learning
architecture to incorporate competing risks while modeling continuous time to a
specific event, using both tabular and image data.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLMs）生成有害内容的问题，重点分析了输入提示和输出过滤的计算挑战，并指出外部过滤器无法完全确保安全性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，防止其生成有害内容的需求日益迫切，研究旨在探索过滤器的有效性及其计算限制。

Method: 通过理论分析，研究了输入提示和输出过滤的计算复杂性，并基于密码学假设证明了其不可行性。

Result: 发现高效过滤输入提示和输出内容在计算上不可行，且外部过滤器无法完全解决安全问题。

Conclusion: 安全性需通过LLM内部设计实现，而非依赖外部过滤器，智能与判断不可分割。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [14] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 研究评估了微调的Llama 3.2模型从急诊分诊笔记中提取疫苗相关信息的能力，支持近实时疫苗安全监测。


<details>
  <summary>Details</summary>
Motivation: 支持高效的疫苗安全监测和早期发现疫苗接种后的不良事件。

Method: 使用提示工程创建标记数据集，并由人工标注确认。比较了提示工程模型、微调模型和基于规则的方法。

Result: 微调的Llama 3B参数模型在提取疫苗名称的准确性上优于其他模型，量化技术使其在资源受限环境中高效部署。

Conclusion: 大型语言模型在自动化急诊笔记数据提取中具有潜力，可支持疫苗安全监测。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [15] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 该论文提出了一种基于轮廓线分类小提琴是否被缩小的方法，通过几何特征区分缩小与非缩小乐器。


<details>
  <summary>Details</summary>
Motivation: 研究小提琴制作中尺寸标准化对乐器几何特征的影响，尤其是轮廓线的变化，填补定量研究的空白。

Method: 使用摄影测量获取25把小提琴的3D几何网格，提取并拟合轮廓线为抛物线状曲线，计算参数特征，应用分类方法。

Result: 研究发现几何特征可以一定程度上区分缩小与非缩小乐器，其中开口参数β最具预测性。

Conclusion: 几何特征可用于小提琴分类，但需考虑乐器变形的连续谱系，β参数是关键指标。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [16] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: FAI Benchmark评估AI在七个维度上对人类繁荣的贡献，发现现有模型虽部分表现良好，但整体未达标。


<details>
  <summary>Details</summary>
Motivation: 传统AI评估聚焦技术能力或避免危害，而FAI Benchmark旨在衡量AI对人类全面繁荣的贡献。

Method: 通过1,229个主客观问题，结合专家LLM和几何平均评分，评估AI在七个维度的表现。

Result: 测试28个领先语言模型，最高得分72/100，但无模型在所有维度（尤其是信仰与灵性等）上达标。

Conclusion: FAI Benchmark为开发支持人类繁荣的AI提供了框架，对AI伦理和评估有重要意义。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [17] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 论文认为，随着计算资源投入的边际效益递减，AI模型性能将趋于收敛，即使资源有限的小模型也能接近顶级模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨AI模型性能不平等问题，并挑战当前关于计算资源投入与模型性能关系的直觉。

Method: 开发模型分析计算资源投入的边际效益递减现象，并通过基准数据和理论模型验证。

Result: 计算资源投入的边际效益显著下降，小模型性能将接近顶级模型。

Conclusion: AI战略和政策需重新审视，以适应小模型性能提升的趋势。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>
