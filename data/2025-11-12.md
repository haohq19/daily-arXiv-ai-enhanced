<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 12]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models](https://arxiv.org/abs/2511.07496)
*Barath Chandran. C,Srinivas Anumasa,Dianbo Liu*

Main category: cs.CV

TL;DR: 提出了一种在扩散模型推理过程中通过拉普拉斯校正来减少模式插值幻觉的后处理方法


<details>
  <summary>Details</summary>
Motivation: 扩散模型存在产生不连贯或不真实样本的幻觉问题，现有工作缺乏在采样过程中防止幻觉生成的方法

Method: 在推理时对得分函数进行后验调整，利用得分的拉普拉斯（锐度）来减少模式插值幻觉，并为高维数据推导了基于Hutchinson迹估计器的高效拉普拉斯近似

Result: 该方法在1D、2D玩具分布和高维图像数据集上显著降低了幻觉样本的比例

Conclusion: 拉普拉斯与得分不确定性的关系值得进一步探索，该方法能有效减少扩散模型中的模式插值幻觉

Abstract: Diffusion models, though successful, are known to suffer from hallucinations that create incoherent or unrealistic samples. Recent works have attributed this to the phenomenon of mode interpolation and score smoothening, but they lack a method to prevent their generation during sampling. In this paper, we propose a post-hoc adjustment to the score function during inference that leverages the Laplacian (or sharpness) of the score to reduce mode interpolation hallucination in unconditional diffusion models across 1D, 2D, and high-dimensional image data. We derive an efficient Laplacian approximation for higher dimensions using a finite-difference variant of the Hutchinson trace estimator. We show that this correction significantly reduces the rate of hallucinated samples across toy 1D/2D distributions and a high- dimensional image dataset. Furthermore, our analysis explores the relationship between the Laplacian and uncertainty in the score.

</details>


### [2] [I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks](https://arxiv.org/abs/2511.08065)
*Ruichen Ma,Liwei Meng,Guanchao Qiao,Ning Ning,Yang Liu,Shaogang Hu*

Main category: cs.CV

TL;DR: I2E框架通过模拟微扫视眼动将静态图像转换为高保真事件流，解决了SNN训练中事件流数据稀缺的问题，实现了300倍以上的转换速度提升，并在ImageNet和CIFAR10-DVS数据集上取得了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决脉冲神经网络(SNN)训练中事件流数据严重稀缺的瓶颈问题，为开发高性能神经形态系统提供可扩展的数据解决方案。

Method: 通过高度并行化的卷积模拟微扫视眼动，将静态图像转换为高保真事件流，实现快速数据转换和在线数据增强。

Result: 在I2E-ImageNet数据集上训练的SNN达到60.50%的最先进准确率；通过模拟到真实范式，在CIFAR10-DVS数据集上获得92.5%的突破性准确率。

Conclusion: 合成事件数据可以作为真实传感器数据的高保真代理，填补了神经形态工程中长期存在的空白，为领域研究提供了基础工具包。

Abstract: Spiking neural networks (SNNs) promise highly energy-efficient computing, but their adoption is hindered by a critical scarcity of event-stream data. This work introduces I2E, an algorithmic framework that resolves this bottleneck by converting static images into high-fidelity event streams. By simulating microsaccadic eye movements with a highly parallelized convolution, I2E achieves a conversion speed over 300x faster than prior methods, uniquely enabling on-the-fly data augmentation for SNN training. The framework's effectiveness is demonstrated on large-scale benchmarks. An SNN trained on the generated I2E-ImageNet dataset achieves a state-of-the-art accuracy of 60.50%. Critically, this work establishes a powerful sim-to-real paradigm where pre-training on synthetic I2E data and fine-tuning on the real-world CIFAR10-DVS dataset yields an unprecedented accuracy of 92.5%. This result validates that synthetic event data can serve as a high-fidelity proxy for real sensor data, bridging a long-standing gap in neuromorphic engineering. By providing a scalable solution to the data problem, I2E offers a foundational toolkit for developing high-performance neuromorphic systems. The open-source algorithm and all generated datasets are provided to accelerate research in the field.

</details>


### [3] [PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions](https://arxiv.org/abs/2511.08140)
*Luoping Cui,Hanqing Liu,Mingjie Liu,Endian Lin,Donghong Jiang,Yuhao Wang,Chuang Zhu*

Main category: cs.CV

TL;DR: 提出了PEOD数据集，这是首个大规模、像素对齐的高分辨率（1280×720）事件-RGB数据集，用于挑战条件下的目标检测，包含130+时空对齐序列和34万手动标注框，57%数据在低光、过曝和高速运动条件下采集。


<details>
  <summary>Details</summary>
Motivation: 现有事件-RGB数据集在极端条件覆盖稀疏且空间分辨率低（≤640×480），无法全面评估挑战场景下的检测器性能。

Method: 构建PEOD数据集，包含130+时空对齐序列和340k手动边界框，57%数据在低光、过曝和高速运动条件下采集。在三种输入配置（事件、RGB、事件-RGB融合）上对14种方法进行基准测试。

Result: 在完整测试集和正常子集上，融合模型表现优异；在光照挑战子集上，顶级事件模型优于所有融合模型，但融合模型仍优于RGB模型，表明当帧模态严重退化时现有融合方法存在局限。

Conclusion: PEOD为多模态感知建立了真实、高质量的基准，促进了未来研究。

Abstract: Robust object detection for challenging scenarios increasingly relies on event cameras, yet existing Event-RGB datasets remain constrained by sparse coverage of extreme conditions and low spatial resolution (<= 640 x 480), which prevents comprehensive evaluation of detectors under challenging scenarios. To address these limitations, we propose PEOD, the first large-scale, pixel-aligned and high-resolution (1280 x 720) Event-RGB dataset for object detection under challenge conditions. PEOD contains 130+ spatiotemporal-aligned sequences and 340k manual bounding boxes, with 57% of data captured under low-light, overexposure, and high-speed motion. Furthermore, we benchmark 14 methods across three input configurations (Event-based, RGB-based, and Event-RGB fusion) on PEOD. On the full test set and normal subset, fusion-based models achieve the excellent performance. However, in illumination challenge subset, the top event-based model outperforms all fusion models, while fusion models still outperform their RGB-based counterparts, indicating limits of existing fusion methods when the frame modality is severely degraded. PEOD establishes a realistic, high-quality benchmark for multimodal perception and facilitates future research.

</details>


### [4] [Re-coding for Uncertainties: Edge-awareness Semantic Concordance for Resilient Event-RGB Segmentation](https://arxiv.org/abs/2511.08269)
*Nan Bao,Yifan Zhao,Lin Zhu,Jia Li*

Main category: cs.CV

TL;DR: 提出了一种边缘感知语义一致性框架，通过边缘线索统一事件和RGB模态的异构特征，解决极端条件下语义分割性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 在极端条件下（如光线不足、剧烈相机运动），现有语义分割方法因RGB信息丢失而性能下降。事件模态虽能补充信息，但与RGB存在异构性，导致特征不匹配和优化困难。

Method: 提出边缘感知语义一致性框架：1）边缘感知潜在重编码，通过重编码分布将事件-RGB特征对齐到统一语义空间；2）重编码整合和不确定性优化，利用重编码边缘特征和不确定性指标解决异构融合问题。

Result: 在提出的DERS-XS数据集上，方法比现有最佳方法提升2.55% mIoU，在空间遮挡下表现出优越的鲁棒性。

Conclusion: 该方法通过边缘线索有效统一了事件和RGB的异构特征，在极端条件下显著提升了语义分割性能，具有实际应用价值。

Abstract: Semantic segmentation has achieved great success in ideal conditions. However, when facing extreme conditions (e.g., insufficient light, fierce camera motion), most existing methods suffer from significant information loss of RGB, severely damaging segmentation results. Several researches exploit the high-speed and high-dynamic event modality as a complement, but event and RGB are naturally heterogeneous, which leads to feature-level mismatch and inferior optimization of existing multi-modality methods. Different from these researches, we delve into the edge secret of both modalities for resilient fusion and propose a novel Edge-awareness Semantic Concordance framework to unify the multi-modality heterogeneous features with latent edge cues. In this framework, we first propose Edge-awareness Latent Re-coding, which obtains uncertainty indicators while realigning event-RGB features into unified semantic space guided by re-coded distribution, and transfers event-RGB distributions into re-coded features by utilizing a pre-established edge dictionary as clues. We then propose Re-coded Consolidation and Uncertainty Optimization, which utilize re-coded edge features and uncertainty indicators to solve the heterogeneous event-RGB fusion issues under extreme conditions. We establish two synthetic and one real-world event-RGB semantic segmentation datasets for extreme scenario comparisons. Experimental results show that our method outperforms the state-of-the-art by a 2.55% mIoU on our proposed DERS-XS, and possesses superior resilience under spatial occlusion. Our code and datasets are publicly available at https://github.com/iCVTEAM/ESC.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Methodological Precedence in Health Tech: Why ML/Big Data Analysis Must Follow Basic Epidemiological Consistency. A Case Study](https://arxiv.org/abs/2511.07500)
*Marco Roccetti*

Main category: cs.LG

TL;DR: 该研究通过一个疫苗结果与精神事件的队列研究案例，证明即使使用先进的机器学习和大数据分析，如果基础研究设计存在严重方法学缺陷，复杂分析反而会放大错误，导致误导性结论。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和海量数据处理在健康研究中的广泛应用，研究者需要警惕这些复杂方法对基础方法学缺陷的放大效应。本文旨在强调在应用高级分析前必须验证基本方法学一致性的重要性。

Method: 作者使用简单的标准描述性统计方法和已确立的国家流行病学基准，对一个已发表的疫苗结果与精神事件队列研究进行分析，揭示其中存在的统计悖论。

Result: 分析暴露了多个统计上不可调和的悖论，包括高风险人群中慢性疾病风险的不可信降低以及矛盾的发病率比较，这些发现明确否定了报告的风险比。观察到的效应源于队列构建中未纠正的选择偏倚。

Conclusion: 该研究强有力地提醒，即使是最复杂的健康研究，在从后续高级机器学习或统计建模得出任何结论之前，都必须首先通过基本流行病学一致性检验。对于非随机化的行政数据，倾向评分匹配等稳健方法对于实现有效的因果推断至关重要。

Abstract: The integration of advanced analytical tools, including Machine Learning (ML) and massive data processing, has revolutionized health research, promising unprecedented accuracy in diagnosis and risk prediction. However, the rigor of these complex methods is fundamentally dependent on the quality and integrity of the underlying datasets and the validity of their statistical design. We propose an emblematic case where advanced analysis (ML/Big Data) must necessarily be subsequent to the verification of basic methodological coherence. This study highlights a crucial cautionary principle: sophisticated analyses amplify, rather than correct, severe methodological flaws rooted in basic design choices, leading to misleading or contradictory findings. By applying simple, standard descriptive statistical methods and established national epidemiological benchmarks to a recently published cohort study on vaccine outcomes and psychiatric events, we expose multiple, statistically irreconcilable paradoxes. These paradoxes, including an implausible risk reduction for a chronic disorder in a high-risk group and contradictory incidence rate comparisons, definitively invalidate the reported hazard ratios (HRs). We demonstrate that the observed effects are mathematical artifacts stemming from an uncorrected selection bias in the cohort construction. This analysis serves as a robust reminder that even the most complex health studies must first pass the test of basic epidemiological consistency before any conclusion drawn from subsequent advanced ML or statistical modeling can be considered valid or publishable. We conclude that robust methods, such as Propensity Score Matching, are essential for achieving valid causal inference from administrative data in the absence of randomization

</details>


### [6] [On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection](https://arxiv.org/abs/2511.07700)
*Brandon Dominique,Prudence Lam,Nicholas Kurtansky,Jochen Weber,Kivanc Kose,Veronica Rotemberg,Jennifer Dy*

Main category: cs.LG

TL;DR: 本研究评估了皮肤癌检测AI模型在不同人口统计亚组（性别、种族、年龄）中的性能，发现现有模型虽然提高了判别准确性，但在新数据集上存在过度诊断风险和校准问题，强调需要全面的模型审计策略。


<details>
  <summary>Details</summary>
Motivation: AI模型在黑色素瘤检测中表现出专家级性能，但其临床采用受到跨人口统计亚组（性别、种族、年龄）性能差异的阻碍。现有基准测试主要依赖AUROC的群体公平性指标，无法提供模型提供准确估计的能力洞察。

Method: 将校准作为AUROC公平性指标的补充基准测试指标，评估ISIC 2020挑战赛领先皮肤癌检测算法在ISIC 2020挑战数据集和PROVE-AI数据集上的性能，并与第二、三名模型比较，重点关注性别、种族（Fitzpatrick皮肤类型）和年龄定义的亚组。

Result: 研究发现现有模型虽然增强了判别准确性，但在应用于新数据集时经常过度诊断风险并表现出校准问题。

Conclusion: 本研究强调了实现公平AI驱动医疗解决方案需要全面的模型审计策略和广泛的元数据收集。

Abstract: Artificial Intelligence (AI) models have demonstrated expert-level performance in melanoma detection, yet their clinical adoption is hindered by performance disparities across demographic subgroups such as gender, race, and age. Previous efforts to benchmark the performance of AI models have primarily focused on assessing model performance using group fairness metrics that rely on the Area Under the Receiver Operating Characteristic curve (AUROC), which does not provide insights into a model's ability to provide accurate estimates. In line with clinical assessments, this paper addresses this gap by incorporating calibration as a complementary benchmarking metric to AUROC-based fairness metrics. Calibration evaluates the alignment between predicted probabilities and observed event rates, offering deeper insights into subgroup biases. We assess the performance of the leading skin cancer detection algorithm of the ISIC 2020 Challenge on the ISIC 2020 Challenge dataset and the PROVE-AI dataset, and compare it with the second and third place models, focusing on subgroups defined by sex, race (Fitzpatrick Skin Tone), and age. Our findings reveal that while existing models enhance discriminative accuracy, they often over-diagnose risk and exhibit calibration issues when applied to new datasets. This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration.

</details>


### [7] [From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training](https://arxiv.org/abs/2511.07738)
*Donglai Xu,Hongzheng Yang,Yuzhi Zhao,Pingping Zhang,Jinpeng Chen,Wenao Ma,Zhijian Hou,Mengyang Wu,Xiaolei Li,Senkang Hu,Ziyi Guan,Jason Chun Lok Li,Lai Man Po*

Main category: cs.LG

TL;DR: 提出了一种用于多模态大语言模型的两阶段令牌级熵优化方法，通过动态调节从探索到利用的训练过程，增强对噪声标签的鲁棒性，在GRPO中实现更可靠的奖励梯度估计。


<details>
  <summary>Details</summary>
Motivation: 现实场景中高质量标注数据稀缺且存在大量标注噪声，现有无监督RLVR方法容易过拟合到错误标签并限制GRPO中的奖励排序信号，需要提高噪声容忍度。

Method: 两阶段令牌级熵优化方法：探索阶段通过令牌级熵最大化促进多样化随机输出生成，防止过早收敛到噪声标签；利用阶段通过令牌级熵最小化鼓励模型产生确定性输出，巩固学习成果。

Result: 在三种MLLM骨干网络（Qwen2-VL-2B、Qwen2-VL-7B、Qwen2.5-VL-3B）上，跨越多种噪声设置和任务，该方法始终优于先前方法，实现了鲁棒且优越的性能。

Conclusion: 提出的分阶段策略通过统一和增强外部、内部和基于熵的方法，在MLLM的RLVR中提供了有效的噪声容忍解决方案，显著提升了性能表现。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) for Multimodal Large Language Models (MLLMs) is highly dependent on high-quality labeled data, which is often scarce and prone to substantial annotation noise in real-world scenarios. Existing unsupervised RLVR methods, including pure entropy minimization, can overfit to incorrect labels and limit the crucial reward ranking signal for Group-Relative Policy Optimization (GRPO). To address these challenges and enhance noise tolerance, we propose a novel two-stage, token-level entropy optimization method for RLVR. This approach dynamically guides the model from exploration to exploitation during training. In the initial exploration phase, token-level entropy maximization promotes diverse and stochastic output generation, serving as a strong regularizer that prevents premature convergence to noisy labels and ensures sufficient intra-group variation, which enables more reliable reward gradient estimation in GRPO. As training progresses, the method transitions into the exploitation phase, where token-level entropy minimization encourages the model to produce confident and deterministic outputs, thereby consolidating acquired knowledge and refining prediction accuracy. Empirically, across three MLLM backbones - Qwen2-VL-2B, Qwen2-VL-7B, and Qwen2.5-VL-3B - spanning diverse noise settings and multiple tasks, our phased strategy consistently outperforms prior approaches by unifying and enhancing external, internal, and entropy-based methods, delivering robust and superior performance across the board.

</details>


### [8] [Physical Consistency of Aurora's Encoder: A Quantitative Study](https://arxiv.org/abs/2511.07787)
*Benjamin Richards,Pushpa Kumar Balan*

Main category: cs.LG

TL;DR: 本文通过线性分类器探究Aurora天气模型编码器的潜在表征是否与已知物理和气象概念一致，发现模型学习到了物理一致的特征，但在捕捉罕见事件方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 大型天气预报模型如Aurora虽然准确度高，但其内部表征不透明，这种"黑箱"特性阻碍了在高风险操作环境中的应用，因此需要验证其物理一致性。

Method: 使用大规模嵌入数据集，训练线性分类器来识别三个不同概念：基本的海陆边界、高影响极端温度事件和大气不稳定性。

Result: 定量证据表明Aurora学习了物理一致的特征，但在捕捉最罕见事件方面存在局限性。

Conclusion: 这项工作强调了可解释性方法对于验证和建立对下一代AI驱动天气模型信任的关键需求。

Abstract: The high accuracy of large-scale weather forecasting models like Aurora is often accompanied by a lack of transparency, as their internal representations remain largely opaque. This "black box" nature hinders their adoption in high-stakes operational settings. In this work, we probe the physical consistency of Aurora's encoder by investigating whether its latent representations align with known physical and meteorological concepts. Using a large-scale dataset of embeddings, we train linear classifiers to identify three distinct concepts: the fundamental land-sea boundary, high-impact extreme temperature events, and atmospheric instability. Our findings provide quantitative evidence that Aurora learns physically consistent features, while also highlighting its limitations in capturing the rarest events. This work underscores the critical need for interpretability methods to validate and build trust in the next generation of Al-driven weather models.

</details>


### [9] [Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction](https://arxiv.org/abs/2511.07899)
*Ihab Tabbara,Yuxuan Yang,Hussein Sibai*

Main category: cs.LG

TL;DR: 该论文提出了一个基于保形预测的框架，为使用学习型Hamilton-Jacobi值函数和策略的控制系统提供概率安全保证


<details>
  <summary>Details</summary>
Motivation: 学习型HJ值函数及其安全策略无法保证正确性，需要解决这种不确定性

Method: 使用保形预测来校准不安全标称控制器与学习型HJ安全策略之间的切换，并推导切换策略下的安全保证

Result: 开发了一个框架，能够为使用学习型HJ值函数的控制系统提供概率安全保证

Conclusion: 保形预测框架能够有效处理学习型HJ值函数的不确定性，为自主系统提供可靠的安全保障

Abstract: Safety assurance is a fundamental requirement for deploying learning-enabled autonomous systems. Hamilton-Jacobi (HJ) reachability analysis is a fundamental method for formally verifying safety and generating safe controllers. However, computing the HJ value function that characterizes the backward reachable set (BRS) of a set of user-defined failure states is computationally expensive, especially for high-dimensional systems, motivating the use of reinforcement learning approaches to approximate the value function. Unfortunately, a learned value function and its corresponding safe policy are not guaranteed to be correct. The learned value function evaluated at a given state may not be equal to the actual safety return achieved by following the learned safe policy. To address this challenge, we introduce a conformal prediction-based (CP) framework that bounds such uncertainty. We leverage CP to provide probabilistic safety guarantees when using learned HJ value functions and policies to prevent control systems from reaching failure states. Specifically, we use CP to calibrate the switching between the unsafe nominal controller and the learned HJ-based safe policy and to derive safety guarantees under this switched policy. We also investigate using an ensemble of independently trained HJ value functions as a safety filter and compare this ensemble approach to using individual value functions alone.

</details>


### [10] [Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks](https://arxiv.org/abs/2511.08086)
*Muthukumar Pandaram,Jakob Hollenstein,David Drexel,Samuele Tosatto,Antonio Rodríguez-Sánchez,Justus Piater*

Main category: cs.LG

TL;DR: 本文批判性地检验了强化学习中动态模型的稀疏性假设，发现全局稀疏性很少见，但存在局部、状态依赖的稀疏性结构


<details>
  <summary>Details</summary>
Motivation: 检验强化学习中动态模型的因果图是否稀疏、这种稀疏性是否状态依赖、以及局部系统动态是否稀疏变化等假设是否在实际任务中成立

Method: 通过分析MuJoCo Playground基准套件中机器人强化学习环境的真实动态数据，研究动态因果图的稀疏性、状态依赖性和局部动态变化

Result: 全局稀疏性很少见，但任务在其动态中表现出局部、状态依赖的稀疏性，这种稀疏性在时间局部化簇中出现并影响特定的状态维度子集

Conclusion: 研究结果挑战了动态学习中常见的稀疏性先验假设，强调需要反映真实世界动态状态依赖稀疏性结构的接地气的归纳偏置

Abstract: The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.
  In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.
  We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.
  Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.

</details>


### [11] [SERL: Self-Examining Reinforcement Learning on Open-Domain](https://arxiv.org/abs/2511.07922)
*Weixuan Ou,Yanzhao Zheng,Shuoshuo Sun,Wei Zhang,Baohua Dong,Hangcheng Zhu,Ruohui Huang,Gang Yu,Pengwei Yan,Yifan Qiao*

Main category: cs.LG

TL;DR: 提出SERL框架，让大语言模型同时作为行动者和评判者，通过两种奖励机制实现自我改进，在开放域任务中达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决RL在开放域任务中的两个关键挑战：主观性任务无法提供可验证奖励，以及RLHF依赖外部奖励机制。

Method: SERL框架包含两个协同的奖励机制：基于Copeland风格成对比较的奖励来改进行动者能力，以及自一致性奖励来提高评判者可靠性。

Result: 在AlpacaEval 2上，Qwen3-8B的LC胜率从52.37%提升到59.90%，达到自改进方法中的最先进性能，与更大的Qwen3-32B模型性能相当。

Conclusion: SERL框架有效解决了开放域任务中RL应用的挑战，实现了无需外部信号的自我改进，在效果和鲁棒性方面表现出色。

Abstract: Reinforcement Learning (RL) has been shown to improve the capabilities of large language models (LLMs). However, applying RL to open-domain tasks faces two key challenges: (1) the inherent subjectivity of these tasks prevents the verifiable rewards as required by Reinforcement Learning with Verifiable Rewards (RLVR); (2) Reinforcement Learning from Human Feedback (RLHF) relies on external reward mechanisms. To overcome these limitations, we propose Self-Examining Reinforcement Learning (SERL), a novel self-improving framework where the LLM serves as both Actor and Judge. SERL introduces two synergistic reward mechanisms without any external signals. On the one hand, to improve the Actor's capability, we derive rewards from Copeland-style pairwise comparison judgments across a group of generated responses. On the other hand, a self-consistency reward that encourages coherent judgments is proposed to improve the Judge's reliability. This process refines the Judge's capability, which in turn provides a more robust reward for Actor. Experiments show that our method outperforms existing self-improvement training methods. SERL improves the LC win rate of Qwen3-8B on AlpacaEval 2 from 52.37% to 59.90%. To the best of our knowledge, our method achieves state-of-the-art performance among self-improving approaches. Furthermore, it achieves a performance comparable to significantly larger models like Qwen3-32B, demonstrating superior effectiveness and robustness on open-domain tasks.

</details>


### [12] [Generalizable Insights for Graph Transformers in Theory and Practice](https://arxiv.org/abs/2511.08028)
*Timo Stoll,Luis Müller,Christopher Morris*

Main category: cs.LG

TL;DR: 提出了广义距离变换器(GDT)，这是一种使用标准注意力的图变换器架构，结合了近年来图变换器的多项进展，并深入分析了其在注意力和位置嵌入方面的表示能力。


<details>
  <summary>Details</summary>
Motivation: 当前图变换器架构在注意力机制、位置嵌入和表达能力方面差异很大，现有表达能力结果往往与特定设计选择相关，缺乏在大规模数据上的全面实证验证，导致理论与实践之间存在差距。

Method: 开发了广义距离变换器(GDT)架构，使用标准注意力机制，整合了图变换器的多项最新进展，通过大量实验评估不同设计选择在各种应用、任务和模型规模上的表现。

Result: 在包含约800万张图和2.7亿个标记的多样化领域数据上进行了评估，包括基于图像的目标检测、分子性质预测、代码摘要和分布外算法推理，在少样本迁移设置中表现出色且无需微调。

Conclusion: 从理论和实践中提炼出关于有效图变换器设计、训练和推理的多个可推广见解，为图变换器的通用设计提供了指导。

Abstract: Graph Transformers (GTs) have shown strong empirical performance, yet current architectures vary widely in their use of attention mechanisms, positional embeddings (PEs), and expressivity. Existing expressivity results are often tied to specific design choices and lack comprehensive empirical validation on large-scale data. This leaves a gap between theory and practice, preventing generalizable insights that exceed particular application domains. Here, we propose the Generalized-Distance Transformer (GDT), a GT architecture using standard attention that incorporates many advancements for GTs from recent years, and develop a fine-grained understanding of the GDT's representation power in terms of attention and PEs. Through extensive experiments, we identify design choices that consistently perform well across various applications, tasks, and model scales, demonstrating strong performance in a few-shot transfer setting without fine-tuning. Our evaluation covers over eight million graphs with roughly 270M tokens across diverse domains, including image-based object detection, molecular property prediction, code summarization, and out-of-distribution algorithmic reasoning. We distill our theoretical and practical findings into several generalizable insights about effective GT design, training, and inference.

</details>


### [13] [An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models](https://arxiv.org/abs/2511.08077)
*Jinbo Li,Peng Liu,Long Chen,Witold Pedrycz,Weiping Ding*

Main category: cs.LG

TL;DR: 提出一个集成融合框架，将模糊规则模型与梯度提升相结合，通过动态控制因子优化模型贡献，防止过拟合并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 模糊规则模型具有良好可解释性但面临复杂设计和大数据集扩展性问题，梯度提升能提供强大性能但缺乏可解释性。融合两者可克服各自局限性。

Method: 集成融合框架：在每次迭代中构建模糊规则模型，通过动态控制因子优化其贡献，防止模型主导、鼓励多样性、作为正则化参数。包含基于样本的校正机制进行自适应调整。

Result: 实验结果表明该框架有效提升了模糊规则模型的性能，特别是在减轻过拟合和规则复杂性方面，同时保持了模型的可解释性。

Conclusion: 通过最优控制因子管理每个模型的贡献，该框架在提升性能的同时保持了可解释性，简化了模型的维护和更新。

Abstract: The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.

</details>


### [14] [PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore](https://arxiv.org/abs/2511.08241)
*Zhihao Lin,Lin Wu,Zhen Tian,Jianglin Lan*

Main category: cs.LG

TL;DR: PrefPoE是一个基于偏好-专家乘积的新型强化学习探索框架，通过优势引导的智能探索解决了传统熵最大化方法的高方差问题，在多个控制任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中的探索策略通常采用简单的熵最大化方法，但这会导致高方差和低效的策略更新。需要一种更智能的探索机制来平衡探索与利用。

Method: 提出PrefPoE框架，训练偏好网络集中概率质量于高优势动作，并通过专家乘积（PoE）将其与主策略融合，创建软信任区域来稳定策略更新同时保持目标探索。

Result: 在连续和离散动作空间的多种控制任务中表现优异：HalfCheetah-v4提升321%（1276→5375），Ant-v4提升69%，LunarLander-v2提升276%，训练稳定性和样本效率均显著提升。

Conclusion: 通过优势引导偏好学习"在哪里探索"与学习"如何行动"同样重要，PrefPoE为增强策略梯度方法提供了一个通用框架，能防止过早收敛并实现更优性能。

Abstract: Exploration in reinforcement learning remains a critical challenge, as naive entropy maximization often results in high variance and inefficient policy updates. We introduce \textbf{PrefPoE}, a novel \textit{Preference-Product-of-Experts} framework that performs intelligent, advantage-guided exploration via the first principled application of product-of-experts (PoE) fusion for single-task exploration-exploitation balancing. By training a preference network to concentrate probability mass on high-advantage actions and fusing it with the main policy through PoE, PrefPoE creates a \textbf{soft trust region} that stabilizes policy updates while maintaining targeted exploration. Across diverse control tasks spanning both continuous and discrete action spaces, PrefPoE demonstrates consistent improvements: +321\% on HalfCheetah-v4 (1276~$\rightarrow$~5375), +69\% on Ant-v4, +276\% on LunarLander-v2, with consistently enhanced training stability and sample efficiency. Unlike standard PPO, which suffers from entropy collapse, PrefPoE sustains adaptive exploration through its unique dynamics, thereby preventing premature convergence and enabling superior performance. Our results establish that learning \textit{where to explore} through advantage-guided preferences is as crucial as learning how to act, offering a general framework for enhancing policy gradient methods across the full spectrum of reinforcement learning domains. Code and pretrained models are available in supplementary materials.

</details>


### [15] [LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration](https://arxiv.org/abs/2511.08339)
*Ruiyu Qiu,Rui Wang,Guanghui Yang,Xiang Li,Zhijiang Shao*

Main category: cs.LG

TL;DR: 提出了LPPG-RL框架，通过顺序梯度投影解决词典序多目标强化学习问题，适用于连续空间且兼容所有策略梯度算法。


<details>
  <summary>Details</summary>
Motivation: 传统安全RL和多目标RL方法难以有效处理具有明确优先级的多个冲突子任务，现有词典序多目标RL方法要么依赖启发式阈值调优，要么仅限于离散域。

Method: 使用顺序梯度投影识别可行的策略更新方向，将投影步骤重新表述为优化问题，采用Dykstra投影而非通用求解器加速计算，并引入子问题探索防止梯度消失。

Result: 在2D导航环境中进行广泛实验，证明LPPG-RL优于现有最先进的连续词典序多目标RL方法。

Conclusion: LPPG-RL是一个有效的词典序多目标RL框架，具有理论收敛保证和策略改进下界，在连续空间中表现出优越性能。

Abstract: Lexicographic multi-objective problems, which consist of multiple conflicting subtasks with explicit priorities, are common in real-world applications. Despite the advantages of Reinforcement Learning (RL) in single tasks, extending conventional RL methods to prioritized multiple objectives remains challenging. In particular, traditional Safe RL and Multi-Objective RL (MORL) methods have difficulty enforcing priority orderings efficiently. Therefore, Lexicographic Multi-Objective RL (LMORL) methods have been developed to address these challenges. However, existing LMORL methods either rely on heuristic threshold tuning with prior knowledge or are restricted to discrete domains. To overcome these limitations, we propose Lexicographically Projected Policy Gradient RL (LPPG-RL), a novel LMORL framework which leverages sequential gradient projections to identify feasible policy update directions, thereby enabling LPPG-RL broadly compatible with all policy gradient algorithms in continuous spaces. LPPG-RL reformulates the projection step as an optimization problem, and utilizes Dykstra's projection rather than generic solvers to deliver great speedups, especially for small- to medium-scale instances. In addition, LPPG-RL introduces Subproblem Exploration (SE) to prevent gradient vanishing, accelerate convergence and enhance stability. We provide theoretical guarantees for convergence and establish a lower bound on policy improvement. Finally, through extensive experiments in a 2D navigation environment, we demonstrate the effectiveness of LPPG-RL, showing that it outperforms existing state-of-the-art continuous LMORL methods.

</details>


### [16] [One Model for All: Universal Pre-training for EEG based Emotion Recognition across Heterogeneous Datasets and Paradigms](https://arxiv.org/abs/2511.08444)
*Xiang Li,You Li,Yazhou Zhang*

Main category: cs.LG

TL;DR: 提出'One Model for All'通用预训练框架，通过解耦学习和新颖架构解决EEG数据集异构性问题，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: EEG情感识别面临严重的数据集异构性（通道/受试者变异性），现有方法难以有效迁移知识，需要通用化的预训练框架。

Method: 两阶段学习：1）基于统一通道模式的单变量自监督对比预训练；2）使用ART和GAT架构的多变量微调，捕捉复杂时空依赖关系。

Result: 在SEED、DEAP和DREAMER数据集上实现新的SOTA性能（99.27%、93.69%、93.93%），跨数据集迁移达到94.08%，GAT模块在DEAP上带来+22.19%提升。

Conclusion: 该框架为多样化EEG分析任务提供了更通用、可扩展和有效的预训练模型路径。

Abstract: EEG-based emotion recognition is hampered by profound dataset heterogeneity (channel/subject variability), hindering generalizable models. Existing approaches struggle to transfer knowledge effectively. We propose 'One Model for All', a universal pre-training framework for EEG analysis across disparate datasets. Our paradigm decouples learning into two stages: (1) Univariate pre-training via self-supervised contrastive learning on individual channels, enabled by a Unified Channel Schema (UCS) that leverages the channel union (e.g., SEED-62ch, DEAP-32ch); (2) Multivariate fine-tuning with a novel 'ART' (Adaptive Resampling Transformer) and 'GAT' (Graph Attention Network) architecture to capture complex spatio-temporal dependencies. Experiments show universal pre-training is an essential stabilizer, preventing collapse on SEED (vs. scratch) and yielding substantial gains on DEAP (+7.65%) and DREAMER (+3.55%). Our framework achieves new SOTA performance on all within-subject benchmarks: SEED (99.27%), DEAP (93.69%), and DREAMER (93.93%). We also show SOTA cross-dataset transfer, achieving 94.08% (intersection) and 93.05% (UCS) on the unseen DREAMER dataset, with the former surpassing the within-domain pre-training benchmark. Ablation studies validate our architecture: the GAT module is critical, yielding a +22.19% gain over GCN on the high-noise DEAP dataset, and its removal causes a catastrophic -16.44% performance drop. This work paves the way for more universal, scalable, and effective pre-trained models for diverse EEG analysis tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces](https://arxiv.org/abs/2511.07587)
*Shreyas Rajesh,Pavan Holur,Chenda Duan,David Chong,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: 提出了Generative Semantic Workspace (GSW)框架，解决LLM在长上下文推理中的挑战，通过构建结构化、可解释的情境表示，在Episodic Memory Benchmark上比现有RAG基线提升20%，并减少51%的查询时上下文token。


<details>
  <summary>Details</summary>
Motivation: LLM在长上下文推理中面临根本挑战：许多文档超过其有限上下文窗口，且性能随序列长度下降。现有解决方案针对基于事实的检索，无法构建时空锚定的叙事表示来跟踪实体在事件中的演变。

Method: GSW框架包含Operator和Reconciler两个组件：Operator将观察映射到中间语义结构，Reconciler将这些结构整合到持久工作空间中，强制执行时间、空间和逻辑一致性。

Result: 在EpBench（包含10万到100万token的语料库）上，GSW比现有RAG基线性能提升高达20%，同时减少51%的查询时上下文token，显著降低推理时间成本。

Conclusion: GSW为赋予LLM类似人类的片段记忆提供了具体蓝图，为能够进行长视野推理的更强大智能体铺平了道路。

Abstract: Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with external memory frameworks. Current solutions, which have evolved from retrieval using semantic embeddings to more sophisticated structured knowledge graphs representations for improved sense-making and associativity, are tailored for fact-based retrieval and fail to build the space-time-anchored narrative representations required for tracking entities through episodic events. To bridge this gap, we propose the \textbf{Generative Semantic Workspace} (GSW), a neuro-inspired generative memory framework that builds structured, interpretable representations of evolving situations, enabling LLMs to reason over evolving roles, actions, and spatiotemporal contexts. Our framework comprises an \textit{Operator}, which maps incoming observations to intermediate semantic structures, and a \textit{Reconciler}, which integrates these into a persistent workspace that enforces temporal, spatial, and logical coherence. On the Episodic Memory Benchmark (EpBench) \cite{huet_episodic_2025} comprising corpora ranging from 100k to 1M tokens in length, GSW outperforms existing RAG based baselines by up to \textbf{20\%}. Furthermore, GSW is highly efficient, reducing query-time context tokens by \textbf{51\%} compared to the next most token-efficient baseline, reducing inference time costs considerably. More broadly, GSW offers a concrete blueprint for endowing LLMs with human-like episodic memory, paving the way for more capable agents that can reason over long horizons.

</details>


### [18] [Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions](https://arxiv.org/abs/2511.07669)
*Alejandro R. Jadad*

Main category: cs.AI

TL;DR: 该研究提出了一个框架，使人类与AI在高风险战略决策中实现认知伙伴关系，通过7阶段校准序列和5层保护架构来防止认知偏见，避免可预防的决策遗憾。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在可验证领域表现出色，但在具有不确定结果的高风险战略决策中可靠性不足，这种差距源于人类和AI系统中相互强化的认知偏见，威胁着估值辩护和投资可持续性。

Method: 通过对7个前沿级LLM和3个市场导向风险案例进行系统性定性评估，开发了包含7阶段校准序列的框架，建立在4阶段初始化过程和5层保护架构之上，支持偏见自我监控、人机对抗挑战、伙伴状态验证、性能退化检测和利益相关者保护。

Result: 研究发现：通过有序校准可实现伙伴状态但需要新兴维护协议；当架构漂移和上下文耗尽同时发生时可靠性会下降；解散纪律可防止在根本错误方向上浪费资源。跨模型验证揭示了不同LLM架构间的系统性性能差异。

Conclusion: 该方法证明人类-AI团队能够实现认知伙伴关系，在高风险决策中防止可避免的遗憾，满足依赖AI系统支持重要决策而不引入可预防认知陷阱的投资回报期望。

Abstract: Current large language models (LLMs) excel in verifiable domains where outputs can be checked before action but prove less reliable for high-stakes strategic decisions with uncertain outcomes. This gap, driven by mutually reinforcing cognitive biases in both humans and artificial intelligence (AI) systems, threatens the defensibility of valuations and sustainability of investments in the sector.
  This report describes a framework emerging from systematic qualitative assessment across 7 frontier-grade LLMs and 3 market-facing venture vignettes under time pressure. Detailed prompting specifying decision partnership and explicitly instructing avoidance of sycophancy, confabulation, solution drift, and nihilism achieved initial partnership state but failed to maintain it under operational pressure. Sustaining protective partnership state required an emergent 7-stage calibration sequence, built upon a 4-stage initialization process, within a 5-layer protection architecture enabling bias self-monitoring, human-AI adversarial challenge, partnership state verification, performance degradation detection, and stakeholder protection.
  Three discoveries resulted: partnership state is achievable through ordered calibration but requires emergent maintenance protocols; reliability degrades when architectural drift and context exhaustion align; and dissolution discipline prevents costly pursuit of fundamentally wrong directions. Cross-model validation revealed systematic performance differences across LLM architectures.
  This approach demonstrates that human-AI teams can achieve cognitive partnership capable of preventing avoidable regret in high-stakes decisions, addressing return-on-investment expectations that depend on AI systems supporting consequential decision-making without introducing preventable cognitive traps when verification arrives too late.

</details>


### [19] [AIA Forecaster: Technical Report](https://arxiv.org/abs/2511.07678)
*Rohan Alur,Bradly C. Stadie,Daniel Kang,Ryan Chen,Matt McManus,Michael Rickert,Tyler Lee,Michael Federici,Richard Zhu,Dennis Fogerty,Hayley Williamson,Nina Lozinski,Aaron Linsky,Jasjeet S. Sekhon*

Main category: cs.AI

TL;DR: AIA Forecaster是一个基于LLM的判断性预测系统，通过智能搜索、监督代理和统计校准技术，在ForecastBench上达到人类超级预测者的水平，并在预测市场中提供附加信息。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够利用非结构化数据进行专家级预测的AI系统，解决现有LLM在预测任务中的行为偏差问题。

Method: 结合三个核心要素：高质量新闻源的智能搜索、协调不同预测的监督代理、以及对抗LLM行为偏差的统计校准技术。

Result: 在ForecastBench上表现与人类超级预测者相当，在预测市场基准上虽然不如市场共识，但与市场共识的集成模型优于单独使用市场共识。

Conclusion: 建立了AI预测的新技术水平，提供了实用的可转移建议，是首个可验证实现大规模专家级预测的工作。

Abstract: This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts for the same event, and a set of statistical calibration techniques to counter behavioral biases in large language models. On the ForecastBench benchmark (Karger et al., 2024), the AIA Forecaster achieves performance equal to human superforecasters, surpassing prior LLM baselines. In addition to reporting on ForecastBench, we also introduce a more challenging forecasting benchmark sourced from liquid prediction markets. While the AIA Forecaster underperforms market consensus on this benchmark, an ensemble combining AIA Forecaster with market consensus outperforms consensus alone, demonstrating that our forecaster provides additive information. Our work establishes a new state of the art in AI forecasting and provides practical, transferable recommendations for future research. To the best of our knowledge, this is the first work that verifiably achieves expert-level forecasting at scale.

</details>


### [20] [Towards Provably Unlearnable Examples via Bayes Error Optimisation](https://arxiv.org/abs/2511.08191)
*Ruihan Zhang,Jun Sun,Ee-Peng Lim,Peixin Zhang*

Main category: cs.AI

TL;DR: 提出了一种基于最大化贝叶斯误差的系统性方法来构建不可学习示例，该方法在混合干净数据时仍保持有效性，并通过实验验证了其实际效果。


<details>
  <summary>Details</summary>
Motivation: 解决大规模机器学习模型训练中用户数据隐私保护问题，现有不可学习示例方法缺乏理论保证且在混合干净数据时失效。

Method: 开发基于优化的方法，使用投影梯度上升来系统性地最大化贝叶斯误差，构建不可学习示例。

Result: 实验结果表明该方法能有效限制数据可学习性，在多种数据集和模型架构上均表现良好，且与理论分析一致。

Conclusion: 提出的贝叶斯误差最大化方法为构建不可学习示例提供了理论保证和实际有效性，解决了现有方法的局限性。

Abstract: The recent success of machine learning models, especially large-scale classifiers and language models, relies heavily on training with massive data. These data are often collected from online sources. This raises serious concerns about the protection of user data, as individuals may not have given consent for their data to be used in training. To address this concern, recent studies introduce the concept of unlearnable examples, i.e., data instances that appear natural but are intentionally altered to prevent models from effectively learning from them. While existing methods demonstrate empirical effectiveness, they typically rely on heuristic trials and lack formal guarantees. Besides, when unlearnable examples are mixed with clean data, as is often the case in practice, their unlearnability disappears. In this work, we propose a novel approach to constructing unlearnable examples by systematically maximising the Bayes error, a measurement of irreducible classification error. We develop an optimisation-based approach and provide an efficient solution using projected gradient ascent. Our method provably increases the Bayes error and remains effective when the unlearning examples are mixed with clean samples. Experimental results across multiple datasets and model architectures are consistent with our theoretical analysis and show that our approach can restrict data learnability, effectively in practice.

</details>


### [21] [Hyperdimensional Decoding of Spiking Neural Networks](https://arxiv.org/abs/2511.08558)
*Cedrick Kinavuidi,Luca Peres,Oliver Rhodes*

Main category: cs.AI

TL;DR: 提出了一种结合脉冲神经网络(SNN)和超维计算(HDC)的新型解码方法，在多个数据集上实现了更高的分类准确率、更低的延迟和更低的能耗。


<details>
  <summary>Details</summary>
Motivation: 开发一种具有高精度、高噪声鲁棒性、低延迟和低能耗的解码方法，为神经形态计算提供更优的解决方案。

Method: 将脉冲神经网络(SNN)与超维计算(HDC)相结合，创建SNN-HDC模型进行解码。

Result: 在DvsGesture和SL-Animals-DVS数据集上，SNN-HDC模型相比现有方法实现了1.24x到3.67x的能耗降低，并能有效识别未训练过的未知类别。

Conclusion: SNN-HDC解码方法在准确率、延迟和能耗方面均表现出色，是速率解码和延迟解码的有力替代方案。

Abstract: This work presents a novel spiking neural network (SNN) decoding method, combining SNNs with Hyperdimensional computing (HDC). The goal is to create a decoding method with high accuracy, high noise robustness, low latency and low energy usage. Compared to analogous architectures decoded with existing approaches, the presented SNN-HDC model attains generally better classification accuracy, lower classification latency and lower estimated energy consumption on multiple test cases from literature. The SNN-HDC achieved estimated energy consumption reductions ranging from 1.24x to 3.67x on the DvsGesture dataset and from 1.38x to 2.27x on the SL-Animals-DVS dataset. The presented decoding method can also efficiently identify unknown classes it has not been trained on. In the DvsGesture dataset the SNN-HDC model can identify 100% of samples from an unseen/untrained class. Given the numerous benefits shown and discussed in this paper, this decoding method represents a very compelling alternative to both rate and latency decoding.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [22] [Critical Confabulation: Can LLMs Hallucinate for Social Good?](https://arxiv.org/abs/2511.07722)
*Peiqi Sui,Eamon Duede,Hoyt Long,Richard Jean So*

Main category: cs.CL

TL;DR: 提出"关键虚构"方法，利用LLM的幻觉来填补因社会政治不平等导致的档案空白，为历史中的"隐藏人物"重建基于证据的替代叙事。


<details>
  <summary>Details</summary>
Motivation: LLM会产生幻觉，但经过精心约束的虚构可以具有社会价值，特别是用于填补因不平等而缺失的历史档案，重建被忽视人物的叙事。

Method: 使用开放式叙事填空任务：让LLM在基于未发表文本的人物时间线中生成被掩盖的事件。评估了经过数据污染审计的完全开放模型和未审计的基线模型。

Result: 验证了LLM具备执行关键虚构的基础叙事理解能力，展示了受控且明确指定的幻觉可以支持LLM在知识生产中的应用，而不会损害历史准确性。

Conclusion: 受控的LLM幻觉可以成为有用的知识生产工具，通过关键虚构方法填补历史空白，同时保持对历史准确性的尊重。

Abstract: LLMs hallucinate, yet some confabulations can have social affordances if carefully bounded. We propose critical confabulation (inspired by critical fabulation from literary and social theory), the use of LLM hallucinations to "fill-in-the-gap" for omissions in archives due to social and political inequality, and reconstruct divergent yet evidence-bound narratives for history's "hidden figures". We simulate these gaps with an open-ended narrative cloze task: asking LLMs to generate a masked event in a character-centric timeline sourced from a novel corpus of unpublished texts. We evaluate audited (for data contamination), fully-open models (the OLMo-2 family) and unaudited open-weight and proprietary baselines under a range of prompts designed to elicit controlled and useful hallucinations. Our findings validate LLMs' foundational narrative understanding capabilities to perform critical confabulation, and show how controlled and well-specified hallucinations can support LLM applications for knowledge production without collapsing speculation into a lack of historical accuracy and fidelity.

</details>


### [23] [Planned Event Forecasting using Future Mentions and Related Entity Extraction in News Articles](https://arxiv.org/abs/2511.07879)
*Neelesh Kumar Shukla,Pranay Sanghvi*

Main category: cs.CL

TL;DR: 开发了一个基于新闻分析的社会动荡事件预测系统，使用主题建模和word2vec过滤相关新闻，NER识别实体，时间标准化处理未来日期，并提出了相关实体提取方法。


<details>
  <summary>Details</summary>
Motivation: 在民主国家如印度，公民自由表达观点可能导致抗议、集会等社会动荡事件，这些事件往往未经许可且具有破坏性。预测这些事件有助于行政官员采取必要措施。

Method: 使用主题建模和word2vec过滤相关新闻文章，NER识别人物、组织、地点和日期等实体，应用时间标准化将未来日期转换为标准格式，并提出了相关实体提取方法。

Result: 开发了一个地理独立、通用的模型来识别过滤社会动荡事件的关键特征，能够从众多实体中提取出真正参与事件的相关实体。

Conclusion: 该系统能够通过分析新闻公告提前预测计划中的社会动荡事件，为行政管理部门提供决策支持。

Abstract: In democracies like India, people are free to express their views and demands. Sometimes this causes situations of civil unrest such as protests, rallies, and marches. These events may be disruptive in nature and are often held without prior permission from the competent authority. Forecasting these events helps administrative officials take necessary action. Usually, protests are announced well in advance to encourage large participation. Therefore, by analyzing such announcements in news articles, planned events can be forecasted beforehand. We developed such a system in this paper to forecast social unrest events using topic modeling and word2vec to filter relevant news articles, and Named Entity Recognition (NER) methods to identify entities such as people, organizations, locations, and dates. Time normalization is applied to convert future date mentions into a standard format. In this paper, we have developed a geographically independent, generalized model to identify key features for filtering civil unrest events. There could be many mentions of entities, but only a few may actually be involved in the event. This paper calls such entities Related Entities and proposes a method to extract them, referred to as Related Entity Extraction.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Learning Omnidirectional Locomotion for a Salamander-Like Quadruped Robot](https://arxiv.org/abs/2511.08299)
*Zhiang Liu,Yang Liu,Yongchun Fang,Xian Guo*

Main category: cs.RO

TL;DR: 提出了一种学习框架，使蝾螈样四足机器人无需参考运动即可获得多种全向步态，通过相位变量控制和形态对称性增强实现灵活运动。


<details>
  <summary>Details</summary>
Motivation: 现有控制器无法充分利用蝾螈样机器人的形态特征，主要依赖预定义的步态模式或关节轨迹，限制了在真实场景中的多样性和灵活性。

Method: 使用能够前后演化的相位变量控制每个身体部位，通过相位覆盖奖励促进腿部相位空间探索，并利用形态对称性进行数据增强。

Result: 机器人成功获得了22种全向步态，展现出动态和对称的运动，证明了学习框架的有效性。

Conclusion: 该学习框架能够有效生成多样化的全向步态，提高了机器人在真实环境中的适用性。

Abstract: Salamander-like quadruped robots are designed inspired by the skeletal structure of their biological counterparts. However, existing controllers cannot fully exploit these morphological features and largely rely on predefined gait patterns or joint trajectories, which prevents the generation of diverse and flexible locomotion and limits their applicability in real-world scenarios. In this paper, we propose a learning framework that enables the robot to acquire a diverse repertoire of omnidirectional gaits without reference motions. Each body part is controlled by a phase variable capable of forward and backward evolution, with a phase coverage reward to promote the exploration of the leg phase space. Additionally, morphological symmetry of the robot is incorporated via data augmentation, improving sample efficiency and enforcing both motion-level and task-level symmetry in learned behaviors. Extensive experiments show that the robot successfully acquires 22 omnidirectional gaits exhibiting both dynamic and symmetric movements, demonstrating the effectiveness of the proposed learning framework.

</details>
