<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
*Chirag Seth,Divya Naiken,Keyan Lin*

Main category: cs.CV

TL;DR: 研究利用事件相机和深度学习（CNN_LSTM模型）实现低成本高精度眼动追踪，准确率达81%，未来计划通过LRP提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 快速眼动（300度/秒）需昂贵高速相机，研究旨在开发低成本算法以提升VR/AR设备的用户体验。

Method: 采用CNN_LSTM模型结合事件相机数据定位眼球中心位置。

Result: 模型准确率约81%，验证了方法的有效性。

Conclusion: 未来将通过LRP进一步优化模型可解释性和性能。

Abstract: This research project addresses the challenge of accurately tracking eye
movements during specific events by leveraging previous research. Given the
rapid movements of human eyes, which can reach speeds of 300{\deg}/s, precise
eye tracking typically requires expensive and high-speed cameras. Our primary
objective is to locate the eye center position (x, y) using inputs from an
event camera. Eye movement analysis has extensive applications in consumer
electronics, especially in VR and AR product development. Therefore, our
ultimate goal is to develop an interpretable and cost-effective algorithm using
deep learning methods to predict human attention, thereby improving device
comfort and enhancing overall user experience. To achieve this goal, we
explored various approaches, with the CNN\_LSTM model proving most effective,
achieving approximately 81\% accuracy. Additionally, we propose future work
focusing on Layer-wise Relevance Propagation (LRP) to further enhance the
model's interpretability and predictive performance.

</details>


### [2] [FedGIN: Federated Learning with Dynamic Global Intensity Non-linear Augmentation for Organ Segmentation using Multi-modal Images](https://arxiv.org/abs/2508.05137)
*Sachin Dudda Nagaraju,Ashkan Moradi,Bendik Skarre Abrahamsen,Mattijs Elschot*

Main category: cs.CV

TL;DR: FedGIN是一个联邦学习框架，通过全局强度非线性增强模块（GIN）实现多模态医学图像分割，无需共享原始数据，显著提升了跨模态泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中数据稀缺、模态间域偏移和隐私限制等问题，开发一个统一且泛化能力强的模型以优化临床工作流程。

Method: 提出FedGIN框架，结合GIN模块在本地训练中协调模态强度分布，并在有限数据集和完整数据集两种场景下进行评估。

Result: 在有限数据场景下，FedGIN比无GIN的联邦学习在MRI测试中提升12-18%的3D Dice分数；在完整数据场景下，性能接近集中式训练，跨模态泛化能力显著。

Conclusion: FedGIN在隐私保护下有效提升多模态医学图像分割性能，为临床决策提供可靠支持。

Abstract: Medical image segmentation plays a crucial role in AI-assisted diagnostics,
surgical planning, and treatment monitoring. Accurate and robust segmentation
models are essential for enabling reliable, data-driven clinical decision
making across diverse imaging modalities. Given the inherent variability in
image characteristics across modalities, developing a unified model capable of
generalizing effectively to multiple modalities would be highly beneficial.
This model could streamline clinical workflows and reduce the need for
modality-specific training. However, real-world deployment faces major
challenges, including data scarcity, domain shift between modalities (e.g., CT
vs. MRI), and privacy restrictions that prevent data sharing. To address these
issues, we propose FedGIN, a Federated Learning (FL) framework that enables
multimodal organ segmentation without sharing raw patient data. Our method
integrates a lightweight Global Intensity Non-linear (GIN) augmentation module
that harmonizes modality-specific intensity distributions during local
training. We evaluated FedGIN using two types of datasets: an imputed dataset
and a complete dataset. In the limited dataset scenario, the model was
initially trained using only MRI data, and CT data was added to assess its
performance improvements. In the complete dataset scenario, both MRI and CT
data were fully utilized for training on all clients. In the limited-data
scenario, FedGIN achieved a 12 to 18% improvement in 3D Dice scores on MRI test
cases compared to FL without GIN and consistently outperformed local baselines.
In the complete dataset scenario, FedGIN demonstrated near-centralized
performance, with a 30% Dice score improvement over the MRI-only baseline and a
10% improvement over the CT-only baseline, highlighting its strong
cross-modality generalization under privacy constraints.

</details>


### [3] [ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking](https://arxiv.org/abs/2508.05221)
*Xiao Wang,Liye Jin,Xufeng Lou,Shiao Wang,Lan Chen,Bo Jiang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于推理的视觉语言跟踪框架ReasoningTrack，结合预训练模型Qwen2.5-VL，通过SFT和GRPO优化推理与语言生成，并构建了大规模数据集TNLLT验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言跟踪方法在目标变化适应性和推理过程透明度上的不足，充分利用大模型优势。

Method: 使用预训练模型Qwen2.5-VL，结合SFT和GRPO优化推理与语言生成，嵌入更新的语言描述与视觉特征，通过跟踪头预测目标位置。

Result: 在多个基准数据集上验证了推理式自然语言生成策略的有效性，并构建了TNLLT数据集。

Conclusion: ReasoningTrack框架显著提升了视觉语言跟踪的性能，为未来研究提供了新方向。

Abstract: Vision-language tracking has received increasing attention in recent years,
as textual information can effectively address the inflexibility and inaccuracy
associated with specifying the target object to be tracked. Existing works
either directly fuse the fixed language with vision features or simply modify
using attention, however, their performance is still limited. Recently, some
researchers have explored using text generation to adapt to the variations in
the target during tracking, however, these works fail to provide insights into
the model's reasoning process and do not fully leverage the advantages of large
models, which further limits their overall performance. To address the
aforementioned issues, this paper proposes a novel reasoning-based
vision-language tracking framework, named ReasoningTrack, based on a
pre-trained vision-language model Qwen2.5-VL. Both SFT (Supervised Fine-Tuning)
and reinforcement learning GRPO are used for the optimization of reasoning and
language generation. We embed the updated language descriptions and feed them
into a unified tracking backbone network together with vision features. Then,
we adopt a tracking head to predict the specific location of the target object.
In addition, we propose a large-scale long-term vision-language tracking
benchmark dataset, termed TNLLT, which contains 200 video sequences. 20
baseline visual trackers are re-trained and evaluated on this dataset, which
builds a solid foundation for the vision-language visual tracking task.
Extensive experiments on multiple vision-language tracking benchmark datasets
fully validated the effectiveness of our proposed reasoning-based natural
language generation strategy. The source code of this paper will be released on
https://github.com/Event-AHU/Open_VLTrack

</details>


### [4] [Revealing Latent Information: A Physics-inspired Self-supervised Pre-training Framework for Noisy and Sparse Events](https://arxiv.org/abs/2508.05507)
*Lin Zhu,Ruonan Liu,Xiao Wang,Lizhi Wang,Hua Huang*

Main category: cs.CV

TL;DR: 提出了一种自监督预训练框架，用于从稀疏且嘈杂的事件数据中提取潜在信息，包括边缘和纹理线索，并在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 事件数据具有高时间分辨率和宽动态范围，但其稀疏性和噪声特性使得特征提取困难。

Method: 框架包含三个阶段：差异引导掩码建模、主干固定的特征转换和聚焦对比学习。

Result: 在物体识别、语义分割和光流估计等任务中优于现有方法。

Conclusion: 该框架能有效提取事件数据的潜在信息，提升下游任务性能。

Abstract: Event camera, a novel neuromorphic vision sensor, records data with high
temporal resolution and wide dynamic range, offering new possibilities for
accurate visual representation in challenging scenarios. However, event data is
inherently sparse and noisy, mainly reflecting brightness changes, which
complicates effective feature extraction. To address this, we propose a
self-supervised pre-training framework to fully reveal latent information in
event data, including edge information and texture cues. Our framework consists
of three stages: Difference-guided Masked Modeling, inspired by the event
physical sampling process, reconstructs temporal intensity difference maps to
extract enhanced information from raw event data. Backbone-fixed Feature
Transition contrasts event and image features without updating the backbone to
preserve representations learned from masked modeling and stabilizing their
effect on contrastive learning. Focus-aimed Contrastive Learning updates the
entire model to improve semantic discrimination by focusing on high-value
regions. Extensive experiments show our framework is robust and consistently
outperforms state-of-the-art methods on various downstream tasks, including
object recognition, semantic segmentation, and optical flow estimation. The
code and dataset are available at https://github.com/BIT-Vision/EventPretrain.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 提出了一种名为EPOPR的公平感知电力恢复策略，通过预测-优化框架解决现有方法的不公平问题，显著减少停电时间和社区间不平等。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件频发，现有电力恢复决策基于请求量，导致弱势社区请求较少，恢复不公平。

Method: 设计EPOPR框架，包含不确定性修复时间预测和时空注意力强化学习，平衡效率与公平。

Result: 实验显示EPOPR平均减少停电时间3.60%，降低社区间不平等14.19%。

Conclusion: EPOPR有效提升电力恢复的公平性和效率，适用于极端天气事件下的电力系统。

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [6] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: 提出了一种统一的流匹配框架，用于非自回归建模事件序列，显著提升了长范围预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有自回归模型在长范围事件序列预测中的效率低和误差累积问题。

Method: 采用连续和离散流匹配技术，联合建模事件间隔时间和事件类型。

Result: 在六个真实世界基准测试中，模型在准确性和生成效率上均优于自回归和基于扩散的基线方法。

Conclusion: 提出的流匹配框架为长范围标记事件序列建模提供了高效且准确的解决方案。

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [7] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
*Zhehan Qu,Tianyi Hu,Christian Fronk,Maria Gorlatova*

Main category: cs.LG

TL;DR: 研究探讨了AR系统在CPR任务中如何影响情境意识（SA），并通过眼动追踪和机器学习模型预测SA水平。


<details>
  <summary>Details</summary>
Motivation: AR系统虽能提升任务表现，但可能导致认知隧道效应，降低SA，尤其在安全关键场景（如CPR）中需平衡虚拟指导和现实警觉。

Method: 开发了AR应用（Magic Leap 2），提供实时CPR反馈，并通过用户研究（模拟意外事件）收集SA数据，结合眼动分析和FixGraphPool模型预测SA。

Result: 高SA水平与更大的眼跳幅度和速度相关，且虚拟内容注视比例更低。FixGraphPool模型预测SA准确率达83.0%，优于其他方法。

Conclusion: 眼动追踪可用于AR中的SA建模，为设计兼顾安全和SA的AR系统提供依据。

Abstract: Augmented Reality (AR) systems, while enhancing task performance through
real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on
virtual content that compromises situational awareness (SA) in safety-critical
scenarios. This paper investigates SA in AR-guided cardiopulmonary
resuscitation (CPR), where responders must balance effective compressions with
vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR
app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth
and rate) and conducted a user study with simulated unexpected incidents (e.g.,
bleeding) to evaluate SA, in which SA metrics were collected via observation
and questionnaires administered during freeze-probe events. Eye tracking
analysis revealed that higher SA levels were associated with greater saccadic
amplitude and velocity, and with reduced proportion and frequency of fixations
on virtual content. To predict SA, we propose FixGraphPool, a graph neural
network that structures gaze events (fixations, saccades) into spatiotemporal
graphs, effectively capturing dynamic attentional patterns. Our model achieved
83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and
state-of-the-art time-series models by leveraging domain knowledge and
spatial-temporal information encoded in ET data. These findings demonstrate the
potential of eye tracking for SA modeling in AR and highlight its utility in
designing AR systems that ensure user safety and situational awareness.

</details>


### [8] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
*Yue Duan,Taicai Chen,Lei Qi,Yinghuan Shi*

Main category: cs.LG

TL;DR: USP框架通过分而治之的方法提升半监督持续学习（SSCL）中的学习可塑性、无标签学习和记忆稳定性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 减少标注成本并应对持续数据流入的挑战，同时平衡无标签学习、记忆稳定性和学习可塑性。

Method: USP框架包含三个策略：特征空间保留（FSR）用于学习可塑性，分而治之伪标签（DCP）用于无标签学习，类均值锚定无标签蒸馏（CUD）用于记忆稳定性。

Result: USP在最终准确率上比现有方法提升高达5.94%。

Conclusion: USP框架有效解决了SSCL中的关键问题，验证了其优越性。

Abstract: Semi-supervised continual learning (SSCL) seeks to leverage both labeled and
unlabeled data in a sequential learning setup, aiming to reduce annotation
costs while managing continual data arrival. SSCL introduces complex
challenges, including ensuring effective unlabeled learning (UL), while
balancing memory stability (MS) and learning plasticity (LP). Previous SSCL
efforts have typically focused on isolated aspects of the three, while this
work presents USP, a divide-and-conquer framework designed to synergistically
enhance these three aspects: (1) Feature Space Reservation (FSR) strategy for
LP, which constructs reserved feature locations for future classes by shaping
old classes into an equiangular tight frame; (2) Divide-and-Conquer
Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels
across both high- and low-confidence unlabeled data; and (3)
Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's
outputs to anchor unlabeled data to stable class means for distillation to
prevent forgetting. Comprehensive evaluations show USP outperforms prior SSCL
methods, with gains up to 5.94% in the last accuracy, validating its
effectiveness. The code is available at https://github.com/NJUyued/USP4SSCL.

</details>


### [9] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
*Vincent Jeanselme,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 论文指出将竞争风险视为截尾数据会导致生存估计的显著偏差，并加剧不公平性，提出了量化误差的框架，并强调在生存模型中考虑竞争风险的重要性。


<details>
  <summary>Details</summary>
Motivation: 准确的时间到事件预测对决策至关重要，但现有方法常将竞争风险误认为截尾数据，导致偏差和不公平。

Method: 通过理论分析量化将竞争风险视为截尾数据的误差，并开发框架评估其对预测性能和算法公平性的影响。

Result: 研究发现忽略竞争风险会系统性高估风险并加剧群体间的不公平性，尤其在心血管管理数据中表现明显。

Conclusion: 在生存模型中必须考虑竞争风险以提高准确性、减少评估偏差，并改善决策的公平性。

Abstract: Accurate time-to-event prediction is integral to decision-making, informing
medical guidelines, hiring decisions, and resource allocation. Survival
analysis, the quantitative framework used to model time-to-event data, accounts
for patients who do not experience the event of interest during the study
period, known as censored patients. However, many patients experience events
that prevent the observation of the outcome of interest. These competing risks
are often treated as censoring, a practice frequently overlooked due to a
limited understanding of its consequences. Our work theoretically demonstrates
why treating competing risks as censoring introduces substantial bias in
survival estimates, leading to systematic overestimation of risk and,
critically, amplifying disparities. First, we formalize the problem of
misclassifying competing risks as censoring and quantify the resulting error in
survival estimates. Specifically, we develop a framework to estimate this error
and demonstrate the associated implications for predictive performance and
algorithmic fairness. Furthermore, we examine how differing risk profiles
across demographic groups lead to group-specific errors, potentially
exacerbating existing disparities. Our findings, supported by an empirical
analysis of cardiovascular management, demonstrate that ignoring competing
risks disproportionately impacts the individuals most at risk of these events,
potentially accentuating inequity. By quantifying the error and highlighting
the fairness implications of the common practice of considering competing risks
as censoring, our work provides a critical insight into the development of
survival models: practitioners must account for competing risks to improve
accuracy, reduce disparities in risk assessment, and better inform downstream
decisions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预防性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以避免灾难性故障并优化运行效率，传统方法仅能检测异常，无法提供具体维护建议。

Method: 系统将轴承振动数据（BPFO、BPFI、BSF、FTF频率）序列化为自然语言供LLM处理，结合多代理组件分析维护手册和网络信息，生成结构化维护建议。

Result: 实验验证表明，系统能有效检测异常并提供上下文相关的维护指导，填补了状态监测与可操作维护计划之间的空白。

Conclusion: 该研究推动了LLM在工业维护中的应用，为跨机械组件和工业领域的预防性维护提供了可扩展框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [11] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 本文提出了一种基于异构图神经网络（HGNN）的方法，用于修复过程挖掘中事件日志的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实中的事件日志常因数据采集问题导致信息缺失，现有方法或依赖过程模型，或仅修复部分属性，无法全面解决问题。

Method: 开发了一种HGNN模型，能够处理不完整事件，并修复所有缺失属性。

Result: 在合成和真实日志上测试，该方法在修复所有事件属性方面表现优异。

Conclusion: HGNN为事件日志修复提供了更全面、高效的解决方案。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [12] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）正在改变有机合成中化学家的反应规划和执行方式，结合图神经网络、量子计算和实时光谱等技术，加速发现周期并推动绿色化学。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何从理论工具发展为实验室实用伙伴，推动数据驱动的化学研究。

Method: 结合LLMs与图神经网络、量子计算和实时光谱技术，优化合成路线和反应预测。

Result: 缩短发现周期，支持绿色化学，但仍存在数据集偏见、推理不透明等限制。

Conclusion: 通过开放基准、联邦学习和可解释界面等社区倡议，确保人类控制下实现快速、可靠且包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出了一种基于视觉语言聚类的框架，用于解决动作识别评估中动词语义模糊的问题，比传统方法更符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 由于动词语义和图像解释的模糊性，传统精确匹配评估方法无法全面评估模型性能。

Method: 采用视觉语言聚类框架构建动词意义簇，分析imSitu数据集，评估多个动作识别模型。

Result: 每张图像平均映射到2.8个意义簇，聚类评估更符合人类判断。

Conclusion: 聚类评估方法能更全面地评估模型性能，优于传统方法。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [14] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 提出了一种多阶段大语言模型框架，用于从非结构化文本中提取社会健康决定因素（SDoH），提升自杀事件相关分析的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决自杀事件中SDoH因素提取的挑战，如长尾分布、关键压力源分析和模型可解释性不足。

Method: 采用多阶段大语言模型框架，并与BioBERT、GPT-3.5-turbo和DeepSeek-R1等模型对比，结合用户研究评估。

Result: 框架在SDoH因素提取和相关上下文检索任务中表现更优，且小规模任务专用模型性能相当但成本更低。

Conclusion: 该方法提高了从非结构化文本中提取自杀相关SDoH的准确性和透明度，有助于早期风险识别和预防策略制定。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [15] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: 提出了一种名为CGRS的方法，通过动态抑制大语言模型中的冗余反思行为，减少推理成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长链推理中因过度反思导致的冗余推理步骤问题，提升实用性和效率。

Method: CGRS方法动态抑制高置信度时的反思触发词生成，无需重新训练或修改架构。

Result: 在多个基准测试中，CGRS平均减少18.5%至41.9%的token使用，同时保持准确性。

Conclusion: CGRS是一种高效且通用的方法，适用于不同规模和架构的模型，具有实际应用价值。

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [16] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: 论文提出了一种名为LAG的新方法，通过逻辑分解和依赖感知推理增强语言模型的知识密集型任务表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型任务中存在幻觉问题，现有检索增强生成方法在复杂推理场景中表现不足。

Method: LAG将复杂问题分解为原子子问题，按逻辑依赖顺序解决，并引入逻辑终止机制防止错误传播。

Result: 实验表明LAG显著提升了推理鲁棒性，减少了幻觉，并更贴近人类认知。

Conclusion: LAG为现有RAG系统提供了一种更原则性的替代方案。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [17] [On the causality between affective impact and coordinated human-robot reactions](https://arxiv.org/abs/2508.04834)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 研究机器人通过共享事件反应对人类感知的影响，发现200ms延迟对小型非人形机器人最有效，100ms延迟则让人感觉对机器人影响最大。


<details>
  <summary>Details</summary>
Motivation: 改善机器人在社交环境中的表现，探究机器人共享事件反应是否影响人类对其情感影响的感知。

Method: 设计两个实验：一个隔离机器人情感表达的反应元素，另一个测试不同反应延迟时间对物理互动的影响。

Result: 机器人共享事件反应显著改变人类感知（p<0.05），200ms延迟最有效，100ms延迟让人感觉对机器人影响最大。

Conclusion: 200ms延迟对小型非人形机器人最有效，100ms延迟则让人感觉对机器人影响最大。

Abstract: In an effort to improve how robots function in social contexts, this paper
investigates if a robot that actively shares a reaction to an event with a
human alters how the human perceives the robot's affective impact. To verify
this, we created two different test setups. One to highlight and isolate the
reaction element of affective robot expressions, and one to investigate the
effects of applying specific timing delays to a robot reacting to a physical
encounter with a human. The first test was conducted with two different groups
(n=84) of human observers, a test group and a control group both interacting
with the robot. The second test was performed with 110 participants using
increasingly longer reaction delays for the robot with every ten participants.
The results show a statistically significant change (p$<$.05) in perceived
affective impact for the robots when they react to an event shared with a human
observer rather than reacting at random. The result also shows for shared
physical interaction, the near-human reaction times from the robot are most
appropriate for the scenario. The paper concludes that a delay time around
200ms may render the biggest impact on human observers for small-sized
non-humanoid robots. It further concludes that a slightly shorter reaction time
around 100ms is most effective when the goal is to make the human observers
feel they made the biggest impact on the robot.

</details>
