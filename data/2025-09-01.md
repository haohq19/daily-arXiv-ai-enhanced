<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Radially Distorted Homographies, Revisited](https://arxiv.org/abs/2508.21190)
*Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt*

Main category: cs.CV

TL;DR: 本文提出了一种统一的方法来解决三种不同配置的径向畸变单应性估计问题，相比现有方法在保持精度的同时实现了更快的计算速度。


<details>
  <summary>Details</summary>
Motivation: 在实际图像处理中，相机镜头引起的几何畸变（特别是径向畸变）会影响单应性估计的准确性。传统方法需要分别处理三种不同的畸变配置，缺乏统一解决方案。

Method: 提出了一种新颖的统一方法，能够同时处理三种径向畸变配置：单图像畸变、两图像相同畸变和两图像独立畸变。基于该方法构建了快速、稳定且准确的最小求解器。

Result: 在所有三种情况下，提出的求解器都比现有最先进方法更快，同时保持相似的精度。在包括鱼眼相机图像在内的标准基准测试中表现优异。

Conclusion: 该方法为径向畸变单应性估计提供了一个统一的框架，显著提高了计算效率，适用于各种实际计算机视觉任务。

Abstract: Homographies are among the most prevalent transformations occurring in
geometric computer vision and projective geometry, and homography estimation is
consequently a crucial step in a wide assortment of computer vision tasks. When
working with real images, which are often afflicted with geometric distortions
caused by the camera lens, it may be necessary to determine both the homography
and the lens distortion-particularly the radial component, called radial
distortion-simultaneously to obtain anything resembling useful estimates. When
considering a homography with radial distortion between two images, there are
three conceptually distinct configurations for the radial distortion; (i)
distortion in only one image, (ii) identical distortion in the two images, and
(iii) independent distortion in the two images. While these cases have been
addressed separately in the past, the present paper provides a novel and
unified approach to solve all three cases. We demonstrate how the proposed
approach can be used to construct new fast, stable, and accurate minimal
solvers for radially distorted homographies. In all three cases, our proposed
solvers are faster than the existing state-of-the-art solvers while maintaining
similar accuracy. The solvers are tested on well-established benchmarks
including images taken with fisheye cameras. The source code for our solvers
will be made available in the event our paper is accepted for publication.

</details>


### [2] [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](https://arxiv.org/abs/2508.21496)
*Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu*

Main category: cs.CV

TL;DR: 该论文提出了ELV-Halluc基准，专门针对长视频多模态大语言模型的语义聚合幻觉问题，发现语义复杂度和语义变化速度是主要影响因素，并通过位置编码和DPO策略有效减少了27.7%的SAH比例。


<details>
  <summary>Details</summary>
Motivation: 现有视频多模态大语言模型存在幻觉问题，特别是在长视频中语义聚合过程中产生的语义聚合幻觉(SAH)，而之前的基准主要关注短视频，未能充分研究这种复杂幻觉类型。

Method: 构建ELV-Halluc长视频幻觉基准，系统研究SAH现象；分析语义复杂度和语义变化速度对SAH的影响；采用位置编码策略和DPO（直接偏好优化）策略来缓解SAH问题。

Result: 实验证实了SAH的存在，并发现其随语义复杂度增加而增加；模型在快速变化的语义上更容易产生SAH；通过位置编码和DPO策略在ELV-Halluc和Video-MME基准上均取得改进，SAH比例显著降低27.7%。

Conclusion: SAH是长视频理解中的重要幻觉类型，需要专门的基准和方法来应对；位置编码和DPO策略能有效缓解SAH问题，为提升长视频多模态模型的可靠性提供了有效途径。

Abstract: Video multimodal large language models (Video-MLLMs) have achieved remarkable
progress in video understanding. However, they remain vulnerable to
hallucination-producing content inconsistent with or unrelated to video inputs.
Previous video hallucination benchmarks primarily focus on short-videos. They
attribute hallucinations to factors such as strong language priors, missing
frames, or vision-language biases introduced by the visual encoder. While these
causes indeed account for most hallucinations in short videos, they still
oversimplify the cause of hallucinations. Sometimes, models generate incorrect
outputs but with correct frame-level semantics. We refer to this type of
hallucination as Semantic Aggregation Hallucination (SAH), which arises during
the process of aggregating frame-level semantics into event-level semantic
groups. Given that SAH becomes particularly critical in long videos due to
increased semantic complexity across multiple events, it is essential to
separate and thoroughly investigate the causes of this type of hallucination.
To address the above issues, we introduce ELV-Halluc, the first benchmark
dedicated to long-video hallucination, enabling a systematic investigation of
SAH. Our experiments confirm the existence of SAH and show that it increases
with semantic complexity. Additionally, we find that models are more prone to
SAH on rapidly changing semantics. Moreover, we discuss potential approaches to
mitigate SAH. We demonstrate that positional encoding strategy contributes to
alleviating SAH, and further adopt DPO strategy to enhance the model's ability
to distinguish semantics within and across events. To support this, we curate a
dataset of 8K adversarial data pairs and achieve improvements on both
ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.

</details>


### [3] [The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](https://arxiv.org/abs/2508.21816)
*Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin*

Main category: cs.CV

TL;DR: 本文揭示了场景识别中动词分类本质上是多标签问题，提出了单正例多标签学习框架和GE-VerbMLP模型，在保持传统指标竞争力的同时实现了3%以上的MAP提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法将动词分类视为单标签问题，但视觉事件识别存在固有歧义性，同一图像可能被多个动词类别合理描述，需要重新审视这一设定。

Method: 将动词分类重新定义为单正例多标签学习(SPMLL)问题，提出Graph Enhanced Verb MLP模型，结合图神经网络捕捉标签相关性和对抗训练优化决策边界。

Result: 在真实数据集上的大量实验表明，该方法在保持传统top-1和top-5准确率竞争力的同时，实现了超过3%的平均精度均值(MAP)提升。

Conclusion: 动词分类本质上是多标签问题，SPMLL框架和GE-VerbMLP模型能有效处理场景识别中的语义重叠问题，为多标签评估提供了新的基准。

Abstract: Context recognition (SR) is a fundamental task in computer vision that aims
to extract structured semantic summaries from images by identifying key events
and their associated entities. Specifically, given an input image, the model
must first classify the main visual events (verb classification), then identify
the participating entities and their semantic roles (semantic role labeling),
and finally localize these entities in the image (semantic role localization).
Existing methods treat verb classification as a single-label problem, but we
show through a comprehensive analysis that this formulation fails to address
the inherent ambiguity in visual event recognition, as multiple verb categories
may reasonably describe the same image. This paper makes three key
contributions: First, we reveal through empirical analysis that verb
classification is inherently a multi-label problem due to the ubiquitous
semantic overlap between verb categories. Second, given the impracticality of
fully annotating large-scale datasets with multiple labels, we propose to
reformulate verb classification as a single positive multi-label learning
(SPMLL) problem - a novel perspective in SR research. Third, we design a
comprehensive multi-label evaluation benchmark for SR that is carefully
designed to fairly evaluate model performance in a multi-label setting. To
address the challenges of SPMLL, we futher develop the Graph Enhanced Verb
Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to
capture label correlations and adversarial training to optimize decision
boundaries. Extensive experiments on real-world datasets show that our approach
achieves more than 3\% MAP improvement while remaining competitive on
traditional top-1 and top-5 accuracy metrics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics](https://arxiv.org/abs/2508.21249)
*Mohammad Amin Nabian,Sanjay Choudhry*

Main category: cs.LG

TL;DR: 提出基于混合专家(MoE)的元学习框架，动态整合三种先进CFD代理模型的预测，在汽车空气动力学仿真中显著降低预测误差


<details>
  <summary>Details</summary>
Motivation: 高保真CFD仿真计算成本高，现有ML代理模型架构多样但无单一最优方案，需要利用架构多样性提升预测精度

Method: 使用门控网络动态组合DoMINO、X-MeshGraphNet和FigConvNet三种异构专家模型的预测，加入熵正则化防止模型坍塌

Result: 在DrivAerML数据集上验证，MoE模型L-2预测误差显著降低，优于集成平均和最准确的单个专家模型

Conclusion: MoE框架通过协同整合专业架构的互补优势，为构建更鲁棒准确的复合代理模型提供了有效策略

Abstract: The computational cost associated with high-fidelity CFD simulations remains
a significant bottleneck in the automotive design and optimization cycle. While
ML-based surrogate models have emerged as a promising alternative to accelerate
aerodynamic predictions, the field is characterized by a diverse and rapidly
evolving landscape of specialized neural network architectures, with no single
model demonstrating universal superiority. This paper introduces a novel
meta-learning framework that leverages this architectural diversity as a
strength. We propose a Mixture of Experts (MoE) model that employs a dedicated
gating network to dynamically and optimally combine the predictions from three
heterogeneous, state-of-the-art surrogate models: DoMINO, a decomposable
multi-scale neural operator; X-MeshGraphNet, a scalable multi-scale graph
neural network; and FigConvNet, a factorized implicit global convolution
network. The gating network learns a spatially-variant weighting strategy,
assigning credibility to each expert based on its localized performance in
predicting surface pressure and wall shear stress fields. To prevent model
collapse and encourage balanced expert contributions, we integrate an entropy
regularization term into the training loss function. The entire system is
trained and validated on the DrivAerML dataset, a large-scale, public benchmark
of high-fidelity CFD simulations for automotive aerodynamics. Quantitative
results demonstrate that the MoE model achieves a significant reduction in L-2
prediction error, outperforming not only the ensemble average but also the most
accurate individual expert model across all evaluated physical quantities. This
work establishes the MoE framework as a powerful and effective strategy for
creating more robust and accurate composite surrogate models by synergistically
combining the complementary strengths of specialized architectures.

</details>


### [5] [Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control](https://arxiv.org/abs/2508.21505)
*Vishal Pandey,Debasmita Biswas*

Main category: cs.LG

TL;DR: SNN-DT将脉冲神经网络与决策变换器结合，在保持性能的同时大幅降低能耗，适用于边缘设备


<details>
  <summary>Details</summary>
Motivation: 传统Transformer决策智能体依赖密集矩阵运算，能耗高，不适合能源受限的边缘平台。脉冲神经网络具有超低功耗特性，但尚未与回报条件序列建模无缝融合

Method: 在自注意力块中嵌入Leaky Integrate-and-Fire神经元，通过替代梯度端到端训练，结合生物启发的三因子可塑性、相移脉冲位置编码和轻量级树突路由模块

Result: 在经典控制基准测试中匹配或超越标准决策变换器性能，每个决策发射少于10个脉冲，推理能耗降低超过4个数量级

Conclusion: SNN-DT通过将序列建模与神经形态效率结合，为嵌入式可穿戴设备开辟了实时低功耗控制的新途径

Abstract: Reinforcement learning agents based on Transformer architectures have
achieved impressive performance on sequential decision-making tasks, but their
reliance on dense matrix operations makes them ill-suited for
energy-constrained, edge-oriented platforms. Spiking neural networks promise
ultra-low-power, event-driven inference, yet no prior work has seamlessly
merged spiking dynamics with return-conditioned sequence modeling. We present
the Spiking Decision Transformer (SNN-DT), which embeds Leaky
Integrate-and-Fire neurons into each self-attention block, trains end-to-end
via surrogate gradients, and incorporates biologically inspired three-factor
plasticity, phase-shifted spike-based positional encodings, and a lightweight
dendritic routing module. Our implementation matches or exceeds standard
Decision Transformer performance on classic control benchmarks (CartPole-v1,
MountainCar-v0, Acrobot-v1, Pendulum-v1) while emitting fewer than ten spikes
per decision, an energy proxy suggesting over four orders-of-magnitude
reduction in per inference energy. By marrying sequence modeling with
neuromorphic efficiency, SNN-DT opens a pathway toward real-time, low-power
control on embedded and wearable devices.

</details>


### [6] [Inferring Effects of Major Events through Discontinuity Forecasting of Population Anxiety](https://arxiv.org/abs/2508.21722)
*Siddharth Mangalik,Ojas Deshpande,Adithya V. Ganesan,Sean A. P. Clouston,H. Andrew Schwartz*

Main category: cs.LG

TL;DR: 本文提出将纵向回归断点设计(LRDD)扩展到统计学习框架，用于预测特定事件对社区心理健康的时间特异性影响，包括断点和斜率变化。


<details>
  <summary>Details</summary>
Motivation: 传统心理健康评分预测无法有效评估事件对社区福祉的因果影响，需要从观测数据中提取更可能具有因果关系的效应。

Method: 将LRDD方法扩展到统计学习框架，利用历史评分、动态协变量和外生变量来预测未来的断点(时间特异性变化)和斜率(线性轨迹)变化。

Result: 在预测COVID-19事件对美国县焦虑水平的断点影响时，任务具有挑战性，但随着模型复杂度增加而改善。最佳结果来自整合外生和动态协变量(r=+0.46用于断点预测，r=+0.65用于斜率预测)，显著优于传统静态社区表示方法。

Conclusion: 断点预测为估计未来或假设事件对特定社区的异质性影响提供了新的可能性，展示了统计学习框架在因果推断中的价值。

Abstract: Estimating community-specific mental health effects of local events is vital
for public health policy. While forecasting mental health scores alone offers
limited insights into the impact of events on community well-being,
quasi-experimental designs like the Longitudinal Regression Discontinuity
Design (LRDD) from econometrics help researchers derive more effects that are
more likely to be causal from observational data. LRDDs aim to extrapolate the
size of changes in an outcome (e.g. a discontinuity in running scores for
anxiety) due to a time-specific event. Here, we propose adapting LRDDs beyond
traditional forecasting into a statistical learning framework whereby future
discontinuities (i.e. time-specific shifts) and changes in slope (i.e. linear
trajectories) are estimated given a location's history of the score, dynamic
covariates (other running assessments), and exogenous variables (static
representations). Applying our framework to predict discontinuities in the
anxiety of US counties from COVID-19 events, we found the task was difficult
but more achievable as the sophistication of models was increased, with the
best results coming from integrating exogenous and dynamic covariates. Our
approach shows strong improvement ($r=+.46$ for discontinuity and $r = +.65$
for slope) over traditional static community representations. Discontinuity
forecasting raises new possibilities for estimating the idiosyncratic effects
of potential future or hypothetical events on specific communities.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个新的多模态搜索基准测试，包含311个需要深度视觉推理的任务，旨在解决现有基准测试中浅层工作流的问题，通过空间-时间外推法构建需要从局部视觉线索推断出图像外事实的复杂任务。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态浏览基准测试往往可以通过浅层、固定的工作流程解决，依赖于高召回率的图像搜索和邻近文本匹配，无法真正测试细粒度视觉推理、来源验证和长时程工具使用等真正的多模态挑战。

Method: 采用空间-时间外推法构建基准测试，每个任务包含多个弱局部视觉信号，需要通过迭代的文本-图像搜索进行提取和传播，并在检索噪声下进行交叉验证。提供了一个模型无关的代理框架和浏览工具。

Result: 最强代理(o3)在没有搜索的情况下达到15.1%准确率，在框架下通过搜索达到36.0%准确率；最强的开源模型(Qwen-2.5-VL-72B-Instruct)在没有搜索时为0.0%，经过20轮搜索后达到6.9%。

Conclusion: 该基准测试揭示了当前MLLM在来源验证、基于部件的推理和长时程规划方面的失败，为评估真正多模态理解能力提供了重要工具。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [8] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架，结合传统网络优化模型和大语言模型，为供应链规划提供交互式、可解释性和角色感知的决策支持系统。


<details>
  <summary>Details</summary>
Motivation: 弥补复杂运算研究输出与业务利益相关者理解之间的差距，通过自然语言摘要、上下文可视化和定制关键性能指标来提升决策可理解性。

Method: 核心优化模型采用混合整数规划法，处理多周期多物品在分销中心网络中的战术性库存重新分配。技术架构包含AI代理、RESTful API和动态用户界面，支持实时交互、配置更新和基于模拟的洞察。

Result: 案例研究表明，该系统能够通过防止缺货、降低成本和维持服务水平来改善规划结果。

Conclusion: 未来扩展包括集成私有大语言模型、迁移学习、强化学习和贝叶斯神经网络，以提升系统的可解释性、适应性和实时决策能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2508.21201)
*Arash Ahmadi,Sarah Sharif,Yaser Banad*

Main category: cs.CL

TL;DR: 基于GRPO强化学习的自动化HFACS分析框架，通过精调Llama-3.1 8B模型在航空安全分析中实现了显著性能提升，超越了GPT-5-mini等独立模型


<details>
  <summary>Details</summary>
Motivation: 传统HFACS人因分析方法存在扩展性和一致性问题，需要自动化解决方案来提高航空安全分析的效率和准确性

Method: 使用基于GRPO强化学习算法精调Llama-3.1 8B语言模型，构建多组件奖励系统，集成合成数据生成技术解决类别不平衡问题

Result: 模型性能显著提升，精确匹配准确度提高350%（从0.0400到0.1800），部分匹配准确度达到0.8800，超越GPT-5-mini等独立模型

Conclusion: 领域优化的小型模型能够提供计算效率更高、性能更好的解决方案，适合在资源受限边缘设处上部署

Abstract: Analyzing the human factors behind aviation accidents is crucial for
preventing future incidents, yet traditional methods using the Human Factors
Analysis and Classification System (HFACS) are limited by scalability and
consistency. To address this, we introduce an automated HFACS classification
framework for aviation safety analysis that utilizes Reinforcement Learning
with Group Relative Policy Optimization (GRPO) to fine-tune a Llama-3.1 8B
language model. Our approach incorporates a multi-component reward system
tailored for aviation safety analysis and integrates synthetic data generation
to overcome class imbalance in accident datasets. The resulting GRPO-optimized
model achieved noticeable performance gains, including a 350% increase in exact
match accuracy (from 0.0400 to 0.1800) and an improved partial match accuracy
of 0.8800. Significantly, our specialized model outperforms state-of-the-art
LLMs (Large Language Models), including GPT-5-mini and Gemini-2.5-fiash, on key
metrics. This research also proposes exact match accuracy in multi-label HFACS
classification problem as a new benchmarking methodology to evaluate the
advanced reasoning capabilities of language models. Ultimately, our work
validates that smaller, domain-optimized models can provide a computationally
efficient and better solution for critical safety analysis. This approach makes
powerful, low-latency deployment on resource-constrained edge devices feasible.

</details>


### [10] [Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance](https://arxiv.org/abs/2508.21741)
*Yao Wang,Di Liang,Minlong Peng*

Main category: cs.CL

TL;DR: 核参数隔离精细调整框架(CPI-FT)通过识别任务核心参数区域、任务分组和参数融合技术，有效缓解多任务精细调整中的任务干扰和恐怖遗忘问题


<details>
  <summary>Details</summary>
Motivation: 解决监督式精细调整(SFT)中的"泵泵板现象"，即不区分性的参数更新导致某些任务性能提升以损害其他任务为代价

Method: 1、单任务精细调整识别核心参数区域 2、根据核心区域重叠进行任务分组 3、核心参数直接移植，非核心参数通过球面线性插值(SLERP)融合 4、轻量级流水线精细调整阶段，冻结以前任务的核心区域

Result: 在多个公开测试集上的实验表明，该方法显著缓解任务干扰和恐怖遗忘问题，一贵超过普通多任务和多阶段精细调整基线方法

Conclusion: CPI-FT框架通过核心参数隔离和融合策略，有效解决了多任务精细调整中的性能冒险问题，为大语言模型的下游任务适配提供了有效觤决方案

Abstract: Supervised fine-tuning (SFT) is a pivotal approach to adapting large language
models (LLMs) for downstream tasks; however, performance often suffers from the
``seesaw phenomenon'', where indiscriminate parameter updates yield progress on
certain tasks at the expense of others. To address this challenge, we propose a
novel \emph{Core Parameter Isolation Fine-Tuning} (CPI-FT) framework.
Specifically, we first independently fine-tune the LLM on each task to identify
its core parameter regions by quantifying parameter update magnitudes. Tasks
with similar core regions are then grouped based on region overlap, forming
clusters for joint modeling. We further introduce a parameter fusion technique:
for each task, core parameters from its individually fine-tuned model are
directly transplanted into a unified backbone, while non-core parameters from
different tasks are smoothly integrated via Spherical Linear Interpolation
(SLERP), mitigating destructive interference. A lightweight, pipelined SFT
training phase using mixed-task data is subsequently employed, while freezing
core regions from prior tasks to prevent catastrophic forgetting. Extensive
experiments on multiple public benchmarks demonstrate that our approach
significantly alleviates task interference and forgetting, consistently
outperforming vanilla multi-task and multi-stage fine-tuning baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?](https://arxiv.org/abs/2508.21690)
*Olger Siebinga,David Abbink*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的方法，让机器人学习如何与行人互动以避免"人行道莎莎舞"的尴尬情况，通过利用CEI模型成功实现了意图沟通和风险降低。


<details>
  <summary>Details</summary>
Motivation: 研究行人之间的"人行道莎莎舞"现象可以为机器人与行人互动提供重要见解，理解这种隐式沟通失败的原因有助于设计更安全、更可接受的机器人行为。

Method: 使用强化学习（RL）代理利用先前开发的Communication-Enabled Interaction（CEI）框架模型，学习如何与行人互动，包括基本RL代理和能够感知CEI模型风险的风险规避RL代理。

Result: 基本RL代理成功学会了与CEI模型互动，风险规避RL代理通过动作有效沟通意图，显著降低了感知风险，并显示了建模行人的努力。

Conclusion: 这种方法显示出很好的前景，鼓励进一步探索使用强化学习来改善机器人与行人之间的隐式沟通和互动安全性。

Abstract: Pedestrians approaching each other on a sidewalk sometimes end up in an
awkward interaction known as the "sidewalk salsa": they both (repeatedly)
deviate to the same side to avoid a collision. This provides an interesting use
case to study interactions between pedestrians and mobile robots because, in
the vast majority of cases, this phenomenon is avoided through a negotiation
based on implicit communication. Understanding how it goes wrong and how
pedestrians end up in the sidewalk salsa will therefore provide insight into
the implicit communication. This understanding can be used to design safe and
acceptable robotic behaviour. In a previous attempt to gain this understanding,
a model of pedestrian behaviour based on the Communication-Enabled Interaction
(CEI) framework was developed that can replicate the sidewalk salsa. However,
it is unclear how to leverage this model in robotic planning and
decision-making since it violates the assumptions of game theory, a much-used
framework in planning and decision-making. Here, we present a proof-of-concept
for an approach where a Reinforcement Learning (RL) agent leverages the model
to learn how to interact with pedestrians. The results show that a basic RL
agent successfully learned to interact with the CEI model. Furthermore, a
risk-averse RL agent that had access to the perceived risk of the CEI model
learned how to effectively communicate its intention through its motion and
thereby substantially lowered the perceived risk, and displayed effort by the
modelled pedestrian. These results show this is a promising approach and
encourage further exploration.

</details>
