<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Radially Distorted Homographies, Revisited](https://arxiv.org/abs/2508.21190)
*Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt*

Main category: cs.CV

TL;DR: 本文提出了一种统一的方法来同时估计单应性变换和径向畸变，解决了三种不同配置下的径向畸变问题，并开发了新的快速、稳定的最小求解器。


<details>
  <summary>Details</summary>
Motivation: 在真实图像处理中，相机镜头引起的几何畸变（特别是径向畸变）会影响单应性估计的准确性。现有方法分别处理三种不同的径向畸变配置，缺乏统一解决方案。

Method: 提出了一种新颖的统一方法，能够同时处理三种径向畸变配置：单图像畸变、两图像相同畸变和两图像独立畸变。基于此方法构建了新的最小求解器。

Result: 在所有三种情况下，提出的求解器比现有最先进方法更快，同时保持相似的精度。在包括鱼眼相机图像在内的标准基准测试中表现良好。

Conclusion: 该方法为径向畸变单应性估计提供了统一的解决方案，开发的求解器具有快速、稳定和准确的特点，适用于各种计算机视觉任务。

Abstract: Homographies are among the most prevalent transformations occurring in
geometric computer vision and projective geometry, and homography estimation is
consequently a crucial step in a wide assortment of computer vision tasks. When
working with real images, which are often afflicted with geometric distortions
caused by the camera lens, it may be necessary to determine both the homography
and the lens distortion-particularly the radial component, called radial
distortion-simultaneously to obtain anything resembling useful estimates. When
considering a homography with radial distortion between two images, there are
three conceptually distinct configurations for the radial distortion; (i)
distortion in only one image, (ii) identical distortion in the two images, and
(iii) independent distortion in the two images. While these cases have been
addressed separately in the past, the present paper provides a novel and
unified approach to solve all three cases. We demonstrate how the proposed
approach can be used to construct new fast, stable, and accurate minimal
solvers for radially distorted homographies. In all three cases, our proposed
solvers are faster than the existing state-of-the-art solvers while maintaining
similar accuracy. The solvers are tested on well-established benchmarks
including images taken with fisheye cameras. The source code for our solvers
will be made available in the event our paper is accepted for publication.

</details>


### [2] [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](https://arxiv.org/abs/2508.21496)
*Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu*

Main category: cs.CV

TL;DR: 论文提出了ELV-Halluc基准，专门针对长视频多模态大语言模型中的语义聚合幻觉问题进行研究，发现位置编码策略和DPO训练能有效减少这类幻觉


<details>
  <summary>Details</summary>
Motivation: 现有视频MLLMs存在幻觉问题，但之前的基准主要关注短视频，忽略了长视频中由于语义复杂性导致的语义聚合幻觉(SAH)，需要专门研究这类幻觉

Method: 构建ELV-Halluc长视频幻觉基准，分析SAH现象，采用位置编码策略和DPO训练方法来缓解SAH问题，并构建了8K对抗数据对

Result: 实验证实了SAH的存在，发现其随语义复杂性增加而增加，在快速变化的语义上更容易出现。通过位置编码和DPO训练，在ELV-Halluc和Video-MME基准上取得改进，SAH比率大幅降低27.7%

Conclusion: 长视频中的语义聚合幻觉是一个重要但被忽视的问题，需要专门的基准和方法来解决，位置编码和DPO训练是有效的缓解策略

Abstract: Video multimodal large language models (Video-MLLMs) have achieved remarkable
progress in video understanding. However, they remain vulnerable to
hallucination-producing content inconsistent with or unrelated to video inputs.
Previous video hallucination benchmarks primarily focus on short-videos. They
attribute hallucinations to factors such as strong language priors, missing
frames, or vision-language biases introduced by the visual encoder. While these
causes indeed account for most hallucinations in short videos, they still
oversimplify the cause of hallucinations. Sometimes, models generate incorrect
outputs but with correct frame-level semantics. We refer to this type of
hallucination as Semantic Aggregation Hallucination (SAH), which arises during
the process of aggregating frame-level semantics into event-level semantic
groups. Given that SAH becomes particularly critical in long videos due to
increased semantic complexity across multiple events, it is essential to
separate and thoroughly investigate the causes of this type of hallucination.
To address the above issues, we introduce ELV-Halluc, the first benchmark
dedicated to long-video hallucination, enabling a systematic investigation of
SAH. Our experiments confirm the existence of SAH and show that it increases
with semantic complexity. Additionally, we find that models are more prone to
SAH on rapidly changing semantics. Moreover, we discuss potential approaches to
mitigate SAH. We demonstrate that positional encoding strategy contributes to
alleviating SAH, and further adopt DPO strategy to enhance the model's ability
to distinguish semantics within and across events. To support this, we curate a
dataset of 8K adversarial data pairs and achieve improvements on both
ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.

</details>


### [3] [The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](https://arxiv.org/abs/2508.21816)
*Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin*

Main category: cs.CV

TL;DR: 该论文发现场景识别中的动词分类本质上是多标签问题，提出了单正例多标签学习框架和GE-VerbMLP模型，在保持传统指标竞争力的同时实现了3%以上的MAP提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法将动词分类视为单标签问题，但实际图像中存在语义模糊性，多个动词类别可能合理描述同一图像，需要重新审视这一设定。

Method: 将动词分类重新定义为单正例多标签学习(SPMLL)问题，提出Graph Enhanced Verb MLP模型，结合图神经网络捕捉标签相关性和对抗训练优化决策边界。

Result: 在真实数据集上实验表明，该方法在保持top-1和top-5准确率竞争力的同时，实现了超过3%的平均精度均值(MAP)提升。

Conclusion: 动词分类本质上是多标签问题，提出的SPMLL框架和GE-VerbMLP模型有效解决了语义模糊性，为场景识别提供了新的研究方向。

Abstract: Context recognition (SR) is a fundamental task in computer vision that aims
to extract structured semantic summaries from images by identifying key events
and their associated entities. Specifically, given an input image, the model
must first classify the main visual events (verb classification), then identify
the participating entities and their semantic roles (semantic role labeling),
and finally localize these entities in the image (semantic role localization).
Existing methods treat verb classification as a single-label problem, but we
show through a comprehensive analysis that this formulation fails to address
the inherent ambiguity in visual event recognition, as multiple verb categories
may reasonably describe the same image. This paper makes three key
contributions: First, we reveal through empirical analysis that verb
classification is inherently a multi-label problem due to the ubiquitous
semantic overlap between verb categories. Second, given the impracticality of
fully annotating large-scale datasets with multiple labels, we propose to
reformulate verb classification as a single positive multi-label learning
(SPMLL) problem - a novel perspective in SR research. Third, we design a
comprehensive multi-label evaluation benchmark for SR that is carefully
designed to fairly evaluate model performance in a multi-label setting. To
address the challenges of SPMLL, we futher develop the Graph Enhanced Verb
Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to
capture label correlations and adversarial training to optimize decision
boundaries. Extensive experiments on real-world datasets show that our approach
achieves more than 3\% MAP improvement while remaining competitive on
traditional top-1 and top-5 accuracy metrics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics](https://arxiv.org/abs/2508.21249)
*Mohammad Amin Nabian,Sanjay Choudhry*

Main category: cs.LG

TL;DR: 提出基于混合专家(MoE)的元学习框架，动态整合三种先进CFD代理模型的预测，在汽车空气动力学预测中显著降低误差


<details>
  <summary>Details</summary>
Motivation: 高保真CFD仿真计算成本高，现有ML代理模型架构多样但无单一最优方案，需要利用架构多样性提升预测精度

Method: 使用门控网络动态组合DoMINO、X-MeshGraphNet和FigConvNet三种异构专家模型，通过熵正则化防止模型坍塌，在DrivAerML数据集上训练验证

Result: MoE模型在所有评估物理量上均显著降低L-2预测误差，优于集成平均和最准确的单个专家模型

Conclusion: MoE框架通过协同整合专用架构的互补优势，为构建更鲁棒准确的复合代理模型提供了有效策略

Abstract: The computational cost associated with high-fidelity CFD simulations remains
a significant bottleneck in the automotive design and optimization cycle. While
ML-based surrogate models have emerged as a promising alternative to accelerate
aerodynamic predictions, the field is characterized by a diverse and rapidly
evolving landscape of specialized neural network architectures, with no single
model demonstrating universal superiority. This paper introduces a novel
meta-learning framework that leverages this architectural diversity as a
strength. We propose a Mixture of Experts (MoE) model that employs a dedicated
gating network to dynamically and optimally combine the predictions from three
heterogeneous, state-of-the-art surrogate models: DoMINO, a decomposable
multi-scale neural operator; X-MeshGraphNet, a scalable multi-scale graph
neural network; and FigConvNet, a factorized implicit global convolution
network. The gating network learns a spatially-variant weighting strategy,
assigning credibility to each expert based on its localized performance in
predicting surface pressure and wall shear stress fields. To prevent model
collapse and encourage balanced expert contributions, we integrate an entropy
regularization term into the training loss function. The entire system is
trained and validated on the DrivAerML dataset, a large-scale, public benchmark
of high-fidelity CFD simulations for automotive aerodynamics. Quantitative
results demonstrate that the MoE model achieves a significant reduction in L-2
prediction error, outperforming not only the ensemble average but also the most
accurate individual expert model across all evaluated physical quantities. This
work establishes the MoE framework as a powerful and effective strategy for
creating more robust and accurate composite surrogate models by synergistically
combining the complementary strengths of specialized architectures.

</details>


### [5] [Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control](https://arxiv.org/abs/2508.21505)
*Vishal Pandey,Debasmita Biswas*

Main category: cs.LG

TL;DR: SNN-DT将脉冲神经网络与决策变换器结合，在保持性能的同时大幅降低能耗，适用于边缘设备


<details>
  <summary>Details</summary>
Motivation: 传统Transformer决策智能体依赖密集矩阵运算，能耗高，不适合能源受限的边缘平台。脉冲神经网络具有超低功耗特性，但尚未与回报条件序列建模结合

Method: 在自注意力块中嵌入Leaky Integrate-and-Fire神经元，通过替代梯度端到端训练，包含生物启发的三因子可塑性、相移脉冲位置编码和轻量级树突路由模块

Result: 在经典控制基准测试中达到或超过标准决策变换器性能，每个决策发射少于10个脉冲，能耗降低超过4个数量级

Conclusion: SNN-DT通过将序列建模与神经形态效率结合，为嵌入式可穿戴设备开辟了实时低功耗控制的新途径

Abstract: Reinforcement learning agents based on Transformer architectures have
achieved impressive performance on sequential decision-making tasks, but their
reliance on dense matrix operations makes them ill-suited for
energy-constrained, edge-oriented platforms. Spiking neural networks promise
ultra-low-power, event-driven inference, yet no prior work has seamlessly
merged spiking dynamics with return-conditioned sequence modeling. We present
the Spiking Decision Transformer (SNN-DT), which embeds Leaky
Integrate-and-Fire neurons into each self-attention block, trains end-to-end
via surrogate gradients, and incorporates biologically inspired three-factor
plasticity, phase-shifted spike-based positional encodings, and a lightweight
dendritic routing module. Our implementation matches or exceeds standard
Decision Transformer performance on classic control benchmarks (CartPole-v1,
MountainCar-v0, Acrobot-v1, Pendulum-v1) while emitting fewer than ten spikes
per decision, an energy proxy suggesting over four orders-of-magnitude
reduction in per inference energy. By marrying sequence modeling with
neuromorphic efficiency, SNN-DT opens a pathway toward real-time, low-power
control on embedded and wearable devices.

</details>


### [6] [Inferring Effects of Major Events through Discontinuity Forecasting of Population Anxiety](https://arxiv.org/abs/2508.21722)
*Siddharth Mangalik,Ojas Deshpande,Adithya V. Ganesan,Sean A. P. Clouston,H. Andrew Schwartz*

Main category: cs.LG

TL;DR: 本文提出将纵向回归断点设计(LRDD)从传统预测扩展到统计学习框架，用于预测COVID-19事件对美国县焦虑评分的断点和斜率变化，结果显示整合外生和动态协变量能显著提升预测效果。


<details>
  <summary>Details</summary>
Motivation: 估计地方事件对特定社区心理健康的影响对公共卫生政策至关重要，但单纯预测心理健康评分无法深入了解事件对社区福祉的因果影响。

Method: 将LRDD扩展到统计学习框架，利用位置评分历史、动态协变量和外生变量来预测未来的断点（时间特定变化）和斜率（线性轨迹）变化。

Result: 预测COVID-19事件导致的焦虑评分断点具有挑战性，但随着模型复杂度增加而变得可行，最佳结果来自整合外生和动态协变量（断点r=+0.46，斜率r=+0.65）。

Conclusion: 断点预测为估计未来或假设事件对特定社区的异质性影响开辟了新可能性，相比传统静态社区表征有显著改进。

Abstract: Estimating community-specific mental health effects of local events is vital
for public health policy. While forecasting mental health scores alone offers
limited insights into the impact of events on community well-being,
quasi-experimental designs like the Longitudinal Regression Discontinuity
Design (LRDD) from econometrics help researchers derive more effects that are
more likely to be causal from observational data. LRDDs aim to extrapolate the
size of changes in an outcome (e.g. a discontinuity in running scores for
anxiety) due to a time-specific event. Here, we propose adapting LRDDs beyond
traditional forecasting into a statistical learning framework whereby future
discontinuities (i.e. time-specific shifts) and changes in slope (i.e. linear
trajectories) are estimated given a location's history of the score, dynamic
covariates (other running assessments), and exogenous variables (static
representations). Applying our framework to predict discontinuities in the
anxiety of US counties from COVID-19 events, we found the task was difficult
but more achievable as the sophistication of models was increased, with the
best results coming from integrating exogenous and dynamic covariates. Our
approach shows strong improvement ($r=+.46$ for discontinuity and $r = +.65$
for slope) over traditional static community representations. Discontinuity
forecasting raises new possibilities for estimating the idiosyncratic effects
of potential future or hypothetical events on specific communities.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个新的多模态搜索基准测试，包含311个需要深度视觉理解和迭代搜索的任务，旨在解决现有基准测试中浅层工作流程的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态浏览基准测试往往可以通过浅层的固定工作流程解决，无法真正测试细粒度视觉推理、来源验证和长时程工具使用等真正多模态挑战。

Method: 采用空间-时间外推法构建任务，要求从空间线索（微文本、局部外观、布局、标志）和时间痕迹（广播叠加、季节上下文）外推到图像外的事实。提供模型无关的代理框架和浏览工具。

Result: 最强代理（o3）无搜索准确率为15.1%，有搜索准确率为36.0%；最强开源模型（Qwen-2.5-VL-72B-Instruct）无搜索准确率为0.0%，20轮搜索后为6.9%。

Conclusion: 该基准测试揭示了模型在来源验证、基于部件的推理和长时程规划方面的失败，为多模态语言模型的真实能力评估提供了更严格的测试标准。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [8] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 这篇论文提出了一个集成传统网络优化模型和大语言模型的框架，为供应链规划提供交互式、可解释性和角色感知的决策支持系统。


<details>
  <summary>Details</summary>
Motivation: 平泽操作研究输出的复杂性与业务利益相关者理解之间的差距，需要一种能够生成自然语言摘要、上下文可视化和定制KPI的解决方案。

Method: 采用混合整数规划模型处理多周期多物品的战术性库存重新分配问题，通过AI代理、RESTful API和动态用户界面构建技术架构，支持实时交互、配置更新和模拟见解。

Result: 案例研究证明该系统能够改善规划效果，包括预防缺货、降低成本和维持服务水平。

Conclusion: 该框架成功结合优化模型和LLM技术，未来可通过集成私有LLM、迁移学习、强化学习和贝叶斯神经网络来提升可解释性、适应性和实时决策能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2508.21201)
*Arash Ahmadi,Sarah Sharif,Yaser Banad*

Main category: cs.CL

TL;DR: 基于强化学习和GRPO优化的自动化HFACS分析框架，将Llama-3.1 8B模型在航空安全领域优化，实现了精确匹配准确度的350%提升，超越现有最佳大语言模型。


<details>
  <summary>Details</summary>
Motivation: 传统HFACS分析方法存在扩展性和一致性问题，需要自动化解决方案来提高航空事故人因分析的效率和准确性。

Method: 使用强化学习组相对策略优化(GRPO)精调Llama-3.1 8B模型，构建多组件奖励系统，并集成合成数据生成来解决类别不平衡问题。

Result: 模型精确匹配准确度从0.0400提升到0.1800(增长350%)，部分匹配准确度达到0.8800，超越GPT-5-mini和Gemini-2.5-flash等现有最佳模型。

Conclusion: 领域优化的轻量模型能够提供更高效、更优秀的安全分析方案，适合在资源受限边缘设处上部署。

Abstract: Analyzing the human factors behind aviation accidents is crucial for
preventing future incidents, yet traditional methods using the Human Factors
Analysis and Classification System (HFACS) are limited by scalability and
consistency. To address this, we introduce an automated HFACS classification
framework for aviation safety analysis that utilizes Reinforcement Learning
with Group Relative Policy Optimization (GRPO) to fine-tune a Llama-3.1 8B
language model. Our approach incorporates a multi-component reward system
tailored for aviation safety analysis and integrates synthetic data generation
to overcome class imbalance in accident datasets. The resulting GRPO-optimized
model achieved noticeable performance gains, including a 350% increase in exact
match accuracy (from 0.0400 to 0.1800) and an improved partial match accuracy
of 0.8800. Significantly, our specialized model outperforms state-of-the-art
LLMs (Large Language Models), including GPT-5-mini and Gemini-2.5-fiash, on key
metrics. This research also proposes exact match accuracy in multi-label HFACS
classification problem as a new benchmarking methodology to evaluate the
advanced reasoning capabilities of language models. Ultimately, our work
validates that smaller, domain-optimized models can provide a computationally
efficient and better solution for critical safety analysis. This approach makes
powerful, low-latency deployment on resource-constrained edge devices feasible.

</details>


### [10] [Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance](https://arxiv.org/abs/2508.21741)
*Yao Wang,Di Liang,Minlong Peng*

Main category: cs.CL

TL;DR: 提出CPI-FT框架，通过核心参数隔离和融合技术解决多任务微调中的跷跷板现象和灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 监督微调中参数更新会导致某些任务进步而其他任务退化的跷跷板现象，需要解决多任务间的干扰和遗忘问题

Method: 1) 独立微调识别核心参数区域 2) 基于区域重叠的任务聚类 3) 核心参数移植+非核心参数SLERP融合 4) 轻量级流水线SFT训练，冻结核心区域

Result: 在多个公开基准测试中显著缓解任务干扰和遗忘，持续优于普通多任务和多阶段微调基线

Conclusion: CPI-FT框架通过参数隔离和智能融合有效解决了多任务微调中的关键挑战，为LLM适配下游任务提供了新思路

Abstract: Supervised fine-tuning (SFT) is a pivotal approach to adapting large language
models (LLMs) for downstream tasks; however, performance often suffers from the
``seesaw phenomenon'', where indiscriminate parameter updates yield progress on
certain tasks at the expense of others. To address this challenge, we propose a
novel \emph{Core Parameter Isolation Fine-Tuning} (CPI-FT) framework.
Specifically, we first independently fine-tune the LLM on each task to identify
its core parameter regions by quantifying parameter update magnitudes. Tasks
with similar core regions are then grouped based on region overlap, forming
clusters for joint modeling. We further introduce a parameter fusion technique:
for each task, core parameters from its individually fine-tuned model are
directly transplanted into a unified backbone, while non-core parameters from
different tasks are smoothly integrated via Spherical Linear Interpolation
(SLERP), mitigating destructive interference. A lightweight, pipelined SFT
training phase using mixed-task data is subsequently employed, while freezing
core regions from prior tasks to prevent catastrophic forgetting. Extensive
experiments on multiple public benchmarks demonstrate that our approach
significantly alleviates task interference and forgetting, consistently
outperforming vanilla multi-task and multi-stage fine-tuning baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?](https://arxiv.org/abs/2508.21690)
*Olger Siebinga,David Abbink*

Main category: cs.RO

TL;DR: 该研究使用强化学习代理与行人行为模型交互，成功解决了"人行道尬舞"问题，并通过风险感知降低了行人的感知风险。


<details>
  <summary>Details</summary>
Motivation: 研究人行道上行人相遇时的"人行道尬舞"现象，理解隐式通信机制，为移动机器人设计安全可接受的行为提供 insights。

Method: 采用强化学习(RL)代理与基于通信使能交互(CEI)框架的行人行为模型进行交互学习。

Result: 基础RL代理成功学会了与CEI模型交互；风险规避型RL代理通过动作有效传达意图，显著降低了行人的感知风险。

Conclusion: 这是一个有前景的方法，证明了RL可以学习与违反博弈论假设的模型进行有效交互，值得进一步探索。

Abstract: Pedestrians approaching each other on a sidewalk sometimes end up in an
awkward interaction known as the "sidewalk salsa": they both (repeatedly)
deviate to the same side to avoid a collision. This provides an interesting use
case to study interactions between pedestrians and mobile robots because, in
the vast majority of cases, this phenomenon is avoided through a negotiation
based on implicit communication. Understanding how it goes wrong and how
pedestrians end up in the sidewalk salsa will therefore provide insight into
the implicit communication. This understanding can be used to design safe and
acceptable robotic behaviour. In a previous attempt to gain this understanding,
a model of pedestrian behaviour based on the Communication-Enabled Interaction
(CEI) framework was developed that can replicate the sidewalk salsa. However,
it is unclear how to leverage this model in robotic planning and
decision-making since it violates the assumptions of game theory, a much-used
framework in planning and decision-making. Here, we present a proof-of-concept
for an approach where a Reinforcement Learning (RL) agent leverages the model
to learn how to interact with pedestrians. The results show that a basic RL
agent successfully learned to interact with the CEI model. Furthermore, a
risk-averse RL agent that had access to the perceived risk of the CEI model
learned how to effectively communicate its intention through its motion and
thereby substantially lowered the perceived risk, and displayed effort by the
modelled pedestrian. These results show this is a promising approach and
encourage further exploration.

</details>
