<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Decoding Future Risk: Deep Learning Analysis of Tubular Adenoma Whole-Slide Images](https://arxiv.org/abs/2602.09155)
*Ahmed Rahu,Brian Shula,Brandon Combs,Aqsa Sultana,Surendra P. Singh,Vijayan K. Asari,Derrick Forchetti*

Main category: cs.CV

TL;DR: 利用卷积神经网络分析低级别管状腺瘤的数字化病理切片，预测患者未来结直肠癌风险


<details>
  <summary>Details</summary>
Motivation: 结直肠癌仍是重要死因，即使筛查能降低发病率，仍有部分低级别腺瘤患者会发展为结直肠癌。传统组织学评估可能无法完全捕捉预示恶性潜能的细微特征，需要更精准的风险分层方法。

Method: 采用数字病理和机器学习技术，特别是卷积神经网络（CNNs），全面客观地分析低级别管状腺瘤的整张切片图像（WSIs），检测细微的组织学特征。

Result: 研究探讨了机器学习算法能否从低级别管状腺瘤的WSIs中检测出预测患者长期结直肠癌风险的细微组织学特征。

Conclusion: 数字病理和机器学习为识别低风险患者中的高风险亚群提供了新机会，有助于制定个体化监测和预防策略。

Abstract: Colorectal cancer (CRC) remains a significant cause of cancer-related mortality, despite the widespread implementation of prophylactic initiatives aimed at detecting and removing precancerous polyps. Although screening effectively reduces incidence, a notable portion of patients initially diagnosed with low-grade adenomatous polyps will still develop CRC later in life, even without the presence of known high-risk syndromes. Identifying which low-risk patients are at higher risk of progression is a critical unmet need for tailored surveillance and preventative therapeutic strategies. Traditional histological assessment of adenomas, while fundamental, may not fully capture subtle architectural or cytological features indicative of malignant potential. Advancements in digital pathology and machine learning provide an opportunity to analyze whole-slide images (WSIs) comprehensively and objectively. This study investigates whether machine learning algorithms, specifically convolutional neural networks (CNNs), can detect subtle histological features in WSIs of low-grade tubular adenomas that are predictive of a patient's long-term risk of developing colorectal cancer.

</details>


### [2] [All-in-One Conditioning for Text-to-Image Synthesis](https://arxiv.org/abs/2602.09165)
*Hirunima Jayasekara,Chuong Huynh,Yixuan Ren,Christabel Acquaye,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 提出基于场景图的零样本条件机制ASQL Conditioner，通过轻量语言模型生成视觉条件，在推理时优化引导扩散模型，提升复杂提示下的文本-图像对齐和组合能力。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像合成模型在处理包含多个对象、属性和空间关系的复杂提示时，难以保持语义保真度和结构连贯性。现有方法使用预定义布局图，但这种刚性约束限制了组合灵活性和多样性。

Method: 提出基于场景图结构的零样本条件机制，核心是ASQL（属性-大小-数量-位置）条件器。使用轻量语言模型生成软视觉指导，在推理时通过优化引导扩散模型生成过程。

Result: 该方法能够在保持文本-图像对齐的同时，支持轻量、连贯且多样化的图像合成，提升了复杂提示下的组合能力。

Conclusion: 通过场景图框架和ASQL条件器的软视觉指导，实现了对复杂文本提示的更准确解释和视觉表示，克服了传统刚性布局约束的限制。

Abstract: Accurate interpretation and visual representation of complex prompts involving multiple objects, attributes, and spatial relationships is a critical challenge in text-to-image synthesis. Despite recent advancements in generating photorealistic outputs, current models often struggle with maintaining semantic fidelity and structural coherence when processing intricate textual inputs. We propose a novel approach that grounds text-to-image synthesis within the framework of scene graph structures, aiming to enhance the compositional abilities of existing models. Eventhough, prior approaches have attempted to address this by using pre-defined layout maps derived from prompts, such rigid constraints often limit compositional flexibility and diversity. In contrast, we introduce a zero-shot, scene graph-based conditioning mechanism that generates soft visual guidance during inference. At the core of our method is the Attribute-Size-Quantity-Location (ASQL) Conditioner, which produces visual conditions via a lightweight language model and guides diffusion-based generation through inference-time optimization. This enables the model to maintain text-image alignment while supporting lightweight, coherent, and diverse image synthesis.

</details>


### [3] [SchröMind: Mitigating Hallucinations in Multimodal Large Language Models via Solving the Schrödinger Bridge Problem](https://arxiv.org/abs/2602.09528)
*Ziqiang Shi,Rujie Liu,Shanshan Yu,Satoshi Munakata,Koichi Shirahata*

Main category: cs.CV

TL;DR: 提出SchröMind框架，通过求解薛定谔桥问题减少多模态大语言模型的幻觉问题，在医疗等高风险领域实现更可靠的视觉-文本对齐


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医疗等高风险领域应用受限，主要问题是幻觉现象——生成的文本与视觉输入矛盾或忽略视觉信息。虽然模型能理解图像，但难以生成准确的token序列，且自回归特性阻碍错误修正

Method: 提出SchröMind框架，通过求解薛定谔桥问题，建立幻觉激活和真实激活之间的token级映射，以最小传输成本实现轻量级训练，同时保持模型原有能力

Result: 在POPE和MME基准测试中表现优异，达到最先进性能，同时仅引入最小计算开销

Conclusion: SchröMind通过薛定谔桥方法有效减少多模态大语言模型的幻觉问题，为高风险领域的可靠应用提供了可行方案

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have achieved significant success across various domains. However, their use in high-stakes fields like healthcare remains limited due to persistent hallucinations, where generated text contradicts or ignores visual input. We contend that MLLMs can comprehend images but struggle to produce accurate token sequences. Minor perturbations can shift attention from truthful to untruthful states, and the autoregressive nature of text generation often prevents error correction. To address this, we propose SchröMind-a novel framework reducing hallucinations via solving the Schrödinger bridge problem. It establishes a token-level mapping between hallucinatory and truthful activations with minimal transport cost through lightweight training, while preserving the model's original capabilities. Extensive experiments on the POPE and MME benchmarks demonstrate the superiority of Schrödinger, which achieves state-of-the-art performance while introducing only minimal computational overhead.

</details>


### [4] [Hand2World: Autoregressive Egocentric Interaction Generation via Free-Space Hand Gestures](https://arxiv.org/abs/2602.09600)
*Yuxi Wang,Wenqi Ouyang,Tianyi Wei,Yi Dong,Zhiqi Shen,Xingang Pan*

Main category: cs.CV

TL;DR: Hand2World：基于单张场景图像的自我中心交互生成框架，通过3D手部网格投影和相机几何注入解决手势交互视频合成的挑战，支持任意长度生成和相机控制。


<details>
  <summary>Details</summary>
Motivation: 增强现实和具身AI需要能够响应手势输入、具有低延迟、几何一致性和长期稳定性的自我中心交互世界模型。现有方法面临自由空间手势与接触训练数据之间的分布偏移、单目视图中手部运动与相机运动的模糊性，以及需要任意长度视频生成等挑战。

Method: 提出Hand2World统一自回归框架：1）使用投影3D手部网格进行遮挡不变的手部条件化；2）通过逐像素Plücker射线嵌入注入显式相机几何；3）开发全自动单目标注流程；4）将双向扩散模型蒸馏为因果生成器。

Result: 在三个自我中心交互基准测试中，Hand2World在感知质量和3D一致性方面取得显著改进，同时支持相机控制和长时域交互生成。

Conclusion: Hand2World通过创新的手部条件化和相机几何表示，有效解决了自我中心交互生成的多个核心挑战，为增强现实和具身AI应用提供了高质量的交互视频合成能力。

Abstract: Egocentric interactive world models are essential for augmented reality and embodied AI, where visual generation must respond to user input with low latency, geometric consistency, and long-term stability. We study egocentric interaction generation from a single scene image under free-space hand gestures, aiming to synthesize photorealistic videos in which hands enter the scene, interact with objects, and induce plausible world dynamics under head motion. This setting introduces fundamental challenges, including distribution shift between free-space gestures and contact-heavy training data, ambiguity between hand motion and camera motion in monocular views, and the need for arbitrary-length video generation. We present Hand2World, a unified autoregressive framework that addresses these challenges through occlusion-invariant hand conditioning based on projected 3D hand meshes, allowing visibility and occlusion to be inferred from scene context rather than encoded in the control signal. To stabilize egocentric viewpoint changes, we inject explicit camera geometry via per-pixel Plücker-ray embeddings, disentangling camera motion from hand motion and preventing background drift. We further develop a fully automated monocular annotation pipeline and distill a bidirectional diffusion model into a causal generator, enabling arbitrary-length synthesis. Experiments on three egocentric interaction benchmarks show substantial improvements in perceptual quality and 3D consistency while supporting camera control and long-horizon interactive generation.

</details>


### [5] [BabyMamba-HAR: Lightweight Selective State Space Models for Efficient Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.09872)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: BabyMamba-HAR：针对资源受限可穿戴设备的人体活动识别框架，包含两种轻量级Mamba架构，在保持高精度的同时大幅减少计算开销


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备上的人体活动识别受限于内存和计算资源，同时需要在不同传感器配置下保持竞争力。选择性状态空间模型（SSMs）提供线性时间序列处理能力，是二次复杂度注意力机制的有力替代方案，但在TinyML领域的应用设计空间尚未充分探索。

Method: 提出BabyMamba-HAR框架，包含两种新颖的轻量级Mamba架构：1) CI-BabyMamba-HAR使用通道独立主干，通过共享权重但实例独立的变换处理每个传感器通道，防止跨通道噪声传播；2) Crossover-BiDir-BabyMamba-HAR使用早期融合主干，实现通道数无关的计算复杂度。两种变体都包含权重绑定的双向扫描和轻量级时间注意力池化。

Result: Crossover-BiDir-BabyMamba-HAR在八个不同基准测试中平均宏F1分数达到86.52%，仅需约27K参数和2.21M MACs，与TinyHAR（86.16%）性能相当，但在高通道数据集上需要11倍更少的MACs。消融研究表明，双向扫描可带来高达8.42%的F1分数提升，门控时间注意力相比平均池化可提供高达8.94%的F1分数增益。

Conclusion: 该研究为在TinyML领域部署选择性状态空间模型作为高效的人体活动识别骨干网络建立了实用的设计原则，证明了SSMs在资源受限设备上的可行性和优势。

Abstract: Human activity recognition (HAR) on wearable and mobile devices is constrained by memory footprint and computational budget, yet competitive accuracy must be maintained across heterogeneous sensor configurations. Selective state space models (SSMs) offer linear time sequence processing with input dependent gating, presenting a compelling alternative to quadratic complexity attention mechanisms. However, the design space for deploying SSMs in the TinyML regime remains largely unexplored. In this paper, BabyMamba-HAR is introduced, a framework comprising two novel lightweight Mamba inspired architectures optimized for resource constrained HAR: (1) CI-BabyMamba-HAR, using a channel independent stem that processes each sensor channel through shared weight, but instance independent transformations to prevent cross channel noise propagation, and (2) Crossover-BiDir-BabyMamba-HAR, using an early fusion stem that achieves channel count independent computational complexity. Both variants incorporate weight tied bidirectional scanning and lightweight temporal attention pooling. Through evaluation across eight diverse benchmarks, it is demonstrated that Crossover-BiDir-BabyMamba-HAR achieves 86.52% average macro F1-score with approximately 27K parameters and 2.21M MACs, matching TinyHAR (86.16%) while requiring 11x fewer MACs on high channel datasets. Systematic ablation studies reveal that bidirectional scanning contributes up to 8.42% F1-score improvement, and gated temporal attention provides up to 8.94% F1-score gain over mean pooling. These findings establish practical design principles for deploying selective state space models as efficient TinyML backbones for HAR.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Patient foundation model for risk stratification in low-risk overweight patients](https://arxiv.org/abs/2602.09079)
*Zachary N. Flamholz,Dillon Tracy,Ripple Khera,Jordan Wolinsky,Nicholas Lee,Nathaniel Tann,Xiao Yin Zhu,Harry Phillips,Jeffrey Sherman*

Main category: cs.LG

TL;DR: PatientTPP是一个神经时间点过程模型，利用50万+真实临床轨迹学习患者表征，通过建模临床事件类型和时间来改善肥胖患者风险分层，在心血管相关医疗成本预测上优于BMI指标。


<details>
  <summary>Details</summary>
Motivation: 准确的风险分层对于超重或肥胖患者至关重要，可以指导预防性护理和分配高成本治疗（如GLP-1受体激动剂）。现有方法如BMI在风险预测上有限，需要更精确的模型来识别高风险患者。

Method: 开发PatientTPP神经时间点过程模型，扩展现有TPP方法以包含静态和数值特征，并整合临床知识进行事件编码。模型基于50多万真实临床轨迹训练，学习诊断、实验室检查和药物序列的患者表征。

Result: PatientTPP表征支持下游预测任务，包括对低风险个体中肥胖相关结局的分类，即使对于训练期间未明确建模的事件。在健康经济评估中，PatientTPP在按未来心血管相关医疗成本分层患者方面优于BMI，能更有效地识别高风险患者。

Conclusion: 通过建模临床事件的类型和时间，PatientTPP提供了一个可解释的通用基础，用于患者风险建模，可直接应用于肥胖相关护理和成本目标定位，为精准医疗提供有力工具。

Abstract: Accurate risk stratification in patients with overweight or obesity is critical for guiding preventive care and allocating high-cost therapies such as GLP-1 receptor agonists. We present PatientTPP, a neural temporal point process (TPP) model trained on over 500,000 real-world clinical trajectories to learn patient representations from sequences of diagnoses, labs, and medications. We extend existing TPP modeling approaches to include static and numeric features and incorporate clinical knowledge for event encoding. PatientTPP representations support downstream prediction tasks, including classification of obesity-associated outcomes in low-risk individuals, even for events not explicitly modeled during training. In health economic evaluation, PatientTPP outperformed body mass index in stratifying patients by future cardiovascular-related healthcare costs, identifying higher-risk patients more efficiently. By modeling both the type and timing of clinical events, PatientTPP offers an interpretable, general-purpose foundation for patient risk modeling with direct applications to obesity-related care and cost targeting.

</details>


### [7] [A Lightweight Multi-View Approach to Short-Term Load Forecasting](https://arxiv.org/abs/2602.09220)
*Julien Guité-Vinet,Alexandre Blondin Massé,Éric Beaudry*

Main category: cs.LG

TL;DR: 提出轻量级多视角短期负荷预测方法，使用单值嵌入和缩放时间范围输入，引入嵌入丢弃机制防止过拟合，参数量少但性能有竞争力


<details>
  <summary>Details</summary>
Motivation: 虽然基于Transformer和大参数模型在时间序列预测中取得了SOTA结果，但其复杂性容易导致过拟合和不稳定预测，特别是当旧数据点相关性降低时。需要更轻量、稳健的方法来处理短期负荷预测

Method: 提出轻量级多视角方法：1）使用单值嵌入和缩放时间范围输入有效捕捉时间相关特征；2）引入嵌入丢弃机制防止对特定特征的过度依赖并增强可解释性

Result: 方法在显著减少参数量的情况下实现了有竞争力的性能，在多个数据集上表现出鲁棒性，包括噪声或稀疏数据场景，并能提供单个特征对预测贡献的洞察

Conclusion: 提出的轻量级多视角方法为短期负荷预测提供了高效、稳健的解决方案，在保持性能的同时大幅减少模型复杂度，增强了可解释性

Abstract: Time series forecasting is a critical task across domains such as energy, finance, and meteorology, where accurate predictions enable informed decision-making. While transformer-based and large-parameter models have recently achieved state-of-the-art results, their complexity can lead to overfitting and unstable forecasts, especially when older data points become less relevant. In this paper, we propose a lightweight multi-view approach to short-term load forecasting that leverages single-value embeddings and a scaled time-range input to capture temporally relevant features efficiently. We introduce an embedding dropout mechanism to prevent over-reliance on specific features and enhance interpretability. Our method achieves competitive performance with significantly fewer parameters, demonstrating robustness across multiple datasets, including scenarios with noisy or sparse data, and provides insights into the contributions of individual features to the forecast.

</details>


### [8] [In-Hospital Stroke Prediction from PPG-Derived Hemodynamic Features](https://arxiv.org/abs/2602.09328)
*Jiaming Liu,Cheng Ding,Daoqiang Zhang*

Main category: cs.LG

TL;DR: 利用住院期间已接受连续监测的卒中患者队列，首次大规模分析卒中前PPG波形，证明PPG信号在卒中发生前数小时具有预测价值。


<details>
  <summary>Details</summary>
Motivation: 标准临床数据集中缺乏院前生理数据限制了卒中的早期预测，因为患者通常在卒中发生后才就诊，导致连续监测信号（如PPG）的预测价值无法验证。

Method: 1) 聚焦住院期间发生卒中且已接受连续监测的罕见队列；2) 使用LLM辅助数据挖掘管道从非结构化临床记录中提取精确的院内卒中发作时间戳；3) 从PPG提取血流动力学特征；4) 使用ResNet-1D模型在多个预警时间窗口预测即将发生的卒中。

Result: 在MIMIC-III上，模型在卒中发生前4、5、6小时分别达到0.7956、0.8759、0.9406的F1分数；在MC-MED上（无需重新调参）分别达到0.9256、0.9595、0.9888。首次从真实世界临床数据提供PPG在卒中前数小时包含预测特征的实证证据。

Conclusion: 被动获取的生理信号可以支持可靠的早期预警，支持从卒中后识别向基于生理学的主动监测转变，可能显著改善常规临床护理中的患者预后。

Abstract: The absence of pre-hospital physiological data in standard clinical datasets fundamentally constrains the early prediction of stroke, as patients typically present only after stroke has occurred, leaving the predictive value of continuous monitoring signals such as photoplethysmography (PPG) unvalidated. In this work, we overcome this limitation by focusing on a rare but clinically critical cohort - patients who suffered stroke during hospitalization while already under continuous monitoring - thereby enabling the first large-scale analysis of pre-stroke PPG waveforms aligned to verified onset times. Using MIMIC-III and MC-MED, we develop an LLM-assisted data mining pipeline to extract precise in-hospital stroke onset timestamps from unstructured clinical notes, followed by physician validation, identifying 176 patients (MIMIC) and 158 patients (MC-MED) with high-quality synchronized pre-onset PPG data, respectively. We then extract hemodynamic features from PPG and employ a ResNet-1D model to predict impending stroke across multiple early-warning horizons. The model achieves F1-scores of 0.7956, 0.8759, and 0.9406 at 4, 5, and 6 hours prior to onset on MIMIC-III, and, without re-tuning, reaches 0.9256, 0.9595, and 0.9888 on MC-MED for the same horizons. These results provide the first empirical evidence from real-world clinical data that PPG contains predictive signatures of stroke several hours before onset, demonstrating that passively acquired physiological signals can support reliable early warning, supporting a shift from post-event stroke recognition to proactive, physiology-based surveillance that may materially improve patient outcomes in routine clinical care.

</details>


### [9] [Scalable and Reliable State-Aware Inference of High-Impact N-k Contingencies](https://arxiv.org/abs/2602.09461)
*Lihao Mai,Chenhan Xiao,Yang Weng*

Main category: cs.LG

TL;DR: 提出一个可扩展的状态感知故障推理框架，使用条件扩散模型直接生成高影响的N-k故障场景，避免枚举组合空间，并提供可控的覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 随着逆变器资源渗透率增加、负荷变化快速，高阶N-k故障评估变得重要但计算量大。传统方法要么不可行（枚举所有组合），要么依赖启发式筛选但无法保证覆盖所有关键故障。

Method: 1) 使用条件扩散模型根据当前运行状态生成候选故障场景；2) 仅使用基态和N-1案例训练拓扑感知图神经网络离线构建高风险训练样本；3) 提供可控的覆盖保证，允许在有限AC潮流评估预算下管理遗漏关键事件的风险。

Result: 在IEEE基准系统上的实验表明，在给定评估预算下，该方法比均匀采样能持续评估更高严重性的故障，从而以更少的计算量更可靠地识别关键故障。

Conclusion: 该框架为N-k故障评估提供了一个可扩展的解决方案，能够直接生成高影响故障场景，提供可控的风险覆盖保证，显著提高故障识别效率。

Abstract: Increasing penetration of inverter-based resources, flexible loads, and rapidly changing operating conditions make higher-order $N\!-\!k$ contingency assessment increasingly important but computationally prohibitive. Exhaustive evaluation of all outage combinations using AC power-flow or ACOPF is infeasible in routine operation. This fact forces operators to rely on heuristic screening methods whose ability to consistently retain all critical contingencies is not formally established. This paper proposes a scalable, state-aware contingency inference framework designed to directly generate high-impact $N\!-\!k$ outage scenarios without enumerating the combinatorial contingency space. The framework employs a conditional diffusion model to produce candidate contingencies tailored to the current operating state, while a topology-aware graph neural network trained only on base and $N\!-\!1$ cases efficiently constructs high-risk training samples offline. Finally, the framework is developed to provide controllable coverage guarantees for severe contingencies, allowing operators to explicitly manage the risk of missing critical events under limited AC power-flow evaluation budgets. Experiments on IEEE benchmark systems show that, for a given evaluation budget, the proposed approach consistently evaluates higher-severity contingencies than uniform sampling. This allows critical outages to be identified more reliably with reduced computational effort.

</details>


### [10] [PlugSI: Plug-and-Play Test-Time Graph Adaptation for Spatial Interpolation](https://arxiv.org/abs/2602.09824)
*Xuhang Wu,Zhuoxuan Liang,Wei Li,Xiaohua Jia,Sumi Helal*

Main category: cs.LG

TL;DR: PlugSI是一个即插即用的框架，通过未知拓扑适配器和时间平衡适配器，在测试时动态优化图结构，提升空间插值方法的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和边缘计算的发展，大规模传感器部署成本高昂。现有的基于图的空间插值方法依赖预训练模型，无法适应测试时更大或未见过的图结构，且忽略了测试数据的利用。

Method: 提出PlugSI框架，包含两个核心创新：1) 未知拓扑适配器(UTA)，在测试时适应每个小批量的新图结构；2) 时间平衡适配器(TBA)，维护稳定的历史共识来指导UTA适应，防止当前批次噪声导致的漂移。

Result: 实验表明PlugSI可以无缝集成到现有的基于图的空间插值方法中，并带来显著改进（例如MAE降低10.81%）。

Conclusion: PlugSI通过测试时图结构优化，解决了现有空间插值方法在泛化性和适应性方面的局限性，为大规模传感器网络部署提供了更有效的解决方案。

Abstract: With the rapid advancement of IoT and edge computing, sensor networks have become indispensable, driving the need for large-scale sensor deployment. However, the high deployment cost hinders their scalability. To tackle the issues, Spatial Interpolation (SI) introduces virtual sensors to infer readings from observed sensors, leveraging graph structure. However, current graph-based SI methods rely on pre-trained models, lack adaptation to larger and unseen graphs at test-time, and overlook test data utilization. To address these issues, we propose PlugSI, a plug-and-play framework that refines test-time graph through two key innovations. First, we design an Unknown Topology Adapter (UTA) that adapts to the new graph structure of each small-batch at test-time, enhancing the generalization of SI pre-trained models. Second, we introduce a Temporal Balance Adapter (TBA) that maintains a stable historical consensus to guide UTA adaptation and prevent drifting caused by noise in the current batch. Empirically, extensive experiments demonstrate PlugSI can be seamlessly integrated into existing graph-based SI methods and provide significant improvement (e.g., a 10.81% reduction in MAE).

</details>


### [11] [A Task-Centric Theory for Iterative Self-Improvement with Easy-to-Hard Curricula](https://arxiv.org/abs/2602.10014)
*Chenruo Liu,Yijun Dong,Yiqiu Shen,Qi Lei*

Main category: cs.LG

TL;DR: 论文分析了自改进LLM的理论基础，建立了有限样本下的性能保证，揭示了反馈循环机制，并证明了课程学习在特定条件下的优势。


<details>
  <summary>Details</summary>
Motivation: 尽管迭代自改进在实践中取得了成功，但其在有限样本设置下的理论基础仍然有限。本文旨在填补这一空白，为自改进过程提供理论分析框架。

Method: 将每轮自改进建模为对奖励过滤分布的最大似然微调，推导有限样本下的期望奖励保证。采用任务中心视角，考虑多难度级别的推理任务，分析模型初始化、任务难度和样本预算等条件。

Result: 分析揭示了明确的反馈循环机制：更好的模型每轮接受更多数据，支持持续自改进同时解释改进饱和现象。证明了在特定条件下，从易到难的课程学习比固定任务混合训练具有更好的理论保证。

Conclusion: 本文为LLM自改进提供了理论基础，揭示了其内在机制，并为课程学习策略提供了理论支持，通过蒙特卡洛模拟和图推理任务实验验证了分析结果。

Abstract: Iterative self-improvement fine-tunes an autoregressive large language model (LLM) on reward-verified outputs generated by the LLM itself. In contrast to the empirical success of self-improvement, the theoretical foundation of this generative, iterative procedure in a practical, finite-sample setting remains limited. We make progress toward this goal by modeling each round of self-improvement as maximum-likelihood fine-tuning on a reward-filtered distribution and deriving finite-sample guarantees for the expected reward. Our analysis reveals an explicit feedback loop where better models accept more data per iteration, supporting sustained self-improvement while explaining eventual saturation of such improvement. Adopting a task-centric view by considering reasoning tasks with multiple difficulty levels, we further prove quantifiable conditions on model initialization, task difficulty, and sample budget where easy-to-hard curricula provably achieve better guarantees than training on fixed mixtures of tasks. Our analyses are validated via Monte-Carlo simulations and controlled experiments on graph-based reasoning tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation](https://arxiv.org/abs/2602.09112)
*Russ Webb,Jason Ramapuram*

Main category: cs.AI

TL;DR: 研究人员开发了Cadmus系统，包含整数虚拟机、真实程序数据集和小型Transformer模型，用于以低成本研究程序合成、分布外表示和推理任务，相比大型语言模型提供更好的透明度和控制。


<details>
  <summary>Details</summary>
Motivation: 当前程序合成研究主要依赖大型语言模型，存在分布问题难以界定、微调效果不明、分词影响不清、计算存储成本高等问题。需要一个小型、透明、可控的系统来深入研究程序完成、分布外表示、归纳推理等核心问题。

Method: 开发Cadmus系统，包含：1）整数虚拟机；2）多样任务的真实程序数据集；3）自回归Transformer模型（训练成本低于200美元）。该系统允许研究人员精细控制训练分布，并能检查和插装模型。

Result: Cadmus模型在简单的整数算术程序完成任务上达到100%准确率，优于GPT-5的95%。更重要的是，系统提供了数据集与问题关系的透明度，而GPT-5在解决相同任务时引入了未知的先验知识，这成为某些研究中的混淆因素。

Conclusion: 小型模型在复杂推理任务上能够实现经济有效的插装和调查，为程序合成研究提供了透明、可控的平台。当需要完全理解训练集与任务关系时，大型语言模型的未知先验知识会成为研究障碍，而Cadmus系统解决了这一问题。

Abstract: What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\% accuracy while GPT-5 has 95\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.

</details>


### [13] [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063)
*Tianyi Jiang,Arctanx An,Hengyi Feng,Naixin Zhai,Haodong Li,Xiaomin Yu,Jiahui Liu,Hanwen Du,Shuo Zhang,Zhi Yang,Jie Huang,Yuhua Li,Yongxin Ni,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: 提出Chain of Mindset (CoM)框架，通过动态协调四种异构思维模式（空间、收敛、发散、算法）来提升LLM推理能力，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法存在"单一思维陷阱"，即在所有推理步骤中应用相同的固定思维模式，忽略了解决同一问题不同阶段需要根本不同的思维模式，这限制了模型达到更高智能水平。

Method: 提出CoM框架：1) 将推理分解为四种功能异构的思维模式：空间思维、收敛思维、发散思维、算法思维；2) 元代理根据演化中的推理状态动态选择最优思维模式；3) 双向上下文门控过滤跨模块信息流以保持效率和效果。

Result: 在数学、代码生成、科学QA和空间推理等六个挑战性基准测试中，CoM在Qwen3-VL-32B-Instruct和Gemini-2.0-Flash上分别以4.96%和4.72%的总体准确率优势超越最强基线，达到SOTA性能，同时平衡推理效率。

Conclusion: CoM框架通过动态协调多种思维模式，突破了现有LLM推理方法的单一思维限制，实现了更接近人类问题解决方式的适应性推理，为下一代智能系统提供了有前景的方向。

Abstract: Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\% and 4.72\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Knowledge Integration Decay in Search-Augmented Reasoning of Large Language Models](https://arxiv.org/abs/2602.09517)
*Sangwon Yu,Ik-hwan Kim,Donghun Kang,Bongkyu Hwang,Junhwa Choi,Suk-hoon Jung,Seungki Hong,Taehee Lee,Sungroh Yoon*

Main category: cs.CL

TL;DR: SAKE是一种无需训练、推理时使用的策略，通过将检索到的知识锚定在推理过程的首尾，解决LLMs在长推理链中知识整合衰减的问题。


<details>
  <summary>Details</summary>
Motivation: 研究发现大型语言模型在搜索增强推理中存在"知识整合衰减"瓶颈：随着搜索前生成的推理长度增加，模型越来越难以将检索到的证据整合到后续推理步骤中，即使相关信息可用也会限制性能。

Method: 提出Self-Anchored Knowledge Encoding (SAKE)策略，这是一种无需训练的推理时方法。通过在推理过程的开始和结束处锚定检索到的知识，防止知识被先前上下文淹没，从而保持其语义完整性。

Result: 在多跳问答和复杂推理基准测试上的广泛实验表明，SAKE显著缓解了知识整合衰减问题并提高了性能。

Conclusion: SAKE为智能体式LLMs中的知识整合提供了一种轻量级但有效的解决方案，无需额外训练即可改善知识利用的稳定性。

Abstract: Modern Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks by employing search-augmented reasoning to incorporate external knowledge into long chains of thought. However, we identify a critical yet underexplored bottleneck in this paradigm, termed Knowledge Integration Decay (KID). Specifically, we observe that as the length of reasoning generated before search grows, models increasingly fail to integrate retrieved evidence into subsequent reasoning steps, limiting performance even when relevant information is available. To address this, we propose Self-Anchored Knowledge Encoding (SAKE), a training-free inference-time strategy designed to stabilize knowledge utilization. By anchoring retrieved knowledge at both the beginning and end of the reasoning process, SAKE prevents it from being overshadowed by prior context, thereby preserving its semantic integrity. Extensive experiments on multi-hop QA and complex reasoning benchmarks demonstrate that SAKE significantly mitigates KID and improves performance, offering a lightweight yet effective solution for knowledge integration in agentic LLMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [15] [STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory](https://arxiv.org/abs/2602.09255)
*Mingfeng Yuan,Hao Zhang,Mahan Mohammadi,Runhao Li,Jinjun Shan,Steven L. Waslander*

Main category: cs.RO

TL;DR: STaR是一个面向移动机器人的智能推理框架，通过构建任务无关的多模态长期记忆和基于信息瓶颈原则的可扩展检索算法，支持在开放动态场景中进行长时程规划、检索和推理。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在开放动态场景中长期部署时，面临构建可扩展长期记忆的挑战，需要支持不同粒度的开放指令规划、检索和推理，同时产生精确可执行的导航答案。

Method: 提出STaR框架：(1)构建任务无关的多模态长期记忆，泛化到未见查询同时保留细粒度环境语义；(2)基于信息瓶颈原则设计可扩展的任务条件检索算法，从长期记忆中提取紧凑、非冗余、信息丰富的候选记忆进行上下文推理。

Result: 在NaVQA（混合室内外校园场景）和WH-VQA（仓库基准）数据集上，STaR持续优于强基线，实现更高成功率和显著更低的空间误差。在真实Husky轮式机器人上的室内外部署验证了其鲁棒的长时程推理、可扩展性和实际效用。

Conclusion: STaR框架有效解决了移动机器人在开放动态场景中的长期记忆和智能推理问题，通过创新的记忆构建和检索机制实现了可扩展的智能决策能力。

Abstract: Mobile robots are often deployed over long durations in diverse open, dynamic scenes, including indoor setting such as warehouses and manufacturing facilities, and outdoor settings such as agricultural and roadway operations. A core challenge is to build a scalable long-horizon memory that supports an agentic workflow for planning, retrieval, and reasoning over open-ended instructions at variable granularity, while producing precise, actionable answers for navigation. We present STaR, an agentic reasoning framework that (i) constructs a task-agnostic, multimodal long-term memory that generalizes to unseen queries while preserving fine-grained environmental semantics (object attributes, spatial relations, and dynamic events), and (ii) introduces a Scalable TaskConditioned Retrieval algorithm based on the Information Bottleneck principle to extract from long-term memory a compact, non-redundant, information-rich set of candidate memories for contextual reasoning. We evaluate STaR on NaVQA (mixed indoor/outdoor campus scenes) and WH-VQA, a customized warehouse benchmark with many visually similar objects built with Isaac Sim, emphasizing contextual reasoning. Across the two datasets, STaR consistently outperforms strong baselines, achieving higher success rates and markedly lower spatial error. We further deploy STaR on a real Husky wheeled robot in both indoor and outdoor environments, demonstrating robust longhorizon reasoning, scalability, and practical utility.

</details>


### [16] [CAPER: Constrained and Procedural Reasoning for Robotic Scientific Experiments](https://arxiv.org/abs/2602.09367)
*Jinghan Yang,Jingyi Hou,Xinbo Yu,Wei He,Yifan Wu*

Main category: cs.RO

TL;DR: CAPER框架通过责任分离结构实现科学实验机器人操作：高层任务推理生成符合约束的动作序列，中层多模态接地实现子任务，低层强化学习适应物理不确定性，提高成功率、程序正确性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 科学实验室机器人辅助需要程序正确的长时程操作、有限监督下的可靠执行，以及低演示数据下的鲁棒性。端到端视觉-语言-动作模型在这些条件下面临挑战，其可恢复错误假设和数据驱动策略学习在协议敏感实验中常常失效。

Method: CAPER采用责任分离结构：1) 任务级推理在显式约束下生成程序有效的动作序列；2) 中层多模态接地实现子任务，不将空间决策委托给大语言模型；3) 低层控制通过最少演示的强化学习适应物理不确定性。通过可解释中间表示编码程序承诺。

Result: 在科学工作流基准和公共长时程操作数据集上的实验显示，在成功率、程序正确性方面取得一致改进，特别是在低数据和长时程设置下表现优异。

Conclusion: CAPER通过限制学习和推理在规划控制管道中的位置，防止执行时违反实验逻辑，提高了可控性、鲁棒性和数据效率，为科学实验机器人提供了更可靠的解决方案。

Abstract: Robotic assistance in scientific laboratories requires procedurally correct long-horizon manipulation, reliable execution under limited supervision, and robustness in low-demonstration regimes. Such conditions greatly challenge end-to-end vision-language-action (VLA) models, whose assumptions of recoverable errors and data-driven policy learning often break down in protocol-sensitive experiments. We propose CAPER, a framework for Constrained And ProcEdural Reasoning for robotic scientific experiments, which explicitly restricts where learning and reasoning occur in the planning and control pipeline. Rather than strengthening end-to-end policies, CAPER enforces a responsibility-separated structure: task-level reasoning generates procedurally valid action sequences under explicit constraints, mid-level multimodal grounding realizes subtasks without delegating spatial decision-making to large language models, and low-level control adapts to physical uncertainty via reinforcement learning with minimal demonstrations. By encoding procedural commitments through interpretable intermediate representations, CAPER prevents execution-time violations of experimental logic, improving controllability, robustness, and data efficiency. Experiments on a scientific workflow benchmark and a public long-horizon manipulation dataset demonstrate consistent improvements in success rate and procedural correctness, particularly in low-data and long-horizon settings.

</details>


### [17] [Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments](https://arxiv.org/abs/2602.09430)
*Yiwen Pang,Bo Zhou,Changjin Li,Xuanhao Wang,Shengxiang Xu,Deng-Bao Wang,Min-Ling Zhang,Shimin Di*

Main category: cs.RO

TL;DR: 提出Agentic VLA推理插件，通过LLM代理机制在科学实验长时程任务中生成过渡动作代码，解决VLA模型执行复合任务时的分布不匹配问题，无需额外训练即可提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 科学实验通常由多个原子任务组成的长时程复合任务，现有VLA模型虽然能可靠执行训练中见过的原子动作，但在重新组合这些原子动作形成复合任务时，由于训练时的原子任务与推理时的复合任务存在分布不匹配，导致模型无法执行必要的过渡操作。

Method: 提出Agentic VLA推理插件，引入基于LLM的代理推理机制，在执行顺序操作任务时进行干预。通过显式的过渡推理和生成过渡性机器人动作代码，引导VLA模型完成缺失的过渡步骤，实现复合科学工作流的可靠执行。

Result: 在现有仿真环境中构建科学仪器和常见科学操作场景的3D资产，验证方法将每个原子任务的平均成功率提高了42%。同时展示方法可以轻松从仿真环境迁移到真实科学实验室。

Conclusion: 该方法通过推理时干预而非额外训练，计算和数据效率高，适合开放性和长时程的机器人实验室任务，有效解决了VLA模型在科学实验复合任务执行中的分布不匹配问题。

Abstract: Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during training, they often fail to perform composite tasks formed by reordering and composing these known atomic actions. This limitation arises from a distributional mismatch between training-time atomic tasks and inference-time composite tasks, which prevents VLA models from executing necessary transitional operations between atomic tasks. To address this challenge, we propose an Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments. It introduces an LLM-based agentic inference mechanism that intervenes when executing sequential manipulation tasks. By performing explicit transition inference and generating transitional robotic action code, the proposed plugin guides VLA models through missing transitional steps, enabling reliable execution of composite scientific workflows without any additional training. This inference-only intervention makes our method computationally efficient, data-efficient, and well-suited for open-ended and long-horizon robotic laboratory tasks. We build 3D assets of scientific instruments and common scientific operating scenes within an existing simulation environment. In these scenes, we have verified that our method increases the average success rate per atomic task by 42\% during inference. Furthermore, we show that our method can be easily transferred from the simulation to real scientific laboratories.

</details>


### [18] [Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning](https://arxiv.org/abs/2602.09767)
*Ruopeng Cui,Yifei Bi,Haojie Luo,Wei Li*

Main category: cs.RO

TL;DR: 提出OMoE架构和多判别器框架，用于无监督技能发现，防止技能表示重叠和奖励欺骗，在四足机器人上实现多样化的运动技能。


<details>
  <summary>Details</summary>
Motivation: 强化学习需要专家精心设计奖励函数，模仿学习需要昂贵的任务特定数据。现有无监督技能发现方法存在两个关键问题：1）依赖单一策略学习多样化技能，没有建模技能间的共享结构和差异，导致学习效率低；2）容易发生奖励欺骗，奖励信号快速增加但实际技能多样性不足。

Method: 1）提出正交混合专家（OMoE）架构，防止多样化行为在表示空间中重叠，使单一策略能够掌握广泛的运动技能；2）设计多判别器框架，不同判别器在不同观察空间上操作，有效缓解奖励欺骗问题。

Result: 在12-DOF Unitree A1四足机器人上评估，展示了多样化的运动技能。实验表明，提出的框架提高了训练效率，与基线相比状态空间覆盖度提升了18.3%。

Conclusion: 通过OMoE架构和多判别器框架，解决了无监督技能发现中的技能表示重叠和奖励欺骗问题，实现了更高效和多样化的技能学习。

Abstract: Reinforcement learning necessitates meticulous reward shaping by specialists to elicit target behaviors, while imitation learning relies on costly task-specific data. In contrast, unsupervised skill discovery can potentially reduce these burdens by learning a diverse repertoire of useful skills driven by intrinsic motivation. However, existing methods exhibit two key limitations: they typically rely on a single policy to master a versatile repertoire of behaviors without modeling the shared structure or distinctions among them, which results in low learning efficiency; moreover, they are susceptible to reward hacking, where the reward signal increases and converges rapidly while the learned skills display insufficient actual diversity. In this work, we introduce an Orthogonal Mixture-of-Experts (OMoE) architecture that prevents diverse behaviors from collapsing into overlapping representations, enabling a single policy to master a wide spectrum of locomotion skills. In addition, we design a multi-discriminator framework in which different discriminators operate on distinct observation spaces, effectively mitigating reward hacking. We evaluated our method on the 12-DOF Unitree A1 quadruped robot, demonstrating a diverse set of locomotion skills. Our experiments demonstrate that the proposed framework boosts training efficiency and yields an 18.3\% expansion in state-space coverage compared to the baseline.

</details>


### [19] [Acoustic Drone Package Delivery Detection](https://arxiv.org/abs/2602.09991)
*François Marcoux,François Grondin*

Main category: cs.RO

TL;DR: 基于地面麦克风阵列的声学包裹投递检测算法，通过分析无人机螺旋桨转速变化识别投递事件


<details>
  <summary>Details</summary>
Motivation: 近年来无人机在监狱等限制区域的非法投递成为重大安全隐患，现有研究多关注无人机检测或定位，对投递事件识别关注不足

Method: 使用地面麦克风阵列采集声学信号，通过深度神经网络从梅尔频谱图中检测无人机存在并估计螺旋桨转速（叶片通过频率），分析转速在特定时间前后的突变来识别投递时刻

Result: 无人机150米范围内叶片通过频率估计平均绝对误差16Hz，无人机存在检测准确率97%，投递事件识别正确率96%，误报率8%，有效检测范围达100米

Conclusion: 研究表明声学信号可在100米范围内有效识别无人机投递事件，为限制区域安全监控提供了新方法

Abstract: In recent years, the illicit use of unmanned aerial vehicles (UAVs) for deliveries in restricted area such as prisons became a significant security challenge. While numerous studies have focused on UAV detection or localization, little attention has been given to delivery events identification. This study presents the first acoustic package delivery detection algorithm using a ground-based microphone array. The proposed method estimates both the drone's propeller speed and the delivery event using solely acoustic features. A deep neural network detects the presence of a drone and estimates the propeller's rotation speed or blade passing frequency (BPF) from a mel spectrogram. The algorithm analyzes the BPFs to identify probable delivery moments based on sudden changes before and after a specific time. Results demonstrate a mean absolute error of the blade passing frequency estimator of 16 Hz when the drone is less than 150 meters away from the microphone array. The drone presence detection estimator has a accuracy of 97%. The delivery detection algorithm correctly identifies 96% of events with a false positive rate of 8%. This study shows that deliveries can be identified using acoustic signals up to a range of 100 meters.

</details>
