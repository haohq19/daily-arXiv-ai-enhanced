<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning](https://arxiv.org/abs/2510.19183)
*Fengyuan Sun,Hui Chen,Xinhao Xu,Dandan Zheng,Jingdong Chen,Jun Zhou,Jungong Han,Guiguang Ding*

Main category: cs.CV

TL;DR: PruneHal是一种无需训练的方法，通过自适应KV缓存剪枝来增强MLLMs对关键视觉信息的关注，从而减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案要么引入额外数据进行训练，要么在推理时加入外部或内部信息，这些方法都会带来额外计算成本。研究发现MLLMs中的幻觉与视觉token注意力不足密切相关。

Method: 提出PruneHal方法，利用自适应KV缓存剪枝来增强模型对关键视觉信息的关注，无需额外训练，几乎不增加推理成本，且与不同解码策略兼容。

Result: 在多个主流幻觉评估基准上使用四种主流MLLMs进行测试，取得了稳健且出色的结果。

Conclusion: PruneHal是首个将token剪枝应用于MLLMs幻觉缓解的方法，具有模型无关性，能无缝集成到不同解码策略中，有效性和优越性得到验证。

Abstract: While multi-modal large language models (MLLMs) have made significant
progress in recent years, the issue of hallucinations remains a major
challenge. To mitigate this phenomenon, existing solutions either introduce
additional data for further training or incorporate external or internal
information during inference. However, these approaches inevitably introduce
extra computational costs. In this paper, we observe that hallucinations in
MLLMs are strongly associated with insufficient attention allocated to visual
tokens. In particular, the presence of redundant visual tokens disperses the
model's attention, preventing it from focusing on the most informative ones. As
a result, critical visual cues are often under-attended, which in turn
exacerbates the occurrence of hallucinations. Building on this observation, we
propose \textbf{PruneHal}, a training-free, simple yet effective method that
leverages adaptive KV cache pruning to enhance the model's focus on critical
visual information, thereby mitigating hallucinations. To the best of our
knowledge, we are the first to apply token pruning for hallucination mitigation
in MLLMs. Notably, our method don't require additional training and incurs
nearly no extra inference cost. Moreover, PruneHal is model-agnostic and can be
seamlessly integrated with different decoding strategies, including those
specifically designed for hallucination mitigation. We evaluate PruneHal on
several widely used hallucination evaluation benchmarks using four mainstream
MLLMs, achieving robust and outstanding results that highlight the
effectiveness and superiority of our method. Our code will be publicly
available.

</details>


### [2] [DARE: A Deformable Adaptive Regularization Estimator for Learning-Based Medical Image Registration](https://arxiv.org/abs/2510.19353)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: DARE是一个可变形医学图像配准框架，通过动态调整弹性正则化来平衡稳定性和灵活性，同时包含折叠预防机制以确保物理合理的变换。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在医学图像配准中往往忽视正则化的重要性，导致缺乏鲁棒性和解剖学合理性。

Method: 基于变形场梯度范数动态调整弹性正则化，整合应变和剪切能量项，并包含折叠预防机制惩罚负变形雅可比区域。

Result: 该方法减轻了非物理伪影如折叠，避免了过度平滑，提高了配准精度和解剖学合理性。

Conclusion: DARE框架通过自适应正则化在医学图像配准中实现了更好的稳定性和解剖学合理性。

Abstract: Deformable medical image registration is a fundamental task in medical image
analysis. While deep learning-based methods have demonstrated superior accuracy
and computational efficiency compared to traditional techniques, they often
overlook the critical role of regularization in ensuring robustness and
anatomical plausibility. We propose DARE (Deformable Adaptive Regularization
Estimator), a novel registration framework that dynamically adjusts elastic
regularization based on the gradient norm of the deformation field. Our
approach integrates strain and shear energy terms, which are adaptively
modulated to balance stability and flexibility. To ensure physically realistic
transformations, DARE includes a folding-prevention mechanism that penalizes
regions with negative deformation Jacobian. This strategy mitigates
non-physical artifacts such as folding, avoids over-smoothing, and improves
both registration accuracy and anatomical plausibility

</details>


### [3] [HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking](https://arxiv.org/abs/2510.19560)
*Yao Deng,Xian Zhong,Wenxuan Liu,Zhaofei Yu,Jingling Yuan,Tiejun Huang*

Main category: cs.CV

TL;DR: 提出HAD框架，通过分层非对称蒸馏解决RGB相机和事件相机之间的时空不对称问题，提升多模态目标跟踪性能


<details>
  <summary>Details</summary>
Motivation: RGB相机和事件相机具有互补优势，但两者存在显著的时空不对称性，阻碍了有效的多模态融合

Method: 提出分层非对称蒸馏框架，采用分层对齐策略，在保持学生网络计算效率和参数紧凑性的同时最小化信息损失

Result: 在多个实验中一致优于最先进方法，消融研究验证了各设计组件的有效性和必要性

Conclusion: HAD框架成功解决了多模态融合中的时空不对称问题，显著提升了目标跟踪性能

Abstract: RGB cameras excel at capturing rich texture details with high spatial
resolution, whereas event cameras offer exceptional temporal resolution and a
high dynamic range (HDR). Leveraging their complementary strengths can
substantially enhance object tracking under challenging conditions, such as
high-speed motion, HDR environments, and dynamic background interference.
However, a significant spatio-temporal asymmetry exists between these two
modalities due to their fundamentally different imaging mechanisms, hindering
effective multi-modal integration. To address this issue, we propose
{Hierarchical Asymmetric Distillation} (HAD), a multi-modal knowledge
distillation framework that explicitly models and mitigates spatio-temporal
asymmetries. Specifically, HAD proposes a hierarchical alignment strategy that
minimizes information loss while maintaining the student network's
computational efficiency and parameter compactness. Extensive experiments
demonstrate that HAD consistently outperforms state-of-the-art methods, and
comprehensive ablation studies further validate the effectiveness and necessity
of each designed component. The code will be released soon.

</details>


### [4] [Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning](https://arxiv.org/abs/2510.19622)
*Zhengxuan Wei,Jiajin Tang,Sibei Yang*

Main category: cs.CV

TL;DR: 提出AMR框架解决时刻检索的三个关键瓶颈：数据稀缺、边界模糊和语义区分不足，通过零外部依赖的增强方法提升性能


<details>
  <summary>Details</summary>
Motivation: 解决现有时刻检索方法面临的三个关键问题：数据稀缺导致模型陷入浅层关键词特征关联、相邻事件间边界模糊、以及细粒度语义区分能力不足

Method: 提出两阶段训练框架：冷启动阶段使用课程学习在增强数据上建立基础边界/语义感知；蒸馏阶段引入双查询集（原始查询和动态查询），通过跨阶段蒸馏损失保持知识一致性

Result: 在多个基准测试中，AMR相比之前的最先进方法实现了性能提升

Conclusion: AMR框架能够在不依赖外部数据的情况下有效解决时刻检索中的边界模糊和语义混淆问题，显著提升模型性能

Abstract: Existing Moment Retrieval methods face three critical bottlenecks: (1) data
scarcity forces models into shallow keyword-feature associations; (2) boundary
ambiguity in transition regions between adjacent events; (3) insufficient
discrimination of fine-grained semantics (e.g., distinguishing ``kicking" vs.
``throwing" a ball). In this paper, we propose a zero-external-dependency
Augmented Moment Retrieval framework, AMR, designed to overcome local optima
caused by insufficient data annotations and the lack of robust boundary and
semantic discrimination capabilities. AMR is built upon two key insights: (1)
it resolves ambiguous boundary information and semantic confusion in existing
annotations without additional data (avoiding costly manual labeling), and (2)
it preserves boundary and semantic discriminative capabilities enhanced by
training while generalizing to real-world scenarios, significantly improving
performance. Furthermore, we propose a two-stage training framework with
cold-start and distillation adaptation. The cold-start stage employs curriculum
learning on augmented data to build foundational boundary/semantic awareness.
The distillation stage introduces dual query sets: Original Queries maintain
DETR-based localization using frozen Base Queries from the cold-start model,
while Active Queries dynamically adapt to real-data distributions. A
cross-stage distillation loss enforces consistency between Original and Base
Queries, preventing knowledge forgetting while enabling real-world
generalization. Experiments on multiple benchmarks show that AMR achieves
improved performance over prior state-of-the-art approaches.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation](https://arxiv.org/abs/2510.19296)
*Yang Zhang,Rui Zhang,Jiaming Guo,Lei Huang,Di Huang,Yunpu Zhao,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 提出了QiMeng-SALV方法，通过利用功能正确的输出信号的代码段来优化Verilog代码生成的强化学习训练，解决了传统模块级优化中功能性奖励不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在Verilog代码生成方面展现出潜力，但基于强化学习的偏好优化缺乏有意义的函数奖励，阻碍了生成功能正确代码的能力。

Method: 通过比较生成模块与参考模块的信号功能正确性，提取已验证的信号感知实现；使用抽象语法树识别信号感知代码段；引入信号感知DPO在正确的信号级代码段上进行优化。

Result: 在VerilogEval和RTLLM基准测试中达到最先进性能，7B参数模型性能与DeepSeek v3 671B模型相当，并显著优于在同一数据集上训练的开源模型CodeV。

Conclusion: QiMeng-SALV标志着Verilog代码生成从传统模块级优化向细粒度信号级优化的范式转变，有效解决了功能性奖励不足的问题。

Abstract: The remarkable progress of Large Language Models (LLMs) presents promising
opportunities for Verilog code generation which is significantly important for
automated circuit design. The lacking of meaningful functional rewards hinders
the preference optimization based on Reinforcement Learning (RL) for producing
functionally correct Verilog code. In this paper, we propose Signal-Aware
Learning for Verilog code generation (QiMeng-SALV) by leveraging code segments
of functionally correct output signal to optimize RL training. Considering
Verilog code specifies the structural interconnection of hardware gates and
wires so that different output signals are independent, the key insight of
QiMeng-SALV is to extract verified signal-aware implementations in partially
incorrect modules, so as to enhance the extraction of meaningful functional
rewards. Roughly, we verify the functional correctness of signals in generated
module by comparing with that of reference module in the training data. Then
abstract syntax tree (AST) is employed to identify signal-aware code segments
which can provide meaningful functional rewards from erroneous modules.
Finally, we introduce signal-aware DPO which is optimized on the correct
signal-level code segments, thereby preventing noise and interference from
incorrect signals. The proposed QiMeng-SALV underscores the paradigm shift from
conventional module-level to fine-grained signal-level optimization in Verilog
code generation, addressing the issue of insufficient functional rewards.
Experiments demonstrate that our method achieves state-of-the-art performance
on VerilogEval and RTLLM, with a 7B parameter model matching the performance of
the DeepSeek v3 671B model and significantly outperforming the leading
open-source model CodeV trained on the same dataset. Our code is available at
https://github.com/zy1xxx/SALV.

</details>


### [6] [Foundation Model Forecasts: Form and Function](https://arxiv.org/abs/2510.19345)
*Alvaro Perez-Diaz,James C. Loach,Danielle E. Toutoungi,Lee Middleton*

Main category: cs.LG

TL;DR: 该论文指出时间序列基础模型(TSFMs)的预测形式(点预测、分位数预测、参数预测或轨迹集成)决定了其实际应用价值，许多操作任务需要轨迹集成来保持时间依赖性，而多数TSFM仅产生点或参数预测。


<details>
  <summary>Details</summary>
Motivation: 当前TSFMs虽然预测精度高，但仅关注精度不足以确定实际价值。预测形式限制了其支持的操作任务类型，需要研究不同预测形式之间的转换可能性和实际应用价值。

Method: 调查近期TSFMs的预测形式，建立预测类型转换的理论框架，证明边际分布无法确定路径依赖事件概率，映射六个基本预测任务到最小充分预测类型，提供任务对齐的评估框架。

Result: 发现三分之二的TSFMs仅产生点或参数预测，而许多操作任务需要轨迹集成。证明轨迹集成可以通过边际化转换为简单形式，但反向转换需要施加时间依赖性。

Conclusion: 预测类型而非精度决定了实际效用，需要根据具体任务选择合适的预测形式，轨迹集成对于需要时间依赖性的操作任务至关重要。

Abstract: Time-series foundation models (TSFMs) achieve strong forecast accuracy, yet
accuracy alone does not determine practical value. The form of a forecast --
point, quantile, parametric, or trajectory ensemble -- fundamentally constrains
which operational tasks it can support. We survey recent TSFMs and find that
two-thirds produce only point or parametric forecasts, while many operational
tasks require trajectory ensembles that preserve temporal dependence. We
establish when forecast types can be converted and when they cannot: trajectory
ensembles convert to simpler forms via marginalization without additional
assumptions, but the reverse requires imposing temporal dependence through
copulas or conformal methods. We prove that marginals cannot determine
path-dependent event probabilities -- infinitely many joint distributions share
identical marginals but yield different answers to operational questions. We
map six fundamental forecasting tasks to minimal sufficient forecast types and
provide a task-aligned evaluation framework. Our analysis clarifies when
forecast type, not accuracy, differentiates practical utility.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [7] [When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs](https://arxiv.org/abs/2510.18892)
*Richard J. Young,Brandon Gillins,Alice M. Matthews*

Main category: cs.CL

TL;DR: 提出了一个简化的评估框架，使用20个精心设计的提示来评估LLM的指令遵循能力，通过大规模实证研究测试了256个模型。


<details>
  <summary>Details</summary>
Motivation: 由于现有模型可能在已有基准上进行训练，需要新的评估方法来评估真实能力而非记忆性能；同时需要实用的诊断工具来快速评估特定指令遵循模式。

Method: 构建包含20个提示的紧凑测试套件，涵盖格式合规、内容约束、逻辑排序和多步任务执行等不同方面；通过OpenRouter测试256个验证可用的模型。

Result: 研究揭示了持续存在的失败模式，并识别出特定类型的指令特别具有挑战性；提供了主要提供商和新兴实现模型的比较性能分析。

Conclusion: 该工作既提供了实用的评估工具，又对当代LLM景观中的指令遵循能力进行了最全面的实证分析之一。

Abstract: Despite widespread deployment of Large Language Models, systematic evaluation
of instruction-following capabilities remains challenging. While comprehensive
benchmarks exist, focused assessments that quickly diagnose specific
instruction adherence patterns are valuable. As newer models may be trained on
existing benchmarks, novel evaluation approaches are needed to assess genuine
capabilities rather than memorized performance. This paper presents a
streamlined evaluation framework using twenty carefully designed prompts to
assess LLM instruction-following across diverse task categories. We demonstrate
this framework through a large-scale empirical study conducted on October 14,
2025, testing 256 verified working models from 331 available via OpenRouter. To
ensure methodological rigor and prevent selection bias, we first verified each
model's basic functionality before inclusion. Unlike large-scale benchmarks
requiring extensive computational resources, our approach offers a practical
diagnostic tool researchers and practitioners can readily apply. Our
methodology builds upon verifiable instructions while introducing a compact
test suite balancing comprehensiveness with efficiency. Each prompt targets
distinct aspects of instruction following, including format compliance, content
constraints, logical sequencing, and multi-step task execution. We evaluate
models from major providers (OpenAI, Anthropic, Google, Meta, Mistral) and
emerging implementations (Qwen, DeepSeek, community models), providing
comparative performance analysis. Our findings reveal consistent failure modes
and identify specific instruction types posing particular challenges. This work
contributes both a practical evaluation tool and one of the most comprehensive
empirical analyses of instruction-following capabilities across the
contemporary LLM landscape.

</details>


### [8] [MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs](https://arxiv.org/abs/2510.19366)
*Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li*

Main category: cs.CL

TL;DR: MoE-Prism通过将传统MoE模型中的单体专家分解为细粒度子专家，提供了弹性服务能力，解决了MoE模型在成本和质量之间难以权衡的问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型通过稀疏激活参数实现高质量，但采用top-k路由机制导致只能提供少量粗粒度操作点，无法适应多样化的服务级别目标(SLOs)，造成资源过度配置。

Method: 采用模型-系统协同设计：1) 离线重构引擎使用元启发式方法将单体专家分解为细粒度子专家；2) 在线调度引擎实现QoS感知调度，支持云部署的最大吞吐量和内存受限设备的延迟优化卸载。

Result: 在三个不同MoE模型上的评估显示，MoE-Prism比基线提供超过4倍的稳定操作点，在严格延迟预算下可将吞吐量提高19.9%，在有限资源下可将延迟降低10.36%。

Conclusion: MoE-Prism提供了关键的"控制旋钮"来弥合模型-系统差距，实现了自适应、高效和QoS感知的AI服务。

Abstract: Mixture-of-Experts (MoE) models, the state-of-the-art in large-scale AI,
achieve high quality by sparsely activating parameters. However, their reliance
on routing between a few monolithic experts via a top-k mechanism creates a
"quality cliff", offering only a few coarse-grained operating points. This
inflexibility forces a difficult trade-off between cost and quality, preventing
adaptation to diverse Service Level Objectives (SLOs) and leading to
significant resource over-provisioning.
  This paper introduces MoE-Prism, a model-system co-design that transforms
rigid MoE models into elastic services. Our methodology is divided into two
phases. First, an \emph{Offline Refactoring Engine} systematically deconstructs
monolithic experts into fine-grained "sub-experts." This engine employs a
partitioning optimization solver that uses a metaheuristic-based approach to
group neurons, preserving functional locality without requiring retraining.
Second, an \emph{Online Scheduling Engine} leverages this new elasticity
through QoS-aware scheduling. It implements specialized policies to solve
complex system problems, including maximizing throughput in cloud deployments
and managing latency-optimized offloading for memory-constrained devices. Our
evaluation across three different MoE models shows that MoE-Prismprovides over
4 times more distinct, stable operating points than the baseline. This allows
an AI service to dynamically improve throughput by up to 19.9\% under a strict
latency budget or reduce latency by up to 10.36\% under limited resources.
MoE-Prism provides the critical "control knob" to bridge the model-system gap,
enabling the next generation of adaptive, efficient, and QoS-aware AI services.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering](https://arxiv.org/abs/2510.19054)
*Shiyu Liu,Ilija Hadzic,Akshay Gupta,Aliasghar Arab*

Main category: cs.RO

TL;DR: 为具有独立转向的过驱动4轮驱动系统（4WIS）开发运动规划和控制方法，处理机械约束导致的转向不连续性，通过数学建模和速度空间分区实现平滑运动。


<details>
  <summary>Details</summary>
Motivation: 4WIS机器人的机械约束限制了车轮的360度旋转能力，导致配置空间存在不连续性，影响运动平滑性，需要专门的运动规划和控制方法。

Method: 建立转向约束的数学公式，推导速度空间的不连续平面分区，设计考虑转向约束和速度过渡平滑性的运动规划器，使用局部反馈控制器处理不连续穿越。

Result: 实现了ROS导航包的扩展，在仿真和物理机器人上进行了系统评估，验证了方法的有效性。

Conclusion: 提出的方法成功解决了4WIS机器人在转向约束下的运动规划和控制问题，实现了平滑高效的运动。

Abstract: This paper addresses motion planning and con- trol of an overactuated 4-wheel
drive train with independent steering (4WIS) where mechanical constraints
prevent the wheels from executing full 360-degree rotations (swerve). The
configuration space of such a robot is constrained and contains discontinuities
that affect the smoothness of the robot motion. We introduce a mathematical
formulation of the steering constraints and derive discontinuity planes that
partition the velocity space into regions of smooth and efficient motion. We
further design the motion planner for path tracking and ob- stacle avoidance
that explicitly accounts for swerve constraints and the velocity transition
smoothness. The motion controller uses local feedback to generate actuation
from the desired velocity, while properly handling the discontinuity crossing
by temporarily stopping the motion and repositioning the wheels. We implement
the proposed motion planner as an extension to ROS Navigation package and
evaluate the system in simulation and on a physical robot.

</details>


### [10] [Convex Maneuver Planning for Spacecraft Collision Avoidance](https://arxiv.org/abs/2510.19058)
*Fausto Vega,Jon Arrizabalaga,Ryan Watson,Zachary Manchester*

Main category: cs.RO

TL;DR: 提出了一种用于短期交会事件的低推力碰撞规避机动规划算法，通过凸优化方法求解非凸问题，确保在最近接近点达到期望的碰撞概率。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星密度增加，传统的手动碰撞规避规划过程耗时且效率低，需要自主化解决方案来提高评估和缓解碰撞的效率。

Method: 将问题建模为非凸二次约束二次规划问题，然后使用Shor松弛转化为凸半定规划问题，通过松弛约束获得全局最优解。

Result: 经验证该松弛方法是紧致的，能够恢复原始非凸问题的全局最优解，在高保真模拟中有效降低了碰撞风险。

Conclusion: 该方法能够生成最小能量解，同时确保期望的碰撞概率，在无法满足约束时提供最小风险解，为自主碰撞规避提供了有效解决方案。

Abstract: Conjunction analysis and maneuver planning for spacecraft collision avoidance
remains a manual and time-consuming process, typically involving repeated
forward simulations of hand-designed maneuvers. With the growing density of
satellites in low-Earth orbit (LEO), autonomy is becoming essential for
efficiently evaluating and mitigating collisions. In this work, we present an
algorithm to design low-thrust collision-avoidance maneuvers for short-term
conjunction events. We first formulate the problem as a nonconvex
quadratically-constrained quadratic program (QCQP), which we then relax into a
convex semidefinite program (SDP) using Shor's relaxation. We demonstrate
empirically that the relaxation is tight, which enables the recovery of
globally optimal solutions to the original nonconvex problem. Our formulation
produces a minimum-energy solution while ensuring a desired probability of
collision at the time of closest approach. Finally, if the desired probability
of collision cannot be satisfied, we relax this constraint into a penalty,
yielding a minimum-risk solution. We validate our algorithm with a
high-fidelity simulation of a satellite conjunction in low-Earth orbit with a
simulated conjunction data message (CDM), demonstrating its effectiveness in
reducing collision risk.

</details>
