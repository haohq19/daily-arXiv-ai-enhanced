<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 6]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving](https://arxiv.org/abs/2512.14044)
*Zhenguo Zhang,Haohan Zhen,Yishen Wang,Le Xu,Tianchen Deng,Xuefeng Chen,Qu Chen,Bo Zhang,Wuxiong Huang*

Main category: cs.CV

TL;DR: OmniDrive-R1是一个用于自动驾驶的端到端视觉语言模型框架，通过交错多模态思维链机制统一感知和推理，利用强化学习驱动的视觉定位能力消除目标幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在自动驾驶等安全关键领域部署时存在可靠性问题，主要是目标幻觉。现有方法存在感知与推理阶段分离、依赖昂贵的密集定位标签等根本缺陷。

Method: 提出OmniDrive-R1框架，采用交错多模态思维链机制统一感知和推理。核心创新是强化学习驱动的视觉定位能力，通过两阶段强化学习训练流程和Clip-GRPO算法实现，该算法引入无标注、基于过程的定位奖励。

Result: 在DriveLMM-o1数据集上的实验显示显著改进：与基线Qwen2.5VL-7B相比，总体推理分数从51.77%提升到80.35%，最终答案准确率从37.81%提升到73.62%。

Conclusion: OmniDrive-R1通过端到端统一感知和推理、强化学习驱动的视觉定位以及无标注的奖励机制，有效解决了自动驾驶中视觉语言模型的目标幻觉问题，显著提升了可靠性和性能。

Abstract: The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and "zoom in" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.

</details>


### [2] [ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes](https://arxiv.org/abs/2512.14092)
*Felix Holm,Ghazal Ghazaei,Nassir Navab*

Main category: cs.CV

TL;DR: ProtoFlow：一种通过动态场景图原型学习来建模复杂手术工作流的可解释框架，在有限数据场景下表现优异


<details>
  <summary>Details</summary>
Motivation: 详细的手术识别对AI辅助手术至关重要，但面临高标注成本、数据稀缺和缺乏可解释模型等挑战。虽然场景图提供了手术事件的结构化抽象，但其潜力尚未充分发挥。

Method: 采用图神经网络编码器-解码器架构，结合自监督预训练进行丰富表示学习，然后通过基于原型的微调阶段发现和优化核心原型，这些原型封装了重复出现的、具有临床意义的手术交互模式。

Result: 在CAT-SG数据集上评估，ProtoFlow不仅超越标准GNN基线，在有限数据、少样本场景下表现出色，仅用一个手术视频训练仍保持强性能。学习到的原型能成功识别不同的手术子技术，并提供清晰可解释的工作流偏差和罕见并发症洞察。

Conclusion: 通过将鲁棒表示学习与内在可解释性相结合，ProtoFlow代表了向开发更透明、可靠、数据高效的AI系统迈出的重要一步，加速其在手术培训、实时决策支持和流程优化中的临床采用潜力。

Abstract: Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.
  Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.
  Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.
  Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.

</details>


### [3] [TAT: Task-Adaptive Transformer for All-in-One Medical Image Restoration](https://arxiv.org/abs/2512.14550)
*Zhiwen Yang,Jiaju Zhang,Yang Yi,Jian Liang,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 提出任务自适应Transformer（TAT）框架，通过任务自适应权重生成和损失平衡策略，解决多任务医学图像恢复中的任务干扰和任务不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像恢复（MedIR）中，All-in-One模型需要同时处理多种不同模态和退化类型的任务。由于任务间存在显著差异，共享模型面临两个关键挑战：任务干扰（不同任务对同一参数的梯度更新方向冲突）和任务不平衡（各任务学习难度不同导致的优化不均衡）。

Method: 提出任务自适应Transformer（TAT）框架，包含两个核心创新：1）任务自适应权重生成策略：为每个任务生成特定的权重参数，避免共享权重上的梯度冲突；2）任务自适应损失平衡策略：根据任务学习难度动态调整损失权重，防止某些任务主导或训练不足。

Result: 在PET合成、CT去噪和MRI超分辨率三个MedIR任务上，TAT在任务特定和All-in-One设置下均取得了最先进的性能。

Conclusion: TAT通过任务自适应机制有效解决了多任务医学图像恢复中的任务干扰和任务不平衡问题，为All-in-One MedIR模型提供了有效的解决方案。

Abstract: Medical image restoration (MedIR) aims to recover high-quality medical images from their low-quality counterparts. Recent advancements in MedIR have focused on All-in-One models capable of simultaneously addressing multiple different MedIR tasks. However, due to significant differences in both modality and degradation types, using a shared model for these diverse tasks requires careful consideration of two critical inter-task relationships: task interference, which occurs when conflicting gradient update directions arise across tasks on the same parameter, and task imbalance, which refers to uneven optimization caused by varying learning difficulties inherent to each task. To address these challenges, we propose a task-adaptive Transformer (TAT), a novel framework that dynamically adapts to different tasks through two key innovations. First, a task-adaptive weight generation strategy is introduced to mitigate task interference by generating task-specific weight parameters for each task, thereby eliminating potential gradient conflicts on shared weight parameters. Second, a task-adaptive loss balancing strategy is introduced to dynamically adjust loss weights based on task-specific learning difficulties, preventing task domination or undertraining. Extensive experiments demonstrate that our proposed TAT achieves state-of-the-art performance in three MedIR tasks--PET synthesis, CT denoising, and MRI super-resolution--both in task-specific and All-in-One settings. Code is available at https://github.com/Yaziwel/TAT.

</details>


### [4] [TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios](https://arxiv.org/abs/2512.14595)
*Mengyu Li,Xingcheng Zhou,Guang Chen,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: 本文提出了首个面向智能交通系统的事件相机数据集，用于车辆和行人检测与跟踪，并建立了基于检测的跟踪基准，取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的相机在弱光和高运动条件下性能不佳，而事件相机具有低延迟、高动态范围和高时间分辨率的优势，但在事件视觉领域研究较少，特别是在智能交通系统中的应用存在研究空白。

Method: 1. 创建了首个专门用于事件相机智能交通系统的数据集，涵盖车辆和行人检测与跟踪；2. 基于该数据集建立了基于检测的跟踪基准；3. 设计了专门的特征提取器。

Result: 在建立的数据集和基准上实现了优异的性能表现，验证了事件相机在智能交通系统中多目标跟踪任务的有效性。

Conclusion: 事件相机在智能交通系统中具有巨大潜力，本文通过创建专用数据集和基准填补了该领域的研究空白，为后续研究提供了重要基础。

Abstract: In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.

</details>


### [5] [WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling](https://arxiv.org/abs/2512.14614)
*Wenqiang Sun,Haiyu Zhang,Haoyuan Wang,Junta Wu,Zehan Wang,Zhenwei Wang,Yunhong Wang,Jun Zhang,Tengfei Wang,Chunchao Guo*

Main category: cs.CV

TL;DR: WorldPlay是一个流式视频扩散模型，通过三项创新技术实现实时交互式世界建模，在保持长期几何一致性的同时解决了速度与内存的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在速度和内存之间存在权衡限制，难以实现实时、交互式的世界建模，同时保持长期几何一致性。需要解决内存衰减问题，使模型能够在实时速度下处理长序列视频。

Method: 1) 双动作表示：支持对键盘鼠标输入的鲁棒动作控制；2) 重构上下文记忆：动态重建过去帧的上下文，使用时间重帧保持几何重要但久远帧的可访问性；3) 上下文强制：为内存感知模型设计的蒸馏方法，对齐师生模型的记忆上下文。

Result: WorldPlay能够以24 FPS实时生成720p长序列流式视频，具有优越的几何一致性，相比现有技术表现更好，并在多样化场景中展现出强大的泛化能力。

Conclusion: WorldPlay通过创新的内存管理和蒸馏技术，成功解决了流式视频生成中速度与内存的权衡问题，实现了实时、交互式的世界建模，为高质量视频生成提供了新方法。

Abstract: This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.

</details>


### [6] [MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives](https://arxiv.org/abs/2512.14699)
*Sihui Ji,Xi Chen,Shuai Yang,Xin Tao,Pengfei Wan,Hengshuang Zhao*

Main category: cs.CV

TL;DR: MemFlow提出动态记忆检索机制，根据文本提示检索最相关的历史帧来维护记忆库，实现长视频生成的内容一致性，同时保持高效性


<details>
  <summary>Details</summary>
Motivation: 现有流式视频生成方法使用预定义策略压缩历史帧作为记忆，但不同视频片段需要参考不同的历史线索，固定策略难以满足这一需求

Method: 在生成每个新视频片段前，根据该片段的文本提示动态检索最相关的历史帧来更新记忆库；在生成过程中，注意力层只激活记忆库中最相关的token，保证生成效率

Result: MemFlow实现了出色的长上下文一致性，计算负担可忽略（相比无记忆基线仅降低7.9%速度），且兼容任何支持KV缓存的流式视频生成模型

Conclusion: 动态记忆检索机制能有效解决流式视频生成中的长上下文一致性问题，同时保持高效性和模型兼容性

Abstract: The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training](https://arxiv.org/abs/2512.13706)
*John Graham Reynolds*

Main category: cs.LG

TL;DR: 在数学推理任务上微调大语言模型会导致灾难性遗忘，混合训练策略能完全消除遗忘同时保持数学性能


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在特定任务（如数学推理）微调时出现的灾难性遗忘问题，即模型会失去先前学习的一般能力

Method: 在Flan-T5-Base模型上使用DeepMind Mathematics数据集进行微调，测量在MultiNLI上的遗忘程度，并提出混合训练策略，将数学和NLI示例交错训练

Result: 纯数学训练将数学准确率从3.1%提升到12.0%，但导致NLI准确率从81.0%暴跌至16.5%（下降64.5个百分点）。混合训练（1:1比例）完全消除遗忘，保持12.0%数学准确率的同时维持86.2%的NLI准确率

Conclusion: 专业化训练不需要以遗忘一般能力为代价，混合训练策略能有效防止灾难性遗忘，对于更大规模的模型可能带来超越遗忘预防的额外益处

Abstract: When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical accuracy from 3.1\% to 12.0\% but causes NLI accuracy to collapse from 81.0\% to 16.5\%--a 64.5 percentage point drop occurring within the first 1,000 training steps. We propose mixed training strategies that interleave mathematical and NLI examples during training. Our results demonstrate that mixed training completely eliminates catastrophic forgetting while maintaining equivalent mathematical performance: the balanced 1:1 ratio achieves 12.0\% math accuracy (matching math-only) while preserving 86.2\% NLI accuracy. We systematically explore mixing ratios from 1:1 to 15:1, finding that even minimal NLI exposure (6.2\%) provides effective regularization. These findings demonstrate that specialization need not require forgetting general capabilities, with implications for scaling to larger models where mixed training may confer additional benefits beyond forgetting prevention.

</details>


### [8] [Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables](https://arxiv.org/abs/2512.13710)
*Edwin Oluoch Awino,Denis Machanda*

Main category: cs.LG

TL;DR: 该研究结合SAR影像与多源环境数据，使用机器学习方法对肯尼亚Nyando河流域进行洪水易发性建模，发现随机森林模型表现最佳，识别出维多利亚湖附近低洼平原为最高风险区。


<details>
  <summary>Details</summary>
Motivation: 洪水是全球最具破坏性的自然灾害之一，对生态系统、基础设施和人类生计构成严重威胁。在数据有限的地区，需要开发有效的洪水易发性评估方法，以支持灾害风险管理和土地利用规划。

Method: 使用Sentinel-1双极化SAR数据处理2024年5月洪水事件，生成二进制洪水清单作为训练数据。结合六个条件因子（坡度、高程、坡向、土地利用/土地覆盖、土壤类型、距河流距离），训练四种监督分类器：逻辑回归、分类回归树、支持向量机和随机森林。

Result: 随机森林模型表现最佳（准确率=0.762；Kappa=0.480），优于其他三种模型。基于RF的易发性地图显示，维多利亚湖附近的Kano平原低洼地区具有最高的洪水脆弱性，这与历史洪水记录和2024年5月洪水事件的影响一致。

Conclusion: 研究表明，在数据有限的地区，结合SAR数据和集成机器学习方法进行洪水易发性制图具有重要价值。生成的易发性地图为灾害风险减少、土地利用规划和预警系统开发提供了重要见解。

Abstract: Flooding is one of the most destructive natural hazards worldwide, posing serious risks to ecosystems, infrastructure, and human livelihoods. This study combines Synthetic Aperture Radar (SAR) imagery with environmental and hydrological data to model flood susceptibility in the River Nyando watershed, western Kenya. Sentinel-1 dual-polarization SAR data from the May 2024 flood event were processed to produce a binary flood inventory, which served as training data for machine learning (ML) models. Six conditioning factors -- slope, elevation, aspect, land use/land cover, soil type, and distance from streams -- were integrated with the SAR-derived flood inventory to train four supervised classifiers: Logistic Regression (LR), Classification and Regression Trees (CART), Support Vector Machines (SVM), and Random Forest (RF). Model performance was assessed using accuracy, Cohen's Kappa, and Receiver Operating Characteristic (ROC) analysis. Results indicate that RF achieved the highest predictive performance (accuracy = 0.762; Kappa = 0.480), outperforming LR, CART, and SVM. The RF-based susceptibility map showed that low-lying Kano Plains near Lake Victoria have the highest flood vulnerability, consistent with historical flood records and the impacts of the May 2024 event. These findings demonstrate the value of combining SAR data and ensemble ML methods for flood susceptibility mapping in regions with limited data. The resulting maps offer important insights for disaster risk reduction, land-use planning, and early warning system development.

</details>


### [9] [Prediction of Respiratory Syncytial Virus-Associated Hospitalizations Using Machine Learning Models Based on Environmental Data](https://arxiv.org/abs/2512.13712)
*Eric Guo*

Main category: cs.LG

TL;DR: 开发机器学习框架，整合废水监测、气象和空气质量数据，预测美国RSV相关住院风险等级，并创建交互式仪表板供公共卫生决策使用。


<details>
  <summary>Details</summary>
Motivation: 呼吸道合胞病毒（RSV）是导致幼儿住院的主要原因，其暴发受环境条件强烈影响。需要结合多种数据源来预测RSV相关住院风险，以支持及时的公共卫生干预。

Method: 整合每周住院率、废水RSV水平、每日气象测量和空气污染物浓度数据。使用CART、随机森林和Boosting等分类模型，预测RSV相关住院率的风险等级（低风险、警报、流行）。

Result: 废水RSV水平是最强预测因子，其次是温度、臭氧水平和比湿等气象和空气质量变量。发现美国原住民和阿拉斯加原住民的RSV相关住院率显著更高，高海拔地区（气压较低）的住院率也持续较高。

Conclusion: 结合环境和社区监测数据对预测RSV暴发具有重要价值，有助于更及时的公共卫生干预和资源分配。开发了交互式R Shiny仪表板，供用户探索各州RSV风险水平、可视化关键预测因子影响并生成预测。

Abstract: Respiratory syncytial virus (RSV) is a leading cause of hospitalization among young children, with outbreaks strongly influenced by environmental conditions. This study developed a machine learning framework to predict RSV-associated hospitalizations in the United States (U.S.) by integrating wastewater surveillance, meteorological, and air quality data. The dataset combined weekly hospitalization rates, wastewater RSV levels, daily meteorological measurements, and air pollutant concentrations. Classification models, including CART, Random Forest, and Boosting, were trained to predict weekly RSV-associated hospitalization rates classified as \textit{Low risk}, \textit{Alert}, and \textit{Epidemic} levels. The wastewater RSV level was identified as the strongest predictor, followed by meteorological and air quality variables such as temperature, ozone levels, and specific humidity. Notably, the analysis also revealed significantly higher RSV-associated hospitalization rates among Native Americans and Alaska Natives. Further research is needed to better understand the drivers of RSV disparity in these communities to improve prevention strategies. Furthermore, states at high altitudes, characterized by lower surface pressure, showed consistently higher RSV-associated hospitalization rates. These findings highlight the value of combining environmental and community surveillance data to forecast RSV outbreaks, enabling more timely public health interventions and resource allocation. In order to provide accessibility and practical use of the models, we have developed an interactive R Shiny dashboard (https://f6yxlu-eric-guo.shinyapps.io/rsv_app/), which allows users to explore RSV-associated hospitalization risk levels across different states, visualize the impact of key predictors, and interactively generate RSV outbreak forecasts.

</details>


### [10] [Federated Few-Shot Learning for Epileptic Seizure Detection Under Privacy Constraints](https://arxiv.org/abs/2512.13717)
*Ekaterina Sysoykova,Bernhard Anzengruber-Tanase,Michael Haslgrubler,Philipp Seidl,Alois Ferscha*

Main category: cs.LG

TL;DR: 提出兩階段聯邦少樣本學習框架，用於個人化EEG癲癇檢測，解決臨床數據分散、稀缺和隱私問題。


<details>
  <summary>Details</summary>
Motivation: 臨床EEG數據通常稀缺、分散在不同機構，且受隱私法規限制無法集中，使得基於AI的癲癇檢測模型開發困難。

Method: 兩階段框架：第一階段使用聯邦學習在非IID模擬醫院站點上微調BIOT模型；第二階段使用聯邦少樣本個人化，僅用5個標註EEG片段為每位患者自適應分類器。

Result: 聯邦微調平衡準確率0.43（集中式0.52）；FFSL階段客戶端特定模型平均平衡準確率達0.77，Cohen's kappa 0.62，加權F1 0.73。

Conclusion: FFSL框架能在現實數據可用性和隱私限制下，支持有效的患者自適應癲癇檢測。

Abstract: Many deep learning approaches have been developed for EEG-based seizure detection; however, most rely on access to large centralized annotated datasets. In clinical practice, EEG data are often scarce, patient-specific distributed across institutions, and governed by strict privacy regulations that prohibit data pooling. As a result, creating usable AI-based seizure detection models remains challenging in real-world medical settings. To address these constraints, we propose a two-stage federated few-shot learning (FFSL) framework for personalized EEG-based seizure detection. The method is trained and evaluated on the TUH Event Corpus, which includes six EEG event classes. In Stage 1, a pretrained biosignal transformer (BIOT) is fine-tuned across non-IID simulated hospital sites using federated learning, enabling shared representation learning without centralizing EEG recordings. In Stage 2, federated few-shot personalization adapts the classifier to each patient using only five labeled EEG segments, retaining seizure-specific information while still benefiting from cross-site knowledge. Federated fine-tuning achieved a balanced accuracy of 0.43 (centralized: 0.52), Cohen's kappa of 0.42 (0.49), and weighted F1 of 0.69 (0.74). In the FFSL stage, client-specific models reached an average balanced accuracy of 0.77, Cohen's kappa of 0.62, and weighted F1 of 0.73 across four sites with heterogeneous event distributions. These results suggest that FFSL can support effective patient-adaptive seizure detection under realistic data-availability and privacy constraints.

</details>


### [11] [CurvaDion: Curvature-Adaptive Distributed Orthonormalization](https://arxiv.org/abs/2512.13728)
*Bhavesh Kumar,Roger Jin,Jeffrey Quesnelle*

Main category: cs.LG

TL;DR: CurvaDion通过RMMC检测高曲率区域，只在需要时同步梯度，减少99%通信开销，同时保持模型收敛性能。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型分布式训练中，梯度同步成为关键瓶颈。现有方法如Dion虽然通过低秩更新减少通信，但每步都同步，忽略了优化过程中不同区域对同步需求的变化：平坦区域梯度相似，频繁同步冗余；高曲率区域需要协调防止发散。

Method: 提出CurvaDion方法，使用相对最大动量变化(RMMC)检测需要同步的高曲率区域。RMMC利用优化过程中已计算的动量动态作为方向曲率的计算可行代理，每层仅增加O(d)操作。建立RMMC与损失曲率的理论联系。

Result: 在160M到1.3B参数规模的模型上，CurvaDion实现99%的通信减少，同时匹配基线收敛性能。

Conclusion: CurvaDion通过智能检测优化曲率变化，只在必要时同步，显著减少分布式训练通信开销，同时保持模型收敛，为大规模语言模型训练提供了高效解决方案。

Abstract: As language models scale to trillions of parameters, distributed training across many GPUs becomes essential, yet gradient synchronization over high-bandwidth, low-latency networks remains a critical bottleneck. While recent methods like Dion reduce per-step communication through low-rank updates, they synchronize at every step regardless of the optimization landscape. We observe that synchronization requirements vary dramatically throughout training: workers naturally compute similar gradients in flat regions, making frequent synchronization redundant, while high-curvature regions require coordination to prevent divergence. We introduce CurvaDion, which uses Relative Maximum Momentum Change (RMMC) to detect high-curvature regions requiring synchronization. RMMC leverages momentum dynamics which are already computed during optimization as a computationally tractable proxy for directional curvature, adding only $\mathcal{O}(d)$ operations per layer. We establish theoretical connections between RMMC and loss curvature and demonstrate that CurvaDion achieves 99\% communication reduction while matching baseline convergence across models from 160M to 1.3B parameters.

</details>


### [12] [EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models](https://arxiv.org/abs/2512.13806)
*Siegfried Ludwig,Stylianos Bakas,Konstantinos Barmpas,Georgios Zoumpourlis,Dimitrios A. Adamos,Nikolaos Laskaris,Yannis Panagakis,Stefanos Zafeiriou*

Main category: cs.LG

TL;DR: 提出D3方法，通过弱监督训练分离EEG信号中的潜在脑活动成分，防止隐藏过拟合，提高模型泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前深度学习解码EEG信号在基准测试中表现良好，但在实际应用中泛化能力有限，存在隐藏过拟合问题，需要一种能分离真实脑活动成分与伪迹的方法

Method: 提出解耦解码分解(D3)方法，通过预测输入窗口在试验序列中的位置来分离EEG信号的潜在成分，类似于非线性ICA；采用完全独立的子网络架构确保严格可解释性

Result: D3能可靠分离运动想象数据中的脑活动成分；在适当成分子集上训练下游分类器可防止任务相关伪迹引起的隐藏过拟合；线性可分离的潜在空间支持有效的少样本睡眠分期学习

Conclusion: D3方法能区分真实脑活动成分与虚假特征，避免隐藏过拟合问题，仅需少量标记数据即可良好泛化到实际应用，为神经科学研究提供分离个体脑过程的新工具

Abstract: Deep learning for decoding EEG signals has gained traction, with many claims to state-of-the-art accuracy. However, despite the convincing benchmark performance, successful translation to real applications is limited. The frequent disconnect between performance on controlled BCI benchmarks and its lack of generalisation to practical settings indicates hidden overfitting problems. We introduce Disentangled Decoding Decomposition (D3), a weakly supervised method for training deep learning models across EEG datasets. By predicting the place in the respective trial sequence from which the input window was sampled, EEG-D3 separates latent components of brain activity, akin to non-linear ICA. We utilise a novel model architecture with fully independent sub-networks for strict interpretability. We outline a feature interpretation paradigm to contrast the component activation profiles on different datasets and inspect the associated temporal and spatial filters. The proposed method reliably separates latent components of brain activity on motor imagery data. Training downstream classifiers on an appropriate subset of these components prevents hidden overfitting caused by task-correlated artefacts, which severely affects end-to-end classifiers. We further exploit the linearly separable latent space for effective few-shot learning on sleep stage classification. The ability to distinguish genuine components of brain activity from spurious features results in models that avoid the hidden overfitting problem and generalise well to real-world applications, while requiring only minimal labelled data. With interest to the neuroscience community, the proposed method gives researchers a tool to separate individual brain processes and potentially even uncover heretofore unknown dynamics.

</details>


### [13] [A Single Architecture for Representing Invariance Under Any Space Group](https://arxiv.org/abs/2512.13989)
*Cindy Y. Zhang,Elif Ertekin,Peter Orbanz,Ryan P. Adams*

Main category: cs.LG

TL;DR: 提出单一机器学习架构，能自动适应任何空间群对称性，通过对称适配傅里叶基实现权重共享和零样本学习


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每个对称群设计专门架构，限制了可扩展性和知识迁移，特别是在材料科学中230个三维空间群的情况下尤为突出

Method: 构建对称适配的傅里叶基，通过显式表征群操作对傅里叶系数的约束，将这些约束编码到神经网络层中，实现跨不同空间群的权重共享

Result: 在材料性质预测任务中取得竞争性性能，并能进行零样本学习以泛化到未见过的空间群

Conclusion: 该方法通过单一架构适应多种空间群对称性，解决了传统方法可扩展性差的问题，实现了跨群的知识迁移和零样本泛化

Abstract: Incorporating known symmetries in data into machine learning models has consistently improved predictive accuracy, robustness, and generalization. However, achieving exact invariance to specific symmetries typically requires designing bespoke architectures for each group of symmetries, limiting scalability and preventing knowledge transfer across related symmetries. In the case of the space groups, symmetries critical to modeling crystalline solids in materials science and condensed matter physics, this challenge is particularly salient as there are 230 such groups in three dimensions. In this work we present a new approach to such crystallographic symmetries by developing a single machine learning architecture that is capable of adapting its weights automatically to enforce invariance to any input space group. Our approach is based on constructing symmetry-adapted Fourier bases through an explicit characterization of constraints that group operations impose on Fourier coefficients. Encoding these constraints into a neural network layer enables weight sharing across different space groups, allowing the model to leverage structural similarities between groups and overcome data sparsity when limited measurements are available for specific groups. We demonstrate the effectiveness of this approach in achieving competitive performance on material property prediction tasks and performing zero-shot learning to generalize to unseen groups.

</details>


### [14] [GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion](https://arxiv.org/abs/2512.14400)
*Fangzhou Lin,Guoshun He,Zhenyu Guo,Zhe Huang,Jinsong Tao*

Main category: cs.LG

TL;DR: GRAFT模型通过文本引导融合和多源信息对齐，显著提升了电力负荷预测性能，特别是在事件驱动场景中表现出色


<details>
  <summary>Details</summary>
Motivation: 电力负荷同时受到天气、日历节奏、突发事件和政策等多时间尺度外生因素的影响，现有方法难以有效整合这些多源文本信息进行电网感知预测

Method: 提出GRAFT模型，改进STanHOP以支持电网感知预测和多源文本干预，通过严格对齐每日新闻、社交媒体和政策文本与半小时负荷数据，在训练和滚动预测中使用交叉注意力实现文本引导融合，并提供即插即用的外部记忆接口

Result: 在澳大利亚五个州的统一基准测试中，GRAFT在多个区域和预测时间尺度上显著优于强基线，达到或超越了最先进水平，在事件驱动场景中表现稳健，并能通过注意力机制实现文本到负荷效应的时空定位和源级解释

Conclusion: GRAFT通过有效整合多源文本信息显著提升了电力负荷预测性能，为电网预测提供了标准化评估框架和可解释性工具，释放的基准数据和代码有助于促进该领域的标准化实证评估和可复现性

Abstract: Electric load is simultaneously affected across multiple time scales by exogenous factors such as weather and calendar rhythms, sudden events, and policies. Therefore, this paper proposes GRAFT (GRid-Aware Forecasting with Text), which modifies and improves STanHOP to better support grid-aware forecasting and multi-source textual interventions. Specifically, GRAFT strictly aligns daily-aggregated news, social media, and policy texts with half-hour load, and realizes text-guided fusion to specific time positions via cross-attention during both training and rolling forecasting. In addition, GRAFT provides a plug-and-play external-memory interface to accommodate different information sources in real-world deployment. We construct and release a unified aligned benchmark covering 2019--2021 for five Australian states (half-hour load, daily-aligned weather/calendar variables, and three categories of external texts), and conduct systematic, reproducible evaluations at three scales -- hourly, daily, and monthly -- under a unified protocol for comparison across regions, external sources, and time scales. Experimental results show that GRAFT significantly outperforms strong baselines and reaches or surpasses the state of the art across multiple regions and forecasting horizons. Moreover, the model is robust in event-driven scenarios and enables temporal localization and source-level interpretation of text-to-load effects through attention read-out. We release the benchmark, preprocessing scripts, and forecasting results to facilitate standardized empirical evaluation and reproducibility in power grid load forecasting.

</details>


### [15] [Early Warning Index for Patient Deteriorations in Hospitals](https://arxiv.org/abs/2512.14683)
*Dimitris Bertsimas,Yu Ma,Kimberly Villalobos Carballo,Gagan Singh,Michal Laskowski,Jeff Mather,Dan Kombert,Howard Haronian*

Main category: cs.LG

TL;DR: 开发了一个多模态机器学习框架EWI，通过整合临床和运营数据预测ICU入院、急救团队派遣和死亡风险，在临床医生参与下实现可解释的风险分层，C统计量0.796，已部署为医院分诊工具。


<details>
  <summary>Details</summary>
Motivation: 医院缺乏自动化系统来利用日益增长的异质临床和运营数据有效预测关键事件。早期识别有恶化风险的患者对患者护理质量监测和医生护理管理都至关重要，但将不同数据流转化为准确且可解释的风险评估面临数据格式不一致的挑战。

Method: 开发了多模态机器学习框架EWI（早期预警指数），采用人机协同流程：临床医生帮助确定警报阈值和解释模型输出。使用SHAP（Shapley Additive exPlanations）提供可解释的输出，突出显示驱动每个患者风险的临床和运营因素（如预定手术、病房人数）。从结构化和非结构化电子健康记录中自动提取特征，将患者分为三个风险等级。

Result: 在美国一家大型医院的18,633名独特患者数据集上，EWI实现了C统计量0.796。目前已部署为医院仪表板中的分诊工具，用于主动管理高风险患者。该方法通过自动对患者进行风险分级，为医生节省了宝贵时间，使他们能专注于患者护理而非筛选复杂的EHR数据。

Conclusion: EWI框架通过整合多模态数据和临床医生参与，成功开发了可解释的风险预测系统。通过识别特定风险驱动因素，为护理人员调度和关键资源分配提供数据支持的调整。临床医生和管理人员可以预防下游并发症，包括昂贵的手术或高再入院率，改善整体患者流程。

Abstract: Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [16] [MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2512.13955)
*Sindhuja Madabushi,Dawood Wasif,Jin-Hee Cho*

Main category: cs.AI

TL;DR: MURIM是一个多维度声誉激励机制，通过综合考虑客户端可靠性、隐私、资源容量和公平性，解决联邦学习中的激励、隐私和资源约束问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临客户端激励不足、隐私风险和资源约束等关键挑战。评估客户端可靠性对于公平分配激励和确保每个客户端数据对全局模型有实质性贡献至关重要。

Method: 提出MURIM多维度声誉激励机制，基于客户端贡献、延迟和声誉分配激励，配备可靠性验证模块，防止恶意或不可靠客户端获得不应得的奖励。

Result: 在MNIST、FMNIST和ADULT Income数据集上的实验表明，MURIM在公平性指标上提升达18%，隐私攻击成功率降低5-9%，对投毒和噪声梯度攻击的鲁棒性提升达85%。

Conclusion: MURIM有效缓解对抗威胁，促进公平真实参与，在异构动态联邦学习环境中保持稳定的模型收敛。

Abstract: Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client reliability is essential for fair incentive allocation and ensuring that each client's data contributes meaningfully to the global model. To this end, we propose MURIM, a MUlti-dimensional Reputation-based Incentive Mechanism that jointly considers client reliability, privacy, resource capacity, and fairness while preventing malicious or unreliable clients from earning undeserved rewards. MURIM allocates incentives based on client contribution, latency, and reputation, supported by a reliability verification module. Extensive experiments on MNIST, FMNIST, and ADULT Income datasets demonstrate that MURIM achieves up to 18% improvement in fairness metrics, reduces privacy attack success rates by 5-9%, and improves robustness against poisoning and noisy-gradient attacks by up to 85% compared to state-of-the-art baselines. Overall, MURIM effectively mitigates adversarial threats, promotes fair and truthful participation, and preserves stable model convergence across heterogeneous and dynamic federated settings.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [17] [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)
*Hongqiu Ni,Jiabao Zhang,Guopeng Li,Zilong Wang,Ruiqi Wu,Chi Zhang,Haisheng Tan*

Main category: cs.CL

TL;DR: Astraea：一个面向LLM智能体工作流的服务引擎，通过全局调度优化减少端到端延迟


<details>
  <summary>Details</summary>
Motivation: 现有推理系统（如vLLM）主要优化局部计算段，无法最小化LLM智能体多阶段工作流的端到端延迟。智能体工作流交替进行本地计算和外部API调用，这种执行模式与现有系统的调度粒度不匹配。

Method: 提出Astraea服务引擎，采用状态感知的分层调度算法，整合请求历史状态和未来预测，动态分类I/O密集型和计算密集型请求，使用增强的HRRN策略平衡效率与公平性，并实现自适应KV缓存管理器来智能处理I/O等待期间的智能体状态。

Result: 实验表明，Astraea相比基线方法平均JCT降低高达25.5%，在高负载下对不同模型规模展现出强大的鲁棒性和稳定性。

Conclusion: Astraea通过将优化重点从局部段转移到全局请求生命周期，有效解决了LLM智能体工作流的端到端延迟优化问题，显著提升了系统性能。

Abstract: Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [Impact of Robot Facial-Audio Expressions on Human Robot Trust Dynamics and Trust Repair](https://arxiv.org/abs/2512.13981)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 研究机器人任务表现和情感表达如何动态影响人类信任，发现成功提升信任、失败导致信任骤降，道歉表达能部分修复信任，且年龄和态度调节信任动态变化


<details>
  <summary>Details</summary>
Motivation: 当前AEC行业中人机协作研究将信任视为静态因素，缺乏对信任在协作过程中如何随时间变化的指导。需要了解机器人任务表现和情感表达如何塑造人类信任的动态变化

Method: 设计受控组内研究，包含两个建筑任务：物料递送（物理协助）和信息收集（感知协助）。使用14项HRI信任感知量表加重新委派选择，四次测量信任。机器人产生两种多模态表达：成功后的"高兴"确认和失败后的"悲伤"道歉加二次机会请求。30名参与者在实验室环境中与四足平台互动

Result: 机器人成功可靠增加信任，失败导致信任骤降，基于道歉的表达部分恢复信任（物料递送44%恢复，信息收集38%恢复）。项目级分析显示恢复的信任主要由交互和沟通因素驱动，能力部分恢复，自主性方面变化最小。年龄组和先前态度调节信任动态：年轻参与者变化更大但短暂，25岁左右参与者修复最持久，年长参与者最保守

Conclusion: 这项工作为未来根据任务需求和用户特征调整修复策略奠定了基础，以支持建筑工地机器人的安全、高效采用。信任是动态的，可以通过机器人表达进行调节，且受用户特征影响

Abstract: Despite recent advances in robotics and human-robot collaboration in the AEC industry, trust has mostly been treated as a static factor, with little guidance on how it changes across events during collaboration. This paper investigates how a robot's task performance and its expressive responses after outcomes shape the dynamics of human trust over time. To this end, we designed a controlled within-subjects study with two construction-inspired tasks, Material Delivery (physical assistance) and Information Gathering (perceptual assistance), and measured trust repeatedly (four times per task) using the 14-item Trust Perception Scale for HRI plus a redelegation choice. The robot produced two multimodal expressions, a "glad" display with a brief confirmation after success, and a "sad" display with an apology and a request for a second chance after failure. The study was conducted in a lab environment with 30 participants and a quadruped platform, and we evaluated trust dynamics and repair across both tasks. Results show that robot success reliably increases trust, failure causes sharp drops, and apology-based expressions partially restores trust (44% recovery in Material Delivery; 38% in Information Gathering). Item-level analysis indicates that recovered trust was driven mostly by interaction and communication factors, with competence recovering partially and autonomy aspects changing least. Additionally, age group and prior attitudes moderated trust dynamics with younger participants showed larger but shorter-lived changes, mid-20s participants exhibited the most durable repair, and older participants showed most conservative dynamics. This work provides a foundation for future efforts that adapt repair strategies to task demands and user profiles to support safe, productive adoption of robots on construction sites.

</details>


### [19] [Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation](https://arxiv.org/abs/2512.14054)
*Humaira Tasnim,Ashik E Rasul,Bruce Jo,Hyung-Jin Yoon*

Main category: cs.RO

TL;DR: 提出一种尺度自适应的双专家感知框架，通过两个专门针对不同尺度训练的YOLOv8模型分别处理远距离和近距离直升机坪检测，在降落过程中根据几何门控机制选择最合适的专家预测，显著提升自主飞行器在GPS拒止环境下的降落精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自主飞行器在GPS拒止或视觉退化条件下的可靠降落需要准确的直升机坪检测。传统单模型检测器在降落过程中面临极端尺度变化挑战：高空时直升机坪小而模糊，接近地面时则大而清晰。单模型难以同时在这两种极端尺度下保持鲁棒性能。

Method: 提出尺度自适应双专家感知框架：1) 使用HelipadCat数据集训练两个YOLOv8专家模型，分别专门针对远距离（小尺度）和近距离（大尺度）直升机坪检测；2) 在推理时并行运行两个专家；3) 引入几何门控机制，根据飞行器视角选择预测最一致的专家输出；4) 在CARLA和NASA GUAM集成的闭环降落环境中进行验证。

Result: 相比单检测器基线，该框架在降落过程中显著提升了：1) 对准稳定性；2) 降落精度；3) 整体鲁棒性。特别是在宽高度范围内避免了单检测器系统常见的性能退化问题。

Conclusion: 通过针对降落问题设计的尺度感知专家路由策略，这项工作推进了自主下降的弹性视觉感知能力，为未来多专家自主飞行器框架奠定了基础。双专家方法有效解决了降落过程中的极端尺度变化挑战。

Abstract: Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.

</details>
