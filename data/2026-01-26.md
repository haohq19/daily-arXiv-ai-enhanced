<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments](https://arxiv.org/abs/2601.16333)
*Aditya K Surikuchi,Raquel Fernández,Sandro Pezzelle*

Main category: cs.CV

TL;DR: 研究评估多模态模型识别足球视频重要子事件的能力，发现现有模型表现接近随机水平，主要依赖单一模态且无法有效整合多源信息。


<details>
  <summary>Details</summary>
Motivation: 基础模型在涉及时序多模态事件的语言生成任务中广泛应用，但模型识别视频中重要子事件的能力尚未得到充分研究。该能力是叙述或总结多模态事件的基本前提，特别是在足球比赛场景中。

Method: 构建新数据集：利用足球比赛精彩集锦中隐含的人类重要性偏好，无需额外标注成本。使用该数据集评估多个最先进的多模态模型，分析模型表现并超越标准评估指标进行深入分析。

Result: 现有多模态模型表现接近随机水平，分析显示模型倾向于依赖单一主导模态，无法有效合成来自多个来源的必要信息。

Conclusion: 需要模块化架构来处理多模态数据中的样本级异质性，以及互补的训练程序来最大化跨模态协同效应。研究强调了当前多模态模型在识别重要事件方面的局限性。

Abstract: Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一个两阶段框架，通过推理增强预测和基于置信度的结果修正来解决罕见事件预测中的类别不平衡问题，显著提升精度并降低相关成本。


<details>
  <summary>Details</summary>
Motivation: 在医疗、金融、可靠性工程等关键领域，罕见事件预测至关重要，但极端类别不平衡导致传统模型偏向多数类预测，限制了召回率、校准性和实际应用价值。

Method: 提出LPCORP两阶段框架：1) 推理模型从叙述输入生成增强预测；2) 轻量级逻辑回归分类器评估并选择性修正这些输出，以减轻流行度驱动的偏差。

Result: 在医疗和消费者服务领域的真实数据集上评估，该方法将高度不平衡设置转化为平衡设置，同时保留原始样本数量且无需重采样策略，测试集评估显示性能显著提升，特别是精度方面。成本降低分析显示在某些情况下可减少50%以上费用。

Conclusion: LPCORP框架有效解决了罕见事件预测中的类别不平衡问题，通过推理增强和选择性修正显著提升预测性能，同时在实际应用中展示了显著的成本节约潜力。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [3] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 该论文通过使用具有显式Berry-Esseen误差控制的正态近似代替Hoeffding不等式，改进了经典的Vapnik-Chervonenkis定理，在ε√n较大时获得了更精确的均匀收敛速率估计。


<details>
  <summary>Details</summary>
Motivation: 经典VC定理使用Hoeffding不等式作为最后一步，作者希望改进这一方法以获得更精确的收敛速率估计，特别是在中等偏差范围内。

Method: 重新审视经典VC定理的概率部分，使用具有显式Berry-Esseen误差控制的正态近似代替Hoeffding不等式，从而获得更精细的收敛速率估计。

Result: 得到了VC估计的中等偏差锐化版本，当ε√n较大时，在主要指数项中获得了额外的(ε√n)^{-1}阶因子，提供了更精确的均匀收敛速率估计。

Conclusion: 通过使用更精确的正态近似方法，改进了经典VC定理的收敛速率估计，为机器学习中的统计学习理论提供了更精细的理论工具。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [4] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频键碰撞不是Engram式条件记忆的主要瓶颈。通过碰撞自由设计实验发现，单纯提高查找精度并不能改善训练效果，碰撞噪声反而提供有益的正则化作用。


<details>
  <summary>Details</summary>
Motivation: 研究高频键碰撞是否是Engram式条件记忆的主要瓶颈，探究单纯消除碰撞是否真的能改善模型性能。

Method: 引入Engram-Nine碰撞自由热层扩展，使用最小完美哈希函数映射最高频n-gram，同时保留原始多头哈希查找作为冷层。在严格等参数设置下，通过路由分层评估分解每个token的损失为热/冷层贡献。

Result: 碰撞自由设计并未持续改善验证损失。发现训练中存在一致的"热到冷优势翻转"现象：热位置初始损失较低，但冷位置最终超越。碰撞自由配置比碰撞基线更早翻转，表明碰撞起到隐式正则化作用。还发现门控失配问题。

Conclusion: 单纯提高查找精度不能保证更好的训练结果。主要限制可能在于门控信用分配而非索引精度，碰撞引起的噪声可能提供有益的正则化，不应简单消除。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [5] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD是一个模型无关的辅助框架，通过双原型自适应解耦机制，为时间序列预测模型提供模式解耦和上下文感知能力，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法通常通过修改架构或引入增强策略来提升预测性能，但往往无法动态解耦和利用时间序列中复杂交织的时序模式，导致学习到静态、平均化的表示，缺乏上下文感知能力。

Method: 提出双原型自适应解耦框架(DPAD)：1)构建动态双原型库(DDP)，包含具有强时序先验的常见模式库和动态记忆关键但罕见事件的罕见模式库；2)设计双路径上下文感知路由(DPC)机制，从DDP中选择性检索上下文特定模式表示来增强输出；3)引入解耦引导损失(DGLoss)确保每个原型库专注于其指定角色同时保持全面覆盖。

Result: 综合实验表明，DPAD在各种真实世界基准测试中，能够一致地提升最先进模型的预测性能和可靠性。

Conclusion: DPAD框架通过模式解耦和上下文感知适应，有效解决了现有方法在动态处理复杂时序模式方面的局限性，为时间序列预测提供了模型无关的增强方案。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [6] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP框架通过几何约束保护MoE模型的路由稳定性，防止传统遗忘方法利用路由漏洞进行表面遗忘，真正从专家参数中擦除知识。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法无法有效应用于MoE架构，因为它们会利用路由器的脆弱性进行表面遗忘（通过操纵路由器将查询从知识专家处重定向），而不是真正擦除知识，导致模型效用损失和表面遗忘。

Method: 提出几何路由不变性保护（GRIP）框架，核心是通过将路由器梯度更新投影到专家特定的零空间来实现几何约束。这解耦了路由稳定性与参数刚性：离散专家选择保持稳定以保留知识，而连续路由器参数在零空间内保持可塑性，允许模型进行必要的内部重构以满足遗忘目标。

Result: 大规模MoE模型实验表明，GRIP适配器消除了专家选择偏移（实现超过95%的路由稳定性），同时保留了所有测试遗忘方法的效用。通过防止现有算法利用MoE模型的路由漏洞，GRIP将现有遗忘研究从密集架构适配到MoE。

Conclusion: GRIP作为一个算法无关的适配器框架，通过几何约束保护路由稳定性，强制遗忘优化直接从专家参数中擦除知识，而不是利用表面路由器操纵的捷径，从而有效解决MoE架构的机器遗忘问题。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Preventing the Collapse of Peer Review Requires Verification-First AI](https://arxiv.org/abs/2601.16909)
*Lei You,Lele Cao,Iryna Gurevych*

Main category: cs.AI

TL;DR: 论文主张AI辅助同行评审应采用"验证优先"而非"模仿评审"范式，提出"真相耦合"作为评审工具的正确目标，并分析导致评审系统转向代理指标主导的两种力量


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助评审系统倾向于模仿人类评审过程，这可能加剧科学评估中的代理指标主导问题。论文旨在重新思考AI在同行评审中的角色，防止评审系统从追求科学真相转向优化代理指标

Method: 提出"真相耦合"作为评审工具的核心目标，形式化验证压力和信号收缩两种力量，建立包含高保真检查和频繁代理判断的最小模型，推导耦合定律和激励崩溃条件

Result: 在最小模型中推导出明确的耦合定律，识别出激励崩溃条件：即使当前决策看起来可靠，理性努力也会从追求真相转向优化代理指标

Conclusion: AI应作为对抗性审计工具，生成可审计的验证工件并扩展有效验证带宽，而不是作为分数预测器放大声明膨胀。工具构建者和程序主席应采取相应行动

Abstract: This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [8] [A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War](https://arxiv.org/abs/2601.16309)
*Dikshya Mohanty,Taisiia Sabadyn,Jelwin Rodrigues,Chenlu Wang,Abhishek Kalugade,Ritwik Banerjee*

Main category: cs.CL

TL;DR: DNIPRO是一个包含24.6万篇新闻文章的多语言语料库，记录了2022年2月至2024年8月的俄乌战争，涵盖11家媒体、5个国家（俄、乌、美、英、中）和3种语言（英、俄、中文），用于研究战时争议性话语的跨国分析。


<details>
  <summary>Details</summary>
Motivation: 现有资源缺乏对俄乌战争的多语言、跨国媒体覆盖的系统性记录，需要包含竞争性地缘政治视角的语料库来研究叙事分歧、媒体框架和信息战。

Method: 构建包含24.6万篇新闻文章的纵向语料库，涵盖11家媒体机构，跨越5个国家、3种语言，提供一致的元数据和多种注释类型，并进行了严格的人工评估。

Result: 创建了DNIPRO语料库，展示了其在立场检测、情感分析、主题框架和矛盾分析等用例实验中的实用性，揭示了媒体如何构建竞争性现实，报道呈现反映地缘政治利益的极化解释。

Conclusion: DNIPRO为理解冲突性叙事如何在全球信息生态系统中出现和演变提供了基础资源，不仅支持计算新闻学研究，还能促进对战时话语的系统性跨国分析。

Abstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.

</details>


### [9] [SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine](https://arxiv.org/abs/2601.16512)
*Hoang-Quoc Nguyen-Son,Minh-Son Dao,Koji Zettsu*

Main category: cs.CL

TL;DR: SearchLLM：一种利用搜索引擎检测LLM改写文本的新方法，通过查找潜在原文来源并分析相似性来识别LLM改写内容，可增强现有检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，用户常使用LLM改写文本以提升质量，但这可能导致原意丢失或扭曲。传统检测方法难以识别LLM生成的类人文本，特别是当改写内容与原文高度相似时。

Method: 提出SearchLLM方法，利用搜索引擎查找潜在原文来源，通过分析输入文本与候选来源再生版本之间的相似性来识别LLM改写内容。该方法设计为代理层，可与现有检测器无缝集成。

Result: 实验结果表明，SearchLLM能持续提升最新检测器在识别高度模仿原文的LLM改写文本方面的准确性，同时帮助检测器防止改写攻击。

Conclusion: SearchLLM为检测LLM改写文本提供了一种有效的新方法，通过搜索引擎辅助增强了现有检测系统的能力，解决了传统方法难以识别高质量改写内容的问题。

Abstract: With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.

</details>


### [10] [Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach](https://arxiv.org/abs/2601.16724)
*Kevin Fan,Eric Yun*

Main category: cs.CL

TL;DR: 本文针对自动作文评分系统对ESL学习者的算法偏见问题，提出基于对比学习的匹配作文对方法，显著减少了高熟练度ESL作文的评分差距。


<details>
  <summary>Details</summary>
Motivation: 自动作文评分系统在高风险教育场景中日益普及，但现有基于Transformer的回归模型主要基于母语者语料训练，容易学习到L2语言表面特征与作文质量之间的虚假相关性，导致对ESL学习者的算法偏见。

Method: 提出对比学习与三元组构建策略：匹配作文对对比学习。构建了17,161对匹配作文对数据集，使用三元组边界损失微调DeBERTa-v3模型，对齐ESL和母语写作的潜在表示。

Result: 将高熟练度ESL作文的评分差距减少了39.9%（从10.3%降至6.2%），同时保持0.76的二次加权Kappa值。后验语言分析表明模型成功解耦了句子复杂性和语法错误，避免了对有效L2句法结构的惩罚。

Conclusion: 匹配作文对对比学习是减少自动作文评分系统中算法偏见的有效方法，能够在不牺牲整体评分性能的情况下显著改善对ESL学习者的公平性。

Abstract: As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.

</details>
