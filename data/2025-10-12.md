<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cross-Modal Attention Guided Unlearning in Vision-Language Models](https://arxiv.org/abs/2510.07567)
*Karuna Bhaila,Aneesh Komanduri,Minh-Hao Van,Xintao Wu*

Main category: cs.CV

TL;DR: 提出CAGUL框架，用于视觉语言模型的遗忘学习，防止模型泄露敏感信息，同时保持原有性能


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在训练过程中可能记忆并泄露敏感信息，现有遗忘学习方法主要针对纯文本模型，而视觉语言模型由于包含视觉上下文而更加复杂

Method: 利用跨模态注意力机制分析视觉token对输出的重要性，通过外部模块对低重要性视觉token进行编码来实现遗忘学习

Result: CAGUL在防止信息泄露方面表现优于或等同于微调基线方法，且不改变预训练模型参数或产生重训练成本

Conclusion: CAGUL是一种轻量级、高效的视觉语言模型遗忘学习解决方案，具有实际应用价值

Abstract: Vision-Language Models (VLMs) have demonstrated immense capabilities in
multi-modal understanding and inference tasks such as Visual Question Answering
(VQA), which requires models to infer outputs based on visual and textual
context simultaneously. Such inference abilities of large-scale pretrained
models are often attributed to the massive scale of pre-training data collected
across several domains. However, the models may memorize private and/or
sensitive information during training and regurgitate it in inference.
Recently, machine unlearning has been leveraged to address the leakage of
private data in LLMs. VLMs add a layer of complexity to this process, as the
visual context in the query may also contain sensitive information in addition
to the text. To address this issue, we explore unlearning for vision-language
models, specifically for the VQA task. We explore the role of visual tokens for
output generation in VLMs using cross-modal attention and utilize it to
formulate Cross-Modal Attention Guided Unlearning (CAGUL), a lightweight and
efficient VLM unlearning framework. In contrast to computationally expensive
model finetuning methods, CAGUL utilizes external modules to encode unlearning
information in visual tokens of low importance for relevant queries. We find
that the transformed visual tokens not only prevent leakage but also retain
reference model behavior. Experimental results show that our method performs
better or on par with finetuning-based baselines without altering the
pre-trained model parameters or incurring retraining costs, making it a
practical and effective unlearning solution for VLMs.

</details>


### [2] [DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream](https://arxiv.org/abs/2510.07752)
*Junhao He,Jiaxu Wang,Jia Li,Mingyuan Sun,Qiang Zhang,Jiahang Cao,Ziyi Zhang,Yi Gu,Jingkai Sun,Renjing Xu*

Main category: cs.CV

TL;DR: 提出了一种结合低帧率RGB视频和高帧率事件流来重建动态3D高斯泼溅的方法，通过事件运动先验指导变形场优化，解决了大帧间运动带来的不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 从低帧率RGB视频重建动态3D高斯泼溅具有挑战性，因为大帧间运动会增加解空间的不确定性。事件相机能异步捕捉快速视觉变化且对运动模糊鲁棒，但缺乏颜色信息。结合两种模态可以解决这一挑战。

Method: 采用事件运动先验指导变形场优化：1) 使用LoCM无监督微调框架提取事件流中的运动先验；2) 提出几何感知数据关联方法建立事件-高斯运动对应关系；3) 采用运动分解和帧间伪标签策略。

Result: 在合成和真实场景上的广泛实验表明，该方法优于现有的图像和事件方法，证明事件数据能有效优化动态3D高斯泼溅。

Conclusion: 通过结合RGB和事件模态，利用事件运动先验指导变形场优化，成功解决了低帧率视频重建动态3D高斯泼溅的挑战，显著提升了重建质量。

Abstract: Reconstructing Dynamic 3D Gaussian Splatting (3DGS) from low-framerate RGB
videos is challenging. This is because large inter-frame motions will increase
the uncertainty of the solution space. For example, one pixel in the first
frame might have more choices to reach the corresponding pixel in the second
frame. Event cameras can asynchronously capture rapid visual changes and are
robust to motion blur, but they do not provide color information. Intuitively,
the event stream can provide deterministic constraints for the inter-frame
large motion by the event trajectories. Hence, combining
low-temporal-resolution images with high-framerate event streams can address
this challenge. However, it is challenging to jointly optimize Dynamic 3DGS
using both RGB and event modalities due to the significant discrepancy between
these two data modalities. This paper introduces a novel framework that jointly
optimizes dynamic 3DGS from the two modalities. The key idea is to adopt event
motion priors to guide the optimization of the deformation fields. First, we
extract the motion priors encoded in event streams by using the proposed LoCM
unsupervised fine-tuning framework to adapt an event flow estimator to a
certain unseen scene. Then, we present the geometry-aware data association
method to build the event-Gaussian motion correspondence, which is the primary
foundation of the pipeline, accompanied by two useful strategies, namely motion
decomposition and inter-frame pseudo-label. Extensive experiments show that our
method outperforms existing image and event-based approaches across synthetic
and real scenes and prove that our method can effectively optimize dynamic 3DGS
with the help of event data.

</details>


### [3] [PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting](https://arxiv.org/abs/2510.07830)
*Houqiang Zhong,Zhenglong Wu,Sihua Fu,Zihan Zheng,Xin Jin,Xiaoyun Zhang,Li Song,Qiang Hu*

Main category: cs.CV

TL;DR: PrismGS是一个基于物理正则化的框架，通过金字塔多尺度监督和显式尺寸正则化，解决了3D高斯溅射在大规模城市场景中的走样问题，显著提升了渲染质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射(3DGS)在大规模城市场景中面临严重的走样伪影和优化不稳定问题，特别是在高分辨率渲染下会出现闪烁纹理和锯齿边缘，现有方法无法解决这一保真度差距。

Method: 提出PrismGS框架，包含两个协同正则化器：金字塔多尺度监督（通过预滤波图像金字塔强制渲染一致性）和显式尺寸正则化（对3D高斯施加物理基础的尺寸下界约束）。

Result: 在MatrixCity、Mill-19和UrbanScene3D数据集上的实验表明，PrismGS实现了最先进的性能，相比CityGaussian获得了约1.5 dB的PSNR增益，在4K渲染下保持了优越的质量和鲁棒性。

Conclusion: PrismGS是一个即插即用的框架，能够有效解决3DGS在大规模场景中的走样问题，显著提升渲染质量，同时与现有流程兼容。

Abstract: 3D Gaussian Splatting (3DGS) has recently enabled real-time photorealistic
rendering in compact scenes, but scaling to large urban environments introduces
severe aliasing artifacts and optimization instability, especially under
high-resolution (e.g., 4K) rendering. These artifacts, manifesting as
flickering textures and jagged edges, arise from the mismatch between Gaussian
primitives and the multi-scale nature of urban geometry. While existing
``divide-and-conquer'' pipelines address scalability, they fail to resolve this
fidelity gap. In this paper, we propose PrismGS, a physically-grounded
regularization framework that improves the intrinsic rendering behavior of 3D
Gaussians. PrismGS integrates two synergistic regularizers. The first is
pyramidal multi-scale supervision, which enforces consistency by supervising
the rendering against a pre-filtered image pyramid. This compels the model to
learn an inherently anti-aliased representation that remains coherent across
different viewing scales, directly mitigating flickering textures. This is
complemented by an explicit size regularization that imposes a
physically-grounded lower bound on the dimensions of the 3D Gaussians. This
prevents the formation of degenerate, view-dependent primitives, leading to
more stable and plausible geometric surfaces and reducing jagged edges. Our
method is plug-and-play and compatible with existing pipelines. Extensive
experiments on MatrixCity, Mill-19, and UrbanScene3D demonstrate that PrismGS
achieves state-of-the-art performance, yielding significant PSNR gains around
1.5 dB against CityGaussian, while maintaining its superior quality and
robustness under demanding 4K rendering.

</details>


### [4] [ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving](https://arxiv.org/abs/2510.08562)
*Zhiyu Zheng,Shaoyu Chen,Haoran Yin,Xinbang Zhang,Jialv Zou,Xinggang Wang,Qian Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 提出ResAD框架，通过归一化残差轨迹建模解决端到端自动驾驶中的时空不平衡问题，将学习任务重新定义为预测与确定性惯性参考的偏差，而非直接预测未来轨迹。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统面临轨迹数据固有的时空不平衡问题，这导致模型学习虚假相关性而非因果推理，同时优先考虑不确定的远距离预测而损害即时安全性。

Method: ResAD框架采用归一化残差轨迹建模，预测与确定性惯性参考的残差偏差，而非直接预测未来轨迹。通过点级归一化重新加权优化目标，防止与远距离不确定路径点相关的大幅度误差主导学习信号。

Result: 在NAVSIM基准测试中，ResAD使用仅有两个去噪步骤的普通扩散策略实现了88.6的最先进PDMS，表明该方法显著简化了学习任务并提高了模型性能。

Conclusion: ResAD框架通过重新定义学习任务为预测残差偏差，并采用点级归一化处理优化不平衡，有效解决了端到端自动驾驶中的时空不平衡问题，提高了模型性能和安全性。

Abstract: End-to-end autonomous driving (E2EAD) systems, which learn to predict future
trajectories directly from sensor data, are fundamentally challenged by the
inherent spatio-temporal imbalance of trajectory data. This imbalance creates a
significant optimization burden, causing models to learn spurious correlations
instead of causal inference, while also prioritizing uncertain, distant
predictions, thereby compromising immediate safety. To address these issues, we
propose ResAD, a novel Normalized Residual Trajectory Modeling framework.
Instead of predicting the future trajectory directly, our approach reframes the
learning task to predict the residual deviation from a deterministic inertial
reference. The inertial reference serves as a counterfactual, forcing the model
to move beyond simple pattern recognition and instead identify the underlying
causal factors (e.g., traffic rules, obstacles) that necessitate deviations
from a default, inertially-guided path. To deal with the optimization imbalance
caused by uncertain, long-term horizons, ResAD further incorporates Point-wise
Normalization of the predicted residual. It re-weights the optimization
objective, preventing large-magnitude errors associated with distant, uncertain
waypoints from dominating the learning signal. Extensive experiments validate
the effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a
state-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two
denoising steps, demonstrating that our approach significantly simplifies the
learning task and improves model performance. The code will be released to
facilitate further research.

</details>


### [5] [GraphEnet: Event-driven Human Pose Estimation with a Graph Neural Network](https://arxiv.org/abs/2510.07990)
*Gaurvi Goyal,Pham Cong Thuong,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi*

Main category: cs.CV

TL;DR: 提出GraphEnet，一种基于图神经网络的2D人体姿态估计方法，专门针对事件相机数据，利用其稀疏特性实现高频姿态估计。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有低延迟和低能耗优势，适用于便携设备和移动机器人等资源受限场景，但现有方法未充分利用其稀疏特性进行人体姿态估计。

Method: 使用图神经网络处理事件相机输出，采用基于线的中间事件表示，结合新颖的偏移向量学习范式和基于置信度的池化来估计人体姿态。

Result: 这是首个将图神经网络应用于事件数据的人体姿态估计工作，实现了高频单人多姿态估计。

Conclusion: GraphEnet成功展示了图神经网络在事件相机人体姿态估计中的有效性，为资源受限场景提供了高效解决方案。

Abstract: Human Pose Estimation is a crucial module in human-machine interaction
applications and, especially since the rise in deep learning technology, robust
methods are available to consumers using RGB cameras and commercial GPUs. On
the other hand, event-based cameras have gained popularity in the vision
research community for their low latency and low energy advantages that make
them ideal for applications where those resources are constrained like portable
electronics and mobile robots. In this work we propose a Graph Neural Network,
GraphEnet, that leverages the sparse nature of event camera output, with an
intermediate line based event representation, to estimate 2D Human Pose of a
single person at a high frequency. The architecture incorporates a novel offset
vector learning paradigm with confidence based pooling to estimate the human
pose. This is the first work that applies Graph Neural Networks to event data
for Human Pose Estimation. The code is open-source at
https://github.com/event-driven-robotics/GraphEnet-NeVi-ICCV2025.

</details>


### [6] [CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.08003)
*Weihuang Lin,Yiwei Ma,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: CIR-CoT是一个端到端的检索导向多模态大语言模型，通过显式的思维链推理来提高组合图像检索的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的组合图像检索方法主要基于视觉语言模型和多模态大语言模型，但这些模型作为"黑盒"存在，用户无法理解检索原理，且难以遵循复杂细粒度的指令。

Method: 提出CIR-CoT模型，强制模型先生成可解释的推理链，然后将其最终检索意图编码到专用嵌入中。通过三阶段过程（描述、推理、结论）创建结构化思维链标注来训练模型。

Result: CIR-CoT在领域内数据集（FashionIQ、CIRR）上表现出高度竞争力，并在领域外CIRCO数据集上展现出卓越的泛化能力。

Conclusion: CIR-CoT为构建更有效和可信的检索系统开辟了新路径，通过显式推理链提高了检索准确性和透明度。

Abstract: Composed Image Retrieval (CIR), which aims to find a target image from a
reference image and a modification text, presents the core challenge of
performing unified reasoning across visual and semantic modalities. While
current approaches based on Vision-Language Models (VLMs, e.g., CLIP) and more
recent Multimodal Large Language Models (MLLMs, e.g., Qwen-VL) have shown
progress, they predominantly function as ``black boxes." This inherent opacity
not only prevents users from understanding the retrieval rationale but also
restricts the models' ability to follow complex, fine-grained instructions. To
overcome these limitations, we introduce CIR-CoT, the first end-to-end
retrieval-oriented MLLM designed to integrate explicit Chain-of-Thought (CoT)
reasoning. By compelling the model to first generate an interpretable reasoning
chain, CIR-CoT enhances its ability to capture crucial cross-modal
interactions, leading to more accurate retrieval while making its decision
process transparent. Since existing datasets like FashionIQ and CIRR lack the
necessary reasoning data, a key contribution of our work is the creation of
structured CoT annotations using a three-stage process involving a caption,
reasoning, and conclusion. Our model is then fine-tuned to produce this
structured output before encoding its final retrieval intent into a dedicated
embedding. Comprehensive experiments show that CIR-CoT achieves highly
competitive performance on in-domain datasets (FashionIQ, CIRR) and
demonstrates remarkable generalization on the out-of-domain CIRCO dataset,
establishing a new path toward more effective and trustworthy retrieval
systems.

</details>


### [7] [VideoVerse: How Far is Your T2V Generator from a World Model?](https://arxiv.org/abs/2510.08398)
*Zeqing Wang,Xinyu Wei,Bairui Li,Zhen Guo,Jinrui Zhang,Hongyang Wei,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: VideoVerse是一个新的文本到视频生成基准测试，专注于评估模型对复杂时间因果性和世界知识的理解能力，弥补现有基准在评估先进T2V模型方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法有效区分最先进的T2V模型，缺乏对事件级时间因果性和世界知识的系统评估，而这些对于构建世界模型至关重要。

Method: 收集跨领域代表性视频，提取具有时间因果关系的事件级描述，由独立标注者改写为文本到视频提示，设计包含动态和静态属性的10个评估维度，构建300个精心策划的提示，涉及815个事件和793个二元评估问题。

Result: 开发了基于现代视觉语言模型的人类偏好对齐QA评估流程，并对最先进的开源和闭源T2V模型进行了系统评估。

Conclusion: VideoVerse基准测试为评估T2V模型在时间因果性和世界知识理解方面的能力提供了全面框架，有助于分析当前T2V生成器与世界模型之间的差距。

Abstract: The recent rapid advancement of Text-to-Video (T2V) generation technologies,
which are critical to build ``world models'', makes the existing benchmarks
increasingly insufficient to evaluate state-of-the-art T2V models. First,
current evaluation dimensions, such as per-frame aesthetic quality and temporal
consistency, are no longer able to differentiate state-of-the-art T2V models.
Second, event-level temporal causality, which not only distinguishes video from
other modalities but also constitutes a crucial component of world models, is
severely underexplored in existing benchmarks. Third, existing benchmarks lack
a systematic assessment of world knowledge, which are essential capabilities
for building world models. To address these issues, we introduce VideoVerse, a
comprehensive benchmark that focuses on evaluating whether a T2V model could
understand complex temporal causality and world knowledge in the real world. We
collect representative videos across diverse domains (e.g., natural landscapes,
sports, indoor scenes, science fiction, chemical and physical experiments) and
extract their event-level descriptions with inherent temporal causality, which
are then rewritten into text-to-video prompts by independent annotators. For
each prompt, we design a suite of binary evaluation questions from the
perspective of dynamic and static properties, with a total of ten carefully
defined evaluation dimensions. In total, our VideoVerse comprises 300 carefully
curated prompts, involving 815 events and 793 binary evaluation questions.
Consequently, a human preference aligned QA-based evaluation pipeline is
developed by using modern vision-language models. Finally, we perform a
systematic evaluation of state-of-the-art open-source and closed-source T2V
models on VideoVerse, providing in-depth analysis on how far the current T2V
generators are from world models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [ConCuR: Conciseness Makes State-of-the-Art Kernel Generation](https://arxiv.org/abs/2510.07356)
*Lingcheng Kong,Jiateng Wei,Hanzhang Shen,Huan Wang*

Main category: cs.LG

TL;DR: 该论文提出了ConCuR数据集和KernelCoder模型，通过生成和筛选带有推理轨迹的高质量CUDA内核来解决内核生成任务中高质量数据稀缺的问题，在KernelBench上显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决GPU内核生成任务中高质量数据稀缺的问题，因为大多数高质量内核是专有且不开源的，这阻碍了使用监督微调来使LLM适应内核生成任务。

Method: 开发了一个生成和筛选带有推理轨迹的高质量CUDA内核的流程，构建了ConCuR数据集，并训练了KernelCoder模型，这是第一个在包含PyTorch、推理和CUDA内核对的数据集上训练的模型。

Result: 在KernelBench设置中，该模型显著优于现有的最佳模型QwQ-32B，并超越了所有为内核生成微调的开源模型以及前沿模型如DeepSeek-V3.1-Think和Claude-4-sonnet。

Conclusion: 平均推理长度可以作为评估内核生成任务难度的指标，该研究的观察、指标以及数据收集和筛选流程有助于在未来获得更好的内核生成数据。

Abstract: GPU kernel generation by LLMs has recently experienced rapid development,
leveraging test-time scaling and reinforcement learning techniques. However, a
key challenge for kernel generation is the scarcity of high-quality data, as
most high-quality kernels are proprietary and not open-source. This challenge
prevents us from leveraging supervised fine-tuning to align LLMs to the kernel
generation task. To address this challenge, we develop a pipeline that
generates and curates high-quality CUDA kernels with reasoning traces,
motivated by a critical observation that concise yet informative reasoning
traces result in robust generation of high-performance kernels. Using this
pipeline, we construct our dataset ConCuR and introduce our model KernelCoder,
which is the first model trained on a curated dataset consisting of PyTorch,
reasoning, and CUDA kernel pairs, to our knowledge. In the KernelBench setup,
our model achieves significant improvements over the existing top-performing
model, QwQ-32B, and outperforms all open-source models fine-tuned for kernel
generation, as well as frontier models such as DeepSeek-V3.1-Think and
Claude-4-sonnet. Finally, we show that the average reasoning length can serve
as a metric to assess the difficulty of kernel generation tasks. The
observations, metrics, and our data collection and curation pipeline can help
obtain better data in the kernel generation task in the future.

</details>


### [9] [Continual Learning for Adaptive AI Systems](https://arxiv.org/abs/2510.07648)
*Md Hasibul Amin,Tamzid Tanvi Alam*

Main category: cs.LG

TL;DR: 提出了一种基于类间分离(ICS)的正则化方法，通过在损失函数中惩罚远离先前任务数据聚类中心的输出，来缓解持续学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 持续学习是神经网络在不丢失先前获得知识的情况下学习多个顺序任务的能力，这是开发真正自适应人工智能的重要障碍。深度学习中过拟合是常见问题，正则化技术可以通过对模型参数添加约束来帮助防止过拟合。

Method: 引入基于类间分离(ICS)的新正则化技术，在损失函数中惩罚模型产生远离先前任务数据形成的聚类中心的输出。同时进行超参数调优以找到正则化项的最佳权重。

Result: 使用标准的5任务Split CIFAR-10基准和ResNet-18架构，证明了ICS在保持初始任务强性能方面的有效性。但结果也突显了长期知识保留的局限性，特别是在任务数量增加时。

Conclusion: 这项工作强调了持续学习固有的复杂性和权衡，并为进一步研究指明了方向。

Abstract: Continual learning the ability of a neural network to learn multiple
sequential tasks without losing previously acquired knowledge remains a
significant obstacle to developing truly adaptive artificial intelligence. Deep
learning models have achieved remarkable results in various applications, but
overfitting remains a common issue. Regularization techniques can help prevent
overfitting by adding constraints to the model's parameters. To prevent
catastrophic forgetting, in this paper we introduce a novel regularization
technique based on inter-cluster separation (ICS) in the loss function, which
penalizes the model for producing outputs that are far away from the centroids
of the clusters formed by the data from previous tasks. We also performed
hyperparameter tuning to find the optimal weighting of the proposed
regularization term. This ensures clearer separation between tasks in the
neural network's internal representation, reducing overlap and mitigating
forgetting. Using the standard 5-task Split CIFAR-10 benchmark and a ResNet-18
architecture, we demonstrate ICS's effectiveness in maintaining strong
performance on initial tasks. However, our results also highlight limitations
in long-term knowledge retention, particularly when the number of tasks
increases. This underscores the complexity and trade-offs inherent in continual
learning and points toward avenues for further research.

</details>


### [10] [GeoGen: A Two-stage Coarse-to-Fine Framework for Fine-grained Synthetic Location-based Social Network Trajectory Generation](https://arxiv.org/abs/2510.07735)
*Rongchao Xu,Kunlin Cai,Lin Jiang,Dahai Yu,Zhiqing Hong,Yuan Tian,Guang Wang*

Main category: cs.LG

TL;DR: GeoGen是一个两阶段粗到细的框架，用于生成基于位置的社交网络签到轨迹数据，通过空间扩散模型和Transformer架构解决轨迹数据的稀疏性和不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 由于LBSN签到轨迹数据收集成本高且存在隐私问题，需要生成既能保护隐私又保留真实数据特征的合成数据，但现有方法难以处理轨迹数据的空间离散、时间不规则特性。

Method: 提出两阶段框架：第一阶段使用稀疏感知时空扩散模型学习潜在移动序列的行为模式；第二阶段使用Transformer架构的Coarse2FineNet，通过动态上下文融合和多任务解码器生成细粒度轨迹。

Result: 在四个真实数据集上的实验表明，GeoGen在保真度和实用性评估上均优于最先进模型，在FS-TKY数据集上距离和半径指标分别提高69%和55%。

Conclusion: GeoGen成功解决了LBSN轨迹生成的挑战，为POI推荐、广告投放等应用提供了高质量的合成数据解决方案。

Abstract: Location-Based Social Network (LBSN) check-in trajectory data are important
for many practical applications, like POI recommendation, advertising, and
pandemic intervention. However, the high collection costs and ever-increasing
privacy concerns prevent us from accessing large-scale LBSN trajectory data.
The recent advances in synthetic data generation provide us with a new
opportunity to achieve this, which utilizes generative AI to generate synthetic
data that preserves the characteristics of real data while ensuring privacy
protection. However, generating synthetic LBSN check-in trajectories remains
challenging due to their spatially discrete, temporally irregular nature and
the complex spatio-temporal patterns caused by sparse activities and uncertain
human mobility. To address this challenge, we propose GeoGen, a two-stage
coarse-to-fine framework for large-scale LBSN check-in trajectory generation.
In the first stage, we reconstruct spatially continuous, temporally regular
latent movement sequences from the original LBSN check-in trajectories and then
design a Sparsity-aware Spatio-temporal Diffusion model (S$^2$TDiff) with an
efficient denosing network to learn their underlying behavioral patterns. In
the second stage, we design Coarse2FineNet, a Transformer-based Seq2Seq
architecture equipped with a dynamic context fusion mechanism in the encoder
and a multi-task hybrid-head decoder, which generates fine-grained LBSN
trajectories based on coarse-grained latent movement sequences by modeling
semantic relevance and behavioral uncertainty. Extensive experiments on four
real-world datasets show that GeoGen excels state-of-the-art models for both
fidelity and utility evaluation, e.g., it increases over 69% and 55% in
distance and radius metrics on the FS-TKY dataset.

</details>


### [11] [MetaDefense: Defending Finetuning-based Jailbreak Attack Before and During Generation](https://arxiv.org/abs/2510.07835)
*Weisen Jiang,Sinno Jialin Pan*

Main category: cs.LG

TL;DR: MetaDefense是一个防御大型语言模型微调越狱攻击的新框架，采用两阶段防御方法：预生成检测和生成中监控，显著优于现有防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制无法泛化到未见攻击模板伪装的有害查询，尽管LLMs在嵌入空间能够区分这些查询。

Method: 提出两阶段防御：预生成防御在响应生成前检测有害查询，生成中防御监控部分响应以防止输出更多有害内容；训练LLM使用专门提示预测查询和部分响应的危害性。

Result: 在多个LLM架构上的实验表明，MetaDefense显著优于现有防御机制，对已见和未见攻击模板的有害查询都能实现鲁棒防御，同时在良性任务上保持竞争力。

Conclusion: MetaDefense框架通过两阶段防御方法有效防御微调越狱攻击，具有强泛化能力和实用性。

Abstract: This paper introduces MetaDefense, a novel framework for defending against
finetuning-based jailbreak attacks in large language models (LLMs). We observe
that existing defense mechanisms fail to generalize to harmful queries
disguised by unseen attack templates, despite LLMs being capable of
distinguishing disguised harmful queries in the embedding space. Based on these
insights, we propose a two-stage defense approach: (i) pre-generation defense
that detects harmful queries before response generation begins, and (ii)
mid-generation defense that monitors partial responses during generation to
prevent outputting more harmful content. Our MetaDefense trains the LLM to
predict the harmfulness of both queries and partial responses using specialized
prompts, enabling early termination of potentially harmful interactions.
Extensive experiments across multiple LLM architectures (LLaMA-2-7B,
Qwen-2.5-3B-Instruct, and LLaMA-3.2-3B-Instruct) demonstrate that MetaDefense
significantly outperforms existing defense mechanisms, achieving robust defense
against harmful queries with seen and unseen attack templates while maintaining
competitive performance on benign tasks. Code is available at
https://github.com/ws-jiang/MetaDefense.

</details>


### [12] [SketchGuard: Scaling Byzantine-Robust Decentralized Federated Learning via Sketch-Based Screening](https://arxiv.org/abs/2510.07922)
*Murtaza Rangwala,Farag Azzedin,Richard O. Sinnott,Rajkumar Buyya*

Main category: cs.LG

TL;DR: SketchGuard是一个基于草图压缩的去中心化联邦学习框架，通过Count Sketch将高维模型压缩为低维草图进行相似性比较，大幅降低通信和计算开销，同时保持拜占庭攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的拜占庭鲁棒DFL防御方法需要每个客户端在每轮训练中与所有邻居交换和比较完整的高维模型向量，导致通信和计算成本过高，无法在web规模部署。

Method: 使用Count Sketch将d维模型压缩为k维草图（k<<d）进行相似性比较，然后仅从接受的邻居处选择性获取完整模型，将每轮通信复杂度从O(d|N_i|)降低到O(k|N_i| + d|S_i|)。

Result: 在多个数据集、网络拓扑和攻击场景下的实验表明，SketchGuard保持了与最先进方法相同的鲁棒性，同时将计算时间减少高达82%，通信开销减少50-70%，且收益随模型维度和网络连接性呈乘性增长。

Conclusion: 基于草图压缩的方法为实现web规模的鲁棒去中心化联邦学习提供了可行的基础使能技术。

Abstract: Decentralized Federated Learning (DFL) enables privacy-preserving
collaborative training without centralized servers, but remains vulnerable to
Byzantine attacks where malicious clients submit corrupted model updates.
Existing Byzantine-robust DFL defenses rely on similarity-based neighbor
screening that requires every client to exchange and compare complete
high-dimensional model vectors with all neighbors in each training round,
creating prohibitive communication and computational costs that prevent
deployment at web scale. We propose SketchGuard, a general framework that
decouples Byzantine filtering from model aggregation through sketch-based
neighbor screening. SketchGuard compresses $d$-dimensional models to
$k$-dimensional sketches ($k \ll d$) using Count Sketch for similarity
comparisons, then selectively fetches full models only from accepted neighbors,
reducing per-round communication complexity from $O(d|N_i|)$ to $O(k|N_i| +
d|S_i|)$, where $|N_i|$ is the neighbor count and $|S_i| \le |N_i|$ is the
accepted neighbor count. We establish rigorous convergence guarantees in both
strongly convex and non-convex settings, proving that Count Sketch compression
preserves Byzantine resilience with controlled degradation bounds where
approximation errors introduce only a $(1+O(\epsilon))$ factor in the effective
threshold parameter. Comprehensive experiments across multiple datasets,
network topologies, and attack scenarios demonstrate that SketchGuard maintains
identical robustness to state-of-the-art methods while reducing computation
time by up to 82% and communication overhead by 50-70% depending on filtering
effectiveness, with benefits scaling multiplicatively with model dimensionality
and network connectivity. These results establish the viability of sketch-based
compression as a fundamental enabler of robust DFL at web scale.

</details>


### [13] [Long-tailed Recognition with Model Rebalancing](https://arxiv.org/abs/2510.08177)
*Jiaan Luo,Feng Hong,Qiang Hu,Xiaofeng Cao,Feng Liu,Jiangchao Yao*

Main category: cs.LG

TL;DR: 提出MORE框架，通过直接重新平衡模型参数空间来解决长尾识别问题，使用低秩参数组件和正弦重加权调度，不增加模型复杂度或推理成本。


<details>
  <summary>Details</summary>
Motivation: 长尾识别在深度学习和基础模型微调中普遍存在且具有挑战性，偏斜的类别分布阻碍了模型对尾部类别的泛化能力。现有方法在多标签长尾识别等广泛场景中难以取得一致改进。

Method: 提出模型再平衡(MORE)框架，引入低秩参数组件来调节参数空间分配，采用定制损失和正弦重加权调度，但不增加整体模型复杂度或推理成本。

Result: 在多样化的长尾基准测试中，涵盖多类和多标签任务，MORE显著提高了泛化能力，特别是对尾部类别，并有效补充了现有的不平衡缓解方法。

Conclusion: MORE作为长尾设置中的鲁棒即插即用模块具有巨大潜力，通过直接重新平衡模型参数空间来解决类别不平衡问题。

Abstract: Long-tailed recognition is ubiquitous and challenging in deep learning and
even in the downstream finetuning of foundation models, since the skew class
distribution generally prevents the model generalization to the tail classes.
Despite the promise of previous methods from the perspectives of data
augmentation, loss rebalancing and decoupled training etc., consistent
improvement in the broad scenarios like multi-label long-tailed recognition is
difficult. In this study, we dive into the essential model capacity impact
under long-tailed context, and propose a novel framework, Model Rebalancing
(MORE), which mitigates imbalance by directly rebalancing the model's parameter
space. Specifically, MORE introduces a low-rank parameter component to mediate
the parameter space allocation guided by a tailored loss and sinusoidal
reweighting schedule, but without increasing the overall model complexity or
inference costs. Extensive experiments on diverse long-tailed benchmarks,
spanning multi-class and multi-label tasks, demonstrate that MORE significantly
improves generalization, particularly for tail classes, and effectively
complements existing imbalance mitigation methods. These results highlight
MORE's potential as a robust plug-and-play module in long-tailed settings.

</details>


### [14] [The Hidden Bias: A Study on Explicit and Implicit Political Stereotypes in Large Language Models](https://arxiv.org/abs/2510.08236)
*Konrad Löhr,Shuzhou Yuan,Michael Färber*

Main category: cs.LG

TL;DR: 本文使用政治罗盘测试评估了8个主流大语言模型的政治偏见和刻板印象传播，发现所有模型都呈现一致的左倾政治倾向，且通过语言变化引发的隐性刻板印象比显性刻板印象更明显。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在社会信息传播和决策过程中的作用日益重要，理解其政治偏见对于防止对公众舆论和民主进程产生不当影响至关重要。

Method: 采用二维政治罗盘测试评估模型的内在政治倾向，使用角色提示探索显性刻板印象，并通过多语言版本测试揭示隐性刻板印象。

Result: 所有被调查模型都显示出一致的左倾政治倾向；隐性刻板印象比显性刻板印象更显著；大多数模型的隐性和显性刻板印象存在显著一致性。

Conclusion: 研究揭示了大语言模型中政治偏见与刻板印象的复杂相互作用，表明模型对其内在偏见具有一定程度的透明度或"意识"。

Abstract: Large Language Models (LLMs) are increasingly integral to information
dissemination and decision-making processes. Given their growing societal
influence, understanding potential biases, particularly within the political
domain, is crucial to prevent undue influence on public opinion and democratic
processes. This work investigates political bias and stereotype propagation
across eight prominent LLMs using the two-dimensional Political Compass Test
(PCT). Initially, the PCT is employed to assess the inherent political leanings
of these models. Subsequently, persona prompting with the PCT is used to
explore explicit stereotypes across various social dimensions. In a final step,
implicit stereotypes are uncovered by evaluating models with multilingual
versions of the PCT. Key findings reveal a consistent left-leaning political
alignment across all investigated models. Furthermore, while the nature and
extent of stereotypes vary considerably between models, implicit stereotypes
elicited through language variation are more pronounced than those identified
via explicit persona prompting. Interestingly, for most models, implicit and
explicit stereotypes show a notable alignment, suggesting a degree of
transparency or "awareness" regarding their inherent biases. This study
underscores the complex interplay of political bias and stereotypes in LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines](https://arxiv.org/abs/2510.07614)
*Amine Barrak*

Main category: cs.AI

TL;DR: 该论文研究了一种可追踪和可问责的多智能体LLM管道系统，通过结构化交接和记录保存来提升系统可靠性和错误追踪能力。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的顺序多智能体系统中错误传递和难以追踪的问题，建立可信赖的自动化软件任务执行系统。

Method: 采用Planner -> Executor -> Critic三阶段管道架构，评估8种配置的三种先进LLM在三个基准测试上的表现，分析错误起源、传播和修复机制。

Result: 结构化交接显著提高准确性并防止常见故障；模型具有明确的角色特定优势和风险；准确度-成本-延迟权衡是任务依赖性的，异构管道通常最有效。

Conclusion: 提供了一种实用的数据驱动方法来设计、追踪和调试可靠、可预测和可问责的多智能体系统。

Abstract: Sequential multi-agent systems built with large language models (LLMs) can
automate complex software tasks, but they are hard to trust because errors
quietly pass from one stage to the next. We study a traceable and accountable
pipeline, meaning a system with clear roles, structured handoffs, and saved
records that let us trace who did what at each step and assign blame when
things go wrong. Our setting is a Planner -> Executor -> Critic pipeline. We
evaluate eight configurations of three state-of-the-art LLMs on three
benchmarks and analyze where errors start, how they spread, and how they can be
fixed. Our results show: (1) adding a structured, accountable handoff between
agents markedly improves accuracy and prevents the failures common in simple
pipelines; (2) models have clear role-specific strengths and risks (e.g.,
steady planning vs. high-variance critiquing), which we quantify with repair
and harm rates; and (3) accuracy-cost-latency trade-offs are task-dependent,
with heterogeneous pipelines often the most efficient. Overall, we provide a
practical, data-driven method for designing, tracing, and debugging reliable,
predictable, and accountable multi-agent systems.

</details>


### [16] [GCPO: When Contrast Fails, Go Gold](https://arxiv.org/abs/2510.07790)
*Hao Wu,Wei Liu*

Main category: cs.AI

TL;DR: 提出了Group Contrastive Policy Optimization (GCPO)方法，通过引入外部标准参考答案来解决GRPO算法中模型无法从全错或全对样本中学习的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法如GRPO存在明显缺陷：模型生成响应的上限完全由模型自身决定，无法从全错或全对的样本中获取知识。

Method: GCPO方法引入外部标准参考答案，当模型无法解决问题时，参考答案提供正确响应，引导模型向明确准确的更新方向学习。

Result: GCPO在多个基准数据集上取得了优异结果，相比基线模型有显著提升。

Conclusion: GCPO方法能够充分利用每个样本提高训练效率，并让模型在训练过程中模仿参考答案的解题策略，从而增强推理的泛化能力。

Abstract: Reinforcement learning has been widely applied to enhance the reasoning
capabilities of large language models. Extending the inference limits of
smaller models has become a prominent research focus. However, algorithms such
as Group Relative Policy Optimization (GRPO) suffer from a clear drawback: the
upper bound of a model's rollout responses is entirely determined by the model
itself, preventing the acquisition of knowledge from samples that are either
all incorrect or all correct. In this paper, we introduce Group Contrastive
Policy Optimization (GCPO), a method that incorporates external standard
reference answers. When the model cannot solve a problem, the reference answer
supplies the correct response, steering the model toward an unequivocally
accurate update direction. This approach offers two main advantages: (1) it
improves training efficiency by fully utilizing every sample; (2) it enables
the model to emulate the problem solving strategy of the reference answer
during training, thereby enhancing generalization in reasoning. GCPO achieves
outstanding results across multiple benchmark datasets, yielding substantial
improvements over the baseline model. Our code is available at:
https://github.com/AchoWu/GCPO.

</details>


### [17] [Can Risk-taking AI-Assistants suitably represent entities](https://arxiv.org/abs/2510.08114)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Amirhossein Farshi Sotoudeh*

Main category: cs.AI

TL;DR: 该研究调查了语言模型中风险厌恶的可操纵性，发现虽然一些模型与人类行为有一定对齐，但仍存在显著差异，需要改进生物中心的可操纵性测量方法。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地集成到AI驱动的决策支持系统中，理解其风险行为对于负责任部署至关重要，需要防止无意中将用户推向风险决策或嵌入隐藏偏见。

Method: 研究了语言模型在不同经济场景中复制人类风险偏好的能力，重点关注性别特定态度、不确定性、基于角色的决策制定以及风险厌恶的可操纵性。

Result: DeepSeek Reasoner和Gemini-2.0-flash-lite等语言模型与人类行为表现出一定对齐，但存在显著差异，突显了改进生物中心可操纵性测量的必要性。

Conclusion: 需要进一步改进模型设计，确保AI系统更准确地复制人类风险偏好，从而提高其在风险管理环境中的有效性，增强AI助手在风险管理中的适用性。

Abstract: Responsible AI demands systems whose behavioral tendencies can be effectively
measured, audited, and adjusted to prevent inadvertently nudging users toward
risky decisions or embedding hidden biases in risk aversion. As language models
(LMs) are increasingly incorporated into AI-driven decision support systems,
understanding their risk behaviors is crucial for their responsible deployment.
This study investigates the manipulability of risk aversion (MoRA) in LMs,
examining their ability to replicate human risk preferences across diverse
economic scenarios, with a focus on gender-specific attitudes, uncertainty,
role-based decision-making, and the manipulability of risk aversion. The
results indicate that while LMs such as DeepSeek Reasoner and
Gemini-2.0-flash-lite exhibit some alignment with human behaviors, notable
discrepancies highlight the need to refine bio-centric measures of
manipulability. These findings suggest directions for refining AI design to
better align human and AI risk preferences and enhance ethical decision-making.
The study calls for further advancements in model design to ensure that AI
systems more accurately replicate human risk preferences, thereby improving
their effectiveness in risk management contexts. This approach could enhance
the applicability of AI assistants in managing risk.

</details>


### [18] [Co-TAP: Three-Layer Agent Interaction Protocol Technical Report](https://arxiv.org/abs/2510.08263)
*Shunyu An,Miao Wang,Yongchao Li,Dong Wan,Lina Wang,Ling Qin,Liqin Gao,Congyao Fan,Zhiyong Mao,Jiange Pu,Wenji Xia,Dong Zhao,Rui Hu,Ji Lu,Guiyue Zhou,Baoyu Tang,Yanqin Gao,Yongsheng Du,Daigang Xu,Lingjun Huang,Baoli Wang,Xiwen Zhang,Luyao Wang,Shilong Liu*

Main category: cs.AI

TL;DR: Co-TAP是一个三层代理交互协议，通过HAI、UAP和MEK三个核心协议解决多智能体系统在互操作性、交互协作和知识共享方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在互操作性、交互协作和知识共享三个核心维度面临的挑战，为构建下一代高效、可扩展和智能的多智能体应用提供工程基础和理论指导。

Method: 设计了三层协议框架：HAI协议标准化人机交互流程，UAP协议实现异构代理间的无缝互连，MEK协议建立标准化的记忆-提取-知识认知链。

Result: 提出了一个完整的协议框架，能够确保交互的实时性、可靠性和协同性，实现异构代理的互操作性，并为集体智能的实现奠定基础。

Conclusion: Co-TAP协议框架为构建高效、可扩展和智能的多智能体应用提供了坚实的工程基础和理论指导，有望推动下一代多智能体系统的发展。

Abstract: This paper proposes Co-TAP (T: Triple, A: Agent, P: Protocol), a three-layer
agent interaction protocol designed to address the challenges faced by
multi-agent systems across the three core dimensions of Interoperability,
Interaction and Collaboration, and Knowledge Sharing. We have designed and
proposed a layered solution composed of three core protocols: the Human-Agent
Interaction Protocol (HAI), the Unified Agent Protocol (UAP), and the
Memory-Extraction-Knowledge Protocol (MEK). HAI focuses on the interaction
layer, standardizing the flow of information between users, interfaces, and
agents by defining a standardized, event-driven communication paradigm. This
ensures the real-time performance, reliability, and synergy of interactions. As
the core of the infrastructure layer, UAP is designed to break down
communication barriers among heterogeneous agents through unified service
discovery and protocol conversion mechanisms, thereby enabling seamless
interconnection and interoperability of the underlying network. MEK, in turn,
operates at the cognitive layer. By establishing a standardized ''Memory (M) -
Extraction (E) - Knowledge (K)'' cognitive chain, it empowers agents with the
ability to learn from individual experiences and form shareable knowledge,
thereby laying the foundation for the realization of true collective
intelligence. We believe this protocol framework will provide a solid
engineering foundation and theoretical guidance for building the next
generation of efficient, scalable, and intelligent multi-agent applications.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 提出一个新的波斯语-塔吉克语双向音译模型，使用序列到序列方法，在多个数据集上训练，实现了目前最先进的音译性能。


<details>
  <summary>Details</summary>
Motivation: 波斯语使用两种书写标准（波斯-阿拉伯字母和塔吉克-西里尔字母），虽然方言相似但书写差异阻碍了塔吉克斯坦与其他波斯语国家的书面交流。现有模型受限于特定领域数据，缺乏实际应用的多样性。

Method: 使用序列到序列模型，在所有可用数据集上进行训练，并贡献了两个新数据集，实现双向音译（波斯语到塔吉克语和塔吉克语到波斯语）。

Result: 模型在波斯语到塔吉克语方向达到chrF++ 87.91和标准化CER 0.05，塔吉克语到波斯语方向达到chrF++ 92.28和标准化CER 0.04，设定了全面的基准。

Conclusion: 该模型提供了跨领域的音译能力，为波斯语书写系统之间的转换建立了新的最先进基准，模型、数据和代码均已公开。

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [20] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 研究发现增强LLM的事实准确性会削弱安全对齐能力，提出通过特征解耦和子空间正交化来同时保持事实准确性和安全拒绝行为。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了增强事实准确性对安全对齐的负面影响，需要解决事实准确性与安全拒绝之间的权衡问题。

Method: 使用稀疏自编码器解耦拒绝相关特征与幻觉特征，在微调过程中通过子空间正交化保持拒绝行为。

Result: 在常识推理任务和有害基准测试中，该方法能保持拒绝行为和任务效用，缓解事实准确性与安全性之间的权衡。

Conclusion: 提出的方法能有效防止幻觉增加的同时保持安全对齐，解决了事实准确性与安全性之间的冲突。

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [21] [Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning](https://arxiv.org/abs/2510.07974)
*Jialu Du,Guiyang Hou,Yihui Fu,Chen Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu*

Main category: cs.CL

TL;DR: LLMs在社交推理任务中存在困难，无法区分客观现实与主观信念。本文提出自适应世界模型增强推理机制，通过构建动态文本世界模型来跟踪实体状态和时间序列，显著提升了社交推理准确性并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和代码推理方面表现出色，但在社交推理任务中却遇到困难，表现出认知混乱、逻辑不一致以及混淆客观世界状态与主观信念状态的问题。

Method: 提出自适应世界模型增强推理机制，构建动态文本世界模型来跟踪实体状态和时间序列，动态监控推理轨迹中的混乱指标，并通过提供清晰的世界状态描述来及时干预。

Result: 在三个社交基准测试中显示出显著改进，准确率提升（例如Hi-ToM中+10%），同时计算成本降低（最多减少33.8%的token使用）。

Conclusion: 该机制提供了一个简单而有效的解决方案，使LLMs能够在社交情境中更好地部署，模仿人类使用隐式世界模型来区分外部事件和内部信念的方式。

Abstract: While large language models (LLMs) excel in mathematical and code reasoning,
we observe they struggle with social reasoning tasks, exhibiting cognitive
confusion, logical inconsistencies, and conflation between objective world
states and subjective belief states. Through deteiled analysis of DeepSeek-R1's
reasoning trajectories, we find that LLMs frequently encounter reasoning
impasses and tend to output contradictory terms like "tricky" and "confused"
when processing scenarios with multiple participants and timelines, leading to
erroneous reasoning or infinite loops. The core issue is their inability to
disentangle objective reality from agents' subjective beliefs. To address this,
we propose an adaptive world model-enhanced reasoning mechanism that constructs
a dynamic textual world model to track entity states and temporal sequences. It
dynamically monitors reasoning trajectories for confusion indicators and
promptly intervenes by providing clear world state descriptions, helping models
navigate through cognitive dilemmas. The mechanism mimics how humans use
implicit world models to distinguish between external events and internal
beliefs. Evaluations on three social benchmarks demonstrate significant
improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational
costs (up to 33.8% token reduction), offering a simple yet effective solution
for deploying LLMs in social contexts.

</details>


### [22] [SenWave: A Fine-Grained Multi-Language Sentiment Analysis Dataset Sourced from COVID-19 Tweets](https://arxiv.org/abs/2510.08214)
*Qiang Yang,Xiuying Chen,Changsheng Ma,Rui Yin,Xin Gao,Xiangliang Zhang*

Main category: cs.CL

TL;DR: SenWave是一个专门用于分析COVID-19推文的多语言细粒度情感分析数据集，包含10个情感类别，涵盖英语、阿拉伯语原始推文以及西班牙语、法语、意大利语翻译推文，总计10万条标注推文和1.05亿条未标注推文。


<details>
  <summary>Details</summary>
Motivation: 现有COVID-19公共数据集存在标注数据不足、情感标签粗糙或不适当的问题，需要更精细的情感分析来全面理解疫情期间的公众情绪。

Method: 构建多语言细粒度情感标注数据集，使用预训练的基于transformer的语言模型进行微调，实现准确的情感分类，并评估与ChatGPT的兼容性。

Result: 提供了跨语言、国家和主题的情绪演变深度分析，展示了数据集在多种应用中的稳健性和多功能性。

Conclusion: SenWave数据集和代码已公开，预计将推动NLP社区对复杂事件细粒度情感分析的进一步探索，促进更细致的理解和研究创新。

Abstract: The global impact of the COVID-19 pandemic has highlighted the need for a
comprehensive understanding of public sentiment and reactions. Despite the
availability of numerous public datasets on COVID-19, some reaching volumes of
up to 100 billion data points, challenges persist regarding the availability of
labeled data and the presence of coarse-grained or inappropriate sentiment
labels. In this paper, we introduce SenWave, a novel fine-grained
multi-language sentiment analysis dataset specifically designed for analyzing
COVID-19 tweets, featuring ten sentiment categories across five languages. The
dataset comprises 10,000 annotated tweets each in English and Arabic, along
with 30,000 translated tweets in Spanish, French, and Italian, derived from
English tweets. Additionally, it includes over 105 million unlabeled tweets
collected during various COVID-19 waves. To enable accurate fine-grained
sentiment classification, we fine-tuned pre-trained transformer-based language
models using the labeled tweets. Our study provides an in-depth analysis of the
evolving emotional landscape across languages, countries, and topics, revealing
significant insights over time. Furthermore, we assess the compatibility of our
dataset with ChatGPT, demonstrating its robustness and versatility in various
applications. Our dataset and accompanying code are publicly accessible on the
repository\footnote{https://github.com/gitdevqiang/SenWave}. We anticipate that
this work will foster further exploration into fine-grained sentiment analysis
for complex events within the NLP community, promoting more nuanced
understanding and research innovations.

</details>


### [23] [Two-Stage Voting for Robust and Efficient Suicide Risk Detection on Social Media](https://arxiv.org/abs/2510.08365)
*Yukai Song,Pengfei Zhou,César Escobar-Viera,Candice Biernesser,Wei Huang,Jingtong Hu*

Main category: cs.CL

TL;DR: 提出两阶段投票架构用于自杀风险检测，平衡效率和鲁棒性。第一阶段用轻量BERT处理高置信度显性案例，第二阶段对模糊输入使用多视角LLM投票或基于心理特征的ML集成。


<details>
  <summary>Details</summary>
Motivation: 全球自杀率上升，需要主动预防策略。社交媒体提供有价值信号，但检测隐式自杀意念（通过隐喻、讽刺或微妙情感表达）极具挑战。轻量模型处理显性信号但无法捕捉细微隐式信号，而LLMs能捕捉细微差别但计算成本过高。

Method: 两阶段投票架构：第一阶段用轻量BERT分类器快速处理高置信度显性案例；第二阶段对模糊输入使用(i)多视角LLM投票框架最大化隐式意念召回率，或(ii)基于心理特征指标的ML集成，通过提示工程LLMs提取心理特征实现效率和可解释性。

Result: 在两个互补数据集（显性主导的Reddit和纯隐式DeepSuiMind）上，框架优于单模型基线，显性案例F1达98.0%，隐式案例达99.7%，跨域差距降至2%以下，同时显著降低LLM成本。

Conclusion: 这是首批将LLM提取的心理特征作为结构化向量用于自杀风险检测的工作之一，提出的框架在效率和鲁棒性之间取得了良好平衡，有效解决了隐式自杀意念检测的挑战。

Abstract: Suicide rates have risen worldwide in recent years, underscoring the urgent
need for proactive prevention strategies. Social media provides valuable
signals, as many at-risk individuals - who often avoid formal help due to
stigma - choose instead to share their distress online. Yet detecting implicit
suicidal ideation, conveyed indirectly through metaphor, sarcasm, or subtle
emotional cues, remains highly challenging. Lightweight models like BERT handle
explicit signals but fail on subtle implicit ones, while large language models
(LLMs) capture nuance at prohibitive computational cost. To address this gap,
we propose a two-stage voting architecture that balances efficiency and
robustness. In Stage 1, a lightweight BERT classifier rapidly resolves
high-confidence explicit cases. In Stage 2, ambiguous inputs are escalated to
either (i) a multi-perspective LLM voting framework to maximize recall on
implicit ideation, or (ii) a feature-based ML ensemble guided by
psychologically grounded indicators extracted via prompt-engineered LLMs for
efficiency and interpretability. To the best of our knowledge, this is among
the first works to operationalize LLM-extracted psychological features as
structured vectors for suicide risk detection. On two complementary datasets -
explicit-dominant Reddit and implicit-only DeepSuiMind - our framework
outperforms single-model baselines, achieving 98.0% F1 on explicit cases, 99.7%
on implicit ones, and reducing the cross-domain gap below 2%, while
significantly lowering LLM cost.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Differentiable Particle Optimization for Fast Sequential Manipulation](https://arxiv.org/abs/2510.07674)
*Lucas Chen,Shrutheesh Raman Iyer,Zachary Kingston*

Main category: cs.RO

TL;DR: SPaSM是一个完全GPU并行化的框架，通过两阶段粒子优化策略解决顺序机器人操作任务中的轨迹优化问题，实现了毫秒级的求解时间和4000倍的加速。


<details>
  <summary>Details</summary>
Motivation: 顺序机器人操作任务需要在可能的高维配置空间中寻找满足多个物体交互几何约束的无碰撞轨迹，但由于计算需求，实时大规模求解一直难以实现。现有GPU加速方法受限于CPU-GPU数据传输开销和复杂逻辑，无法充分利用硬件性能。

Method: SPaSM将约束评估、采样和基于梯度的优化编译为优化的CUDA内核，实现端到端轨迹优化而无需CPU协调。采用两阶段粒子优化策略：首先通过大规模并行采样解决放置约束，然后将解决方案提升到关节空间进行完整轨迹优化。

Result: 在具有挑战性的基准测试中，SPaSM实现了毫秒级的求解时间，成功率达到100%，相比现有方法实现了4000倍的加速。

Conclusion: SPaSM通过完全GPU并行化和联合优化物体放置与机器人轨迹，有效解决了顺序操作任务中的计算瓶颈，为实时大规模机器人操作提供了可行方案。

Abstract: Sequential robot manipulation tasks require finding collision-free
trajectories that satisfy geometric constraints across multiple object
interactions in potentially high-dimensional configuration spaces. Solving
these problems in real-time and at large scales has remained out of reach due
to computational requirements. Recently, GPU-based acceleration has shown
promising results, but prior methods achieve limited performance due to CPU-GPU
data transfer overhead and complex logic that prevents full hardware
utilization. To this end, we present SPaSM (Sampling Particle optimization for
Sequential Manipulation), a fully GPU-parallelized framework that compiles
constraint evaluation, sampling, and gradient-based optimization into optimized
CUDA kernels for end-to-end trajectory optimization without CPU coordination.
The method consists of a two-stage particle optimization strategy: first
solving placement constraints through massively parallel sampling, then lifting
solutions to full trajectory optimization in joint space. Unlike hierarchical
approaches, SPaSM jointly optimizes object placements and robot trajectories to
handle scenarios where motion feasibility constrains placement options.
Experimental evaluation on challenging benchmarks demonstrates solution times
in the realm of $\textbf{milliseconds}$ with a 100% success rate; a
$4000\times$ speedup compared to existing approaches.

</details>


### [25] [DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation](https://arxiv.org/abs/2510.07865)
*Guowei Zou,Haitao Wang,Hejun Wu,Yukun Qian,Yuhang Wang,Weibing Li*

Main category: cs.RO

TL;DR: DM1是一个新颖的流匹配框架，通过引入分散正则化来防止表示坍塌，同时保持一步生成效率，在机器人操作任务中实现快速推理和高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流的策略存在表示坍塌问题，无法区分相似的视觉表示，导致在精确操作任务中失败。需要一种既能保持一步生成效率又能防止表示坍塌的方法。

Method: 在MeanFlow中集成分散正则化，在多个中间嵌入层使用不同的分散正则化变体，鼓励训练批次中的多样化表示，无需额外的网络模块或专门训练过程。

Result: 在RoboMimic基准测试中，DM1实现20-40倍更快的推理速度（0.07s vs. 2-3.5s），成功率提高10-20个百分点，Lift任务达到99%成功率（基线为85%）。真实机器人部署验证了从仿真到物理世界的有效迁移。

Conclusion: 这是首个利用表示正则化使基于流的策略在机器人操作中实现强劲性能的工作，为高效鲁棒的操作建立了一个简单而强大的方法。

Abstract: The ability to learn multi-modal action distributions is indispensable for
robotic manipulation policies to perform precise and robust control. Flow-based
generative models have recently emerged as a promising solution to learning
distributions of actions, offering one-step action generation and thus
achieving much higher sampling efficiency compared to diffusion-based methods.
However, existing flow-based policies suffer from representation collapse, the
inability to distinguish similar visual representations, leading to failures in
precise manipulation tasks. We propose DM1 (MeanFlow with Dispersive
Regularization for One-Step Robotic Manipulation), a novel flow matching
framework that integrates dispersive regularization into MeanFlow to prevent
collapse while maintaining one-step efficiency. DM1 employs multiple dispersive
regularization variants across different intermediate embedding layers,
encouraging diverse representations across training batches without introducing
additional network modules or specialized training procedures. Experiments on
RoboMimic benchmarks show that DM1 achieves 20-40 times faster inference (0.07s
vs. 2-3.5s) and improves success rates by 10-20 percentage points, with the
Lift task reaching 99% success over 85% of the baseline. Real-robot deployment
on a Franka Panda further validates that DM1 transfers effectively from
simulation to the physical world. To the best of our knowledge, this is the
first work to leverage representation regularization to enable flow-based
policies to achieve strong performance in robotic manipulation, establishing a
simple yet powerful approach for efficient and robust manipulation.

</details>


### [26] [Scalable Offline Metrics for Autonomous Driving](https://arxiv.org/abs/2510.08571)
*Animikh Aich,Adwait Kulkarni,Eshed Ohn-Bar*

Main category: cs.RO

TL;DR: 本文评估了感知规划模型在自动驾驶中的离线与在线性能相关性，发现两者相关性比先前研究更差，并提出基于认知不确定性的离线指标来改善相关性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的离线评估虽然安全经济，但难以准确预测在线性能，微小错误可能在测试时导致事故，这种关系在复杂城市场景中研究不足。

Method: 通过广泛的仿真实验分析离线与在线性能相关性，研究基于认知不确定性的离线指标来捕捉可能导致闭环错误的场景。

Result: 发现离线与在线性能相关性比先前报告更差，提出的新离线指标相比先前指标相关性提升超过13%，在真实世界环境中获得更大改进。

Conclusion: 当前驾驶策略评估实践存在有效性疑问，基于认知不确定性的离线指标能更好桥接离线与在线评估差距，在真实环境中表现更佳。

Abstract: Real-World evaluation of perception-based planning models for robotic
systems, such as autonomous vehicles, can be safely and inexpensively conducted
offline, i.e., by computing model prediction error over a pre-collected
validation dataset with ground-truth annotations. However, extrapolating from
offline model performance to online settings remains a challenge. In these
settings, seemingly minor errors can compound and result in test-time
infractions or collisions. This relationship is understudied, particularly
across diverse closed-loop metrics and complex urban maneuvers. In this work,
we revisit this undervalued question in policy evaluation through an extensive
set of experiments across diverse conditions and metrics. Based on analysis in
simulation, we find an even worse correlation between offline and online
settings than reported by prior studies, casting doubts on the validity of
current evaluation practices and metrics for driving policies. Next, we bridge
the gap between offline and online evaluation. We investigate an offline metric
based on epistemic uncertainty, which aims to capture events that are likely to
cause errors in closed-loop settings. The resulting metric achieves over 13%
improvement in correlation compared to previous offline metrics. We further
validate the generalization of our findings beyond the simulation environment
in real-world settings, where even greater gains are observed.

</details>
