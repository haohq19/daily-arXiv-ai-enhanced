<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 6]
- [cs.RO](#cs.RO) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MemEvo: Memory-Evolving Incremental Multi-view Clustering](https://arxiv.org/abs/2509.14544)
*Zisen Kong,Bo Zhong,Pengyuan Li,Dongxia Chang,Yiming Wang*

Main category: cs.CV

TL;DR: MemEvo是一种基于神经科学记忆机制的多视图增量聚类方法，通过海马体启发的视图对齐、认知遗忘机制和前额叶皮层启发的知识巩固模块，有效解决了增量学习中的稳定性-可塑性困境。


<details>
  <summary>Details</summary>
Motivation: 解决多视图增量聚类中的稳定性-可塑性困境(SPD)，使模型既能快速适应新数据，又能保持长期知识避免灾难性遗忘。

Method: 1) 海马体启发的视图对齐模块，通过连续表示中的结构对齐捕获新视图增益信息；2) 认知遗忘机制，模拟人类记忆衰减模式调节历史知识权重；3) 前额叶皮层启发的知识巩固记忆模块，利用时间张量稳定性逐步巩固历史知识。

Result: 在视图数量增长场景下表现出强大的知识保留能力，相比现有最先进方法具有显著优势。

Conclusion: MemEvo通过神经科学启发的记忆机制成功平衡了增量学习中的稳定性和可塑性需求，为多视图增量聚类提供了有效解决方案。

Abstract: Incremental multi-view clustering aims to achieve stable clustering results
while addressing the stability-plasticity dilemma (SPD) in incremental views.
At the core of SPD is the challenge that the model must have enough plasticity
to quickly adapt to new data, while maintaining sufficient stability to
consolidate long-term knowledge and prevent catastrophic forgetting. Inspired
by the hippocampal-prefrontal cortex collaborative memory mechanism in
neuroscience, we propose a Memory-Evolving Incremental Multi-view Clustering
method (MemEvo) to achieve this balance. First, we propose a
hippocampus-inspired view alignment module that captures the gain information
of new views by aligning structures in continuous representations. Second, we
introduce a cognitive forgetting mechanism that simulates the decay patterns of
human memory to modulate the weights of historical knowledge. Additionally, we
design a prefrontal cortex-inspired knowledge consolidation memory module that
leverages temporal tensor stability to gradually consolidate historical
knowledge. By integrating these modules, MemEvo achieves strong knowledge
retention capabilities in scenarios with a growing number of views. Extensive
experiments demonstrate that MemEvo exhibits remarkable advantages over
existing state-of-the-art methods.

</details>


### [2] [RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching](https://arxiv.org/abs/2509.14966)
*Xingwu Zhang,Guanxuan Li,Zhuocheng Zhang,Zijun Long*

Main category: cs.CV

TL;DR: RoboEye是一个两阶段识别框架，通过动态结合2D语义特征和领域适应的3D推理来解决电商仓库自动化包装中的物体识别难题，在仅使用RGB图像的情况下将Recall@1提升了7.1%。


<details>
  <summary>Details</summary>
Motivation: 电商产品类别快速增长导致仓库自动化包装中的物体识别更加困难，类内变异性增加、长尾物品和视觉相似物品增多，加上多样化包装、杂乱容器、遮挡和大视角变化等因素，使得仅依赖2D外观特征的方法性能急剧下降。

Method: 两阶段识别框架：第一阶段训练大型视觉模型提取2D特征生成候选排名；第二阶段通过轻量级3D特征感知模块评估3D特征质量并预测是否需要3D重排序，使用机器人3D检索变换器（包含3D特征提取器和基于关键点的匹配器）计算关键点对应置信度。

Result: 实验显示RoboEye比之前最先进的方法（RoboLLM）在Recall@1上提升了7.1%，且仅使用RGB图像，避免了显式3D输入的依赖，降低了部署成本。

Conclusion: RoboEye通过动态结合2D和3D推理，有效解决了大规模电商环境下的物体识别挑战，在性能和部署成本方面都有显著改进。

Abstract: The rapidly growing number of product categories in large-scale e-commerce
makes accurate object identification for automated packing in warehouses
substantially more difficult. As the catalog grows, intra-class variability and
a long tail of rare or visually similar items increase, and when combined with
diverse packaging, cluttered containers, frequent occlusion, and large
viewpoint changes-these factors amplify discrepancies between query and
reference images, causing sharp performance drops for methods that rely solely
on 2D appearance features. Thus, we propose RoboEye, a two-stage identification
framework that dynamically augments 2D semantic features with domain-adapted 3D
reasoning and lightweight adapters to bridge training deployment gaps. In the
first stage, we train a large vision model to extract 2D features for
generating candidate rankings. A lightweight 3D-feature-awareness module then
estimates 3D feature quality and predicts whether 3D re-ranking is necessary,
preventing performance degradation and avoiding unnecessary computation. When
invoked, the second stage uses our robot 3D retrieval transformer, comprising a
3D feature extractor that produces geometry-aware dense features and a
keypoint-based matcher that computes keypoint-correspondence confidences
between query and reference images instead of conventional cosine-similarity
scoring. Experiments show that RoboEye improves Recall@1 by 7.1% over the prior
state of the art (RoboLLM). Moreover, RoboEye operates using only RGB images,
avoiding reliance on explicit 3D inputs and reducing deployment costs. The code
used in this paper is publicly available at:
https://github.com/longkukuhi/RoboEye.

</details>


### [3] [UCorr: Wire Detection and Depth Estimation for Autonomous Drones](https://arxiv.org/abs/2509.14989)
*Benedikt Kolbeinsson,Krystian Mikolajczyk*

Main category: cs.CV

TL;DR: 提出了一种用于电线分割和深度估计的单目端到端模型，通过时间相关层和合成数据训练，在电线检测和深度估计联合任务上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 在无人机自主导航中，电线等细长障碍物的准确检测对于安全导航和防碰撞至关重要，但由于电线轮廓细长，检测具有独特且复杂的问题

Method: 采用单目端到端模型，利用时间相关层在合成数据上进行训练，能够有效处理电线检测和深度估计的复杂联合任务

Result: 在电线检测和深度估计联合任务上证明了所提方法优于现有竞争方法

Conclusion: 该模型有潜力提高自主无人机的安全性和精确性，在现实场景中具有广阔的应用前景

Abstract: In the realm of fully autonomous drones, the accurate detection of obstacles
is paramount to ensure safe navigation and prevent collisions. Among these
challenges, the detection of wires stands out due to their slender profile,
which poses a unique and intricate problem. To address this issue, we present
an innovative solution in the form of a monocular end-to-end model for wire
segmentation and depth estimation. Our approach leverages a temporal
correlation layer trained on synthetic data, providing the model with the
ability to effectively tackle the complex joint task of wire detection and
depth estimation. We demonstrate the superiority of our proposed method over
existing competitive approaches in the joint task of wire detection and depth
estimation. Our results underscore the potential of our model to enhance the
safety and precision of autonomous drones, shedding light on its promising
applications in real-world scenarios.

</details>


### [4] [OmniSegmentor: A Flexible Multi-Modal Learning Framework for Semantic Segmentation](https://arxiv.org/abs/2509.15096)
*Bo-Wen Yin,Jiao-Long Cao,Xuying Zhang,Yuming Chen,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: 提出了OmniSegmentor多模态学习框架，包含ImageNeXt大规模多模态预训练数据集和高效预训练方法，在多个多模态语义分割数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有研究证明多模态线索对鲁棒语义分割有益，但缺乏灵活的多视觉模态预训练-微调流程

Method: 1) 基于ImageNet构建包含5种流行视觉模态的大规模数据集ImageNeXt；2) 提出高效预训练方法使模型能够编码不同模态信息

Result: 在NYU Depthv2、EventScape、MFNet、DeLiVER、SUNRGBD和KITTI-360等多个多模态语义分割数据集上创造了新的最先进记录

Conclusion: 首次提出了通用的多模态预训练框架，无论涉及模态的任意组合，都能持续增强模型在各种场景下的感知能力

Abstract: Recent research on representation learning has proved the merits of
multi-modal clues for robust semantic segmentation. Nevertheless, a flexible
pretrain-and-finetune pipeline for multiple visual modalities remains
unexplored. In this paper, we propose a novel multi-modal learning framework,
termed OmniSegmentor. It has two key innovations: 1) Based on ImageNet, we
assemble a large-scale dataset for multi-modal pretraining, called ImageNeXt,
which contains five popular visual modalities. 2) We provide an efficient
pretraining manner to endow the model with the capacity to encode different
modality information in the ImageNeXt. For the first time, we introduce a
universal multi-modal pretraining framework that consistently amplifies the
model's perceptual capabilities across various scenarios, regardless of the
arbitrary combination of the involved modalities. Remarkably, our OmniSegmentor
achieves new state-of-the-art records on a wide range of multi-modal semantic
segmentation datasets, including NYU Depthv2, EventScape, MFNet, DeLiVER,
SUNRGBD, and KITTI-360.

</details>


### [5] [Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation](https://arxiv.org/abs/2509.15224)
*Luca Bartolomei,Enrico Mannocci,Fabio Tosi,Matteo Poggi,Stefano Mattoccia*

Main category: cs.CV

TL;DR: 通过跨模态萌荐技术，利用视觉基础模型为事件相机生成密集深度代理标签，解决了缺乏大规模深度注释数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机在高速运动和光照变化环境中优势显著，但缺乏密集深度注释数据阻碍了学习基于单目深度估计的发展。

Method: 提出跨模态萌荐范式，利用视觉基础模型生成密集代理标签，并适配Depth Anything v2模型或提出新的循环结构来从单目事件相机推断深度。

Result: 在合成和真实数据集上评估，跨模态萌荐方法达到了与全监督方法相竞争的性能，且无需昂贵深度注释；基于VFM的模型实现了状态质艺的性能。

Conclusion: 该方法有效解决了事件相机深度估计中的标签缺乏问题，通过利用视觉基础模型的稳健性实现了高性能的无监督深度估计。

Abstract: Event cameras capture sparse, high-temporal-resolution visual information,
making them particularly suitable for challenging environments with high-speed
motion and strongly varying lighting conditions. However, the lack of large
datasets with dense ground-truth depth annotations hinders learning-based
monocular depth estimation from event data. To address this limitation, we
propose a cross-modal distillation paradigm to generate dense proxy labels
leveraging a Vision Foundation Model (VFM). Our strategy requires an event
stream spatially aligned with RGB frames, a simple setup even available
off-the-shelf, and exploits the robustness of large-scale VFMs. Additionally,
we propose to adapt VFMs, either a vanilla one like Depth Anything v2 (DAv2),
or deriving from it a novel recurrent architecture to infer depth from
monocular event cameras. We evaluate our approach with synthetic and real-world
datasets, demonstrating that i) our cross-modal paradigm achieves competitive
performance compared to fully supervised methods without requiring expensive
depth annotations, and ii) our VFM-based models achieve state-of-the-art
performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [FlowCast-ODE: Continuous Hourly Weather Forecasting with Dynamic Flow Matching and ODE Integration](https://arxiv.org/abs/2509.14775)
*Shuangshuang He,Yuanting Zhang,Hongli Liang,Qingye Meng,Xingyuan Yuan*

Main category: cs.LG

TL;DR: FlowCast-ODE是一个基于常微分方程的连续流建模框架，用于小时级天气预报，通过粗到细的训练策略和轻量级调制机制，解决了自回归误差累积和数据同化周期不连续性问题。


<details>
  <summary>Details</summary>
Motivation: 准确的逐小时天气预报对许多应用至关重要。现有深度学习模型在6小时间隔上表现良好，但由于自回归推演中的误差快速累积和ERA5数据12小时同化周期的时间不连续性，实现准确稳定的小时级预测仍是一个关键挑战。

Method: 提出FlowCast-ODE框架，将大气状态演化建模为连续流。采用粗到细策略：先在6小时数据上用动态流匹配训练，然后在小时级数据上用ODE求解器进行精炼以获得时间一致的预测。还提出轻量级低秩AdaLN-Zero调制机制，将模型大小减少15%而不损失精度。

Result: 实验表明FlowCast-ODE优于强基线，具有更低的均方根误差和更好的能量守恒，减少了模糊并保留了更多精细空间细节。在台风等极端事件预测上与最先进模型性能相当，同时缓解了同化周期转换相关的时间不连续性。

Conclusion: FlowCast-ODE通过连续流建模和ODE求解器有效解决了小时级天气预报中的误差累积和时间不连续性问题，在保持模型轻量化的同时实现了优异的预测性能。

Abstract: Accurate hourly weather forecasting is critical for numerous applications.
Recent deep learning models have demonstrated strong capability on 6-hour
intervals, yet achieving accurate and stable hourly predictions remains a
critical challenge. This is primarily due to the rapid accumulation of errors
in autoregressive rollouts and temporal discontinuities within the ERA5 data's
12-hour assimilation cycle. To address these issues, we propose FlowCast-ODE, a
framework that models atmospheric state evolution as a continuous flow.
FlowCast-ODE learns the conditional flow path directly from the previous state,
an approach that aligns more naturally with physical dynamic systems and
enables efficient computation. A coarse-to-fine strategy is introduced to train
the model on 6-hour data using dynamic flow matching and then refined on hourly
data that incorporates an Ordinary Differential Equation (ODE) solver to
achieve temporally coherent forecasts. In addition, a lightweight low-rank
AdaLN-Zero modulation mechanism is proposed and reduces model size by 15%
without compromising accuracy. Experiments demonstrate that FlowCast-ODE
outperforms strong baselines, yielding lower root mean square error (RMSE) and
better energy conservation, which reduces blurring and preserves more
fine-scale spatial details. It also shows comparable performance to the
state-of-the-art model in forecasting extreme events like typhoons.
Furthermore, the model alleviates temporal discontinuities associated with
assimilation cycle transitions.

</details>


### [7] [Pre-training under infinite compute](https://arxiv.org/abs/2509.14786)
*Konwoo Kim,Suhas Kotha,Percy Liang,Tatsunori Hashimoto*

Main category: cs.LG

TL;DR: 在计算资源丰富但训练数据固定的情况下，通过调整正则化、参数缩放、集成学习等简单算法改进，可以实现显著的数据效率提升，在200M标记数据上节省5.17倍数据。


<details>
  <summary>Details</summary>
Motivation: 计算资源的增长速度远超语言模型预训练所需的网络文本数量，需要研究在固定数据量下如何最大化预训练效果。

Method: 首先识别现有数据约束方法的限制，通过调整正则化参数（权重衰减调整到30倍），使用缩放律估计最佳性能，并采用独立训练模型集成技术。最佳方案结合了多次迭代、正则化、参数缩放和集成缩放。

Result: 在200M标记数据上节省5.17倍数据，通过模型精简技术可将集成模型压缩至8倍小的学生模型，保留83%的集成效果。在下游任务上实现了9%的预训练评估提升和17.5倍的数据效率提升。

Conclusion: 简单的算法改进可以在计算资源丰富的未来实现显著的数据效率提升，为语言模型预训练提供了更有效的方案。

Abstract: Since compute grows much faster than web text available for language model
pre-training, we ask how one should approach pre-training under fixed data and
no compute constraints. We first show that existing data-constrained approaches
of increasing epoch count and parameter count eventually overfit, and we
significantly improve upon such recipes by properly tuning regularization,
finding that the optimal weight decay is $30\times$ larger than standard
practice. Since our regularized recipe monotonically decreases loss following a
simple power law in parameter count, we estimate its best possible performance
via the asymptote of its scaling law rather than the performance at a fixed
compute budget. We then identify that ensembling independently trained models
achieves a significantly lower loss asymptote than the regularized recipe. Our
best intervention combining epoching, regularization, parameter scaling, and
ensemble scaling achieves an asymptote at 200M tokens using $5.17\times$ less
data than our baseline, and our data scaling laws predict that this improvement
persists at higher token budgets. We find that our data efficiency gains can be
realized at much smaller parameter counts as we can distill an ensemble into a
student model that is 8$\times$ smaller and retains $83\%$ of the ensembling
benefit. Finally, our interventions designed for validation loss generalize to
downstream benchmarks, achieving a $9\%$ improvement for pre-training evals and
a $17.5\times$ data efficiency improvement over continued pre-training on math
mid-training data. Our results show that simple algorithmic improvements can
enable significantly more data-efficient pre-training in a compute-rich future.

</details>


### [8] [Exploring the Global-to-Local Attention Scheme in Graph Transformers: An Empirical Study](https://arxiv.org/abs/2509.14863)
*Zhengwei Wang,Gang Wu*

Main category: cs.LG

TL;DR: G2LFormer是一个新颖的图Transformer，采用全局到局部的注意力机制，浅层捕获全局信息，深层学习局部结构信息，通过跨层信息融合策略防止信息丢失，同时保持线性复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统图Transformer将GNN与全局注意力机制并行或顺序集成时，全局注意力机制可能会稀释GNN学习的局部邻域信息，导致信息丢失。

Method: 提出全局到局部注意力方案：浅层使用注意力机制捕获全局信息，深层使用GNN模块学习局部结构信息；引入跨层信息融合策略，让局部层保留全局层的有利信息。

Result: 在节点级和图级任务上与最先进的线性图Transformer和GNN相比，G2LFormer表现出优异性能，同时保持线性复杂度。

Conclusion: 全局到局部注意力方案是可行的，G2LFormer能够有效防止节点忽略其直接邻居，在性能和可扩展性之间取得良好平衡。

Abstract: Graph Transformers (GTs) show considerable potential in graph representation
learning. The architecture of GTs typically integrates Graph Neural Networks
(GNNs) with global attention mechanisms either in parallel or as a precursor to
attention mechanisms, yielding a local-and-global or local-to-global attention
scheme. However, as the global attention mechanism primarily captures
long-range dependencies between nodes, these integration schemes may suffer
from information loss, where the local neighborhood information learned by GNN
could be diluted by the attention mechanism. Therefore, we propose G2LFormer,
featuring a novel global-to-local attention scheme where the shallow network
layers use attention mechanisms to capture global information, while the deeper
layers employ GNN modules to learn local structural information, thereby
preventing nodes from ignoring their immediate neighbors. An effective
cross-layer information fusion strategy is introduced to allow local layers to
retain beneficial information from global layers and alleviate information
loss, with acceptable trade-offs in scalability. To validate the feasibility of
the global-to-local attention scheme, we compare G2LFormer with
state-of-the-art linear GTs and GNNs on node-level and graph-level tasks. The
results indicate that G2LFormer exhibits excellent performance while keeping
linear complexity.

</details>


### [9] [A Comparative Analysis of Transformer Models in Social Bot Detection](https://arxiv.org/abs/2509.14936)
*Rohan Veit,Michael Lones*

Main category: cs.LG

TL;DR: 比较基于编码器和解码器变换器的机器人检测模型效果，发现编码器模型准确性和鲁棒性更好，但解码器模型通过任务对齐展现更强的适应性和泛化潜力


<details>
  <summary>Details</summary>
Motivation: 社交媒体中AI生成内容（如大型语言模型）加剧了虚假信息传播问题，需要有效检测人工用户（机器人）来保护在线讨论的完整性

Method: 开发评估管道，比较基于编码器和解码器变换器的分类器性能，分析其准确性和适应性

Result: 编码器分类器表现出更高的准确性和鲁棒性，而解码器模型通过任务特定对齐显示出更强的适应性和跨用例泛化潜力

Conclusion: 研究为预防数字环境操纵提供了重要见解，两种架构各有优势，编码器更适合准确性要求高的场景，解码器在适应性方面更有潜力

Abstract: Social media has become a key medium of communication in today's society.
This realisation has led to many parties employing artificial users (or bots)
to mislead others into believing untruths or acting in a beneficial manner to
such parties. Sophisticated text generation tools, such as large language
models, have further exacerbated this issue. This paper aims to compare the
effectiveness of bot detection models based on encoder and decoder
transformers. Pipelines are developed to evaluate the performance of these
classifiers, revealing that encoder-based classifiers demonstrate greater
accuracy and robustness. However, decoder-based models showed greater
adaptability through task-specific alignment, suggesting more potential for
generalisation across different use cases in addition to superior observa.
These findings contribute to the ongoing effort to prevent digital environments
being manipulated while protecting the integrity of online discussion.

</details>


### [10] [Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers](https://arxiv.org/abs/2509.15113)
*Andrei Chertkov,Artem Basharin,Mikhail Saygin,Evgeny Frolov,Stanislav Straupe,Ivan Oseledets*

Main category: cs.LG

TL;DR: 一种给合成数字神经网络与非可微物理层的混合网络提供端到端训练的框架，通过随机零阶优化和动态低秩代理模型解决物理层非可微的挑战


<details>
  <summary>Details</summary>
Motivation: 应对能源效率和高性能AI系统的需求，整合光子学等物理设备到深度学习流水线中遇到挑战，包括物理设备表达能限和非可微性质导致无法在设备上进行反向传播

Method: 给合随机零阶优化更新物理层参数，使用动态低秩代理模型实现梯度传播，采用隐式投影仪分解积分算法轻量更新代理模型，避免高成本的全矩阵重构

Result: 在计算机视觉、音频分类和语言建模等多种任务中，方法达到了接近数字基线的准确性，成功训练包含各种非可微物理组件的混合模型

Conclusion: 该工作桥接了硬件知觉深度学习和无梯度优化，为将非可微物理组件集成到可扩展的端到端可训练AI系给供了实用路径

Abstract: The growing demand for energy-efficient, high-performance AI systems has led
to increased attention on alternative computing platforms (e.g., photonic,
neuromorphic) due to their potential to accelerate learning and inference.
However, integrating such physical components into deep learning pipelines
remains challenging, as physical devices often offer limited expressiveness,
and their non-differentiable nature renders on-device backpropagation difficult
or infeasible. This motivates the development of hybrid architectures that
combine digital neural networks with reconfigurable physical layers, which
effectively behave as black boxes. In this work, we present a framework for the
end-to-end training of such hybrid networks. This framework integrates
stochastic zeroth-order optimization for updating the physical layer's internal
parameters with a dynamic low-rank surrogate model that enables gradient
propagation through the physical layer. A key component of our approach is the
implicit projector-splitting integrator algorithm, which updates the
lightweight surrogate model after each forward pass with minimal hardware
queries, thereby avoiding costly full matrix reconstruction. We demonstrate our
method across diverse deep learning tasks, including: computer vision, audio
classification, and language modeling. Notably, across all modalities, the
proposed approach achieves near-digital baseline accuracy and consistently
enables effective end-to-end training of hybrid models incorporating various
non-differentiable physical components (spatial light modulators, microring
resonators, and Mach-Zehnder interferometers). This work bridges hardware-aware
deep learning and gradient-free optimization, thereby offering a practical
pathway for integrating non-differentiable physical components into scalable,
end-to-end trainable AI systems.

</details>


### [11] [Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation](https://arxiv.org/abs/2509.15194)
*Yujun Zhou,Zhenwen Liang,Haolin Liu,Wenhao Yu,Kishan Panaganti,Linfeng Song,Dian Yu,Xiangliang Zhang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: EVOL-RL是一种无标签强化学习方法，通过结合多数投票稳定性和新颖性奖励来防止熵崩溃，保持模型探索能力和泛化能力，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有无标签方法（如置信度最小化、自一致性或多数投票目标）虽然稳定学习但会逐渐缩小探索范围，导致熵崩溃：生成内容变短、多样性减少且脆弱。需要一种既能实现通用改进又不牺牲模型固有探索能力和泛化能力的方法。

Method: 提出EVOL-RL方法，将多数投票答案作为稳定锚点（选择），同时添加新颖性奖励来偏好与已产生内容在语义空间上不同的响应（变异）。使用GRPO实现，采用非对称裁剪保留强信号和熵正则化器维持搜索。

Result: EVOL-RL在无标签AIME24训练中将Qwen3-4B-Base的AIME25 pass@1从TTRL的4.6%提升到16.4%，pass@16从18.5%提升到37.9%。不仅防止多样性崩溃，还在跨领域（如GPQA）展现更强泛化能力，在RLVR设置中也提升性能。

Conclusion: EVOL-RL通过选择+变异的简单设计有效防止熵崩溃，保持更长的思维链，提升模型性能，具有广泛适用性，为无标签强化学习提供了有效的解决方案。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning from verifiable rewards (RLVR), yet real-world deployment demands
models that can self-improve without labels or external judges. Existing
label-free methods, confidence minimization, self-consistency, or majority-vote
objectives, stabilize learning but steadily shrink exploration, causing an
entropy collapse: generations become shorter, less diverse, and brittle. Unlike
prior approaches such as Test-Time Reinforcement Learning (TTRL), which
primarily adapt models to the immediate unlabeled dataset at hand, our goal is
broader: to enable general improvements without sacrificing the model's
inherent exploration capacity and generalization ability, i.e., evolving. We
formalize this issue and propose EVolution-Oriented and Label-free
Reinforcement Learning (EVOL-RL), a simple rule that couples stability with
variation under a label-free setting. EVOL-RL keeps the majority-voted answer
as a stable anchor (selection) while adding a novelty-aware reward that favors
responses whose reasoning differs from what has already been produced
(variation), measured in semantic space. Implemented with GRPO, EVOL-RL also
uses asymmetric clipping to preserve strong signals and an entropy regularizer
to sustain search. This majority-for-selection + novelty-for-variation design
prevents collapse, maintains longer and more informative chains of thought, and
improves both pass@1 and pass@n. EVOL-RL consistently outperforms the
majority-only TTRL baseline; e.g., training on label-free AIME24 lifts
Qwen3-4B-Base AIME25 pass@1 from TTRL's 4.6% to 16.4%, and pass@16 from 18.5%
to 37.9%. EVOL-RL not only prevents diversity collapse but also unlocks
stronger generalization across domains (e.g., GPQA). Furthermore, we
demonstrate that EVOL-RL also boosts performance in the RLVR setting,
highlighting its broad applicability.

</details>


### [12] [CausalPre: Scalable and Effective Data Pre-processing for Causal Fairness](https://arxiv.org/abs/2509.15199)
*Ying Zheng,Yangfan Jiang,Kian-Lee Tan*

Main category: cs.LG

TL;DR: CausalPre是一个无需强因果模型假设的可扩展因果公平数据预处理框架，通过分布估计和低维边际分解实现高效的因果公平关系提取


<details>
  <summary>Details</summary>
Motivation: 现有因果公平方法通常需要已知因果模型或依赖强假设，且往往无法捕捉关键属性关系来保持数据效用，需要探索不依赖强因果模型假设的有效公平解决方案

Method: 将复杂的因果公平关系提取任务转化为定制化的分布估计问题，采用精心设计的低维边际分解变体来近似联合分布，并配合启发式算法解决计算挑战

Result: 在基准数据集上的广泛实验表明，CausalPre既有效又可扩展，能够保证合理的公平性（一种强因果公平概念）

Conclusion: CausalPre挑战了传统观念，证明实现因果公平无需在关系覆盖范围和放松模型假设之间进行权衡

Abstract: Causal fairness in databases is crucial to preventing biased and inaccurate
outcomes in downstream tasks. While most prior work assumes a known causal
model, recent efforts relax this assumption by enforcing additional
constraints. However, these approaches often fail to capture broader attribute
relationships that are critical to maintaining utility. This raises a
fundamental question: Can we harness the benefits of causal reasoning to design
efficient and effective fairness solutions without relying on strong
assumptions about the underlying causal model? In this paper, we seek to answer
this question by introducing CausalPre, a scalable and effective
causality-guided data pre-processing framework that guarantees justifiable
fairness, a strong causal notion of fairness. CausalPre extracts causally fair
relationships by reformulating the originally complex and computationally
infeasible extraction task into a tailored distribution estimation problem. To
ensure scalability, CausalPre adopts a carefully crafted variant of
low-dimensional marginal factorization to approximate the joint distribution,
complemented by a heuristic algorithm that efficiently tackles the associated
computational challenge. Extensive experiments on benchmark datasets
demonstrate that CausalPre is both effective and scalable, challenging the
conventional belief that achieving causal fairness requires trading off
relationship coverage for relaxed model assumptions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition and Patient Outcomes in an Irish Hospital with Transformers](https://arxiv.org/abs/2509.14942)
*Minh-Khoi Pham,Tai Tan Mai,Martin Crane,Rob Brennan,Marie E. Ward,Una Geary,Declan Byrne,Brian O Connell,Colm Bergin,Donncha Creagh,Nick McDonald,Marija Bezbradica*

Main category: cs.AI

TL;DR: 这篇论文提出了一种可解释的AI框架，使用Transformer模型预测肠权菌科生产卡巴赖纳米酶相关的患者转归、死亡率和住院时长等临床结果，TabTransformer模型表现最优。


<details>
  <summary>Details</summary>
Motivation: 肠权菌科生产卡巴赖纳米酶(CPE)对医院感染控制构成严重威胁，但现有风险预测模型对于读入院、死亡率等结果的预测仍然不足，特别是缺乏现代深度学习方法的应用。

Method: 研究构建了一个可解释的AI模型框架，分析爱尔兰医院的电子病历数据，包括诊断代码、病房转移、患者人口统计学、感染相关变量和接触网络特征。对比了Transformer基础架构与传统机器学习模型的性能。

Result: TabTransformer模型在多个临床预测任务中持续超过基线模型，特别是在CPE获得预测中(AUROC和敏感度)。感染相关特征、历史医院暴露、入院情况和网络中心性指标对患者结果和CPE风险预测有重要影响。

Conclusion: 该研究提供了一个健壮且可解释的AI框架，用于分析复杂的电子病历数据以识别关键风险因素和预测CPE相关结果。Transformer模型表现优异，临床和网络特征对风险预测至关重要。

Abstract: Carbapenemase-Producing Enterobacteriace poses a critical concern for
infection prevention and control in hospitals. However, predictive modeling of
previously highlighted CPE-associated risks such as readmission, mortality, and
extended length of stay (LOS) remains underexplored, particularly with modern
deep learning approaches. This study introduces an eXplainable AI modeling
framework to investigate CPE impact on patient outcomes from Electronic Medical
Records data of an Irish hospital. We analyzed an inpatient dataset from an
Irish acute hospital, incorporating diagnostic codes, ward transitions, patient
demographics, infection-related variables and contact network features. Several
Transformer-based architectures were benchmarked alongside traditional machine
learning models. Clinical outcomes were predicted, and XAI techniques were
applied to interpret model decisions. Our framework successfully demonstrated
the utility of Transformer-based models, with TabTransformer consistently
outperforming baselines across multiple clinical prediction tasks, especially
for CPE acquisition (AUROC and sensitivity). We found infection-related
features, including historical hospital exposure, admission context, and
network centrality measures, to be highly influential in predicting patient
outcomes and CPE acquisition risk. Explainability analyses revealed that
features like "Area of Residence", "Admission Ward" and prior admissions are
key risk factors. Network variables like "Ward PageRank" also ranked highly,
reflecting the potential value of structural exposure information. This study
presents a robust and explainable AI framework for analyzing complex EMR data
to identify key risk factors and predict CPE-related outcomes. Our findings
underscore the superior performance of the Transformer models and highlight the
importance of diverse clinical and network features.

</details>


### [14] [Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention](https://arxiv.org/abs/2506.11445)
*Xuan Duy Ta,Bang Giang Le,Thanh Ha Le,Viet Cuong Ta*

Main category: cs.AI

TL;DR: 提出基于局部状态注意力模块的MARL方法，用于解决混合交通环境中自动驾驶车辆的冲突协调问题，在高速公路汇入场景中显著提升效率


<details>
  <summary>Details</summary>
Motivation: 混合交通环境中自动驾驶车辆需要适应人类驾驶车辆和异常情况，现有MARL方法难以解决智能体间局部冲突和泛化到随机事件

Method: 使用局部状态注意力模块，通过自注意力算子压缩附近车辆的关键信息来解决交通冲突，在高速公路汇入场景中优先处理其他车辆信息

Result: 在高速公路汇入场景中相比主流基线方法显著提升了汇入效率，特别是在高密度交通环境下表现优异

Conclusion: 局部状态注意力模块能有效帮助自动驾驶车辆在混合交通环境中协调冲突，提高整体交通效率

Abstract: In mixed-traffic environments, autonomous vehicles must adapt to
human-controlled vehicles and other unusual driving situations. This setting
can be framed as a multi-agent reinforcement learning (MARL) environment with
full cooperative reward among the autonomous vehicles. While methods such as
Multi-agent Proximal Policy Optimization can be effective in training MARL
tasks, they often fail to resolve local conflict between agents and are unable
to generalize to stochastic events. In this paper, we propose a Local State
Attention module to assist the input state representation. By relying on the
self-attention operator, the module is expected to compress the essential
information of nearby agents to resolve the conflict in traffic situations.
Utilizing a simulated highway merging scenario with the priority vehicle as the
unexpected event, our approach is able to prioritize other vehicles'
information to manage the merging process. The results demonstrate significant
improvements in merging efficiency compared to popular baselines, especially in
high-density traffic settings.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [Defining, Understanding, and Detecting Online Toxicity: Challenges and Machine Learning Approaches](https://arxiv.org/abs/2509.14264)
*Gautam Kishore Shahi,Tim A. Majchrzak*

Main category: cs.CL

TL;DR: 这篇论文是一个综述性研究，系统总结140篇关于网络毒性内容检测的研究成果，包括数据集、机器学习方法和实践建议。


<details>
  <summary>Details</summary>
Motivation: 网络毒性内容在危机时期、选举和社会动荡期间日益增长，需要系统性的自动化检测方法来应对这一挑战。

Method: 研究综合了140篇相关论文，分析了包括32种语言的数据集、定义标准、数据源、挑战以及各种机器学习检测方法。

Result: 研究提供了跨平台数据使用来改善分类模型性能的可能性，并对网络毒性内容检测领域的研究进行了全面评估。

Conclusion: 研究提出了新的毒性内容研究指南和内容审核减少毒性内容的实践建议，为平台管理提供了具体的网络内容管理方案。

Abstract: Online toxic content has grown into a pervasive phenomenon, intensifying
during times of crisis, elections, and social unrest. A significant amount of
research has been focused on detecting or analyzing toxic content using
machine-learning approaches. The proliferation of toxic content across digital
platforms has spurred extensive research into automated detection mechanisms,
primarily driven by advances in machine learning and natural language
processing. Overall, the present study represents the synthesis of 140
publications on different types of toxic content on digital platforms. We
present a comprehensive overview of the datasets used in previous studies
focusing on definitions, data sources, challenges, and machine learning
approaches employed in detecting online toxicity, such as hate speech,
offensive language, and harmful discourse. The dataset encompasses content in
32 languages, covering topics such as elections, spontaneous events, and
crises. We examine the possibility of using existing cross-platform data to
improve the performance of classification models. We present the
recommendations and guidelines for new research on online toxic consent and the
use of content moderation for mitigation. Finally, we present some practical
guidelines to mitigate toxic content from online platforms.

</details>


### [16] [SparseDoctor: Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models](https://arxiv.org/abs/2509.14269)
*Zhang Jianbin,Yulin Zhu,Wai Lun Lo,Richard Tai-Chiu Hsung,Harris Sik-Ho Tsang,Kai Zhou*

Main category: cs.CL

TL;DR: 提出了SparseDoctor，一种基于对比学习增强的LoRA-MoE架构的稀疏医疗大语言模型，通过自动路由机制和专家记忆队列提高训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 传统微调策略需要更新数十亿参数，训练成本高。为提高医疗LLMs的效率和效果，探索LLMs在医疗领域的表示能力边界。

Method: 采用对比学习增强的LoRA-MoE架构，包含自动路由机制科学分配计算资源，以及专家记忆队列机制防止训练时内存溢出。

Result: 在CMB、CMExam和CMMLU-Med三个医疗基准测试中，性能持续优于HuatuoGPT系列等强基线模型。

Conclusion: SparseDoctor通过创新的稀疏架构设计，有效提升了医疗LLMs的训练效率和性能表现。

Abstract: Large language models (LLMs) have achieved great success in medical question
answering and clinical decision-making, promoting the efficiency and
popularization of the personalized virtual doctor in society. However, the
traditional fine-tuning strategies on LLM require the updates of billions of
parameters, substantially increasing the training cost, including the training
time and utility cost. To enhance the efficiency and effectiveness of the
current medical LLMs and explore the boundary of the representation capability
of the LLMs on the medical domain, apart from the traditional fine-tuning
strategies from the data perspective (i.e., supervised fine-tuning or
reinforcement learning from human feedback), we instead craft a novel sparse
medical LLM named SparseDoctor armed with contrastive learning enhanced
LoRA-MoE (low rank adaptation-mixture of experts) architecture. To this end,
the crafted automatic routing mechanism can scientifically allocate the
computational resources among different LoRA experts supervised by the
contrastive learning. Additionally, we also introduce a novel expert memory
queue mechanism to further boost the efficiency of the overall framework and
prevent the memory overflow during training. We conduct comprehensive
evaluations on three typical medical benchmarks: CMB, CMExam, and CMMLU-Med.
Experimental results demonstrate that the proposed LLM can consistently
outperform the strong baselines such as the HuatuoGPT series.

</details>


### [17] [Position: Thematic Analysis of Unstructured Clinical Transcripts with Large Language Models](https://arxiv.org/abs/2509.14597)
*Seungjun Yi,Joakim Nguyen,Terence Lim,Andrew Well,Joseph Skrovan,Mehak Beri,YongGeon Lee,Kavita Radhakrishnan,Liu Leqi,Mia Markey,Ying Ding*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型在临床文本主题分析中的应用现状，发现当前方法在分析类型、数据集、提示策略和评估标准等方面存在碎片化问题，提出了基于有效性、可靠性和可解释性的标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 临床转录本的主题分析是一种广泛使用但资源密集的方法，需要探索LLMs如何支持这一过程以提高效率和分析质量。

Method: 通过系统回顾近期将LLMs应用于主题分析的研究，并结合执业临床医生的访谈，分析当前方法的碎片化问题。

Result: 发现当前LLMs在主题分析中的应用在多个维度上存在碎片化，特别是评估方法差异很大（从定性专家评审到自动相似性指标），阻碍了进展和跨研究的有意义基准测试。

Conclusion: 建立标准化的评估实践对推动该领域发展至关重要，提出了以有效性、可靠性和可解释性为核心的评估框架。

Abstract: This position paper examines how large language models (LLMs) can support
thematic analysis of unstructured clinical transcripts, a widely used but
resource-intensive method for uncovering patterns in patient and provider
narratives. We conducted a systematic review of recent studies applying LLMs to
thematic analysis, complemented by an interview with a practicing clinician.
Our findings reveal that current approaches remain fragmented across multiple
dimensions including types of thematic analysis, datasets, prompting strategies
and models used, most notably in evaluation. Existing evaluation methods vary
widely (from qualitative expert review to automatic similarity metrics),
hindering progress and preventing meaningful benchmarking across studies. We
argue that establishing standardized evaluation practices is critical for
advancing the field. To this end, we propose an evaluation framework centered
on three dimensions: validity, reliability, and interpretability.

</details>


### [18] [MUSE: MCTS-Driven Red Teaming Framework for Enhanced Multi-Turn Dialogue Safety in Large Language Models](https://arxiv.org/abs/2509.14651)
*Siyu Yan,Long Zeng,Xuecheng Wu,Chengcheng Han,Kongcheng Zhang,Chong Peng,Xuezhi Cao,Xunliang Cai,Chenjuan Guo*

Main category: cs.CL

TL;DR: MUSE框架从攻击和防御两个角度解决多轮对话中的越狱问题，MUSE-A利用框架语义和启发式树搜索进行攻击，MUSE-D通过细粒度安全对齐进行早期防御


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，需要确保其与人类价值观对齐，防止越狱攻击。现有防御主要针对单轮攻击，但现实使用中多轮对话更易被利用绕过安全措施

Method: 提出MUSE框架：攻击方面使用MUSE-A方法，基于框架语义和启发式树搜索探索多样化语义轨迹；防御方面使用MUSE-D方法，通过细粒度安全对齐在对话早期进行干预

Result: 在各种模型上的广泛实验表明，MUSE能够有效识别和缓解多轮对话中的漏洞

Conclusion: MUSE框架为多轮越狱攻击提供了全面的解决方案，在攻击和防御两方面都表现出色，代码已开源

Abstract: As large language models~(LLMs) become widely adopted, ensuring their
alignment with human values is crucial to prevent jailbreaks where adversaries
manipulate models to produce harmful content. While most defenses target
single-turn attacks, real-world usage often involves multi-turn dialogues,
exposing models to attacks that exploit conversational context to bypass safety
measures. We introduce MUSE, a comprehensive framework tackling multi-turn
jailbreaks from both attack and defense angles. For attacks, we propose MUSE-A,
a method that uses frame semantics and heuristic tree search to explore diverse
semantic trajectories. For defense, we present MUSE-D, a fine-grained safety
alignment approach that intervenes early in dialogues to reduce
vulnerabilities. Extensive experiments on various models show that MUSE
effectively identifies and mitigates multi-turn vulnerabilities. Code is
available at
\href{https://github.com/yansiyu02/MUSE}{https://github.com/yansiyu02/MUSE}.

</details>


### [19] [SINAI at eRisk@CLEF 2023: Approaching Early Detection of Gambling with Natural Language Processing](https://arxiv.org/abs/2509.14797)
*Alba Maria Marmol-Romero,Flor Miriam Plaza-del-Arco,Arturo Montejo-Raez*

Main category: cs.CL

TL;DR: SINAI团队在eRisk@CLEF实验室任务2中，使用基于Transformer预训练模型结合LSTM的方法进行病态赌博早期检测，在49个参赛提交中排名第7，F1分数0.126，但在召回率和早期检测相关指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 参与eRisk@CLEF实验室的任务2，专注于病态赌博行为的早期检测，这是一个重要的心理健康监测问题。

Method: 采用基于Transformer架构的预训练模型，结合全面的数据预处理和数据平衡技术，并集成LSTM架构与Transformer的自动模型。

Result: 在49个参赛提交中排名第7位，F1得分为0.126，但在召回率指标和早期检测相关指标上获得了最高值。

Conclusion: 虽然整体F1分数不高，但该方法在早期检测的关键指标上表现优异，证明了集成Transformer和LSTM架构在病态赌博早期识别中的有效性。

Abstract: This paper describes the participation of the SINAI team in the eRisk@CLEF
lab. Specifically, one of the proposed tasks has been addressed: Task 2 on the
early detection of signs of pathological gambling. The approach presented in
Task 2 is based on pre-trained models from Transformers architecture with
comprehensive preprocessing data and data balancing techniques. Moreover, we
integrate Long-short Term Memory (LSTM) architecture with automodels from
Transformers. In this Task, our team has been ranked in seventh position, with
an F1 score of 0.126, out of 49 participant submissions and achieves the
highest values in recall metrics and metrics related to early detection.

</details>


### [20] [FURINA: Free from Unmergeable Router via LINear Aggregation of mixed experts](https://arxiv.org/abs/2509.14900)
*Jiayi Han,Liang Du,Yinda Chen,Xiao Kang,Weiyang Ding,Donghong Han*

Main category: cs.CL

TL;DR: FURINA是一个无需路由器的MoE-LoRA框架，通过线性聚合专家实现动态路由，可完全合并到主干模型中，无额外推理成本


<details>
  <summary>Details</summary>
Motivation: 现有MoE-LoRA方法依赖离散路由器，无法将MoE组件集成到主干模型中，限制了实际应用

Method: 提出自路由机制：1）解耦LoRA适配器的方向和幅度学习 2）共享可学习幅度向量 3）专家选择损失促进专家激活分化 4）引入共享专家提供稳定基础知识

Result: FURINA显著优于标准LoRA，性能匹配或超越现有MoE-LoRA方法，同时消除了MoE的额外推理开销

Conclusion: FURINA是首个无需路由器、可完全合并到主干模型的MoE增强LoRA方法，实现了零额外推理成本的高效微调

Abstract: The Mixture of Experts (MoE) paradigm has been successfully integrated into
Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning (PEFT),
delivering performance gains with minimal parameter overhead. However, a key
limitation of existing MoE-LoRA methods is their reliance on a discrete router,
which prevents the integration of the MoE components into the backbone model.
To overcome this, we propose FURINA, a novel Free from Unmergeable Router
framework based on the LINear Aggregation of experts. FURINA eliminates the
router by introducing a Self-Routing mechanism. This is achieved through three
core innovations: (1) decoupled learning of the direction and magnitude for
LoRA adapters, (2) a shared learnable magnitude vector for consistent
activation scaling, and (3) expert selection loss that encourages divergent
expert activation. The proposed mechanism leverages the angular similarity
between the input and each adapter's directional component to activate experts,
which are then scaled by the shared magnitude vector. This design allows the
output norm to naturally reflect the importance of each expert, thereby
enabling dynamic, router-free routing. The expert selection loss further
sharpens this behavior by encouraging sparsity and aligning it with standard
MoE activation patterns. We also introduce a shared expert within the MoE-LoRA
block that provides stable, foundational knowledge. To the best of our
knowledge, FURINA is the first router-free, MoE-enhanced LoRA method that can
be fully merged into the backbone model, introducing zero additional
inference-time cost or complexity. Extensive experiments demonstrate that
FURINA not only significantly outperforms standard LoRA but also matches or
surpasses the performance of existing MoE-LoRA methods, while eliminating the
extra inference-time overhead of MoE.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [21] [Event-LAB: Towards Standardized Evaluation of Neuromorphic Localization Methods](https://arxiv.org/abs/2509.14516)
*Adam D. Hines,Alejandro Fontan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Event-LAB是一个统一框架，用于在多个数据集上运行事件相机定位方法，解决了该领域代码依赖和数据格式多样化带来的比较困难问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机定位研究快速发展，但代码依赖和数据格式的多样性使得方法比较和实施变得困难，需要一个统一的框架来简化研究流程。

Method: 使用Pixi包和依赖管理器实现Event-LAB框架，支持单命令行安装和调用，实现了视觉位置识别(VPR)和同步定位与建图(SLAM)两种常见定位流程。

Result: 框架能够系统性地可视化和分析多种方法和数据集的结果，揭示了事件收集计数和帧生成窗口大小等参数对性能的重要影响。

Conclusion: Event-LAB为研究社区提供了公平比较方法的能力，通过一致的参数设置简化了多条件实验设置流程，强调了参数一致性对公平比较的重要性。

Abstract: Event-based localization research and datasets are a rapidly growing area of
interest, with a tenfold increase in the cumulative total number of published
papers on this topic over the past 10 years. Whilst the rapid expansion in the
field is exciting, it brings with it an associated challenge: a growth in the
variety of required code and package dependencies as well as data formats,
making comparisons difficult and cumbersome for researchers to implement
reliably. To address this challenge, we present Event-LAB: a new and unified
framework for running several event-based localization methodologies across
multiple datasets. Event-LAB is implemented using the Pixi package and
dependency manager, that enables a single command-line installation and
invocation for combinations of localization methods and datasets. To
demonstrate the capabilities of the framework, we implement two common
event-based localization pipelines: Visual Place Recognition (VPR) and
Simultaneous Localization and Mapping (SLAM). We demonstrate the ability of the
framework to systematically visualize and analyze the results of multiple
methods and datasets, revealing key insights such as the association of
parameters that control event collection counts and window sizes for frame
generation to large variations in performance. The results and analysis
demonstrate the importance of fairly comparing methodologies with consistent
event image generation parameters. Our Event-LAB framework provides this
ability for the research community, by contributing a streamlined workflow for
easily setting up multiple conditions.

</details>


### [22] [Dual-Arm Hierarchical Planning for Laboratory Automation: Vibratory Sieve Shaker Operations](https://arxiv.org/abs/2509.14531)
*Haoran Xiao,Xue Wang,Huimin Lu,Zhiwen Zeng,Zirui Guo,Ziqi Ni,Yicong Ye,Wei Dai*

Main category: cs.RO

TL;DR: 本文提出了一个分层规划框架，结合先验引导路径规划和多步轨迹优化，解决了振动筛分机自动化操作中的三个关键任务：狭窄空间双机械臂操作、双手交接和受限条件下的粉末容器输送。


<details>
  <summary>Details</summary>
Motivation: 自动化振动筛分机操作面临三大挑战：狭窄通道中的低效采样、需要平滑轨迹防止洒落，以及传统方法生成的次优路径。这些挑战限制了实验室自动化的效率和可靠性。

Method: 采用分层规划框架：1) 先验引导路径规划使用有限高斯混合模型提高狭窄通道采样效率；2) 多步轨迹优化通过路径缩短、简化、关节约束施加和B样条平滑来精炼路径。

Result: 实验结果显示规划时间减少80.4%，路径点减少89.4%。系统在物理实验中成功完成了完整的振动筛分机操作流程，验证了其实用性。

Conclusion: 该分层规划框架有效解决了复杂实验室自动化中的操作挑战，显著提高了规划效率和路径质量，具有实际应用价值。

Abstract: This paper addresses the challenges of automating vibratory sieve shaker
operations in a materials laboratory, focusing on three critical tasks: 1)
dual-arm lid manipulation in 3 cm clearance spaces, 2) bimanual handover in
overlapping workspaces, and 3) obstructed powder sample container delivery with
orientation constraints. These tasks present significant challenges, including
inefficient sampling in narrow passages, the need for smooth trajectories to
prevent spillage, and suboptimal paths generated by conventional methods. To
overcome these challenges, we propose a hierarchical planning framework
combining Prior-Guided Path Planning and Multi-Step Trajectory Optimization.
The former uses a finite Gaussian mixture model to improve sampling efficiency
in narrow passages, while the latter refines paths by shortening, simplifying,
imposing joint constraints, and B-spline smoothing. Experimental results
demonstrate the framework's effectiveness: planning time is reduced by up to
80.4%, and waypoints are decreased by 89.4%. Furthermore, the system completes
the full vibratory sieve shaker operation workflow in a physical experiment,
validating its practical applicability for complex laboratory automation.

</details>


### [23] [Exploratory Movement Strategies for Texture Discrimination with a Neuromorphic Tactile Sensor](https://arxiv.org/abs/2509.14954)
*Xingchen Xu,Ao Li,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 提出受人类探索策略启发的神经形态触觉感知框架，通过NeuroTac传感器在多种探索动作中采集数据，发现滑动+旋转组合动作在复杂条件下达到87.33%的最高分类精度，且功耗仅8.04mW


<details>
  <summary>Details</summary>
Motivation: 受人类触觉探索策略启发，开发适用于机器人纹理分类的神经形态触觉感知系统，以提升机器人与环境的交互能力

Method: 使用NeuroTac传感器采集神经形态触觉数据，测试六种探索动作（滑动、旋转、敲击及其组合），在固定环境和变化条件下评估性能

Result: 滑动+旋转组合动作在变化接触深度和速度条件下达到87.33%的最高分类精度，功耗仅为8.04mW，表现最优

Conclusion: 滑动+旋转是神经形态触觉感知在纹理分类任务中的最佳探索策略，具有显著的应用潜力

Abstract: We propose a neuromorphic tactile sensing framework for robotic texture
classification that is inspired by human exploratory strategies. Our system
utilizes the NeuroTac sensor to capture neuromorphic tactile data during a
series of exploratory motions. We first tested six distinct motions for texture
classification under fixed environment: sliding, rotating, tapping, as well as
the combined motions: sliding+rotating, tapping+rotating, and tapping+sliding.
We chose sliding and sliding+rotating as the best motions based on final
accuracy and the sample timing length needed to reach converged accuracy. In
the second experiment designed to simulate complex real-world conditions, these
two motions were further evaluated under varying contact depth and speeds.
Under these conditions, our framework attained the highest accuracy of 87.33\%
with sliding+rotating while maintaining an extremely low power consumption of
only 8.04 mW. These results suggest that the sliding+rotating motion is the
optimal exploratory strategy for neuromorphic tactile sensing deployment in
texture classification tasks and holds significant promise for enhancing
robotic environmental interaction.

</details>


### [24] [AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](https://arxiv.org/abs/2509.15153)
*Yating Lin,Zixuan Huang,Fan Yang,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出了基于扩散模型的AnoF-Diff方法，用于从时间序列数据中提取力-扭矩特征并检测异常，在嘈杂数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现实世界中的流式传感器数据通常具有噪声大、非平稳且随任务和工具变化的特点，直接应用现有多元时间序列异常检测方法存在挑战

Method: 基于扩散模型提取力-扭矩特征，提出并行异常评分评估方法，支持一步扩散的在线异常检测

Result: 在四个强力工具使用任务上，F1分数和AUROC指标均优于现有最先进方法，对噪声数据集更具鲁棒性

Conclusion: AnoF-Diff方法在强力工具使用场景中表现出优异的异常检测性能，特别适用于现实世界中的嘈杂传感器数据

Abstract: Multivariate time-series anomaly detection, which is critical for identifying
unexpected events, has been explored in the field of machine learning for
several decades. However, directly applying these methods to data from forceful
tool use tasks is challenging because streaming sensor data in the real world
tends to be inherently noisy, exhibits non-stationary behavior, and varies
across different tasks and tools. To address these challenges, we propose a
method, AnoF-Diff, based on the diffusion model to extract force-torque
features from time-series data and use force-torque features to detect
anomalies. We compare our method with other state-of-the-art methods in terms
of F1-score and Area Under the Receiver Operating Characteristic curve (AUROC)
on four forceful tool-use tasks, demonstrating that our method has better
performance and is more robust to a noisy dataset. We also propose the method
of parallel anomaly score evaluation based on one-step diffusion and
demonstrate how our method can be used for online anomaly detection in several
forceful tool use experiments.

</details>
