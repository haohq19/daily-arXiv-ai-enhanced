<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 8]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [VAGU & GtS: LLM-Based Benchmark and Framework for Joint Video Anomaly Grounding and Understanding](https://arxiv.org/abs/2507.21507)
*Shibo Gao,Peipei Yang,Yangyang Liu,Yi Chen,Han Zhu,Xuyao Zhang,Linlin Huang*

Main category: cs.CV

TL;DR: VAGU是首个整合视频异常检测与理解的基准数据集，支持异常类别、语义解释、时间定位和视频问答。提出的GtS框架通过文本提示实现粗定位和精细分析，并引入JeAUG指标联合评估语义和时间精度。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法仅关注时间定位或语义理解，缺乏同时支持两者的模型和数据集。

Method: 提出VAGU数据集和GtS框架，结合粗定位与精细分析，并使用JeAUG指标评估。

Result: 实验验证了VAGU数据集、GtS框架和JeAUG指标的有效性。

Conclusion: VAGU和GtS为视频异常检测提供了更全面的解决方案，JeAUG改进了评估方式。

Abstract: Video Anomaly Detection (VAD) aims to identify anomalous events in videos and
accurately determine their time intervals. Current VAD methods mainly fall into
two categories: traditional DNN-based approaches that focus on temporal
localization, and LLM-based approaches that emphasize semantic understanding.
Both anomaly understanding and grounding are essential for comprehensive video
anomaly detection and can complement each other. However, no existing model or
dataset supports both tasks simultaneously. To address this, we introduce VAGU
(Video Anomaly Grounding and Understanding), the first benchmark to integrate
both tasks. Each VAGU instance includes annotations for anomaly category,
semantic explanation, precise temporal grounding and Video QA. We also provide
multiple-choice Video QA for objective evaluation. Based on this dataset, we
propose Glance then Scrutinize (GtS), a training-free framework guided by
textual prompts. The framework first enables coarse localization of
high-probability anomalous regions, followed by detailed anomaly interpretation
and temporal boundary refinement. Additionally, we propose the JeAUG metric,
which jointly evaluates semantic interpretability and temporal precision,
overcoming the limitations of traditional metrics. Extensive experiments verify
the effectiveness of our benchmark, framework, and evaluation metric.

</details>


### [2] [The Evolution of Video Anomaly Detection: A Unified Framework from DNN to MLLM](https://arxiv.org/abs/2507.21649)
*Shibo Gao,Peipei Yang,Haiyang Guo,Yangyang Liu,Yi Chen,Shuai Li,Han Zhu,Jian Xu,Xu-Yao Zhang,Linlin Huang*

Main category: cs.CV

TL;DR: 本文综述了基于多模态大语言模型（MLLMs）和大语言模型（LLMs）的视频异常检测（VAD）方法，探讨了其带来的变革，并提出统一框架。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习和LLMs的发展，VAD领域面临新的机遇与挑战，亟需系统性综述以指导未来研究。

Method: 通过分析数据标注、输入模态、模型架构和任务目标的变化，构建分类系统并比较优劣。

Result: 提出统一框架，涵盖基于DNN和LLM的VAD方法，总结新范式并分析其优缺点。

Conclusion: 提炼关键挑战与未来研究方向，为VAD社区提供指导。

Abstract: Video anomaly detection (VAD) aims to identify and ground anomalous behaviors
or events in videos, serving as a core technology in the fields of intelligent
surveillance and public safety. With the advancement of deep learning, the
continuous evolution of deep model architectures has driven innovation in VAD
methodologies, significantly enhancing feature representation and scene
adaptability, thereby improving algorithm generalization and expanding
application boundaries. More importantly, the rapid development of multi-modal
large language (MLLMs) and large language models (LLMs) has introduced new
opportunities and challenges to the VAD field. Under the support of MLLMs and
LLMs, VAD has undergone significant transformations in terms of data
annotation, input modalities, model architectures, and task objectives. The
surge in publications and the evolution of tasks have created an urgent need
for systematic reviews of recent advancements. This paper presents the first
comprehensive survey analyzing VAD methods based on MLLMs and LLMs, providing
an in-depth discussion of the changes occurring in the VAD field in the era of
large models and their underlying causes. Additionally, this paper proposes a
unified framework that encompasses both deep neural network (DNN)-based and
LLM-based VAD methods, offering a thorough analysis of the new VAD paradigms
empowered by LLMs, constructing a classification system, and comparing their
strengths and weaknesses. Building on this foundation, this paper focuses on
current VAD methods based on MLLMs/LLMs. Finally, based on the trajectory of
technological advancements and existing bottlenecks, this paper distills key
challenges and outlines future research directions, offering guidance for the
VAD community.

</details>


### [3] [LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection](https://arxiv.org/abs/2507.21756)
*Jing Ren,Suyu Ma,Hong Jia,Xiwei Xu,Ivan Lee,Haytham Fayek,Xiaodong Li,Feng Xia*

Main category: cs.CV

TL;DR: LiteFat是一种轻量级的时空图学习模型，用于高效检测驾驶员疲劳，具有高精度和低计算需求。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是交通事故的主要原因，现有解决方案计算量大，不适合资源有限的嵌入式设备。

Method: 将视频数据转换为时空图（STG），使用MobileNet提取面部特征，轻量级时空图神经网络检测疲劳。

Result: 在基准数据集上表现优异，显著降低计算复杂性和延迟。

Conclusion: LiteFat为嵌入式设备提供了实时、高效的疲劳检测解决方案。

Abstract: Detecting driver fatigue is critical for road safety, as drowsy driving
remains a leading cause of traffic accidents. Many existing solutions rely on
computationally demanding deep learning models, which result in high latency
and are unsuitable for embedded robotic devices with limited resources (such as
intelligent vehicles/cars) where rapid detection is necessary to prevent
accidents. This paper introduces LiteFat, a lightweight spatio-temporal graph
learning model designed to detect driver fatigue efficiently while maintaining
high accuracy and low computational demands. LiteFat involves converting
streaming video data into spatio-temporal graphs (STG) using facial landmark
detection, which focuses on key motion patterns and reduces unnecessary data
processing. LiteFat uses MobileNet to extract facial features and create a
feature matrix for the STG. A lightweight spatio-temporal graph neural network
is then employed to identify signs of fatigue with minimal processing and low
latency. Experimental results on benchmark datasets show that LiteFat performs
competitively while significantly decreasing computational complexity and
latency as compared to current state-of-the-art methods. This work enables the
development of real-time, resource-efficient human fatigue detection systems
that can be implemented upon embedded robotic devices.

</details>


### [4] [MSGCoOp: Multiple Semantic-Guided Context Optimization for Few-Shot Learning](https://arxiv.org/abs/2507.21786)
*Zhaolong Wang,Tongfeng Sun,Mingzheng Du,Yachao Huang*

Main category: cs.CV

TL;DR: MSGCoOp框架通过多语义引导上下文优化提升少样本泛化能力，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在新类别泛化上表现不佳，且复杂架构或计算开销大。

Method: 利用并行可学习上下文向量集合，结合LLM生成的类描述进行语义引导，并引入多样性正则化损失。

Result: 在11个基准数据集上显著提升基类到新类的泛化性能，平均调和均值提升1.10%。

Conclusion: MSGCoOp在少样本和跨域泛化任务中表现出色，计算高效。

Abstract: Vision-language pre-trained models (VLMs) such as CLIP have demonstrated
remarkable zero-shot generalization, and prompt learning has emerged as an
efficient alternative to full fine-tuning. However, existing methods often
struggle with generalization to novel classes, a phenomenon attributed to
overfitting on seen classes and forgetting general knowledge. Furthermore,
recent approaches that improve generalization often introduce complex
architectures or heavy computational overhead. In this paper, we propose a
Multiple Semantic-Guided Context Optimization (MSGCoOp) framework to enhance
few-shot generalization while maintaining computational efficiency. Our
approach leverages an ensemble of parallel learnable context vectors to capture
diverse semantic aspects. To enrich these prompts, we introduce a semantic
guidance mechanism that aligns them with comprehensive class descriptions
automatically generated by a Large Language Model (LLM). Furthermore, a
diversity regularization loss encourages the prompts to learn complementary and
orthogonal features, preventing them from collapsing into redundant
representations. Extensive experiments on 11 benchmark datasets show that
MSGCoOp significantly improves performance on base-to-novel generalization,
achieving an average harmonic mean improvement of 1.10\% over the strong KgCoOp
baseline. Our method also demonstrates enhanced robustness in cross-domain
generalization tasks. Our code is avaliable at:
\href{https://github.com/Rain-Bus/MSGCoOp}{https://github.com/Rain-Bus/MSGCoOp}.

</details>


### [5] [Cross-Architecture Distillation Made Simple with Redundancy Suppression](https://arxiv.org/abs/2507.21844)
*Weijia Zhang,Yuehao Liu,Wu Ran,Chao Ma*

Main category: cs.CV

TL;DR: 提出了一种简单的跨架构知识蒸馏方法，通过抑制冗余信息实现知识迁移，避免了复杂模块和额外参数。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常引入复杂模块和架构定制设计，降低了效率和适用性，因此需要一种更简单高效的解决方案。

Method: 提出冗余抑制蒸馏（RSD）损失，包括跨架构不变性最大化和特征去相关目标，并设计轻量级模块解耦RSD目标与学生内部表示。

Result: 在CIFAR-100和ImageNet-1k基准测试中优于OFA方法，且参数开销显著减少。

Conclusion: 该方法为跨架构蒸馏领域提供了一个简单而强大的基线。

Abstract: We describe a simple method for cross-architecture knowledge distillation,
where the knowledge transfer is cast into a redundant information suppression
formulation. Existing methods introduce sophisticated modules,
architecture-tailored designs, and excessive parameters, which impair their
efficiency and applicability. We propose to extract the architecture-agnostic
knowledge in heterogeneous representations by reducing the redundant
architecture-exclusive information. To this end, we present a simple redundancy
suppression distillation (RSD) loss, which comprises cross-architecture
invariance maximisation and feature decorrelation objectives. To prevent the
student from entirely losing its architecture-specific capabilities, we further
design a lightweight module that decouples the RSD objective from the student's
internal representations. Our method is devoid of the architecture-specific
designs and complex operations in the pioneering method of OFA. It outperforms
OFA on CIFAR-100 and ImageNet-1k benchmarks with only a fraction of their
parameter overhead, which highlights its potential as a simple and strong
baseline to the cross-architecture distillation community.

</details>


### [6] [Unleashing the Power of Motion and Depth: A Selective Fusion Strategy for RGB-D Video Salient Object Detection](https://arxiv.org/abs/2507.21857)
*Jiahao He,Daerji Suolang,Keren Fu,Qijun Zhao*

Main category: cs.CV

TL;DR: SMFNet提出了一种选择性跨模态融合框架，通过像素级选择性融合策略和多维选择性注意力模块，优化了RGB-D视频显著目标检测中光流和深度的利用。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D VSOD方法对光流和深度的利用不够灵活，限制了性能提升。

Method: 提出SMFNet框架，包含像素级选择性融合策略（PSF）和多维选择性注意力模块（MSAM）。

Result: 在多个数据集上优于19种现有模型，验证了SMFNet的优越性。

Conclusion: SMFNet通过选择性融合策略显著提升了RGB-D视频显著目标检测的性能。

Abstract: Applying salient object detection (SOD) to RGB-D videos is an emerging task
called RGB-D VSOD and has recently gained increasing interest, due to
considerable performance gains of incorporating motion and depth and that RGB-D
videos can be easily captured now in daily life. Existing RGB-D VSOD models
have different attempts to derive motion cues, in which extracting motion
information explicitly from optical flow appears to be a more effective and
promising alternative. Despite this, there remains a key issue that how to
effectively utilize optical flow and depth to assist the RGB modality in SOD.
Previous methods always treat optical flow and depth equally with respect to
model designs, without explicitly considering their unequal contributions in
individual scenarios, limiting the potential of motion and depth. To address
this issue and unleash the power of motion and depth, we propose a novel
selective cross-modal fusion framework (SMFNet) for RGB-D VSOD, incorporating a
pixel-level selective fusion strategy (PSF) that achieves optimal fusion of
optical flow and depth based on their actual contributions. Besides, we propose
a multi-dimensional selective attention module (MSAM) to integrate the fused
features derived from PSF with the remaining RGB modality at multiple
dimensions, effectively enhancing feature representation to generate refined
features. We conduct comprehensive evaluation of SMFNet against 19
state-of-the-art models on both RDVS and DVisal datasets, making the evaluation
the most comprehensive RGB-D VSOD benchmark up to date, and it also
demonstrates the superiority of SMFNet over other models. Meanwhile, evaluation
on five video benchmark datasets incorporating synthetic depth validates the
efficacy of SMFNet as well. Our code and benchmark results are made publicly
available at https://github.com/Jia-hao999/SMFNet.

</details>


### [7] [EIFNet: Leveraging Event-Image Fusion for Robust Semantic Segmentation](https://arxiv.org/abs/2507.21971)
*Zhijiang Li,Haoran He*

Main category: cs.CV

TL;DR: EIFNet是一个多模态融合网络，结合事件和帧输入的优势，通过自适应特征优化和注意力机制解决事件语义分割的挑战。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高动态范围和精细时间分辨率，但在稀疏和噪声事件流中提取可靠特征以及与密集图像数据融合仍具挑战性。

Method: 提出EIFNet，包含自适应事件特征优化模块（AEFRM）、模态自适应重校准模块（MARM）和多头注意力门控融合模块（MGFM）。

Result: 在DDD17-Semantic和DSEC-Semantic数据集上达到最先进性能。

Conclusion: EIFNet有效解决了事件语义分割中的特征提取和模态融合问题。

Abstract: Event-based semantic segmentation explores the potential of event cameras,
which offer high dynamic range and fine temporal resolution, to achieve robust
scene understanding in challenging environments. Despite these advantages, the
task remains difficult due to two main challenges: extracting reliable features
from sparse and noisy event streams, and effectively fusing them with dense,
semantically rich image data that differ in structure and representation. To
address these issues, we propose EIFNet, a multi-modal fusion network that
combines the strengths of both event and frame-based inputs. The network
includes an Adaptive Event Feature Refinement Module (AEFRM), which improves
event representations through multi-scale activity modeling and spatial
attention. In addition, we introduce a Modality-Adaptive Recalibration Module
(MARM) and a Multi-Head Attention Gated Fusion Module (MGFM), which align and
integrate features across modalities using attention mechanisms and gated
fusion strategies. Experiments on DDD17-Semantic and DSEC-Semantic datasets
show that EIFNet achieves state-of-the-art performance, demonstrating its
effectiveness in event-based semantic segmentation.

</details>


### [8] [ZIUM: Zero-Shot Intent-Aware Adversarial Attack on Unlearned Models](https://arxiv.org/abs/2507.21985)
*Hyun Jun Yook,Ga San Jhun,Jae Hyun Cho,Min Jeon,Donghyun Kim,Tae Hyung Kim,Youn Kyu Lee*

Main category: cs.CV

TL;DR: ZIUM是一种零样本意图感知对抗攻击方法，针对未学习模型，能高效生成符合攻击者意图的内容，并显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法在生成符合攻击者意图的内容时效率低且计算成本高，需要一种更高效的方法。

Method: 提出ZIUM，支持零样本对抗攻击，无需额外优化即可针对未学习概念生成定制化攻击内容。

Result: ZIUM在多种未学习场景中表现优异，攻击成功率高且显著减少攻击时间。

Conclusion: ZIUM为对抗攻击提供了一种高效、灵活的解决方案，显著提升了攻击效率和效果。

Abstract: Machine unlearning (MU) removes specific data points or concepts from deep
learning models to enhance privacy and prevent sensitive content generation.
Adversarial prompts can exploit unlearned models to generate content containing
removed concepts, posing a significant security risk. However, existing
adversarial attack methods still face challenges in generating content that
aligns with an attacker's intent while incurring high computational costs to
identify successful prompts. To address these challenges, we propose ZIUM, a
Zero-shot Intent-aware adversarial attack on Unlearned Models, which enables
the flexible customization of target attack images to reflect an attacker's
intent. Additionally, ZIUM supports zero-shot adversarial attacks without
requiring further optimization for previously attacked unlearned concepts. The
evaluation across various MU scenarios demonstrated ZIUM's effectiveness in
successfully customizing content based on user-intent prompts while achieving a
superior attack success rate compared to existing methods. Moreover, its
zero-shot adversarial attack significantly reduces the attack time for
previously attacked unlearned concepts.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning](https://arxiv.org/abs/2507.21147)
*Fabrizio Lo Scudo,Alessio De Rango,Luca Furnari,Alfonso Senatore,Donato D'Ambrosio,Giuseppe Mendicino,Gianluigi Greco*

Main category: cs.LG

TL;DR: 论文提出了一种基于形态学的课程对比学习框架，用于解决野火预测中数据不平衡和高维时空数据的挑战，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 野火对生态系统和人类健康造成严重影响，气候变化加剧了这一问题。现有数据存在不平衡和高维复杂性，且依赖天气数据的预测需要降低计算成本。

Method: 采用对比学习框架，提出形态学课程对比学习方法，优化动态特征的潜在表示，并使用更小的补丁尺寸。

Result: 实验验证了所提方法的有效性，能够在不影响性能的情况下处理区域多样性并减少计算成本。

Conclusion: 形态学课程对比学习为野火预测提供了一种高效解决方案，适用于复杂数据环境。

Abstract: Wildfires significantly impact natural ecosystems and human health, leading
to biodiversity loss, increased hydrogeological risks, and elevated emissions
of toxic substances. Climate change exacerbates these effects, particularly in
regions with rising temperatures and prolonged dry periods, such as the
Mediterranean. This requires the development of advanced risk management
strategies that utilize state-of-the-art technologies. However, in this
context, the data show a bias toward an imbalanced setting, where the incidence
of wildfire events is significantly lower than typical situations. This
imbalance, coupled with the inherent complexity of high-dimensional
spatio-temporal data, poses significant challenges for training deep learning
architectures. Moreover, since precise wildfire predictions depend mainly on
weather data, finding a way to reduce computational costs to enable more
frequent updates using the latest weather forecasts would be beneficial. This
paper investigates how adopting a contrastive framework can address these
challenges through enhanced latent representations for the patch's dynamic
features. We thus introduce a new morphology-based curriculum contrastive
learning that mitigates issues associated with diverse regional characteristics
and enables the use of smaller patch sizes without compromising performance. An
experimental analysis is performed to validate the effectiveness of the
proposed modeling strategies.

</details>


### [10] [Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning](https://arxiv.org/abs/2507.21494)
*Wenxuan Bao,Ruxi Deng,Ruizhong Qiu,Tianxin Wei,Hanghang Tong,Jingrui He*

Main category: cs.LG

TL;DR: Latte是一个新颖的框架，用于解决分布式学习中的测试时适应问题，通过本地和外部内存存储历史数据，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法在分布式环境中因数据有限或共享全局内存而无法个性化适应每个客户端。

Method: Latte框架中，每个客户端维护本地内存存储自身历史测试数据，外部内存存储相关客户端的类原型，通过服务器协调检索相似客户端的原型。

Result: 实验证明Latte在分布式环境中性能优越，且通信和计算成本极低。

Conclusion: Latte有效利用分布内客户端并保持对分布外客户端的鲁棒性，适用于分布式测试时适应。

Abstract: Test-time adaptation with pre-trained vision-language models has gained
increasing attention for addressing distribution shifts during testing. Among
these approaches, memory-based algorithms stand out due to their training-free
nature and ability to leverage historical test data. However, existing
test-time adaptation methods are typically designed for a single domain with
abundant data. In decentralized settings such as federated learning, applying
these methods individually to each client suffers from limited test data, while
directly sharing a single global memory via the server prevents proper
personalization to each client's unique distribution. To address this, we
propose Latte, a novel framework where each client maintains a local memory to
store embeddings from its own historical test data and an external memory to
store class prototypes from other relevant clients. During communication, each
client retrieves prototypes from similar clients under the server's
coordination to expand its memory. For local adaptation, Latte utilizes both
embedding similarity and uncertainty to enhance model performance. Our
theoretical analysis shows that Latte effectively leverages in-distribution
clients while remaining robust to out-of-distribution clients. Extensive
experiments on domain adaptation and corruption benchmarks validate that Latte
achieves superior performance in decentralized settings, while introducing only
negligible communication and computation costs. Our code is available at
https://github.com/baowenxuan/Latte .

</details>


### [11] [Categorical Distributions are Effective Neural Network Outputs for Event Prediction](https://arxiv.org/abs/2507.21616)
*Kevin Doran,Tom Baden*

Main category: cs.LG

TL;DR: 论文探讨了使用简单的神经网络输出（分类概率分布）进行下一个尖峰预测的有效性，并研究了为何这种输出结构在神经时间点过程模型中不常见。


<details>
  <summary>Details</summary>
Motivation: 研究简单输出结构在神经时间点过程模型中不常见的原因，并探索其在更广泛数据集中的表现。

Method: 通过扩展和创建新的数据集，验证简单分类概率分布作为输出的有效性。

Result: 发现简单分类分布在多种数据集中表现优异，且现有数据集可能未能充分揭示事件生成过程的信息。

Conclusion: 简单分类分布是一种有效的输出结构，尤其在更广泛的数据集环境中表现良好。

Abstract: We demonstrate the effectiveness of using a simple neural network output, a
categorical probability distribution, for the task of next spike prediction.
This case study motivates an investigation into why this simple output
structure is not commonly used with neural temporal point process models. We
find evidence that many existing datasets for evaluating temporal point process
models do not reveal much information about the underlying event generating
processes, and many existing models perform well due to regularization effects
of model size and constraints on output structure. We extend existing datasets
and create new ones in order to explore outside of this information limited
regime and find that outputting a simple categorical distribution is
competitive across a wide range of datasets.

</details>


### [12] [Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation](https://arxiv.org/abs/2507.21738)
*Huiqiang Chen,Tianqing Zhu,Xin Yu,Wanlei Zhou*

Main category: cs.LG

TL;DR: 提出了一种名为ZS-PAG的新框架，用于解决零样本机器遗忘中的过遗忘问题，通过生成对抗样本和设计影响伪标签策略来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘算法依赖剩余数据，无法适用于仅提供遗忘样本的零样本场景，因此需要一种新方法。

Method: 通过生成对抗样本近似剩余数据，确定特定子空间进行遗忘，并设计影响伪标签策略以防止过遗忘。

Result: 实验验证了ZS-PAG在多种基准测试中的有效性和优越性。

Conclusion: ZS-PAG在零样本机器遗忘中表现出色，解决了过遗忘问题并提升了模型性能。

Abstract: Machine unlearning aims to remove the influence of specific samples from a
trained model. A key challenge in this process is over-unlearning, where the
model's performance on the remaining data significantly drops due to the change
in the model's parameters. Existing unlearning algorithms depend on the
remaining data to prevent this issue. As such, these methods are inapplicable
in a more practical scenario, where only the unlearning samples are available
(i.e., zero-shot unlearning). This paper presents a novel framework, ZS-PAG, to
fill this gap. Our approach offers three key innovations: (1) we approximate
the inaccessible remaining data by generating adversarial samples; (2)
leveraging the generated samples, we pinpoint a specific subspace to perform
the unlearning process, therefore preventing over-unlearning in the challenging
zero-shot scenario; and (3) we consider the influence of the unlearning process
on the remaining samples and design an influence-based pseudo-labeling
strategy. As a result, our method further improves the model's performance
after unlearning. The proposed method holds a theoretical guarantee, and
experiments on various benchmarks validate the effectiveness and superiority of
our proposed method over several baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image](https://arxiv.org/abs/2507.21881)
*Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 该研究提出了一种基于电皮肤活动信号的多表示融合方法，用于自动疼痛评估，效果优于传统融合方法。


<details>
  <summary>Details</summary>
Motivation: 疼痛评估对临床决策和患者管理至关重要，但传统方法缺乏客观性和连续性。本研究旨在通过生理信号提供更准确的疼痛评估。

Method: 利用电皮肤活动信号生成多种表示形式，并通过多表示图联合可视化，结合多种处理和过滤技术进行实验。

Result: 该方法在多种表示组合下表现优异，优于传统融合方法。

Conclusion: 该方法为信号表示或模态的整合提供了稳健的替代方案。

Abstract: Pain is a multifaceted phenomenon that affects a substantial portion of the
population. Reliable and consistent evaluation benefits those experiencing pain
and underpins the development of effective and advanced management strategies.
Automatic pain-assessment systems deliver continuous monitoring, inform
clinical decision-making, and aim to reduce distress while preventing
functional decline. By incorporating physiological signals, these systems
provide objective, accurate insights into an individual's condition. This study
has been submitted to the \textit{Second Multimodal Sensing Grand Challenge for
Next-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline
that leverages electrodermal activity signals as input modality. Multiple
representations of the signal are created and visualized as waveforms, and they
are jointly visualized within a single multi-representation diagram. Extensive
experiments incorporating various processing and filtering techniques, along
with multiple representation combinations, demonstrate the effectiveness of the
proposed approach. It consistently yields comparable, and in several cases
superior, results to traditional fusion methods, establishing it as a robust
alternative for integrating different signal representations or modalities.

</details>


### [14] [Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline](https://arxiv.org/abs/2507.21886)
*Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 该论文提出了一种基于呼吸信号和多窗口策略的高效交叉注意力Transformer模型，用于自动疼痛评估，实验表明其性能优于大型模型。


<details>
  <summary>Details</summary>
Motivation: 疼痛评估对个体健康和临床决策至关重要，自动评估系统能提供连续监测并支持有效管理策略的开发。

Method: 利用呼吸信号作为输入，结合高效交叉注意力Transformer和多窗口策略，捕捉短期、长期及全局特征。

Result: 实验证明呼吸信号是有效的疼痛评估生理模态，优化后的紧凑模型性能优于大型模型。

Conclusion: 多窗口策略增强了模型表征能力，呼吸信号结合高效模型为疼痛评估提供了新方向。

Abstract: Pain is a complex condition affecting a large portion of the population.
Accurate and consistent evaluation is essential for individuals experiencing
pain, and it supports the development of effective and advanced management
strategies. Automatic pain assessment systems provide continuous monitoring and
support clinical decision-making, aiming to reduce distress and prevent
functional decline. This study has been submitted to the \textit{Second
Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The
proposed method introduces a pipeline that leverages respiration as the input
signal and incorporates a highly efficient cross-attention transformer
alongside a multi-windowing strategy. Extensive experiments demonstrate that
respiration is a valuable physiological modality for pain assessment. Moreover,
experiments revealed that compact and efficient models, when properly
optimized, can achieve strong performance, often surpassing larger
counterparts. The proposed multi-window approach effectively captures both
short-term and long-term features, as well as global characteristics, thereby
enhancing the model's representational capacity.

</details>


### [15] [LLM-based Content Classification Approach for GitHub Repositories by the README Files](https://arxiv.org/abs/2507.21899)
*Malik Uzair Mehmood,Shahid Hussain,Wen Li Wang,Muhammad Usama Malik*

Main category: cs.AI

TL;DR: 研究提出了一种基于LLMs的方法，用于自动分类GitHub README文件的不同部分，通过微调BERT、DistilBERT和RoBERTa模型，取得了0.98的F1分数，并探索了参数高效微调技术。


<details>
  <summary>Details</summary>
Motivation: GitHub仓库的README文件对项目的采用和利用有重要影响，但许多仓库所有者忽视了其完整性，限制了项目的潜力。

Method: 研究微调了三种编码器模型（BERT、DistilBERT和RoBERTa），并使用包含4226个README文件片段的黄金标准数据集进行训练。

Result: 该方法在分类任务中表现优异，F1分数达到0.98，并验证了参数高效微调技术的可行性。

Conclusion: LLMs在自动分类GitHub README文件内容方面具有潜力，为改进仓库识别和利用提供了自动化工具。

Abstract: GitHub is the world's most popular platform for storing, sharing, and
managing code. Every GitHub repository has a README file associated with it.
The README files should contain project-related information as per the
recommendations of GitHub to support the usage and improvement of repositories.
However, GitHub repository owners sometimes neglected these recommendations.
This prevents a GitHub repository from reaching its full potential. This
research posits that the comprehensiveness of a GitHub repository's README file
significantly influences its adoption and utilization, with a lack of detail
potentially hindering its full potential for widespread engagement and impact
within the research community. Large Language Models (LLMs) have shown great
performance in many text-based tasks including text classification, text
generation, text summarization and text translation. In this study, an approach
is developed to fine-tune LLMs for automatically classifying different sections
of GitHub README files. Three encoder-only LLMs are utilized, including BERT,
DistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a
gold-standard dataset consisting of 4226 README file sections. This approach
outperforms current state-of-the-art methods and has achieved an overall F1
score of 0.98. Moreover, we have also investigated the use of
Parameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation
(LoRA) and shown an economical alternative to full fine-tuning without
compromising much performance. The results demonstrate the potential of using
LLMs in designing an automatic classifier for categorizing the content of
GitHub README files. Consequently, this study contributes to the development of
automated tools for GitHub repositories to improve their identifications and
potential usages.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [Understanding Public Perception of Crime in Bangladesh: A Transformer-Based Approach with Explainability](https://arxiv.org/abs/2507.21234)
*Fatema Binte Hassan,Md Al Jubair,Mohammad Mehadi Hasan,Tahmid Hossain,S M Mehebubur Rahman Khan Shuvo,Mohammad Shamsul Arefin*

Main category: cs.CL

TL;DR: 该研究利用XLM-RoBERTa Base架构的Transformer模型，对孟加拉语社交媒体评论进行情感分类，准确率达97%，并采用可解释AI技术提升模型透明度。


<details>
  <summary>Details</summary>
Motivation: 社交媒体成为公众表达对犯罪事件意见的重要平台，动态变化的公众情绪需要被量化分析。

Method: 构建包含28,528条孟加拉语评论的数据集，使用XLM-RoBERTa Base架构的Transformer模型进行分类。

Result: 模型分类准确率达97%，优于现有方法，并通过可解释AI技术识别关键特征。

Conclusion: Transformer模型在低资源语言（如孟加拉语）中表现优异，可为公共政策制定和犯罪预防提供支持。

Abstract: In recent years, social media platforms have become prominent spaces for
individuals to express their opinions on ongoing events, including criminal
incidents. As a result, public sentiment can shift dynamically over time. This
study investigates the evolving public perception of crime-related news by
classifying user-generated comments into three categories: positive, negative,
and neutral. A newly curated dataset comprising 28,528 Bangla-language social
media comments was developed for this purpose. We propose a transformer-based
model utilizing the XLM-RoBERTa Base architecture, which achieves a
classification accuracy of 97%, outperforming existing state-of-the-art methods
in Bangla sentiment analysis. To enhance model interpretability, explainable AI
technique is employed to identify the most influential features driving
sentiment classification. The results underscore the effectiveness of
transformer-based models in processing low-resource languages such as Bengali
and demonstrate their potential to extract actionable insights that can support
public policy formulation and crime prevention strategies.

</details>


### [17] [Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)
*Runjin Chen,Andy Arditi,Henry Sleight,Owain Evans,Jack Lindsey*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型中“助手”角色的激活空间方向（即“角色向量”），用于监控和预测训练中的角色变化，并提出干预和预防方法。


<details>
  <summary>Details</summary>
Motivation: 研究助手角色在训练和部署时可能偏离理想行为（如邪恶、奉承、幻觉倾向）的原因及其影响。

Method: 通过提取角色向量来监控角色变化，并利用这些向量预测和控制训练中的角色偏移，提出干预和预防方法。

Result: 角色向量能有效预测和控制角色变化，干预和预防方法可减少不良角色偏移，并能标记导致不良变化的训练数据。

Conclusion: 角色向量为监控和调整语言模型行为提供了自动化工具，适用于任何感兴趣的角色特征。

Abstract: Large language models interact with users through a simulated 'Assistant'
persona. While the Assistant is typically trained to be helpful, harmless, and
honest, it sometimes deviates from these ideals. In this paper, we identify
directions in the model's activation space-persona vectors-underlying several
traits, such as evil, sycophancy, and propensity to hallucinate. We confirm
that these vectors can be used to monitor fluctuations in the Assistant's
personality at deployment time. We then apply persona vectors to predict and
control personality shifts that occur during training. We find that both
intended and unintended personality changes after finetuning are strongly
correlated with shifts along the relevant persona vectors. These shifts can be
mitigated through post-hoc intervention, or avoided in the first place with a
new preventative steering method. Moreover, persona vectors can be used to flag
training data that will produce undesirable personality changes, both at the
dataset level and the individual sample level. Our method for extracting
persona vectors is automated and can be applied to any personality trait of
interest, given only a natural-language description.

</details>


### [18] [Modelling Adjectival Modification Effects on Semantic Plausibility](https://arxiv.org/abs/2507.21828)
*Anna Golub,Beate Zywietz,Annerose Eichel*

Main category: cs.CL

TL;DR: 论文研究了事件合理性变化评估，提出了一种基于句子Transformer的新方法，发现现有模型在该任务上表现不佳，并强调了平衡评估方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 理解事件合理性变化对对话生成、常识推理等任务至关重要，但现有研究对此关注不足。

Method: 使用句子Transformer和Transformer模型（如RoBERTa）对16K英语句子对进行建模实验。

Result: 句子Transformer和Transformer模型在该任务上表现不佳，句子Transformer甚至不如RoBERTa。评估方法的不平衡会影响结果可信度。

Conclusion: 论文提出了一种新方法，但揭示了模型在该任务上的局限性，并强调了平衡评估的必要性。

Abstract: While the task of assessing the plausibility of events such as ''news is
relevant'' has been addressed by a growing body of work, less attention has
been paid to capturing changes in plausibility as triggered by event
modification. Understanding changes in plausibility is relevant for tasks such
as dialogue generation, commonsense reasoning, and hallucination detection as
it allows to correctly model, for example, ''gentle sarcasm'' as a sign of
closeness rather than unkindness among friends [9]. In this work, we tackle the
ADEPT challenge benchmark [6] consisting of 16K English sentence pairs
differing by exactly one adjectival modifier. Our modeling experiments provide
a conceptually novel method by using sentence transformers, and reveal that
both they and transformer-based models struggle with the task at hand, and
sentence transformers - despite their conceptual alignment with the task - even
under-perform in comparison to models like RoBERTa. Furthermore, an in-depth
comparison with prior work highlights the importance of a more realistic,
balanced evaluation method: imbalances distort model performance and evaluation
metrics, and weaken result trustworthiness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [A Deep Learning-Driven Autonomous System for Retinal Vein Cannulation: Validation Using a Chicken Embryo Model](https://arxiv.org/abs/2507.21965)
*Yi Wang,Peiyao Zhang,Mojtaba Esfandiari,Peter Gehlbach,Iulian I. Iordachita*

Main category: cs.RO

TL;DR: 论文提出了一种自动化机器人系统，结合深度学习和光学相干断层扫描（OCT）成像，用于视网膜静脉插管（RVC），显著提高了手术的精确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 视网膜静脉插管（RVC）技术面临小尺寸、脆弱性及高精度操作需求等挑战，亟需机器人辅助提升手术效果。

Method: 采用自上而下的显微镜和B-scan OCT成像，结合深度学习模型实现实时针头导航、接触检测和静脉穿刺识别，使用鸡胚胎模型模拟人类视网膜静脉。

Result: 系统自主检测针头位置和穿刺事件的准确率达85%，实验显示导航和穿刺时间较手动方法显著减少。

Conclusion: 结合先进成像和深度学习可自动化显微手术任务，为RVC手术提供更安全、可靠且精确的解决方案。

Abstract: Retinal vein cannulation (RVC) is a minimally invasive microsurgical
procedure for treating retinal vein occlusion (RVO), a leading cause of vision
impairment. However, the small size and fragility of retinal veins, coupled
with the need for high-precision, tremor-free needle manipulation, create
significant technical challenges. These limitations highlight the need for
robotic assistance to improve accuracy and stability. This study presents an
automated robotic system with a top-down microscope and B-scan optical
coherence tomography (OCT) imaging for precise depth sensing. Deep
learning-based models enable real-time needle navigation, contact detection,
and vein puncture recognition, using a chicken embryo model as a surrogate for
human retinal veins. The system autonomously detects needle position and
puncture events with 85% accuracy. The experiments demonstrate notable
reductions in navigation and puncture times compared to manual methods. Our
results demonstrate the potential of integrating advanced imaging and deep
learning to automate microsurgical tasks, providing a pathway for safer and
more reliable RVC procedures with enhanced precision and reproducibility.

</details>
