{"id": "2510.08812", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08812", "abs": "https://arxiv.org/abs/2510.08812", "authors": ["Grace Ra Kim", "Hailey Warner", "Duncan Eddy", "Evan Astle", "Zachary Booth", "Edward Balaban", "Mykel J. Kochenderfer"], "title": "Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning", "comment": "7 pages, 4 tables, 5 figures, accepted in IEEE ISPARO 2026", "summary": "Deep space missions face extreme communication delays and environmental\nuncertainty that prevent real-time ground operations. To support autonomous\nscience operations in communication-constrained environments, we present a\npartially observable Markov decision process (POMDP) framework that adaptively\nsequences spacecraft science instruments. We integrate a Bayesian network into\nthe POMDP observation space to manage the high-dimensional and uncertain\nmeasurements typical of astrobiology missions. This network compactly encodes\ndependencies among measurements and improves the interpretability and\ncomputational tractability of science data. Instrument operation policies are\ncomputed offline, allowing resource-aware plans to be generated and thoroughly\nvalidated prior to launch. We use the Enceladus Orbilander's proposed Life\nDetection Suite (LDS) as a case study, demonstrating how Bayesian network\nstructure and reward shaping influence system performance. We compare our\nmethod against the mission's baseline Concept of Operations (ConOps),\nevaluating both misclassification rates and performance in off-nominal sample\naccumulation scenarios. Our approach reduces sample identification errors by\nnearly 40%", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8ePOMDP\u548c\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u81ea\u9002\u5e94\u79d1\u5b66\u4eea\u5668\u5e8f\u5217\u6846\u67b6\uff0c\u7528\u4e8e\u6df1\u7a7a\u4efb\u52a1\u4e2d\u7684\u81ea\u4e3b\u79d1\u5b66\u64cd\u4f5c\uff0c\u5728Enceladus Orbilander\u6848\u4f8b\u4e2d\u51cf\u5c11\u8fd140%\u7684\u6837\u672c\u8bc6\u522b\u9519\u8bef\u3002", "motivation": "\u6df1\u7a7a\u4efb\u52a1\u9762\u4e34\u6781\u7aef\u901a\u4fe1\u5ef6\u8fdf\u548c\u73af\u5883\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u6cd5\u8fdb\u884c\u5b9e\u65f6\u5730\u9762\u64cd\u4f5c\uff0c\u9700\u8981\u652f\u6301\u901a\u4fe1\u53d7\u9650\u73af\u5883\u4e0b\u7684\u81ea\u4e3b\u79d1\u5b66\u64cd\u4f5c\u3002", "method": "\u5c06\u8d1d\u53f6\u65af\u7f51\u7edc\u96c6\u6210\u5230POMDP\u89c2\u6d4b\u7a7a\u95f4\u4e2d\uff0c\u7ba1\u7406\u9ad8\u7ef4\u4e0d\u786e\u5b9a\u6d4b\u91cf\uff1b\u79bb\u7ebf\u8ba1\u7b97\u4eea\u5668\u64cd\u4f5c\u7b56\u7565\uff0c\u5141\u8bb8\u5728\u53d1\u5c04\u524d\u751f\u6210\u548c\u9a8c\u8bc1\u8d44\u6e90\u611f\u77e5\u8ba1\u5212\u3002", "result": "\u5728Enceladus Orbilander\u7684\u751f\u547d\u68c0\u6d4b\u5957\u4ef6\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4e0e\u57fa\u7ebf\u64cd\u4f5c\u6982\u5ff5\u76f8\u6bd4\uff0c\u6837\u672c\u8bc6\u522b\u9519\u8bef\u51cf\u5c11\u8fd140%\u3002", "conclusion": "\u8be5POMDP\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6df1\u7a7a\u4efb\u52a1\u4e2d\u79d1\u5b66\u6570\u636e\u91c7\u96c6\u7684\u51c6\u786e\u6027\u548c\u81ea\u4e3b\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u901a\u4fe1\u53d7\u9650\u73af\u5883\u3002"}}
{"id": "2510.08631", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08631", "abs": "https://arxiv.org/abs/2510.08631", "authors": ["Hanieh Shojaei Miandashti", "Claus Brenner"], "title": "Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs", "comment": null, "summary": "In addition to accurate scene understanding through precise semantic\nsegmentation of LiDAR point clouds, detecting out-of-distribution (OOD)\nobjects, instances not encountered during training, is essential to prevent the\nincorrect assignment of unknown objects to known classes. While supervised OOD\ndetection methods depend on auxiliary OOD datasets, unsupervised methods avoid\nthis requirement but typically rely on predictive entropy, the entropy of the\npredictive distribution obtained by averaging over an ensemble or multiple\nposterior weight samples. However, these methods often conflate epistemic\n(model) and aleatoric (data) uncertainties, misclassifying ambiguous in\ndistribution regions as OOD. To address this issue, we present an unsupervised\nOOD detection approach that employs epistemic uncertainty derived from\nhierarchical Bayesian modeling of Gaussian Mixture Model (GMM) parameters in\nthe feature space of a deep neural network. Without requiring auxiliary data or\nadditional training stages, our approach outperforms existing uncertainty-based\nmethods on the SemanticKITTI dataset, achieving an 18\\% improvement in AUROC,\n22\\% increase in AUPRC, and 36\\% reduction in FPR95 (from 76\\% to 40\\%),\ncompared to the predictive entropy approach used in prior works.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u8d1d\u53f6\u65af\u5efa\u6a21\u7684\u65e0\u76d1\u7763OOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6539\u8fdbLiDAR\u70b9\u4e91\u4e2d\u7684\u5f02\u5e38\u7269\u4f53\u68c0\u6d4b\uff0c\u5728SemanticKITTI\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763OOD\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u9884\u6d4b\u71b5\uff0c\u4f46\u6df7\u6dc6\u4e86\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u5c06\u5206\u5e03\u5185\u6a21\u7cca\u533a\u57df\u8bef\u5206\u7c7b\u4e3aOOD\u3002\u9700\u8981\u5f00\u53d1\u80fd\u51c6\u786e\u5206\u79bb\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u5c42\u6b21\u8d1d\u53f6\u65af\u5efa\u6a21\uff0c\u4ece\u4e2d\u63d0\u53d6\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7528\u4e8eOOD\u68c0\u6d4b\uff0c\u65e0\u9700\u8f85\u52a9\u6570\u636e\u6216\u989d\u5916\u8bad\u7ec3\u9636\u6bb5\u3002", "result": "\u5728SemanticKITTI\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u9884\u6d4b\u71b5\u65b9\u6cd5\uff0cAUROC\u63d0\u534718%\uff0cAUPRC\u63d0\u534722%\uff0cFPR95\u4ece76%\u964d\u4f4e\u523040%\uff08\u51cf\u5c1136%\uff09\u3002", "conclusion": "\u57fa\u4e8e\u5c42\u6b21\u8d1d\u53f6\u65af\u5efa\u6a21\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u8fdb\u65e0\u76d1\u7763OOD\u68c0\u6d4b\u6027\u80fd\uff0c\u907f\u514d\u6df7\u6dc6\u4e0d\u540c\u7c7b\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5728LiDAR\u70b9\u4e91\u5206\u6790\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.08637", "categories": ["cs.CV", "physics.med-ph", "94A12, 62H30, 68T10", "I.5.4; I.4.7; J.3"], "pdf": "https://arxiv.org/pdf/2510.08637", "abs": "https://arxiv.org/abs/2510.08637", "authors": ["Mostafa Mohammadpour", "Mehdi Zekriyapanah Gashti", "Yusif S. Gasimov"], "title": "Detection of high-frequency oscillations using time-frequency analysis", "comment": "17 pages, 7 figures", "summary": "High-frequency oscillations (HFOs) are a new biomarker for identifying the\nepileptogenic zone. Mapping HFO-generating regions can improve the precision of\nresection sites in patients with refractory epilepsy. However, detecting HFOs\nremains challenging, and their clinical features are not yet fully defined.\nVisual identification of HFOs is time-consuming, labor-intensive, and\nsubjective. As a result, developing automated methods to detect HFOs is\ncritical for research and clinical use. In this study, we developed a novel\nmethod for detecting HFOs in the ripple and fast ripple frequency bands (80-500\nHz). We validated it using both controlled datasets and data from epilepsy\npatients. Our method employs an unsupervised clustering technique to categorize\nevents extracted from the time-frequency domain using the S-transform. The\nproposed detector differentiates HFOs events from spikes, background activity,\nand artifacts. Compared to existing detectors, our method achieved a\nsensitivity of 97.67%, a precision of 98.57%, and an F-score of 97.78% on the\ncontrolled dataset. In epilepsy patients, our results showed a stronger\ncorrelation with surgical outcomes, with a ratio of 0.73 between HFOs rates in\nresected versus non-resected contacts. The study confirmed previous findings\nthat HFOs are promising biomarkers of epileptogenicity in epileptic patients.\nRemoving HFOs, especially fast ripple, leads to seizure freedom, while\nremaining HFOs lead to seizure recurrence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u76d1\u7763\u805a\u7c7b\u7684\u9ad8\u9891\u632f\u8361\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u572880-500Hz\u9891\u6bb5\u5185\u80fd\u6709\u6548\u533a\u5206HFOs\u4e0e\u5c16\u5cf0\u3001\u80cc\u666f\u6d3b\u52a8\u548c\u4f2a\u8ff9\uff0c\u5728\u63a7\u5236\u6570\u636e\u96c6\u4e0a\u8fbe\u523097.67%\u7684\u654f\u611f\u5ea6\u548c98.57%\u7684\u7cbe\u786e\u5ea6\u3002", "motivation": "\u9ad8\u9891\u632f\u8361\u662f\u8bc6\u522b\u766b\u75eb\u7076\u7684\u65b0\u751f\u7269\u6807\u5fd7\u7269\uff0c\u4f46\u89c6\u89c9\u8bc6\u522b\u8017\u65f6\u8d39\u529b\u4e14\u4e3b\u89c2\uff0c\u9700\u8981\u5f00\u53d1\u81ea\u52a8\u5316\u68c0\u6d4b\u65b9\u6cd5\u7528\u4e8e\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u65f6\u9891\u57df\u7684S\u53d8\u6362\u63d0\u53d6\u4e8b\u4ef6\uff0c\u91c7\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u6280\u672f\u5bf9\u4e8b\u4ef6\u8fdb\u884c\u5206\u7c7b\uff0c\u533a\u5206\u9ad8\u9891\u632f\u8361\u3001\u5c16\u5cf0\u3001\u80cc\u666f\u6d3b\u52a8\u548c\u4f2a\u8ff9\u3002", "result": "\u5728\u63a7\u5236\u6570\u636e\u96c6\u4e0a\u654f\u611f\u5ea697.67%\u3001\u7cbe\u786e\u5ea698.57%\u3001F\u5206\u657097.78%\uff1b\u5728\u766b\u75eb\u60a3\u8005\u4e2d\uff0c\u5207\u9664\u4e0e\u975e\u5207\u9664\u63a5\u89e6\u70b9\u7684HFOs\u6bd4\u7387\u8fbe\u52300.73\uff0c\u4e0e\u624b\u672f\u7ed3\u679c\u76f8\u5173\u6027\u66f4\u5f3a\u3002", "conclusion": "HFOs\u662f\u766b\u75eb\u60a3\u8005\u766b\u75eb\u53d1\u751f\u6027\u7684\u6709\u524d\u666f\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5207\u9664HFOs\uff08\u7279\u522b\u662f\u5feb\u901f\u6ce2\u7eb9\uff09\u53ef\u8fbe\u5230\u65e0\u766b\u75eb\u53d1\u4f5c\uff0c\u800c\u6b8b\u7559HFOs\u4f1a\u5bfc\u81f4\u766b\u75eb\u590d\u53d1\u3002"}}
{"id": "2510.09013", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.09013", "abs": "https://arxiv.org/abs/2510.09013", "authors": ["Daniel A. Williams", "Airlie Chapman", "Daniel R. Little", "Chris Manzie"], "title": "Trust Modeling and Estimation in Human-Autonomy Interactions", "comment": "10 pages. 13 figures", "summary": "Advances in the control of autonomous systems have accompanied an expansion\nin the potential applications for autonomous robotic systems. The success of\napplications involving humans depends on the quality of interaction between the\nautonomous system and the human supervisor, which is particularly affected by\nthe degree of trust that the supervisor places in the autonomous system. Absent\nfrom the literature are models of supervisor trust dynamics that can\naccommodate asymmetric responses to autonomous system performance and the\nintermittent nature of supervisor-autonomous system communication. This paper\nfocuses on formulating an estimated model of supervisor trust that incorporates\nboth of these features by employing a switched linear system structure with\nevent-triggered sampling of the model input and output. Trust response data\ncollected in a user study with 51 participants were then used identify\nparameters for a switched linear model-based observer of supervisor trust.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5207\u6362\u7ebf\u6027\u7cfb\u7edf\u7684\u76d1\u7763\u8005\u4fe1\u4efb\u52a8\u6001\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u6027\u80fd\u7684\u4e0d\u5bf9\u79f0\u54cd\u5e94\u548c\u95f4\u6b47\u6027\u901a\u4fe1\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u80fd\u591f\u5904\u7406\u81ea\u4e3b\u7cfb\u7edf\u6027\u80fd\u4e0d\u5bf9\u79f0\u54cd\u5e94\u548c\u76d1\u7763\u8005-\u81ea\u4e3b\u7cfb\u7edf\u95f4\u6b47\u6027\u901a\u4fe1\u7684\u76d1\u7763\u8005\u4fe1\u4efb\u52a8\u6001\u6a21\u578b\uff0c\u8fd9\u5f71\u54cd\u4e86\u4eba\u673a\u4ea4\u4e92\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u5177\u6709\u4e8b\u4ef6\u89e6\u53d1\u91c7\u6837\u7684\u5207\u6362\u7ebf\u6027\u7cfb\u7edf\u7ed3\u6784\u6765\u6784\u5efa\u76d1\u7763\u8005\u4fe1\u4efb\u4f30\u8ba1\u6a21\u578b\uff0c\u5e76\u4f7f\u752851\u540d\u53c2\u4e0e\u8005\u7684\u4fe1\u4efb\u54cd\u5e94\u6570\u636e\u6765\u8bc6\u522b\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5207\u6362\u7ebf\u6027\u6a21\u578b\u7684\u76d1\u7763\u8005\u4fe1\u4efb\u89c2\u6d4b\u5668\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349\u4fe1\u4efb\u52a8\u6001\u53d8\u5316\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u63cf\u8ff0\u76d1\u7763\u8005\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u7684\u4fe1\u4efb\u52a8\u6001\uff0c\u4e3a\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2510.09049", "categories": ["cs.AI", "cs.SE", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09049", "abs": "https://arxiv.org/abs/2510.09049", "authors": ["Joonghyuk Hahn", "Soohan Lim", "Yo-Sub Han"], "title": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction", "comment": "24 pages, 11 figures, 10 tables", "summary": "Predicting the complexity of source code is essential for software\ndevelopment and algorithm analysis. Recently, Baik et al. (2025) introduced\nCodeComplex for code time complexity prediction. The paper shows that LLMs\nwithout fine-tuning struggle with certain complexity classes. This suggests\nthat no single LLM excels at every class, but rather each model shows\nadvantages in certain classes. We propose MEC$^3$O, a multi-expert consensus\nsystem, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs\nto complexity classes based on their performance and provides them with\nclass-specialized instructions, turning them into experts. These experts engage\nin structured debates, and their predictions are integrated through a weighted\nconsensus mechanism. Our expertise assignments to LLMs effectively handle\nDegeneration-of-Thought, reducing reliance on a separate judge model, and\npreventing convergence to incorrect majority opinions. Experiments on\nCodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving\nat least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini\nin macro-F1 scores on average and demonstrates competitive on-par F1 scores to\nGPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of\nmulti-expert debates and weight consensus strategy to generate the final\npredictions. Our code and data is available at\nhttps://github.com/suhanmen/MECO.", "AI": {"tldr": "\u63d0\u51fa\u4e86MEC\u00b3O\u591a\u4e13\u5bb6\u5171\u8bc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06LLMs\u5206\u914d\u5230\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u5e76\u8ba9\u4e13\u5bb6\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u4f7f\u7528\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6574\u5408\u9884\u6d4b\uff0c\u5728\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u4e0a\u8868\u73b0\u5404\u5f02\uff0c\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u7c7b\u522b\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\u3002", "method": "MEC\u00b3O\u7cfb\u7edf\u5c06LLMs\u5206\u914d\u5230\u7279\u5b9a\u590d\u6742\u5ea6\u7c7b\u522b\uff0c\u63d0\u4f9b\u7c7b\u522b\u4e13\u4e1a\u5316\u6307\u4ee4\u4f7f\u5176\u6210\u4e3a\u4e13\u5bb6\uff0c\u7136\u540e\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u901a\u8fc7\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6574\u5408\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728CodeComplex\u6570\u636e\u96c6\u4e0a\uff0cMEC\u00b3O\u6bd4\u5f00\u6e90\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u548cmacro-F1\u5206\u6570\u81f3\u5c11\u63d0\u9ad810%\uff0c\u5728macro-F1\u5206\u6570\u4e0a\u5e73\u5747\u8d85\u8fc7GPT-4o-mini\uff0c\u4e0eGPT-4o\u548cGPT-o4-mini\u7684F1\u5206\u6570\u76f8\u5f53\u3002", "conclusion": "\u591a\u4e13\u5bb6\u8fa9\u8bba\u548c\u52a0\u6743\u5171\u8bc6\u7b56\u7565\u80fd\u6709\u6548\u751f\u6210\u6700\u7ec8\u9884\u6d4b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09483", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09483", "abs": "https://arxiv.org/abs/2510.09483", "authors": ["Lars Ohnemus", "Nils Hantke", "Max Wei\u00dfer", "Kai Furmans"], "title": "FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents", "comment": "submitted to the IEEE for possible publication; 8 pages, 3 figures, 1\n  table", "summary": "Dynamic Scene Graphs (DSGs) provide a structured representation of\nhierarchical, interconnected environments, but current approaches struggle to\ncapture stochastic dynamics, partial observability, and multi-agent activity.\nThese aspects are critical for embodied AI, where agents must act under\nuncertainty and delayed perception. We introduce FOGMACHINE , an open-source\nframework that fuses DSGs with discrete-event simulation to model object\ndynamics, agent observations, and interactions at scale. This setup enables the\nstudy of uncertainty propagation, planning under limited perception, and\nemergent multi-agent behavior. Experiments in urban scenarios illustrate\nrealistic temporal and spatial patterns while revealing the challenges of\nbelief estimation under sparse observations. By combining structured\nrepresentations with efficient simulation, FOGMACHINE establishes an effective\ntool for benchmarking, model training, and advancing embodied AI in complex,\nuncertain environments.", "AI": {"tldr": "FOGMACHINE\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5c06\u52a8\u6001\u573a\u666f\u56fe\u4e0e\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5efa\u6a21\u5bf9\u8c61\u52a8\u6001\u3001\u667a\u80fd\u4f53\u89c2\u5bdf\u548c\u4ea4\u4e92\uff0c\u652f\u6301\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u7814\u7a76\u548c\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u52a8\u6001\u573a\u666f\u56fe\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u968f\u673a\u52a8\u6001\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u591a\u667a\u80fd\u4f53\u6d3b\u52a8\uff0c\u800c\u8fd9\u4e9b\u5bf9\u4e8e\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u5ef6\u8fdf\u611f\u77e5\u4e0b\u884c\u52a8\u7684\u5177\u8eabAI\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5c06\u52a8\u6001\u573a\u666f\u56fe\u4e0e\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u878d\u5408\uff0c\u6784\u5efa\u53ef\u6269\u5c55\u6846\u67b6\u6765\u5efa\u6a21\u5bf9\u8c61\u52a8\u6001\u3001\u667a\u80fd\u4f53\u89c2\u5bdf\u548c\u4ea4\u4e92\u3002", "result": "\u5728\u57ce\u5e02\u573a\u666f\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u771f\u5b9e\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u6a21\u5f0f\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5728\u7a00\u758f\u89c2\u5bdf\u4e0b\u4fe1\u5ff5\u4f30\u8ba1\u7684\u6311\u6218\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u8868\u793a\u548c\u9ad8\u6548\u6a21\u62df\uff0cFOGMACHINE\u4e3a\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u57fa\u51c6\u6d4b\u8bd5\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u5177\u8eabAI\u53d1\u5c55\u5efa\u7acb\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.08979", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08979", "abs": "https://arxiv.org/abs/2510.08979", "authors": ["Yuki Nii", "Futa Waseda", "Ching-Chun Chang", "Isao Echizen"], "title": "Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation", "comment": null, "summary": "AI-based colorization has shown remarkable capability in generating realistic\ncolor images from grayscale inputs. However, it poses risks of copyright\ninfringement -- for example, the unauthorized colorization and resale of\nmonochrome manga and films. Despite these concerns, no effective method\ncurrently exists to prevent such misuse. To address this, we introduce the\nfirst defensive paradigm, Uncolorable Examples, which embed imperceptible\nperturbations into grayscale images to invalidate unauthorized colorization. To\nensure real-world applicability, we establish four criteria: effectiveness,\nimperceptibility, transferability, and robustness. Our method, Perception-Aware\nChroma-Restrictive Perturbation (PAChroma), generates Uncolorable Examples that\nmeet these four criteria by optimizing imperceptible perturbations with a\nLaplacian filter to preserve perceptual quality, and applying diverse input\ntransformations during optimization to enhance transferability across models\nand robustness against common post-processing (e.g., compression). Experiments\non ImageNet and Danbooru datasets demonstrate that PAChroma effectively\ndegrades colorization quality while maintaining the visual appearance. This\nwork marks the first step toward protecting visual content from illegitimate AI\ncolorization, paving the way for copyright-aware defenses in generative media.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9632\u5fa1AI\u975e\u6cd5\u4e0a\u8272\u7684\u65b9\u6cd5Uncolorable Examples\uff0c\u901a\u8fc7\u5411\u7070\u5ea6\u56fe\u50cf\u6dfb\u52a0\u4e0d\u53ef\u5bdf\u89c9\u7684\u6270\u52a8\u6765\u7834\u574f\u672a\u7ecf\u6388\u6743\u7684\u4e0a\u8272\u6548\u679c\u3002", "motivation": "AI\u4e0a\u8272\u6280\u672f\u5b58\u5728\u7248\u6743\u4fb5\u6743\u98ce\u9669\uff0c\u5982\u672a\u7ecf\u6388\u6743\u5bf9\u9ed1\u767d\u6f2b\u753b\u548c\u7535\u5f71\u8fdb\u884c\u4e0a\u8272\u5e76\u8f6c\u552e\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u9632\u62a4\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPAChroma\u65b9\u6cd5\uff0c\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u6ee4\u6ce2\u5668\u4f18\u5316\u4e0d\u53ef\u5bdf\u89c9\u7684\u6270\u52a8\u4ee5\u4fdd\u6301\u611f\u77e5\u8d28\u91cf\uff0c\u5e76\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5e94\u7528\u591a\u6837\u5316\u8f93\u5165\u53d8\u6362\u6765\u589e\u5f3a\u8de8\u6a21\u578b\u8fc1\u79fb\u6027\u548c\u5bf9\u540e\u5904\u7406\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728ImageNet\u548cDanbooru\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPAChroma\u80fd\u6709\u6548\u964d\u4f4e\u4e0a\u8272\u8d28\u91cf\u540c\u65f6\u4fdd\u6301\u89c6\u89c9\u5916\u89c2\u3002", "conclusion": "\u8fd9\u662f\u4fdd\u62a4\u89c6\u89c9\u5185\u5bb9\u514d\u53d7\u975e\u6cd5AI\u4e0a\u8272\u7684\u9996\u4e2a\u9632\u5fa1\u65b9\u6cd5\uff0c\u4e3a\u751f\u6210\u5a92\u4f53\u4e2d\u7684\u7248\u6743\u4fdd\u62a4\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.08840", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08840", "abs": "https://arxiv.org/abs/2510.08840", "authors": ["Thai-Hoang Pham", "Jiayuan Chen", "Seungyeon Lee", "Yuanlong Wang", "Sayoko Moroi", "Xueru Zhang", "Ping Zhang"], "title": "The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective", "comment": "Accepted at NeurIPS 2025", "summary": "As machine learning (ML) algorithms are increasingly used in medical image\nanalysis, concerns have emerged about their potential biases against certain\nsocial groups. Although many approaches have been proposed to ensure the\nfairness of ML models, most existing works focus only on medical image\ndiagnosis tasks, such as image classification and segmentation, and overlooked\nprognosis scenarios, which involve predicting the likely outcome or progression\nof a medical condition over time. To address this gap, we introduce FairTTE,\nthe first comprehensive framework for assessing fairness in time-to-event (TTE)\nprediction in medical imaging. FairTTE encompasses a diverse range of imaging\nmodalities and TTE outcomes, integrating cutting-edge TTE prediction and\nfairness algorithms to enable systematic and fine-grained analysis of fairness\nin medical image prognosis. Leveraging causal analysis techniques, FairTTE\nuncovers and quantifies distinct sources of bias embedded within medical\nimaging datasets. Our large-scale evaluation reveals that bias is pervasive\nacross different imaging modalities and that current fairness methods offer\nlimited mitigation. We further demonstrate a strong association between\nunderlying bias sources and model disparities, emphasizing the need for\nholistic approaches that target all forms of bias. Notably, we find that\nfairness becomes increasingly difficult to maintain under distribution shifts,\nunderscoring the limitations of existing solutions and the pressing need for\nmore robust, equitable prognostic models.", "AI": {"tldr": "FairTTE\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u533b\u5b66\u5f71\u50cf\u4e2d\u65f6\u95f4\u5230\u4e8b\u4ef6\u9884\u6d4b\u516c\u5e73\u6027\u7684\u7efc\u5408\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6210\u50cf\u6a21\u6001\u4e2d\u666e\u904d\u5b58\u5728\u7684\u504f\u89c1\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u516c\u5e73\u6027\u65b9\u6cd5\u7f13\u89e3\u6548\u679c\u6709\u9650\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5728\u533b\u5b66\u5f71\u50cf\u5206\u6790\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4eba\u4eec\u62c5\u5fe7\u7b97\u6cd5\u53ef\u80fd\u5bf9\u67d0\u4e9b\u793e\u4f1a\u7fa4\u4f53\u4ea7\u751f\u504f\u89c1\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u533b\u5b66\u5f71\u50cf\u8bca\u65ad\u4efb\u52a1\uff0c\u800c\u5ffd\u89c6\u4e86\u9884\u540e\u573a\u666f\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faFairTTE\u6846\u67b6\uff0c\u6574\u5408\u524d\u6cbf\u7684\u65f6\u95f4\u5230\u4e8b\u4ef6\u9884\u6d4b\u548c\u516c\u5e73\u6027\u7b97\u6cd5\uff0c\u5229\u7528\u56e0\u679c\u5206\u6790\u6280\u672f\u8bc6\u522b\u548c\u91cf\u5316\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e2d\u5d4c\u5165\u7684\u4e0d\u540c\u504f\u89c1\u6765\u6e90\u3002", "result": "\u5927\u89c4\u6a21\u8bc4\u4f30\u663e\u793a\u504f\u89c1\u5728\u4e0d\u540c\u6210\u50cf\u6a21\u6001\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u73b0\u6709\u516c\u5e73\u6027\u65b9\u6cd5\u7f13\u89e3\u6548\u679c\u6709\u9650\u3002\u516c\u5e73\u6027\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u96be\u4ee5\u7ef4\u6301\uff0c\u504f\u89c1\u6765\u6e90\u4e0e\u6a21\u578b\u5dee\u5f02\u4e4b\u95f4\u5b58\u5728\u5f3a\u5173\u8054\u3002", "conclusion": "\u9700\u8981\u9488\u5bf9\u6240\u6709\u5f62\u5f0f\u504f\u89c1\u7684\u6574\u4f53\u65b9\u6cd5\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8feb\u5207\u9700\u8981\u66f4\u7a33\u5065\u3001\u516c\u5e73\u7684\u9884\u540e\u6a21\u578b\u3002"}}
{"id": "2510.08776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08776", "abs": "https://arxiv.org/abs/2510.08776", "authors": ["Kimaya Basu", "Savi Kolari", "Allison Yu"], "title": "Measuring Moral LLM Responses in Multilingual Capacities", "comment": "10 pages, 5 figures; referenced articles: arXiv:2303.08774,\n  arXiv:2303.12528, arXiv:2308.14132, arXiv:2505.12201, arXiv:2406.04428,\n  arXiv:2407.02273, arXiv:2404.01268, arXiv:2502.09747, arXiv:2507.13474,\n  arXiv:2505.21479, arXiv:2306.05685", "summary": "With LLM usage becoming widespread across countries, languages, and humanity\nmore broadly, the need to understand and guardrail their multilingual responses\nincreases. Large-scale datasets for testing and benchmarking have been created\nto evaluate and facilitate LLM responses across multiple dimensions. In this\nstudy, we evaluate the responses of frontier and leading open-source models in\nfive dimensions across low and high-resource languages to measure LLM accuracy\nand consistency across multilingual contexts. We evaluate the responses using a\nfive-point grading rubric and a judge LLM. Our study shows that GPT-5 performed\nthe best on average in each category, while other models displayed more\ninconsistency across language and category. Most notably, in the Consent &\nAutonomy and Harm Prevention & Safety categories, GPT scored the highest with\naverages of 3.56 and 4.73, while Gemini 2.5 Pro scored the lowest with averages\nof 1.39 and 1.98, respectively. These findings emphasize the need for further\ntesting on how linguistic shifts impact LLM responses across various categories\nand improvement in these areas.", "AI": {"tldr": "\u8bc4\u4f30\u524d\u6cbf\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u591a\u8bed\u8a00\u54cd\u5e94\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u53d1\u73b0GPT-5\u8868\u73b0\u6700\u4f73\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u7c7b\u522b\u4e2d\u8868\u73b0\u4e0d\u4e00\u81f4\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5168\u7403\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u7406\u89e3\u548c\u4fdd\u969c\u5176\u591a\u8bed\u8a00\u54cd\u5e94\u7684\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u8bed\u8a00\u8d44\u6e90\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u4e94\u70b9\u8bc4\u5206\u6807\u51c6\u548c\u8bc4\u5224\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u8bc4\u4f30\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u54cd\u5e94\u3002", "result": "GPT-5\u5728\u6240\u6709\u7c7b\u522b\u4e2d\u5e73\u5747\u8868\u73b0\u6700\u4f73\uff0c\u7279\u522b\u662f\u5728\u540c\u610f\u4e0e\u81ea\u4e3b\u6743\uff083.56\u5206\uff09\u548c\u4f24\u5bb3\u9884\u9632\u4e0e\u5b89\u5168\uff084.73\u5206\uff09\u7c7b\u522b\u4e2d\u5f97\u5206\u6700\u9ad8\uff1bGemini 2.5 Pro\u8868\u73b0\u6700\u5dee\uff0c\u76f8\u5e94\u5f97\u5206\u4e3a1.39\u548c1.98\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u8bed\u8a00\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u522b\u4e2d\u7684\u54cd\u5e94\uff0c\u5e76\u6539\u8fdb\u8fd9\u4e9b\u9886\u57df\u7684\u6027\u80fd\u3002"}}
{"id": "2510.08924", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08924", "abs": "https://arxiv.org/abs/2510.08924", "authors": ["Jonah Botvinick-Greenhouse", "Wael H. Ali", "Mouhacine Benosman", "Saviz Mowlavi"], "title": "AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition", "comment": null, "summary": "We introduce adaptive-basis physics-informed neural networks (AB-PINNs), a\nnovel approach to domain decomposition for training PINNs in which existing\nsubdomains dynamically adapt to the intrinsic features of the unknown solution.\nDrawing inspiration from classical mesh refinement techniques, we also modify\nthe domain decomposition on-the-fly throughout training by introducing new\nsubdomains in regions of high residual loss, thereby providing additional\nexpressive power where the solution of the differential equation is challenging\nto represent. Our flexible approach to domain decomposition is well-suited for\nmultiscale problems, as different subdomains can learn to capture different\nscales of the underlying solution. Moreover, the ability to introduce new\nsubdomains during training helps prevent convergence to unwanted local minima\nand can reduce the need for extensive hyperparameter tuning compared to static\ndomain decomposition approaches. Throughout, we present comprehensive numerical\nresults which demonstrate the effectiveness of AB-PINNs at solving a variety of\ncomplex multiscale partial differential equations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u57fa\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08AB-PINNs\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u5b50\u57df\u4ee5\u9002\u5e94\u89e3\u5185\u5728\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9ad8\u6b8b\u5dee\u533a\u57df\u5f15\u5165\u65b0\u5b50\u57df\u6765\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\uff0c\u7279\u522b\u9002\u5408\u591a\u5c3a\u5ea6\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfPINNs\u5728\u5904\u7406\u591a\u5c3a\u5ea6\u95ee\u9898\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9759\u6001\u57df\u5206\u89e3\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8d85\u53c2\u6570\u8c03\u4f18\u4e14\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u5c0f\u503c\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u9002\u5e94\u89e3\u7279\u5f81\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u7f51\u683c\u7ec6\u5316\u6280\u672f\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u4fee\u6539\u57df\u5206\u89e3\uff1a\u73b0\u6709\u5b50\u57df\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u540c\u65f6\u5728\u9ad8\u6b8b\u5dee\u533a\u57df\u5f15\u5165\u65b0\u5b50\u57df\uff0c\u4e0d\u540c\u5b50\u57df\u53ef\u4ee5\u5b66\u4e60\u6355\u6349\u89e3\u7684\u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660eAB-PINNs\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5404\u79cd\u590d\u6742\u591a\u5c3a\u5ea6\u504f\u5fae\u5206\u65b9\u7a0b\uff0c\u76f8\u6bd4\u9759\u6001\u57df\u5206\u89e3\u65b9\u6cd5\u51cf\u5c11\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u9700\u6c42\u5e76\u9632\u6b62\u4e86\u5c40\u90e8\u6700\u5c0f\u503c\u6536\u655b\u3002", "conclusion": "AB-PINNs\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u57df\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5b50\u57df\u9002\u5e94\u548c\u5f15\u5165\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86PINNs\u5728\u591a\u5c3a\u5ea6\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u8d1f\u62c5\u5e76\u6539\u5584\u4e86\u6536\u655b\u6027\u3002"}}
{"id": "2510.09001", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09001", "abs": "https://arxiv.org/abs/2510.09001", "authors": ["Jingyu Zhou", "Lu Ma", "Hao Liang", "Chengyu Shen", "Bin Cui", "Wentao Zhang"], "title": "DARO: Difficulty-Aware Reweighting Policy Optimization", "comment": null, "summary": "Recent advances in large language models (LLMs) have shown that reasoning\nability can be significantly enhanced through Reinforcement Learning with\nVerifiable Rewards (RLVR). Group Relative Policy Optimization (GRPO) has\nemerged as the de facto approach for RLVR, inspiring numerous variants.\nHowever, our mathematical analysis reveals that these methods are fundamentally\nweighted variations of GRPO. We provide a unified view, demonstrating that\ntheir reliance on static or overly simplistic weighting schemes tied to sample\ndifficulty prevents adaptation to a model's evolving capabilities. This creates\na significant loss scale issue, where training disproportionately focuses on\ncertain difficulty levels at the expense of others, hindering overall\nperformance. To address these limitations, we introduce\n\\textbf{Difficulty-Aware Reweighting Policy Optimization (DARO)}, a method that\ndynamically adjusts the loss contribution of each difficulty group based on the\nmodel's learning state. Extensive experiments on Qwen2.5-Math-1.5B,\nQwen2.5-Math-7B, and Llama3.1-8B show that DARO outperforms four leading\nbaselines across six math benchmarks, achieving significantly faster\nconvergence and superior final performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DARO\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e0d\u540c\u96be\u5ea6\u7ec4\u7684\u635f\u5931\u8d21\u732e\u6765\u89e3\u51b3\u73b0\u6709RLVR\u65b9\u6cd5\u4e2d\u7684\u635f\u5931\u5c3a\u5ea6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eGRPO\u7684RLVR\u65b9\u6cd5\u4f7f\u7528\u9759\u6001\u6216\u8fc7\u4e8e\u7b80\u5316\u7684\u6743\u91cd\u65b9\u6848\uff0c\u65e0\u6cd5\u9002\u5e94\u6a21\u578b\u80fd\u529b\u7684\u53d8\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u5728\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u4e0a\u5931\u8861\uff0c\u963b\u788d\u6574\u4f53\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51faDARO\u65b9\u6cd5\uff0c\u6839\u636e\u6a21\u578b\u5b66\u4e60\u72b6\u6001\u52a8\u6001\u8c03\u6574\u6bcf\u4e2a\u96be\u5ea6\u7ec4\u7684\u635f\u5931\u8d21\u732e\uff0c\u89e3\u51b3\u635f\u5931\u5c3a\u5ea6\u95ee\u9898\u3002", "result": "\u5728Qwen2.5-Math-1.5B\u3001Qwen2.5-Math-7B\u548cLlama3.1-8B\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDARO\u5728\u516d\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u56db\u4e2a\u9886\u5148\u57fa\u7ebf\uff0c\u6536\u655b\u901f\u5ea6\u66f4\u5feb\u4e14\u6700\u7ec8\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "DARO\u901a\u8fc7\u52a8\u6001\u91cd\u52a0\u6743\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86RLVR\u8bad\u7ec3\u4e2d\u7684\u635f\u5931\u5c3a\u5ea6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.09023", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.09023", "abs": "https://arxiv.org/abs/2510.09023", "authors": ["Milad Nasr", "Nicholas Carlini", "Chawin Sitawarin", "Sander V. Schulhoff", "Jamie Hayes", "Michael Ilie", "Juliette Pluto", "Shuang Song", "Harsh Chaudhari", "Ilia Shumailov", "Abhradeep Thakurta", "Kai Yuanqing Xiao", "Andreas Terzis", "Florian Tram\u00e8r"], "title": "The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections", "comment": null, "summary": "How should we evaluate the robustness of language model defenses? Current\ndefenses against jailbreaks and prompt injections (which aim to prevent an\nattacker from eliciting harmful knowledge or remotely triggering malicious\nactions, respectively) are typically evaluated either against a static set of\nharmful attack strings, or against computationally weak optimization methods\nthat were not designed with the defense in mind. We argue that this evaluation\nprocess is flawed.\n  Instead, we should evaluate defenses against adaptive attackers who\nexplicitly modify their attack strategy to counter a defense's design while\nspending considerable resources to optimize their objective. By systematically\ntuning and scaling general optimization techniques-gradient descent,\nreinforcement learning, random search, and human-guided exploration-we bypass\n12 recent defenses (based on a diverse set of techniques) with attack success\nrate above 90% for most; importantly, the majority of defenses originally\nreported near-zero attack success rates. We believe that future defense work\nmust consider stronger attacks, such as the ones we describe, in order to make\nreliable and convincing claims of robustness.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u9632\u5fa1\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u5e94\u4f7f\u7528\u81ea\u9002\u5e94\u653b\u51fb\u8005\u8fdb\u884c\u6d4b\u8bd5\u3002\u4f5c\u8005\u901a\u8fc7\u7cfb\u7edf\u4f18\u5316\u6280\u672f\u6210\u529f\u7ed5\u8fc7\u4e8612\u79cd\u6700\u65b0\u9632\u5fa1\u65b9\u6cd5\uff0c\u5927\u591a\u6570\u9632\u5fa1\u7684\u653b\u51fb\u6210\u529f\u7387\u4ece\u63a5\u8fd1\u96f6\u63d0\u5347\u523090%\u4ee5\u4e0a\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u9632\u5fa1\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u901a\u5e38\u53ea\u9488\u5bf9\u9759\u6001\u653b\u51fb\u96c6\u6216\u5f31\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u6d4b\u8bd5\uff0c\u65e0\u6cd5\u771f\u5b9e\u53cd\u6620\u9632\u5fa1\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u81ea\u9002\u5e94\u653b\u51fb\u7b56\u7565\uff0c\u7cfb\u7edf\u8c03\u6574\u548c\u6269\u5c55\u901a\u7528\u4f18\u5316\u6280\u672f\uff0c\u5305\u62ec\u68af\u5ea6\u4e0b\u964d\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u968f\u673a\u641c\u7d22\u548c\u4eba\u5de5\u5f15\u5bfc\u63a2\u7d22\u3002", "result": "\u6210\u529f\u7ed5\u8fc7\u4e8612\u79cd\u57fa\u4e8e\u4e0d\u540c\u6280\u672f\u7684\u6700\u65b0\u9632\u5fa1\u65b9\u6cd5\uff0c\u5927\u591a\u6570\u9632\u5fa1\u7684\u653b\u51fb\u6210\u529f\u7387\u4ece\u63a5\u8fd1\u96f6\u63d0\u5347\u523090%\u4ee5\u4e0a\u3002", "conclusion": "\u672a\u6765\u7684\u9632\u5fa1\u5de5\u4f5c\u5fc5\u987b\u8003\u8651\u66f4\u5f3a\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5982\u672c\u6587\u6240\u8ff0\uff0c\u624d\u80fd\u505a\u51fa\u53ef\u9760\u4e14\u4ee4\u4eba\u4fe1\u670d\u7684\u9c81\u68d2\u6027\u58f0\u660e\u3002"}}
{"id": "2510.09041", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09041", "abs": "https://arxiv.org/abs/2510.09041", "authors": ["Junchao Fan", "Xiaolin Chang"], "title": "Robust Driving Control for Autonomous Vehicles: An Intelligent General-sum Constrained Adversarial Reinforcement Learning Approach", "comment": null, "summary": "Deep reinforcement learning (DRL) has demonstrated remarkable success in\ndeveloping autonomous driving policies. However, its vulnerability to\nadversarial attacks remains a critical barrier to real-world deployment.\nAlthough existing robust methods have achieved success, they still suffer from\nthree key issues: (i) these methods are trained against myopic adversarial\nattacks, limiting their abilities to respond to more strategic threats, (ii)\nthey have trouble causing truly safety-critical events (e.g., collisions), but\ninstead often result in minor consequences, and (iii) these methods can\nintroduce learning instability and policy drift during training due to the lack\nof robust constraints. To address these issues, we propose Intelligent\nGeneral-sum Constrained Adversarial Reinforcement Learning (IGCARL), a novel\nrobust autonomous driving approach that consists of a strategic targeted\nadversary and a robust driving agent. The strategic targeted adversary is\ndesigned to leverage the temporal decision-making capabilities of DRL to\nexecute strategically coordinated multi-step attacks. In addition, it\nexplicitly focuses on inducing safety-critical events by adopting a general-sum\nobjective. The robust driving agent learns by interacting with the adversary to\ndevelop a robust autonomous driving policy against adversarial attacks. To\nensure stable learning in adversarial environments and to mitigate policy drift\ncaused by attacks, the agent is optimized under a constrained formulation.\nExtensive experiments show that IGCARL improves the success rate by at least\n27.9\\% over state-of-the-art methods, demonstrating superior robustness to\nadversarial attacks and enhancing the safety and reliability of DRL-based\nautonomous driving.", "AI": {"tldr": "\u63d0\u51faIGCARL\u65b9\u6cd5\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u5bf9\u6297\u653b\u51fb\u8106\u5f31\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u6218\u7565\u5bf9\u6297\u8005\u548c\u7ea6\u675f\u4f18\u5316\u63d0\u5347\u9c81\u68d2\u6027", "motivation": "\u73b0\u6709\u9c81\u68d2\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u5bf9\u6297\u77ed\u89c6\u653b\u51fb\u3001\u96be\u4ee5\u5f15\u53d1\u5b89\u5168\u5173\u952e\u4e8b\u4ef6\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u5bfc\u81f4\u7b56\u7565\u6f02\u79fb", "method": "IGCARL\u5305\u542b\u6218\u7565\u76ee\u6807\u5bf9\u6297\u8005\u548c\u9c81\u68d2\u9a7e\u9a76\u4ee3\u7406\uff0c\u5bf9\u6297\u8005\u6267\u884c\u6218\u7565\u534f\u8c03\u591a\u6b65\u653b\u51fb\uff0c\u4ee3\u7406\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u5b66\u4e60\u9c81\u68d2\u7b56\u7565", "result": "\u5b9e\u9a8c\u663e\u793aIGCARL\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u6210\u529f\u7387\u63d0\u9ad8\u81f3\u5c1127.9%\uff0c\u663e\u8457\u589e\u5f3a\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027", "conclusion": "IGCARL\u80fd\u6709\u6548\u63d0\u5347DRL\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u89e3\u51b3\u5bf9\u6297\u653b\u51fb\u8106\u5f31\u6027\u95ee\u9898"}}
{"id": "2510.09048", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09048", "abs": "https://arxiv.org/abs/2510.09048", "authors": ["Jose Tupayachi", "Mustafa C. Camur", "Kevin Heaslip", "Xueping Li"], "title": "Spatio-Temporal Graph Convolutional Networks for EV Charging Demand Forecasting Using Real-World Multi-Modal Data Integration", "comment": null, "summary": "Transportation remains a major contributor to greenhouse gas emissions,\nhighlighting the urgency of transitioning toward sustainable alternatives such\nas electric vehicles (EVs). Yet, uneven spatial distribution and irregular\nutilization of charging infrastructure create challenges for both power grid\nstability and investment planning. This study introduces TW-GCN, a\nspatio-temporal forecasting framework that combines Graph Convolutional\nNetworks with temporal architectures to predict EV charging demand in\nTennessee, United States (U.S.). We utilize real-world traffic flows, weather\nconditions, and proprietary data provided by one of the largest EV\ninfrastructure company in the U.S. to capture both spatial dependencies and\ntemporal dynamics. Extensive experiments across varying lag horizons,\nclustering strategies, and sequence lengths reveal that mid-horizon (3-hour)\nforecasts achieve the best balance between responsiveness and stability, with\n1DCNN consistently outperforming other temporal models. Regional analysis shows\ndisparities in predictive accuracy across East, Middle, and West Tennessee,\nreflecting how station density, population, and local demand variability shape\nmodel performance. The proposed TW-GCN framework advances the integration of\ndata-driven intelligence into EV infrastructure planning, supporting both\nsustainable mobility transitions and resilient grid management.", "AI": {"tldr": "TW-GCN\u6846\u67b6\u7ed3\u5408\u56fe\u5377\u79ef\u7f51\u7edc\u548c\u65f6\u5e8f\u67b6\u6784\uff0c\u9884\u6d4b\u7f8e\u56fd\u7530\u7eb3\u897f\u5dde\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\uff0c3\u5c0f\u65f6\u4e2d\u671f\u9884\u6d4b\u6548\u679c\u6700\u4f73\uff0c1DCNN\u8868\u73b0\u6700\u4f18\uff0c\u533a\u57df\u5206\u6790\u663e\u793a\u9884\u6d4b\u7cbe\u5ea6\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u4ea4\u901a\u662f\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u4e3b\u8981\u6765\u6e90\uff0c\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7a7a\u95f4\u5206\u5e03\u4e0d\u5747\u548c\u4f7f\u7528\u4e0d\u89c4\u5f8b\u7ed9\u7535\u7f51\u7a33\u5b9a\u6027\u548c\u6295\u8d44\u89c4\u5212\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51faTW-GCN\u65f6\u7a7a\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u56fe\u5377\u79ef\u7f51\u7edc\u548c\u65f6\u5e8f\u67b6\u6784\uff0c\u5229\u7528\u771f\u5b9e\u4ea4\u901a\u6d41\u91cf\u3001\u5929\u6c14\u6761\u4ef6\u548c\u4e13\u6709\u6570\u636e\u6355\u6349\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u65f6\u5e8f\u52a8\u6001\u3002", "result": "3\u5c0f\u65f6\u4e2d\u671f\u9884\u6d4b\u5728\u54cd\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff0c1DCNN\u6a21\u578b\u8868\u73b0\u6700\u4f18\uff1b\u533a\u57df\u5206\u6790\u663e\u793a\u4e1c\u3001\u4e2d\u3001\u897f\u7530\u7eb3\u897f\u5dde\u9884\u6d4b\u7cbe\u5ea6\u5b58\u5728\u5dee\u5f02\uff0c\u53d7\u7ad9\u70b9\u5bc6\u5ea6\u3001\u4eba\u53e3\u548c\u9700\u6c42\u53d8\u5316\u5f71\u54cd\u3002", "conclusion": "TW-GCN\u6846\u67b6\u63a8\u8fdb\u4e86\u6570\u636e\u9a71\u52a8\u667a\u80fd\u5728\u7535\u52a8\u6c7d\u8f66\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u4e2d\u7684\u6574\u5408\uff0c\u652f\u6301\u53ef\u6301\u7eed\u4ea4\u901a\u8f6c\u578b\u548c\u5f39\u6027\u7535\u7f51\u7ba1\u7406\u3002"}}
{"id": "2510.09243", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09243", "abs": "https://arxiv.org/abs/2510.09243", "authors": ["Giacomo Gonella", "Gian Maria Campedelli", "Stefano Menini", "Marco Guerini"], "title": "CrisiText: A dataset of warning messages for LLM training in emergency communication", "comment": null, "summary": "Effectively identifying threats and mitigating their potential damage during\ncrisis situations, such as natural disasters or violent attacks, is paramount\nfor safeguarding endangered individuals. To tackle these challenges, AI has\nbeen used in assisting humans in emergency situations. Still, the use of NLP\ntechniques remains limited and mostly focuses on classification tasks. The\nsignificant potential of timely warning message generation using NLG\narchitectures, however, has been largely overlooked. In this paper we present\nCrisiText, the first large-scale dataset for the generation of warning messages\nacross 13 different types of crisis scenarios. The dataset contains more than\n400,000 warning messages (spanning almost 18,000 crisis situations) aimed at\nassisting civilians during and after such events. To generate the dataset, we\nstarted from existing crisis descriptions and created chains of events related\nto the scenarios. Each event was then paired with a warning message. The\ngenerations follow experts' written guidelines to ensure correct terminology\nand factuality of their suggestions. Additionally, each message is accompanied\nby three suboptimal warning types to allow for the study of different NLG\napproaches. To this end, we conducted a series of experiments comparing\nsupervised fine-tuning setups with preference alignment, zero-shot, and\nfew-shot approaches. We further assessed model performance in\nout-of-distribution scenarios and evaluated the effectiveness of an automatic\npost-editor.", "AI": {"tldr": "CrisiText\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u5371\u673a\u9884\u8b66\u6d88\u606f\u751f\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b13\u79cd\u5371\u673a\u573a\u666f\u768440\u4e07\u6761\u9884\u8b66\u6d88\u606f\uff0c\u7528\u4e8e\u7814\u7a76NLG\u6280\u672f\u5728\u5371\u673a\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5728\u81ea\u7136\u707e\u5bb3\u6216\u66b4\u529b\u88ad\u51fb\u7b49\u5371\u673a\u60c5\u51b5\u4e0b\uff0c\u53ca\u65f6\u751f\u6210\u6709\u6548\u7684\u9884\u8b66\u6d88\u606f\u5bf9\u4fdd\u62a4\u6c11\u4f17\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524dNLP\u6280\u672f\u5728\u6b64\u9886\u57df\u7684\u5e94\u7528\u4e3b\u8981\u5c40\u9650\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u9884\u8b66\u6d88\u606f\u751f\u6210\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u6316\u6398\u3002", "method": "\u4ece\u73b0\u6709\u5371\u673a\u63cf\u8ff0\u51fa\u53d1\u521b\u5efa\u4e8b\u4ef6\u94fe\uff0c\u4e3a\u6bcf\u4e2a\u4e8b\u4ef6\u751f\u6210\u9884\u8b66\u6d88\u606f\uff0c\u9075\u5faa\u4e13\u5bb6\u6307\u5357\u786e\u4fdd\u672f\u8bed\u51c6\u786e\u6027\u548c\u4e8b\u5b9e\u6027\u3002\u540c\u65f6\u4e3a\u6bcf\u6761\u6d88\u606f\u63d0\u4f9b\u4e09\u79cd\u6b21\u4f18\u9884\u8b66\u7c7b\u578b\uff0c\u7528\u4e8e\u6bd4\u8f83\u76d1\u7763\u5fae\u8c03\u3001\u504f\u597d\u5bf9\u9f50\u3001\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u7b49\u4e0d\u540cNLG\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b40\u4e07\u6761\u9884\u8b66\u6d88\u606f\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8986\u76d6\u8fd11.8\u4e07\u4e2a\u5371\u673a\u60c5\u5883\u3002\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u591a\u79cdNLG\u65b9\u6cd5\u5728\u5371\u673a\u9884\u8b66\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "CrisiText\u6570\u636e\u96c6\u586b\u8865\u4e86\u5371\u673a\u9884\u8b66\u6d88\u606f\u751f\u6210\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u5371\u673a\u7ba1\u7406AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u5c55\u793a\u4e86NLG\u6280\u672f\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.09159", "categories": ["cs.LG", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.09159", "abs": "https://arxiv.org/abs/2510.09159", "authors": ["Tianyi Chen", "Mingcheng Zhu", "Zhiyao Luo", "Tingting Zhu"], "title": "Cross-Representation Benchmarking in Time-Series Electronic Health Records for Clinical Outcome Prediction", "comment": null, "summary": "Electronic Health Records (EHRs) enable deep learning for clinical\npredictions, but the optimal method for representing patient data remains\nunclear due to inconsistent evaluation practices. We present the first\nsystematic benchmark to compare EHR representation methods, including\nmultivariate time-series, event streams, and textual event streams for LLMs.\nThis benchmark standardises data curation and evaluation across two distinct\nclinical settings: the MIMIC-IV dataset for ICU tasks (mortality, phenotyping)\nand the EHRSHOT dataset for longitudinal care (30-day readmission, 1-year\npancreatic cancer). For each paradigm, we evaluate appropriate modelling\nfamilies--including Transformers, MLP, LSTMs and Retain for time-series, CLMBR\nand count-based models for event streams, 8-20B LLMs for textual streams--and\nanalyse the impact of feature pruning based on data missingness. Our\nexperiments reveal that event stream models consistently deliver the strongest\nperformance. Pre-trained models like CLMBR are highly sample-efficient in\nfew-shot settings, though simpler count-based models can be competitive given\nsufficient data. Furthermore, we find that feature selection strategies must be\nadapted to the clinical setting: pruning sparse features improves ICU\npredictions, while retaining them is critical for longitudinal tasks. Our\nresults, enabled by a unified and reproducible pipeline, provide practical\nguidance for selecting EHR representations based on the clinical context and\ndata regime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u57fa\u51c6\u6765\u6bd4\u8f83EHR\u8868\u793a\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e8b\u4ef6\u6d41\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5c11\u6837\u672c\u573a\u666f\u4e0b\u6548\u7387\u9ad8\uff0c\u7279\u5f81\u9009\u62e9\u7b56\u7565\u9700\u6839\u636e\u4e34\u5e8a\u573a\u666f\u8c03\u6574\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u652f\u6301\u4e34\u5e8a\u9884\u6d4b\u7684\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\uff0c\u4f46\u7531\u4e8e\u8bc4\u4f30\u5b9e\u8df5\u4e0d\u4e00\u81f4\uff0c\u60a3\u8005\u6570\u636e\u7684\u6700\u4f73\u8868\u793a\u65b9\u6cd5\u4ecd\u4e0d\u660e\u786e\u3002", "method": "\u5efa\u7acb\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5728MIMIC-IV\u548cEHRSHOT\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83\u4e09\u79cdEHR\u8868\u793a\u8303\u5f0f\uff1a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u3001\u4e8b\u4ef6\u6d41\u548c\u6587\u672c\u4e8b\u4ef6\u6d41\uff0c\u8bc4\u4f30\u5305\u62ecTransformer\u3001MLP\u3001LSTM\u3001Retain\u3001CLMBR\u3001\u8ba1\u6570\u6a21\u578b\u548cLLM\u7b49\u591a\u79cd\u6a21\u578b\u3002", "result": "\u4e8b\u4ef6\u6d41\u6a21\u578b\u59cb\u7ec8\u8868\u73b0\u6700\u4f73\uff1b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5c11\u6837\u672c\u573a\u666f\u4e0b\u6837\u672c\u6548\u7387\u9ad8\uff1b\u7279\u5f81\u9009\u62e9\u7b56\u7565\u9700\u9002\u5e94\u4e34\u5e8a\u573a\u666f\uff1aICU\u9884\u6d4b\u4e2d\u4fee\u526a\u7a00\u758f\u7279\u5f81\u6709\u76ca\uff0c\u800c\u7eb5\u5411\u4efb\u52a1\u4e2d\u4fdd\u7559\u8fd9\u4e9b\u7279\u5f81\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u53ef\u590d\u73b0\u7684\u6d41\u7a0b\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u57fa\u4e8e\u4e34\u5e8a\u73af\u5883\u548c\u6570\u636e\u60c5\u51b5\u9009\u62e9EHR\u8868\u793a\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.09537", "categories": ["cs.CV", "I.4.0"], "pdf": "https://arxiv.org/pdf/2510.09537", "abs": "https://arxiv.org/abs/2510.09537", "authors": ["Arthur Bizzi", "Matias Grynberg", "Vitor Matias", "Daniel Perazzo", "Jo\u00e3o Paulo Lima", "Luiz Velho", "Nuno Gon\u00e7alves", "Jo\u00e3o Pereira", "Guilherme Schardong", "Tiago Novello"], "title": "FLOWING: Implicit Neural Flows for Structure-Preserving Morphing", "comment": "10 pages main paper; 9 pages references and appendix", "summary": "Morphing is a long-standing problem in vision and computer graphics,\nrequiring a time-dependent warping for feature alignment and a blending for\nsmooth interpolation. Recently, multilayer perceptrons (MLPs) have been\nexplored as implicit neural representations (INRs) for modeling such\ndeformations, due to their meshlessness and differentiability; however,\nextracting coherent and accurate morphings from standard MLPs typically relies\non costly regularizations, which often lead to unstable training and prevent\neffective feature alignment. To overcome these limitations, we propose FLOWING\n(FLOW morphING), a framework that recasts warping as the construction of a\ndifferential vector flow, naturally ensuring continuity, invertibility, and\ntemporal coherence by encoding structural flow properties directly into the\nnetwork architectures. This flow-centric approach yields principled and stable\ntransformations, enabling accurate and structure-preserving morphing of both 2D\nimages and 3D shapes. Extensive experiments across a range of applications -\nincluding face and image morphing, as well as Gaussian Splatting morphing -\nshow that FLOWING achieves state-of-the-art morphing quality with faster\nconvergence. Code and pretrained models are available at\nhttp://schardong.github.io/flowing.", "AI": {"tldr": "FLOWING\u662f\u4e00\u4e2a\u57fa\u4e8e\u5fae\u5206\u5411\u91cf\u6d41\u7684\u53d8\u5f62\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u53d8\u5f62\u5efa\u6a21\u4e3a\u6d41\u6784\u5efa\uff0c\u786e\u4fdd\u8fde\u7eed\u6027\u3001\u53ef\u9006\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u57282D\u56fe\u50cf\u548c3D\u5f62\u72b6\u53d8\u5f62\u4e2d\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u591a\u5c42\u611f\u77e5\u673a\u5728\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u4e2d\u5efa\u6a21\u53d8\u5f62\u65f6\uff0c\u9700\u8981\u6602\u8d35\u7684\u6b63\u5219\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u4e14\u7279\u5f81\u5bf9\u9f50\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5c06\u53d8\u5f62\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5fae\u5206\u5411\u91cf\u6d41\u7684\u6784\u5efa\uff0c\u5c06\u7ed3\u6784\u6d41\u5c5e\u6027\u76f4\u63a5\u7f16\u7801\u5230\u7f51\u7edc\u67b6\u6784\u4e2d\uff0c\u786e\u4fdd\u53d8\u6362\u7684\u8fde\u7eed\u6027\u548c\u53ef\u9006\u6027\u3002", "result": "\u5728\u9762\u90e8\u53d8\u5f62\u3001\u56fe\u50cf\u53d8\u5f62\u548c\u9ad8\u65af\u6cfc\u6e85\u53d8\u5f62\u7b49\u5e94\u7528\u4e2d\uff0cFLOWING\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u53d8\u5f62\u8d28\u91cf\uff0c\u4e14\u6536\u655b\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "\u57fa\u4e8e\u6d41\u7684\u53d8\u5f62\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u539f\u5219\u6027\u5f3a\u4e14\u7a33\u5b9a\u7684\u53d8\u6362\uff0c\u5b9e\u73b0\u51c6\u786e\u4e14\u7ed3\u6784\u4fdd\u6301\u7684\u53d8\u5f62\u6548\u679c\u3002"}}
{"id": "2510.09434", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09434", "abs": "https://arxiv.org/abs/2510.09434", "authors": ["Xixi Wang", "Jordanka Kovaceva", "Miguel Costa", "Shuai Wang", "Francisco Camara Pereira", "Robert Thomson"], "title": "Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives", "comment": null, "summary": "Free-text crash narratives recorded in real-world crash databases have been\nshown to play a significant role in improving traffic safety. However,\nlarge-scale analyses remain difficult to implement as there are no documented\ntools that can batch process the unstructured, non standardized text content\nwritten by various authors with diverse experience and attention to detail. In\nrecent years, Transformer-based pre-trained language models (PLMs), such as\nBidirectional Encoder Representations from Transformers (BERT) and large\nlanguage models (LLMs), have demonstrated strong capabilities across various\nnatural language processing tasks. These models can extract explicit facts from\ncrash narratives, but their performance declines on inference-heavy tasks in,\nfor example, Crash Type identification, which can involve nearly 100\ncategories. Moreover, relying on closed LLMs through external APIs raises\nprivacy concerns for sensitive crash data. Additionally, these black-box tools\noften underperform due to limited domain knowledge. Motivated by these\nchallenges, we study whether compact open-source PLMs can support\nreasoning-intensive extraction from crash narratives. We target two challenging\nobjectives: 1) identifying the Manner of Collision for a crash, and 2) Crash\nType for each vehicle involved in the crash event from real-world crash\nnarratives. To bridge domain gaps, we apply fine-tuning techniques to inject\ntask-specific knowledge to LLMs with Low-Rank Adaption (LoRA) and BERT.\nExperiments on the authoritative real-world dataset Crash Investigation\nSampling System (CISS) demonstrate that our fine-tuned compact models\noutperform strong closed LLMs, such as GPT-4o, while requiring only minimal\ntraining resources. Further analysis reveals that the fine-tuned PLMs can\ncapture richer narrative details and even correct some mislabeled annotations\nin the dataset.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u7d27\u51d1\u7684\u5f00\u6e90\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4ea4\u901a\u4e8b\u6545\u53d9\u8ff0\u6587\u672c\uff0c\u901a\u8fc7\u5fae\u8c03\u6280\u672f\u63d0\u5347\u5728\u78b0\u649e\u65b9\u5f0f\u548c\u4e8b\u6545\u7c7b\u578b\u8bc6\u522b\u7b49\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8eGPT-4o\u7b49\u5927\u578b\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u4ea4\u901a\u4e8b\u6545\u53d9\u8ff0\u6587\u672c\u5206\u6790\u5bf9\u63d0\u5347\u4ea4\u901a\u5b89\u5168\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u6279\u91cf\u5904\u7406\u975e\u7ed3\u6784\u5316\u6587\u672c\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u4e14\u5b58\u5728\u9690\u79c1\u95ee\u9898\uff0c\u56e0\u6b64\u7814\u7a76\u7d27\u51d1\u5f00\u6e90\u6a21\u578b\u662f\u5426\u80fd\u652f\u6301\u6b64\u7c7b\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94(LoRA)\u548cBERT\u5fae\u8c03\u6280\u672f\uff0c\u5411\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u6ce8\u5165\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u9488\u5bf9\u78b0\u649e\u65b9\u5f0f\u548c\u8f66\u8f86\u4e8b\u6545\u7c7b\u578b\u8bc6\u522b\u4e24\u4e2a\u6311\u6218\u6027\u76ee\u6807\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u6743\u5a01\u771f\u5b9e\u6570\u636e\u96c6CISS\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5fae\u8c03\u540e\u7684\u7d27\u51d1\u6a21\u578b\u6027\u80fd\u4f18\u4e8eGPT-4o\u7b49\u5f3a\u95ed\u6e90\u6a21\u578b\uff0c\u4e14\u53ea\u9700\u6700\u5c0f\u8bad\u7ec3\u8d44\u6e90\uff0c\u8fd8\u80fd\u6355\u83b7\u66f4\u4e30\u5bcc\u7684\u53d9\u8ff0\u7ec6\u8282\u5e76\u7ea0\u6b63\u6570\u636e\u96c6\u4e2d\u7684\u9519\u8bef\u6807\u6ce8\u3002", "conclusion": "\u7d27\u51d1\u5f00\u6e90\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9002\u5f53\u5fae\u8c03\u53ef\u4ee5\u6709\u6548\u652f\u6301\u4ea4\u901a\u4e8b\u6545\u53d9\u8ff0\u7684\u63a8\u7406\u5bc6\u96c6\u578b\u4fe1\u606f\u63d0\u53d6\uff0c\u5728\u6027\u80fd\u3001\u9690\u79c1\u548c\u8d44\u6e90\u6548\u7387\u65b9\u9762\u90fd\u4f18\u4e8e\u5927\u578b\u95ed\u6e90\u6a21\u578b\u3002"}}
{"id": "2510.09350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09350", "abs": "https://arxiv.org/abs/2510.09350", "authors": ["Vu Duc Anh Nguyen", "Ziyue Li"], "title": "Deep Learning to Identify the Spatio-Temporal Cascading Effects of Train Delays in a High-Density Network", "comment": "Accepted at SIGSPATIAL 2025 - GeoAI Workshop", "summary": "The operational efficiency of railway networks, a cornerstone of modern\neconomies, is persistently undermined by the cascading effects of train delays.\nAccurately forecasting this delay propagation is a critical challenge for\nreal-time traffic management. While recent research has leveraged Graph Neural\nNetworks (GNNs) to model the network structure of railways, a significant gap\nremains in developing frameworks that provide multi-step autoregressive\nforecasts at a network-wide scale, while simultaneously offering the live,\ninterpretable explanations needed for decision support. This paper addresses\nthis gap by developing and evaluating a novel XGeoAI framework for live,\nexplainable, multi-step train delay forecasting. The core of this work is a\ntwo-stage, autoregressive Graph Attention Network (GAT) model, trained on a\nreal-world dataset covering over 40% of the Dutch railway network. The model\nrepresents the system as a spatio-temporal graph of operational events\n(arrivals and departures) and is enriched with granular features, including\nplatform and station congestion. To test its viability for live deployment, the\nmodel is rigorously evaluated using a sequential, k-step-ahead forecasting\nprotocol that simulates real-world conditions where prediction errors can\ncompound. The results demonstrate that while the proposed GATv2 model is\nchallenged on pure error metrics (MAE) by a simpler Persistence baseline, it\nachieves consistently higher precision in classifying delay events -- a crucial\nadvantage for a reliable decision support tool.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aXGeoAI\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u591a\u6b65\u5217\u8f66\u5ef6\u8bef\u9884\u6d4b\uff0c\u6838\u5fc3\u662f\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u7684\u4e24\u9636\u6bb5\u81ea\u56de\u5f52\u6a21\u578b\u3002", "motivation": "\u94c1\u8def\u7f51\u7edc\u8fd0\u8425\u6548\u7387\u53d7\u5230\u5217\u8f66\u5ef6\u8bef\u7ea7\u8054\u6548\u5e94\u7684\u6301\u7eed\u5f71\u54cd\uff0c\u73b0\u6709\u7814\u7a76\u5728\u63d0\u4f9b\u7f51\u7edc\u8303\u56f4\u591a\u6b65\u81ea\u56de\u5f52\u9884\u6d4b\u548c\u5b9e\u65f6\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u4e24\u9636\u6bb5\u81ea\u56de\u5f52\u56fe\u6ce8\u610f\u529b\u7f51\u7edc(GAT)\u6a21\u578b\uff0c\u5c06\u7cfb\u7edf\u8868\u793a\u4e3a\u8fd0\u884c\u4e8b\u4ef6(\u5230\u8fbe\u548c\u79bb\u5f00)\u7684\u65f6\u7a7a\u56fe\uff0c\u5e76\u52a0\u5165\u5e73\u53f0\u548c\u8f66\u7ad9\u62e5\u5835\u7b49\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002", "result": "\u867d\u7136\u6a21\u578b\u5728\u7eaf\u8bef\u5dee\u6307\u6807(MAE)\u4e0a\u88ab\u7b80\u5355\u7684\u6301\u7eed\u6027\u57fa\u7ebf\u6311\u6218\uff0c\u4f46\u5728\u5ef6\u8bef\u4e8b\u4ef6\u5206\u7c7b\u7cbe\u5ea6\u4e0a\u59cb\u7ec8\u66f4\u9ad8\uff0c\u8fd9\u5bf9\u4e8e\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u65f6\u5217\u8f66\u5ef6\u8bef\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5ef6\u8bef\u4e8b\u4ef6\u5206\u7c7b\u7cbe\u5ea6\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u9002\u5408\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u90e8\u7f72\u3002"}}
{"id": "2510.09452", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09452", "abs": "https://arxiv.org/abs/2510.09452", "authors": ["Faried Abu Zaid", "Tim Katzke", "Emmanuel M\u00fcller", "Daniel Neider"], "title": "On Uniformly Scaling Flows: A Density-Aligned Approach to Deep One-Class Classification", "comment": null, "summary": "Unsupervised anomaly detection is often framed around two widely studied\nparadigms. Deep one-class classification, exemplified by Deep SVDD, learns\ncompact latent representations of normality, while density estimators realized\nby normalizing flows directly model the likelihood of nominal data. In this\nwork, we show that uniformly scaling flows (USFs), normalizing flows with a\nconstant Jacobian determinant, precisely connect these approaches.\nSpecifically, we prove how training a USF via maximum-likelihood reduces to a\nDeep SVDD objective with a unique regularization that inherently prevents\nrepresentational collapse. This theoretical bridge implies that USFs inherit\nboth the density faithfulness of flows and the distance-based reasoning of\none-class methods. We further demonstrate that USFs induce a tighter alignment\nbetween negative log-likelihood and latent norm than either Deep SVDD or\nnon-USFs, and how recent hybrid approaches combining one-class objectives with\nVAEs can be naturally extended to USFs. Consequently, we advocate using USFs as\na drop-in replacement for non-USFs in modern anomaly detection architectures.\nEmpirically, this substitution yields consistent performance gains and\nsubstantially improved training stability across multiple benchmarks and model\nbackbones for both image-level and pixel-level detection. These results unify\ntwo major anomaly detection paradigms, advancing both theoretical understanding\nand practical performance.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5747\u5300\u7f29\u653e\u6d41(USFs)\u7edf\u4e00\u4e86\u6df1\u5ea6\u5355\u7c7b\u5206\u7c7b\u548c\u5bc6\u5ea6\u4f30\u8ba1\u4e24\u79cd\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660eUSF\u7684\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u7b49\u4ef7\u4e8eDeep SVDD\u76ee\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u5c06USFs\u4f5c\u4e3a\u975eUSFs\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8fde\u63a5\u6df1\u5ea6\u5355\u7c7b\u5206\u7c7b\uff08\u5982Deep SVDD\uff09\u548c\u5bc6\u5ea6\u4f30\u8ba1\uff08\u5982\u5f52\u4e00\u5316\u6d41\uff09\u8fd9\u4e24\u79cd\u5e7f\u6cdb\u7814\u7a76\u7684\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\uff0c\u5efa\u7acb\u7406\u8bba\u6865\u6881\u3002", "method": "\u4f7f\u7528\u5747\u5300\u7f29\u653e\u6d41(USFs)\uff0c\u8bc1\u660e\u5176\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u7b49\u4ef7\u4e8eDeep SVDD\u76ee\u6807\uff0c\u5e76\u9632\u6b62\u8868\u793a\u5d29\u6e83\u3002\u5c06USFs\u4f5c\u4e3a\u975eUSFs\u7684\u66ff\u4ee3\u65b9\u6848\u5e94\u7528\u4e8e\u73b0\u4ee3\u5f02\u5e38\u68c0\u6d4b\u67b6\u6784\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u9aa8\u5e72\u4e0a\uff0cUSFs\u66ff\u6362\u975eUSFs\u5e26\u6765\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u548c\u663e\u8457\u6539\u5584\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u7ea7\u548c\u50cf\u7d20\u7ea7\u68c0\u6d4b\u3002", "conclusion": "USFs\u7edf\u4e00\u4e86\u4e24\u79cd\u4e3b\u8981\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\uff0c\u65e2\u63a8\u8fdb\u4e86\u7406\u8bba\u7406\u89e3\u53c8\u63d0\u5347\u4e86\u5b9e\u9645\u6027\u80fd\uff0c\u5efa\u8bae\u5c06USFs\u4f5c\u4e3a\u5f02\u5e38\u68c0\u6d4b\u67b6\u6784\u4e2d\u7684\u6807\u51c6\u7ec4\u4ef6\u3002"}}
{"id": "2510.09566", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09566", "abs": "https://arxiv.org/abs/2510.09566", "authors": ["Ilia Revin", "Leon Strelkov", "Vadim A. Potemkin", "Ivan Kireev", "Andrey Savchenko"], "title": "Automated Evolutionary Optimization for Resource-Efficient Neural Network Training", "comment": null, "summary": "There are many critical challenges in optimizing neural network models,\nincluding distributed computing, compression techniques, and efficient\ntraining, regardless of their application to specific tasks. Solving such\nproblems is crucial because the need for scalable and resource-efficient models\nis increasing. To address these challenges, we have developed a new automated\nmachine learning (AutoML) framework, Parameter Efficient Training with Robust\nAutomation (PETRA). It applies evolutionary optimization to model architecture\nand training strategy. PETRA includes pruning, quantization, and loss\nregularization. Experimental studies on real-world data with financial event\nsequences, as well as image and time-series -- benchmarks, demonstrate PETRA's\nability to improve neural model performance and scalability -- namely, a\nsignificant decrease in model size (up to 75%) and latency (up to 33%), and an\nincrease in throughput (by 13%) without noticeable degradation in the target\nmetric.", "AI": {"tldr": "\u63d0\u51fa\u4e86PETRA\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u526a\u679d\u3001\u91cf\u5316\u548c\u635f\u5931\u6b63\u5219\u5316\uff0c\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u89c4\u6a21\uff08\u6700\u591a75%\uff09\u548c\u5ef6\u8fdf\uff08\u6700\u591a33%\uff09\uff0c\u63d0\u5347\u541e\u5410\u91cf\uff0813%\uff09\u4e14\u4e0d\u5f71\u54cd\u76ee\u6807\u6307\u6807\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f18\u5316\u4e2d\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u3001\u538b\u7f29\u6280\u672f\u548c\u9ad8\u6548\u8bad\u7ec3\u7b49\u5173\u952e\u6311\u6218\uff0c\u6ee1\u8db3\u5bf9\u53ef\u6269\u5c55\u548c\u8d44\u6e90\u9ad8\u6548\u6a21\u578b\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\u3002", "method": "\u5f00\u53d1PETRA\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5e94\u7528\u8fdb\u5316\u4f18\u5316\u65b9\u6cd5\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u542b\u526a\u679d\u3001\u91cf\u5316\u548c\u635f\u5931\u6b63\u5219\u5316\u6280\u672f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u91d1\u878d\u4e8b\u4ef6\u5e8f\u5217\u6570\u636e\u4ee5\u53ca\u56fe\u50cf\u548c\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPETRA\u80fd\u591f\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u89c4\u6a21\uff08\u6700\u591a75%\uff09\u3001\u964d\u4f4e\u5ef6\u8fdf\uff08\u6700\u591a33%\uff09\u3001\u63d0\u9ad8\u541e\u5410\u91cf\uff0813%\uff09\uff0c\u4e14\u4e0d\u5f71\u54cd\u76ee\u6807\u6307\u6807\u6027\u80fd\u3002", "conclusion": "PETRA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f18\u5316\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u7684\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
