<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DESSERT: Diffusion-based Event-driven Single-frame Synthesis via Residual Training](https://arxiv.org/abs/2512.17323)
*Jiyun Kong,Jun-Hyuk Kim,Jong-Seok Lee*

Main category: cs.CV

TL;DR: DESSERT：基于扩散模型的事件驱动单帧合成框架，通过残差训练实现更清晰、时间一致性的视频帧预测


<details>
  <summary>Details</summary>
Motivation: 传统视频帧预测在动态场景中因缺乏下一帧信息而存在预测误差，事件相机通过异步高时间分辨率捕获亮度变化可解决此问题，但现有事件驱动方法通过光流预测和像素扭曲会引入空洞和模糊问题

Method: 提出DESSERT框架：1）ER-VAE对齐事件帧与残差；2）扩散模型基于事件数据去噪残差潜在表示；3）引入DLT增强训练不同时间长度帧段以提高鲁棒性

Result: 实验结果表明，该方法在事件重建、图像视频帧预测、事件视频帧预测和单边事件视频帧插值等任务上均优于现有方法，能生成更清晰、时间一致的帧合成

Conclusion: DESSERT通过扩散模型和残差训练有效解决了事件驱动视频帧预测中的空洞和模糊问题，实现了高质量的帧合成

Abstract: Video frame prediction extrapolates future frames from previous frames, but suffers from prediction errors in dynamic scenes due to the lack of information about the next frame. Event cameras address this limitation by capturing per-pixel brightness changes asynchronously with high temporal resolution. Prior research on event-based video frame prediction has leveraged motion information from event data, often by predicting event-based optical flow and reconstructing frames via pixel warping. However, such approaches introduce holes and blurring when pixel displacement is inaccurate. To overcome this limitation, we propose DESSERT, a diffusion-based event-driven single-frame synthesis framework via residual training. Leveraging a pre-trained Stable Diffusion model, our method is trained on inter-frame residuals to ensure temporal consistency. The training pipeline consists of two stages: (1) an Event-to-Residual Alignment Variational Autoencoder (ER-VAE) that aligns the event frame between anchor and target frames with the corresponding residual, and (2) a diffusion model that denoises the residual latent conditioned on event data. Furthermore, we introduce Diverse-Length Temporal (DLT) augmentation, which improves robustness by training on frame segments of varying temporal lengths. Experimental results demonstrate that our method outperforms existing event-based reconstruction, image-based video frame prediction, event-based video frame prediction, and one-sided event-based video frame interpolation methods, producing sharper and more temporally consistent frame synthesis.

</details>


### [2] [AIFloodSense: A Global Aerial Imagery Dataset for Semantic Segmentation and Understanding of Flooded Environments](https://arxiv.org/abs/2512.17432)
*Georgios Simantiris,Konstantinos Bacharidis,Apostolos Papanikolaou,Petros Giannakakis,Costas Panagiotakis*

Main category: cs.CV

TL;DR: AIFloodSense：一个包含470张高分辨率航拍图像、覆盖64个国家230次洪水事件的全球性洪水检测数据集，支持图像分类、语义分割和视觉问答三种任务。


<details>
  <summary>Details</summary>
Motivation: 现有洪水检测数据集存在地理范围有限、标注细节不足的问题，限制了鲁棒、通用计算机视觉方法的发展。需要更全面、多样化的数据集来推动灾害响应和风险评估的改进。

Method: 构建了AIFloodSense数据集，包含2022-2024年期间来自64个国家、230次洪水事件的470张高分辨率航拍图像。数据集支持三种任务：图像分类（环境类型、相机角度、大陆识别）、语义分割（洪水、天空、建筑物的像素级掩码）和视觉问答。

Result: 建立了所有任务的最先进架构基准，展示了数据集的复杂性和在推进气候韧性领域通用AI工具方面的价值。数据集具有全球多样性和时间相关性。

Conclusion: AIFloodSense填补了洪水检测数据集的空白，通过提供全面、公开可用的全球性数据集，支持开发更鲁棒、通用的计算机视觉方法，用于灾害评估和气候韧性建设。

Abstract: Accurate flood detection from visual data is a critical step toward improving disaster response and risk assessment, yet datasets for flood segmentation remain scarce due to the challenges of collecting and annotating large-scale imagery. Existing resources are often limited in geographic scope and annotation detail, hindering the development of robust, generalized computer vision methods. To bridge this gap, we introduce AIFloodSense, a comprehensive, publicly available aerial imagery dataset comprising 470 high-resolution images from 230 distinct flood events across 64 countries and six continents. Unlike prior benchmarks, AIFloodSense ensures global diversity and temporal relevance (2022-2024), supporting three complementary tasks: (i) Image Classification with novel sub-tasks for environment type, camera angle, and continent recognition; (ii) Semantic Segmentation providing precise pixel-level masks for flood, sky, and buildings; and (iii) Visual Question Answering (VQA) to enable natural language reasoning for disaster assessment. We establish baseline benchmarks for all tasks using state-of-the-art architectures, demonstrating the dataset's complexity and its value in advancing domain-generalized AI tools for climate resilience.

</details>


### [3] [HeadHunt-VAD: Hunting Robust Anomaly-Sensitive Heads in MLLM for Tuning-Free Video Anomaly Detection](https://arxiv.org/abs/2512.17601)
*Zhaolin Cai,Fan Li,Ziwei Zheng,Haixia Bi,Lijun He*

Main category: cs.CV

TL;DR: HeadHunt-VAD：一种无需调优的视频异常检测方法，通过直接识别MLLM中异常敏感的注意力头，避免文本生成的信息损失，实现高效准确的异常检测。


<details>
  <summary>Details</summary>
Motivation: 传统视频异常检测方法依赖大量标注数据且计算成本高。基于多模态大语言模型的免调优方法虽然前景好，但依赖文本输出会导致信息损失、正常性偏差和提示敏感性，难以捕捉细微异常线索。

Method: 提出HeadHunt-VAD范式，绕过文本生成，直接识别冻结MLLM中异常敏感的注意力头。核心是鲁棒头识别模块，通过显著性和稳定性的多标准分析，筛选出对多样提示一致的判别性稀疏头子集。这些专家头的特征输入轻量级异常评分器和时序定位器。

Result: 在两个主要VAD基准测试中，HeadHunt-VAD在免调优方法中达到最先进性能，同时保持高效率，验证了头级探测在MLLM中的有效性和实用性。

Conclusion: MLLM中的头级探测是现实世界异常检测的强大实用解决方案，HeadHunt-VAD通过直接利用注意力头的内部表示，克服了文本生成的局限性，实现了高效准确的异常检测。

Abstract: Video Anomaly Detection (VAD) aims to locate events that deviate from normal patterns in videos. Traditional approaches often rely on extensive labeled data and incur high computational costs. Recent tuning-free methods based on Multimodal Large Language Models (MLLMs) offer a promising alternative by leveraging their rich world knowledge. However, these methods typically rely on textual outputs, which introduces information loss, exhibits normalcy bias, and suffers from prompt sensitivity, making them insufficient for capturing subtle anomalous cues. To address these constraints, we propose HeadHunt-VAD, a novel tuning-free VAD paradigm that bypasses textual generation by directly hunting robust anomaly-sensitive internal attention heads within the frozen MLLM. Central to our method is a Robust Head Identification module that systematically evaluates all attention heads using a multi-criteria analysis of saliency and stability, identifying a sparse subset of heads that are consistently discriminative across diverse prompts. Features from these expert heads are then fed into a lightweight anomaly scorer and a temporal locator, enabling efficient and accurate anomaly detection with interpretable outputs. Extensive experiments show that HeadHunt-VAD achieves state-of-the-art performance among tuning-free methods on two major VAD benchmarks while maintaining high efficiency, validating head-level probing in MLLMs as a powerful and practical solution for real-world anomaly detection.

</details>


### [4] [Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting](https://arxiv.org/abs/2512.17908)
*Ananta R. Bhattarai,Helge Rhodin*

Main category: cs.CV

TL;DR: Re-Depth Anything：一个测试时自监督框架，通过融合Depth Anything V2与大规模2D扩散模型的先验知识，解决单目深度估计在真实世界图像中的领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型如Depth Anything V2在处理与训练分布差异较大的真实世界图像时表现不佳，存在领域差距问题，需要一种无需标注的自监督方法来提升深度估计的准确性和真实性。

Method: 提出测试时自监督框架，通过重新照明预测深度图并增强输入图像，利用形状从阴影线索在生成式环境中进行重合成。采用目标优化策略：冻结编码器，仅更新中间嵌入并微调解码器，避免优化崩溃。

Result: 在多个基准测试中，Re-Depth Anything相比Depth Anything V2在深度准确性和真实性方面取得显著提升，展示了通过增强几何推理实现自监督的新途径。

Conclusion: 该方法成功融合了深度估计基础模型与扩散模型先验，通过创新的测试时自监督框架有效缩小了领域差距，为单目深度估计提供了新的自监督解决方案。

Abstract: Monocular depth estimation remains challenging as recent foundation models, such as Depth Anything V2 (DA-V2), struggle with real-world images that are far from the training distribution. We introduce Re-Depth Anything, a test-time self-supervision framework that bridges this domain gap by fusing DA-V2 with the powerful priors of large-scale 2D diffusion models. Our method performs label-free refinement directly on the input image by re-lighting predicted depth maps and augmenting the input. This re-synthesis method replaces classical photometric reconstruction by leveraging shape from shading (SfS) cues in a new, generative context with Score Distillation Sampling (SDS). To prevent optimization collapse, our framework employs a targeted optimization strategy: rather than optimizing depth directly or fine-tuning the full model, we freeze the encoder and only update intermediate embeddings while also fine-tuning the decoder. Across diverse benchmarks, Re-Depth Anything yields substantial gains in depth accuracy and realism over the DA-V2, showcasing new avenues for self-supervision by augmenting geometric reasoning.

</details>


### [5] [SAVeD: A First-Person Social Media Video Dataset for ADAS-equipped vehicle Near-Miss and Crash Event Analyses](https://arxiv.org/abs/2512.17724)
*Shaoyan Zhai,Mohamed Abdel-Aty,Chenzhu Wang,Rodrigo Vena Garcia*

Main category: cs.CV

TL;DR: SAVeD是一个从社交媒体收集的大规模ADAS车辆事故视频数据集，包含碰撞、险情和系统失效事件，用于安全关键研究。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要基于模拟环境或人类驾驶车辆，缺乏真实ADAS车辆在风险条件下的行为数据，限制了安全关键研究的发展。

Method: 从社交媒体收集2,119个第一人称视角视频，进行帧级标注，并提出TTC计算框架、GEV风险量化方法和VLLM基准测试。

Result: 创建了包含多样场景的ADAS车辆事故数据集，建立了TTC计算和风险量化方法，并证明详细标注能显著提升VLLM在复杂险情场景的性能。

Conclusion: SAVeD填补了真实ADAS车辆风险行为数据集的空白，为安全关键研究提供了重要资源，并展示了在风险分析和模型改进方面的应用价值。

Abstract: The advancement of safety-critical research in driving behavior in ADAS-equipped vehicles require real-world datasets that not only include diverse traffic scenarios but also capture high-risk edge cases such as near-miss events and system failures. However, existing datasets are largely limited to either simulated environments or human-driven vehicle data, lacking authentic ADAS (Advanced Driver Assistance System) vehicle behavior under risk conditions. To address this gap, this paper introduces SAVeD, a large-scale video dataset curated from publicly available social media content, explicitly focused on ADAS vehicle-related crashes, near-miss incidents, and disengagements. SAVeD features 2,119 first-person videos, capturing ADAS vehicle operations in diverse locations, lighting conditions, and weather scenarios. The dataset includes video frame-level annotations for collisions, evasive maneuvers, and disengagements, enabling analysis of both perception and decision-making failures. We demonstrate SAVeD's utility through multiple analyses and contributions: (1) We propose a novel framework integrating semantic segmentation and monocular depth estimation to compute real-time Time-to-Collision (TTC) for dynamic objects. (2) We utilize the Generalized Extreme Value (GEV) distribution to model and quantify the extreme risk in crash and near-miss events across different roadway types. (3) We establish benchmarks for state-of-the-art VLLMs (VideoLLaMA2 and InternVL2.5 HiCo R16), showing that SAVeD's detailed annotations significantly enhance model performance through domain adaptation in complex near-miss scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control](https://arxiv.org/abs/2512.16929)
*Pranesh Sathish Kumar*

Main category: cs.LG

TL;DR: 低成本双模式神经肌肉控制系统，结合EEG和EMG实现假肢多自由度实时控制


<details>
  <summary>Details</summary>
Motivation: 传统低成本上肢假肢缺乏直观控制系统，限制了截肢者在资源匮乏环境下的功能性和可及性

Method: 使用NeuroSky MindWave Mobile 2采集EEG信号，通过ThinkGear蓝牙传输到ESP32运行轻量级分类模型；使用MyoWare 2.0传感器采集EMG信号，通过SparkFun无线模块传输到第二个ESP32进行阈值检测。EEG控制手指开合，EMG控制肘部运动

Result: 构建了功能原型（总成本约240美元），EEG通过眨眼检测控制手指，EMG通过三个激活带控制肘部，系统稳定可靠

Conclusion: 该系统展示了低成本、生物直观假肢控制的可行途径，适合资源匮乏和全球健康应用，未来可改进3D打印外壳、降低EMG延迟、提升伺服扭矩

Abstract: Affordable upper-limb prostheses often lack intuitive control systems, limiting functionality and accessibility for amputees in low-resource settings. This project presents a low-cost, dual-mode neuro-muscular control system integrating electroencephalography (EEG) and electromyography (EMG) to enable real-time, multi-degree-of-freedom control of a prosthetic arm. EEG signals are acquired using the NeuroSky MindWave Mobile 2 and transmitted via ThinkGear Bluetooth packets to an ESP32 microcontroller running a lightweight classification model. The model was trained on 1500 seconds of recorded EEG data using a 6-frame sliding window with low-pass filtering, excluding poor-signal samples and using a 70/20/10 training--validation--test split. The classifier detects strong blink events, which toggle the hand between open and closed states. EMG signals are acquired using a MyoWare 2.0 sensor and SparkFun wireless shield and transmitted to a second ESP32, which performs threshold-based detection. Three activation bands (rest: 0--T1; extension: T1--T2; contraction: greater than T2) enable intuitive elbow control, with movement triggered only after eight consecutive frames in a movement class to improve stability. The EEG-controlled ESP32 actuates four finger servos, while the EMG-controlled ESP32 drives two elbow servos. A functional prototype was constructed using low-cost materials (total cost approximately 240 dollars), with most expense attributed to the commercial EEG headset. Future work includes transitioning to a 3D-printed chassis, integrating auto-regressive models to reduce EMG latency, and upgrading servo torque for improved load capacity and grip strength. This system demonstrates a feasible pathway to low-cost, biologically intuitive prosthetic control suitable for underserved and global health applications.

</details>


### [7] [Physics-Informed Lightweight Machine Learning for Aviation Visibility Nowcasting Across Multiple Climatic Regimes](https://arxiv.org/abs/2512.16967)
*Marcelo Cerda Castillo*

Main category: cs.LG

TL;DR: 基于XGBoost的轻量级梯度提升框架，利用地面观测数据和物理引导特征工程，实现低能见度和降水事件的短期预测，在多个国际机场验证中显著优于传统TAF预报。


<details>
  <summary>Details</summary>
Motivation: 当前航空气象业务依赖计算密集的数值天气预报和人工TAF产品，存在保守偏差和时间分辨率有限的问题，需要更高效、准确的短期预测方法保障航空安全。

Method: 采用XGBoost梯度提升框架，仅使用地面观测数据（METAR），通过热力学原理进行物理引导特征工程，在11个不同气候区的国际机场（2000-2024年数据）进行训练和评估。

Result: 在3小时战术预测中，模型相比业务TAF预报显著提高了检测率，召回率提升2.5-4.0倍，同时降低了误报率。SHAP分析显示模型能隐式重建局地物理驱动过程。

Conclusion: 该轻量级框架能有效捕捉局地物理过程，无需人工配置，提供可解释的预测结果，适用于边缘计算环境，为航空气象短期预测提供了高效解决方案。

Abstract: Short-term prediction (nowcasting) of low-visibility and precipitation events is critical for aviation safety and operational efficiency. Current operational approaches rely on computationally intensive numerical weather prediction guidance and human-issued TAF products, which often exhibit conservative biases and limited temporal resolution. This study presents a lightweight gradient boosting framework (XGBoost) trained exclusively on surface observation data (METAR) and enhanced through physics-guided feature engineering based on thermodynamic principles. The framework is evaluated across 11 international airports representing distinct climatic regimes (including SCEL, KJFK, KORD, KDEN, SBGR, and VIDP) using historical data from 2000 to 2024. Results suggest that the model successfully captures underlying local physical processes without manual configuration. In a blind comparative evaluation against operational TAF forecasts, the automated model achieved substantially higher detection rates at tactical horizons (3 hours), with a 2.5 to 4.0 times improvement in recall while reducing false alarms. Furthermore, SHAP analysis reveals that the model performs an implicit reconstruction of local physical drivers (advection, radiation, and subsidence), providing actionable explainability for operational situational awareness.
  Keywords: aviation meteorology; physics-guided machine learning; explainable artificial intelligence; lightweight machine learning; nowcasting; METAR; TAF verification; edge computing

</details>


### [8] [Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs](https://arxiv.org/abs/2512.17352)
*Ivan Kralj,Lodovico Giaretta,Gordan Ježić,Ivana Podnar Žarko,Šarūnas Girdzijauskas*

Main category: cs.LG

TL;DR: 提出自适应剪枝算法减少ST-GNN在边缘计算中的通信开销，同时引入SEPA新指标评估交通事件预测能力


<details>
  <summary>Details</summary>
Motivation: ST-GNN在智能交通系统中处理高频传感器数据时，在分布式边缘节点部署会产生大量通信开销，特别是相邻节点间重复传输重叠特征数据

Method: 提出自适应剪枝算法动态过滤冗余邻居特征，基于近期模型性能调整剪枝率；引入SEPA新指标专门评估交通减速和恢复事件的预测能力

Result: 在PeMS-BAY和PeMSD7-M数据集上，自适应剪枝算法在保持预测精度的同时显著降低通信成本，SEPA指标能有效揭示空间连接性对动态交通预测的真正价值

Conclusion: 自适应剪枝算法可在不损害关键交通事件响应能力的前提下显著降低通信开销，SEPA指标比标准误差指标更能评估交通事件预测性能

Abstract: Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.

</details>


### [9] [NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks](https://arxiv.org/abs/2512.17531)
*Salar Beigzad*

Main category: cs.LG

TL;DR: CFF算法通过层间协作机制改进Forward-Forward算法，解决层间隔离问题，提升深层架构的收敛效率和表示协调性


<details>
  <summary>Details</summary>
Motivation: 传统Forward-Forward算法存在层间隔离问题，各层独立优化goodness函数，缺乏集体学习动态，限制了表示协调和深层架构的收敛效率

Method: 提出Collaborative Forward-Forward学习框架，包含两种协作范式：固定耦合的F-CFF和可学习协作参数的A-CFF，通过加权所有层的贡献实现协调特征学习

Result: 在MNIST和Fashion-MNIST上相比基线Forward-Forward实现有显著性能提升

Conclusion: 层间协作是Forward-Forward学习的基本增强机制，对神经形态计算架构和能源受限AI系统有直接应用价值

Abstract: The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.

</details>


### [10] [Machine Learning for Static and Single-Event Dynamic Complex Network Analysis](https://arxiv.org/abs/2512.17577)
*Nikolaos Nakis*

Main category: cs.LG

TL;DR: 开发用于静态和单事件动态网络的图表示学习新算法，基于潜在空间模型，创建结构感知的网络表示，实现统一的嵌入学习过程


<details>
  <summary>Details</summary>
Motivation: 开发能够自然捕捉网络重要特性（如同质性、传递性、平衡理论）的图表示学习方法，创建结构感知的网络表示，避免启发式和多阶段处理，实现统一的网络嵌入学习

Method: 基于潜在空间模型家族，特别是潜在距离模型，开发统一的图表示学习算法，能够同时处理静态和单事件动态网络，生成结构感知的层次化网络表示

Result: 提出了能够自然表达网络特性、创建层次化结构表达、社区特征识别、极端轮廓识别和时间网络影响动态量化的统一图表示学习方法

Conclusion: 开发了基于潜在空间模型的统一图表示学习框架，能够全面表征网络结构，处理多样化的图分析任务，为静态和动态网络提供强大的嵌入表示

Abstract: The primary objective of this thesis is to develop novel algorithmic approaches for Graph Representation Learning of static and single-event dynamic networks. In such a direction, we focus on the family of Latent Space Models, and more specifically on the Latent Distance Model which naturally conveys important network characteristics such as homophily, transitivity, and the balance theory. Furthermore, this thesis aims to create structural-aware network representations, which lead to hierarchical expressions of network structure, community characterization, the identification of extreme profiles in networks, and impact dynamics quantification in temporal networks. Crucially, the methods presented are designed to define unified learning processes, eliminating the need for heuristics and multi-stage processes like post-processing steps. Our aim is to delve into a journey towards unified network embeddings that are both comprehensive and powerful, capable of characterizing network structures and adeptly handling the diverse tasks that graph analysis offers.

</details>


### [11] [SCOPE: Sequential Causal Optimization of Process Interventions](https://arxiv.org/abs/2512.17629)
*Jakob De Moor,Hans Weytjens,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: SCOPE是一种新的规范性过程监控方法，使用反向归纳和因果学习来推荐对齐的顺序干预，直接利用观测数据优化KPI，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有规范性过程监控方法在处理顺序干预时存在局限：要么只关注单次干预决策，要么将多次干预视为独立事件，忽略了干预之间的时间交互作用。那些考虑依赖关系的方法通常依赖模拟或数据增强来训练强化学习代理，这会造成现实差距并引入偏差。

Method: SCOPE采用反向归纳法估计每个候选干预行动的效果，将其影响从最终决策点传播回第一个决策点。通过利用因果学习器，该方法可以直接使用观测数据，而不需要构建过程近似来进行强化学习。

Result: 在现有合成数据集和新的半合成数据集上的实验表明，SCOPE在优化关键绩效指标方面始终优于最先进的规范性过程监控技术。基于真实事件日志的新半合成设置可作为未来顺序规范性过程监控研究的可重用基准。

Conclusion: SCOPE提供了一种有效的规范性过程监控方法，能够学习对齐的顺序干预推荐，直接利用观测数据，避免了模拟方法带来的现实差距和偏差问题，为顺序干预优化提供了更好的解决方案。

Abstract: Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework](https://arxiv.org/abs/2512.17266)
*Miru Hong,Minho Lee,Geonhee Jo,Jae-Hee So,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: EventGPT：基于GPT架构的球员条件化下一事件预测模型，通过反事实模拟评估球员转会适应性


<details>
  <summary>Details</summary>
Motivation: 现有转会评估方法依赖静态统计数据或后验价值模型，无法捕捉球员在新战术环境中的适应性变化，需要能模拟球员在不同球队中表现的方法

Method: 基于GPT风格自回归变换器，将比赛处理为离散token序列，联合预测下一动作类型、位置、时间和残差控球价值，通过替换球员嵌入进行反事实模拟

Result: 在英超5个赛季数据上，EventGPT在下一事件预测准确性和空间精度上优于现有序列基线，案例研究展示了在转会分析中的实用价值

Conclusion: EventGPT为转会适应性评估提供了原则性方法，能够模拟球员在不同战术环境中的表现变化，具有实际应用价值

Abstract: Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.

</details>


### [13] [Dialectics for Artificial Intelligence](https://arxiv.org/abs/2512.17373)
*Zhengmian Hu*

Main category: cs.AI

TL;DR: 论文提出从算法信息论视角定义"概念"，将概念视为与智能体整体经验相关的信息对象，通过可逆一致性关系和冗余信息度量来形式化概念发现与演化，并建立多智能体概念对齐的通信框架。


<details>
  <summary>Details</summary>
Motivation: 人类概念具有流动性（如冥王星不再被视为行星），传统基于词典标签的概念定义无法捕捉这种动态性。需要一种能够修订、比较和在智能体间对齐的概念定义方法，以探索AI是否能在无监督下从原始经验中发现人类概念。

Method: 采用算法信息论视角，将概念定义为通过可逆一致性关系与智能体经验结构相关的信息对象。提出"冗余信息"度量分解的自然性，建立辩证法优化动态模型，并形式化基于共享协议的低成本概念传输和多智能体对齐机制。

Result: 建立了概念的形式化定义框架，使概念存在性成为可检验的结构性主张。提出了概念演化（扩展、收缩、分裂、合并）的优化动态模型，以及基于计算-比特权衡的多智能体概念对齐通信协议。

Conclusion: 从算法信息论出发为概念提供了严格的形式化定义，使概念发现、演化和多智能体对齐成为可计算的问题，为AI无监督概念学习提供了理论基础。

Abstract: Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of "concept" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents "concepts" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.

</details>
