<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 16]
- [cs.LG](#cs.LG) [Total: 16]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 7]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Agro-Consensus: Semantic Self-Consistency in Vision-Language Models for Crop Disease Management in Developing Countries](https://arxiv.org/abs/2510.21757)
*Mihir Gupta,Pratik Desai,Ross Greer*

Main category: cs.CV

TL;DR: 提出了一种成本效益高的自一致性框架，通过语义聚类和余弦相似度共识机制，提高农业图像字幕生成的可靠性，在PlantVillage数据集上实现了83.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决发展中国家农业病害管理面临的专家资源有限、网络连接不可靠和成本限制等问题，提高AI系统在农业领域的可靠性。

Method: 使用轻量级预训练嵌入模型进行语义聚类，通过余弦相似度选择最连贯的标题，并加入人机交互组件让用户确认作物类型以过滤错误生成。

Result: 在800张作物病害图像上测试，单聚类共识方法在10个候选生成时达到83.1%的准确率，优于贪婪解码的77.5%；考虑多个聚类时准确率可提升至94.0%。

Conclusion: 该自一致性框架能有效提高农业图像字幕生成的可靠性，为发展中国家农业病害管理提供了一种成本效益高的解决方案。

Abstract: Agricultural disease management in developing countries such as India, Kenya,
and Nigeria faces significant challenges due to limited access to expert plant
pathologists, unreliable internet connectivity, and cost constraints that
hinder the deployment of large-scale AI systems. This work introduces a
cost-effective self-consistency framework to improve vision-language model
(VLM) reliability for agricultural image captioning. The proposed method
employs semantic clustering, using a lightweight (80MB) pre-trained embedding
model to group multiple candidate responses. It then selects the most coherent
caption -- containing a diagnosis, symptoms, analysis, treatment, and
prevention recommendations -- through a cosine similarity-based consensus. A
practical human-in-the-loop (HITL) component is incorporated, wherein user
confirmation of the crop type filters erroneous generations, ensuring
higher-quality input for the consensus mechanism. Applied to the publicly
available PlantVillage dataset using a fine-tuned 3B-parameter PaliGemma model,
our framework demonstrates improvements over standard decoding methods.
Evaluated on 800 crop disease images with up to 21 generations per image, our
single-cluster consensus method achieves a peak accuracy of 83.1% with 10
candidate generations, compared to the 77.5% baseline accuracy of greedy
decoding. The framework's effectiveness is further demonstrated when
considering multiple clusters; accuracy rises to 94.0% when a correct response
is found within any of the top four candidate clusters, outperforming the 88.5%
achieved by a top-4 selection from the baseline.

</details>


### [2] [EventFormer: A Node-graph Hierarchical Attention Transformer for Action-centric Video Event Prediction](https://arxiv.org/abs/2510.21786)
*Qile Su,Shoutai Zhu,Shuai Zhang,Baoyu Liang,Chao Tong*

Main category: cs.CV

TL;DR: 本文提出了AVEP任务，这是一个基于视频的事件预测任务，区别于传统视频预测，包含更复杂的逻辑和语义信息。作者构建了一个包含35K标注视频和178K视频片段的大型数据集，并提出了EventFormer模型，在实验中超越了现有视频预测模型。


<details>
  <summary>Details</summary>
Motivation: 人类事件多以视频形式记录而非文本脚本，但在视觉领域缺乏相关研究。现有视频预测任务缺乏复杂逻辑和丰富语义信息，需要开发专门的事件预测任务。

Method: 构建了大规模结构化视频事件数据集，提出EventFormer模型，采用节点-图层次注意力机制，能够捕捉事件与参数之间的关系以及参数间的共指关系。

Result: 在AVEP任务上，EventFormer模型超越了多个SOTA视频预测模型和LVLMs，证明了任务的复杂性和数据集的价值。

Conclusion: AVEP是一个具有挑战性的视频事件预测任务，提出的数据集和EventFormer模型为视频事件理解提供了新的研究方向，未来将发布数据集和代码。

Abstract: Script event induction, which aims to predict the subsequent event based on
the context, is a challenging task in NLP, achieving remarkable success in
practical applications. However, human events are mostly recorded and presented
in the form of videos rather than scripts, yet there is a lack of related
research in the realm of vision. To address this problem, we introduce AVEP
(Action-centric Video Event Prediction), a task that distinguishes itself from
existing video prediction tasks through its incorporation of more complex logic
and richer semantic information. We present a large structured dataset, which
consists of about $35K$ annotated videos and more than $178K$ video clips of
event, built upon existing video event datasets to support this task. The
dataset offers more fine-grained annotations, where the atomic unit is
represented as a multimodal event argument node, providing better structured
representations of video events. Due to the complexity of event structures,
traditional visual models that take patches or frames as input are not
well-suited for AVEP. We propose EventFormer, a node-graph hierarchical
attention based video event prediction model, which can capture both the
relationships between events and their arguments and the coreferencial
relationships between arguments. We conducted experiments using several SOTA
video prediction models as well as LVLMs on AVEP, demonstrating both the
complexity of the task and the value of the dataset. Our approach outperforms
all these video prediction models. We will release the dataset and code for
replicating the experiments and annotations.

</details>


### [3] [Precise classification of low quality G-banded Chromosome Images by reliability metrics and data pruning classifier](https://arxiv.org/abs/2510.21827)
*Mojtaba Moattari*

Main category: cs.CV

TL;DR: 提出了一种通过可靠性阈值度量和精心设计的特征来提高染色体分类精度的方法，特别适用于低质量图像和低成本系统。


<details>
  <summary>Details</summary>
Motivation: 解决偏远病理实验室因缺乏高质量训练数据和准确设备而导致的染色体分类精度不足问题，防止低质量图像下的假阳性检测。

Method: 使用改进的Alex-Net神经网络、SVM、K最近邻及其级联流水线，结合可靠性阈值度量和工程特征，对半直染色体进行自动过滤。

Result: 对于常见缺陷和易位的染色体，分类精度显著提高超过90%，在极低质量G带数据库上实现了高精度结果。

Conclusion: 所提出的阈值度量和剪枝方法适用于贫困国家和低预算病理实验室的核型分析设施。

Abstract: In the last decade, due to high resolution cameras and accurate meta-phase
analyzes, the accuracy of chromosome classification has improved substantially.
However, current Karyotyping systems demand large number of high quality train
data to have an adequately plausible Precision per each chromosome. Such
provision of high quality train data with accurate devices are not yet
accomplished in some out-reached pathological laboratories. To prevent false
positive detections in low-cost systems and low-quality images settings, this
paper improves the classification Precision of chromosomes using proposed
reliability thresholding metrics and deliberately engineered features. The
proposed method has been evaluated using a variation of deep Alex-Net neural
network, SVM, K Nearest-Neighbors, and their cascade pipelines to an automated
filtering of semi-straight chromosome. The classification results have highly
improved over 90% for the chromosomes with more common defections and
translocations. Furthermore, a comparative analysis over the proposed
thresholding metrics has been conducted and the best metric is bolded with its
salient characteristics. The high Precision results provided for a very
low-quality G-banding database verifies suitability of the proposed metrics and
pruning method for Karyotyping facilities in poor countries and lowbudget
pathological laboratories.

</details>


### [4] [TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge](https://arxiv.org/abs/2510.21879)
*Shu-Hao Zhang,Wei-Cheng Tang,Chen Wu,Peng Hu,Nan Li,Liang-Jie Zhang,Qi Zhang,Shao-Qun Zhang*

Main category: cs.CV

TL;DR: 提出TernaryCLIP框架，将CLIP模型的视觉和文本编码器权重转换为三元格式，实现高效压缩和加速，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型在资源受限设备上部署的挑战，通过极端量化降低计算和存储成本。

Method: 采用量化感知训练和蒸馏模块，将权重转换为三元格式（1.58位表示），实现高压缩比和稀疏性。

Result: 达到99%三元化权重，16.98倍压缩比，2.3倍推理加速，16倍存储减少，10倍内存优化，60%稀疏性，在41个数据集上保持良好性能。

Conclusion: 证明了大型多模态模型极端量化的可行性，支持在资源受限设备上的高效部署。

Abstract: Recent years have witnessed an increasing interest in image-text contrastive
modeling, exemplified by models such as Contrastive Language-Image Pretraining
(CLIP). In this paper, we propose the TernaryCLIP, a lightweight computational
framework that converts connection weights of both vision and text encoders of
CLIP into the ternary format, instead of full-precision or floating ones.
TernaryCLIP incorporates quantization-aware training and distillation modules,
preventing precision degradation and enabling low-cost and high-efficiency
computations. Comprehensive experiments demonstrate that TernaryCLIP can
achieve up to 99\% ternarized weights with 1.58-bit representation, 16.98
$\times$ compression ratio, 2.3 $\times$ inference acceleration, 16 $\times$
storage reduction, 10 $\times$ memory optimization, and 60\% sparsity while
maintaining promising performance on zero-shot image classification and
image-text retrieval tasks across 41 commonly used datasets. Our work
highlights the feasibility of extreme quantization for large multimodal models,
supporting effective and efficient deployment on resource-constrained devices.
The model and code can be accessed from Hugging Face and GitHub.

</details>


### [5] [Human-Centric Anomaly Detection in Surveillance Videos Using YOLO-World and Spatio-Temporal Deep Learning](https://arxiv.org/abs/2510.22056)
*Mohammad Ali Etemadi Naeen,Hoda Mohammadzade,Saeed Bagheri Shouraki*

Main category: cs.CV

TL;DR: 提出结合人类中心预处理和时空建模的深度学习框架，用于监控视频中的多类异常检测，在UCF-Crime数据集上达到92.41%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 解决监控视频异常检测中的挑战：异常事件多样性、类别不平衡和场景相关的视觉干扰。

Method: 使用YOLO-World检测人类实例，ByteTrack进行身份跟踪，高斯模糊抑制背景，InceptionV3提取空间特征，BiLSTM捕获时序动态。

Result: 在UCF-Crime五类子集上平均测试准确率92.41%，各类F1分数均超过0.85，表现出良好的泛化能力和对类别不平衡的鲁棒性。

Conclusion: 前景聚焦的预处理方法显著提升了真实监控场景中的异常识别能力。

Abstract: Anomaly detection in surveillance videos remains a challenging task due to
the diversity of abnormal events, class imbalance, and scene-dependent visual
clutter. To address these issues, we propose a robust deep learning framework
that integrates human-centric preprocessing with spatio-temporal modeling for
multi-class anomaly classification. Our pipeline begins by applying YOLO-World
- an open-vocabulary vision-language detector - to identify human instances in
raw video clips, followed by ByteTrack for consistent identity-aware tracking.
Background regions outside detected bounding boxes are suppressed via Gaussian
blurring, effectively reducing scene-specific distractions and focusing the
model on behaviorally relevant foreground content. The refined frames are then
processed by an ImageNet-pretrained InceptionV3 network for spatial feature
extraction, and temporal dynamics are captured using a bidirectional LSTM
(BiLSTM) for sequence-level classification. Evaluated on a five-class subset of
the UCF-Crime dataset (Normal, Burglary, Fighting, Arson, Explosion), our
method achieves a mean test accuracy of 92.41% across three independent trials,
with per-class F1-scores consistently exceeding 0.85. Comprehensive evaluation
metrics - including confusion matrices, ROC curves, and macro/weighted averages
- demonstrate strong generalization and resilience to class imbalance. The
results confirm that foreground-focused preprocessing significantly enhances
anomaly discrimination in real-world surveillance scenarios.

</details>


### [6] [Audio Frequency-Time Dual Domain Evaluation on Depression Diagnosis](https://arxiv.org/abs/2510.22225)
*Yu Luo,Nan Huang,Sophie Yu,Hendry Xu,Jerry Wang,Colin Wang,Zhichao Liu,Chen Zeng*

Main category: cs.CV

TL;DR: 本研究利用语音作为生理信号，结合深度学习模型开发抑郁症智能评估诊断算法，在抑郁症分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 抑郁症作为典型精神障碍已成为严重影响公共健康的问题，但其防治面临诊断程序复杂、标准模糊、就诊率低等挑战，阻碍了及时评估和干预。

Method: 采用语音作为生理信号，利用其频时双域多模态特征，结合深度学习模型开发智能评估诊断算法。

Result: 实验结果表明，所提方法在抑郁症诊断分类任务中取得了优异性能。

Conclusion: 为抑郁症的评估、筛查和诊断提供了新的思路和方法。

Abstract: Depression, as a typical mental disorder, has become a prevalent issue
significantly impacting public health. However, the prevention and treatment of
depression still face multiple challenges, including complex diagnostic
procedures, ambiguous criteria, and low consultation rates, which severely
hinder timely assessment and intervention. To address these issues, this study
adopts voice as a physiological signal and leverages its frequency-time dual
domain multimodal characteristics along with deep learning models to develop an
intelligent assessment and diagnostic algorithm for depression. Experimental
results demonstrate that the proposed method achieves excellent performance in
the classification task for depression diagnosis, offering new insights and
approaches for the assessment, screening, and diagnosis of depression.

</details>


### [7] [GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping](https://arxiv.org/abs/2510.22319)
*Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang*

Main category: cs.CV

TL;DR: GRPO-Guard通过比率归一化和梯度重加权解决了GRPO强化学习中重要性比率分布偏移问题，有效防止隐式过度优化，在保持生成质量的同时显著提升训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO强化学习框架中重要性比率分布存在系统性偏移（均值低于1、方差不一致），导致PPO剪裁机制无法有效约束过度自信的正向更新，造成隐式过度优化问题。

Method: 提出GRPO-Guard方法：1）比率归一化恢复平衡且步长一致的重要性比率；2）梯度重加权策略均衡不同噪声条件下的策略梯度，防止特定时间步区域的过度更新。

Result: 在多个扩散模型骨干（SD3.5M、Flux.1-dev）和多样化代理任务上的实验表明，GRPO-Guard显著减少了过度优化，同时保持甚至提高了生成质量。

Conclusion: GRPO-Guard作为一种受调节的剪裁机制，无需依赖沉重的KL正则化即可稳定优化过程，有效缓解隐式过度优化问题，使学习到的策略在实际应用中更加实用。

Abstract: Recently, GRPO-based reinforcement learning has shown remarkable progress in
optimizing flow-matching models, effectively improving their alignment with
task-specific rewards. Within these frameworks, the policy update relies on
importance-ratio clipping to constrain overconfident positive and negative
gradients. However, in practice, we observe a systematic shift in the
importance-ratio distribution-its mean falls below 1 and its variance differs
substantially across timesteps. This left-shifted and inconsistent distribution
prevents positive-advantage samples from entering the clipped region, causing
the mechanism to fail in constraining overconfident positive updates. As a
result, the policy model inevitably enters an implicit over-optimization
stage-while the proxy reward continues to increase, essential metrics such as
image quality and text-prompt alignment deteriorate sharply, ultimately making
the learned policy impractical for real-world use. To address this issue, we
introduce GRPO-Guard, a simple yet effective enhancement to existing GRPO
frameworks. Our method incorporates ratio normalization, which restores a
balanced and step-consistent importance ratio, ensuring that PPO clipping
properly constrains harmful updates across denoising timesteps. In addition, a
gradient reweighting strategy equalizes policy gradients over noise conditions,
preventing excessive updates from particular timestep regions. Together, these
designs act as a regulated clipping mechanism, stabilizing optimization and
substantially mitigating implicit over-optimization without relying on heavy KL
regularization. Extensive experiments on multiple diffusion backbones (e.g.,
SD3.5M, Flux.1-dev) and diverse proxy tasks demonstrate that GRPO-Guard
significantly reduces over-optimization while maintaining or even improving
generation quality.

</details>


### [8] [Open Multimodal Retrieval-Augmented Factual Image Generation](https://arxiv.org/abs/2510.22521)
*Yang Tian,Fan Liu,Jingyuan Zhang,Wei Bi,Yupeng Hu,Liqiang Nie*

Main category: cs.CV

TL;DR: ORIG是一个用于事实图像生成(FIG)的代理式开放多模态检索增强框架，通过迭代检索和过滤网络多模态证据，逐步整合精炼知识到增强提示中，显著提升事实一致性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在生成逼真图像方面取得显著进展，但经常产生与可验证知识相矛盾的输出，特别是在涉及细粒度属性或时间敏感事件的提示时。传统检索增强方法依赖静态来源和浅层证据整合，无法基于准确和演化的知识进行生成。

Method: ORIG框架迭代地从网络检索和过滤多模态证据，并逐步将精炼知识整合到增强提示中指导生成。构建了FIG-Eval基准，涵盖感知、组合和时间三个维度的十个类别。

Result: 实验表明ORIG在事实一致性和整体图像质量方面显著优于强基线方法，突显了开放多模态检索在事实图像生成中的潜力。

Conclusion: ORIG通过开放多模态检索增强框架有效解决了事实图像生成中的知识矛盾问题，为生成既逼真又事实准确的图像提供了可行方案。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable progress in
generating photorealistic and prompt-aligned images, but they often produce
outputs that contradict verifiable knowledge, especially when prompts involve
fine-grained attributes or time-sensitive events. Conventional
retrieval-augmented approaches attempt to address this issue by introducing
external information, yet they are fundamentally incapable of grounding
generation in accurate and evolving knowledge due to their reliance on static
sources and shallow evidence integration. To bridge this gap, we introduce
ORIG, an agentic open multimodal retrieval-augmented framework for Factual
Image Generation (FIG), a new task that requires both visual realism and
factual grounding. ORIG iteratively retrieves and filters multimodal evidence
from the web and incrementally integrates the refined knowledge into enriched
prompts to guide generation. To support systematic evaluation, we build
FIG-Eval, a benchmark spanning ten categories across perceptual, compositional,
and temporal dimensions. Experiments demonstrate that ORIG substantially
improves factual consistency and overall image quality over strong baselines,
highlighting the potential of open multimodal retrieval for factual image
generation.

</details>


### [9] [SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning](https://arxiv.org/abs/2510.22534)
*Chen Chen,Majid Abdolshah,Violetta Shevchenko,Hongdong Li,Chang Xu,Pulak Purkait*

Main category: cs.CV

TL;DR: 提出了一种新颖的即插即用空间重聚焦超分辨率框架，通过空间重聚焦交叉注意力和空间目标无分类器引导机制，解决了现有扩散超分辨率方法中的语义模糊和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的超分辨率方法由于文本条件的不准确性和不完整性，以及交叉注意力容易偏向无关像素的固有倾向，经常表现出语义模糊，导致语义错位和幻觉细节。

Method: 提出SRSR框架，包含两个核心组件：1) 空间重聚焦交叉注意力，在推理时通过视觉基础分割掩码引导交叉注意力来细化文本条件；2) 空间目标无分类器引导机制，选择性地绕过对未接地像素的文本影响以防止幻觉。

Result: 在合成和真实世界数据集上的广泛实验表明，SRSR在所有数据集的标准保真度指标（PSNR和SSIM）上始终优于七个最先进的基线方法，并在两个真实世界基准测试的感知质量指标（LPIPS和DISTS）上表现更好。

Conclusion: SRSR在超分辨率中实现了高语义保真度和感知质量的有效性。

Abstract: Existing diffusion-based super-resolution approaches often exhibit semantic
ambiguities due to inaccuracies and incompleteness in their text conditioning,
coupled with the inherent tendency for cross-attention to divert towards
irrelevant pixels. These limitations can lead to semantic misalignment and
hallucinated details in the generated high-resolution outputs. To address
these, we propose a novel, plug-and-play spatially re-focused super-resolution
(SRSR) framework that consists of two core components: first, we introduce
Spatially Re-focused Cross-Attention (SRCA), which refines text conditioning at
inference time by applying visually-grounded segmentation masks to guide
cross-attention. Second, we introduce a Spatially Targeted Classifier-Free
Guidance (STCFG) mechanism that selectively bypasses text influences on
ungrounded pixels to prevent hallucinations. Extensive experiments on both
synthetic and real-world datasets demonstrate that SRSR consistently
outperforms seven state-of-the-art baselines in standard fidelity metrics (PSNR
and SSIM) across all datasets, and in perceptual quality measures (LPIPS and
DISTS) on two real-world benchmarks, underscoring its effectiveness in
achieving both high semantic fidelity and perceptual quality in
super-resolution.

</details>


### [10] [VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree](https://arxiv.org/abs/2510.22693)
*Wenlong Li,Yifei Xu,Yuan Rao,Zhenhua Wang,Shuiguang Deng*

Main category: cs.CV

TL;DR: 提出VADTree方法，通过分层粒度感知树结构实现视频异常检测的灵活采样，利用预训练模型知识减少采样片段数量，在无需训练设置下达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法存在局限性：监督方法需要大量领域内训练数据且无法提供清晰解释；无训练方法虽然利用预训练模型知识，但固定长度时间窗口采样难以准确捕捉不同时间跨度的异常。

Method: 使用分层粒度感知树结构进行灵活采样，基于通用事件边界检测模型分解视频为事件节点，进行自适应粗细分层结构和冗余去除，然后向视觉语言模型注入多维先验增强异常感知，通过大语言模型实现异常推理，最后使用簇间节点相关性方法整合多粒度异常分数。

Result: 在三个挑战性数据集上的大量实验表明，VADTree在无训练设置下实现了最先进的性能，同时大幅减少了采样的视频片段数量。

Conclusion: VADTree通过分层粒度感知树结构和预训练模型知识的有效利用，解决了视频异常检测中时间跨度变化的问题，在减少计算成本的同时提升了检测性能。

Abstract: Video anomaly detection (VAD) focuses on identifying anomalies in videos.
Supervised methods demand substantial in-domain training data and fail to
deliver clear explanations for anomalies. In contrast, training-free methods
leverage the knowledge reserves and language interactivity of large pre-trained
models to detect anomalies. However, the current fixed-length temporal window
sampling approaches struggle to accurately capture anomalies with varying
temporal spans. Therefore, we propose VADTree that utilizes a Hierarchical
Granularityaware Tree (HGTree) structure for flexible sampling in VAD. VADTree
leverages the knowledge embedded in a pre-trained Generic Event Boundary
Detection (GEBD) model to characterize potential anomaly event boundaries.
Specifically, VADTree decomposes the video into generic event nodes based on
boundary confidence, and performs adaptive coarse-fine hierarchical structuring
and redundancy removal to construct the HGTree. Then, the multi-dimensional
priors are injected into the visual language models (VLMs) to enhance the
node-wise anomaly perception, and anomaly reasoning for generic event nodes is
achieved via large language models (LLMs). Finally, an inter-cluster node
correlation method is used to integrate the multi-granularity anomaly scores.
Extensive experiments on three challenging datasets demonstrate that VADTree
achieves state-of-the-art performance in training-free settings while
drastically reducing the number of sampled video segments. The code will be
available at https://github.com/wenlongli10/VADTree.

</details>


### [11] [Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models](https://arxiv.org/abs/2510.22868)
*Yang Zhang,Qianyu Zhou,Farhad Imani,Jiong Tang*

Main category: cs.CV

TL;DR: 提出了一种基于检索增强生成(RAG)和视觉语言模型(VLM)的零样本风机叶片损伤检测框架，无需任务特定训练即可准确识别多种损伤类型。


<details>
  <summary>Details</summary>
Motivation: 风机叶片在恶劣环境中运行，需要及时检测损伤以防止故障。现有基于无人机和深度学习的方法依赖大量标注数据，难以检测罕见或新出现的损伤类型。

Method: 构建包含技术文档、参考图像和领域指南的多模态知识库，使用混合文本-图像检索器结合关键词感知重排序，为VLM提供相关上下文，无需任务特定训练即可注入领域知识。

Result: 在30张标记叶片图像测试集上，RAG增强的VLM正确分类了所有样本，而未经检索的相同VLM在准确率和精度上表现较差。消融研究表明该框架在可解释性和泛化性方面具有优势。

Conclusion: 该研究为工业检测提供了一种数据高效的解决方案，减少了对大量标注数据集的依赖，通过领域知识而非仅依赖视觉线索来检测未见过的缺陷。

Abstract: Wind turbine blades operate in harsh environments, making timely damage
detection essential for preventing failures and optimizing maintenance.
Drone-based inspection and deep learning are promising, but typically depend on
large, labeled datasets, which limit their ability to detect rare or evolving
damage types. To address this, we propose a zero-shot-oriented inspection
framework that integrates Retrieval-Augmented Generation (RAG) with
Vision-Language Models (VLM). A multimodal knowledge base is constructed,
comprising technical documentation, representative reference images, and
domain-specific guidelines. A hybrid text-image retriever with keyword-aware
reranking assembles the most relevant context to condition the VLM at
inference, injecting domain knowledge without task-specific training. We
evaluate the framework on 30 labeled blade images covering diverse damage
categories. Although the dataset is small due to the difficulty of acquiring
verified blade imagery, it covers multiple representative defect types. On this
test set, the RAG-grounded VLM correctly classified all samples, whereas the
same VLM without retrieval performed worse in both accuracy and precision. We
further compare against open-vocabulary baselines and incorporate uncertainty
Clopper-Pearson confidence intervals to account for the small-sample setting.
Ablation studies indicate that the key advantage of the framework lies in
explainability and generalizability: retrieved references ground the reasoning
process and enable the detection of previously unseen defects by leveraging
domain knowledge rather than relying solely on visual cues. This research
contributes a data-efficient solution for industrial inspection that reduces
dependence on extensive labeled datasets.

</details>


### [12] [FAME: Fairness-aware Attention-modulated Video Editing](https://arxiv.org/abs/2510.22960)
*Zhangkai Wu,Xuhui Fan,Zhongyuan Xie,Kaize Shi,Zhidong Li,Longbing Cao*

Main category: cs.CV

TL;DR: FAME是一个公平性感知的视频编辑框架，通过注意力调制来减轻职业相关的性别偏见，同时保持提示对齐和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的免训练视频编辑模型在处理职业相关提示时容易陷入性别刻板印象，需要解决职业相关的性别偏见问题。

Method: 使用公平性嵌入，通过软注入去偏标记到文本编码器；在时间自注意力和跨注意力中集成公平性调制；引入区域约束注意力掩码和时间衰减权重；重新加权标记到区域匹配分数。

Result: 在FairVE基准测试中，FAME实现了更强的公平性对齐和语义保真度，超越了现有的视频编辑基线方法。

Conclusion: FAME通过公平性感知的注意力调制，有效减轻了视频编辑中的职业性别偏见，同时保持了时间一致性和提示对齐。

Abstract: Training-free video editing (VE) models tend to fall back on gender
stereotypes when rendering profession-related prompts. We propose \textbf{FAME}
for \textit{Fairness-aware Attention-modulated Video Editing} that mitigates
profession-related gender biases while preserving prompt alignment and temporal
consistency for coherent VE. We derive fairness embeddings from existing
minority representations by softly injecting debiasing tokens into the text
encoder. Simultaneously, FAME integrates fairness modulation into both temporal
self attention and prompt-to-region cross attention to mitigate the motion
corruption and temporal inconsistency caused by directly introducing fairness
cues. For temporal self attention, FAME introduces a region constrained
attention mask combined with time decay weighting, which enhances intra-region
coherence while suppressing irrelevant inter-region interactions. For cross
attention, it reweights tokens to region matching scores by incorporating
fairness sensitive similarity masks derived from debiasing prompt embeddings.
Together, these modulations keep fairness-sensitive semantics tied to the right
visual regions and prevent temporal drift across frames. Extensive experiments
on new VE fairness-oriented benchmark \textit{FairVE} demonstrate that FAME
achieves stronger fairness alignment and semantic fidelity, surpassing existing
VE baselines.

</details>


### [13] [Evaluation of Vision-LLMs in Surveillance Video](https://arxiv.org/abs/2510.23190)
*Pascal Benschop,Cristian Meo,Justin Dauwels,Jelte P. Mense*

Main category: cs.CV

TL;DR: 该论文研究视觉语言模型的空间推理能力，将异常行为识别构建为零样本、基于语言的任务，评估小规模预训练视觉-LLM作为空间基础异常检测器的效果。


<details>
  <summary>Details</summary>
Motivation: 摄像头产生的海量视频数据远超人工监控能力，需要自动检测异常事件以保障公共安全。智能体识别意外事件的能力与其空间推理能力密切相关。

Method: 将视频转换为文本描述，通过文本蕴含对标签进行评分，评估四种开源模型在UCF-Crime和RWF-2000数据集上的表现，包括提示和隐私保护条件下的测试。

Result: 少量样本示例可提高某些模型的准确率，但可能增加误报；隐私过滤器（特别是全身GAN变换）会引入不一致性降低准确率。模型在简单、空间显著事件上表现良好，但在噪声空间线索和身份模糊时表现不佳。

Conclusion: 提出了无需任务特定训练即可增强空间基础的具体路径：结构感知提示、跨片段的轻量级空间记忆、描述过程中的场景图或3D姿态先验，以及保留动作相关几何的隐私方法。

Abstract: The widespread use of cameras in our society has created an overwhelming
amount of video data, far exceeding the capacity for human monitoring. This
presents a critical challenge for public safety and security, as the timely
detection of anomalous or criminal events is crucial for effective response and
prevention. The ability for an embodied agent to recognize unexpected events is
fundamentally tied to its capacity for spatial reasoning. This paper
investigates the spatial reasoning of vision-language models (VLMs) by framing
anomalous action recognition as a zero-shot, language-grounded task, addressing
the embodied perception challenge of interpreting dynamic 3D scenes from sparse
2D video. Specifically, we investigate whether small, pre-trained vision--LLMs
can act as spatially-grounded, zero-shot anomaly detectors by converting video
into text descriptions and scoring labels via textual entailment. We evaluate
four open models on UCF-Crime and RWF-2000 under prompting and
privacy-preserving conditions. Few-shot exemplars can improve accuracy for some
models, but may increase false positives, and privacy filters -- especially
full-body GAN transforms -- introduce inconsistencies that degrade accuracy.
These results chart where current vision--LLMs succeed (simple, spatially
salient events) and where they falter (noisy spatial cues, identity
obfuscation). Looking forward, we outline concrete paths to strengthen spatial
grounding without task-specific training: structure-aware prompts, lightweight
spatial memory across clips, scene-graph or 3D-pose priors during description,
and privacy methods that preserve action-relevant geometry. This positions
zero-shot, language-grounded pipelines as adaptable building blocks for
embodied, real-world video understanding. Our implementation for evaluating
VLMs is publicly available at:
https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition

</details>


### [14] [ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation](https://arxiv.org/abs/2510.23306)
*Jiahao Chang,Chongjie Ye,Yushuang Wu,Yuantao Chen,Yidan Zhang,Zhongjin Luo,Chenghong Li,Yihao Zhi,Xiaoguang Han*

Main category: cs.CV

TL;DR: ReconViaGen是一个创新的多视角3D重建方法，通过将重建先验整合到生成框架中，解决了现有扩散式3D生成方法在一致性和准确性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有多视角3D重建方法严重依赖输入视角之间的充分重叠，但在实践中遮挡和稀疏覆盖经常导致严重的不完整重建。扩散式3D生成技术虽然能够通过生成先验来补全不可见部分，但其随机性限制了生成结果的准确性和可靠性。

Method: 提出了ReconViaGen方法，创新性地将重建先验整合到生成框架中，设计了多种策略来解决扩散式3D生成方法的一致性问题，包括：(a)改进多视角图像特征的构建和跨视角连接利用；(b)增强迭代去噪过程中的局部细节生成可控性。

Result: 大量实验证明，ReconViaGen能够重建出与输入视角在全局结构和局部细节上都一致的完整且准确的3D模型。

Conclusion: ReconViaGen通过将重建先验整合到生成框架中，有效解决了扩散式3D生成方法的一致性问题，实现了高质量的多视角3D重建。

Abstract: Existing multi-view 3D object reconstruction methods heavily rely on
sufficient overlap between input views, where occlusions and sparse coverage in
practice frequently yield severe reconstruction incompleteness. Recent
advancements in diffusion-based 3D generative techniques offer the potential to
address these limitations by leveraging learned generative priors to
hallucinate invisible parts of objects, thereby generating plausible 3D
structures. However, the stochastic nature of the inference process limits the
accuracy and reliability of generation results, preventing existing
reconstruction frameworks from integrating such 3D generative priors. In this
work, we comprehensively analyze the reasons why diffusion-based 3D generative
methods fail to achieve high consistency, including (a) the insufficiency in
constructing and leveraging cross-view connections when extracting multi-view
image features as conditions, and (b) the poor controllability of iterative
denoising during local detail generation, which easily leads to plausible but
inconsistent fine geometric and texture details with inputs. Accordingly, we
propose ReconViaGen to innovatively integrate reconstruction priors into the
generative framework and devise several strategies that effectively address
these issues. Extensive experiments demonstrate that our ReconViaGen can
reconstruct complete and accurate 3D models consistent with input views in both
global structure and local details.Project page:
https://jiahao620.github.io/reconviagen.

</details>


### [15] [EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT](https://arxiv.org/abs/2510.23569)
*Baoqi Pei,Yifei Huang,Jilan Xu,Yuping He,Guo Chen,Fei Wu,Yu Qiao,Jiangmiao Pang*

Main category: cs.CV

TL;DR: EgoThinker是一个赋予多模态大语言模型(MLLMs)自我中心推理能力的新框架，通过时空思维链监督和两阶段学习课程，在多个自我中心基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs擅长可见事件推理但缺乏具身的第一人称理解能力，无法有效处理自我中心视频中不可观察的智能体动态塑造环境的挑战。

Method: 构建大规模自我中心QA数据集EgoRe-5M，包含1300万个视频片段，标注详细思维链推理和密集手-物体定位；采用两阶段学习：监督微调(SFT)培养推理技能，强化微调(RFT)增强时空定位能力。

Result: EgoThinker在多个自我中心基准测试中超越现有方法，在细粒度时空定位任务上取得显著改进。

Conclusion: 该框架成功赋予MLLMs强大的自我中心推理能力，为具身智能理解提供了有效解决方案。

Abstract: Egocentric video reasoning centers on an unobservable agent behind the camera
who dynamically shapes the environment, requiring inference of hidden
intentions and recognition of fine-grained interactions. This core challenge
limits current multimodal large language models MLLMs, which excel at visible
event reasoning but lack embodied, first-person understanding. To bridge this
gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust
egocentric reasoning capabilities through spatio-temporal chain-of-thought
supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M,
a large-scale egocentric QA dataset constructed from 13M diverse egocentric
video clips. This dataset features multi-minute segments annotated with
detailed CoT rationales and dense hand-object grounding. Second, we employ SFT
on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning
RFT to further enhance spatio-temporal localization. Experimental results show
that EgoThinker outperforms existing methods across multiple egocentric
benchmarks, while achieving substantial improvements in fine-grained
spatio-temporal localization tasks. Full code and data are released at
https://github.com/InternRobotics/EgoThinker.

</details>


### [16] [Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation](https://arxiv.org/abs/2510.23581)
*Junyoung Seo,Rodrigo Mira,Alexandros Haliassos,Stella Bounareli,Honglie Chen,Linh Tran,Seungryong Kim,Zoe Landgraf,Jie Shen*

Main category: cs.CV

TL;DR: 提出Lookahead Anchoring方法，通过利用未来时间步的关键帧作为方向性锚点，解决音频驱动人体动画中的身份漂移问题，无需额外关键帧生成阶段。


<details>
  <summary>Details</summary>
Motivation: 音频驱动人体动画模型在时间自回归生成过程中容易出现身份漂移问题，现有使用关键帧作为时间锚点的方法需要额外生成阶段且限制自然运动动态。

Method: 利用当前生成窗口前方的未来时间步关键帧作为方向性锚点，模型在响应即时音频线索的同时持续追求这些未来锚点，实现自我关键帧化，参考图像直接作为前瞻目标。

Result: 在三个人体动画模型上应用该方法，实现了更好的唇部同步、身份保持和视觉质量，展示了跨不同架构的改进时间条件化效果。

Conclusion: Lookahead Anchoring通过前瞻锚点机制有效平衡表达性和一致性，时间前瞻距离自然控制运动自由度和身份保持之间的权衡。

Abstract: Audio-driven human animation models often suffer from identity drift during
temporal autoregressive generation, where characters gradually lose their
identity over time. One solution is to generate keyframes as intermediate
temporal anchors that prevent degradation, but this requires an additional
keyframe generation stage and can restrict natural motion dynamics. To address
this, we propose Lookahead Anchoring, which leverages keyframes from future
timesteps ahead of the current generation window, rather than within it. This
transforms keyframes from fixed boundaries into directional beacons: the model
continuously pursues these future anchors while responding to immediate audio
cues, maintaining consistent identity through persistent guidance. This also
enables self-keyframing, where the reference image serves as the lookahead
target, eliminating the need for keyframe generation entirely. We find that the
temporal lookahead distance naturally controls the balance between expressivity
and consistency: larger distances allow for greater motion freedom, while
smaller ones strengthen identity adherence. When applied to three recent human
animation models, Lookahead Anchoring achieves superior lip synchronization,
identity preservation, and visual quality, demonstrating improved temporal
conditioning across several different architectures. Video results are
available at the following link: https://lookahead-anchoring.github.io.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [17] [What Causes Postoperative Aspiration?](https://arxiv.org/abs/2510.21779)
*Supriya Nagesh,Karina Covarrubias,Robert El-Kareh,Shiva Prasad Kasiviswanathan,Nina Mishra*

Main category: cs.LG

TL;DR: 开发机器学习模型预测术后误吸风险，识别阿片类药物剂量和手术部位为主要风险因素，发现男性患者误吸风险更高且阿片类药物剂量更大。


<details>
  <summary>Details</summary>
Motivation: 误吸严重影响手术患者发病率和死亡率，需要开发预测模型以实现及时预防干预。

Method: 从MIMIC-IV数据库中识别826名术后误吸患者和匹配对照组，使用XGBoost、多层感知机和随机森林三种机器学习模型，采用增强逆概率加权进行因果分析。

Result: 模型AUROC达到0.86，灵敏度77.3%；最大日阿片剂量、住院时间和患者年龄是最重要预测因子；男性误吸风险是女性的1.5倍，且阿片剂量高27%。

Conclusion: 机器学习模型能有效预测术后误吸风险，阿片类药物剂量和手术部位显著影响风险，性别差异需要进一步研究以改进术后护理方案。

Abstract: Background: Aspiration, the inhalation of foreign material into the lungs,
significantly impacts surgical patient morbidity and mortality. This study
develops a machine learning (ML) model to predict postoperative aspiration,
enabling timely preventative interventions.
  Methods: From the MIMIC-IV database of over 400,000 hospital admissions, we
identified 826 surgical patients (mean age: 62, 55.7\% male) who experienced
aspiration within seven days post-surgery, along with a matched non-aspiration
cohort. Three ML models: XGBoost, Multilayer Perceptron, and Random Forest were
trained using pre-surgical hospitalization data to predict postoperative
aspiration. To investigate causation, we estimated Average Treatment Effects
(ATE) using Augmented Inverse Probability Weighting.
  Results: Our ML model achieved an AUROC of 0.86 and 77.3\% sensitivity on a
held-out test set. Maximum daily opioid dose, length of stay, and patient age
emerged as the most important predictors. ATE analysis identified significant
causative factors: opioids (0.25 +/- 0.06) and operative site (neck: 0.20 +/-
0.13, head: 0.19 +/- 0.13). Despite equal surgery rates across genders, men
were 1.5 times more likely to aspirate and received 27\% higher maximum daily
opioid dosages compared to women.
  Conclusion: ML models can effectively predict postoperative aspiration risk,
enabling targeted preventative measures. Maximum daily opioid dosage and
operative site significantly influence aspiration risk. The gender disparity in
both opioid administration and aspiration rates warrants further investigation.
These findings have important implications for improving postoperative care
protocols and aspiration prevention strategies.

</details>


### [18] [COLA: Continual Learning via Autoencoder Retrieval of Adapters](https://arxiv.org/abs/2510.21836)
*Jaya Krishna Mandivarapu*

Main category: cs.LG

TL;DR: 提出COLA框架解决大语言模型持续学习中的灾难性遗忘问题，使用自编码器学习任务权重的低维嵌入，无需数据回放或大量任务特定参数


<details>
  <summary>Details</summary>
Motivation: 大语言模型持续学习面临灾难性遗忘问题，且频繁重新训练成本高昂，需要一种高效的方法来学习新任务同时保留已有知识

Method: 使用自编码器学习任务权重的低维嵌入，促进知识迁移到新任务，同时防止灾难性遗忘，不使用数据回放或大量任务特定参数

Result: 在多个数据集上评估，不仅克服了灾难性遗忘，还显著减少了参数使用和内存占用，在多个任务上优于现有最先进方法

Conclusion: COLA框架使大语言模型能够高效学习新任务，对先前任务性能影响极小，且无需保留早期训练数据

Abstract: Learning a set of tasks over time, also known as continual learning (CL), is
one of the most challenging problems in artificial intelligence due to
catastrophic forgetting. Large language models (LLMs) are often impractical to
frequent re-training and continual learning , due to high cost of computational
resources for training. Moreover, LLM are not suitable for continual learning
as updating these models over time for acquiring new knowledge leads to
overwrites existing knowledge leading to common phenomenon know as
\textit{catastrophic forgetting}. In this paper, we aim to address these
concerns using a novel framework , COLA that employs an autoencoder to learn
capture low-dimensional embeddings of the weights associated with various
tasks. Our approach facilitates the transfer of knowledge to new tasks while
preventing catastrophic forgetting, all without using data replay or a
substantial set of task-specific parameters. Our approach, COLA, makes the LLM
efficiently learn new tasks with minimal training, insignificant performance
degradation on previous tasks, and eliminates the need for retaining earlier
training data. Empirical evaluation on different datasets ranging from task
oriented dialouge system to intent classsfication datasets showcases that our
method not only overcomes catastrophic forgetting but also achieves significant
reduction in parameter usage and memory size, across multiple tasks and
outperforming the existing state of the art methods across multiple datasets.

</details>


### [19] [SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization](https://arxiv.org/abs/2510.21847)
*Kaiyi Xu,Junchao Gong,Wenlong Zhang,Ben Fei,Lei Bai,Wanli Ouyang*

Main category: cs.LG

TL;DR: 本文提出SynCast方法，首次将偏好优化引入降水临近预报，通过两阶段训练框架解决确定性模型预测过于平滑和概率模型性能波动的问题，协同优化冲突的评估指标。


<details>
  <summary>Details</summary>
Motivation: 降水临近预报面临确定性模型预测过于平滑难以捕捉极端事件，概率模型性能波动且难以在冲突指标上同时表现优异的问题，特别是CSI和FAR指标之间存在权衡关系。

Method: 提出SynCast方法，采用Diffusion-SPO两阶段后训练框架：第一阶段专注于降低FAR，训练模型抑制误报；第二阶段在保持FAR对齐的基础上进一步优化CSI，实现冲突指标的协同改进。

Result: 该方法能够渐进式对齐冲突指标，在降水临近预报中持续实现优越性能。

Conclusion: 偏好优化方法能够有效解决降水临近预报中冲突指标的权衡问题，为极端天气监测和灾害预防提供更可靠的预测工具。

Abstract: Precipitation nowcasting based on radar echoes plays a crucial role in
monitoring extreme weather and supporting disaster prevention. Although deep
learning approaches have achieved significant progress, they still face notable
limitations. For example, deterministic models tend to produce over-smoothed
predictions, which struggle to capture extreme events and fine-scale
precipitation patterns. Probabilistic generative models, due to their inherent
randomness, often show fluctuating performance across different metrics and
rarely achieve consistently optimal results. Furthermore, precipitation
nowcasting is typically evaluated using multiple metrics, some of which are
inherently conflicting. For instance, there is often a trade-off between the
Critical Success Index (CSI) and the False Alarm Ratio (FAR), making it
challenging for existing models to deliver forecasts that perform well on both
metrics simultaneously. To address these challenges, we introduce preference
optimization into precipitation nowcasting for the first time, motivated by the
success of reinforcement learning from human feedback in large language models.
Specifically, we propose SynCast, a method that employs the two-stage
post-training framework of Diffusion Sequential Preference Optimization
(Diffusion-SPO), to progressively align conflicting metrics and consistently
achieve superior performance. In the first stage, the framework focuses on
reducing FAR, training the model to effectively suppress false alarms. Building
on this foundation, the second stage further optimizes CSI with constraints
that preserve FAR alignment, thereby achieving synergistic improvements across
these conflicting metrics.

</details>


### [20] [Privacy-preserving Decision-focused Learning for Multi-energy Systems](https://arxiv.org/abs/2510.21858)
*Yangze Zhou,Ruiyang Yao,Dalin Qin,Yixiong Jia,Yi Wang*

Main category: cs.LG

TL;DR: 提出了一种面向多能源系统的隐私保护决策聚焦学习框架，通过信息掩蔽和安全协议解决传统方法中的隐私泄露问题，同时降低调度成本。


<details>
  <summary>Details</summary>
Motivation: 传统多能源系统负荷预测与决策分离，预测模型仅关注预测精度而忽略对下游决策的影响。决策聚焦学习虽能优化决策成本，但在实际应用中面临敏感数据共享导致的隐私泄露风险。

Method: 采用信息掩蔽技术保护私有数据，同时恢复决策变量和梯度；结合矩阵分解和同态加密设计安全协议防止合谋和未授权访问；开发隐私保护的负荷模式识别算法训练专用模型。

Result: 理论分析和真实多能源系统案例研究表明，该框架不仅能有效保护隐私，而且相比现有方法持续实现更低的平均日调度成本。

Conclusion: 所提出的隐私保护决策聚焦学习框架成功解决了多能源系统调度中的隐私安全与决策优化双重挑战，具有实际应用价值。

Abstract: Decision-making for multi-energy system (MES) dispatch depends on accurate
load forecasting. Traditionally, load forecasting and decision-making for MES
are implemented separately. Forecasting models are typically trained to
minimize forecasting errors, overlooking their impact on downstream
decision-making. To address this, decision-focused learning (DFL) has been
studied to minimize decision-making costs instead. However, practical adoption
of DFL in MES faces significant challenges: the process requires sharing
sensitive load data and model parameters across multiple sectors, raising
serious privacy issues. To this end, we propose a privacy-preserving DFL
framework tailored for MES. Our approach introduces information masking to
safeguard private data while enabling recovery of decision variables and
gradients required for model training. To further enhance security for DFL, we
design a safety protocol combining matrix decomposition and homomorphic
encryption, effectively preventing collusion and unauthorized data access.
Additionally, we developed a privacy-preserving load pattern recognition
algorithm, enabling the training of specialized DFL models for heterogeneous
load patterns. Theoretical analysis and comprehensive case studies, including
real-world MES data, demonstrate that our framework not only protects privacy
but also consistently achieves lower average daily dispatch costs compared to
existing methods.

</details>


### [21] [Joint Score-Threshold Optimization for Interpretable Risk Assessment Under Partial Supervision](https://arxiv.org/abs/2510.21934)
*Fardin Gankhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 提出一个混合整数规划框架，用于优化医疗风险评分工具，解决部分监督和不对称误分类成本问题


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据为优化风险评分工具提供了机会，但面临部分监督（仅极端类别可可靠标记）和不对称误分类成本（随序数距离增加）的挑战

Method: 混合整数规划框架，联合优化评分权重和类别阈值，处理部分监督通过实例可行标签集，结合不对称距离感知目标，通过最小阈值间隙防止中间类别崩溃

Result: 开发了使用softplus损失的CSO松弛方法，保持序数结构的同时实现高效优化

Conclusion: 该框架支持治理约束，包括符号限制、稀疏性和对现有工具的最小修改，确保在临床工作流程中的实际可部署性

Abstract: Risk assessment tools in healthcare commonly employ point-based scoring
systems that map patients to ordinal risk categories via thresholds. While
electronic health record (EHR) data presents opportunities for data-driven
optimization of these tools, two fundamental challenges impede standard
supervised learning: (1) partial supervision arising from intervention-censored
outcomes, where only extreme categories can be reliably labeled, and (2)
asymmetric misclassification costs that increase with ordinal distance. We
propose a mixed-integer programming (MIP) framework that jointly optimizes
scoring weights and category thresholds under these constraints. Our approach
handles partial supervision through per-instance feasible label sets,
incorporates asymmetric distance-aware objectives, and prevents middle-category
collapse via minimum threshold gaps. We further develop a CSO relaxation using
softplus losses that preserves the ordinal structure while enabling efficient
optimization. The framework supports governance constraints including sign
restrictions, sparsity, and minimal modifications to incumbent tools, ensuring
practical deployability in clinical workflows.

</details>


### [22] [Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models](https://arxiv.org/abs/2510.21978)
*Hoang Phan,Xianjun Yang,Kevin Yao,Jingyu Zhang,Shengjie Bi,Xiaocheng Tang,Madian Khabsa,Lijuan Liu,Deren Lei*

Main category: cs.LG

TL;DR: 提出了RECAP方法，一种具有动态目标重加权的回放策略，用于在强化学习与可验证奖励训练中防止能力退化，保护模型的基础知识。


<details>
  <summary>Details</summary>
Motivation: RLVR训练范式存在能力退化风险，模型在长时间训练后会忘记基础技能，如感知和忠实性。现有的KL正则化方法无法保证广泛知识的保留，而异构领域的经验回放难以确定各目标的训练权重。

Method: RECAP方法通过在线动态重加权机制，利用收敛和不稳定的短期信号，将训练重点从饱和目标转向表现不佳或波动的目标，无需额外模型训练或大量调参。

Result: 在Qwen2.5-VL-3B和Qwen2.5-VL-7B基准测试上的广泛实验表明，该方法有效保护了通用能力，并通过在任务奖励间实现更灵活的权衡来改进推理能力。

Conclusion: RECAP是一种端到端的解决方案，可直接应用于现有RLVR流程，既能保护基础知识，又能提升推理性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has delivered
impressive gains in mathematical and multimodal reasoning and has become a
standard post-training paradigm for contemporary language and vision-language
models. However, the RLVR recipe introduces a significant risk of capability
regression, where models forget foundational skills after prolonged training
without employing regularization strategies. We empirically confirm this
concern, observing that open-source reasoning models suffer performance
degradation on core capabilities such as perception and faithfulness. While
imposing regularization terms like KL divergence can help prevent deviation
from the base model, these terms are calculated on the current task, thus they
do not guarantee broader knowledge. Meanwhile, commonly used experience replay
across heterogeneous domains makes it nontrivial to decide how much training
focus each objective should receive. To address this, we propose RECAP-a replay
strategy with dynamic objective reweighting for general knowledge preservation.
Our reweighting mechanism adapts in an online manner using short-horizon
signals of convergence and instability, shifting the post-training focus away
from saturated objectives and toward underperforming or volatile ones. Our
method is end-to-end and readily applicable to existing RLVR pipelines without
training additional models or heavy tuning. Extensive experiments on benchmarks
based on Qwen2.5-VL-3B and Qwen2.5-VL-7B demonstrate the effectiveness of our
method, which not only preserves general capabilities but also improves
reasoning by enabling more flexible trade-offs among in-task rewards.

</details>


### [23] [Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies](https://arxiv.org/abs/2510.22017)
*Naina Balepur,Xingrui Pei,Hari Sundaram*

Main category: cs.LG

TL;DR: 本文开发了一种考虑制度信任的强化学习算法，用于社区资源分配，发现在组织目标不确定时，纳入信任机制能产生更成功的政策，但组织成功与社区福祉之间存在张力。


<details>
  <summary>Details</summary>
Motivation: 现有RL算法假设公民会遵循政府制定的政策，但现实中缺乏制度信任时公民不会配合。本文旨在解决资源分配中制度信任的重要性问题。

Method: 使用深度确定性策略梯度方法学习资源分配策略，模拟资源分配过程并建模社区成员制度信任的变化，研究信任整合对结果的影响。

Result: 整合信任的RL算法能产生更成功的政策，特别是在组织目标不确定时；保守的信任估计能提高公平性和平均社区信任，但会降低组织成功率；外部配额干预可改善公平性和信任。

Conclusion: 制度信任在算法设计和实施中至关重要，组织成功与社区福祉之间存在固有张力，需要平衡考虑。

Abstract: Many governmental bodies are adopting AI policies for decision-making. In
particular, Reinforcement Learning has been used to design policies that
citizens would be expected to follow if implemented. Much RL work assumes that
citizens follow these policies, and evaluate them with this in mind. However,
we know from prior work that without institutional trust, citizens will not
follow policies put in place by governments. In this work, we develop a
trust-aware RL algorithm for resource allocation in communities. We consider
the case of humanitarian engineering, where the organization is aiming to
distribute some technology or resource to community members. We use a Deep
Deterministic Policy Gradient approach to learn a resource allocation that fits
the needs of the organization. Then, we simulate resource allocation according
to the learned policy, and model the changes in institutional trust of
community members. We investigate how this incorporation of institutional trust
affects outcomes, and ask how effectively an organization can learn policies if
trust values are private. We find that incorporating trust into RL algorithms
can lead to more successful policies, specifically when the organization's
goals are less certain. We find more conservative trust estimates lead to
increased fairness and average community trust, though organization success
suffers. Finally, we explore a strategy to prevent unfair outcomes to
communities. We implement a quota system by an external entity which decreases
the organization's utility when it does not serve enough community members. We
find this intervention can improve fairness and trust among communities in some
cases, while decreasing the success of the organization. This work underscores
the importance of institutional trust in algorithm design and implementation,
and identifies a tension between organization success and community well-being.

</details>


### [24] [Hierarchical Graph Networks for Accurate Weather Forecasting via Lightweight Training](https://arxiv.org/abs/2510.22094)
*Thomas Bailie,S. Karthik Mukkavilli,Varvara Vetrova,Yun Sing Koh*

Main category: cs.LG

TL;DR: HiFlowCast和HiAntFlow是嵌入物理约束的层次图神经网络，通过保留全局趋势和多尺度PDE场集成，显著提升长期天气预报准确性，同时降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 传统固定分辨率方法无法捕捉气候变化的多尺度物理过程，而现有层次图神经网络在向下映射时会丢失全局趋势，削弱物理约束的集成效果。

Method: 提出HiFlowCast和HiAntFlow模型，采用潜在记忆保留机制保持全局趋势，以及潜在到物理分支集成多尺度PDE解场。

Result: 在13天预报期误差降低超过5%，在极端分位数条件下误差降低5-8%，利用预训练权重可在单个epoch内收敛。

Conclusion: 该模型在提升天气预报准确性的同时显著降低训练成本，对机器学习可持续性和研究可及性具有重要意义。

Abstract: Climate events arise from intricate, multivariate dynamics governed by
global-scale drivers, profoundly impacting food, energy, and infrastructure.
Yet, accurate weather prediction remains elusive due to physical processes
unfolding across diverse spatio-temporal scales, which fixed-resolution methods
cannot capture. Hierarchical Graph Neural Networks (HGNNs) offer a multiscale
representation, but nonlinear downward mappings often erase global trends,
weakening the integration of physics into forecasts. We introduce HiFlowCast
and its ensemble variant HiAntFlow, HGNNs that embed physics within a
multiscale prediction framework. Two innovations underpin their design: a
Latent-Memory-Retention mechanism that preserves global trends during downward
traversal, and a Latent-to-Physics branch that integrates PDE solution fields
across diverse scales. Our Flow models cut errors by over 5% at 13-day lead
times and by 5-8% under 1st and 99th quantile extremes, improving reliability
for rare events. Leveraging pretrained model weights, they converge within a
single epoch, reducing training cost and their carbon footprint. Such
efficiency is vital as the growing scale of machine learning challenges
sustainability and limits research accessibility. Code and model weights are in
the supplementary materials.

</details>


### [25] [Predicting Metabolic Dysfunction-Associated Steatotic Liver Disease using Machine Learning Methods](https://arxiv.org/abs/2510.22293)
*Mary E. An,Paul Griffin,Jonathan G. Stine,Ramakrishna Balakrishnan,Ram Sriram,Soundar Kumara*

Main category: cs.LG

TL;DR: 开发了MASER预测模型，用于预测代谢功能障碍相关脂肪肝病(MASLD)，通过公平性后处理减少种族和民族亚组间的预测差异，在保持可解释性的同时达到竞争性性能。


<details>
  <summary>Details</summary>
Motivation: MASLD影响约33%的美国成年人，是最常见的慢性肝病。早期检测很重要，因为生活方式干预可以预防疾病进展。需要开发公平、严谨且可复现的MASLD预测模型。

Method: 评估了LASSO逻辑回归、随机森林、XGBoost和神经网络，使用临床特征子集（包括前10个SHAP排名特征）。应用平等机会后处理方法减少种族和民族亚组间的真阳性率差异。

Result: 训练数据59,492例，验证数据24,198例，测试数据25,188例。选择具有前10个特征的LASSO逻辑回归模型。公平性调整前：AUROC 0.84，准确率78%，敏感性72%，特异性79%，F1分数0.617。调整后：准确率81%，特异性94%，敏感性41%，F1分数0.515。

Conclusion: MASER预测模型在MASLD预测中达到竞争性性能（AUROC 0.836，准确率77.6%），与之前报告的集成和基于树的模型相当。可解释模型可以在多样化患者群体中实现预测性能和公平性的平衡。

Abstract: Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD)
affects ~33% of U.S. adults and is the most common chronic liver disease.
Although often asymptomatic, progression can lead to cirrhosis. Early detection
is important, as lifestyle interventions can prevent disease progression. We
developed a fair, rigorous, and reproducible MASLD prediction model and
compared it to prior methods using a large electronic health record database.
  Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and
a neural network for MASLD prediction using clinical feature subsets, including
the top 10 SHAP-ranked features. To reduce disparities in true positive rates
across racial and ethnic subgroups, we applied an equal opportunity
postprocessing method.
  Results: This study included 59,492 patients in the training data, 24,198 in
the validating data, and 25,188 in the testing data. The LASSO logistic
regression model with the top 10 features was selected for its interpretability
and comparable performance. Before fairness adjustment, the model achieved
AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and
F1-score of 0.617. After equal opportunity postprocessing, accuracy modestly
increased to 81% and specificity to 94%, while sensitivity decreased to 41% and
F1-score to 0.515, reflecting the fairness trade-off.
  Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk
Prediction), a LASSO logistic regression model which achieved competitive
performance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to
previously reported ensemble and tree-based models. Overall, this approach
demonstrates that interpretable models can achieve a balance of predictive
performance and fairness in diverse patient populations.

</details>


### [26] [Dynamic Dropout: Leveraging Conway's Game of Life for Neural Networks Regularization](https://arxiv.org/abs/2510.22383)
*David Freire-Obregón,José Salas-Cáceres,Modesto Castrillón-Santana*

Main category: cs.LG

TL;DR: 提出用康威生命游戏替代dropout进行正则化，通过动态单元失活和空间模式演化来提升神经网络泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统dropout存在静态性和缺乏可解释性的局限，需要更动态、可解释的正则化方法。

Method: 将神经网络单元表示为生命游戏网格中的细胞，应用游戏规则动态失活单元，形成自适应训练数据的空间模式。

Result: 在CIFAR-10数据集上，该方法与传统dropout性能相当，同时能通过可视化演化模式提供网络行为洞察。

Conclusion: 基于生命游戏的动态单元失活是有效的正则化替代方案，适用于深层架构并能增强不同dropout技术的性能。

Abstract: Regularization techniques play a crucial role in preventing overfitting and
improving the generalization performance of neural networks. Dropout, a widely
used regularization technique, randomly deactivates units during training to
introduce redundancy and prevent co-adaptation among neurons. Despite its
effectiveness, dropout has limitations, such as its static nature and lack of
interpretability. In this paper, we propose a novel approach to regularization
by substituting dropout with Conway's Game of Life (GoL), a cellular automata
with simple rules that govern the evolution of a grid of cells. We introduce
dynamic unit deactivation during training by representing neural network units
as cells in a GoL grid and applying the game's rules to deactivate units. This
approach allows for the emergence of spatial patterns that adapt to the
training data, potentially enhancing the network's ability to generalize. We
demonstrate the effectiveness of our approach on the CIFAR-10 dataset, showing
that dynamic unit deactivation using GoL achieves comparable performance to
traditional dropout techniques while offering insights into the network's
behavior through the visualization of evolving patterns. Furthermore, our
discussion highlights the applicability of our proposal in deeper
architectures, demonstrating how it enhances the performance of different
dropout techniques.

</details>


### [27] [Air Quality Prediction Using LOESS-ARIMA and Multi-Scale CNN-BiLSTM with Residual-Gated Attention](https://arxiv.org/abs/2510.22818)
*Soham Pahari,Sandeep Chand Kumain*

Main category: cs.LG

TL;DR: 提出了一种结合LOESS分解、ARIMA建模和多尺度CNN-BiLSTM网络的混合预测框架，用于印度大城市的空气质量指数(AQI)预测，在多个污染物指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 印度大城市空气质量问题严重，污染物水平突然飙升给及时干预带来挑战。AQI预测因同时存在线性趋势、季节变化和波动非线性模式而困难。

Method: 使用LOESS分解将AQI序列分为趋势、季节和残差分量，ARIMA建模平滑分量，提出的深度学习模块（带残差门控注意力机制的多尺度CNN-BiLSTM网络）捕捉残差中的多尺度波动，使用UAMMO优化器调整超参数。

Result: 在2021-2023年中央污染控制委员会AQI数据集上的实验表明，该方法在PM2.5、O3、CO和NOx等污染物上均优于统计、深度学习和混合基线方法，MSE降低5-8%，R^2得分>0.94。

Conclusion: 该框架具有鲁棒性，对突发污染事件敏感，适用于城市空气质量管理的实际应用。

Abstract: Air pollution remains a critical environmental and public health concern in
Indian megacities such as Delhi, Kolkata, and Mumbai, where sudden spikes in
pollutant levels challenge timely intervention. Accurate Air Quality Index
(AQI) forecasting is difficult due to the coexistence of linear trends,
seasonal variations, and volatile nonlinear patterns. This paper proposes a
hybrid forecasting framework that integrates LOESS decomposition, ARIMA
modeling, and a multi-scale CNN-BiLSTM network with a residual-gated attention
mechanism. The LOESS step separates the AQI series into trend, seasonal, and
residual components, with ARIMA modeling the smooth components and the proposed
deep learning module capturing multi-scale volatility in the residuals. Model
hyperparameters are tuned via the Unified Adaptive Multi-Stage Metaheuristic
Optimizer (UAMMO), combining multiple optimization strategies for efficient
convergence. Experiments on 2021-2023 AQI datasets from the Central Pollution
Control Board show that the proposed method consistently outperforms
statistical, deep learning, and hybrid baselines across PM2.5, O3, CO, and NOx
in three major cities, achieving up to 5-8% lower MSE and higher R^2 scores
(>0.94) for all pollutants. These results demonstrate the framework's
robustness, sensitivity to sudden pollution events, and applicability to urban
air quality management.

</details>


### [28] [Transforming volcanic monitoring: A dataset and benchmark for onboard volcano activity detection](https://arxiv.org/abs/2510.22889)
*Darshana Priyasad,Tharindu Fernando,Maryam Haghighat,Harshala Gammulle,Clinton Fookes*

Main category: cs.LG

TL;DR: 本文提出了一个专门用于火山活动检测的新数据集，并展示了在下一代卫星上部署检测模型的可行性，为火山灾害管理提供创新解决方案。


<details>
  <summary>Details</summary>
Motivation: 火山灾害造成重大经济损失，新一代小卫星提供了近实时监测机会，但缺乏火山活动的标注数据集阻碍了检测系统的开发。

Method: 创建专门用于火山活动和喷发检测的数据集，提供二元标注识别火山异常；使用最先进模型建立基准；在Intel Movidius Myriad X VPU上测试星载部署可行性。

Result: 数据集为开发检测模型提供了基础资源；基准测试为未来研究建立了基线；证明了在卫星上直接进行火山活动检测的可行性。

Conclusion: 星载火山活动检测能力显著降低了延迟并提高了响应时间，为先进的早期预警系统铺平了道路，推动了火山灾害管理的创新解决方案。

Abstract: Natural disasters, such as volcanic eruptions, pose significant challenges to
daily life and incur considerable global economic losses. The emergence of
next-generation small-satellites, capable of constellation-based operations,
offers unparalleled opportunities for near-real-time monitoring and onboard
processing of such events. However, a major bottleneck remains the lack of
extensive annotated datasets capturing volcanic activity, which hinders the
development of robust detection systems. This paper introduces a novel dataset
explicitly designed for volcanic activity and eruption detection, encompassing
diverse volcanoes worldwide. The dataset provides binary annotations to
identify volcanic anomalies or non-anomalies, covering phenomena such as
temperature anomalies, eruptions, and volcanic ash emissions. These annotations
offer a foundational resource for developing and evaluating detection models,
addressing a critical gap in volcanic monitoring research. Additionally, we
present comprehensive benchmarks using state-of-the-art models to establish
baselines for future studies. Furthermore, we explore the potential for
deploying these models onboard next-generation satellites. Using the Intel
Movidius Myriad X VPU as a testbed, we demonstrate the feasibility of volcanic
activity detection directly onboard. This capability significantly reduces
latency and enhances response times, paving the way for advanced early warning
systems. This paves the way for innovative solutions in volcanic disaster
management, encouraging further exploration and refinement of onboard
monitoring technologies.

</details>


### [29] [SARNet: A Spike-Aware consecutive validation Framework for Accurate Remaining Useful Life Prediction](https://arxiv.org/abs/2510.22955)
*Junhao Fan,Wenrui Liang,Wei-Qiang Zhang*

Main category: cs.LG

TL;DR: SARNet是一个用于剩余使用寿命预测的尖峰感知连续验证框架，结合现代时间卷积网络和尖峰检测机制，提供物理可解释性，在多个基准数据集上实现了较低的预测误差。


<details>
  <summary>Details</summary>
Motivation: 解决当前剩余使用寿命预测模型在故障起始点附近表现脆弱、对工程师不透明的问题，如短时高能尖峰被平滑或误读、固定阈值降低灵敏度、缺乏基于物理解释等。

Method: 基于现代时间卷积网络预测退化敏感指标，采用自适应连续阈值验证真实尖峰并抑制噪声，对故障易发段进行针对性特征工程，最后使用堆叠的随机森林-轻量梯度提升机回归器生成最终RUL预测。

Result: 在事件触发协议下的基准数据集上，SARNet相比近期基线方法持续降低误差（RMSE 0.0365，MAE 0.0204），同时保持轻量、鲁棒且易于部署。

Conclusion: SARNet通过尖峰感知检测和物理信息可解释性，有效提升了剩余使用寿命预测的准确性和可靠性，为系统维护提供了更可靠的决策支持。

Abstract: Accurate prediction of remaining useful life (RUL) is essential to enhance
system reliability and reduce maintenance risk. Yet many strong contemporary
models are fragile around fault onset and opaque to engineers: short,
high-energy spikes are smoothed away or misread, fixed thresholds blunt
sensitivity, and physics-based explanations are scarce. To remedy this, we
introduce SARNet (Spike-Aware Consecutive Validation Framework), which builds
on a Modern Temporal Convolutional Network (ModernTCN) and adds spike-aware
detection to provide physics-informed interpretability. ModernTCN forecasts
degradation-sensitive indicators; an adaptive consecutive threshold validates
true spikes while suppressing noise. Failure-prone segments then receive
targeted feature engineering (spectral slopes, statistical derivatives, energy
ratios), and the final RUL is produced by a stacked RF--LGBM regressor. Across
benchmark-ported datasets under an event-triggered protocol, SARNet
consistently lowers error compared to recent baselines (RMSE 0.0365, MAE
0.0204) while remaining lightweight, robust, and easy to deploy.

</details>


### [30] [The Benchmarking Epistemology: Construct Validity for Evaluating Machine Learning Models](https://arxiv.org/abs/2510.23191)
*Timo Freiesleben,Sebastian Zezulka*

Main category: cs.LG

TL;DR: 该论文提出了预测性基准测试的构建效度框架，通过三个案例研究分析了基准分数支持科学推断所需的条件。


<details>
  <summary>Details</summary>
Motivation: 基准测试分数本身只能衡量模型在特定数据集上的相对性能，要从中得出有意义的科学推断需要额外的理论假设，作者希望明确这些假设条件。

Method: 借鉴心理测量理论开发构建效度条件，并通过ImageNet、WeatherBench和Fragile Families Challenge三个案例研究来检验这些假设。

Result: 明确了基准分数支持科学推断所需的理论结构、评估函数和数据分布等假设条件，为预测性基准测试提供了认识论框架。

Conclusion: 基准测试不仅是技术实践，更是机器学习中概念和理论推理的关键场所，需要明确的构建效度条件来支持科学推断。

Abstract: Predictive benchmarking, the evaluation of machine learning models based on
predictive performance and competitive ranking, is a central epistemic practice
in machine learning research and an increasingly prominent method for
scientific inquiry. Yet, benchmark scores alone provide at best measurements of
model performance relative to an evaluation dataset and a concrete learning
problem. Drawing substantial scientific inferences from the results, say about
theoretical tasks like image classification, requires additional assumptions
about the theoretical structure of the learning problems, evaluation functions,
and data distributions. We make these assumptions explicit by developing
conditions of construct validity inspired by psychological measurement theory.
We examine these assumptions in practice through three case studies, each
exemplifying a typical intended inference: measuring engineering progress in
computer vision with ImageNet; evaluating policy-relevant weather predictions
with WeatherBench; and examining limitations of the predictability of life
events with the Fragile Families Challenge. Our framework clarifies the
conditions under which benchmark scores can support diverse scientific claims,
bringing predictive benchmarking into perspective as an epistemological
practice and a key site of conceptual and theoretical reasoning in machine
learning.

</details>


### [31] [ZeroFlood: A Geospatial Foundation Model for Data-Efficient Flood Susceptibility Mapping](https://arxiv.org/abs/2510.23364)
*Hyeongkyun Kim,Orestis Oikonomou*

Main category: cs.LG

TL;DR: ZeroFlood是一个地理空间基础模型框架，通过Thinking-in-Modality推理微调地理空间基础模型，使用基本地球观测数据实现洪水易发性制图，在数据稀缺区域提供可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺地区进行洪水易发性制图具有挑战性，因为水动力模型需要密集的地球物理输入数据。

Method: 通过Thinking-in-Modality推理微调地理空间基础模型，利用数据丰富区域的配对地球观测和模拟洪水地图进行跨模态表示学习。

Result: 实验显示TiM增强了模型鲁棒性，TerraMind-Large配置达到67.21的F1分数。

Conclusion: 基于基础模型的洪水易发性制图是洪水风险管理的可扩展且数据高效的可行解决方案。

Abstract: Flood susceptibility mapping (FSM) is vital for disaster prevention but
remains challenging in data-scarce regions where hydrodynamic models require
dense geophysical inputs. This work introduces ZeroFlood, a geospatial
foundation model framework for data-efficient FSM. The approach fine-tunes
Geospatial Foundation Models (GFMs) with Thinking-in-Modality (TiM) reasoning,
enabling flood prediction from basic Earth observation data such as Sentinel-1
or Sentinel-2 imagery. Using paired EO and simulated flood maps from data-rich
regions, ZeroFlood bridges data availability gaps through cross-modal
representation learning. Experiments with TerraMind and Prithvi GFMs show that
TiM enhances model robustness, with the TerraMind-Large configuration achieving
an F1 score of 67.21. The results demonstrate the feasibility of
foundation-model-based FSM as a scalable and data-efficient solution for flood
risk management.

</details>


### [32] [TAMI: Taming Heterogeneity in Temporal Interactions for Temporal Graph Link Prediction](https://arxiv.org/abs/2510.23577)
*Zhongyi Yu,Jianqiu Wu,Zhenghao Wu,Shuhan Zhong,Weifeng Su,Chul-Ho Lee,Weipeng Zhuo*

Main category: cs.LG

TL;DR: TAMI是一个处理时序图中异构性问题的框架，通过时间编码函数和链接历史聚合组件，有效提升时序图链接预测性能。


<details>
  <summary>Details</summary>
Motivation: 时序图中的交互存在异构性，如少数节点对产生大部分交互事件、交互间隔时间不均匀等，导致现有方法在预测不频繁交互节点对的链接时效果不佳。

Method: 提出TAMI框架，包含对数时间编码函数（LTE）和链接历史聚合（LHA）两个组件。LTE通过变换交互间隔时间实现更平衡的时间编码，LHA防止目标节点对的历史交互被遗忘。

Result: 在13个经典数据集和3个最新时序图基准数据集上的实验表明，TAMI在转导和归纳设置下都能持续提升底层模型的链接预测性能。

Conclusion: TAMI能有效处理时序图中的异构性问题，提升链接预测效果，且能与现有最先进的时序图神经网络无缝集成。

Abstract: Temporal graph link prediction aims to predict future interactions between
nodes in a graph based on their historical interactions, which are encoded in
node embeddings. We observe that heterogeneity naturally appears in temporal
interactions, e.g., a few node pairs can make most interaction events, and
interaction events happen at varying intervals. This leads to the problems of
ineffective temporal information encoding and forgetting of past interactions
for a pair of nodes that interact intermittently for their link prediction.
Existing methods, however, do not consider such heterogeneity in their learning
process, and thus their learned temporal node embeddings are less effective,
especially when predicting the links for infrequently interacting node pairs.
To cope with the heterogeneity, we propose a novel framework called TAMI, which
contains two effective components, namely log time encoding function (LTE) and
link history aggregation (LHA). LTE better encodes the temporal information
through transforming interaction intervals into more balanced ones, and LHA
prevents the historical interactions for each target node pair from being
forgotten. State-of-the-art temporal graph neural networks can be seamlessly
and readily integrated into TAMI to improve their effectiveness. Experiment
results on 13 classic datasets and three newest temporal graph benchmark (TGB)
datasets show that TAMI consistently improves the link prediction performance
of the underlying models in both transductive and inductive settings. Our code
is available at https://github.com/Alleinx/TAMI_temporal_graph.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [Energy-Efficient Domain-Specific Artificial Intelligence Models and Agents: Pathways and Paradigms](https://arxiv.org/abs/2510.22052)
*Abhijit Chatterjee,Niraj K. Jha,Jonathan D. Cohen,Thomas L. Griffiths,Hongjing Lu,Diana Marculescu,Ashiqur Rasul,Keshab K. Parhi*

Main category: cs.AI

TL;DR: 本文提出了下一代AI的发展愿景：从当前需要大量数据和能源的大型语言模型转向轻量级、领域特定的多模态智能体，这些智能体能够在动态环境中进行推理、规划和决策，同时实现超过现有技术1000倍的能效提升。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统（特别是大型语言模型）存在能耗巨大（GPT-4训练需50-60 GWh）、产生幻觉问题，且无法在关键应用领域部署。相比之下，人脑仅消耗20W功率，因此需要开发更节能、更智能的AI系统。

Method: 提出开发轻量级领域特定多模态模型，这些模型能够：1）在动态环境中进行推理、规划和决策；2）利用实时数据和先验知识；3）持续学习并增强未来决策能力；4）实现超过现有技术1000倍的能效提升。

Result: 提出了未来AI系统的愿景框架，强调从数据密集型大型模型向能效型智能体的转变，但未提供具体的实验结果。

Conclusion: 下一代AI应该朝着轻量级、领域特定、多模态、高能效的方向发展，这需要重新构想硬件架构以实现显著的能效提升，从而在充满不确定性的世界中实现真正的推理和思考能力。

Abstract: The field of artificial intelligence (AI) has taken a tight hold on broad
aspects of society, industry, business, and governance in ways that dictate the
prosperity and might of the world's economies. The AI market size is projected
to grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI
is dominated by large language models that exhibit linguistic and visual
intelligence. However, training these models requires a massive amount of data
scraped from the web as well as large amounts of energy (50--60 GWh to train
GPT-4). Despite these costs, these models often hallucinate, a characteristic
that prevents them from being deployed in critical application domains. In
contrast, the human brain consumes only 20~W of power. What is needed is the
next level of AI evolution in which lightweight domain-specific multimodal
models with higher levels of intelligence can reason, plan, and make decisions
in dynamic environments with real-time data and prior knowledge, while learning
continuously and evolving in ways that enhance future decision-making
capability. This will define the next wave of AI, progressing from today's
large models, trained with vast amounts of data, to nimble energy-efficient
domain-specific agents that can reason and think in a world full of
uncertainty. To support such agents, hardware will need to be reimagined to
allow energy efficiencies greater than 1000x over the state of the art. Such a
vision of future AI systems is developed in this work.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning](https://arxiv.org/abs/2510.21885)
*Anh Pham,Mihir Thalanki,Michael Sun,Aditya Chaloo,Ankita Gupta,Tian Xia,Aditya Mate,Ehimwenma Nosakhare,Soundararajan Srinivasan*

Main category: cs.CL

TL;DR: 提出行为感知采样框架，通过基于指令-响应行为和语义多样性的安全示例选择，有效缓解大语言模型在微调时的灾难性遗忘问题，仅需0.5%额外训练数据即可显著降低有害输出。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在良性数据上微调时经常失去之前对齐的安全行为（灾难性遗忘），现有方法添加随机安全示例效果有限，需要明确哪些示例最有效。

Method: 提出行为感知采样框架，基于两个互补因素选择安全示例：指令-响应行为（如拒绝vs服从）和跨伤害类别的语义多样性。

Result: 系统评估显示该方法显著减少有害输出同时保持帮助性，仅用0.5%额外训练数据即可实现高达41%的有害性降低。

Conclusion: 目标数据选择能够提高大规模微调的安全性和效率，为缓解灾难性遗忘提供了有效解决方案。

Abstract: Large language models often lose previously aligned safety behaviors when
fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior
work shows that adding random safety examples can mitigate this effect, but it
remains unclear which examples are most effective. We propose a behavior-aware
sampling framework that selects safety examples based on two complementary
factors: instruction-response behavior (e.g., refusal versus compliance) and
semantic diversity across harm categories. Systematic evaluation shows that
this approach substantially reduces harmful outputs while maintaining
helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%
additional training data. These results highlight how targeted data selection
can improve the safety and efficiency of fine-tuning at scale.

</details>


### [35] [You Don't Need Prompt Engineering Anymore: The Prompting Inversion](https://arxiv.org/abs/2510.22251)
*Imran Khan*

Main category: cs.CL

TL;DR: Sculpting是一种基于规则的约束提示方法，相比标准CoT能减少语义模糊和常识错误，但在更先进的GPT-5模型中反而有害，出现'提示反转'现象。


<details>
  <summary>Details</summary>
Motivation: 标准CoT提示存在语义模糊和常识错误问题，需要开发更精确的提示方法来提升LLM推理能力。

Method: 提出Sculpting方法，采用约束性、基于规则的提示策略，并与零样本、标准CoT在三个OpenAI模型上进行对比评估。

Result: Sculpting在GPT-4o上表现最佳(97% vs 93%)，但在GPT-5上反而有害(94% vs 96.36%)，出现'提示反转'现象。

Conclusion: 最优提示策略需与模型能力共同进化，更强大的模型需要更简单的提示，避免约束变成'手铐'。

Abstract: Prompt engineering, particularly Chain-of-Thought (CoT) prompting,
significantly enhances LLM reasoning capabilities. We introduce "Sculpting," a
constrained, rule-based prompting method designed to improve upon standard CoT
by reducing errors from semantic ambiguity and flawed common sense.
  We evaluate three prompting strategies (Zero Shot, standard CoT, and
Sculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)
using the GSM8K mathematical reasoning benchmark (1,317 problems).
  Our findings reveal a "Prompting Inversion": Sculpting provides advantages on
gpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%
vs. 96.36% for CoT on full benchmark). We trace this to a
"Guardrail-to-Handcuff" transition where constraints preventing common-sense
errors in mid-tier models induce hyper-literalism in advanced models. Our
detailed error analysis demonstrates that optimal prompting strategies must
co-evolve with model capabilities, suggesting simpler prompts for more capable
models.

</details>


### [36] [Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance](https://arxiv.org/abs/2510.22602)
*Mahyar Abbasian,Ramesh Jain*

Main category: cs.CL

TL;DR: 提出了个人护理效用（PCU）——一个基于人工智能的终身健康指导系统，通过整合多模态数据、知识和服务，为个人和群体提供持续的健康管理支持。


<details>
  <summary>Details</summary>
Motivation: 基于数字基础设施和生物医学创新的成功经验，旨在解决传统间歇性医疗的局限性，提供持续、个性化的健康指导。

Method: 采用多模态智能体、事件中心建模和上下文推理技术，整合个人感知、体验计算和群体分析，构建一个环境化、自适应的健康伴侣系统。

Result: PCU能够提供个性化可信健康信息、主动健康导航和行为指导，以及持续解释康复和治疗反应，实现实时健康监控和指导。

Conclusion: PCU不仅能为个人改善健康结果，还能为公共卫生和科学发现提供新的基础，代表了医疗健康领域的新范式。

Abstract: Building on decades of success in digital infrastructure and biomedical
innovation, we propose the Personal Care Utility (PCU) - a cybernetic system
for lifelong health guidance. PCU is conceived as a global, AI-powered utility
that continuously orchestrates multimodal data, knowledge, and services to
assist individuals and populations alike. Drawing on multimodal agents,
event-centric modeling, and contextual inference, it offers three essential
capabilities: (1) trusted health information tailored to the individual, (2)
proactive health navigation and behavior guidance, and (3) ongoing
interpretation of recovery and treatment response after medical events. Unlike
conventional episodic care, PCU functions as an ambient, adaptive companion -
observing, interpreting, and guiding health in real time across daily life. By
integrating personal sensing, experiential computing, and population-level
analytics, PCU promises not only improved outcomes for individuals but also a
new substrate for public health and scientific discovery. We describe the
architecture, design principles, and implementation challenges of this emerging
paradigm.

</details>


### [37] [Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models](https://arxiv.org/abs/2510.22752)
*Anooshka Bajaj,Deven Mahesh Mistry,Sahaj Singh Maini,Yash Aggarwal,Zoran Tiganj*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在上下文学习中的时间偏差，发现模型倾向于检索序列开头和结尾的信息，而中间部分的信息检索可靠性较低，这与人类情景记忆的时间分离机制类似。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何基于时间和语义关系检索上下文信息，类似于人类情景记忆中通过时间分离来检索特定事件的能力。

Method: 通过固定重复标记位置并置换其他标记来消除语义混淆，隔离时间效应对下一个标记预测的影响；使用包含多个相同标记呈现的序列进行测试。

Result: 模型始终对重复标记后的标记赋予最高概率，但存在明显的偏向序列开头或结尾的偏差；消融实验表明这种现象与transformer中的归纳头相关；状态空间模型和transformer模型显示出相似的时间偏差。

Conclusion: 研究加深了对上下文学习中时间偏差的理解，展示了这些偏差如何实现时间分离和情景检索，为理解LLM的记忆机制提供了新视角。

Abstract: In-context learning is governed by both temporal and semantic relationships,
shaping how Large Language Models (LLMs) retrieve contextual information.
Analogous to human episodic memory, where the retrieval of specific events is
enabled by separating events that happened at different times, this work probes
the ability of various pretrained LLMs, including transformer and state-space
models, to differentiate and retrieve temporally separated events.
Specifically, we prompted models with sequences containing multiple
presentations of the same token, which reappears at the sequence end. By fixing
the positions of these repeated tokens and permuting all others, we removed
semantic confounds and isolated temporal effects on next-token prediction.
Across diverse sequences, models consistently placed the highest probabilities
on tokens following a repeated token, but with a notable bias for those nearest
the beginning or end of the input. An ablation experiment linked this
phenomenon in transformers to induction heads. Extending the analysis to unique
semantic contexts with partial overlap further demonstrated that memories
embedded in the middle of a prompt are retrieved less reliably. Despite
architectural differences, state-space and transformer models showed comparable
temporal biases. Our findings deepen the understanding of temporal biases in
in-context learning and offer an illustration of how these biases can enable
temporal separation and episodic retrieval.

</details>


### [38] [Measuring Teaching with LLMs](https://arxiv.org/abs/2510.22968)
*Michael Hardy*

Main category: cs.CL

TL;DR: 本文开发了基于句子嵌入的定制化LLM，用于评估教学质量，在数据高效训练下达到人类水平甚至超人类表现，并与教师增值指标相关。


<details>
  <summary>Details</summary>
Motivation: 传统通用大语言模型难以可靠应用复杂的课堂观察工具，需要专门方法来解决教学质量的客观可扩展测量问题。

Method: 使用句子级嵌入构建定制化LLM，系统评估五种不同句子嵌入，采用防止过拟合的数据高效训练机制。

Result: 专业模型与专家人类评分相关性超过0.65，超越平均人-人评分相关性；高级模型将更多分数变化归因于课程级特征而非孤立话语。

Conclusion: 建立了AI驱动教学测量的可行强大新方法，为教育者发展提供可扩展、可靠和有效的反馈路径。

Abstract: Objective and scalable measurement of teaching quality is a persistent
challenge in education. While Large Language Models (LLMs) offer potential,
general-purpose models have struggled to reliably apply complex, authentic
classroom observation instruments. This paper uses custom LLMs built on
sentence-level embeddings, an architecture better suited for the long-form,
interpretive nature of classroom transcripts than conventional subword
tokenization. We systematically evaluate five different sentence embeddings
under a data-efficient training regime designed to prevent overfitting. Our
results demonstrate that these specialized models can achieve human-level and
even super-human performance with expert human ratings above 0.65 and
surpassing the average human-human rater correlation. Further, through analysis
of annotation context windows, we find that more advanced models-those better
aligned with human judgments-attribute a larger share of score variation to
lesson-level features rather than isolated utterances, challenging the
sufficiency of single-turn annotation paradigms. Finally, to assess external
validity, we find that aggregate model scores align with teacher value-added
measures, indicating they are capturing features relevant to student learning.
However, this trend does not hold at the individual item level, suggesting that
while the models learn useful signals, they have not yet achieved full
generalization. This work establishes a viable and powerful new methodology for
AI-driven instructional measurement, offering a path toward providing scalable,
reliable, and valid feedback for educator development.

</details>


### [39] [BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and Persona Reasoning](https://arxiv.org/abs/2510.23337)
*Siyuan Zheng,Pai Liu,Xi Chen,Jizheng Dong,Sihan Jia*

Main category: cs.CL

TL;DR: 提出了首个基于八字命理的人格推理问答数据集和BaZi-LLM系统，将符号推理与大型语言模型结合，生成时间动态且细粒度的虚拟人格，相比主流LLM准确率提升30.3%-62.6%。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟角色生成方法依赖标注数据或手工制作的人格提示，难以扩展且难以生成真实、上下文一致的人格。

Method: 创建首个八字命理人格推理问答数据集，将人类经验分类为财富、健康、亲属、职业和关系等生活事件问答；提出BaZi-LLM系统，整合符号推理与大型语言模型。

Result: 相比DeepSeek-v3和GPT-5-mini等主流LLM，准确率提升30.3%-62.6%；当使用错误八字信息时，模型准确率下降20%-45%。

Conclusion: 基于文化基础的符号-LLM整合在真实角色模拟方面具有潜力。

Abstract: Human-like virtual characters are crucial for games, storytelling, and
virtual reality, yet current methods rely heavily on annotated data or
handcrafted persona prompts, making it difficult to scale up and generate
realistic, contextually coherent personas. We create the first QA dataset for
BaZi-based persona reasoning, where real human experiences categorized into
wealth, health, kinship, career, and relationships are represented as
life-event questions and answers. Furthermore, we propose the first BaZi-LLM
system that integrates symbolic reasoning with large language models to
generate temporally dynamic and fine-grained virtual personas. Compared with
mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a
30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information
is used, our model's accuracy drops by 20%-45%, showing the potential of
culturally grounded symbolic-LLM integration for realistic character
simulation.

</details>


### [40] [EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting](https://arxiv.org/abs/2510.23396)
*Musleh Alharthi,Kaleel Mahmood,Sarosh Patel,Ausif Mahmood*

Main category: cs.CL

TL;DR: 本文提出了一个混合专家框架，结合了xLSTM、增强线性模型、PatchTST和minGRU等最先进模型，通过Transformer门控网络集成这些互补的时序预测模型，在标准基准测试中超越了所有现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对时序预测领域Transformer模型有效性的争议，以及数据倾向于近期历史且易受不可预测事件影响的特点，作者旨在开发一个能够整合多种互补模型的强大框架。

Method: 采用混合专家框架，集成xLSTM、增强线性模型、PatchTST、minGRU等SOTA模型，使用基于Transformer的门控网络来协调这些不同的时序预测专家。

Result: 在标准基准测试中，提出的模型超越了所有现有的时序预测模型，包括最新的基于MoE框架的方法。

Conclusion: 通过整合多种互补的时序预测模型，混合专家框架能够有效应对时序数据的特性，提供更优越的预测性能。

Abstract: The immense success of the Transformer architecture
  in Natural Language Processing has led to its adoption in Time Se ries
Forecasting (TSF), where superior performance has been shown.
  However, a recent important paper questioned their effectiveness by
  demonstrating that a simple single layer linear model outperforms
  Transformer-based models. This was soon shown to be not as valid,
  by a better transformer-based model termed PatchTST. More re cently, TimeLLM
demonstrated even better results by repurposing a
  Large Language Model (LLM) for the TSF domain. Again, a follow
  up paper challenged this by demonstrating that removing the LLM
  component or replacing it with a basic attention layer in fact yields
  better performance. One of the challenges in forecasting is the fact
  that TSF data favors the more recent past, and is sometimes subject
  to unpredictable events. Based upon these recent insights in TSF, we
  propose a strong Mixture of Experts (MoE) framework. Our method
  combines the state-of-the-art (SOTA) models including xLSTM, en hanced
Linear, PatchTST, and minGRU, among others. This set of
  complimentary and diverse models for TSF are integrated in a Trans former
based MoE gating network. Our proposed model outperforms
  all existing TSF models on standard benchmarks, surpassing even the
  latest approaches based on MoE frameworks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [41] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 本研究开发了一种基于光纤布拉格光栅和电磁追踪的力-位移分析方法，用于机器人辅助左心耳封堵术，无需电离辐射即可实时监测导管尖端位置和相互作用力，提高手术精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前左心耳封堵术依赖手动导管控制和荧光透视成像，存在辐射暴露和定位精度有限的问题，需要开发更安全、精确的术中监测方法。

Method: 使用集成光纤布拉格光栅的力传感输送鞘管结合电磁追踪系统，在解剖模型中进行机器人辅助左心耳封堵部署，通过力-位移分析方法表征封堵器部署动力学。

Result: 力分布显示低幅度的相互作用力，表明对周围解剖结构施加的机械应力最小，该方法能够识别关键手术步骤而不依赖电离辐射。

Conclusion: 这种力-位移分析方法有望为临床医生提供增强的术中反馈，改善部署结果，未来工作将专注于自动化部署步骤分类和在动态现实环境中验证传感策略。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [42] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: 开发了一个针对电动汽车的相位感知AI跟车模型，相比传统模型显著提高了预测精度


<details>
  <summary>Details</summary>
Motivation: 传统微观模型能有效捕捉内燃机车辆驾驶行为，但缺乏准确描述电动汽车独特跟车动力学的建模框架，而电动汽车在交通中的日益普及使得开发此类模型变得至关重要

Method: 提出了相位感知AI跟车模型，在传统物理框架基础上加入AI组件，识别并适应不同驾驶阶段（如快速加速和再生制动），使用配备自适应巡航控制的车辆真实轨迹数据进行综合仿真验证

Result: 数值结果表明，PAAI模型相比传统跟车模型显著提高了预测精度

Conclusion: 该模型为在交通仿真中准确表示电动汽车行为提供了有效工具

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [43] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [44] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 该研究将随机集神经网络（RS-NNs）集成到自动驾驶车辆软件栈中，使车辆能够明确量化预测不确定性，在不确定场景下动态调节车速以提高安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知系统在面对罕见事件或样本外数据时容易产生过度自信的预测错误，需要让车辆具备'知道何时不确定'的能力。

Method: 使用随机集神经网络作为不确定性感知图像分类器，预测类别集合的置信函数，与传统CNN和贝叶斯神经网络进行对比测试。

Result: RS-NN在多种道路条件下实现了显著更高的准确率和优越的不确定性校准，能够基于预测不确定性动态调节车辆速度。

Conclusion: 不确定性感知神经网络，特别是RS-NNs，是构建更安全、更鲁棒自动驾驶系统的实用解决方案。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [45] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: 提出一个结合学习策略与视觉异常检测的框架，通过三级恢复过程（暂停执行、局部扰动、重置到安全状态）来提高机器人策略执行的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 学习到的机器人策略虽然通用，但在开放环境中缺乏处理复杂性的机制，容易导致执行失败，需要能够识别和应对故障的方法来确保可靠安全的机器人行为。

Method: 使用名义执行数据训练异常检测模型，并将其集成到在线策略执行过程中。当检测到异常时，触发三级顺序恢复过程：暂停执行、局部状态扰动、从学习到的执行成功模型中采样重置到安全状态。

Result: 在两个不同场景（Kinova Gen3臂的门把手到达任务和UFactory xArm 6的物体放置任务）中验证，结果表明集成异常检测和恢复机制能显著提高在存在各种异常（如轨迹偏差和人为干扰）的环境中的执行成功率。

Conclusion: 将策略执行与异常检测和恢复相结合，能够有效提高机器人在复杂开放环境中的执行可靠性和安全性。

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>
