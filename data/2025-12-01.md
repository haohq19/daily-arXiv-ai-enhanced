<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 15]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DialBench: Towards Accurate Reading Recognition of Pointer Meter using Large Foundation Models](https://arxiv.org/abs/2511.21982)
*Futian Wang,Chaoliu Weng,Xiao Wang,Zhen Chen,Zhicheng Zhao,Jin Tang*

Main category: cs.CV

TL;DR: 提出RPM-10K大规模指针仪表数据集和基于物理关系注入的视觉语言模型MRLM，用于精确读取指针仪表读数


<details>
  <summary>Details</summary>
Motivation: 现有指针仪表读数识别方法在反射、遮挡、动态视角、指针与刻度标记重叠等挑战下表现脆弱，且缺乏大规模数据集支持鲁棒算法开发

Method: 1) 创建包含10730张仪表图像的RPM-10K数据集；2) 提出MRLM模型，通过物理关系注入显式编码指针与刻度的几何和因果关系，采用跨注意力融合和自适应专家选择机制

Result: 在新提出的基准数据集上进行了广泛实验，充分验证了所提框架的有效性

Conclusion: 通过构建大规模数据集和引入物理关系注入的视觉语言模型，显著提升了指针仪表读数识别的鲁棒性和准确性

Abstract: The precise reading recognition of pointer meters plays a key role in smart power systems, but existing approaches remain fragile due to challenges like reflections, occlusions, dynamic viewing angles, and overly between thin pointers and scale markings. Up to now, this area still lacks large-scale datasets to support the development of robust algorithms. To address these challenges, this paper first presents a new large-scale benchmark dataset for dial reading, termed RPM-10K, which contains 10730 meter images that fully reflect the aforementioned key challenges. Built upon the dataset, we propose a novel vision-language model for pointer meter reading recognition, termed MRLM, based on physical relation injection. Instead of exhaustively learning image-level correlations, MRLM explicitly encodes the geometric and causal relationships between the pointer and the scale, aligning perception with physical reasoning in the spirit of world-model perspectives. Through cross-attentional fusion and adaptive expert selection, the model learns to interpret dial configurations and generate precise numeric readings. Extensive experiments fully validated the effectiveness of our proposed framework on the newly proposed benchmark dataset. Both the dataset and source code will be released on https://github.com/Event-AHU/DialBench

</details>


### [2] [GA2-CLIP: Generic Attribute Anchor for Efficient Prompt Tuningin Video-Language Models](https://arxiv.org/abs/2511.22125)
*Bin Wang,Ruotong Hu,Wenqian Wang,Wentong Li,Mingliang Gao,Runmin Cong,Wei Zhang*

Main category: cs.CV

TL;DR: 提出耦合提示学习框架，通过引入外部监督提示和竞争性提示机制，缓解视频任务微调中的语义空间窄化问题，提升视觉语言模型在视频任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在视频任务微调时会出现泛化能力下降的问题，现有方法通过正则化手工提示与软提示之间的差距来缓解遗忘效应，但这会削弱软提示的学习能力。

Method: 提出插拔式耦合提示学习框架：1）文本提示方面，引入其他数据集的预训练提示作为硬提示标记，与软提示标记拼接并通过可学习映射层耦合；2）引入精心设计的无关视频集和负提示作为通用属性锚点，保持预训练语义空间中属性的通用相关性。

Result: 在视频任务实验中，该方法显著优于最先进的提示调优方法，在泛化基准测试中表现突出，特别是在基类到新类的预测任务上。

Conclusion: 通过竞争性提示机制和通用属性锚点，有效缓解了微调过程中的语义空间窄化问题，保持了视觉语言模型在视频任务中的泛化能力。

Abstract: Visual and textual soft prompt tuning can effectively improve the adaptability of Vision-Language Models (VLMs) in downstream tasks. However, fine-tuning on video tasks impairs the model's generalization ability to unseen classes. Existing methods attempt to mitigate this forgetting effect by regularizing the gap between hand-crafted prompts and soft prompts, but this also weakens the learning ability of soft prompts. To address this challenge, we propose a plug-and-play coupling prompt learning framework to optimize the generalization performance of V-L models in video tasks, with the core motivation of mitigating semantic space narrowing during fine-tuning by introducing an externally supervised prompt. Specifically, for textual prompts, we introduce pre-trained prompts from other datasets as hard prompt tokens. These are concatenated with soft prompt tokens and coupled via a learnable mapping layer. This competitive prompting approach prevents the semantic space from overfitting to supervised categories. In addition, we introduce a set of well-designed irrelevant video sets and negative prompts as generic attribute anchors to maintain the generic relevance of the attributes in the pre-trained semantic space, thus preserving the generalization ability. Experiments on video tasks demonstrate that our method significantly outperforms state-of-the-art prompt tuning approaches across generalization benchmarks, particularly on base-to-new class prediction.

</details>


### [3] [DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action](https://arxiv.org/abs/2511.22134)
*Zhen Fang,Zhuoyang Liu,Jiaming Liu,Hao Chen,Yu Zeng,Shiting Huang,Zehui Chen,Lin Chen,Shanghang Zhang,Feng Zhao*

Main category: cs.CV

TL;DR: DualVLA通过双阶段后训练解决VLA模型在恢复推理能力时出现的动作退化问题，在保持推理能力的同时提升动作性能


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在从专家模型扩展到通用推理模型时，经常出现动作性能下降的问题（动作退化现象），需要在保持推理能力的同时提升动作执行精度

Method: 1) 双层数据剪枝：去除冗余的具身推理数据，防止干扰动作学习；2) 双教师自适应蒸馏：对不同数据域分配不同的监督信号，同时保持推理能力；3) 提出VLA Score评估框架，从推理、意图、动作和对齐四个维度解耦评估

Result: DualVLA在SimplerEnv中达到61.0%的平均成功率，在八个多模态基准测试中平均得分65.4，在精确动作执行和多模态理解之间取得了更好的平衡

Conclusion: DualVLA通过精心设计的后训练策略有效解决了VLA模型的动作退化问题，在保持强大推理能力的同时显著提升了动作性能，为通用VLA模型的发展提供了新思路

Abstract: To build a generalizable Vision-Language-Action (VLA) model with strong reasoning ability, a common strategy is to first train a specialist VLA on robot demonstrations to acquire reliable manipulation skills, and then incorporate mixed annotated robot data together with multimodal data to restore broader reasoning capabilities. However, we observe that the resulting reasoning VLA often suffers from degraded action performance compared to the specialist model before fine-tuning, a phenomenon we refer to as action degeneration. To address this issue, we propose DualVLA, which enhances action performance through carefully designed post-training while still preserving reasoning capability. We first introduce a dual-layer data pruning method that removes redundant embodied reasoning, preventing it from adversely influencing action learning. To further strengthen action generation, we design a dual-teacher adaptive distillation strategy that assigns different supervision signals to different data domains while maintaining reasoning ability. To fill the evaluation gap for generalist VLAs, we also propose VLA Score, which decouples VLA capability into reasoning, intention, action, and alignment dimensions for a more fine-grained assessment. Experiments show that DualVLA achieves an average success rate of 61.0 in SimplerEnv and an average score of 65.4 across eight competitive multimodal benchmarks, demonstrating a stronger balance between precise action execution and multimodal understanding. Project Website: https://costaliya.github.io/DualVLA/.

</details>


### [4] [Real-Time Long Horizon Air Quality Forecasting via Group-Relative Policy Optimization](https://arxiv.org/abs/2511.22169)
*Inha Kang,Eunki Kim,Wonjeong Ryu,Jaeyo Shin,Seungjun Yu,Yoon-Hee Kang,Seongeun Jeong,Eunhye Kim,Soontae Kim,Hyunjung Shim*

Main category: cs.CV

TL;DR: 该论文提出了一个针对东亚地区PM浓度长期预测的改进框架，通过构建真实观测数据集和引入基于组相对策略优化的对齐方法，显著降低了误报率，提高了预测系统的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型（如Aurora）在复杂地形和强大气动力学的东亚地区存在局限性：缺乏区域特定动态、依赖非实时输入，且标准点预测目标无法反映操作成本的不对称性（误报损害公众信任，漏报危及人群健康）。

Method: 1) 构建并发布东亚地区的真实观测和高分辨率CMAQ-OBS数据集；2) 提出组相对策略优化（GRPO），结合类别特定奖励和课程式展开，使预测与操作优先级对齐。

Result: 区域误差降低59.5%，支持实时48-120小时预测；与仅使用监督微调（SFT）的基线相比，误报率降低47.3%，同时保持有竞争力的F1分数，显著提高了长期预测场景下的可靠性。

Conclusion: 该框架通过数据集构建和操作成本对齐优化，有效解决了东亚地区PM浓度长期预测的实践挑战，为公共卫生预警系统提供了更可靠、实用的空气质量预测解决方案。

Abstract: Accurate long horizon forecasting of particulate matter (PM) concentration fields is essential for operational public health decisions. However, achieving reliable forecasts remains challenging in regions with complex terrain and strong atmospheric dynamics such as East Asia. While foundation models such as Aurora offer global generality, they often miss region-specific dynamics and rely on non-real-time inputs, limiting their practical utility for localized warning systems. To address this gap, we construct and release the real-world observations and high-resolution CMAQ-OBS dataset for East Asia, reducing regional error by 59.5% and enabling real-time 48-120 hour forecasts critical for public health alerts. However, standard point-wise objectives cannot reflect asymmetric operational costs, where false alarms deteriorate public trust while missed severe events endanger populations. This cost mismatch causes SFT models to over-predict and yield high False Alarm Rates. We introduce Group-Relative Policy Optimization (GRPO) with class-wise rewards and curriculum rollout to align predictions with operational priorities. Experimental results demonstrate that our framework significantly improves the reliability of the forecast. Compared to the SFT-only baseline, our model reduces the False Alarm Rate by 47.3% while achieving a competitive F1-score, proving its effectiveness for practical, real-world air quality forecasting systems on long lead time scenarios.

</details>


### [5] [Creating Blank Canvas Against AI-enabled Image Forgery](https://arxiv.org/abs/2511.22237)
*Qi Song,Ziyuan Luo,Renjie Wan*

Main category: cs.CV

TL;DR: 提出一种基于SAM的篡改检测新方法，通过对抗扰动使SAM"看不见"原始图像，从而在图像被篡改时识别伪造区域


<details>
  <summary>Details</summary>
Motivation: AIGC图像编辑技术简化了逼真图像修改，带来了严重的图像伪造风险，需要有效的篡改检测方法

Method: 1) 将图像转化为神经模型的"空白画布"；2) 引入对抗扰动使SAM无法"看见"原始内容；3) 采用频率感知优化策略彻底欺骗SAM；4) 当图像被篡改时，SAM能识别伪造区域

Result: 大量实验结果表明该方法在篡改定位方面具有有效性

Conclusion: 通过使SAM对原始图像"失明"的新策略，实现了有效的篡改检测，为解决AIGC带来的图像伪造风险提供了新思路

Abstract: AIGC-based image editing technology has greatly simplified the realistic-level image modification, causing serious potential risks of image forgery. This paper introduces a new approach to tampering detection using the Segment Anything Model (SAM). Instead of training SAM to identify tampered areas, we propose a novel strategy. The entire image is transformed into a blank canvas from the perspective of neural models. Any modifications to this blank canvas would be noticeable to the models. To achieve this idea, we introduce adversarial perturbations to prevent SAM from ``seeing anything'', allowing it to identify forged regions when the image is tampered with. Due to SAM's powerful perceiving capabilities, naive adversarial attacks cannot completely tame SAM. To thoroughly deceive SAM and make it blind to the image, we introduce a frequency-aware optimization strategy, which further enhances the capability of tamper localization. Extensive experimental results demonstrate the effectiveness of our method.

</details>


### [6] [Semantic Anchoring for Robust Personalization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.22245)
*Seoyun Yang,Gihoon Kim,Taesup Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种基于语义锚定的文本到图像扩散模型个性化方法，通过将新概念锚定到预训练分布中，在保持语义一致性的同时学习用户特定的视觉概念。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型在个性化方面存在挑战：从少量参考图像学习新视觉概念时，要么过度拟合参考图像而失去预训练语义先验，要么强调先验保持而无法学习新的个性化属性。需要在保持文本-图像对齐的同时实现稳定的个性化适应。

Method: 提出语义锚定策略，将个性化过程重新定义为通过语义锚定在频繁对应概念的指导下学习罕见概念。该方法通过将新概念锚定到其对应分布中来引导模型适应，使模型能够以稳定可控的方式适应新概念，同时保持预训练的语义结构。

Result: 与基线方法相比，提出的方法实现了稳定的适应，并在主体保真度和文本-图像对齐方面都取得了一致的改进。广泛的实验和消融研究进一步证明了所提锚定策略的鲁棒性和有效性。

Conclusion: 语义锚定策略能够有效地指导扩散模型个性化过程，在扩展预训练分布到个性化区域的同时保持其语义结构，解决了现有方法在主体保真度和语义保持之间的权衡问题。

Abstract: Text-to-image diffusion models have achieved remarkable progress in generating diverse and realistic images from textual descriptions. However, they still struggle with personalization, which requires adapting a pretrained model to depict user-specific subjects from only a few reference images. The key challenge lies in learning a new visual concept from a limited number of reference images while preserving the pretrained semantic prior that maintains text-image alignment. When the model focuses on subject fidelity, it tends to overfit the limited reference images and fails to leverage the pretrained distribution. Conversely, emphasizing prior preservation maintains semantic consistency but prevents the model from learning new personalized attributes. Building on these observations, we propose the personalization process through a semantic anchoring that guides adaptation by grounding new concepts in their corresponding distributions. We therefore reformulate personalization as the process of learning a rare concept guided by its frequent counterpart through semantic anchoring. This anchoring encourages the model to adapt new concepts in a stable and controlled manner, expanding the pretrained distribution toward personalized regions while preserving its semantic structure. As a result, the proposed method achieves stable adaptation and consistent improvements in both subject fidelity and text-image alignment compared to baseline methods. Extensive experiments and ablation studies further demonstrate the robustness and effectiveness of the proposed anchoring strategy.

</details>


### [7] [Toward Diffusible High-Dimensional Latent Spaces: A Frequency Perspective](https://arxiv.org/abs/2511.22249)
*Bolin Lai,Xudong Wang,Saketh Rambhatla,James M. Rehg,Zsolt Kira,Rohit Girdhar,Ishan Misra*

Main category: cs.CV

TL;DR: FreqWarm：一种即插即用的频率预热课程，通过增加扩散训练早期阶段对高频潜在信号的暴露，解决潜在扩散中重建与生成的权衡问题，无需修改或重新训练自编码器。


<details>
  <summary>Details</summary>
Motivation: 潜在扩散已成为视觉生成的默认范式，但观察到随着潜在维度增加，重建与生成之间存在持续权衡：更高容量的自编码器提高重建保真度，但生成质量最终下降。研究发现这是由于高频编码和解码行为差异导致的。

Method: 通过RGB和潜在域中的受控扰动分析编码器/解码器行为，发现解码器强烈依赖高频潜在分量来恢复细节，而编码器对高频内容表示不足。为此提出FreqWarm，一种频率预热课程，在扩散或流匹配训练早期阶段增加对高频潜在信号的暴露，无需修改自编码器。

Result: 在多个高维自编码器上应用FreqWarm，一致改善生成质量：在Wan2.2-VAE上gFID降低14.11，在LTX-VAE上降低6.13，在DC-AE-f32上降低4.42。该方法与架构无关，兼容多种骨干网络。

Conclusion: 研究表明，显式管理频率暴露可以成功地将高维潜在空间转化为更可扩散的目标，FreqWarm为解决潜在扩散中的重建-生成权衡提供了有效解决方案。

Abstract: Latent diffusion has become the default paradigm for visual generation, yet we observe a persistent reconstruction-generation trade-off as latent dimensionality increases: higher-capacity autoencoders improve reconstruction fidelity but generation quality eventually declines. We trace this gap to the different behaviors in high-frequency encoding and decoding. Through controlled perturbations in both RGB and latent domains, we analyze encoder/decoder behaviors and find that decoders depend strongly on high-frequency latent components to recover details, whereas encoders under-represent high-frequency contents, yielding insufficient exposure and underfitting in high-frequency bands for diffusion model training. To address this issue, we introduce FreqWarm, a plug-and-play frequency warm-up curriculum that increases early-stage exposure to high-frequency latent signals during diffusion or flow-matching training -- without modifying or retraining the autoencoder. Applied across several high-dimensional autoencoders, FreqWarm consistently improves generation quality: decreasing gFID by 14.11 on Wan2.2-VAE, 6.13 on LTX-VAE, and 4.42 on DC-AE-f32, while remaining architecture-agnostic and compatible with diverse backbones. Our study shows that explicitly managing frequency exposure can successfully turn high-dimensional latent spaces into more diffusible targets.

</details>


### [8] [UAV-MM3D: A Large-Scale Synthetic Benchmark for 3D Perception of Unmanned Aerial Vehicles with Multi-Modal Data](https://arxiv.org/abs/2511.22404)
*Longkun Zou,Jiale Wang,Rongqin Liang,Hai Wu,Ke Chen,Yaowei Wang*

Main category: cs.CV

TL;DR: UAV-MM3D是一个用于低空无人机感知的高保真多模态合成数据集，包含40万帧同步数据，涵盖多种场景、天气条件和无人机模型，提供五种传感器模态和丰富标注，用于3D检测、姿态估计、跟踪和轨迹预测等任务。


<details>
  <summary>Details</summary>
Motivation: 真实世界无人机数据收集面临空域管制、隐私问题和环境变化等限制，而手动标注3D姿态和跨模态对应关系耗时且昂贵，因此需要大规模、准确标注的多模态数据集来推动无人机感知研究。

Method: 通过可控仿真环境创建UAV-MM3D合成数据集，包含40万帧同步数据，涵盖城市、郊区、森林、海岸等多种场景和天气条件，提供RGB、红外、LiDAR、雷达和DVS五种传感器模态，并包含2D/3D边界框、6自由度姿态和实例级标注。

Result: 开发了UAV-MM3D数据集，并提出LGFusionNet（LiDAR引导的多模态融合基线）和专用的无人机轨迹预测基线，为无人机3D感知和运动理解提供了公开基准。

Conclusion: UAV-MM3D通过其可控仿真环境、全面的场景覆盖和丰富标注，为推进无人机3D感知研究提供了有价值的公共基准，有助于克服真实数据收集和标注的挑战。

Abstract: Accurate perception of UAVs in complex low-altitude environments is critical for airspace security and related intelligent systems. Developing reliable solutions requires large-scale, accurately annotated, and multimodal data. However, real-world UAV data collection faces inherent constraints due to airspace regulations, privacy concerns, and environmental variability, while manual annotation of 3D poses and cross-modal correspondences is time-consuming and costly. To overcome these challenges, we introduce UAV-MM3D, a high-fidelity multimodal synthetic dataset for low-altitude UAV perception and motion understanding. It comprises 400K synchronized frames across diverse scenes (urban areas, suburbs, forests, coastal regions) and weather conditions (clear, cloudy, rainy, foggy), featuring multiple UAV models (micro, small, medium-sized) and five modalities - RGB, IR, LiDAR, Radar, and DVS (Dynamic Vision Sensor). Each frame provides 2D/3D bounding boxes, 6-DoF poses, and instance-level annotations, enabling core tasks related to UAVs such as 3D detection, pose estimation, target tracking, and short-term trajectory forecasting. We further propose LGFusionNet, a LiDAR-guided multimodal fusion baseline, and a dedicated UAV trajectory prediction baseline to facilitate benchmarking. With its controllable simulation environment, comprehensive scenario coverage, and rich annotations, UAV3D offers a public benchmark for advancing 3D perception of UAVs.

</details>


### [9] [Wukong's 72 Transformations: High-fidelity Textured 3D Morphing via Flow Models](https://arxiv.org/abs/2511.22425)
*Minghao Yin,Yukang Cao,Kai Han*

Main category: cs.CV

TL;DR: WUKONG是一个无需训练的高保真纹理3D变形框架，利用基于流的transformer生成先验，通过最优传输重心问题实现平滑形状过渡，并引入相似性引导的语义一致性机制保持纹理细节。


<details>
  <summary>Details</summary>
Motivation: 传统3D变形方法依赖手动对应匹配和变形轨迹估计，限制了泛化能力且需要昂贵的预处理。需要一种能够自动生成高质量3D变形并保持纹理细节的方法。

Method: 1) 利用基于流的transformer生成先验；2) 将变形建模为最优传输重心问题确保平滑形状过渡；3) 引入序列初始化策略防止几何畸变；4) 提出相似性引导的语义一致性机制选择性保留高频细节和控制混合动态。

Result: 广泛的定量和定性评估表明，WUKONG在多样化的几何和纹理变化上显著优于现有最先进方法，实现了高质量的3D变形结果。

Conclusion: WUKONG框架通过利用生成先验和最优传输理论，实现了无需训练的高保真3D变形，在保持纹理细节和语义一致性方面表现出色，为3D内容创作提供了有效工具。

Abstract: We present WUKONG, a novel training-free framework for high-fidelity textured 3D morphing that takes a pair of source and target prompts (image or text) as input. Unlike conventional methods -- which rely on manual correspondence matching and deformation trajectory estimation (limiting generalization and requiring costly preprocessing) -- WUKONG leverages the generative prior of flow-based transformers to produce high-fidelity 3D transitions with rich texture details. To ensure smooth shape transitions, we exploit the inherent continuity of flow-based generative processes and formulate morphing as an optimal transport barycenter problem. We further introduce a sequential initialization strategy to prevent abrupt geometric distortions and preserve identity coherence. For faithful texture preservation, we propose a similarity-guided semantic consistency mechanism that selectively retains high-frequency details and enables precise control over blending dynamics. This avoids common artifacts like oversmoothing while maintaining semantic fidelity. Extensive quantitative and qualitative evaluations demonstrate that WUKONG significantly outperforms state-of-the-art methods, achieving superior results across diverse geometry and texture variations.

</details>


### [10] [ITS3D: Inference-Time Scaling for Text-Guided 3D Diffusion Models](https://arxiv.org/abs/2511.22456)
*Zhenglin Zhou,Fan Ma,Xiaobo Xia,Hehe Fan,Yi Yang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: ITS3D是一个无需额外训练的推理时缩放框架，通过优化高斯噪声输入来提升文本引导3D扩散模型的生成质量，采用验证器引导的搜索算法和三种技术改进稳定性、效率和探索能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何在无需额外训练的情况下，通过推理时缩放来提升文本引导3D扩散模型的生成质量，解决3D生成中的稳定性、计算效率和局部最优问题。

Method: 提出ITS3D框架，将任务形式化为优化问题以寻找最优高斯噪声输入。采用验证器引导的搜索算法，迭代优化噪声候选。引入三种关键技术：1) 高斯归一化稳定搜索过程；2) 基于奇异值分解的压缩技术降低高维搜索空间复杂度；3) 奇异空间重置机制防止陷入局部最优。

Result: 大量实验表明ITS3D能够显著提升文本到3D生成的质量，展示了计算高效搜索方法在生成过程中的潜力。

Conclusion: ITS3D通过推理时优化噪声输入，有效提升了3D扩散模型的生成质量，为无需额外训练的生成质量改进提供了可行方案。

Abstract: We explore inference-time scaling in text-guided 3D diffusion models to enhance generative quality without additional training. To this end, we introduce ITS3D, a framework that formulates the task as an optimization problem to identify the most effective Gaussian noise input. The framework is driven by a verifier-guided search algorithm, where the search algorithm iteratively refines noise candidates based on verifier feedback. To address the inherent challenges of 3D generation, we introduce three techniques for improved stability, efficiency, and exploration capability. 1) Gaussian normalization is applied to stabilize the search process. It corrects distribution shifts when noise candidates deviate from a standard Gaussian distribution during iterative updates. 2) The high-dimensional nature of the 3D search space increases computational complexity. To mitigate this, a singular value decomposition-based compression technique is employed to reduce dimensionality while preserving effective search directions. 3) To further prevent convergence to suboptimal local minima, a singular space reset mechanism dynamically updates the search space based on diversity measures. Extensive experiments demonstrate that ITS3D enhances text-to-3D generation quality, which shows the potential of computationally efficient search methods in generative processes. The source code is available at https://github.com/ZhenglinZhou/ITS3D.

</details>


### [11] [Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach](https://arxiv.org/abs/2511.23311)
*Haruki Sakajo,Hiroshi Takato,Hiroshi Tsutsui,Komei Soda,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CV

TL;DR: 论文研究了大规模视觉语言模型在同步处理驾驶员视角和道路视角视频方面的能力，用于生成安全驾驶指令，发现预训练模型效果有限但微调后能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶等工业应用需要同时监控驾驶员行为和道路状况以确保安全，但现有LVLMs在处理同步多视角视频方面能力有限，需要研究其在此领域的潜力。

Method: 构建了包含驾驶员视角和道路视角同步视频的数据集，对LVLMs进行微调，并评估其在生成安全驾驶指令方面的性能。

Result: 实验结果显示预训练LVLMs效果有限，但经过微调的模型能够生成准确且安全意识的驾驶指令，不过在检测视频中细微或复杂事件方面仍存在挑战。

Conclusion: LVLMs在同步多视角视频处理方面具有潜力，微调能显著提升性能，但检测复杂事件仍是挑战，研究结果为该领域系统改进提供了有价值的见解。

Abstract: Large-scale Vision Language Models (LVLMs) exhibit advanced capabilities in tasks that require visual information, including object detection. These capabilities have promising applications in various industrial domains, such as autonomous driving. For example, LVLMs can generate safety-oriented descriptions of videos captured by road-facing cameras. However, ensuring comprehensive safety requires monitoring driver-facing views as well to detect risky events, such as the use of mobiles while driving. Thus, the ability to process synchronized inputs is necessary from both driver-facing and road-facing cameras. In this study, we develop models and investigate the capabilities of LVLMs by constructing a dataset and evaluating their performance on this dataset. Our experimental results demonstrate that while pre-trained LVLMs have limited effectiveness, fine-tuned LVLMs can generate accurate and safety-aware driving instructions. Nonetheless, several challenges remain, particularly in detecting subtle or complex events in the video. Our findings and error analysis provide valuable insights that can contribute to the improvement of LVLM-based systems in this domain.

</details>


### [12] [Taming the Light: Illumination-Invariant Semantic 3DGS-SLAM](https://arxiv.org/abs/2511.22968)
*Shouhe Zhang,Dayong Ren,Sensen Song,Yurong Qian,Zhenhong Jia*

Main category: cs.CV

TL;DR: 提出一种新颖的语义SLAM框架，通过主动的固有外观归一化模块和反应式的动态辐射平衡损失，实现光照不变性，提升极端曝光条件下的系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 极端曝光会同时降低3D地图重建和语义分割的准确性，这对紧耦合系统特别有害。现有方法缺乏对光照变化的鲁棒性，需要一种能够处理极端光照条件的解决方案。

Method: 1. 固有外观归一化模块：主动解耦场景的固有属性（如反照率）和瞬时光照，学习标准化的光照不变外观模型，为每个高斯基元分配稳定一致的颜色表示。
2. 动态辐射平衡损失：仅在图像曝光不佳时激活，直接在辐射场上操作以指导针对性优化，防止极端光照下的误差累积，同时不影响正常条件下的性能。

Result: 在公开数据集上的评估表明，在相机跟踪、地图质量、语义和几何精度方面都达到了最先进的性能。

Conclusion: IAN的主动不变性和DRB-Loss的反应式校正之间的协同作用，赋予了系统前所未有的鲁棒性，能够在极端光照条件下保持稳定的语义SLAM性能。

Abstract: Extreme exposure degrades both the 3D map reconstruction and semantic segmentation accuracy, which is particularly detrimental to tightly-coupled systems. To achieve illumination invariance, we propose a novel semantic SLAM framework with two designs. First, the Intrinsic Appearance Normalization (IAN) module proactively disentangles the scene's intrinsic properties, such as albedo, from transient lighting. By learning a standardized, illumination-invariant appearance model, it assigns a stable and consistent color representation to each Gaussian primitive. Second, the Dynamic Radiance Balancing Loss (DRB-Loss) reactively handles frames with extreme exposure. It activates only when an image's exposure is poor, operating directly on the radiance field to guide targeted optimization. This prevents error accumulation from extreme lighting without compromising performance under normal conditions. The synergy between IAN's proactive invariance and DRB-Loss's reactive correction endows our system with unprecedented robustness. Evaluations on public datasets demonstrate state-of-the-art performance in camera tracking, map quality, and semantic and geometric accuracy.

</details>


### [13] [MultiBanana: A Challenging Benchmark for Multi-Reference Text-to-Image Generation](https://arxiv.org/abs/2511.22989)
*Yuta Oshima,Daiki Miyake,Kohsei Matsutani,Yusuke Iwasawa,Masahiro Suzuki,Yutaka Matsuo,Hiroki Furuta*

Main category: cs.CV

TL;DR: MultiBanana是一个新的多参考图像生成基准测试，旨在评估文本到图像模型在多参考条件下的能力，包括参考数量变化、领域不匹配、尺度不匹配、罕见概念和多语言文本参考等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单参考或少量参考图像生成，无法全面评估模型在多参考条件下的性能，且任务定义模糊，无法捕捉多参考设置的内在难度。

Method: 设计MultiBanana基准测试，广泛覆盖多参考特定问题：1) 参考数量变化；2) 参考图像间领域不匹配（如照片vs动漫）；3) 参考与目标场景尺度不匹配；4) 包含罕见概念的参考；5) 多语言文本参考。

Result: 对多种文本到图像模型的分析揭示了它们的优越性能、典型失败模式和需要改进的领域。MultiBanana将作为开放基准发布，为多参考图像生成建立标准化比较基础。

Conclusion: MultiBanana填补了多参考图像生成评估的空白，通过系统化的基准测试推动该领域发展，为公平比较提供标准化基础，并识别模型在多参考条件下的能力边界和改进方向。

Abstract: Recent text-to-image generation models have acquired the ability of multi-reference generation and editing; the ability to inherit the appearance of subjects from multiple reference images and re-render them under new contexts. However, the existing benchmark datasets often focus on the generation with single or a few reference images, which prevents us from measuring the progress on how model performance advances or pointing out their weaknesses, under different multi-reference conditions. In addition, their task definitions are still vague, typically limited to axes such as "what to edit" or "how many references are given", and therefore fail to capture the intrinsic difficulty of multi-reference settings. To address this gap, we introduce $\textbf{MultiBanana}$, which is carefully designed to assesses the edge of model capabilities by widely covering multi-reference-specific problems at scale: (1) varying the number of references, (2) domain mismatch among references (e.g., photo vs. anime), (3) scale mismatch between reference and target scenes, (4) references containing rare concepts (e.g., a red banana), and (5) multilingual textual references for rendering. Our analysis among a variety of text-to-image models reveals their superior performances, typical failure modes, and areas for improvement. MultiBanana will be released as an open benchmark to push the boundaries and establish a standardized basis for fair comparison in multi-reference image generation. Our data and code are available at https://github.com/matsuolab/multibanana .

</details>


### [14] [JarvisEvo: Towards a Self-Evolving Photo Editing Agent with Synergistic Editor-Evaluator Optimization](https://arxiv.org/abs/2511.23002)
*Yunlong Lin,Linqing Wang,Kunjie Lin,Zixu Lin,Kaixiong Gong,Wenbo Li,Bin Lin,Zhenxi Li,Shiyi Zhang,Yuyang Peng,Wenxun Dai,Xinghao Ding,Chunyu Wang,Qinglin Lu*

Main category: cs.CV

TL;DR: JarvisEvo：一个统一的图像编辑智能体，通过多模态思维链推理和协同编辑-评估策略优化，解决指令幻觉和奖励攻击问题，在图像编辑任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于智能体的编辑模型存在两个关键挑战：1) 指令幻觉 - 纯文本思维链推理无法完全避免事实错误；2) 奖励攻击 - 动态策略优化会利用静态奖励函数的缺陷。需要解决这些问题来提升编辑质量。

Method: 提出JarvisEvo统一图像编辑智能体，模拟人类专家设计师的迭代编辑过程。核心包括：1) 交错多模态思维链推理机制(iMCoT)；2) 协同编辑-评估策略优化框架(SEPO)，无需外部奖励实现自我改进；3) 集成Adobe Lightroom支持全局和局部精细编辑。

Result: 在ArtEdit-Bench上，JarvisEvo比Nano-Banana平均提升18.95%的保护性编辑指标，其中像素级内容保真度大幅提升44.96%。

Conclusion: JarvisEvo通过创新的多模态推理和自改进框架，有效解决了指令幻觉和奖励攻击问题，显著提升了图像编辑的质量和可靠性。

Abstract: Agent-based editing models have substantially advanced interactive experiences, processing quality, and creative flexibility. However, two critical challenges persist: (1) instruction hallucination, text-only chain-of-thought (CoT) reasoning cannot fully prevent factual errors due to inherent information bottlenecks; (2) reward hacking, dynamic policy optimization against static reward models allows agents to exploit flaws in reward functions. To address these issues, we propose JarvisEvo, a unified image editing agent that emulates an expert human designer by iteratively editing, selecting appropriate tools, evaluating results, and reflecting on its own decisions to refine outcomes. JarvisEvo offers three key advantages: (1) an interleaved multimodal chain-of-thought (iMCoT) reasoning mechanism that enhances instruction following and editing quality; (2) a synergistic editor-evaluator policy optimization (SEPO) framework that enables self-improvement without external rewards, effectively mitigating reward hacking; and (3) support for both global and local fine-grained editing through seamless integration of Adobe Lightroom. On ArtEdit-Bench, JarvisEvo outperforms Nano-Banana by an average of 18.95% on preservative editing metrics, including a substantial 44.96% improvement in pixel-level content fidelity.

</details>


### [15] [A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors](https://arxiv.org/abs/2511.23355)
*Vinh Chau,Khoa Le Dinh Van,Hon Huynh Ngoc,Binh Nguyen Thien,Hao Nguyen Thien,Vy Nguyen Quang,Phuc Vo Hong,Yen Lam Minh,Kieu Pham Tieu,Trinh Nguyen Thi Diem,Louise Thwaites,Hai Ho Bich*

Main category: cs.CV

TL;DR: 提出基于计算机视觉的管道，从床旁监护仪屏幕自动捕获和数字化生命体征数据，解决低资源医疗环境中设备缺乏网络连接的问题。


<details>
  <summary>Details</summary>
Motivation: 低资源医疗环境中，床旁监护仪多为独立遗留设备，缺乏网络连接，导致生理数据无法无缝集成到电子健康记录系统，形成互操作性障碍。

Method: 采用分层检测框架：YOLOv11用于精确定位监护仪和感兴趣区域，PaddleOCR用于稳健的文本提取。包含几何校正模块，在不同摄像头角度和光照条件下标准化屏幕透视。

Result: 在6,498张图像数据集上评估：监护仪检测mAP@50-95达99.5%，生命体征ROI定位达91.5%。端到端提取核心生理参数（心率、血氧饱和度、动脉血压）准确率超过98.9%。

Conclusion: 轻量级、基于摄像头的方法能可靠地将屏幕捕获的非结构化信息转化为结构化数字数据，为低资源环境提供实用、可扩展的解决方案，改善信息可访问性和临床文档记录。

Abstract: In many low-resource healthcare settings, bedside monitors remain standalone legacy devices without network connectivity, creating a persistent interoperability gap that prevents seamless integration of physiological data into electronic health record (EHR) systems. To address this challenge without requiring costly hardware replacement, we present a computer vision-based pipeline for the automated capture and digitisation of vital sign data directly from bedside monitor screens. Our method employs a hierarchical detection framework combining YOLOv11 for accurate monitor and region of interest (ROI) localisation with PaddleOCR for robust text extraction. To enhance reliability across variable camera angles and lighting conditions, a geometric rectification module standardizes the screen perspective before character recognition. We evaluated the system on a dataset of 6,498 images collected from open-source corpora and real-world intensive care units in Vietnam. The model achieved a mean Average Precision (mAP@50-95) of 99.5% for monitor detection and 91.5% for vital sign ROI localisation. The end-to-end extraction accuracy exceeded 98.9% for core physiological parameters, including heart rate, oxygen saturation SpO2, and arterial blood pressure. These results demonstrate that a lightweight, camera-based approach can reliably transform unstructured information from screen captures into structured digital data, providing a practical and scalable pathway to improve information accessibility and clinical documentation in low-resource settings.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [16] [Physics-Informed Spiking Neural Networks via Conservative Flux Quantization](https://arxiv.org/abs/2511.21784)
*Chi Zhang,Lin Wang*

Main category: cs.LG

TL;DR: 提出PISNN框架，结合物理约束与脉冲神经网络，通过C-LIF神经元和CFQ策略实现严格物理守恒和长期泛化，适用于边缘设备实时物理预测。


<details>
  <summary>Details</summary>
Motivation: 边缘设备需要实时、物理一致的预测，但传统PINNs能耗高且难以严格保证物理守恒定律。脉冲神经网络虽适合边缘计算，但简单转换会降低物理保真度。

Method: 提出PISNN框架：1) 设计C-LIF神经元，其动力学结构保证局部质量守恒；2) 提出CFQ策略，将神经脉冲重新定义为物理通量的离散包，学习时间不变的物理演化算子。

Result: 在1D热方程和2D拉普拉斯方程等基准测试中，PISNN能准确模拟系统动力学，同时通过设计保持完美的质量守恒，优于传统PINNs。

Conclusion: 该工作建立了将科学计算的严谨性与神经形态工程效率融合的稳健框架，为智能系统的复杂、长期、节能物理预测铺平了道路。

Abstract: Real-time, physically-consistent predictions on low-power edge devices is critical for the next generation embodied AI systems, yet it remains a major challenge. Physics-Informed Neural Networks (PINNs) combine data-driven learning with physics-based constraints to ensure the model's predictions are with underlying physical principles.However, PINNs are energy-intensive and struggle to strictly enforce physical conservation laws. Brain-inspired spiking neural networks (SNNs) have emerged as a promising solution for edge computing and real-time processing. However, naively converting PINNs to SNNs degrades physical fidelity and fails to address long-term generalization issues. To this end, this paper introduce a novel Physics-Informed Spiking Neural Network (PISNN) framework. Importantly, to ensure strict physical conservation, we design the Conservative Leaky Integrate-and-Fire (C-LIF) neuron, whose dynamics structurally guarantee local mass preservation. To achieve robust temporal generalization, we introduce a novel Conservative Flux Quantization (CFQ) strategy, which redefines neural spikes as discrete packets of physical flux. Our CFQ learns a time-invariant physical evolution operator, enabling the PISNN to become a general-purpose solver -- conservative-by-construction. Extensive experiments show that our PISNN excels on diverse benchmarks. For both the canonical 1D heat equation and the more challenging 2D Laplace's Equation, it accurately simulates the system dynamics while maintaining perfect mass conservation by design -- a feat that is challenging for conventional PINNs. This work establishes a robust framework for fusing the rigor of scientific computing with the efficiency of neuromorphic engineering, paving the way for complex, long-term, and energy-efficient physics predictions for intelligent systems.

</details>


### [17] [PULSE-ICU: A Pretrained Unified Long-Sequence Encoder for Multi-task Prediction in Intensive Care Units](https://arxiv.org/abs/2511.22199)
*Sejeong Jang,Joo Heung Yoon,Hyo Kyung Lee*

Main category: cs.LG

TL;DR: PULSE-ICU是一个自监督基础模型，通过统一嵌入模块和Longformer编码器处理不规则ICU数据，在18个预测任务中表现优异，并在外部验证中显示出良好的领域适应性和数据效率。


<details>
  <summary>Details</summary>
Motivation: ICU数据具有高度不规则性、异质性和时间碎片化的特点，这给临床预测的泛化带来了挑战。传统方法需要重采样或手动特征工程，难以适应多样化的临床环境。

Method: 提出PULSE-ICU自监督基础模型：1）统一嵌入模块编码事件身份、连续值、单位和时间属性；2）基于Longformer的编码器高效建模长轨迹；3）无需重采样或手动特征工程，直接从大规模EHR序列学习事件级ICU表示。

Result: 在18个预测任务（包括死亡率、干预预测和表型识别）上微调后表现优异。在eICU、HiRID和P12数据集的外部验证中，仅需少量微调即取得显著改进，显示出对领域偏移和变量约束的鲁棒性。

Conclusion: 基础模型方法能够提高数据效率和适应性，为不同临床环境中的ICU决策支持提供了一个可扩展的框架。

Abstract: Intensive care unit (ICU) data are highly irregular, heterogeneous, and temporally fragmented, posing challenges for generalizable clinical prediction. We present PULSE-ICU, a self-supervised foundation model that learns event-level ICU representations from large-scale EHR sequences without resampling or manual feature engineering. A unified embedding module encodes event identity, continuous values, units, and temporal attributes, while a Longformer-based encoder enables efficient modeling of long trajectories. PULSE-ICU was fine-tuned across 18 prediction tasks, including mortality, intervention forecasting, and phenotype identification, achieving strong performance across task types. External validation on eICU, HiRID, and P12 showed substantial improvements with minimal fine-tuning, demonstrating robustness to domain shift and variable constraints. These findings suggest that foundation-style modeling can improve data efficiency and adaptability, providing a scalable framework for ICU decision support across diverse clinical environments.

</details>


### [18] [Estimating the Event-Related Potential from Few EEG Trials](https://arxiv.org/abs/2511.23162)
*Anders Vestergaard Nørskov,Kasper Jørgensen,Alexander Neergaard Zahid,Morten Mørup*

Main category: cs.LG

TL;DR: EEG2ERP是一种基于不确定性感知自编码器的新方法，能够将任意数量的EEG试次映射到相应的ERP，显著减少传统平均方法所需的试次数。


<details>
  <summary>Details</summary>
Motivation: 传统ERP估计需要大量EEG试次的平均来降低噪声和信号变异性，这限制了ERP研究的效率和实用性。需要开发能够减少所需试次数的新方法。

Method: 提出EEG2ERP不确定性感知自编码器方法，使用引导训练目标和单独的方差解码器来建模ERP估计的不确定性，支持零样本泛化到新被试。

Result: 在三个公开数据集（ERP CORE、P300拼写器BCI、面部感知神经影像）上评估，在少量试次情况下，EEG2ERP比传统平均方法提供显著更好的ERP估计。

Conclusion: EEG2ERP是首个将EEG信号映射到相关ERP的深度学习方法，能够显著减少ERP研究所需的试次数，推动该领域的发展。

Abstract: Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP

</details>


### [19] [Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting](https://arxiv.org/abs/2511.23276)
*Joongwon Chae,Runming Wang,Chen Xiong,Gong Yunhan,Lian Zhang,Ji Jiansong,Dongmei Yu,Peiwu Qin*

Main category: cs.LG

TL;DR: 提出一个两智能体框架，将上下文解释与概率预测解耦，使用LLM处理异构信号生成传播影响信号，再结合历史病例数据进行概率预测，在手足口病监测中实现竞争性预测精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统模型和基础模型虽然能纳入协变量，但缺乏语义推理能力来解释冲突驱动因素之间的因果关系。手足口病的有效监测需要考虑流行病学模式和学校日历、天气等上下文驱动因素。

Method: 提出两智能体框架：1) LLM"事件解释器"处理异构信号（学校日程、气象摘要、报告等）生成标量传播影响信号；2) 神经符号核心将此信号与历史病例数结合，产生校准的概率预测。

Result: 在香港（2023-2024）和丽水（2024）的真实手足口病数据集上评估，相比传统和基础模型基线，该方法在点预测准确性上具有竞争力，同时提供稳健的90%预测区间（覆盖率0.85-1.00）和人类可解释的推理。

Conclusion: 通过LLM结构化整合领域知识可以匹配最先进的性能，同时产生符合公共卫生工作流程的上下文感知预测，为疾病监测提供可解释的预测框架。

Abstract: Effective surveillance of hand, foot and mouth disease (HFMD) requires forecasts accounting for epidemiological patterns and contextual drivers like school calendars and weather. While classical models and recent foundation models (e.g., Chronos, TimesFM) incorporate covariates, they often lack the semantic reasoning to interpret the causal interplay between conflicting drivers. In this work, we propose a two-agent framework decoupling contextual interpretation from probabilistic forecasting. An LLM "event interpreter" processes heterogeneous signals-including school schedules, meteorological summaries, and reports-into a scalar transmission-impact signal. A neuro-symbolic core then combines this with historical case counts to produce calibrated probabilistic forecasts. We evaluate the framework on real-world HFMD datasets from Hong Kong (2023-2024) and Lishui, China (2024). Compared to traditional and foundation-model baselines, our approach achieves competitive point forecasting accuracy while providing robust 90% prediction intervals (coverage 0.85-1.00) and human-interpretable rationales. Our results suggest that structurally integrating domain knowledge through LLMs can match state-of-the-art performance while yielding context-aware forecasts that align with public health workflows. Code is available at https://github.com/jw-chae/forecast_MED .

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [Solving Context Window Overflow in AI Agents](https://arxiv.org/abs/2511.22729)
*Anton Bulle Labate,Valesca Moura de Sousa,Sandro Rama Fiorini,Leonardo Guerreiro Azevedo,Raphael Melo Thiago,Viviane Torres da Silva*

Main category: cs.AI

TL;DR: 提出一种让LLM处理任意长度工具输出而不丢失信息的方法，通过内存指针替代原始数据交互，减少token使用和执行时间


<details>
  <summary>Details</summary>
Motivation: LLM在处理动态、知识密集型领域（如化学和材料科学）时，大型工具输出会超出上下文窗口限制，现有截断或摘要方法无法保留完整数据，不适合需要完整输出的工作流程

Method: 将LLM与工具的交互从原始数据转向内存指针，保留工具功能，实现无缝集成到智能体工作流程中

Result: 在真实材料科学应用中验证了该方法，传统方法无法执行的任务得以完成；在两种方法都能成功的对比实验中，新方法消耗的token数量约为传统方法的七分之一

Conclusion: 提出的方法使LLM能够处理任意长度的工具输出而不丢失信息，显著减少资源消耗，适用于需要完整数据的工作流程

Abstract: Large Language Models (LLMs) have become increasingly capable of interacting with external tools, granting access to specialized knowledge beyond their training data - critical in dynamic, knowledge-intensive domains such as Chemistry and Materials Science. However, large tool outputs can overflow the LLMs' context window, preventing task completion. Existing solutions such as truncation or summarization fail to preserve complete outputs, making them unsuitable for workflows requiring the full data. This work introduces a method that enables LLMs to process and utilize tool responses of arbitrary length without loss of information. By shifting the model's interaction from raw data to memory pointers, the method preserves tool functionality, allows seamless integration into agentic workflows, and reduces token usage and execution time. The proposed method is validated on a real-world Materials Science application that cannot be executed with conventional workflows, and its effectiveness is demonstrated via a comparative analysis where both methods succeed. In this experiment, the proposed approach consumed approximately seven times fewer tokens than the traditional workflow.

</details>


### [21] [Agentic AI Framework for Individuals with Disabilities and Neurodivergence: A Multi-Agent System for Healthy Eating, Daily Routines, and Inclusive Well-Being](https://arxiv.org/abs/2511.22737)
*Salman Jan,Toqeer Ali Syed,Gohar Ali,Ali Akarma,Mohammad Riyaz Belgaum,Ahmad Ali*

Main category: cs.AI

TL;DR: 提出一个多层代理AI框架，通过四个专用代理（膳食规划、提醒、食物指导、监测）为残障和神经多样性人群提供个性化健康支持，结合隐私保护数据源和可解释AI模块。


<details>
  <summary>Details</summary>
Motivation: 传统辅助系统缺乏包容性、个性化和可访问性，需要为残障和神经多样性人群开发能够促进健康、规律生活和数字公平的智能系统。

Method: 采用三层架构：应用接口层、代理层、数据源层。通过混合推理引擎协调四个专用代理（膳食规划、提醒、食物指导、监测），使用黑板/事件总线进行通信，整合EHR、营养数据库、可穿戴设备、智能厨房IoT等隐私敏感数据源。

Result: 提出了一个超越传统辅助系统的代理AI框架，实现了包容性、个性化和可访问性的整合，展示了多代理推理、多模态界面和以人为中心设计的交叉应用。

Conclusion: 该框架能够增强残障和神经多样性人群的自主性、健康和数字公平，是多代理推理、多模态界面和以人为中心设计的创新结合。

Abstract: The paper presents a detailed Agentic Artificial Intelligence (AI) model that would enable people with disabilities and neurodivergence to lead healthier lives and have more regular days. The system will use a multi-layer structure; it will include an Application and Interface Layer, an Agents Layer, and a Data Source Layer to provide adaptive, transparent, and inclusive support. Fundamentally, a hybrid reasoning engine will synchronize four special-purpose agents, which include: a personalized-nutrition-based, called a Meal Planner Agent; an adaptive-scheduling-based, called a Reminder Agent; interactive assistance during grocery shopping and cooking, called a Food Guidance Agent; and a continuous-intake-and-physiological-tracking, called a Monitoring Agent. All the agents interact through a central communicative system called the Blackboard/Event Bus, which allows autonomous interaction and real-time feedback loops with multimedia user interfaces. Privacy-sensitive data sources, including electronic health records (EHRs), nutritional databases, wearable sensors, and smart kitchen Internet of Things, are also included in the framework and placed into a policy-controlled layer, which ensures data safety and compliance with consent. Collaborative care and clinician dashboards allow common supervision, and discussable artificial intelligence (XAI) modules give brief explanations of why a decision was made, making users responsible and reliant. The proposed agentic AI framework is an extension beyond traditional assistive systems since it incorporates inclusiveness, personalization, and accessibility at all levels. It displays the intersection of multi-agent reasoning, multi-modal interfaces, and human-centered design that will enable the development of autonomy, health, and digital equity among people with disabilities and neurodivergence.

</details>


### [22] [Agentic AI Framework for Cloudburst Prediction and Coordinated Response](https://arxiv.org/abs/2511.22767)
*Toqeer Ali Syed,Sohail Khan,Salman Jan,Gohar Ali,Muhammad Nauman,Ali Akarma,Ahmad Ali*

Main category: cs.AI

TL;DR: 该论文提出了一种基于多智能体AI的闭环系统，用于极端短时降雨事件（如云爆）的预测和响应，将传感、预报、降尺度、水文建模和协调响应整合为单一系统，在巴基斯坦北部地区验证中提高了预报可靠性和预警提前时间。


<details>
  <summary>Details</summary>
Motivation: 传统预报系统将预测和响应视为两个独立过程，难以应对极端短时降雨事件（如云爆）的挑战。需要将传感、预报、建模和响应整合为闭环系统，实现实时决策智能。

Method: 采用多智能体AI框架，包含自主但协作的智能体，在整个事件生命周期中进行推理、感知和行动。系统整合大气水循环智能，包括传感、预报、降尺度、水文建模和协调响应，形成闭环系统。智能体通过通信和路由优化响应，并通过嵌入式学习层实现自适应校准和透明审计。

Result: 在巴基斯坦北部地区的多年雷达、卫星和地面数据评估中，多智能体配置相比基线模型提高了预报可靠性、关键成功指数和预警提前时间。通过通信和路由智能体最大化人口覆盖范围，最小化疏散过程中的错误，嵌入式学习层提供了自适应重新校准和透明审计能力。

Conclusion: 协作AI智能体能够将大气数据流转化为可操作的预见性，为可扩展的、基于学习和自适应的气候韧性提供了一个平台，能够改变极端天气事件的预测和响应方式。

Abstract: The challenge is growing towards extreme and short-duration rainfall events like a cloudburst that are peculiar to the traditional forecasting systems, in which the predictions and the response are taken as two distinct processes. The paper outlines an agentic artificial intelligence system to study atmospheric water-cycle intelligence, which combines sensing, forecasting, downscaling, hydrological modeling and coordinated response into a single, interconnected, priceless, closed-loop system. The framework uses autonomous but cooperative agents that reason, sense, and act throughout the entire event lifecycle, and use the intelligence of weather prediction to become real-time decision intelligence. Comparison of multi-year radar, satellite, and ground-based evaluation of the northern part of Pakistan demonstrates that the multi-agent configuration enhances forecast reliability, critical success index and warning lead time compared to the baseline models. Population reach was maximised, and errors during evacuation were minimised through communication and routing agents, and adaptive recalibration and transparent auditability were provided by the embedded layer of learning. Collectively, this leads to the conclusion that collaborative AI agents are capable of transforming atmospheric data streams into practicable foresight and provide a platform of scalable adaptive and learning-based climate resilience.

</details>


### [23] [Agentic AI Framework for Smart Inventory Replenishment](https://arxiv.org/abs/2511.23366)
*Toqeer Ali Syed,Salman Jan,Gohar Ali,Ali Akarma,Ahmad Ali,Qurat-ul-Ain Mastoi*

Main category: cs.AI

TL;DR: 提出一个用于零售库存管理的智能代理AI系统，通过需求预测、供应商优化、多代理协商和持续学习来减少缺货、降低库存成本并优化产品组合。


<details>
  <summary>Details</summary>
Motivation: 现代零售中产品种类繁多（服装、杂货、化妆品、冷冻食品等），难以准确预测需求、防止缺货并发现高潜力产品，需要更智能的库存管理系统。

Method: 开发了一个智能代理AI模型，包含库存监控、供应商采购启动、趋势产品扫描功能，应用需求预测、供应商选择优化、多代理协商和持续学习技术，并在中型超市环境中进行原型测试。

Result: 在三种传统和人工数据表上的测试表明，系统相比基准启发式方法能减少缺货、降低库存持有成本，并改善产品组合周转率。

Conclusion: 该智能代理系统能有效改善零售库存管理，但存在约束和可扩展性挑战，未来有改进空间。

Abstract: In contemporary retail, the variety of products available (e.g. clothing, groceries, cosmetics, frozen goods) make it difficult to predict the demand, prevent stockouts, and find high-potential products. We suggest an agentic AI model that will be used to monitor the inventory, initiate purchase attempts to the appropriate suppliers, and scan for trending or high-margin products to incorporate. The system applies demand forecasting, supplier selection optimization, multi-agent negotiation and continuous learning. We apply a prototype to a setting in the store of a middle scale mart, test its performance on three conventional and artificial data tables, and compare the results to the base heuristics. Our findings indicate that there is a decrease in stockouts, a reduction of inventory holding costs, and an improvement in product mix turnover. We address constraints, scalability as well as improvement prospect.

</details>


### [24] [Hierarchical AI-Meteorologist: LLM-Agent System for Multi-Scale and Explainable Weather Forecast Reporting](https://arxiv.org/abs/2511.23387)
*Daniil Sukhorukov,Andrei Zakharov,Nikita Glazkov,Katsiaryna Yanchanka,Vladimir Kirilin,Maxim Dubovitsky,Roman Sultimov,Yuri Maksimov,Ilya Makarov*

Main category: cs.AI

TL;DR: 提出分层AI气象学家系统，使用LLM代理通过分层预报推理和天气关键词生成可解释的天气报告，相比传统时间序列方法能更好地捕捉短期动态和长期趋势。


<details>
  <summary>Details</summary>
Motivation: 传统天气预测方法将预报视为扁平时间序列，缺乏对多尺度天气模式的理解和解释性。需要开发能够生成可解释天气报告并确保语义一致性的自动化系统。

Method: 构建分层LLM代理系统，在小时、6小时和日尺度进行多尺度推理。核心推理代理将结构化气象输入转换为连贯叙述，同时提取总结主要气象事件的关键词。这些关键词作为语义锚点验证报告的一致性、时间连贯性和事实对齐。

Result: 使用OpenWeather和Meteostat数据验证，分层上下文和基于关键词的验证显著提高了LLM生成天气叙述的可解释性和鲁棒性，为自动化气象报告的语义评估提供了可复现框架。

Conclusion: 分层AI气象学家系统通过多尺度推理和关键词验证，提升了LLM生成天气报告的质量和可靠性，为基于代理的科学推理和自动化气象报告语义评估提供了有效框架。

Abstract: We present the Hierarchical AI-Meteorologist, an LLM-agent system that generates explainable weather reports using a hierarchical forecast reasoning and weather keyword generation. Unlike standard approaches that treat forecasts as flat time series, our framework performs multi-scale reasoning across hourly, 6-hour, and daily aggregations to capture both short-term dynamics and long-term trends. Its core reasoning agent converts structured meteorological inputs into coherent narratives while simultaneously extracting a few keywords effectively summarizing the dominant meteorological events. These keywords serve as semantic anchors for validating consistency, temporal coherence and factual alignment of the generated reports. Using OpenWeather and Meteostat data, we demonstrate that hierarchical context and keyword-based validation substantially improve interpretability and robustness of LLM-generated weather narratives, offering a reproducible framework for semantic evaluation of automated meteorological reporting and advancing agent-based scientific reasoning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [25] [Beyond Component Strength: Synergistic Integration and Adaptive Calibration in Multi-Agent RAG Systems](https://arxiv.org/abs/2511.21729)
*Jithin Krishnan*

Main category: cs.CL

TL;DR: RAG系统组件协同集成比单个组件强度更重要，通过综合使用混合检索、集成验证和自适应阈值等技术，可将弃答率从40%降至2%而不增加幻觉，同时需要标准化指标和标签来准确评估性能。


<details>
  <summary>Details</summary>
Motivation: 构建可靠的检索增强生成系统需要理解各组件如何相互作用，而不仅仅是添加强大组件。当前存在测量挑战：不同验证策略可能产生不一致的标签，导致幻觉率评估不准确。

Method: 使用消融研究分析50个查询（15个可回答、10个边缘案例、25个对抗性查询），评估混合检索、集成验证和自适应阈值等技术在单独使用和组合使用时的效果。

Result: 增强技术单独使用时几乎无益，但协同使用时可将弃答率从40%降至2%而不增加幻觉。同时发现不同验证策略会产生不一致标签（如"弃答"与"不支持"），导致幻觉率评估出现伪影。

Conclusion: RAG系统的协同集成比任何单个组件的强度更重要；需要标准化指标和标签来正确解释性能；即使检索质量高，也需要自适应校准来防止过度自信的过度回答。

Abstract: Building reliable retrieval-augmented generation (RAG) systems requires more than adding powerful components; it requires understanding how they interact. Using ablation studies on 50 queries (15 answerable, 10 edge cases, and 25 adversarial), we show that enhancements such as hybrid retrieval, ensemble verification, and adaptive thresholding provide almost no benefit when used in isolation, yet together achieve a 95% reduction in abstention (from 40% to 2%) without increasing hallucinations. We also identify a measurement challenge: different verification strategies can behave safely but assign inconsistent labels (for example, "abstained" versus "unsupported"), creating apparent hallucination rates that are actually artifacts of labeling. Our results show that synergistic integration matters more than the strength of any single component, that standardized metrics and labels are essential for correctly interpreting performance, and that adaptive calibration is needed to prevent overconfident over-answering even when retrieval quality is high.

</details>


### [26] [Decoding inner speech with an end-to-end brain-to-text neural interface](https://arxiv.org/abs/2511.21740)
*Yizi Zhang,Linyang He,Chaofei Fan,Tingkai Liu,Han Yu,Trung Le,Jingyuan Li,Scott Linderman,Lea Duncker,Francis R Willett,Nima Mesgarani,Liam Paninski*

Main category: cs.CL

TL;DR: 研究者提出了一种端到端的脑到文本（BIT）框架，使用单一可微分神经网络将神经活动直接翻译为连贯句子，显著降低了词错误率，并实现了跨任务和跨物种的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前大多数语音脑机接口使用级联框架，先解码音素再用语言模型组装句子，这种分离架构无法同时优化所有阶段，限制了系统性能。需要一种端到端的可微分框架来提升解码效果。

Method: 提出BIT框架，核心是跨任务、跨物种预训练的神经编码器，其表征可迁移到尝试性和想象性语音。在级联设置中使用n-gram语言模型，在端到端设置中与音频大语言模型集成，采用对比学习进行跨模态对齐。

Result: 在Brain-to-Text '24和'25基准测试中，预训练编码器在级联设置下达到新的SOTA。端到端集成将词错误率从24.69%降至10.22%。小型音频LLM显著改善端到端解码，BIT框架还能对齐尝试性和想象性语音嵌入实现跨任务泛化。

Conclusion: BIT框架推进了大规模多样化神经数据集的整合，为支持无缝可微分优化的端到端解码框架铺平了道路，在性能和泛化能力上都取得了突破性进展。

Abstract: Speech brain-computer interfaces (BCIs) aim to restore communication for people with paralysis by translating neural activity into text. Most systems use cascaded frameworks that decode phonemes before assembling sentences with an n-gram language model (LM), preventing joint optimization of all stages simultaneously. Here, we introduce an end-to-end Brain-to-Text (BIT) framework that translates neural activity into coherent sentences using a single differentiable neural network. Central to our approach is a cross-task, cross-species pretrained neural encoder, whose representations transfer to both attempted and imagined speech. In a cascaded setting with an n-gram LM, the pretrained encoder establishes a new state-of-the-art (SOTA) on the Brain-to-Text '24 and '25 benchmarks. Integrated end-to-end with audio large language models (LLMs) and trained with contrastive learning for cross-modal alignment, BIT reduces the word error rate (WER) of the prior end-to-end method from 24.69% to 10.22%. Notably, we find that small-scale audio LLMs markedly improve end-to-end decoding. Beyond record-setting performance, BIT aligns attempted and imagined speech embeddings to enable cross-task generalization. Altogether, our approach advances the integration of large, diverse neural datasets, paving the way for an end-to-end decoding framework that supports seamless, differentiable optimization.

</details>


### [27] [Scaling Competence, Shrinking Reasoning: Cognitive Signatures in Language Model Learning](https://arxiv.org/abs/2511.21743)
*Mukul Singh,Ananya Singha,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.CL

TL;DR: 语言模型在任务微调中的推理过程类似于人类工作记忆，经历四个能力阶段：从无推理错误输出，到有推理但错误，再到有效推理，最后无需显式推理即可解决任务。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在任务特定微调过程中的推理行为，将推理标记（解决问题的中间步骤）与人类工作记忆进行类比，从认知科学角度理解模型的学习过程。

Method: 从认知科学的"能力四阶段"理论出发，将训练动态与四个阶段对齐：无意识无能、有意识无能、有意识能力、无意识能力。通过分析推理标记长度变化来跟踪模型学习过程。

Result: 推理标记长度随性能提升而扩展，在"有意识能力"阶段达到峰值，然后随着模型将任务内化而下降。训练后，即使移除推理标记，模型仍能保持性能，表明推理起到了学习支架作用。

Conclusion: 推理标记动态可作为诊断训练阶段、识别收敛和指导早停的信号。提出的指标可跟踪这一轨迹，推理行为对于理解和优化推理模型训练具有重要价值。

Abstract: We analyze reasoning in language models during task-specific fine-tuning and draws parallel between reasoning tokens--intermediate steps generated while solving problem and the human working memory. Drawing from cognitive science, we align training dynamics with the Four Stages of Competence: models initially produce incorrect outputs without reasoning, then begin reasoning (but still fail), eventually reason effectively, and finally solve tasks without explicit reasoning. We find that reasoning token length expands as performance improves, peaks at the stage of conscious competence, then declines as the model internalizes the task. Notably, after training, models retain performance even when reasoning is removed--suggesting it scaffolded learning but is no longer needed. This progression offers actionable insights: reasoning token dynamics can serve as a signal for diagnosing training stage, identifying convergence, and guiding early stopping. We propose metrics to track this trajectory and argue that reasoning behavior is valuable for understanding and optimizing reasoning model training.

</details>


### [28] [Semantics as a Shield: Label Disguise Defense (LDD) against Prompt Injection in LLM Sentiment Classification](https://arxiv.org/abs/2511.21752)
*Yanxi Li,Ruocheng Shan*

Main category: cs.CL

TL;DR: 提出Label Disguise Defense(LDD)方法，通过将真实标签替换为语义转换或无关的别名标签来防御提示注入攻击，在多个大语言模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本分类任务中依赖自然语言提示，容易受到提示注入攻击，特别是利用模型标签集知识的类别导向注入攻击。现有防御方法要么需要模型重新训练，要么容易受到混淆攻击。

Method: 提出Label Disguise Defense(LDD)方法，这是一种轻量级且模型无关的策略。通过将真实标签替换为语义转换或无关的别名标签（如"蓝色"vs"黄色"），模型通过少量示例演示隐式学习这些新标签映射，防止注入指令与决策输出之间的直接对应关系。

Result: 在9个最先进的模型（包括GPT-5、GPT-4o、LLaMA3.2、Gemma3和Mistral变体）上评估LDD。结果显示，LDD恢复因对抗攻击而损失的性能能力因模型和别名选择而异。对于每个评估的模型，LDD都能恢复部分因攻击而降低的准确率。对于绝大多数模型，可以找到多个别名对，其准确率高于仅依赖少量学习而无防御机制的受攻击基线。语义对齐的别名标签比未对齐的符号标签提供更强的鲁棒性。

Conclusion: 研究表明标签语义可以作为有效的防御层，将意义本身转化为对抗提示注入的盾牌。Label Disguise Defense提供了一种轻量级、模型无关的防御策略，通过隐藏真实标签来抵御类别导向注入攻击。

Abstract: Large language models are increasingly used for text classification tasks such as sentiment analysis, yet their reliance on natural language prompts exposes them to prompt injection attacks. In particular, class-directive injections exploit knowledge of the model's label set (e.g., positive vs. negative) to override its intended behavior through adversarial instructions. Existing defenses, such as detection-based filters, instruction hierarchies, and signed prompts, either require model retraining or remain vulnerable to obfuscation. This paper introduces Label Disguise Defense (LDD), a lightweight and model-agnostic strategy that conceals true labels by replacing them with semantically transformed or unrelated alias labels(e.g., blue vs. yellow). The model learns these new label mappings implicitly through few-shot demonstrations, preventing direct correspondence between injected directives and decision outputs. We evaluate LDD across nine state-of-the-art models, including GPT-5, GPT-4o, LLaMA3.2, Gemma3, and Mistral variants, under varying few-shot and an adversarial setting. Our results show that the ability of LDD to recover performance lost to the adversarial attack varies across models and alias choices. For every model evaluated, LDD is able to restore a portion of the accuracy degradation caused by the attack. Moreover, for the vast majority of models, we can identify more than one alias pair that achieves higher accuracy than the under-attack baseline, in which the model relies solely on few-shot learning without any defensive mechanism. A linguistic analysis further reveals that semantically aligned alias labels(e.g., good vs. bad) yield stronger robustness than unaligned symbols(e.g., blue vs. yellow). Overall, this study demonstrates that label semantics can serve as an effective defense layer, transforming meaning itself into a shield against prompt injection.

</details>


### [29] [ResearchArcade: Graph Interface for Academic Tasks](https://arxiv.org/abs/2511.22036)
*Jingjun Xu,Chongshan Lin,Haofei Yu,Tao Feng,Jiaxuan You*

Main category: cs.CL

TL;DR: ResearchArcade是一个基于图的统一数据接口，连接多个学术数据源，支持多模态信息，用于开发各种学术任务的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 学术研究产生多样化的数据源，研究人员越来越多地使用机器学习辅助研究任务，需要构建统一的数据接口来支持开发各种学术任务的机器学习模型，加速知识发现。

Method: 采用基于图的接口，使用一致的多表格式和图结构组织不同来源的数据（如ArXiv和OpenReview），包含文本、图表等多模态信息，保留手稿和社区层面的时间演化，统一学术任务定义并支持多种基础模型。

Result: 在六个学术任务上的实验表明，结合跨源和多模态信息能够支持更广泛的任务范围，而图结构的加入相比基线方法持续提升性能。

Conclusion: ResearchArcade展示了其有效性，具有推动研究进展的潜力，为学术机器学习模型开发提供了统一的数据接口解决方案。

Abstract: Academic research generates diverse data sources, and as researchers increasingly use machine learning to assist research tasks, a crucial question arises: Can we build a unified data interface to support the development of machine learning models for various academic tasks? Models trained on such a unified interface can better support human researchers throughout the research process, eventually accelerating knowledge discovery. In this work, we introduce ResearchArcade, a graph-based interface that connects multiple academic data sources, unifies task definitions, and supports a wide range of base models to address key academic challenges. ResearchArcade utilizes a coherent multi-table format with graph structures to organize data from different sources, including academic corpora from ArXiv and peer reviews from OpenReview, while capturing information with multiple modalities, such as text, figures, and tables. ResearchArcade also preserves temporal evolution at both the manuscript and community levels, supporting the study of paper revisions as well as broader research trends over time. Additionally, ResearchArcade unifies diverse academic task definitions and supports various models with distinct input requirements. Our experiments across six academic tasks demonstrate that combining cross-source and multi-modal information enables a broader range of tasks, while incorporating graph structures consistently improves performance over baseline methods. This highlights the effectiveness of ResearchArcade and its potential to advance research progress.

</details>


### [30] [Early Risk Prediction with Temporally and Contextually Grounded Clinical Language Processing](https://arxiv.org/abs/2511.22038)
*Rochana Chaturvedi,Yue Zhou,Andrew Boyd,Brian T. Layden,Mudassir Rashid,Lu Cheng,Ali Cinar,Barbara Di Eugenio*

Main category: cs.CL

TL;DR: 提出了HiTGNN和ReVeAL两种方法，用于从电子健康记录中的临床笔记进行时间上下文风险预测，特别针对2型糖尿病的早期筛查，在保持隐私的同时提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富的时序信息和结构化数据中缺失的事件细节，可用于慢性疾病的及时识别，但面临文本长、事件分布不规则、时间依赖复杂、隐私限制和资源有限等NLP挑战。

Method: 提出两种互补方法：1) HiTGNN：分层时序图神经网络，整合笔记内事件结构、就诊间动态和医学知识，以细粒度时间粒度建模患者轨迹；2) ReVeAL：轻量级测试时框架，将大语言模型的推理能力蒸馏到较小的验证器模型中。

Result: 在2型糖尿病机会性筛查中，HiTGNN实现了最高的预测准确性，特别是对近期风险，同时保护隐私并减少对大模型的依赖；ReVeAL提高了对真实病例的敏感性并保留解释性推理；消融研究确认了时间结构和知识增强的价值，公平性分析显示HiTGNN在各亚组中表现更公平。

Conclusion: 提出的两种方法有效解决了从临床笔记进行时序风险预测的挑战，HiTGNN在预测准确性方面表现优异，ReVeAL增强了敏感性和可解释性，为慢性疾病的早期筛查提供了实用且隐私友好的解决方案。

Abstract: Clinical notes in Electronic Health Records (EHRs) capture rich temporal information on events, clinician reasoning, and lifestyle factors often missing from structured data. Leveraging them for predictive modeling can be impactful for timely identification of chronic diseases. However, they present core natural language processing (NLP) challenges: long text, irregular event distribution, complex temporal dependencies, privacy constraints, and resource limitations. We present two complementary methods for temporally and contextually grounded risk prediction from longitudinal notes. First, we introduce HiTGNN, a hierarchical temporal graph neural network that integrates intra-note temporal event structures, inter-visit dynamics, and medical knowledge to model patient trajectories with fine-grained temporal granularity. Second, we propose ReVeAL, a lightweight, test-time framework that distills the reasoning of large language models into smaller verifier models. Applied to opportunistic screening for Type 2 Diabetes (T2D) using temporally realistic cohorts curated from private and public hospital corpora, HiTGNN achieves the highest predictive accuracy, especially for near-term risk, while preserving privacy and limiting reliance on large proprietary models. ReVeAL enhances sensitivity to true T2D cases and retains explanatory reasoning. Our ablations confirm the value of temporal structure and knowledge augmentation, and fairness analysis shows HiTGNN performs more equitably across subgroups.

</details>


### [31] [Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information](https://arxiv.org/abs/2511.22176)
*Lukas Struppek,Dominik Hintersdorf,Hannah Struppek,Daniel Neider,Kristian Kersting*

Main category: cs.CL

TL;DR: Focused Chain-of-Thought (F-CoT) 是一种无需训练、基于输入的方法，通过分离信息提取和推理过程，将查询中的关键信息组织成简洁结构化上下文，从而减少推理路径长度，在保持准确性的同时将生成token减少2-3倍。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型通过生成详细的思维链实现强大推理能力，但这导致过多的token使用和较高的推理延迟。现有效率方法通常关注模型中心的干预（如强化学习或监督微调）来减少冗余，但本文提出无需训练的输入中心方法。

Method: 提出Focused Chain-of-Thought (F-CoT)，受认知心理学启发，将信息提取与推理过程分离。首先从查询中提取关键信息组织成简洁结构化上下文，然后引导模型仅在此上下文中进行推理，避免关注无关细节，自然产生更短的推理路径。

Result: 在算术文字问题上，F-CoT将生成的token减少2-3倍，同时保持与标准零样本思维链相当的准确性。结构化输入被证明是提高LLM推理效率的简单而有效的杠杆。

Conclusion: F-CoT展示了结构化输入作为无需训练的方法，能够显著提高LLM推理效率，在保持准确性的同时大幅减少token使用，为高效推理提供了新的方向。

Abstract: Recent large language models achieve strong reasoning performance by generating detailed chain-of-thought traces, but this often leads to excessive token use and high inference latency. Existing efficiency approaches typically focus on model-centric interventions, such as reinforcement learning or supervised fine-tuning, to reduce verbosity. In contrast, we propose a training-free, input-centric approach. Inspired by cognitive psychology, we introduce Focused Chain-of-Thought (F-CoT), which separates information extraction from the reasoning process. F-CoT first organizes the essential information from a query into a concise, structured context and then guides the model to reason exclusively over this context. By preventing attention to irrelevant details, F-CoT naturally produces shorter reasoning paths. On arithmetic word problems, F-CoT reduces generated tokens by 2-3x while maintaining accuracy comparable to standard zero-shot CoT. These results highlight structured input as a simple yet effective lever for more efficient LLM reasoning.

</details>


### [32] [TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies](https://arxiv.org/abs/2511.23225)
*Guang Liang,Jie Shao,Ningyuan Tang,Xinyao Liu,Jianxin Wu*

Main category: cs.CL

TL;DR: TWEO通过简单的损失函数项消除Transformer训练中的极端异常值，实现无需工程技巧的全模型FP8训练，并首次使W8A8静态量化达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现代硬件原生支持FP8对于训练大型Transformer至关重要，但极端激活异常值严重阻碍了其应用。现有解决方案要么依赖复杂的混合精度工程，要么需要侵入式架构修改。

Method: TWEO（Transformers Without Extreme Outliers）是一种新颖的非侵入式损失函数。它基于一个关键发现：极端异常值不是数据驱动的，而是训练过程中由权重矩阵的特定结构特性（即共线性）产生的机械性伪影。TWEO通过一个非常简单的损失项有效防止极端异常值。

Result: TWEO将异常值从10000+减少到小于20，实现全模型FP8预训练（LLM和ViT），性能与BF16基线相当，训练吞吐量提升36%。同时使硬件友好的W8A8每张量静态量化首次达到SOTA性能。

Conclusion: TWEO通过挑战传统认知，揭示了异常值的机械性本质，并提供了一种简单有效的解决方案，为FP8训练和新型量化范式铺平了道路，无需工程技巧或架构修改。

Abstract: Native FP8 support in modern hardware is essential for training large Transformers, but is severely hindered by extreme activation outliers. Existing solutions either rely on complex mixed-precision engineering or invasive architectural modifications. This paper fundamentally challenges the conventional wisdom that outliers are data-driven. We demonstrate that extreme outliers are a data-independent, mechanically-produced artifact of training, originating from specific structural properties of the weight matrices (i.e., colinearity). Based on this insight, we propose TWEO (Transformers Without Extreme Outliers), a novel, non-invasive loss function. TWEO effectively prevents extreme outliers via a very simple loss term, which reduces outliers from 10000+ to less than 20. TWEO then enables full-model FP8 pre-training with neither engineering tricks nor architectural changes for both LLM and ViT. When standard FP8 training catastrophically collapses, TWEO achieves performance comparable to the BF16 baseline while delivering a 36% increase in training throughput. Also, TWEO enables a new quantization paradigm. Hardware-friendly W8A8 per-tensor static quantization of LLMs, previously considered completely unusable due to outliers, achieves SOTA performance for the first time on TWEO-trained models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [33] [Bayesian Decentralized Decision-making for Multi-Robot Systems: Sample-efficient Estimation of Event Rates](https://arxiv.org/abs/2511.22225)
*Gabriel Aguirre,Simay Atasoy Bingöl,Heiko Hamann,Jonas Kuckling*

Main category: cs.RO

TL;DR: 提出一种去中心化贝叶斯框架，让简单机器人群体在危险环境中识别更安全区域，通过泊松过程建模危险事件，使用共轭先验预测事件间隔，实现样本高效的安全决策。


<details>
  <summary>Details</summary>
Motivation: 在危险环境中，群体机器人需要平衡探索、通信和个体不确定性估计，特别是在直接测量受限或成本高昂的情况下，需要开发有效的集体决策方法。

Method: 采用去中心化贝叶斯框架，机器人使用共轭先验逐步预测危险事件的时间间隔，并推导置信度估计来调整行为，通过泊松过程建模两个区域的未知危险事件率。

Result: 仿真结果显示机器人群体能持续选择正确区域，同时通过样本高效性减少暴露于危险事件，相比基准启发式方法在安全性和收敛速度方面表现更好。

Conclusion: 该场景可扩展集体决策的基准测试集，方法适用于危险动态环境中的自适应风险感知采样和探索应用。

Abstract: Effective collective decision-making in swarm robotics often requires balancing exploration, communication and individual uncertainty estimation, especially in hazardous environments where direct measurements are limited or costly. We propose a decentralized Bayesian framework that enables a swarm of simple robots to identify the safer of two areas, each characterized by an unknown rate of hazardous events governed by a Poisson process. Robots employ a conjugate prior to gradually predict the times between events and derive confidence estimates to adapt their behavior. Our simulation results show that the robot swarm consistently chooses the correct area while reducing exposure to hazardous events by being sample-efficient. Compared to baseline heuristics, our proposed approach shows better performance in terms of safety and speed of convergence. The proposed scenario has potential to extend the current set of benchmarks in collective decision-making and our method has applications in adaptive risk-aware sampling and exploration in hazardous, dynamic environments.

</details>


### [34] [LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning](https://arxiv.org/abs/2511.22354)
*Suraj Borate,Bhavish Rai B,Vipul Pardeshi,Madhu Vadali*

Main category: cs.RO

TL;DR: CoMuRoS是一个分层架构，将集中式规划与分布式执行结合，支持事件驱动的重规划，实现异构机器人团队的自然语言任务协作。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的机器人系统缺乏运行时事件驱动的重规划能力，难以在物理机器人上实现鲁棒的多机器人协作。需要一种能处理任务失败、用户意图变化和意外事件的通用架构。

Method: 采用分层架构：任务管理器LLM解释自然语言目标、分类任务、分配子任务；每个机器人运行本地LLM将原始技能组合成可执行Python代码；机载感知持续监控事件并分类；事件触发重规划机制。

Result: 硬件实验显示：能从干扰事件中自主恢复（多机器人协作物体恢复成功率9/10）、过滤无关干扰、紧密协调运输（8/8成功）、人机协作恢复（5/5成功）。仿真验证意图感知重规划。基准测试在22个场景中表现优异（正确率最高0.91）。

Conclusion: CoMuRoS首次在物理机器人上实现了运行时事件驱动的重规划，提供了鲁棒、灵活的多机器人和人机协作能力，超越了现有LLM驱动的系统。

Abstract: This paper introduces CoMuRoS (Collaborative Multi-Robot System), a generalizable hierarchical architecture for heterogeneous robot teams that unifies centralized deliberation with decentralized execution, and supports event-driven replanning. A Task Manager LLM interprets natural-language goals, classifies tasks, and allocates subtasks using static rules plus dynamic contexts (task, history, robot and task status, and events).Each robot runs a local LLM that composes executable Python code from primitive skills (ROS2 nodes, policies), while onboard perception (VLMs/image processing) continuously monitors events and classifies them into relevant or irrelevant to the task. Task failures or user intent changes trigger replanning, allowing robots to assist teammates, resume tasks, or request human help. Hardware studies demonstrate autonomous recovery from disruptive events, filtering of irrelevant distractions, and tightly coordinated transport with emergent human-robot cooperation (e.g., multirobot collaborative object recovery success rate: 9/10, coordinated transport: 8/8, human-assisted recovery: 5/5).Simulation studies show intention-aware replanning. A curated textual benchmark spanning 22 scenarios (3 tasks each, around 20 robots) evaluates task allocation, classification, IoU, executability, and correctness, with high average scores (e.g., correctness up to 0.91) across multiple LLMs, a separate replanning set (5 scenarios) achieves 1.0 correctness. Compared with prior LLM-based systems, CoMuRoS uniquely demonstrates runtime, event-driven replanning on physical robots, delivering robust, flexible multi-robot and human-robot collaboration.

</details>


### [35] [Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation](https://arxiv.org/abs/2511.22685)
*Haoyi Wang,Licheng Luo,Yiannis Kantaros,Bruno Sinopoli,Mingyu Cai*

Main category: cs.RO

TL;DR: 提出混合框架整合RL反应式导航与按需MAPF，解决多机器人密集环境中的死锁问题，显著提升任务完成率


<details>
  <summary>Details</summary>
Motivation: 多机器人在杂乱环境中导航面临反应式避碰与长期目标达成的平衡挑战，特别是在狭窄通道中，RL策略遇到超出学习分布的新配置时容易产生死锁，现有RL方法在未见环境中的泛化能力有限

Method: 提出混合框架，无缝整合基于RL的反应式导航与按需多智能体路径规划(MAPF)。包含安全层监控智能体进度检测死锁，触发时启动受影响智能体的协调控制器。框架通过MAPF构建全局可行轨迹，并调节航点进度以减少导航中的智能体间冲突

Result: 在密集多智能体基准测试中，方法将任务完成率从边缘提升到接近普遍成功，显著减少死锁和碰撞。与分层任务规划结合时，能够实现异构机器人的协调导航

Conclusion: 将反应式RL导航与选择性MAPF干预相结合，能够实现鲁棒的零样本性能，为解决多机器人导航中的死锁问题提供了有效方案

Abstract: Multi-robot navigation in cluttered environments presents fundamental challenges in balancing reactive collision avoidance with long-range goal achievement. When navigating through narrow passages
  or confined spaces, deadlocks frequently emerge that prevent agents from reaching their destinations, particularly when Reinforcement Learning (RL) control policies encounter novel configurations out of learning distribution. Existing RL-based approaches suffer from limited generalization capability in unseen environments. We propose a hybrid framework that seamlessly integrates RL-based reactive navigation with on-demand Multi-Agent Path Finding (MAPF) to explicitly resolve topological deadlocks. Our approach integrates a safety layer that monitors agent progress to detect deadlocks and, when detected, triggers a coordination controller for affected agents. The framework constructs globally feasible trajectories via MAPF and regulates waypoint progression to reduce inter-agent conflicts during navigation.
  Extensive evaluation on dense multi-agent benchmarks shows that our method boosts task completion from marginal to near-universal success, markedly reducing deadlocks and collisions. When integrated with hierarchical task planning, it enables coordinated navigation for heterogeneous robots, demonstrating that coupling reactive RL navigation with selective MAPF intervention yields a robust, zero-shot performance.

</details>
