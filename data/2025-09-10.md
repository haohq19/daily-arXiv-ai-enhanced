<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models](https://arxiv.org/abs/2509.07027)
*Jisung Hwang,Jaihoon Kim,Minhyuk Sung*

Main category: cs.CV

TL;DR: 提出一种新颖的正则化损失函数，通过空间域矩正则化和频谱域功率谱正则化的组合，强制潜在空间样本符合标准高斯分布，提升文本到图像模型的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有高斯性正则化方法存在局限性，需要一种统一框架来有效约束潜在空间分布，以支持文本到图像模型的优化任务，如美学提升和文本对齐。

Method: 将高维样本元素视为一维标准高斯变量，结合空间域矩正则化和频谱域功率谱正则化构建复合损失函数，通过随机排列确保排列不变性。

Result: 该方法优于现有高斯性正则化，有效防止奖励破解，加速收敛，在测试时奖励对齐任务中表现出色。

Conclusion: 提出的统一框架为高斯性正则化提供了理论基础和实践指导，在生成建模中具有重要应用价值。

Abstract: We propose a novel regularization loss that enforces standard Gaussianity,
encouraging samples to align with a standard Gaussian distribution. This
facilitates a range of downstream tasks involving optimization in the latent
space of text-to-image models. We treat elements of a high-dimensional sample
as one-dimensional standard Gaussian variables and define a composite loss that
combines moment-based regularization in the spatial domain with power
spectrum-based regularization in the spectral domain. Since the expected values
of moments and power spectrum distributions are analytically known, the loss
promotes conformity to these properties. To ensure permutation invariance, the
losses are applied to randomly permuted inputs. Notably, existing
Gaussianity-based regularizations fall within our unified framework: some
correspond to moment losses of specific orders, while the previous
covariance-matching loss is equivalent to our spectral loss but incurs higher
time complexity due to its spatial-domain computation. We showcase the
application of our regularization in generative modeling for test-time reward
alignment with a text-to-image model, specifically to enhance aesthetics and
text alignment. Our regularization outperforms previous Gaussianity
regularization, effectively prevents reward hacking and accelerates
convergence.

</details>


### [2] [Automated Evaluation of Gender Bias Across 13 Large Multimodal Models](https://arxiv.org/abs/2509.07050)
*Juan Manuel Contreras*

Main category: cs.CV

TL;DR: 研究开发了Aymara图像公平性评估基准，测试13个商业大模型在职业图像生成中的性别偏见，发现模型系统性放大性别刻板印象，存在默认男性偏见，且不同模型偏见程度差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究存在方法学限制，无法进行大规模、可比较的跨模型分析，需要开发标准化评估工具来识别和解决多模态模型中的社会偏见问题。

Method: 使用75个程序生成的性别中性提示词，测试13个商业LMM模型在刻板印象男性、女性和非刻板印象职业中生成人物图像，使用经过验证的LLM-as-judge系统对965张图像进行性别表征评分。

Result: 模型系统性放大职业性别刻板印象（男性职业93.0%生成男性，女性职业仅22.5%生成男性），存在强烈默认男性偏见（非刻板职业68.3%生成男性），不同模型偏见程度差异显著（46.7%-73.3%）。

Conclusion: 高度偏见不是必然结果而是设计选择后果，最佳模型可实现性别平等，强调需要标准化自动化评估工具来促进AI开发的问责制和公平性。

Abstract: Large multimodal models (LMMs) have revolutionized text-to-image generation,
but they risk perpetuating the harmful social biases in their training data.
Prior work has identified gender bias in these models, but methodological
limitations prevented large-scale, comparable, cross-model analysis. To address
this gap, we introduce the Aymara Image Fairness Evaluation, a benchmark for
assessing social bias in AI-generated images. We test 13 commercially available
LMMs using 75 procedurally-generated, gender-neutral prompts to generate people
in stereotypically-male, stereotypically-female, and non-stereotypical
professions. We then use a validated LLM-as-a-judge system to score the 965
resulting images for gender representation. Our results reveal (p < .001 for
all): 1) LMMs systematically not only reproduce but actually amplify
occupational gender stereotypes relative to real-world labor data, generating
men in 93.0% of images for male-stereotyped professions but only 22.5% for
female-stereotyped professions; 2) Models exhibit a strong default-male bias,
generating men in 68.3% of the time for non-stereotyped professions; and 3) The
extent of bias varies dramatically across models, with overall male
representation ranging from 46.7% to 73.3%. Notably, the top-performing model
de-amplified gender stereotypes and approached gender parity, achieving the
highest fairness scores. This variation suggests high bias is not an inevitable
outcome but a consequence of design choices. Our work provides the most
comprehensive cross-model benchmark of gender bias to date and underscores the
necessity of standardized, automated evaluation tools for promoting
accountability and fairness in AI development.

</details>


### [3] [EHWGesture -- A dataset for multimodal understanding of clinical gestures](https://arxiv.org/abs/2509.07525)
*Gianluca Amprimo,Alberto Ancilotto,Alessandro Savino,Fabio Quazzolo,Claudia Ferraris,Gabriella Olmo,Elisabetta Farella,Stefano Di Carlo*

Main category: cs.CV

TL;DR: EHWGesture是一个多模态手势理解数据集，包含5种临床相关手势，超过1100条记录（6小时），来自25名健康受试者，使用RGB-Depth相机和事件相机采集，并提供精确的手部关键点跟踪和动作质量评估。


<details>
  <summary>Details</summary>
Motivation: 动态手势理解在临床手部灵活性评估等应用中至关重要，但现有数据集缺乏多模态多视角多样性、精确的真值跟踪以及嵌入动作质量评估的能力。

Method: 使用两个高分辨率RGB-Depth相机和一个事件相机采集数据，通过运动捕捉系统提供精确的手部地标跟踪，所有设备经过空间校准和时间同步以确保跨模态对齐。

Result: 数据集包含超过1100条记录（6小时），来自25名健康受试者，按照执行速度等级组织以反映临床手部灵活性评估。基线实验展示了数据集在手势分类、手势触发检测和动作质量评估方面的潜力。

Conclusion: EHWGesture可作为推进多模态临床手势理解的综合基准数据集。

Abstract: Hand gesture understanding is essential for several applications in
human-computer interaction, including automatic clinical assessment of hand
dexterity. While deep learning has advanced static gesture recognition, dynamic
gesture understanding remains challenging due to complex spatiotemporal
variations. Moreover, existing datasets often lack multimodal and multi-view
diversity, precise ground-truth tracking, and an action quality component
embedded within gestures. This paper introduces EHWGesture, a multimodal video
dataset for gesture understanding featuring five clinically relevant gestures.
It includes over 1,100 recordings (6 hours), captured from 25 healthy subjects
using two high-resolution RGB-Depth cameras and an event camera. A motion
capture system provides precise ground-truth hand landmark tracking, and all
devices are spatially calibrated and synchronized to ensure cross-modal
alignment. Moreover, to embed an action quality task within gesture
understanding, collected recordings are organized in classes of execution speed
that mirror clinical evaluations of hand dexterity. Baseline experiments
highlight the dataset's potential for gesture classification, gesture trigger
detection, and action quality assessment. Thus, EHWGesture can serve as a
comprehensive benchmark for advancing multimodal clinical gesture
understanding.

</details>


### [4] [Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search](https://arxiv.org/abs/2509.07969)
*Xin Lai,Junyi Li,Wei Li,Tao Liu,Tianjian Li,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 小型o3系统通过扩大工具交互轮数和多样化推理模式，在视觉搜索任务上实现了深度多轮推理和独创性能


<details>
  <summary>Details</summary>
Motivation: 解决现有开源多模态模型在视觉问题中推理模式单调、交互轮数有限的问题，特别是对需要试错探索的复杂任务无法处理

Method: 构建Visual Probe数据集、迭代数据收集流水线获取多样化推理轨迹、采用超轮掩码策略避免迅速轮数处罚

Result: 模型在仅训练6轮交互的情况下能够生成十几轮的推理轨迹，准确率随轮数增加而提升，在具有挑战性的视觉搜索任务上达到独创性能

Conclusion: 通过扩大工具交互规模和提供多样化推理模式，Mini-o3系统能够在视觉问题中实现深度思考和有效探索

Abstract: Recent advances in large multimodal models have leveraged image-based tools
with reinforcement learning to tackle visual problems. However, existing
open-source approaches often exhibit monotonous reasoning patterns and allow
only a limited number of interaction turns, making them inadequate for
difficult tasks that require trial-and-error exploration. In this work, we
address this limitation by scaling up tool-based interactions and introduce
Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of
steps -- and achieves state-of-the-art performance on challenging visual search
tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key
components. First, we construct the Visual Probe Dataset, a collection of
thousands of challenging visual search problems designed for exploratory
reasoning. Second, we develop an iterative data collection pipeline to obtain
cold-start trajectories that exhibit diverse reasoning patterns, including
depth-first search, trial-and-error, and goal maintenance. Third, we propose an
over-turn masking strategy that prevents penalization of over-turn responses
(those that hit the maximum number of turns) during reinforcement learning,
thereby balancing training-time efficiency with test-time scalability. Despite
training with an upper bound of only six interaction turns, our model generates
trajectories that naturally scale to tens of turns at inference time, with
accuracy improving as the number of turns increases. Extensive experiments
demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking
paths, effectively solving challenging visual search problems.

</details>


### [5] [RayGaussX: Accelerating Gaussian-Based Ray Marching for Real-Time and High-Quality Novel View Synthesis](https://arxiv.org/abs/2509.07782)
*Hugo Blanc,Jean-Emmanuel Deschaud,Alexis Paljic*

Main category: cs.CV

TL;DR: RayGaussX在RayGauss基础上进行优化，通过引入体积渲染加速策略、增强光线连贯性和尺度正则化等技术，实现了5-12倍训练加速和50-80倍渲染速度提升，同时提高了视觉质量。


<details>
  <summary>Details</summary>
Motivation: RayGauss虽然在新视角合成方面达到了最先进的渲染质量，但其计算成本过高，无法在真实场景中实现实时渲染。

Method: 引入体积渲染加速策略（空空间跳过和自适应采样）、增强光线连贯性、尺度正则化减少误报交集，并提出新的致密化标准改善远距离区域密度分布。

Result: 在真实世界数据集上实现了5-12倍训练加速和50-80倍渲染速度提升（FPS），视觉质量提升高达+0.56 dB PSNR。

Conclusion: RayGaussX成功解决了RayGauss的计算效率问题，在保持高质量渲染的同时实现了显著的性能提升，适用于更大场景的高质量实时渲染。

Abstract: RayGauss has achieved state-of-the-art rendering quality for novel-view
synthesis on synthetic and indoor scenes by representing radiance and density
fields with irregularly distributed elliptical basis functions, rendered via
volume ray casting using a Bounding Volume Hierarchy (BVH). However, its
computational cost prevents real-time rendering on real-world scenes. Our
approach, RayGaussX, builds on RayGauss by introducing key contributions that
accelerate both training and inference. Specifically, we incorporate volumetric
rendering acceleration strategies such as empty-space skipping and adaptive
sampling, enhance ray coherence, and introduce scale regularization to reduce
false-positive intersections. Additionally, we propose a new densification
criterion that improves density distribution in distant regions, leading to
enhanced graphical quality on larger scenes. As a result, RayGaussX achieves 5x
to 12x faster training and 50x to 80x higher rendering speeds (FPS) on
real-world datasets while improving visual quality by up to +0.56 dB in PSNR.
Project page with videos and code: https://raygaussx.github.io/.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Individualized and Interpretable Sleep Forecasting via a Two-Stage Adaptive Spatial-Temporal Model](https://arxiv.org/abs/2509.06974)
*Xueyi Wang,Elisabeth Wilhelm*

Main category: cs.LG

TL;DR: 这篇论文提出了一种可解释的两阶段适配性空间-时间模型，用于预测睡眠质量分数，在多种预测窗口下都超过了现有时间序列预测基线方法，最佳RMSE为0.216。


<details>
  <summary>Details</summary>
Motivation: 睡眠质量影响健康状况，需要可访问和可靠的预测工具来进行预防性干预。

Method: 提出了一个可解释的个体化两阶段适配性空间-时间模型，结合多尺度卷积层模拟多重输入变量的空间交互作用，递归层和注意力机制捕捉长期时间依赖关系，以及两阶段域适配策略来提高模型的普遍性。

Result: 模型在5种输入窗口大小（3、5、7、9、11天）和5种预测窗口大小（1、3、5、7、9天）的实验中都超过了时间序列预测基线方法（LSTM、Informer、PatchTST、TimesNet）。最佳性能是使用3天输入窗口和1天预测窗口，RMSE为0.216。甚至在更长的预测距离下也表现良好（例如3天预测窗口的RMSE为0.257）。

Conclusion: 该框架为使用商业可穿戴设备的稀疏数据进行个性化睡眠预测提供了一个稳健、适配性强且可解释的解决方案。

Abstract: Sleep quality significantly impacts well-being. Therefore, healthcare
providers and individuals need accessible and reliable forecasting tools for
preventive interventions. This paper introduces an interpretable,
individualized two-stage adaptive spatial-temporal model for predicting sleep
quality scores. Our proposed framework combines multi-scale convolutional
layers to model spatial interactions across multiple input variables, recurrent
layers and attention mechanisms to capture long-term temporal dependencies, and
a two-stage domain adaptation strategy to enhance generalization. The first
adaptation stage is applied during training to mitigate overfitting on the
training set. In the second stage, a source-free test-time adaptation mechanism
is employed to adapt the model to new users without requiring labels. We
conducted various experiments with five input window sizes (3, 5, 7, 9, and 11
days) and five prediction window sizes (1, 3, 5, 7, and 9 days). Our model
consistently outperformed time series forecasting baseline approaches,
including Long Short-Term Memory (LSTM), Informer, PatchTST, and TimesNet. The
best performance was achieved with a three-day input window and a one-day
prediction window, yielding a root mean square error (RMSE) of 0.216.
Furthermore, the model demonstrated good predictive performance even for longer
forecasting horizons (e.g, with a 0.257 RMSE for a three-day prediction
window), highlighting its practical utility for real-world applications. We
also conducted an explainability analysis to examine how different features
influence sleep quality. These findings proved that the proposed framework
offers a robust, adaptive, and explainable solution for personalized sleep
forecasting using sparse data from commercial wearable devices.

</details>


### [7] [An efficient deep reinforcement learning environment for flexible job-shop scheduling](https://arxiv.org/abs/2509.07019)
*Xinquan Wu,Xuefeng Yan,Mingqiang Wei,Donghai Guan*

Main category: cs.LG

TL;DR: 本文提出了一个基于离散事件仿真的简单时序DRL环境用于柔性作业车间调度问题，并基于PPO算法构建端到端DRL调度模型，通过新的状态表示和奖励函数设计，在公开基准测试中取得了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习方法主要关注调度智能体的设计，而忽视了DRL环境的建模，需要为FJSP问题开发更有效的环境模型。

Method: 基于离散事件仿真构建时序DRL环境，使用PPO算法建立端到端调度模型，提出基于两个状态变量的短状态表示和基于机器调度区域的可理解奖励函数。

Result: 实验结果显示，在公开基准实例中，简单优先级调度规则在该环境中的性能得到提升，DRL调度模型相比OR-Tools、元启发式、DRL和PDR方法获得了竞争性性能。

Conclusion: 所提出的简单时序DRL环境和端到端调度模型为FJSP问题提供了有效的解决方案，在保持简单性的同时实现了良好的调度性能。

Abstract: The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial
optimization problem that has a wide-range of applications in the real world.
In order to generate fast and accurate scheduling solutions for FJSP, various
deep reinforcement learning (DRL) scheduling methods have been developed.
However, these methods are mainly focused on the design of DRL scheduling
Agent, overlooking the modeling of DRL environment. This paper presents a
simple chronological DRL environment for FJSP based on discrete event
simulation and an end-to-end DRL scheduling model is proposed based on the
proximal policy optimization (PPO). Furthermore, a short novel state
representation of FJSP is proposed based on two state variables in the
scheduling environment and a novel comprehensible reward function is designed
based on the scheduling area of machines. Experimental results on public
benchmark instances show that the performance of simple priority dispatching
rules (PDR) is improved in our scheduling environment and our DRL scheduling
model obtains competing performance compared with OR-Tools, meta-heuristic, DRL
and PDR scheduling methods.

</details>


### [8] [RoseCDL: Robust and Scalable Convolutional Dictionary Learning for Rare-event Detection](https://arxiv.org/abs/2509.07523)
*Jad Yehya,Mansour Benbakoura,Cédric Allain,Benoît Malezieux,Matthieu Kowalski,Thomas Moreau*

Main category: cs.LG

TL;DR: RoseCDL是一个可扩展且鲁棒的卷积字典学习算法，用于长信号中的无监督罕见事件检测，通过随机窗口化和在线异常检测解决了传统CDL的高计算成本和异常敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模信号中识别重复模式和罕见事件是天文学、物理模拟和生物医学等领域的基本挑战。卷积字典学习(CDL)虽然能有效建模信号局部结构，但在罕见事件检测方面存在高计算成本和异常敏感性两大挑战。

Method: RoseCDL结合了随机窗口化技术以实现大数据集上的高效训练，并采用在线异常检测来增强鲁棒性并隔离异常模式。

Result: 该算法将CDL重新定位为实际事件发现和特征提取工具，扩展了其在压缩或去噪等传统任务之外的应用范围。

Conclusion: RoseCDL为现实世界信号中的事件发现和特征提取提供了一个实用的CDL框架，解决了传统方法在罕见事件检测中的局限性。

Abstract: Identifying recurring patterns and rare events in large-scale signals is a
fundamental challenge in fields such as astronomy, physical simulations, and
biomedical science. Convolutional Dictionary Learning (CDL) offers a powerful
framework for modeling local structures in signals, but its use for detecting
rare or anomalous events remains largely unexplored. In particular, CDL faces
two key challenges in this setting: high computational cost and sensitivity to
artifacts and outliers. In this paper, we introduce RoseCDL, a scalable and
robust CDL algorithm designed for unsupervised rare event detection in long
signals. RoseCDL combines stochastic windowing for efficient training on large
datasets with inline outlier detection to enhance robustness and isolate
anomalous patterns. This reframes CDL as a practical tool for event discovery
and characterization in real-world signals, extending its role beyond
traditional tasks like compression or denoising.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation](https://arxiv.org/abs/2509.07324)
*Nakyung Lee,Yeongoon Kim,Minhae Oh,Suhwan Kim,Jin Woo Koo,Hyewon Jo,Jungwoo Lee*

Main category: cs.CL

TL;DR: 通过信忱传播过程注入多跳关系，SAOBP框架解决了Transformer自注意力的局部化问题，提升了小规模模型的推理质量


<details>
  <summary>Details</summary>
Motivation: 解决Transformer自注意力机制存在的局部化问题，即注意力夸缩到少数token上而无法捕捉长距离依赖关系

Method: 提出Self-Attention One-step Belief Propagation (SAOBP)精炼框架，通过信忱传播过程注入多跳关系，并引入Global Token Dependency (GTD)来量化多跳连接的相对贡献

Result: 实验结果显示SAOBP能够阻止深层的熵增夸缩，并根据任务需求自适应地维持GTD水平，从而提升模型性能，小规模模型中也取得了竞争性的收益

Conclusion: SAOBP框架通过信忱传播有效解决了自注意力的局部化问题，特别在资源受限的小规模模型中显示出重要价值，为收集长距离依赖关系提供了有效方案

Abstract: Transformer-based self-attention mechanism serves as the core of modern
language models, yet it often suffers from localization, where attentions
collapse onto a limited subset of tokens and fail to capture long-range
dependencies. To address this issue, we propose Self-Attention One-step Belief
Propagation (SAOBP), a refinement framework that injects multi-hop
relationships through a belief propagation process. To interpret and quantify
these interactions, we introduce Global Token Dependency (GTD) that captures
the relative contribution of multihop connections within the attention graph.
Empirical results indicate that SAOBP helps prevent entropy collapse in deeper
layers and adaptively maintains GTD at task-appropriate levels, thereby
supporting improvements in model performance. Importantly, we observe
competitive gains in small-scale models, highlighting its potential for
improving inference quality in resource-constrained scenarios.

</details>


### [10] [HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention](https://arxiv.org/abs/2509.07475)
*Saumya Goswami,Siddharth Kurra*

Main category: cs.CL

TL;DR: HALT-RAG是一个后验验证系统，使用NLI模型和词汇特征来检测RAG输出中的幻觉内容，在多个任务上取得了优异的性能表现。


<details>
  <summary>Details</summary>
Motivation: 检测生成语言模型输出中与源文本矛盾或缺乏支持的内容，对于模型的安全部署至关重要，特别是在检索增强生成(RAG)管道中。

Method: 使用两个冻结的现成NLI模型和轻量级词汇信号构建通用特征集，训练简单、校准且任务适应的元分类器，采用5折交叉验证防止数据泄露。

Result: 在HaluEval基准测试中，HALT-RAG在摘要、问答和对话任务上分别获得了0.7756、0.9786和0.7391的F1分数，具有良好的校准概率和实用的弃权机制。

Conclusion: HALT-RAG提供了一个灵活、任务适应的框架，能够有效平衡模型性能与安全需求，为RAG管道的安全部署提供了可靠工具。

Abstract: Detecting content that contradicts or is unsupported by a given source text
is a critical challenge for the safe deployment of generative language models.
We introduce HALT-RAG, a post-hoc verification system designed to identify
hallucinations in the outputs of Retrieval-Augmented Generation (RAG)
pipelines. Our flexible and task-adaptable framework uses a universal feature
set derived from an ensemble of two frozen, off-the-shelf Natural Language
Inference (NLI) models and lightweight lexical signals. These features are used
to train a simple, calibrated, and task-adapted meta-classifier. Using a
rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and
produce unbiased estimates, we evaluate our system on the HaluEval benchmark.
By pairing our universal feature set with a lightweight, task-adapted
classifier and a precision-constrained decision policy, HALT-RAG achieves
strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,
and dialogue tasks, respectively. The system's well-calibrated probabilities
enable a practical abstention mechanism, providing a reliable tool for
balancing model performance with safety requirements.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [Attention and Risk-Aware Decision Framework for Safe Autonomous Driving](https://arxiv.org/abs/2509.07412)
*Zhen Tian,Fujiang Yuan,Yangfan He,Qinghao Li,Changlin Chen,Huilin Chen,Tianxiang Xu,Jianyu Duan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 本文提出了一种改进的PPO算法，通过引入风险感知机制、风险注意力决策网络、平衡奖励函数和安全辅助机制，解决了自动驾驶中PPO算法训练效果差、效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，基于模型的方法难以应对意外事件，而现有的PPO算法在长序列训练中存在训练效果差、效率低的问题，训练效果差等同于驾驶任务中的碰撞风险。

Method: 开发了改进的PPO算法，包含：1)风险感知机制突出潜在碰撞区域；2)平衡奖励函数根据周围车辆数量调整奖励；3)风险注意力网络增强对高风险区域的关注；4)安全辅助机制监督和防止危险动作。

Result: 在物理引擎上的仿真结果表明，该算法在避碰性能上优于基准算法，获得了更高的峰值奖励、更少的训练时间，以及在多种测试交通流场景中在风险区域停留时间更短。

Conclusion: 提出的改进PPO算法有效提升了自动驾驶的安全性和训练效率，为解决PPO在自动驾驶应用中的挑战提供了有效解决方案。

Abstract: Autonomous driving has attracted great interest due to its potential
capability in full-unsupervised driving. Model-based and learning-based methods
are widely used in autonomous driving. Model-based methods rely on pre-defined
models of the environment and may struggle with unforeseen events. Proximal
policy optimization (PPO), an advanced learning-based method, can adapt to the
above limits by learning from interactions with the environment. However,
existing PPO faces challenges with poor training results, and low training
efficiency in long sequences. Moreover, the poor training results are
equivalent to collisions in driving tasks. To solve these issues, this paper
develops an improved PPO by introducing the risk-aware mechanism, a
risk-attention decision network, a balanced reward function, and a
safety-assisted mechanism. The risk-aware mechanism focuses on highlighting
areas with potential collisions, facilitating safe-driving learning of the PPO.
The balanced reward function adjusts rewards based on the number of surrounding
vehicles, promoting efficient exploration of the control strategy during
training. Additionally, the risk-attention network enhances the PPO to hold
channel and spatial attention for the high-risk areas of input images.
Moreover, the safety-assisted mechanism supervises and prevents the actions
with risks of collisions during the lane keeping and lane changing. Simulation
results on a physical engine demonstrate that the proposed algorithm
outperforms benchmark algorithms in collision avoidance, achieving higher peak
reward with less training time, and shorter driving time remaining on the risky
areas among multiple testing traffic flow scenarios.

</details>


### [12] [Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers](https://arxiv.org/abs/2509.07464)
*Rui Yang,Lei Zheng,Shuzhi Sam Ge,Jun Ma*

Main category: cs.RO

TL;DR: 提出实时应急轨迹优化框架，通过事件触发在线学习量化多模态不确定性，使用FRS屏障约束确保安全，在保持安全的同时提升驾驶效率和舒适性


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要在动态不确定环境中平衡安全性和驾驶效率，传统方法要么过于保守影响效率，要么确定性方法在遇到突发情况时存在安全风险

Method: 采用事件触发在线学习HV控制意图集，动态量化多模态不确定性，通过FRS屏障约束确保安全不变性，使用共识ADMM算法高效求解应急轨迹优化问题

Result: 在高速公路和城市场景的高保真仿真以及真实世界实验中，在不确定性条件下显著提升了驾驶效率和乘客舒适性，同时保持了安全性

Conclusion: 该框架能够持续适应HV行为的不确定性，在不牺牲安全性的前提下避免过度保守，为自动驾驶在动态不确定环境中的安全高效导航提供了有效解决方案

Abstract: Autonomous vehicles must navigate dynamically uncertain environments while
balancing the safety and driving efficiency. This challenge is exacerbated by
the unpredictable nature of surrounding human-driven vehicles (HVs) and
perception inaccuracies, which require planners to adapt to evolving
uncertainties while maintaining safe trajectories. Overly conservative planners
degrade driving efficiency, while deterministic approaches may encounter
serious issues and risks of failure when faced with sudden and unexpected
maneuvers. To address these issues, we propose a real-time contingency
trajectory optimization framework in this paper. By employing event-triggered
online learning of HV control-intent sets, our method dynamically quantifies
multi-modal HV uncertainties and refines the forward reachable set (FRS)
incrementally. Crucially, we enforce invariant safety through FRS-based barrier
constraints that ensure safety without reliance on accurate trajectory
prediction of HVs. These constraints are embedded in contingency trajectory
optimization and solved efficiently through consensus alternative direction
method of multipliers (ADMM). The system continuously adapts to the
uncertainties in HV behaviors, preserving feasibility and safety without
resorting to excessive conservatism. High-fidelity simulations on highway and
urban scenarios, as well as a series of real-world experiments demonstrate
significant improvements in driving efficiency and passenger comfort while
maintaining safety under uncertainty. The project page is available at
https://pathetiue.github.io/frscp.github.io/.

</details>
