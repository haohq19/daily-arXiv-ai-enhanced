<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 9]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)
*Adam Colton*

Main category: cs.CV

TL;DR: 论文提出在IJEPA架构中用DynTanh激活替代层归一化（LN），以保留视觉标记的自然能量层级，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 层归一化（LN）破坏了视觉标记的自然能量层级，导致语义重要区域无法被优先处理，并引入棋盘状伪影。

Method: 用DynTanh激活替换LN，以保留标记能量并让高能量标记对预测损失贡献更大。

Result: 改进后模型在ImageNet线性探针准确率从38%提升至42.7%，并在NYU Depth V2上降低RMSE 0.08。

Conclusion: 保留自然标记能量对自监督视觉表示学习至关重要。

Abstract: In the standard image joint embedding predictive architecture (IJEPA),
features at the output of the teacher encoder are layer normalized (LN) before
serving as a distillation target for the student encoder and predictor. We
propose that this feature normalization disrupts the natural energy hierarchy
of visual tokens, where high-energy tokens (those with larger L2 norms) encode
semantically important image regions. LN forces all features to have identical
L2 norms, effectively equalizing their energies and preventing the model from
prioritizing semantically rich regions. We find that IJEPA models trained with
feature LN exhibit loss maps with significant checkerboard-like artifacts. We
propose that feature LN be replaced with a DynTanh activation as the latter
better preserves token energies and allows high-energy tokens to greater
contribute to the prediction loss. We show that IJEPA trained with feature
DynTanh exhibits a longer-tailed loss distribution and fixes the checkerboard
artifacts in the loss map. Our empirical results show that our simple
modification improves ImageNet linear probe accuracy from 38% to 42.7% for
ViT-Small and reduces RMSE by 0.08 on NYU Depth V2 monocular depth estimation.
These results suggest that preserving natural token energies is crucial for
effective self-supervised visual representation learning.

</details>


### [2] [Enhancing Long Video Question Answering with Scene-Localized Frame Grouping](https://arxiv.org/abs/2508.03009)
*Xuyi Yang,Wenhao Zhang,Hongbo Jin,Lin Liu,Hongbo Xu,Yongwei Nie,Fei Yu,Fei Ma*

Main category: cs.CV

TL;DR: 提出了一种名为SLFG的新方法，通过将视频帧组合成语义连贯的场景帧，提升多模态大语言模型（MLLMs）在长视频理解中的表现，并开发了LVSQA数据集支持SceneQA任务。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在长视频理解中表现不佳，主要因资源限制无法处理所有帧信息，且现有框架不满足实际需求。

Method: 提出SLFG方法，结合场景定位和动态帧重组机制，无需修改原模型架构。

Result: 实验显示SLFG在多个长视频基准测试中表现优异。

Conclusion: SLFG方法显著提升了MLLMs的长视频理解能力，具有即插即用的实用性。

Abstract: Current Multimodal Large Language Models (MLLMs) often perform poorly in long
video understanding, primarily due to resource limitations that prevent them
from processing all video frames and their associated information. Efficiently
extracting relevant information becomes a challenging task. Existing frameworks
and evaluation tasks focus on identifying specific frames containing core
objects from a large number of irrelevant frames, which does not align with the
practical needs of real-world applications. To address this issue, we propose a
new scenario under the video question-answering task, SceneQA, which emphasizes
scene-based detail perception and reasoning abilities. And we develop the LVSQA
dataset to support the SceneQA task, which is built upon carefully selected
videos from LVBench and contains a new collection of question-answer pairs to
promote a more fair evaluation of MLLMs' scene perception abilities in long
videos. Inspired by human cognition, we introduce a novel method called SLFG.
The core idea of SLFG is to combine individual frames into semantically
coherent scene frames. By leveraging scene localization methods and dynamic
frame reassembly mechanisms, SLFG significantly enhances the understanding
capabilities of existing MLLMs in long videos. SLFG requires no modification to
the original model architecture and boasts excellent plug-and-play usability.
Experimental results show that this method performs exceptionally well in
several long video benchmark tests. Code and dataset will be released at
http://www.slfg.pkuzwh.cn.

</details>


### [3] [Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts](https://arxiv.org/abs/2508.03094)
*Jiantao Tan,Peixian Ma,Kanghao Chen,Zhiming Dai,Ruixuan Wang*

Main category: cs.CV

TL;DR: 提出了一种利用大型语言模型生成的视觉概念作为语义指导的持续学习框架，通过跨模态注意力模块整合语义信息，显著提升医学图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖简单的文本模板，忽略了丰富的语义信息，限制了持续学习的效果。

Method: 动态构建视觉概念池，采用相似性过滤机制避免冗余，并通过跨模态图像-概念注意力模块整合语义知识。

Result: 在医学和自然图像数据集上实现了最先进的性能。

Conclusion: 该方法有效且优越，代码将公开。

Abstract: Continual learning is essential for medical image classification systems to
adapt to dynamically evolving clinical environments. The integration of
multimodal information can significantly enhance continual learning of image
classes. However, while existing approaches do utilize textual modality
information, they solely rely on simplistic templates with a class name,
thereby neglecting richer semantic information. To address these limitations,
we propose a novel framework that harnesses visual concepts generated by large
language models (LLMs) as discriminative semantic guidance. Our method
dynamically constructs a visual concept pool with a similarity-based filtering
mechanism to prevent redundancy. Then, to integrate the concepts into the
continual learning process, we employ a cross-modal image-concept attention
module, coupled with an attention loss. Through attention, the module can
leverage the semantic knowledge from relevant visual concepts and produce
class-representative fused features for classification. Experiments on medical
and natural image datasets show our method achieves state-of-the-art
performance, demonstrating the effectiveness and superiority of our method. We
will release the code publicly.

</details>


### [4] [Ultralight Polarity-Split Neuromorphic SNN for Event-Stream Super-Resolution](https://arxiv.org/abs/2508.03244)
*Chuanzhi Xu,Haoxian Zhou,Langyi Chen,Yuk Ying Chung,Qiang Qu*

Main category: cs.CV

TL;DR: 提出了一种基于脉冲神经网络（SNN）的超轻量级事件超分辨率方法，适用于资源受限设备实时部署。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高时间分辨率、低延迟和高动态范围优势明显，但其有限的空间分辨率限制了细粒度感知任务。

Method: 采用双向前极性分割事件编码策略，将正负事件分离处理，并通过共享SNN实现；提出可学习的时空极性感知损失（LearnSTPLoss）自适应平衡一致性。

Result: 在多个数据集上实现了竞争性的超分辨率性能，同时显著减小模型规模和推理时间。

Conclusion: 轻量级设计使其可嵌入事件相机或作为下游视觉任务的高效前端预处理模块。

Abstract: Event cameras offer unparalleled advantages such as high temporal resolution,
low latency, and high dynamic range. However, their limited spatial resolution
poses challenges for fine-grained perception tasks. In this work, we propose an
ultra-lightweight, stream-based event-to-event super-resolution method based on
Spiking Neural Networks (SNNs), designed for real-time deployment on
resource-constrained devices. To further reduce model size, we introduce a
novel Dual-Forward Polarity-Split Event Encoding strategy that decouples
positive and negative events into separate forward paths through a shared SNN.
Furthermore, we propose a Learnable Spatio-temporal Polarity-aware Loss
(LearnSTPLoss) that adaptively balances temporal, spatial, and polarity
consistency using learnable uncertainty-based weights. Experimental results
demonstrate that our method achieves competitive super-resolution performance
on multiple datasets while significantly reducing model size and inference
time. The lightweight design enables embedding the module into event cameras or
using it as an efficient front-end preprocessing for downstream vision tasks.

</details>


### [5] [Efficient Multi-Slide Visual-Language Feature Fusion for Placental Disease Classification](https://arxiv.org/abs/2508.03277)
*Hang Guo,Qing Zhang,Zixuan Gao,Siyuan Yang,Shulin Peng,Xiang Tao,Ting Yu,Yan Wang,Qingli Li*

Main category: cs.CV

TL;DR: 提出了一种名为EmmPD的高效多模态框架，用于通过全切片图像（WSI）预测胎盘疾病，解决了现有方法在计算效率和全局上下文保留上的不足。


<details>
  <summary>Details</summary>
Motivation: 胎盘疾病的准确预测对预防母婴并发症至关重要，但现有WSI分析方法因数据量大和全局上下文丢失存在局限性。

Method: 采用两阶段补丁选择模块和多模态融合模块，结合自适应图学习和文本报告增强特征表示。

Result: 在自建和公共数据集上实现了最先进的诊断性能。

Conclusion: EmmPD框架在计算效率和诊断准确性上取得了显著改进。

Abstract: Accurate prediction of placental diseases via whole slide images (WSIs) is
critical for preventing severe maternal and fetal complications. However, WSI
analysis presents significant computational challenges due to the massive data
volume. Existing WSI classification methods encounter critical limitations: (1)
inadequate patch selection strategies that either compromise performance or
fail to sufficiently reduce computational demands, and (2) the loss of global
histological context resulting from patch-level processing approaches. To
address these challenges, we propose an Efficient multimodal framework for
Patient-level placental disease Diagnosis, named EmmPD. Our approach introduces
a two-stage patch selection module that combines parameter-free and learnable
compression strategies, optimally balancing computational efficiency with
critical feature preservation. Additionally, we develop a hybrid multimodal
fusion module that leverages adaptive graph learning to enhance pathological
feature representation and incorporates textual medical reports to enrich
global contextual understanding. Extensive experiments conducted on both a
self-constructed patient-level Placental dataset and two public datasets
demonstrating that our method achieves state-of-the-art diagnostic performance.
The code is available at https://github.com/ECNU-MultiDimLab/EmmPD.

</details>


### [6] [Live Demonstration: Neuromorphic Radar for Gesture Recognition](https://arxiv.org/abs/2508.03324)
*Satyapreet Singh Yadav,Chandra Sekhar Seelamantula,Chetan Singh Thakur*

Main category: cs.CV

TL;DR: 提出了一种基于事件驱动架构的神经形态雷达框架，用于实时、低功耗的手势识别（HGR）。


<details>
  <summary>Details</summary>
Motivation: 传统雷达手势识别系统需要连续采样和处理数据，导致高功耗和高计算开销。本文旨在通过生物启发的异步编码和事件驱动处理框架解决这一问题。

Method: 系统包括24 GHz多普勒雷达前端和自定义神经形态采样器，通过异步sigma-delta编码将中频信号转换为稀疏的基于尖峰的表示，并由轻量级神经网络在Cortex-M0微控制器上进行处理。

Result: 在七名用户的五种手势数据集上，系统实现了>85%的实时准确率。

Conclusion: 这是首个将生物启发的异步sigma-delta编码和事件驱动处理框架应用于雷达手势识别的工作，显著降低了内存、功耗和计算开销。

Abstract: We present a neuromorphic radar framework for real-time, low-power hand
gesture recognition (HGR) using an event-driven architecture inspired by
biological sensing. Our system comprises a 24 GHz Doppler radar front-end and a
custom neuromorphic sampler that converts intermediate-frequency (IF) signals
into sparse spike-based representations via asynchronous sigma-delta encoding.
These events are directly processed by a lightweight neural network deployed on
a Cortex-M0 microcontroller, enabling low-latency inference without requiring
spectrogram reconstruction. Unlike conventional radar HGR pipelines that
continuously sample and process data, our architecture activates only when
meaningful motion is detected, significantly reducing memory, power, and
computation overhead. Evaluated on a dataset of five gestures collected from
seven users, our system achieves > 85% real-time accuracy. To the best of our
knowledge, this is the first work that employs bio-inspired asynchronous
sigma-delta encoding and an event-driven processing framework for radar-based
HGR.

</details>


### [7] [R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation](https://arxiv.org/abs/2508.03426)
*Futian Wang,Yuhan Qiao,Xiao Wang,Fuling Wang,Yuxiang Zhang,Dengdi Sun*

Main category: cs.CV

TL;DR: 论文提出了一种基于多模态医学知识图谱（M3KG）的X光报告生成框架，结合GPT-4o构建知识图谱，并通过R-GCN和Swin-Transformer提取特征，最终利用大语言模型生成报告。实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决X光医学报告生成中的幻觉问题和疾病诊断能力不足的挑战。

Method: 构建M3KG知识图谱，结合R-GCN和Swin-Transformer提取特征，利用交叉注意力机制和大语言模型生成报告。

Result: 在多个数据集上验证了知识图谱和报告生成框架的有效性。

Conclusion: 提出的方法显著提升了X光医学报告生成的准确性和可靠性。

Abstract: X-ray medical report generation is one of the important applications of
artificial intelligence in healthcare. With the support of large foundation
models, the quality of medical report generation has significantly improved.
However, challenges such as hallucination and weak disease diagnostic
capability still persist. In this paper, we first construct a large-scale
multi-modal medical knowledge graph (termed M3KG) based on the ground truth
medical report using the GPT-4o. It contains 2477 entities, 3 kinds of
relations, 37424 triples, and 6943 disease-aware vision tokens for the CheXpert
Plus dataset. Then, we sample it to obtain multi-granularity semantic graphs
and use an R-GCN encoder for feature extraction. For the input X-ray image, we
adopt the Swin-Transformer to extract the vision features and interact with the
knowledge using cross-attention. The vision tokens are fed into a Q-former and
retrieved the disease-aware vision tokens using another cross-attention.
Finally, we adopt the large language model to map the semantic knowledge graph,
input X-ray image, and disease-aware vision tokens into language descriptions.
Extensive experiments on multiple datasets fully validated the effectiveness of
our proposed knowledge graph and X-ray report generation framework. The source
code of this paper will be released on
https://github.com/Event-AHU/Medical_Image_Analysis.

</details>


### [8] [Distribution-aware Knowledge Unification and Association for Non-exemplar Lifelong Person Re-identification](https://arxiv.org/abs/2508.03516)
*Shiben Liu,Mingyue Xu,Huijie Fan,Qiang Wang,Yandong Tang,Zhi Han*

Main category: cs.CV

TL;DR: 论文提出了一种分布感知知识统一与关联（DKUA）框架，通过域风格建模和自适应知识整合，解决了终身行人重识别（LReID）中的旧知识保留与新信息适应问题。


<details>
  <summary>Details</summary>
Motivation: 终身行人重识别（LReID）需平衡旧知识保留与新信息适应，现有方法忽略了特定分布感知和跨域统一知识学习。

Method: 提出DKUA框架，包括分布感知模型、自适应知识整合（AKC）、统一知识关联（UKA）和基于分布的知识转移（DKT）。

Result: 实验显示DKUA在抗遗忘和泛化能力上分别平均提升7.6%和5.3%。

Conclusion: DKUA有效解决了LReID中的知识保留与适应问题，性能显著优于现有方法。

Abstract: Lifelong person re-identification (LReID) encounters a key challenge:
balancing the preservation of old knowledge with adaptation to new information.
Existing LReID methods typically employ knowledge distillation to enforce
representation alignment. However, these approaches ignore two crucial aspects:
specific distribution awareness and cross-domain unified knowledge learning,
both of which are essential for addressing this challenge. To overcome these
limitations, we propose a novel distribution-aware knowledge unification and
association (DKUA) framework where domain-style modeling is performed for each
instance to propagate domain-specific representations, enhancing
anti-forgetting and generalization capacity. Specifically, we design a
distribution-aware model to transfer instance-level representations of the
current domain into the domain-specific representations with the different
domain styles, preserving learned knowledge without storing old samples. Next,
we propose adaptive knowledge consolidation (AKC) to dynamically generate the
unified representation as a cross-domain representation center. To further
mitigate forgetting, we develop a unified knowledge association (UKA)
mechanism, which explores the unified representation as a bridge to explicitly
model inter-domain associations, reducing inter-domain gaps. Finally,
distribution-based knowledge transfer (DKT) is proposed to prevent the current
domain distribution from deviating from the cross-domain distribution center,
improving adaptation capacity. Experimental results show our DKUA outperforms
the existing methods by 7.6%/5.3% average mAP/R@1 improvement on
anti-forgetting and generalization capacity, respectively. Our code will be
publicly released.

</details>


### [9] [evTransFER: A Transfer Learning Framework for Event-based Facial Expression Recognition](https://arxiv.org/abs/2508.03609)
*Rodrigo Verschae,Ignacio Bugueno-Cordova*

Main category: cs.CV

TL;DR: 提出了evTransFER，一种基于迁移学习的框架，用于事件相机的人脸表情识别，显著提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高动态范围和微秒级延迟，但缺乏针对其特性的高效表情识别方法。

Method: 通过对抗生成方法训练特征提取器，迁移至表情识别系统，并结合LSTM和新的TIE表示。

Result: 在e-CK+数据库上达到93.6%的识别率，比现有方法提升25.9%以上。

Conclusion: evTransFER框架显著提升了事件相机的人脸表情识别性能。

Abstract: Event-based cameras are bio-inspired vision sensors that asynchronously
capture per-pixel intensity changes with microsecond latency, high temporal
resolution, and high dynamic range, providing valuable information about the
spatio-temporal dynamics of the scene. In the present work, we propose
evTransFER, a transfer learning-based framework and architecture for face
expression recognition using event-based cameras. The main contribution is a
feature extractor designed to encode the spatio-temporal dynamics of faces,
built by training an adversarial generative method on a different problem
(facial reconstruction) and then transferring the trained encoder weights to
the face expression recognition system. We show that this proposed transfer
learning method greatly improves the ability to recognize facial expressions
compared to training a network from scratch. In addition, we propose an
architecture that incorporates an LSTM to capture longer-term facial expression
dynamics, and we introduce a new event-based representation, referred to as
TIE, both of which further improve the results. We evaluate the proposed
framework on the event-based facial expression database e-CK+ and compare it to
state-of-the-art methods. The results show that the proposed framework
evTransFER achieves a 93.6\% recognition rate on the e-CK+ database,
significantly improving the accuracy (25.9\% points or more) when compared to
state-of-the-art performance for similar problems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [Considering Spatial Structure of the Road Network in Pavement Deterioration Modeling](https://arxiv.org/abs/2508.02749)
*Lu Gao,Ke Yu,Pan Lu*

Main category: cs.LG

TL;DR: 该研究通过图神经网络（GNN）将道路网络的空间依赖性纳入路面退化建模，发现考虑空间结构能提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 利用GNN能够直接利用道路网络的丰富结构信息，从而改进路面性能建模。

Method: 使用GNN建模道路网络的空间依赖性，并基于德克萨斯州交通部的路面管理信息系统（PMIS）的大规模数据集进行验证。

Result: 结果表明，考虑空间关系的路面退化预测模型表现更优。

Conclusion: 空间结构对路面退化建模具有显著影响，GNN是一种有效的工具。

Abstract: Pavement deterioration modeling is important in providing information
regarding the future state of the road network and in determining the needs of
preventive maintenance or rehabilitation treatments. This research incorporated
spatial dependence of road network into pavement deterioration modeling through
a graph neural network (GNN). The key motivation of using a GNN for pavement
performance modeling is the ability to easily and directly exploit the rich
structural information in the network. This paper explored if considering
spatial structure of the road network will improve the prediction performance
of the deterioration models. The data used in this research comprises a large
pavement condition data set with more than a half million observations taken
from the Pavement Management Information System (PMIS) maintained by the Texas
Department of Transportation. The promising comparison results indicates that
pavement deterioration prediction models perform better when spatial
relationship is considered.

</details>


### [11] [Physics-Embedded Neural ODEs for Sim2Real Edge Digital Twins of Hybrid Power Electronics Systems](https://arxiv.org/abs/2508.02887)
*Jialin Zheng,Haoyu Wang,Yangbin Zeng,Di Mou,Xin Zhang,Hong Li,Sergio Vazquez,Leopoldo G. Franquelo*

Main category: cs.LG

TL;DR: 论文提出了一种物理嵌入神经ODE（PENODE）方法，用于解决电力电子系统（PES）中混合动态建模的挑战，提升边缘设备上的仿真到现实的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有建模方法难以捕捉电力电子系统中持续演变的混合动态，导致在资源受限的边缘设备上仿真到现实的泛化能力下降。

Method: PENODE通过嵌入混合操作机制作为事件自动机来显式控制离散切换，并将已知的ODE组件直接注入未建模动态的神经参数化中。

Result: 实验表明，PENODE在白盒、灰盒和黑盒场景中显著提高了准确性，神经元数量减少了75%。

Conclusion: PENODE在保持物理可解释性的同时，实现了高效的边缘部署和实时控制增强。

Abstract: Edge Digital Twins (EDTs) are crucial for monitoring and control of Power
Electronics Systems (PES). However, existing modeling approaches struggle to
consistently capture continuously evolving hybrid dynamics that are inherent in
PES, degrading Sim-to-Real generalization on resource-constrained edge devices.
To address these challenges, this paper proposes a Physics-Embedded Neural ODEs
(PENODE) that (i) embeds the hybrid operating mechanism as an event automaton
to explicitly govern discrete switching and (ii) injects known governing ODE
components directly into the neural parameterization of unmodeled dynamics.
This unified design yields a differentiable end-to-end trainable architecture
that preserves physical interpretability while reducing redundancy, and it
supports a cloud-to-edge toolchain for efficient FPGA deployment. Experimental
results demonstrate that PENODE achieves significantly higher accuracy in
benchmarks in white-box, gray-box, and black-box scenarios, with a 75%
reduction in neuron count, validating that the proposed PENODE maintains
physical interpretability, efficient edge deployment, and real-time control
enhancement.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: Nemori是一种新型自组织记忆架构，通过两步对齐原则和预测校准原则，解决了LLMs在长期交互中记忆持久性的问题，显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长期交互中缺乏持久记忆能力，现有记忆系统依赖被动规则，限制了其学习和进化能力。

Method: Nemori采用两步对齐原则（基于事件分割理论）和预测校准原则（基于自由能原理），实现语义连贯的记忆组织和自适应知识进化。

Result: 在LoCoMo和LongMemEval基准测试中，Nemori显著优于现有系统，尤其在长上下文环境中表现突出。

Conclusion: Nemori为自主代理的长期动态工作流提供了可行的解决方案，通过认知启发的原则提升了记忆和学习能力。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
*Giovanni Cherubin,Andrew Paverd*

Main category: cs.CL

TL;DR: 论文提出了一种名为Highlight & Summarize (H&S)的设计模式，通过分离用户问题和生成LLM的交互，防止LLM被恶意攻击。


<details>
  <summary>Details</summary>
Motivation: 防止大型语言模型（LLMs）被越狱和劫持是一个重要但具有挑战性的任务，现有方法容易被绕过。

Method: H&S将检索增强生成（RAG）流程分为高亮器和总结器两部分，避免用户问题直接暴露给生成LLM。

Result: 使用基于LLM的高亮器时，H&S生成的回答在正确性、相关性和质量上优于标准RAG流程。

Conclusion: H&S通过设计有效防止了LLM的恶意攻击，同时提升了回答质量。

Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs)
is an important yet challenging task. For example, when interacting with a
chatbot, malicious users can input specially crafted prompts to cause the LLM
to generate undesirable content or perform a completely different task from its
intended purpose. Existing mitigations for such attacks typically rely on
hardening the LLM's system prompt or using a content classifier trained to
detect undesirable content or off-topic conversations. However, these
probabilistic approaches are relatively easy to bypass due to the very large
space of possible inputs and undesirable outputs. In this paper, we present and
evaluate Highlight & Summarize (H&S), a new design pattern for
retrieval-augmented generation (RAG) systems that prevents these attacks by
design. The core idea is to perform the same task as a standard RAG pipeline
(i.e., to provide natural language answers to questions, based on relevant
sources) without ever revealing the user's question to the generative LLM. This
is achieved by splitting the pipeline into two components: a highlighter, which
takes the user's question and extracts relevant passages ("highlights") from
the retrieved documents, and a summarizer, which takes the highlighted passages
and summarizes them into a cohesive answer. We describe several possible
instantiations of H&S and evaluate their generated responses in terms of
correctness, relevance, and response quality. Surprisingly, when using an
LLM-based highlighter, the majority of H&S responses are judged to be better
than those of a standard RAG pipeline.

</details>


### [14] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种针对检索增强生成（RAG）框架的新型攻击方法TPARAG，通过优化恶意文本在检索和生成阶段的攻击效果，揭示了RAG系统的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG框架通过外部知识提升了语言模型的准确性和实时性，但其集成也引入了新的安全风险，现有攻击方法在效果和适用性上存在不足。

Method: 提出TPARAG框架，利用轻量级白盒语言模型生成并迭代优化恶意文本，针对检索和生成阶段进行攻击。

Result: 在开放域QA数据集上的实验表明，TPARAG在检索和端到端攻击效果上优于现有方法。

Conclusion: 研究揭示了RAG系统的关键漏洞，为提升其鲁棒性提供了新思路。

Abstract: While large language models (LLMs) have achieved remarkable success in
providing trustworthy responses for knowledge-intensive tasks, they still face
critical limitations such as hallucinations and outdated knowledge. To address
these issues, the retrieval-augmented generation (RAG) framework enhances LLMs
with access to external knowledge via a retriever, enabling more accurate and
real-time outputs about the latest events. However, this integration brings new
security vulnerabilities: the risk that malicious content in the external
database can be retrieved and used to manipulate model outputs. Although prior
work has explored attacks on RAG systems, existing approaches either rely
heavily on access to the retriever or fail to jointly consider both retrieval
and generation stages, limiting their effectiveness, particularly in black-box
scenarios. To overcome these limitations, we propose Token-level Precise Attack
on the RAG (TPARAG), a novel framework that targets both white-box and
black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an
attacker to generate and iteratively optimize malicious passages at the token
level, ensuring both retrievability and high attack success in generation.
Extensive experiments on open-domain QA datasets demonstrate that TPARAG
consistently outperforms previous approaches in retrieval-stage and end-to-end
attack effectiveness. These results further reveal critical vulnerabilities in
RAG pipelines and offer new insights into improving their robustness.

</details>


### [15] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
*Ge Shi,Kaiyu Huang,Guochen Feng*

Main category: cs.CL

TL;DR: 提出多智能体故事生成结构，通过长短期记忆存储和故事主题障碍框架解决主题漂移和逻辑不连贯问题，生成更高质量的长故事。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于大纲生成方法中主题漂移和逻辑不连贯的问题，提升长文本生成质量。

Method: 采用多智能体结构，结合长短期记忆存储防止主题漂移，设计故事主题障碍框架增强故事吸引力，并通过多智能体交互模拟作家-读者互动。

Result: 相比传统方法，能生成更高质量的长故事。

Conclusion: 多智能体结构和记忆存储模型有效解决了长文本生成中的关键问题，提升了故事的连贯性和吸引力。

Abstract: The generation of a long story consisting of several thousand words is a
sub-task in the field of long text generation~(LTG). Previous research has
addressed this challenge through outline-based generation, which employs a
multi-stage method for generating outlines into stories. However, this approach
suffers from two common issues: almost inevitable theme drift caused by the
loss of memory of previous outlines, and tedious plots with incoherent logic
that are less appealing to human readers.
  In this paper, we propose the multi-agent Story Generator structure to
improve the multi-stage method, using large language models~(LLMs) as the core
components of agents. To avoid theme drift, we introduce a memory storage model
comprising two components: a long-term memory storage that identifies the most
important memories, thereby preventing theme drift; and a short-term memory
storage that retains the latest outlines from each generation round. To
incorporate engaging elements into the story, we design a story theme obstacle
framework based on literary narratology theory that introduces uncertain
factors and evaluation criteria to generate outline. This framework calculates
the similarity of the former storyline and enhances the appeal of the story by
building a knowledge graph and integrating new node content. Additionally, we
establish a multi-agent interaction stage to simulate writer-reader interaction
through dialogue and revise the story text according to feedback, to ensure it
remains consistent and logical. Evaluations against previous methods
demonstrate that our approach can generate higher-quality long stories.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [16] [AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed](https://arxiv.org/abs/2508.02947)
*M Tanjid Hasan Tonmoy,Rahath Malladi,Kaustubh Singh,Forsad Al Hossain,Rajesh Gupta,Andrés E. Tejada-Martínez,Tauhidur Rahman*

Main category: cs.RO

TL;DR: AeroSafe通过机器人咳嗽模拟器和数字孪生技术提升室内空气净化效果，预测气溶胶浓度动态，实时干预策略优于静态过滤器。


<details>
  <summary>Details</summary>
Motivation: 当前便携式空气过滤器忽视咳嗽产生的气溶胶浓度，尤其在医疗和公共场所存在风险。

Method: 使用机器人双代理模拟器（模拟咳嗽和空气净化器响应）训练数字孪生模型，结合物理模型和LSTM网络。

Result: 模型预测气溶胶浓度动态，平均停留时间误差在35秒内，实时干预策略优于静态过滤器。

Conclusion: AeroSafe系统能有效降低空气传播病原体风险，适用于高风险环境。

Abstract: Indoor air quality plays an essential role in the safety and well-being of
occupants, especially in the context of airborne diseases. This paper
introduces AeroSafe, a novel approach aimed at enhancing the efficacy of indoor
air purification systems through a robotic cough emulator testbed and a
digital-twins-based aerosol residence time analysis. Current portable air
filters often overlook the concentrations of respiratory aerosols generated by
coughs, posing a risk, particularly in high-exposure environments like
healthcare facilities and public spaces. To address this gap, we present a
robotic dual-agent physical emulator comprising a maneuverable mannequin
simulating cough events and a portable air purifier autonomously responding to
aerosols. The generated data from this emulator trains a digital twins model,
combining a physics-based compartment model with a machine learning approach,
using Long Short-Term Memory (LSTM) networks and graph convolution layers.
Experimental results demonstrate the model's ability to predict aerosol
concentration dynamics with a mean residence time prediction error within 35
seconds. The proposed system's real-time intervention strategies outperform
static air filter placement, showcasing its potential in mitigating airborne
pathogen risks.

</details>
