<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cross-Modal Attention Guided Unlearning in Vision-Language Models](https://arxiv.org/abs/2510.07567)
*Karuna Bhaila,Aneesh Komanduri,Minh-Hao Van,Xintao Wu*

Main category: cs.CV

TL;DR: 提出了CAGUL框架，一种轻量级的视觉语言模型遗忘方法，通过跨模态注意力引导来保护敏感信息，避免重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在训练过程中可能记忆并泄露私密敏感信息，现有的遗忘方法主要针对纯文本模型，而视觉语言模型由于包含视觉上下文而更加复杂。

Method: 利用跨模态注意力分析视觉token的重要性，通过外部模块在低重要性视觉token中编码遗忘信息，而不改变预训练模型参数。

Result: 实验表明该方法性能优于或与基于微调的基线方法相当，能有效防止信息泄露同时保持参考模型行为。

Conclusion: CAGUL为视觉语言模型提供了一种实用有效的遗忘解决方案，无需修改预训练参数或承担重新训练成本。

Abstract: Vision-Language Models (VLMs) have demonstrated immense capabilities in
multi-modal understanding and inference tasks such as Visual Question Answering
(VQA), which requires models to infer outputs based on visual and textual
context simultaneously. Such inference abilities of large-scale pretrained
models are often attributed to the massive scale of pre-training data collected
across several domains. However, the models may memorize private and/or
sensitive information during training and regurgitate it in inference.
Recently, machine unlearning has been leveraged to address the leakage of
private data in LLMs. VLMs add a layer of complexity to this process, as the
visual context in the query may also contain sensitive information in addition
to the text. To address this issue, we explore unlearning for vision-language
models, specifically for the VQA task. We explore the role of visual tokens for
output generation in VLMs using cross-modal attention and utilize it to
formulate Cross-Modal Attention Guided Unlearning (CAGUL), a lightweight and
efficient VLM unlearning framework. In contrast to computationally expensive
model finetuning methods, CAGUL utilizes external modules to encode unlearning
information in visual tokens of low importance for relevant queries. We find
that the transformed visual tokens not only prevent leakage but also retain
reference model behavior. Experimental results show that our method performs
better or on par with finetuning-based baselines without altering the
pre-trained model parameters or incurring retraining costs, making it a
practical and effective unlearning solution for VLMs.

</details>


### [2] [DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream](https://arxiv.org/abs/2510.07752)
*Junhao He,Jiaxu Wang,Jia Li,Mingyuan Sun,Qiang Zhang,Jiahang Cao,Ziyi Zhang,Yi Gu,Jingkai Sun,Renjing Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种结合低帧率RGB视频和高帧率事件流来重建动态3D高斯泼溅的方法，通过事件运动先验指导变形场优化，解决了大帧间运动带来的不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 从低帧率RGB视频重建动态3D高斯泼溅具有挑战性，因为大帧间运动会增加解空间的不确定性。事件相机可以异步捕捉快速视觉变化且对运动模糊具有鲁棒性，但缺乏颜色信息。结合这两种模态可以解决这一挑战。

Method: 采用事件运动先验指导变形场优化：1) 使用LoCM无监督微调框架提取事件流中的运动先验；2) 提出几何感知数据关联方法建立事件-高斯运动对应关系；3) 采用运动分解和帧间伪标签策略。

Result: 在合成和真实场景上的广泛实验表明，该方法优于现有的基于图像和事件的方法，证明事件数据可以有效优化动态3D高斯泼溅。

Conclusion: 该方法成功地将事件数据与RGB图像结合，通过事件运动先验有效解决了动态3D高斯泼溅重建中的大帧间运动问题，为多模态动态场景重建提供了有效解决方案。

Abstract: Reconstructing Dynamic 3D Gaussian Splatting (3DGS) from low-framerate RGB
videos is challenging. This is because large inter-frame motions will increase
the uncertainty of the solution space. For example, one pixel in the first
frame might have more choices to reach the corresponding pixel in the second
frame. Event cameras can asynchronously capture rapid visual changes and are
robust to motion blur, but they do not provide color information. Intuitively,
the event stream can provide deterministic constraints for the inter-frame
large motion by the event trajectories. Hence, combining
low-temporal-resolution images with high-framerate event streams can address
this challenge. However, it is challenging to jointly optimize Dynamic 3DGS
using both RGB and event modalities due to the significant discrepancy between
these two data modalities. This paper introduces a novel framework that jointly
optimizes dynamic 3DGS from the two modalities. The key idea is to adopt event
motion priors to guide the optimization of the deformation fields. First, we
extract the motion priors encoded in event streams by using the proposed LoCM
unsupervised fine-tuning framework to adapt an event flow estimator to a
certain unseen scene. Then, we present the geometry-aware data association
method to build the event-Gaussian motion correspondence, which is the primary
foundation of the pipeline, accompanied by two useful strategies, namely motion
decomposition and inter-frame pseudo-label. Extensive experiments show that our
method outperforms existing image and event-based approaches across synthetic
and real scenes and prove that our method can effectively optimize dynamic 3DGS
with the help of event data.

</details>


### [3] [PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting](https://arxiv.org/abs/2510.07830)
*Houqiang Zhong,Zhenglong Wu,Sihua Fu,Zihan Zheng,Xin Jin,Xiaoyun Zhang,Li Song,Qiang Hu*

Main category: cs.CV

TL;DR: PrismGS提出了一种基于物理正则化的框架，通过金字塔多尺度监督和显式尺寸正则化，解决了3D高斯泼溅在大规模城市场景中的走样问题和优化不稳定性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在紧凑场景中能实现实时逼真渲染，但在大规模城市场景中会出现严重的走样伪影和优化不稳定问题，特别是在高分辨率渲染下。现有方法虽然解决了可扩展性问题，但未能解决这种保真度差距。

Method: PrismGS集成了两个协同的正则化器：金字塔多尺度监督（通过监督渲染与预滤波图像金字塔的一致性来强制学习抗锯齿表示）和显式尺寸正则化（对3D高斯的尺寸施加物理基础的下界约束）。

Result: 在MatrixCity、Mill-19和UrbanScene3D数据集上的实验表明，PrismGS实现了最先进的性能，相比CityGaussian获得了约1.5 dB的PSNR增益，同时在苛刻的4K渲染下保持了优越的质量和鲁棒性。

Conclusion: PrismGS是一个即插即用的框架，能够显著改善3D高斯泼溅在城市场景中的渲染质量，有效缓解闪烁纹理和锯齿边缘问题，且与现有管道兼容。

Abstract: 3D Gaussian Splatting (3DGS) has recently enabled real-time photorealistic
rendering in compact scenes, but scaling to large urban environments introduces
severe aliasing artifacts and optimization instability, especially under
high-resolution (e.g., 4K) rendering. These artifacts, manifesting as
flickering textures and jagged edges, arise from the mismatch between Gaussian
primitives and the multi-scale nature of urban geometry. While existing
``divide-and-conquer'' pipelines address scalability, they fail to resolve this
fidelity gap. In this paper, we propose PrismGS, a physically-grounded
regularization framework that improves the intrinsic rendering behavior of 3D
Gaussians. PrismGS integrates two synergistic regularizers. The first is
pyramidal multi-scale supervision, which enforces consistency by supervising
the rendering against a pre-filtered image pyramid. This compels the model to
learn an inherently anti-aliased representation that remains coherent across
different viewing scales, directly mitigating flickering textures. This is
complemented by an explicit size regularization that imposes a
physically-grounded lower bound on the dimensions of the 3D Gaussians. This
prevents the formation of degenerate, view-dependent primitives, leading to
more stable and plausible geometric surfaces and reducing jagged edges. Our
method is plug-and-play and compatible with existing pipelines. Extensive
experiments on MatrixCity, Mill-19, and UrbanScene3D demonstrate that PrismGS
achieves state-of-the-art performance, yielding significant PSNR gains around
1.5 dB against CityGaussian, while maintaining its superior quality and
robustness under demanding 4K rendering.

</details>


### [4] [ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving](https://arxiv.org/abs/2510.08562)
*Zhiyu Zheng,Shaoyu Chen,Haoran Yin,Xinbang Zhang,Jialv Zou,Xinggang Wang,Qian Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: ResAD提出了一种归一化残差轨迹建模框架，通过预测与确定性惯性参考的残差偏差来解决端到端自动驾驶中的时空不平衡问题，显著简化学习任务并提升性能。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统面临轨迹数据固有的时空不平衡问题，这导致模型学习虚假相关性而非因果推理，同时优先处理不确定的远距离预测，从而危及即时安全。

Method: ResAD框架将学习任务重新定义为预测与确定性惯性参考的残差偏差，并使用点归一化对预测残差进行重新加权，防止大误差主导学习信号。

Result: 在NAVSIM基准测试中，ResAD使用仅有两个去噪步骤的普通扩散策略实现了88.6的最优PDMS，表明该方法显著简化了学习任务并提升了模型性能。

Conclusion: ResAD通过残差轨迹建模有效解决了端到端自动驾驶中的优化不平衡问题，为因果推理提供了更好的框架，代码将开源以促进进一步研究。

Abstract: End-to-end autonomous driving (E2EAD) systems, which learn to predict future
trajectories directly from sensor data, are fundamentally challenged by the
inherent spatio-temporal imbalance of trajectory data. This imbalance creates a
significant optimization burden, causing models to learn spurious correlations
instead of causal inference, while also prioritizing uncertain, distant
predictions, thereby compromising immediate safety. To address these issues, we
propose ResAD, a novel Normalized Residual Trajectory Modeling framework.
Instead of predicting the future trajectory directly, our approach reframes the
learning task to predict the residual deviation from a deterministic inertial
reference. The inertial reference serves as a counterfactual, forcing the model
to move beyond simple pattern recognition and instead identify the underlying
causal factors (e.g., traffic rules, obstacles) that necessitate deviations
from a default, inertially-guided path. To deal with the optimization imbalance
caused by uncertain, long-term horizons, ResAD further incorporates Point-wise
Normalization of the predicted residual. It re-weights the optimization
objective, preventing large-magnitude errors associated with distant, uncertain
waypoints from dominating the learning signal. Extensive experiments validate
the effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a
state-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two
denoising steps, demonstrating that our approach significantly simplifies the
learning task and improves model performance. The code will be released to
facilitate further research.

</details>


### [5] [GraphEnet: Event-driven Human Pose Estimation with a Graph Neural Network](https://arxiv.org/abs/2510.07990)
*Gaurvi Goyal,Pham Cong Thuong,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi*

Main category: cs.CV

TL;DR: 提出了一种基于图神经网络的2D人体姿态估计方法GraphEnet，专门针对事件相机数据，利用其稀疏特性实现高频姿态估计。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有低延迟和低能耗优势，适合便携电子设备和移动机器人等资源受限场景，但现有方法未充分利用其稀疏特性进行人体姿态估计。

Method: 使用图神经网络处理事件相机输出，采用基于线的中间事件表示，结合新颖的偏移向量学习范式和基于置信度的池化策略。

Result: 这是首个将图神经网络应用于事件数据的人体姿态估计工作，实现了单人的高频2D姿态估计。

Conclusion: GraphEnet有效利用了事件相机的稀疏特性，为资源受限场景下的人体姿态估计提供了高效解决方案，代码已开源。

Abstract: Human Pose Estimation is a crucial module in human-machine interaction
applications and, especially since the rise in deep learning technology, robust
methods are available to consumers using RGB cameras and commercial GPUs. On
the other hand, event-based cameras have gained popularity in the vision
research community for their low latency and low energy advantages that make
them ideal for applications where those resources are constrained like portable
electronics and mobile robots. In this work we propose a Graph Neural Network,
GraphEnet, that leverages the sparse nature of event camera output, with an
intermediate line based event representation, to estimate 2D Human Pose of a
single person at a high frequency. The architecture incorporates a novel offset
vector learning paradigm with confidence based pooling to estimate the human
pose. This is the first work that applies Graph Neural Networks to event data
for Human Pose Estimation. The code is open-source at
https://github.com/event-driven-robotics/GraphEnet-NeVi-ICCV2025.

</details>


### [6] [CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.08003)
*Weihuang Lin,Yiwei Ma,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: CIR-CoT是一个端到端的检索导向多模态大语言模型，通过集成显式的思维链推理来提高组合图像检索的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型和多模态大语言模型的组合图像检索方法存在"黑箱"问题，用户无法理解检索原理，且模型难以遵循复杂细粒度的指令。

Method: 提出CIR-CoT模型，强制模型先生成可解释的推理链，然后将其最终检索意图编码到专用嵌入中。通过三阶段流程创建结构化思维链标注，包括描述、推理和结论。

Result: CIR-CoT在领域内数据集（FashionIQ、CIRR）上取得了极具竞争力的性能，并在领域外数据集CIRCO上表现出卓越的泛化能力。

Conclusion: CIR-CoT为构建更有效和可信的检索系统开辟了新路径，通过显式推理链实现了准确检索和决策过程透明化。

Abstract: Composed Image Retrieval (CIR), which aims to find a target image from a
reference image and a modification text, presents the core challenge of
performing unified reasoning across visual and semantic modalities. While
current approaches based on Vision-Language Models (VLMs, e.g., CLIP) and more
recent Multimodal Large Language Models (MLLMs, e.g., Qwen-VL) have shown
progress, they predominantly function as ``black boxes." This inherent opacity
not only prevents users from understanding the retrieval rationale but also
restricts the models' ability to follow complex, fine-grained instructions. To
overcome these limitations, we introduce CIR-CoT, the first end-to-end
retrieval-oriented MLLM designed to integrate explicit Chain-of-Thought (CoT)
reasoning. By compelling the model to first generate an interpretable reasoning
chain, CIR-CoT enhances its ability to capture crucial cross-modal
interactions, leading to more accurate retrieval while making its decision
process transparent. Since existing datasets like FashionIQ and CIRR lack the
necessary reasoning data, a key contribution of our work is the creation of
structured CoT annotations using a three-stage process involving a caption,
reasoning, and conclusion. Our model is then fine-tuned to produce this
structured output before encoding its final retrieval intent into a dedicated
embedding. Comprehensive experiments show that CIR-CoT achieves highly
competitive performance on in-domain datasets (FashionIQ, CIRR) and
demonstrates remarkable generalization on the out-of-domain CIRCO dataset,
establishing a new path toward more effective and trustworthy retrieval
systems.

</details>


### [7] [VideoVerse: How Far is Your T2V Generator from a World Model?](https://arxiv.org/abs/2510.08398)
*Zeqing Wang,Xinyu Wei,Bairui Li,Zhen Guo,Jinrui Zhang,Hongyang Wei,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: VideoVerse是一个新的文本到视频生成基准测试，专注于评估T2V模型对现实世界中复杂时间因果性和世界知识的理解能力，填补现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 现有T2V基准测试存在三个主要问题：1) 现有评估维度无法区分最先进的T2V模型；2) 事件级时间因果性评估严重不足；3) 缺乏对世界知识的系统性评估。

Method: 收集跨领域代表性视频，提取具有内在时间因果性的事件级描述，由独立注释者重写为文本到视频提示，设计包含10个维度的二元评估问题，构建包含300个提示、815个事件和793个评估问题的数据集。

Result: 开发了基于现代视觉语言模型的人类偏好对齐QA评估流程，并对开源和闭源T2V模型进行了系统性评估。

Conclusion: VideoVerse基准测试为评估T2V模型是否接近世界模型提供了深入分析，揭示了当前T2V生成器与世界模型之间的差距。

Abstract: The recent rapid advancement of Text-to-Video (T2V) generation technologies,
which are critical to build ``world models'', makes the existing benchmarks
increasingly insufficient to evaluate state-of-the-art T2V models. First,
current evaluation dimensions, such as per-frame aesthetic quality and temporal
consistency, are no longer able to differentiate state-of-the-art T2V models.
Second, event-level temporal causality, which not only distinguishes video from
other modalities but also constitutes a crucial component of world models, is
severely underexplored in existing benchmarks. Third, existing benchmarks lack
a systematic assessment of world knowledge, which are essential capabilities
for building world models. To address these issues, we introduce VideoVerse, a
comprehensive benchmark that focuses on evaluating whether a T2V model could
understand complex temporal causality and world knowledge in the real world. We
collect representative videos across diverse domains (e.g., natural landscapes,
sports, indoor scenes, science fiction, chemical and physical experiments) and
extract their event-level descriptions with inherent temporal causality, which
are then rewritten into text-to-video prompts by independent annotators. For
each prompt, we design a suite of binary evaluation questions from the
perspective of dynamic and static properties, with a total of ten carefully
defined evaluation dimensions. In total, our VideoVerse comprises 300 carefully
curated prompts, involving 815 events and 793 binary evaluation questions.
Consequently, a human preference aligned QA-based evaluation pipeline is
developed by using modern vision-language models. Finally, we perform a
systematic evaluation of state-of-the-art open-source and closed-source T2V
models on VideoVerse, providing in-depth analysis on how far the current T2V
generators are from world models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [ConCuR: Conciseness Makes State-of-the-Art Kernel Generation](https://arxiv.org/abs/2510.07356)
*Lingcheng Kong,Jiateng Wei,Hanzhang Shen,Huan Wang*

Main category: cs.LG

TL;DR: 该论文提出了ConCuR数据集和KernelCoder模型，通过生成和筛选带有推理轨迹的高质量CUDA内核来解决内核生成任务中高质量数据稀缺的问题，在KernelBench基准测试中超越了现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决GPU内核生成任务中高质量数据稀缺的挑战，因为大多数高质量内核是专有且不开源的，无法通过监督微调让LLMs适应内核生成任务。

Method: 开发了一个生成和筛选高质量CUDA内核及其推理轨迹的流程，构建了ConCuR数据集，并训练了KernelCoder模型，该模型是首个在包含PyTorch、推理和CUDA内核对的数据集上训练的模型。

Result: 在KernelBench设置中，模型显著超越了现有最佳模型QwQ-32B，优于所有为内核生成微调的开源模型以及前沿模型如DeepSeek-V3.1-Think和Claude-4-sonnet。

Conclusion: 平均推理长度可以作为评估内核生成任务难度的指标，该研究的观察、指标以及数据收集和筛选流程有助于未来获得更好的内核生成数据。

Abstract: GPU kernel generation by LLMs has recently experienced rapid development,
leveraging test-time scaling and reinforcement learning techniques. However, a
key challenge for kernel generation is the scarcity of high-quality data, as
most high-quality kernels are proprietary and not open-source. This challenge
prevents us from leveraging supervised fine-tuning to align LLMs to the kernel
generation task. To address this challenge, we develop a pipeline that
generates and curates high-quality CUDA kernels with reasoning traces,
motivated by a critical observation that concise yet informative reasoning
traces result in robust generation of high-performance kernels. Using this
pipeline, we construct our dataset ConCuR and introduce our model KernelCoder,
which is the first model trained on a curated dataset consisting of PyTorch,
reasoning, and CUDA kernel pairs, to our knowledge. In the KernelBench setup,
our model achieves significant improvements over the existing top-performing
model, QwQ-32B, and outperforms all open-source models fine-tuned for kernel
generation, as well as frontier models such as DeepSeek-V3.1-Think and
Claude-4-sonnet. Finally, we show that the average reasoning length can serve
as a metric to assess the difficulty of kernel generation tasks. The
observations, metrics, and our data collection and curation pipeline can help
obtain better data in the kernel generation task in the future.

</details>


### [9] [Continual Learning for Adaptive AI Systems](https://arxiv.org/abs/2510.07648)
*Md Hasibul Amin,Tamzid Tanvi Alam*

Main category: cs.LG

TL;DR: 提出了一种基于类间分离（ICS）的新型正则化技术，通过在损失函数中惩罚与先前任务数据形成的聚类中心距离较远的输出来防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 持续学习是神经网络在不丢失先前获得知识的情况下学习多个顺序任务的能力，这是开发真正自适应人工智能的重要障碍。深度学习中过拟合是常见问题，正则化技术可以通过对模型参数添加约束来防止过拟合。

Method: 在损失函数中引入基于类间分离（ICS）的正则化项，惩罚模型产生远离先前任务数据形成的聚类中心的输出。通过超参数调优找到正则化项的最佳权重，确保神经网络内部表示中任务之间有更清晰的分离。

Result: 使用标准的5任务Split CIFAR-10基准和ResNet-18架构，证明了ICS在保持初始任务强性能方面的有效性。但结果也突显了长期知识保留的局限性，特别是在任务数量增加时。

Conclusion: 这项工作强调了持续学习固有的复杂性和权衡，并为进一步研究指明了方向。

Abstract: Continual learning the ability of a neural network to learn multiple
sequential tasks without losing previously acquired knowledge remains a
significant obstacle to developing truly adaptive artificial intelligence. Deep
learning models have achieved remarkable results in various applications, but
overfitting remains a common issue. Regularization techniques can help prevent
overfitting by adding constraints to the model's parameters. To prevent
catastrophic forgetting, in this paper we introduce a novel regularization
technique based on inter-cluster separation (ICS) in the loss function, which
penalizes the model for producing outputs that are far away from the centroids
of the clusters formed by the data from previous tasks. We also performed
hyperparameter tuning to find the optimal weighting of the proposed
regularization term. This ensures clearer separation between tasks in the
neural network's internal representation, reducing overlap and mitigating
forgetting. Using the standard 5-task Split CIFAR-10 benchmark and a ResNet-18
architecture, we demonstrate ICS's effectiveness in maintaining strong
performance on initial tasks. However, our results also highlight limitations
in long-term knowledge retention, particularly when the number of tasks
increases. This underscores the complexity and trade-offs inherent in continual
learning and points toward avenues for further research.

</details>


### [10] [GeoGen: A Two-stage Coarse-to-Fine Framework for Fine-grained Synthetic Location-based Social Network Trajectory Generation](https://arxiv.org/abs/2510.07735)
*Rongchao Xu,Kunlin Cai,Lin Jiang,Dahai Yu,Zhiqing Hong,Yuan Tian,Guang Wang*

Main category: cs.LG

TL;DR: GeoGen是一个两阶段粗到细的框架，用于生成LBSN签到轨迹数据，通过空间-时间扩散模型和Transformer架构解决轨迹数据的稀疏性和不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: LBSN签到轨迹数据收集成本高且存在隐私问题，需要生成既能保护隐私又保留真实数据特征的合成数据。

Method: 两阶段框架：第一阶段使用稀疏感知空间-时间扩散模型学习潜在行为模式；第二阶段使用Transformer Seq2Seq架构生成细粒度轨迹。

Result: 在四个真实数据集上的实验表明，GeoGen在保真度和实用性评估上优于现有模型，在FS-TKY数据集上距离和半径指标分别提升69%和55%。

Conclusion: GeoGen能够有效生成高质量的LBSN签到轨迹数据，为POI推荐、广告投放等应用提供数据支持。

Abstract: Location-Based Social Network (LBSN) check-in trajectory data are important
for many practical applications, like POI recommendation, advertising, and
pandemic intervention. However, the high collection costs and ever-increasing
privacy concerns prevent us from accessing large-scale LBSN trajectory data.
The recent advances in synthetic data generation provide us with a new
opportunity to achieve this, which utilizes generative AI to generate synthetic
data that preserves the characteristics of real data while ensuring privacy
protection. However, generating synthetic LBSN check-in trajectories remains
challenging due to their spatially discrete, temporally irregular nature and
the complex spatio-temporal patterns caused by sparse activities and uncertain
human mobility. To address this challenge, we propose GeoGen, a two-stage
coarse-to-fine framework for large-scale LBSN check-in trajectory generation.
In the first stage, we reconstruct spatially continuous, temporally regular
latent movement sequences from the original LBSN check-in trajectories and then
design a Sparsity-aware Spatio-temporal Diffusion model (S$^2$TDiff) with an
efficient denosing network to learn their underlying behavioral patterns. In
the second stage, we design Coarse2FineNet, a Transformer-based Seq2Seq
architecture equipped with a dynamic context fusion mechanism in the encoder
and a multi-task hybrid-head decoder, which generates fine-grained LBSN
trajectories based on coarse-grained latent movement sequences by modeling
semantic relevance and behavioral uncertainty. Extensive experiments on four
real-world datasets show that GeoGen excels state-of-the-art models for both
fidelity and utility evaluation, e.g., it increases over 69% and 55% in
distance and radius metrics on the FS-TKY dataset.

</details>


### [11] [MetaDefense: Defending Finetuning-based Jailbreak Attack Before and During Generation](https://arxiv.org/abs/2510.07835)
*Weisen Jiang,Sinno Jialin Pan*

Main category: cs.LG

TL;DR: MetaDefense是一个针对大语言模型微调越狱攻击的防御框架，通过预生成和生成中两阶段防御机制，显著优于现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制无法泛化到使用未见攻击模板伪装的有害查询，尽管LLMs能在嵌入空间中区分这些查询。

Method: 采用两阶段防御：预生成阶段检测有害查询，生成中阶段监控部分响应；通过专门提示训练LLM预测查询和部分响应的危害性。

Result: 在多个LLM架构上的实验表明，MetaDefense显著优于现有防御机制，对可见和未见攻击模板的有害查询都能实现鲁棒防御，同时在良性任务上保持竞争力。

Conclusion: MetaDefense框架有效防御微调越狱攻击，通过早期终止潜在有害交互，在保持模型性能的同时提升安全性。

Abstract: This paper introduces MetaDefense, a novel framework for defending against
finetuning-based jailbreak attacks in large language models (LLMs). We observe
that existing defense mechanisms fail to generalize to harmful queries
disguised by unseen attack templates, despite LLMs being capable of
distinguishing disguised harmful queries in the embedding space. Based on these
insights, we propose a two-stage defense approach: (i) pre-generation defense
that detects harmful queries before response generation begins, and (ii)
mid-generation defense that monitors partial responses during generation to
prevent outputting more harmful content. Our MetaDefense trains the LLM to
predict the harmfulness of both queries and partial responses using specialized
prompts, enabling early termination of potentially harmful interactions.
Extensive experiments across multiple LLM architectures (LLaMA-2-7B,
Qwen-2.5-3B-Instruct, and LLaMA-3.2-3B-Instruct) demonstrate that MetaDefense
significantly outperforms existing defense mechanisms, achieving robust defense
against harmful queries with seen and unseen attack templates while maintaining
competitive performance on benign tasks. Code is available at
https://github.com/ws-jiang/MetaDefense.

</details>


### [12] [SketchGuard: Scaling Byzantine-Robust Decentralized Federated Learning via Sketch-Based Screening](https://arxiv.org/abs/2510.07922)
*Murtaza Rangwala,Farag Azzedin,Richard O. Sinnott,Rajkumar Buyya*

Main category: cs.LG

TL;DR: SketchGuard是一个用于去中心化联邦学习的拜占庭鲁棒性框架，通过草图压缩技术降低通信和计算开销，同时保持与现有方法相同的防御能力。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化联邦学习拜占庭防御方法需要交换完整的高维模型向量，导致通信和计算成本过高，无法扩展到网络规模。

Method: 使用Count Sketch将d维模型压缩到k维草图进行相似性比较，仅从接受的邻居处获取完整模型，显著降低通信复杂度。

Result: 在保持与最先进方法相同鲁棒性的同时，计算时间减少82%，通信开销减少50-70%，且收益随模型维度和网络连接性成倍增长。

Conclusion: 基于草图压缩的方法为实现网络规模的鲁棒去中心化联邦学习提供了可行的解决方案。

Abstract: Decentralized Federated Learning (DFL) enables privacy-preserving
collaborative training without centralized servers, but remains vulnerable to
Byzantine attacks where malicious clients submit corrupted model updates.
Existing Byzantine-robust DFL defenses rely on similarity-based neighbor
screening that requires every client to exchange and compare complete
high-dimensional model vectors with all neighbors in each training round,
creating prohibitive communication and computational costs that prevent
deployment at web scale. We propose SketchGuard, a general framework that
decouples Byzantine filtering from model aggregation through sketch-based
neighbor screening. SketchGuard compresses $d$-dimensional models to
$k$-dimensional sketches ($k \ll d$) using Count Sketch for similarity
comparisons, then selectively fetches full models only from accepted neighbors,
reducing per-round communication complexity from $O(d|N_i|)$ to $O(k|N_i| +
d|S_i|)$, where $|N_i|$ is the neighbor count and $|S_i| \le |N_i|$ is the
accepted neighbor count. We establish rigorous convergence guarantees in both
strongly convex and non-convex settings, proving that Count Sketch compression
preserves Byzantine resilience with controlled degradation bounds where
approximation errors introduce only a $(1+O(\epsilon))$ factor in the effective
threshold parameter. Comprehensive experiments across multiple datasets,
network topologies, and attack scenarios demonstrate that SketchGuard maintains
identical robustness to state-of-the-art methods while reducing computation
time by up to 82% and communication overhead by 50-70% depending on filtering
effectiveness, with benefits scaling multiplicatively with model dimensionality
and network connectivity. These results establish the viability of sketch-based
compression as a fundamental enabler of robust DFL at web scale.

</details>


### [13] [Long-tailed Recognition with Model Rebalancing](https://arxiv.org/abs/2510.08177)
*Jiaan Luo,Feng Hong,Qiang Hu,Xiaofeng Cao,Feng Liu,Jiangchao Yao*

Main category: cs.LG

TL;DR: 提出MORE框架，通过直接重新平衡模型参数空间来解决长尾识别问题，使用低秩参数组件调节参数分配，不增加模型复杂度或推理成本。


<details>
  <summary>Details</summary>
Motivation: 长尾识别在深度学习和基础模型微调中普遍存在且具有挑战性，偏斜的类别分布阻碍模型对尾部类别的泛化能力。现有方法在多标签长尾识别等广泛场景中难以取得一致改进。

Method: 提出模型重平衡(MORE)框架，引入低秩参数组件来调节参数空间分配，使用定制损失和正弦重加权调度，但不增加整体模型复杂度或推理成本。

Result: 在多样化的长尾基准测试中，涵盖多类和多标签任务，MORE显著改善了泛化能力，特别是对尾部类别，并能有效补充现有的不平衡缓解方法。

Conclusion: MORE作为长尾设置中的鲁棒即插即用模块具有巨大潜力。

Abstract: Long-tailed recognition is ubiquitous and challenging in deep learning and
even in the downstream finetuning of foundation models, since the skew class
distribution generally prevents the model generalization to the tail classes.
Despite the promise of previous methods from the perspectives of data
augmentation, loss rebalancing and decoupled training etc., consistent
improvement in the broad scenarios like multi-label long-tailed recognition is
difficult. In this study, we dive into the essential model capacity impact
under long-tailed context, and propose a novel framework, Model Rebalancing
(MORE), which mitigates imbalance by directly rebalancing the model's parameter
space. Specifically, MORE introduces a low-rank parameter component to mediate
the parameter space allocation guided by a tailored loss and sinusoidal
reweighting schedule, but without increasing the overall model complexity or
inference costs. Extensive experiments on diverse long-tailed benchmarks,
spanning multi-class and multi-label tasks, demonstrate that MORE significantly
improves generalization, particularly for tail classes, and effectively
complements existing imbalance mitigation methods. These results highlight
MORE's potential as a robust plug-and-play module in long-tailed settings.

</details>


### [14] [The Hidden Bias: A Study on Explicit and Implicit Political Stereotypes in Large Language Models](https://arxiv.org/abs/2510.08236)
*Konrad Löhr,Shuzhou Yuan,Michael Färber*

Main category: cs.LG

TL;DR: 该研究使用政治罗盘测试评估了8个主流大语言模型的政治偏见和刻板印象传播，发现所有模型都呈现左倾政治倾向，且通过语言变化引发的隐性刻板印象比显性刻板印象更明显。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在社会信息传播和决策过程中的作用日益重要，理解其政治偏见对于防止对公众舆论和民主进程产生不当影响至关重要。

Method: 使用二维政治罗盘测试评估模型的固有政治倾向，通过角色提示探索显性刻板印象，并使用多语言版本PCT揭示隐性刻板印象。

Result: 所有被调查模型都呈现一致的左倾政治倾向；隐性刻板印象比显性刻板印象更明显；大多数模型的隐性和显性刻板印象存在显著一致性。

Conclusion: 研究揭示了LLMs中政治偏见与刻板印象的复杂相互作用，表明模型对其固有偏见具有一定程度的透明度或"意识"。

Abstract: Large Language Models (LLMs) are increasingly integral to information
dissemination and decision-making processes. Given their growing societal
influence, understanding potential biases, particularly within the political
domain, is crucial to prevent undue influence on public opinion and democratic
processes. This work investigates political bias and stereotype propagation
across eight prominent LLMs using the two-dimensional Political Compass Test
(PCT). Initially, the PCT is employed to assess the inherent political leanings
of these models. Subsequently, persona prompting with the PCT is used to
explore explicit stereotypes across various social dimensions. In a final step,
implicit stereotypes are uncovered by evaluating models with multilingual
versions of the PCT. Key findings reveal a consistent left-leaning political
alignment across all investigated models. Furthermore, while the nature and
extent of stereotypes vary considerably between models, implicit stereotypes
elicited through language variation are more pronounced than those identified
via explicit persona prompting. Interestingly, for most models, implicit and
explicit stereotypes show a notable alignment, suggesting a degree of
transparency or "awareness" regarding their inherent biases. This study
underscores the complex interplay of political bias and stereotypes in LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines](https://arxiv.org/abs/2510.07614)
*Amine Barrak*

Main category: cs.AI

TL;DR: 本文研究了可追踪和可问责的LLM多智能体系统，通过Planner->Executor->Critic流水线结构，分析错误传播机制并量化各角色的表现差异，发现结构化交接能显著提升系统准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM多智能体系统在自动化复杂软件任务时存在信任问题，错误会在各阶段间静默传递而难以追踪和问责。

Method: 构建Planner->Executor->Critic流水线，评估8种配置的3种先进LLM在3个基准测试上的表现，分析错误起源、传播和修复机制。

Result: 结构化交接显著提高准确性并防止简单流水线的常见故障；不同模型在特定角色上表现各异；准确度-成本-延迟权衡具有任务依赖性。

Conclusion: 提供了一种实用的数据驱动方法，用于设计、追踪和调试可靠、可预测且可问责的多智能体系统。

Abstract: Sequential multi-agent systems built with large language models (LLMs) can
automate complex software tasks, but they are hard to trust because errors
quietly pass from one stage to the next. We study a traceable and accountable
pipeline, meaning a system with clear roles, structured handoffs, and saved
records that let us trace who did what at each step and assign blame when
things go wrong. Our setting is a Planner -> Executor -> Critic pipeline. We
evaluate eight configurations of three state-of-the-art LLMs on three
benchmarks and analyze where errors start, how they spread, and how they can be
fixed. Our results show: (1) adding a structured, accountable handoff between
agents markedly improves accuracy and prevents the failures common in simple
pipelines; (2) models have clear role-specific strengths and risks (e.g.,
steady planning vs. high-variance critiquing), which we quantify with repair
and harm rates; and (3) accuracy-cost-latency trade-offs are task-dependent,
with heterogeneous pipelines often the most efficient. Overall, we provide a
practical, data-driven method for designing, tracing, and debugging reliable,
predictable, and accountable multi-agent systems.

</details>


### [16] [GCPO: When Contrast Fails, Go Gold](https://arxiv.org/abs/2510.07790)
*Hao Wu,Wei Liu*

Main category: cs.AI

TL;DR: 提出了Group Contrastive Policy Optimization (GCPO)方法，通过引入外部标准参考答案来解决GRPO算法在样本全错或全对时无法有效学习的问题，提升训练效率和推理泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法如GRPO存在明显缺陷：模型生成响应的上界完全由模型自身决定，无法从全错或全对的样本中获取知识，限制了小模型推理能力的提升。

Method: GCPO方法引入外部标准参考答案，当模型无法解决问题时，参考答案提供正确响应，引导模型向明确正确的更新方向学习，充分利用每个样本并模仿参考答案的解题策略。

Result: GCPO在多个基准数据集上取得了优异结果，相比基线模型有显著改进。

Conclusion: GCPO通过引入外部参考答案有效解决了GRPO的局限性，提高了训练效率和推理泛化能力，为增强语言模型推理能力提供了有效方法。

Abstract: Reinforcement learning has been widely applied to enhance the reasoning
capabilities of large language models. Extending the inference limits of
smaller models has become a prominent research focus. However, algorithms such
as Group Relative Policy Optimization (GRPO) suffer from a clear drawback: the
upper bound of a model's rollout responses is entirely determined by the model
itself, preventing the acquisition of knowledge from samples that are either
all incorrect or all correct. In this paper, we introduce Group Contrastive
Policy Optimization (GCPO), a method that incorporates external standard
reference answers. When the model cannot solve a problem, the reference answer
supplies the correct response, steering the model toward an unequivocally
accurate update direction. This approach offers two main advantages: (1) it
improves training efficiency by fully utilizing every sample; (2) it enables
the model to emulate the problem solving strategy of the reference answer
during training, thereby enhancing generalization in reasoning. GCPO achieves
outstanding results across multiple benchmark datasets, yielding substantial
improvements over the baseline model. Our code is available at:
https://github.com/AchoWu/GCPO.

</details>


### [17] [Can Risk-taking AI-Assistants suitably represent entities](https://arxiv.org/abs/2510.08114)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Amirhossein Farshi Sotoudeh*

Main category: cs.AI

TL;DR: 研究语言模型风险厌恶可操纵性，发现虽然模型与人类行为有一定对齐，但存在明显差异，需要改进生物中心测量方法。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地集成到AI决策支持系统中，理解其风险行为对于负责任部署至关重要。需要防止模型无意中将用户推向风险决策或嵌入隐藏偏见。

Method: 研究语言模型风险厌恶可操纵性，考察其在多样化经济场景中复制人类风险偏好的能力，重点关注性别特定态度、不确定性、基于角色的决策以及风险厌恶可操纵性。

Result: DeepSeek Reasoner和Gemini-2.0-flash-lite等语言模型与人类行为有一定对齐，但存在显著差异，突显了改进生物中心可操纵性测量的必要性。

Conclusion: 需要进一步改进模型设计，确保AI系统更准确地复制人类风险偏好，从而在风险管理环境中提高其有效性，增强AI助手在风险管理中的适用性。

Abstract: Responsible AI demands systems whose behavioral tendencies can be effectively
measured, audited, and adjusted to prevent inadvertently nudging users toward
risky decisions or embedding hidden biases in risk aversion. As language models
(LMs) are increasingly incorporated into AI-driven decision support systems,
understanding their risk behaviors is crucial for their responsible deployment.
This study investigates the manipulability of risk aversion (MoRA) in LMs,
examining their ability to replicate human risk preferences across diverse
economic scenarios, with a focus on gender-specific attitudes, uncertainty,
role-based decision-making, and the manipulability of risk aversion. The
results indicate that while LMs such as DeepSeek Reasoner and
Gemini-2.0-flash-lite exhibit some alignment with human behaviors, notable
discrepancies highlight the need to refine bio-centric measures of
manipulability. These findings suggest directions for refining AI design to
better align human and AI risk preferences and enhance ethical decision-making.
The study calls for further advancements in model design to ensure that AI
systems more accurately replicate human risk preferences, thereby improving
their effectiveness in risk management contexts. This approach could enhance
the applicability of AI assistants in managing risk.

</details>


### [18] [Co-TAP: Three-Layer Agent Interaction Protocol Technical Report](https://arxiv.org/abs/2510.08263)
*Shunyu An,Miao Wang,Yongchao Li,Dong Wan,Lina Wang,Ling Qin,Liqin Gao,Congyao Fan,Zhiyong Mao,Jiange Pu,Wenji Xia,Dong Zhao,Rui Hu,Ji Lu,Guiyue Zhou,Baoyu Tang,Yanqin Gao,Yongsheng Du,Daigang Xu,Lingjun Huang,Baoli Wang,Xiwen Zhang,Luyao Wang,Shilong Liu*

Main category: cs.AI

TL;DR: Co-TAP是一个三层智能体交互协议框架，通过HAI、UAP、MEK三个核心协议分别解决交互层、基础设施层和认知层的挑战，旨在实现多智能体系统在互操作性、交互协作和知识共享三个维度的统一。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统面临的互操作性、交互协作和知识共享三大核心挑战，为构建高效、可扩展的智能多智能体应用提供工程基础和理论指导。

Method: 设计了三层协议：HAI（人机交互协议）标准化事件驱动通信；UAP（统一智能体协议）通过服务发现和协议转换实现异构智能体互联；MEK（记忆-提取-知识协议）建立标准化认知链实现知识共享。

Result: 提出了一个完整的协议框架，能够确保交互的实时性、可靠性、协同性，实现异构智能体的无缝互联，并为集体智能的实现奠定基础。

Conclusion: Co-TAP协议框架为构建下一代高效、可扩展、智能的多智能体应用提供了坚实的工程基础和理论指导。

Abstract: This paper proposes Co-TAP (T: Triple, A: Agent, P: Protocol), a three-layer
agent interaction protocol designed to address the challenges faced by
multi-agent systems across the three core dimensions of Interoperability,
Interaction and Collaboration, and Knowledge Sharing. We have designed and
proposed a layered solution composed of three core protocols: the Human-Agent
Interaction Protocol (HAI), the Unified Agent Protocol (UAP), and the
Memory-Extraction-Knowledge Protocol (MEK). HAI focuses on the interaction
layer, standardizing the flow of information between users, interfaces, and
agents by defining a standardized, event-driven communication paradigm. This
ensures the real-time performance, reliability, and synergy of interactions. As
the core of the infrastructure layer, UAP is designed to break down
communication barriers among heterogeneous agents through unified service
discovery and protocol conversion mechanisms, thereby enabling seamless
interconnection and interoperability of the underlying network. MEK, in turn,
operates at the cognitive layer. By establishing a standardized ''Memory (M) -
Extraction (E) - Knowledge (K)'' cognitive chain, it empowers agents with the
ability to learn from individual experiences and form shareable knowledge,
thereby laying the foundation for the realization of true collective
intelligence. We believe this protocol framework will provide a solid
engineering foundation and theoretical guidance for building the next
generation of efficient, scalable, and intelligent multi-agent applications.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 提出新的波斯语-塔吉克语双向音译模型，在多个数据集上训练，在跨领域文本上取得最佳性能，为波斯语不同书写体系之间的交流提供解决方案。


<details>
  <summary>Details</summary>
Motivation: 波斯语作为双语种语言，在阿富汗和伊朗使用波斯-阿拉伯字母，在塔吉克斯坦使用塔吉克-西里尔字母。虽然方言相似，但书写体系差异阻碍了塔吉克斯坦与其他波斯语国家的书面交流。现有音译模型大多局限于特定领域，缺乏实际应用的通用性。

Method: 开发了新的序列到序列模型，在所有可用数据集上进行训练，并贡献了两个新数据集。模型采用跨领域训练策略，提高泛化能力。

Result: 模型在双向音译任务中表现优异：从波斯语到塔吉克语的chrF++和标准化CER得分分别为87.91和0.05；从塔吉克语到波斯语分别为92.28和0.04。

Conclusion: 该研究提供了首个跨领域的波斯语-塔吉克语音译基准，模型在多样化文本上表现出色，为波斯语不同书写体系之间的交流提供了实用解决方案。

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [20] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型中真实性增强与安全对齐之间的权衡，发现提高事实准确性会削弱模型的拒绝行为，并提出了一种通过稀疏自编码器分离拒绝相关特征与幻觉特征的方法来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 当前对LLM幻觉的研究主要集中在检测和缓解以提高真实性，但忽视了增强真实性可能对安全对齐产生的负面影响。本文旨在研究这种权衡关系。

Method: 使用稀疏自编码器将拒绝相关特征与幻觉特征分离，并通过子空间正交化在微调过程中保持拒绝行为。

Result: 在常识推理任务和有害基准测试（AdvBench和StrongReject）上的评估表明，该方法能保持拒绝行为和任务效用，缓解真实性与安全性之间的权衡。

Conclusion: 提出的方法有效防止了幻觉增加的同时保持了安全对齐，解决了真实性与安全性之间的冲突问题。

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [21] [Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning](https://arxiv.org/abs/2510.07974)
*Jialu Du,Guiyang Hou,Yihui Fu,Chen Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu*

Main category: cs.CL

TL;DR: LLMs在社交推理任务中存在困难，无法区分客观现实与主观信念。本文提出自适应世界模型增强推理机制，通过构建动态文本世界模型来跟踪实体状态和时间序列，显著提升社交推理准确性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数学和代码推理方面表现出色，但在社交推理任务中却遇到困难，表现出认知混乱、逻辑不一致以及混淆客观世界状态与主观信念状态的问题。

Method: 提出自适应世界模型增强推理机制，构建动态文本世界模型来跟踪实体状态和时间序列，动态监控推理轨迹中的混乱指标，并通过提供清晰的世界状态描述来及时干预。

Result: 在三个社交基准测试中显示出显著改进，准确率提升（如在Hi-ToM中+10%），同时计算成本降低（最多减少33.8%的token使用）。

Conclusion: 该机制提供了一种简单而有效的解决方案，使LLMs能够在社交情境中更好地部署，模仿人类使用隐式世界模型来区分外部事件和内部信念的方式。

Abstract: While large language models (LLMs) excel in mathematical and code reasoning,
we observe they struggle with social reasoning tasks, exhibiting cognitive
confusion, logical inconsistencies, and conflation between objective world
states and subjective belief states. Through deteiled analysis of DeepSeek-R1's
reasoning trajectories, we find that LLMs frequently encounter reasoning
impasses and tend to output contradictory terms like "tricky" and "confused"
when processing scenarios with multiple participants and timelines, leading to
erroneous reasoning or infinite loops. The core issue is their inability to
disentangle objective reality from agents' subjective beliefs. To address this,
we propose an adaptive world model-enhanced reasoning mechanism that constructs
a dynamic textual world model to track entity states and temporal sequences. It
dynamically monitors reasoning trajectories for confusion indicators and
promptly intervenes by providing clear world state descriptions, helping models
navigate through cognitive dilemmas. The mechanism mimics how humans use
implicit world models to distinguish between external events and internal
beliefs. Evaluations on three social benchmarks demonstrate significant
improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational
costs (up to 33.8% token reduction), offering a simple yet effective solution
for deploying LLMs in social contexts.

</details>


### [22] [SenWave: A Fine-Grained Multi-Language Sentiment Analysis Dataset Sourced from COVID-19 Tweets](https://arxiv.org/abs/2510.08214)
*Qiang Yang,Xiuying Chen,Changsheng Ma,Rui Yin,Xin Gao,Xiangliang Zhang*

Main category: cs.CL

TL;DR: SenWave是一个针对COVID-19推文的多语言细粒度情感分析数据集，包含10个情感类别，涵盖英语、阿拉伯语、西班牙语、法语和意大利语，并包含超过1.05亿条未标记推文。


<details>
  <summary>Details</summary>
Motivation: 解决现有COVID-19数据集中标记数据不足、情感标签粒度粗或不适当的问题，以深入理解疫情期间的公众情感变化。

Method: 构建了包含10,000条英语和阿拉伯语标注推文，以及30,000条翻译推文的数据集；使用预训练的基于transformer的语言模型进行细粒度情感分类。

Result: 实现了跨语言、国家和主题的情感演变分析，验证了数据集与ChatGPT的兼容性，展示了其在各种应用中的稳健性和多功能性。

Conclusion: SenWave数据集和代码已公开，预计将推动NLP社区对复杂事件的细粒度情感分析研究，促进更细致理解和研究创新。

Abstract: The global impact of the COVID-19 pandemic has highlighted the need for a
comprehensive understanding of public sentiment and reactions. Despite the
availability of numerous public datasets on COVID-19, some reaching volumes of
up to 100 billion data points, challenges persist regarding the availability of
labeled data and the presence of coarse-grained or inappropriate sentiment
labels. In this paper, we introduce SenWave, a novel fine-grained
multi-language sentiment analysis dataset specifically designed for analyzing
COVID-19 tweets, featuring ten sentiment categories across five languages. The
dataset comprises 10,000 annotated tweets each in English and Arabic, along
with 30,000 translated tweets in Spanish, French, and Italian, derived from
English tweets. Additionally, it includes over 105 million unlabeled tweets
collected during various COVID-19 waves. To enable accurate fine-grained
sentiment classification, we fine-tuned pre-trained transformer-based language
models using the labeled tweets. Our study provides an in-depth analysis of the
evolving emotional landscape across languages, countries, and topics, revealing
significant insights over time. Furthermore, we assess the compatibility of our
dataset with ChatGPT, demonstrating its robustness and versatility in various
applications. Our dataset and accompanying code are publicly accessible on the
repository\footnote{https://github.com/gitdevqiang/SenWave}. We anticipate that
this work will foster further exploration into fine-grained sentiment analysis
for complex events within the NLP community, promoting more nuanced
understanding and research innovations.

</details>


### [23] [Two-Stage Voting for Robust and Efficient Suicide Risk Detection on Social Media](https://arxiv.org/abs/2510.08365)
*Yukai Song,Pengfei Zhou,César Escobar-Viera,Candice Biernesser,Wei Huang,Jingtong Hu*

Main category: cs.CL

TL;DR: 提出两阶段投票架构用于自杀风险检测，第一阶段用轻量BERT处理明确案例，第二阶段用多视角LLM投票或基于心理学特征的ML集成处理模糊案例，在效率和准确性上取得平衡。


<details>
  <summary>Details</summary>
Motivation: 自杀率上升需要主动预防策略，社交媒体提供有价值信号，但检测间接表达的自杀意念非常困难，现有模型要么效率低要么无法处理细微暗示。

Method: 两阶段架构：第一阶段BERT快速处理高置信度明确案例；第二阶段对模糊输入采用多视角LLM投票或基于LLM提取心理学特征的ML集成方法。

Result: 在两个数据集上表现优异：明确案例F1达98.0%，隐含案例达99.7%，跨域差距低于2%，同时显著降低LLM成本。

Conclusion: 该框架在自杀风险检测中有效平衡效率和鲁棒性，是首批将LLM提取的心理学特征作为结构化向量用于此任务的工作之一。

Abstract: Suicide rates have risen worldwide in recent years, underscoring the urgent
need for proactive prevention strategies. Social media provides valuable
signals, as many at-risk individuals - who often avoid formal help due to
stigma - choose instead to share their distress online. Yet detecting implicit
suicidal ideation, conveyed indirectly through metaphor, sarcasm, or subtle
emotional cues, remains highly challenging. Lightweight models like BERT handle
explicit signals but fail on subtle implicit ones, while large language models
(LLMs) capture nuance at prohibitive computational cost. To address this gap,
we propose a two-stage voting architecture that balances efficiency and
robustness. In Stage 1, a lightweight BERT classifier rapidly resolves
high-confidence explicit cases. In Stage 2, ambiguous inputs are escalated to
either (i) a multi-perspective LLM voting framework to maximize recall on
implicit ideation, or (ii) a feature-based ML ensemble guided by
psychologically grounded indicators extracted via prompt-engineered LLMs for
efficiency and interpretability. To the best of our knowledge, this is among
the first works to operationalize LLM-extracted psychological features as
structured vectors for suicide risk detection. On two complementary datasets -
explicit-dominant Reddit and implicit-only DeepSuiMind - our framework
outperforms single-model baselines, achieving 98.0% F1 on explicit cases, 99.7%
on implicit ones, and reducing the cross-domain gap below 2%, while
significantly lowering LLM cost.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Differentiable Particle Optimization for Fast Sequential Manipulation](https://arxiv.org/abs/2510.07674)
*Lucas Chen,Shrutheesh Raman Iyer,Zachary Kingston*

Main category: cs.RO

TL;DR: SPaSM是一个完全GPU并行化的框架，通过两阶段粒子优化策略解决顺序机器人操作任务中的轨迹优化问题，实现毫秒级求解速度。


<details>
  <summary>Details</summary>
Motivation: 顺序机器人操作任务需要在可能的高维配置空间中找到满足多个物体交互几何约束的无碰撞轨迹，但现有方法因CPU-GPU数据传输开销和复杂逻辑导致性能受限。

Method: 将约束评估、采样和基于梯度的优化编译为优化的CUDA内核，采用两阶段粒子优化策略：首先通过大规模并行采样解决放置约束，然后在关节空间中提升为完整轨迹优化。

Result: 在具有挑战性的基准测试中，求解时间达到毫秒级，成功率为100%，相比现有方法实现了4000倍的加速。

Conclusion: SPaSM通过完全GPU并行化和联合优化物体放置与机器人轨迹，显著提升了顺序操作任务的求解效率。

Abstract: Sequential robot manipulation tasks require finding collision-free
trajectories that satisfy geometric constraints across multiple object
interactions in potentially high-dimensional configuration spaces. Solving
these problems in real-time and at large scales has remained out of reach due
to computational requirements. Recently, GPU-based acceleration has shown
promising results, but prior methods achieve limited performance due to CPU-GPU
data transfer overhead and complex logic that prevents full hardware
utilization. To this end, we present SPaSM (Sampling Particle optimization for
Sequential Manipulation), a fully GPU-parallelized framework that compiles
constraint evaluation, sampling, and gradient-based optimization into optimized
CUDA kernels for end-to-end trajectory optimization without CPU coordination.
The method consists of a two-stage particle optimization strategy: first
solving placement constraints through massively parallel sampling, then lifting
solutions to full trajectory optimization in joint space. Unlike hierarchical
approaches, SPaSM jointly optimizes object placements and robot trajectories to
handle scenarios where motion feasibility constrains placement options.
Experimental evaluation on challenging benchmarks demonstrates solution times
in the realm of $\textbf{milliseconds}$ with a 100% success rate; a
$4000\times$ speedup compared to existing approaches.

</details>


### [25] [DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation](https://arxiv.org/abs/2510.07865)
*Guowei Zou,Haitao Wang,Hejun Wu,Yukun Qian,Yuhang Wang,Weibing Li*

Main category: cs.RO

TL;DR: DM1提出了一种结合分散正则化的流匹配框架，解决了基于流的策略中的表示崩溃问题，在保持一步生成效率的同时显著提升了机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 基于流的生成模型在机器人操作策略中具有采样效率高的优势，但存在表示崩溃问题，无法区分相似的视觉表示，导致在精确操作任务中失败。

Method: DM1将分散正则化集成到MeanFlow中，在不同中间嵌入层使用多种分散正则化变体，鼓励训练批次中的多样化表示，无需额外网络模块或专门训练过程。

Result: 在RoboMimic基准测试中，DM1实现了20-40倍的推理加速（0.07s vs 2-3.5s），成功率提升10-20个百分点，Lift任务达到99%成功率（基线为85%）。真实机器人部署验证了从仿真到物理世界的有效迁移。

Conclusion: 这是首个利用表示正则化使基于流的策略在机器人操作中实现强性能的工作，为高效和鲁棒的操作建立了一种简单而强大的方法。

Abstract: The ability to learn multi-modal action distributions is indispensable for
robotic manipulation policies to perform precise and robust control. Flow-based
generative models have recently emerged as a promising solution to learning
distributions of actions, offering one-step action generation and thus
achieving much higher sampling efficiency compared to diffusion-based methods.
However, existing flow-based policies suffer from representation collapse, the
inability to distinguish similar visual representations, leading to failures in
precise manipulation tasks. We propose DM1 (MeanFlow with Dispersive
Regularization for One-Step Robotic Manipulation), a novel flow matching
framework that integrates dispersive regularization into MeanFlow to prevent
collapse while maintaining one-step efficiency. DM1 employs multiple dispersive
regularization variants across different intermediate embedding layers,
encouraging diverse representations across training batches without introducing
additional network modules or specialized training procedures. Experiments on
RoboMimic benchmarks show that DM1 achieves 20-40 times faster inference (0.07s
vs. 2-3.5s) and improves success rates by 10-20 percentage points, with the
Lift task reaching 99% success over 85% of the baseline. Real-robot deployment
on a Franka Panda further validates that DM1 transfers effectively from
simulation to the physical world. To the best of our knowledge, this is the
first work to leverage representation regularization to enable flow-based
policies to achieve strong performance in robotic manipulation, establishing a
simple yet powerful approach for efficient and robust manipulation.

</details>


### [26] [Scalable Offline Metrics for Autonomous Driving](https://arxiv.org/abs/2510.08571)
*Animikh Aich,Adwait Kulkarni,Eshed Ohn-Bar*

Main category: cs.RO

TL;DR: 该研究重新评估了自动驾驶系统中离线模型性能与在线实际表现之间的相关性，发现两者相关性比先前研究报道的更差，并提出基于认知不确定性的离线评估指标，显著改善了相关性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的感知规划模型在离线评估中表现良好，但在实际在线环境中微小错误会累积导致事故，这种离线与在线性能之间的关联性研究不足，特别是在复杂城市驾驶场景中。

Method: 通过大量仿真实验分析离线与在线评估的相关性，提出基于认知不确定性的离线评估指标，并在仿真和真实世界环境中验证其有效性。

Result: 研究发现离线与在线评估的相关性比先前报道的更差，基于认知不确定性的新指标相比传统离线指标提升了13%以上的相关性，在真实世界环境中效果更显著。

Conclusion: 当前自动驾驶策略的评估实践和指标存在有效性疑问，基于认知不确定性的离线评估方法能更好地预测在线性能，为改进评估方法提供了新方向。

Abstract: Real-World evaluation of perception-based planning models for robotic
systems, such as autonomous vehicles, can be safely and inexpensively conducted
offline, i.e., by computing model prediction error over a pre-collected
validation dataset with ground-truth annotations. However, extrapolating from
offline model performance to online settings remains a challenge. In these
settings, seemingly minor errors can compound and result in test-time
infractions or collisions. This relationship is understudied, particularly
across diverse closed-loop metrics and complex urban maneuvers. In this work,
we revisit this undervalued question in policy evaluation through an extensive
set of experiments across diverse conditions and metrics. Based on analysis in
simulation, we find an even worse correlation between offline and online
settings than reported by prior studies, casting doubts on the validity of
current evaluation practices and metrics for driving policies. Next, we bridge
the gap between offline and online evaluation. We investigate an offline metric
based on epistemic uncertainty, which aims to capture events that are likely to
cause errors in closed-loop settings. The resulting metric achieves over 13%
improvement in correlation compared to previous offline metrics. We further
validate the generalization of our findings beyond the simulation environment
in real-world settings, where even greater gains are observed.

</details>
