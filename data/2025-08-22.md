<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis](https://arxiv.org/abs/2508.15189)
*Jiahao Xu,Changchang Yin,Odysseas Chatzipanagiotou,Diamantis Tsilimigras,Kevin Clear,Bingsheng Yao,Dakuo Wang,Timothy Pawlik,Ping Zhang*

Main category: cs.CV

TL;DR: 提出了首个开源手术伤口数据集SurgWound和基准测试，并开发了三阶段学习框架WoundQwen用于手术伤口诊断，包括特征预测、风险评估和报告生成。


<details>
  <summary>Details</summary>
Motivation: 手术部位感染(SSI)是常见且昂贵的医疗相关感染，现有深度学习研究受限于数据隐私和专家标注成本高的问题，缺乏公开数据集和开源筛查工具。

Method: 1) 创建包含697张手术伤口图像的SurgWound数据集，由3名专业外科医生标注8个细粒度临床属性；2) 建立包含视觉问答和报告生成任务的基准测试；3) 提出三阶段框架WoundQwen：第一阶段用5个MLLM预测伤口特征，第二阶段用2个MLLM进行风险评估，第三阶段整合结果生成综合报告。

Result: 开发了首个开源手术伤口数据集和基准测试，提出了能够分析伤口特征、评估感染风险并提供个性化护理指导的三阶段诊断框架。

Conclusion: 该研究为手术伤口筛查提供了重要的数据集和基准，提出的三阶段框架为实现个性化伤口护理、及时干预和改善患者预后奠定了基础。

Abstract: Surgical site infection (SSI) is one of the most common and costly
healthcare-associated infections and and surgical wound care remains a
significant clinical challenge in preventing SSIs and improving patient
outcomes. While recent studies have explored the use of deep learning for
preliminary surgical wound screening, progress has been hindered by concerns
over data privacy and the high costs associated with expert annotation.
Currently, no publicly available dataset or benchmark encompasses various types
of surgical wounds, resulting in the absence of an open-source Surgical-Wound
screening tool. To address this gap: (1) we present SurgWound, the first
open-source dataset featuring a diverse array of surgical wound types. It
contains 697 surgical wound images annotated by 3 professional surgeons with
eight fine-grained clinical attributes. (2) Based on SurgWound, we introduce
the first benchmark for surgical wound diagnosis, which includes visual
question answering (VQA) and report generation tasks to comprehensively
evaluate model performance. (3) Furthermore, we propose a three-stage learning
framework, WoundQwen, for surgical wound diagnosis. In the first stage, we
employ five independent MLLMs to accurately predict specific surgical wound
characteristics. In the second stage, these predictions serve as additional
knowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess
infection risk and guide subsequent interventions. In the third stage, we train
a MLLM that integrates the diagnostic results from the previous two stages to
produce a comprehensive report. This three-stage framework can analyze detailed
surgical wound characteristics and provide subsequent instructions to patients
based on surgical images, paving the way for personalized wound care, timely
intervention, and improved patient outcomes.

</details>


### [2] [VideoEraser: Concept Erasure in Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.15314)
*Naen Xu,Jinghuai Zhang,Changjiang Li,Zhi Chen,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CV

TL;DR: VideoEraser是一个无需训练的即插即用框架，通过两阶段处理防止文本到视频扩散模型生成包含不良概念的内容，在四个任务中平均减少46%的不良内容生成。


<details>
  <summary>Details</summary>
Motivation: 文本到视频扩散模型的快速发展引发了隐私、版权和安全担忧，这些模型可能被滥用来生成有害或误导性内容，需要一种方法来防止生成不良概念。

Method: 采用两阶段过程：选择性提示嵌入调整（SPEA）和抗干扰噪声引导（ARNG），作为即插即用模块与现有T2V扩散模型无缝集成。

Result: 在对象擦除、艺术风格擦除、名人擦除和显式内容擦除四个任务中，VideoEraser在效能、完整性、保真度、鲁棒性和泛化性方面均优于现有方法。

Conclusion: VideoEraser在抑制T2V生成中的不良内容方面达到了最先进的性能，为控制扩散模型输出提供了有效的解决方案。

Abstract: The rapid growth of text-to-video (T2V) diffusion models has raised concerns
about privacy, copyright, and safety due to their potential misuse in
generating harmful or misleading content. These models are often trained on
numerous datasets, including unauthorized personal identities, artistic
creations, and harmful materials, which can lead to uncontrolled production and
distribution of such content. To address this, we propose VideoEraser, a
training-free framework that prevents T2V diffusion models from generating
videos with undesirable concepts, even when explicitly prompted with those
concepts. Designed as a plug-and-play module, VideoEraser can seamlessly
integrate with representative T2V diffusion models via a two-stage process:
Selective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise
Guidance (ARNG). We conduct extensive evaluations across four tasks, including
object erasure, artistic style erasure, celebrity erasure, and explicit content
erasure. Experimental results show that VideoEraser consistently outperforms
prior methods regarding efficacy, integrity, fidelity, robustness, and
generalizability. Notably, VideoEraser achieves state-of-the-art performance in
suppressing undesirable content during T2V generation, reducing it by 46% on
average across four tasks compared to baselines.

</details>


### [3] [Spiking Variational Graph Representation Inference for Video Summarization](https://arxiv.org/abs/2508.15389)
*Wenrui Li,Wei Han,Liang-Jian Deng,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 提出SpiVG网络，结合脉冲神经网络和变分推理，解决视频摘要中的时序依赖和语义连贯性问题，在多个数据集上表现优异


<details>
  <summary>Details</summary>
Motivation: 短视频内容兴起需要高效的关键信息提取技术，但现有方法难以捕捉全局时序依赖、保持语义连贯性，且在多通道特征融合时易受噪声影响

Method: 设计基于SNN的关键帧提取器，引入动态聚合图推理器解耦上下文对象一致性和语义视角连贯性，使用变分推理重建模块处理多通道特征融合的不确定性和噪声

Result: 在SumMe、TVSum、VideoXum和QFVS等多个数据集上超越现有方法

Conclusion: SpiVG网络通过SNN的事件驱动机制和变分推理技术，有效提升了视频摘要的信息密度和语义连贯性，同时降低了计算复杂度

Abstract: With the rise of short video content, efficient video summarization
techniques for extracting key information have become crucial. However,
existing methods struggle to capture the global temporal dependencies and
maintain the semantic coherence of video content. Additionally, these methods
are also influenced by noise during multi-channel feature fusion. We propose a
Spiking Variational Graph (SpiVG) Network, which enhances information density
and reduces computational complexity. First, we design a keyframe extractor
based on Spiking Neural Networks (SNN), leveraging the event-driven computation
mechanism of SNNs to learn keyframe features autonomously. To enable
fine-grained and adaptable reasoning across video frames, we introduce a
Dynamic Aggregation Graph Reasoner, which decouples contextual object
consistency from semantic perspective coherence. We present a Variational
Inference Reconstruction Module to address uncertainty and noise arising during
multi-channel feature fusion. In this module, we employ Evidence Lower Bound
Optimization (ELBO) to capture the latent structure of multi-channel feature
distributions, using posterior distribution regularization to reduce
overfitting. Experimental results show that SpiVG surpasses existing methods
across multiple datasets such as SumMe, TVSum, VideoXum, and QFVS. Our codes
and pre-trained models are available at https://github.com/liwrui/SpiVG.

</details>


### [4] [Aligning Moments in Time using Video Queries](https://arxiv.org/abs/2508.15439)
*Yogesh Kumar,Uday Agarwal,Manish Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: MATR是一个基于Transformer的视频到视频时刻检索模型，通过双阶段序列对齐和自监督预训练，在ActivityNet-VRL和SportsMoments数据集上显著超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 视频到视频时刻检索任务需要语义帧级对齐和建模查询视频与目标视频之间的复杂依赖关系，现有方法在这方面存在挑战。

Method: 提出MATR模型，使用基于Transformer的双阶段序列对齐来捕获语义上下文和时间细节，并采用自监督预训练技术来初始化模型。

Result: 在ActivityNet-VRL数据集上R@1提升13.1%，mIoU提升8.1%；在SportsMoments数据集上R@1提升14.7%，mIoU提升14.4%。

Conclusion: MATR通过有效的序列对齐和预训练策略，显著提升了视频到视频时刻检索的性能，为解决该任务的挑战提供了有效方案。

Abstract: Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen
events or moments in a target video using a query video. This task poses
several challenges, such as the need for semantic frame-level alignment and
modeling complex dependencies between query and target videos. To tackle this
challenging problem, we introduce MATR (Moment Alignment TRansformer), a
transformer-based model designed to capture semantic context as well as the
temporal details necessary for precise moment localization. MATR conditions
target video representations on query video features using dual-stage sequence
alignment that encodes the required correlations and dependencies. These
representations are then used to guide foreground/background classification and
boundary prediction heads, enabling the model to accurately identify moments in
the target video that semantically match with the query video. Additionally, to
provide a strong task-specific initialization for MATR, we propose a
self-supervised pre-training technique that involves training the model to
localize random clips within videos. Extensive experiments demonstrate that
MATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU
on an absolute scale compared to state-of-the-art methods on the popular
ActivityNet-VRL dataset. Additionally, on our newly proposed dataset,
SportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an
absolute scale over strong baselines.

</details>


### [5] [When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding](https://arxiv.org/abs/2508.15641)
*Pengcheng Fang,Yuxia Chen,Rui Guo*

Main category: cs.CV

TL;DR: Grounded VideoDiT是一个视频大语言模型，通过扩散时序潜在编码器、对象接地表示和混合令牌方案，解决了现有视频LLM在时间感知精度上的不足，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频LLM在整体推理方面取得显著进展，但在时间感知上仍显粗糙：时间戳仅隐式编码、帧级特征连续性捕捉能力弱、语言视觉对齐容易偏离关注实体。

Method: 1) 扩散时序潜在(DTL)编码器增强边界敏感性和保持时间一致性；2) 对象接地表示显式绑定查询实体到局部视觉证据；3) 混合令牌方案提供显式时间戳建模

Result: 在Charades STA、NExT GQA和多个VideoQA基准测试中取得了最先进的结果，验证了模型的强大接地能力

Conclusion: Grounded VideoDiT通过三个关键创新设计，成功克服了现有视频LLM的时间感知局限性，实现了细粒度的时间推理和稳健的接地能力

Abstract: Understanding videos requires more than answering open ended questions, it
demands the ability to pinpoint when events occur and how entities interact
across time. While recent Video LLMs have achieved remarkable progress in
holistic reasoning, they remain coarse in temporal perception: timestamps are
encoded only implicitly, frame level features are weak in capturing continuity,
and language vision alignment often drifts from the entities of interest. In
this paper, we present Grounded VideoDiT, a Video LLM designed to overcome
these limitations by introducing three key innovations. First, a Diffusion
Temporal Latent (DTL) encoder enhances boundary sensitivity and maintains
temporal consistency. Second, object grounded representations explicitly bind
query entities to localized visual evidence, strengthening alignment. Third, a
mixed token scheme with discrete temporal tokens provides explicit timestamp
modeling, enabling fine grained temporal reasoning. Together, these designs
equip Grounded VideoDiT with robust grounding capabilities, as validated by
state of the art results on Charades STA, NExT GQA, and multiple VideoQA
benchmarks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving](https://arxiv.org/abs/2508.14926)
*Dianzhao Li,Ostap Okhrin*

Main category: cs.LG

TL;DR: 提出了一种分层安全强化学习框架，将道德考量与标准驾驶目标结合，通过伦理风险成本和安全强化学习来提升自动驾驶车辆的伦理决策能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在减少交通事故和提高交通效率方面具有巨大潜力，但其广泛采用取决于能否在常规和紧急操作中嵌入稳健的伦理推理能力。

Method: 采用分层安全强化学习框架：决策层使用包含碰撞概率和伤害严重性的复合伦理风险成本训练Safe RL智能体；执行层使用多项式路径规划和PID+Stanley控制器将目标转化为平滑可行的轨迹。采用动态优先经验回放机制强化高风险事件的学习。

Result: 在包含多样化车辆、骑行者和行人的真实交通数据集上验证，该方法在降低伦理风险和保持驾驶性能方面优于基线方法。

Conclusion: 这是首个通过安全强化学习在真实场景中研究自动驾驶车辆伦理决策的工作，结合形式控制理论和数据驱动学习有望推动复杂人车混合交通环境中的伦理问责自治。

Abstract: Autonomous vehicles hold great promise for reducing traffic fatalities and
improving transportation efficiency, yet their widespread adoption hinges on
embedding robust ethical reasoning into routine and emergency maneuvers. Here,
we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that
explicitly integrates moral considerations with standard driving objectives. At
the decision level, a Safe RL agent is trained using a composite ethical risk
cost, combining collision probability and harm severity, to generate high-level
motion targets. A dynamic Prioritized Experience Replay mechanism amplifies
learning from rare but critical, high-risk events. At the execution level,
polynomial path planning coupled with Proportional-Integral-Derivative (PID)
and Stanley controllers translates these targets into smooth, feasible
trajectories, ensuring both accuracy and comfort. We train and validate our
approach on rich, real-world traffic datasets encompassing diverse vehicles,
cyclists, and pedestrians, and demonstrate that it outperforms baseline methods
in reducing ethical risk and maintaining driving performance. To our knowledge,
this is the first study of ethical decision-making for autonomous vehicles via
Safe RL in real-world scenarios. Our results highlight the potential of
combining formal control theory and data-driven learning to advance ethically
accountable autonomy in complex, human-mixed traffic environments.

</details>


### [7] [Wormhole Dynamics in Deep Neural Networks](https://arxiv.org/abs/2508.15086)
*Yen-Lung Lai,Zhe Jin*

Main category: cs.LG

TL;DR: 该研究分析了深度神经网络在过参数化状态下的泛化行为，发现网络会出现特征空间坍缩和退化现象，并提出"虫洞"解决方案来绕过退化问题，为理解DNN泛化机制提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 研究深度神经网络中"欺骗性样本"现象，即DNN对看似随机的输入也能给出高置信度分类，旨在探索DNN泛化行为的理论基础，弥补理论与实践的差距。

Method: 采用基于最大似然估计的分析框架，避免传统的基于梯度的优化方法和显式标签，研究过参数化状态下DNN的特征空间坍缩和退化现象。

Result: 发现DNN在过参数化状态下会出现特征空间坍缩（改善泛化）但最终导致退化（不同输入映射到相同输出），提出的"虫洞"解决方案能有效绕过退化问题，协调随机标签与有意义标签的关系。

Conclusion: 研究揭示了DNN泛化行为的新机制，为理解捷径学习提供了新视角，指明了在无监督设置下研究学习动力学以弥合理论与实践差距的未来研究方向。

Abstract: This work investigates the generalization behavior of deep neural networks
(DNNs), focusing on the phenomenon of "fooling examples," where DNNs
confidently classify inputs that appear random or unstructured to humans. To
explore this phenomenon, we introduce an analytical framework based on maximum
likelihood estimation, without adhering to conventional numerical approaches
that rely on gradient-based optimization and explicit labels. Our analysis
reveals that DNNs operating in an overparameterized regime exhibit a collapse
in the output feature space. While this collapse improves network
generalization, adding more layers eventually leads to a state of degeneracy,
where the model learns trivial solutions by mapping distinct inputs to the same
output, resulting in zero loss. Further investigation demonstrates that this
degeneracy can be bypassed using our newly derived "wormhole" solution. The
wormhole solution, when applied to arbitrary fooling examples, reconciles
meaningful labels with random ones and provides a novel perspective on shortcut
learning. These findings offer deeper insights into DNN generalization and
highlight directions for future research on learning dynamics in unsupervised
settings to bridge the gap between theory and practice.

</details>


### [8] [A Solvable Molecular Switch Model for Stable Temporal Information Processing](https://arxiv.org/abs/2508.15451)
*H. I. Nurdin,C. A. Nijhuis*

Main category: cs.LG

TL;DR: 该论文研究了一个输入驱动的单状态微分方程模型，该模型最初为实验证明的动态分子开关开发，具有类似大脑突触的切换特性。模型具有精确可解性、收敛性和衰减记忆等数学特性，能够稳定处理时变输入。


<details>
  <summary>Details</summary>
Motivation: 研究动态分子开关的计算特性，探索其作为神经形态计算单元的潜力，为大脑启发的稳定计算提供理论支持。

Method: 采用线性状态、非线性输入的微分方程模型，进行数学分析和理论证明，验证模型的收敛性、衰减记忆和精确可解性。

Result: 模型展现出生物学启发行为与稳定数学特性的共存，能够稳定处理时序数据，适用于深度前馈和循环神经网络架构。

Conclusion: 该研究为动态分子开关作为计算单元提供了理论依据，并可能启发更多精确可解模型来模拟物理设备，实现大脑启发的稳定计算。

Abstract: This paper studies an input-driven one-state differential equation model
initially developed for an experimentally demonstrated dynamic molecular switch
that switches like synapses in the brain do. The linear-in-the-state and
nonlinear-in-the-input model is exactly solvable, and it is shown that it also
possesses mathematical properties of convergence and fading memory that enable
stable processing of time-varying inputs by nonlinear dynamical systems. Thus,
the model exhibits the co-existence of biologically-inspired behavior and
desirable mathematical properties for stable learning on sequential data. The
results give theoretical support for the use of the dynamic molecular switches
as computational units in deep cascaded/layered feedforward and recurrent
architectures as well as other more general structures for neuromorphic
computing. They could also inspire more general exactly solvable models that
can be fitted to emulate arbitrary physical devices which can mimic
brain-inspired behaviour and perform stable computation on input signals.

</details>


### [9] [Classification errors distort findings in automated speech processing: examples and solutions from child-development research](https://arxiv.org/abs/2508.15637)
*Lucas Gautheron,Evan Kidd,Anton Malko,Marvin Lavechin,Alejandrina Cristia*

Main category: cs.LG

TL;DR: 本文提出贝叶斯方法来研究自动分类器错误对科学测量的影响，发现在语言习得研究中，分类错误会显著扭曲效应大小估计，并展示了贝叶斯校准方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴录音设备的普及，研究者越来越多地使用自动分类器分析音频数据来研究儿童语言发展。虽然已有研究关注分类器的准确性，但较少探讨分类错误对下游统计推断（如相关性和效应大小估计）的影响。

Method: 采用贝叶斯方法来研究算法错误对关键科学问题的影响，包括兄弟姐妹对儿童语言经验的影响以及儿童产出与输入之间的关联。在LENA和ACLEW系统的Voice Type Classifier两种分类器上进行测试。

Result: 发现分类错误会显著扭曲估计值，例如自动标注低估了兄弟姐妹对成人输入的负面效应达20-80%，可能导致结果低于统计显著性阈值。贝叶斯校准方法在恢复无偏效应大小估计方面有效但不完美。

Conclusion: 分类错误会严重影响科学测量的准确性，贝叶斯校准提供了一种有前景的解决方案，但并非万无一失。这一问题及解决方案适用于任何涉及事件检测和分类且错误率非零的分类器。

Abstract: With the advent of wearable recorders, scientists are increasingly turning to
automated methods of analysis of audio and video data in order to measure
children's experience, behavior, and outcomes, with a sizable literature
employing long-form audio-recordings to study language acquisition. While
numerous articles report on the accuracy and reliability of the most popular
automated classifiers, less has been written on the downstream effects of
classification errors on measurements and statistical inferences (e.g., the
estimate of correlations and effect sizes in regressions). This paper proposes
a Bayesian approach to study the effects of algorithmic errors on key
scientific questions, including the effect of siblings on children's language
experience and the association between children's production and their input.
In both the most commonly used \gls{lena}, and an open-source alternative (the
Voice Type Classifier from the ACLEW system), we find that classification
errors can significantly distort estimates. For instance, automated annotations
underestimated the negative effect of siblings on adult input by 20--80\%,
potentially placing it below statistical significance thresholds. We further
show that a Bayesian calibration approach for recovering unbiased estimates of
effect sizes can be effective and insightful, but does not provide a fool-proof
solution. Both the issue reported and our solution may apply to any classifier
involving event detection and classification with non-zero error rates.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 使用语言模型实时评估对话中的假社交关系线索，通过小型合成数据集验证能在前几轮对话中准确检测假社交关系并避免误报


<details>
  <summary>Details</summary>
Motivation: 人工智能代理形成的假社交关系对人类健康造成严重危害，但防止这种关系面临挑战，需要实时监测私密对话中的假社交线索

Method: 重新调整最先进语言模型构建简单的响应评估框架，在实时对话中评估假社交线索，使用30个合成对话的小型数据集进行测试

Result: 通过五阶段迭代测试，在宽松一致性规则下成功识别所有假社交对话且避免了误报，检测通常在对话前几轮就可完成

Conclusion: 评估代理提供了一种可行的解决方案，能够预防人与AI代理形成有害的假社交关系

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [TComQA: Extracting Temporal Commonsense from Text](https://arxiv.org/abs/2508.15274)
*Lekshmi R Nair,Arun Sankar,Koninika Pal*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型自动挖掘时间常识的管道，构建了TComQA数据集，并在时间问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自然语言中往往不会明确表述事件的时间上下文，即使先进的大语言模型也难以生成需要时间常识推理的文本，因此需要自动挖掘时间常识来构建更鲁棒的语言模型。

Method: 提出了一个时间常识提取管道，利用大语言模型从SAMSum和RealNews语料库中自动挖掘时间常识，构建TComQA数据集，并通过众包验证。

Result: TComQA数据集在提取时间常识方面达到超过80%的精确度，使用该数据集训练的模型在时间问答任务上优于基于现有数据集微调的大语言模型。

Conclusion: 该方法能够有效提取时间常识，构建高质量数据集，并提升模型在时间推理任务上的性能。

Abstract: Understanding events necessitates grasping their temporal context, which is
often not explicitly stated in natural language. For example, it is not a
trivial task for a machine to infer that a museum tour may last for a few
hours, but can not take months. Recent studies indicate that even advanced
large language models (LLMs) struggle in generating text that require reasoning
with temporal commonsense due to its infrequent explicit mention in text.
Therefore, automatically mining temporal commonsense for events enables the
creation of robust language models. In this work, we investigate the capacity
of LLMs to extract temporal commonsense from text and evaluate multiple
experimental setups to assess their effectiveness. Here, we propose a temporal
commonsense extraction pipeline that leverages LLMs to automatically mine
temporal commonsense and use it to construct TComQA, a dataset derived from
SAMSum and RealNews corpora. TComQA has been validated through crowdsourcing
and achieves over 80\% precision in extracting temporal commonsense. The model
trained with TComQA also outperforms an LLM fine-tuned on existing dataset of
temporal question answering task.

</details>


### [12] [The Enemy from Within: A Study of Political Delegitimization Discourse in Israeli Political Speech](https://arxiv.org/abs/2508.15524)
*Naama Rivlin-Angert,Guy Mor-Lan*

Main category: cs.CL

TL;DR: 首个大规模政治去合法化话语(PDD)计算研究，构建希伯来语语料库并开发两阶段分类模型，发现PDD在社交媒体和政治事件中显著增加


<details>
  <summary>Details</summary>
Motivation: 研究政治去合法化话语(PDD)的自动分析可行性，以理解民主话语中的规范性攻击现象

Method: 构建包含10,410句希伯来语语料库，手动标注1,812个PDD实例；开发两阶段分类管道，结合微调编码器模型和解码器LLM

Result: 最佳模型(DictaLM 2.0)在二元PDD检测中F1得分0.74，特征分类macro-F1得分0.67；发现PDD在30年间显著上升，社交媒体比议会辩论更普遍，右倾行为者使用更多

Conclusion: 自动化PDD分析对于理解民主话语具有可行性和重要价值，能够揭示政治话语中的规范性攻击模式

Abstract: We present the first large-scale computational study of political
delegitimization discourse (PDD), defined as symbolic attacks on the normative
validity of political entities. We curate and manually annotate a novel
Hebrew-language corpus of 10,410 sentences drawn from Knesset speeches
(1993-2023), Facebook posts (2018-2021), and leading news outlets, of which
1,812 instances (17.4\%) exhibit PDD and 642 carry additional annotations for
intensity, incivility, target type, and affective framing. We introduce a
two-stage classification pipeline combining finetuned encoder models and
decoder LLMs. Our best model (DictaLM 2.0) attains an F$_1$ of 0.74 for binary
PDD detection and a macro-F$_1$ of 0.67 for classification of delegitimization
characteristics. Applying this classifier to longitudinal and cross-platform
data, we see a marked rise in PDD over three decades, higher prevalence on
social media versus parliamentary debate, greater use by male than female
politicians, and stronger tendencies among right-leaning actors - with
pronounced spikes during election campaigns and major political events. Our
findings demonstrate the feasibility and value of automated PDD analysis for
understanding democratic discourse.

</details>


### [13] [Stemming -- The Evolution and Current State with a Focus on Bangla](https://arxiv.org/abs/2508.15711)
*Abhijit Paul,Mashiat Amin Farin,Sharif Md. Abdullah,Ahmedul Kabir,Zarif Masud,Shebuti Rayana*

Main category: cs.CL

TL;DR: 本文对孟加拉语词干提取方法进行了全面调查，指出该领域存在研究断层、实现稀缺和评估方法不足等问题，并提出了发展方向建议。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为全球第七大语言拥有3亿母语者，但在数字领域代表性不足，缺乏标注数据集资源。词干提取作为语言分析的关键预处理步骤，对于孟加拉语这种低资源、高屈折性语言尤为重要。

Method: 通过对现有孟加拉语词干提取方法的全面调查和分析，批判性地评估现有研究方法、实现可用性和评估指标的有效性。

Result: 研究发现孟加拉语词干提取领域存在显著的研究断层，缺乏可复现的实现方案，评估方法不够相关和有效。

Conclusion: 建议开发更强大的孟加拉语词干提取器，改进评估指标，并继续深入研究以提升孟加拉语的语言分析和处理能力。

Abstract: Bangla, the seventh most widely spoken language worldwide with 300 million
native speakers, faces digital under-representation due to limited resources
and lack of annotated datasets. Stemming, a critical preprocessing step in
language analysis, is essential for low-resource, highly-inflectional languages
like Bangla, because it can reduce the complexity of algorithms and models by
significantly reducing the number of words the algorithm needs to consider.
This paper conducts a comprehensive survey of stemming approaches, emphasizing
the importance of handling morphological variants effectively. While exploring
the landscape of Bangla stemming, it becomes evident that there is a
significant gap in the existing literature. The paper highlights the
discontinuity from previous research and the scarcity of accessible
implementations for replication. Furthermore, it critiques the evaluation
methodologies, stressing the need for more relevant metrics. In the context of
Bangla's rich morphology and diverse dialects, the paper acknowledges the
challenges it poses. To address these challenges, the paper suggests directions
for Bangla stemmer development. It concludes by advocating for robust Bangla
stemmers and continued research in the field to enhance language analysis and
processing.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot](https://arxiv.org/abs/2508.14994)
*Murilo Vinicius da Silva,Matheus Hipolito Carvalho,Juliano Negri,Thiago Segreto,Gustavo J. G. Lahr,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出基于视觉姿态估计的直观四足机器人遥操作方法，通过外部摄像头检测操作员手腕位置，实时映射到机械臂控制，结合轨迹规划器确保安全操作


<details>
  <summary>Details</summary>
Motivation: 在危险和远程环境中，四足机器人机械臂系统需要更安全和高效的操作。传统遥操作方法（如操纵杆）不直观且需要专业知识，认知负荷高，缺乏集成的障碍物检测功能，在受限或动态工作空间中碰撞风险高

Method: 使用基于机器学习模型的外部摄像头视觉姿态估计管道检测操作员手腕位置，将这些手腕运动实时映射为机械臂命令，并采用轨迹规划器检测和防止与障碍物及机械臂自身的碰撞

Result: 在真实机器人上验证了系统，展示了实时控制的稳健性能

Conclusion: 该方法为工业应用提供了成本效益高的解决方案，在安全性、精确性和易用性至关重要的高风险环境中确保可靠和直观的机器人控制

Abstract: In hazardous and remote environments, robotic systems perform critical tasks
demanding improved safety and efficiency. Among these, quadruped robots with
manipulator arms offer mobility and versatility for complex operations.
However, teleoperating quadruped robots is challenging due to the lack of
integrated obstacle detection and intuitive control methods for the robotic
arm, increasing collision risks in confined or dynamically changing workspaces.
Teleoperation via joysticks or pads can be non-intuitive and demands a high
level of expertise due to its complexity, culminating in a high cognitive load
on the operator. To address this challenge, a teleoperation approach that
directly maps human arm movements to the robotic manipulator offers a simpler
and more accessible solution. This work proposes an intuitive remote control by
leveraging a vision-based pose estimation pipeline that utilizes an external
camera with a machine learning-based model to detect the operator's wrist
position. The system maps these wrist movements into robotic arm commands to
control the robot's arm in real-time. A trajectory planner ensures safe
teleoperation by detecting and preventing collisions with both obstacles and
the robotic arm itself. The system was validated on the real robot,
demonstrating robust performance in real-time control. This teleoperation
approach provides a cost-effective solution for industrial applications where
safety, precision, and ease of use are paramount, ensuring reliable and
intuitive robotic control in high-risk environments.

</details>


### [15] [Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation](https://arxiv.org/abs/2508.15663)
*Nikita Kachaev,Andrei Spiridonov,Andrey Gorodetsky,Kirill Muravyev,Nikita Oskolkov,Aditya Narendra,Vlad Shakhuro,Dmitry Makarov,Aleksandr I. Panov,Polina Fedotova,Alexey K. Kovalev*

Main category: cs.RO

TL;DR: Kitchen-R是一个新的机器人基准测试，统一评估任务规划和低级控制在模拟厨房环境中的表现，填补了高级语言指令跟随和低级控制之间的评估鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在显著差距：高级语言指令跟随基准假设完美低级执行，而低级控制基准依赖简单单步命令，缺乏对任务规划和物理执行集成系统的综合评估。

Method: 使用Isaac Sim模拟器构建数字孪生厨房环境，包含500多个复杂语言指令，支持移动机械臂机器人。提供基于视觉语言模型的任务规划策略和基于扩散策略的低级控制策略基线方法。

Result: Kitchen-R基准提供了三种评估模式的灵活框架：独立评估规划模块、独立评估控制策略，以及关键的系统集成评估。

Conclusion: Kitchen-R填补了具身AI研究中的关键空白，实现了对语言引导机器人代理更全面和现实的基准测试。

Abstract: Benchmarks are crucial for evaluating progress in robotics and embodied AI.
However, a significant gap exists between benchmarks designed for high-level
language instruction following, which often assume perfect low-level execution,
and those for low-level robot control, which rely on simple, one-step commands.
This disconnect prevents a comprehensive evaluation of integrated systems where
both task planning and physical execution are critical. To address this, we
propose Kitchen-R, a novel benchmark that unifies the evaluation of task
planning and low-level control within a simulated kitchen environment. Built as
a digital twin using the Isaac Sim simulator and featuring more than 500
complex language instructions, Kitchen-R supports a mobile manipulator robot.
We provide baseline methods for our benchmark, including a task-planning
strategy based on a vision-language model and a low-level control policy based
on diffusion policy. We also provide a trajectory collection system. Our
benchmark offers a flexible framework for three evaluation modes: independent
assessment of the planning module, independent assessment of the control
policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R
bridges a key gap in embodied AI research, enabling more holistic and realistic
benchmarking of language-guided robotic agents.

</details>
