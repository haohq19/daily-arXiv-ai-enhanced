<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 20]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CL](#cs.CL) [Total: 6]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Adapter Shield: A Unified Framework with Built-in Authentication for Preventing Unauthorized Zero-Shot Image-to-Image Generation](https://arxiv.org/abs/2512.00075)
*Jun Jia,Hongyi Miao,Yingjie Zhou,Wangqiu Zhou,Jianbo Zhang,Linhan Cao,Dandan Zhu,Hua Yang,Xiongkuo Min,Wei Sun,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出Adapter Shield，首个针对零样本图像生成场景的通用认证集成防御方案，通过可逆加密系统和多目标对抗扰动保护个人图像免遭未经授权的身份克隆和风格模仿。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型的快速发展，零样本图像生成技术能够仅用一张肖像或艺术作品就实现高保真度的身份复制或风格模仿，这虽然增强了创作可能性，但也带来了严重的知识产权侵权风险，包括未经授权的身份克隆和风格模仿。

Method: 首先研究当前零样本方法如何通过图像编码器提取嵌入向量，并通过交叉注意力层输入扩散模型UNet。基于此机制构建可逆加密系统，将原始嵌入映射为不同密钥对应的加密表示。授权用户可通过解密模块和正确密钥恢复原始嵌入。为保护目的，设计多目标对抗扰动方法，主动将原始嵌入向指定加密模式偏移，使受保护图像嵌入防御层，确保未经授权用户只能生成扭曲或加密的输出。

Result: 广泛评估表明，该方法在阻止未经授权的零样本图像合成方面优于现有最先进的防御方法，同时支持灵活且安全的访问控制供已验证用户使用。

Conclusion: Adapter Shield为保护个人图像免遭零样本生成场景的滥用提供了有效的解决方案，实现了防御与授权使用的平衡。

Abstract: With the rapid progress in diffusion models, image synthesis has advanced to the stage of zero-shot image-to-image generation, where high-fidelity replication of facial identities or artistic styles can be achieved using just one portrait or artwork, without modifying any model weights. Although these techniques significantly enhance creative possibilities, they also pose substantial risks related to intellectual property violations, including unauthorized identity cloning and stylistic imitation. To counter such threats, this work presents Adapter Shield, the first universal and authentication-integrated solution aimed at defending personal images from misuse in zero-shot generation scenarios. We first investigate how current zero-shot methods employ image encoders to extract embeddings from input images, which are subsequently fed into the UNet of diffusion models through cross-attention layers. Inspired by this mechanism, we construct a reversible encryption system that maps original embeddings into distinct encrypted representations according to different secret keys. The authorized users can restore the authentic embeddings via a decryption module and the correct key, enabling normal usage for authorized generation tasks. For protection purposes, we design a multi-target adversarial perturbation method that actively shifts the original embeddings toward designated encrypted patterns. Consequently, protected images are embedded with a defensive layer that ensures unauthorized users can only produce distorted or encrypted outputs. Extensive evaluations demonstrate that our method surpasses existing state-of-the-art defenses in blocking unauthorized zero-shot image synthesis, while supporting flexible and secure access control for verified users.

</details>


### [2] [Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels](https://arxiv.org/abs/2512.00080)
*André Dehne,Juri Zach,Peer Stelldinger*

Main category: cs.CV

TL;DR: MARWIN机器人采用深度视觉立体里程计(DVSO)替代现有导航系统，以提升在加速器隧道中的自主导航能力，解决现有系统在未知几何和障碍物环境中的灵活性不足问题。


<details>
  <summary>Details</summary>
Motivation: 欧洲XFEL的MARWIN机器人当前导航系统结合激光雷达边缘检测、轮式/激光雷达里程计和QR码参考，在预定义区域表现稳健，但缺乏对未知几何结构和障碍物的灵活性，需要更自主的导航方案。

Method: 提出采用深度视觉立体里程计(DVSO)，利用立体视差、光流和自监督学习联合估计深度和自我运动，无需标记数据，并可后续与绝对参考或其他传感器融合以确保全局一致性。

Result: 概念性评估显示DVSO在加速器隧道环境中具有潜力，预期优势包括通过立体视觉减少尺度漂移、低成本传感和可扩展数据收集，但仍面临低纹理表面、光照变化、计算负载和辐射环境下鲁棒性等挑战。

Conclusion: 本文为MARWIN机器人在受限、安全关键基础设施中实现更自主导航定义了研究议程，DVSO作为有前景的替代方案，但需要解决实际部署中的技术挑战。

Abstract: The MARWIN robot operates at the European XFEL to perform autonomous radiation monitoring in long, monotonous accelerator tunnels where conventional localization approaches struggle. Its current navigation concept combines lidar-based edge detection, wheel/lidar odometry with periodic QR-code referencing, and fuzzy control of wall distance, rotation, and longitudinal position. While robust in predefined sections, this design lacks flexibility for unknown geometries and obstacles. This paper explores deep visual stereo odometry (DVSO) with 3D-geometric constraints as a focused alternative. DVSO is purely vision-based, leveraging stereo disparity, optical flow, and self-supervised learning to jointly estimate depth and ego-motion without labeled data. For global consistency, DVSO can subsequently be fused with absolute references (e.g., landmarks) or other sensors. We provide a conceptual evaluation for accelerator tunnel environments, using the European XFEL as a case study. Expected benefits include reduced scale drift via stereo, low-cost sensing, and scalable data collection, while challenges remain in low-texture surfaces, lighting variability, computational load, and robustness under radiation. The paper defines a research agenda toward enabling MARWIN to navigate more autonomously in constrained, safety-critical infrastructures.

</details>


### [3] [Analysis of Incursive Breast Cancer in Mammograms Using YOLO, Explainability, and Domain Adaptation](https://arxiv.org/abs/2512.00129)
*Jayan Adhikari,Prativa Joshi,Susish Baral*

Main category: cs.CV

TL;DR: 该研究提出了一种结合ResNet50 OOD过滤与YOLO架构的乳腺癌检测系统，通过严格筛选非乳腺图像确保检测可靠性，在OOD测试集上达到100%准确率，检测性能mAP@0.5为0.947。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在乳腺癌检测中面临OOD输入（如其他影像模态或设备差异）的可靠性问题，导致误诊风险。需要解决模型在临床环境数据异质性下的可靠性挑战。

Method: 采用综合方法：1）基于ResNet50的OOD过滤，通过余弦相似度建立域内图库，严格拒绝非乳腺图像；2）使用YOLO架构（YOLOv8/v11/v12）进行乳腺癌检测；3）结合Grad-CAM增强可解释性。经过12种CNN架构搜索选择ResNet50作为最佳骨干网络。

Result: OOD检测组件达到99.77%总体准确率，在OOD测试集上实现100%准确率。联合框架检测性能mAP@0.5为0.947。实验验证OOD过滤显著提升系统可靠性，防止OOD输入误报，同时保持乳腺数据高检测精度。

Conclusion: 该研究为在数据异质性的临床环境中部署可靠的AI乳腺癌检测系统提供了基础，通过OOD过滤确保系统仅处理相关影像，结合高检测性能和可解释性，提升临床应用的可靠性。

Abstract: Deep learning models for breast cancer detection from mammographic images have significant reliability problems when presented with Out-of-Distribution (OOD) inputs such as other imaging modalities (CT, MRI, X-ray) or equipment variations, leading to unreliable detection and misdiagnosis. The current research mitigates the fundamental OOD issue through a comprehensive approach integrating ResNet50-based OOD filtering with YOLO architectures (YOLOv8, YOLOv11, YOLOv12) for accurate detection of breast cancer. Our strategy establishes an in-domain gallery via cosine similarity to rigidly reject non-mammographic inputs prior to processing, ensuring that only domain-associated images supply the detection pipeline. The OOD detection component achieves 99.77\% general accuracy with immaculate 100\% accuracy on OOD test sets, effectively eliminating irrelevant imaging modalities. ResNet50 was selected as the optimum backbone after 12 CNN architecture searches. The joint framework unites OOD robustness with high detection performance (mAP@0.5: 0.947) and enhanced interpretability through Grad-CAM visualizations. Experimental validation establishes that OOD filtering significantly improves system reliability by preventing false alarms on out-of-distribution inputs while maintaining higher detection accuracy on mammographic data. The present study offers a fundamental foundation for the deployment of reliable AI-based breast cancer detection systems in diverse clinical environments with inherent data heterogeneity.

</details>


### [4] [UniDiff: Parameter-Efficient Adaptation of Diffusion Models for Land Cover Classification with Multi-Modal Remotely Sensed Imagery and Sparse Annotations](https://arxiv.org/abs/2512.00261)
*Yuzhen Hu,Saurabh Prasad*

Main category: cs.CV

TL;DR: UniDiff框架通过参数高效的方式将ImageNet预训练的扩散模型适配到多模态遥感数据，解决了稀疏标注下的数据融合问题


<details>
  <summary>Details</summary>
Motivation: 多模态遥感数据（如高光谱成像和合成孔径雷达）面临稀疏标注的挑战，现有监督方法如MSFMamba受限于标注数据可用性，而ImageNet预训练模型难以直接适配到异构模态

Method: 提出UniDiff框架：1) 使用FiLM-based timestep-modality conditioning进行模态条件化；2) 仅适配约5%参数的参数高效适应；3) 采用pseudo-RGB anchoring保持预训练表示并防止灾难性遗忘

Result: 在两个已建立的多模态基准数据集上，无监督适应预训练扩散模型有效缓解了标注约束，实现了多模态遥感数据的有效融合

Conclusion: UniDiff通过参数高效的方式将单个ImageNet预训练扩散模型适配到多种遥感模态，仅使用目标域数据，在稀疏标注条件下实现了有效的多模态特征提取和融合

Abstract: Sparse annotations fundamentally constrain multimodal remote sensing: even recent state-of-the-art supervised methods such as MSFMamba are limited by the availability of labeled data, restricting their practical deployment despite architectural advances. ImageNet-pretrained models provide rich visual representations, but adapting them to heterogeneous modalities such as hyperspectral imaging (HSI) and synthetic aperture radar (SAR) without large labeled datasets remains challenging. We propose UniDiff, a parameter-efficient framework that adapts a single ImageNet-pretrained diffusion model to multiple sensing modalities using only target-domain data. UniDiff combines FiLM-based timestep-modality conditioning, parameter-efficient adaptation of approximately 5% of parameters, and pseudo-RGB anchoring to preserve pre-trained representations and prevent catastrophic forgetting. This design enables effective feature extraction from remote sensing data under sparse annotations. Our results with two established multi-modal benchmarking datasets demonstrate that unsupervised adaptation of a pre-trained diffusion model effectively mitigates annotation constraints and achieves effective fusion of multi-modal remotely sensed data.

</details>


### [5] [Odometry Without Correspondence from Inertially Constrained Ruled Surfaces](https://arxiv.org/abs/2512.00327)
*Chenqi Zhu,Levi Burner,Yiannis Aloimonos*

Main category: cs.CV

TL;DR: 提出一种基于直线特征和惯性测量单元（IMU）的视觉里程计新方法，通过分析图像空间中的直纹曲面来估计运动，避免传统点对点匹配的计算成本和不稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉里程计依赖特征点提取和光流计算，存在计算成本高、精度不稳定等问题。虽然已有研究尝试使用直线特征或融合其他传感器，但仍严重依赖特征对应关系。本文旨在绕过对应问题，利用直线在图像空间形成的直纹曲面来获取运动信息。

Method: 提出一种新颖算法，通过分析相机运动时直线在图像空间形成的直纹曲面来重建3D场景和估计视觉里程计。该方法仅需点与线的关联进行微分计算更新，并利用IMU的惯性测量约束解空间维度，大幅降低计算复杂度。

Result: 该方法通过直纹曲面分析和IMU约束，能够有效估计视觉里程计，避免了传统点对点匹配的计算负担和不稳定性。特别适合事件相机等擅长边缘检测的传感器。

Conclusion: 基于直纹曲面分析和IMU约束的视觉里程计方法提供了一种绕过传统特征对应问题的新途径，计算效率更高，特别适用于事件相机等边缘检测优势明显的传感器系统。

Abstract: Visual odometry techniques typically rely on feature extraction from a sequence of images and subsequent computation of optical flow. This point-to-point correspondence between two consecutive frames can be costly to compute and suffers from varying accuracy, which affects the odometry estimate's quality. Attempts have been made to bypass the difficulties originating from the correspondence problem by adopting line features and fusing other sensors (event camera, IMU) to improve performance, many of which still heavily rely on correspondence. If the camera observes a straight line as it moves, the image of the line sweeps a smooth surface in image-space time. It is a ruled surface and analyzing its shape gives information about odometry. Further, its estimation requires only differentially computed updates from point-to-line associations. Inspired by event cameras' propensity for edge detection, this research presents a novel algorithm to reconstruct 3D scenes and visual odometry from these ruled surfaces. By constraining the surfaces with the inertia measurements from an onboard IMU sensor, the dimensionality of the solution space is greatly reduced.

</details>


### [6] [What about gravity in video generation? Post-Training Newton's Laws with Verifiable Rewards](https://arxiv.org/abs/2512.00425)
*Minh-Quan Le,Yuanzhi Zhu,Vicky Kalogeiton,Dimitris Samaras*

Main category: cs.CV

TL;DR: NewtonRewards：首个基于可验证奖励的物理基础后训练框架，通过提取光学流和外观特征作为速度和质量代理，强制执行牛顿运动学和质量守恒约束，显著提升视频生成的物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前视频扩散模型能生成视觉上吸引人的片段，但经常违反基本物理定律（物体漂浮、加速度漂移、碰撞不一致），揭示了视觉真实感与物理真实感之间的持续差距。

Method: 提出NewtonRewards框架：1) 使用冻结的实用模型从生成视频中提取可测量代理（光学流作为速度代理，高级外观特征作为质量代理）；2) 通过两个互补奖励强制执行牛顿结构：牛顿运动学约束（强制恒定加速度动力学）和质量守恒奖励（防止退化解）。

Result: 在NewtonBench-60K基准测试中，NewtonRewards在所有牛顿运动基本类型（自由落体、水平/抛物线投掷、斜坡滑下/上）的视觉和物理指标上，相比现有后训练方法持续提升物理合理性、运动平滑性和时间一致性，且在高度、速度和摩擦力的分布外偏移下保持强性能。

Conclusion: 物理基础的可验证奖励为物理感知视频生成提供了可扩展的路径，能够有效弥合视觉真实感与物理真实感之间的差距。

Abstract: Recent video diffusion models can synthesize visually compelling clips, yet often violate basic physical laws-objects float, accelerations drift, and collisions behave inconsistently-revealing a persistent gap between visual realism and physical realism. We propose $\texttt{NewtonRewards}$, the first physics-grounded post-training framework for video generation based on $\textit{verifiable rewards}$. Instead of relying on human or VLM feedback, $\texttt{NewtonRewards}$ extracts $\textit{measurable proxies}$ from generated videos using frozen utility models: optical flow serves as a proxy for velocity, while high-level appearance features serve as a proxy for mass. These proxies enable explicit enforcement of Newtonian structure through two complementary rewards: a Newtonian kinematic constraint enforcing constant-acceleration dynamics, and a mass conservation reward preventing trivial, degenerate solutions. We evaluate $\texttt{NewtonRewards}$ on five Newtonian Motion Primitives (free fall, horizontal/parabolic throw, and ramp sliding down/up) using our newly constructed large-scale benchmark, $\texttt{NewtonBench-60K}$. Across all primitives in visual and physics metrics, $\texttt{NewtonRewards}$ consistently improves physical plausibility, motion smoothness, and temporal coherence over prior post-training methods. It further maintains strong performance under out-of-distribution shifts in height, speed, and friction. Our results show that physics-grounded verifiable rewards offer a scalable path toward physics-aware video generation.

</details>


### [7] [Structured Context Learning for Generic Event Boundary Detection](https://arxiv.org/abs/2512.00475)
*Xin Gu,Congcong Li,Xinyao Wang,Dexiang Hong,Libo Zhang,Tiejian Luo,Longyin Wen,Heng Fan*

Main category: cs.CV

TL;DR: 提出结构化上下文学习(SCL)方法，通过结构化序列分割(SPoS)为GEBD任务提供结构化上下文，实现更好的速度-准确率平衡


<details>
  <summary>Details</summary>
Motivation: 通用事件边界检测(GEBD)旨在识别人类感知的事件边界时刻。现有方法在速度-准确率平衡方面存在限制，需要更灵活且高效的方法来处理视频序列的时序信息。

Method: 1. 提出结构化序列分割(SPoS)将输入帧序列分割并提供结构化上下文；2. 计算组间相似度捕捉帧间差异；3. 使用轻量级全卷积网络基于分组相似度图确定事件边界；4. 采用高斯核预处理地面真值边界以解决标注模糊问题。

Result: 在Kinetics-GEBD、TAPOS和镜头转换检测数据集上进行了广泛评估，证明了该方法优于现有最先进方法。SPoS的计算复杂度与视频长度呈线性关系。

Conclusion: 提出的结构化上下文学习方法通过结构化序列分割为GEBD任务提供了有效的结构化上下文，实现了端到端训练和灵活性，在多个数据集上取得了优越性能。

Abstract: Generic Event Boundary Detection (GEBD) aims to identify moments in videos that humans perceive as event boundaries. This paper proposes a novel method for addressing this task, called Structured Context Learning, which introduces the Structured Partition of Sequence (SPoS) to provide a structured context for learning temporal information. Our approach is end-to-end trainable and flexible, not restricted to specific temporal models like GRU, LSTM, and Transformers. This flexibility enables our method to achieve a better speed-accuracy trade-off. Specifically, we apply SPoS to partition the input frame sequence and provide a structured context for the subsequent temporal model. Notably, SPoS's overall computational complexity is linear with respect to the video length. We next calculate group similarities to capture differences between frames, and a lightweight fully convolutional network is utilized to determine the event boundaries based on the grouped similarity maps. To remedy the ambiguities of boundary annotations, we adapt the Gaussian kernel to preprocess the ground-truth event boundaries. Our proposed method has been extensively evaluated on the challenging Kinetics-GEBD, TAPOS, and shot transition detection datasets, demonstrating its superiority over existing state-of-the-art methods.

</details>


### [8] [Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion](https://arxiv.org/abs/2512.02017)
*Shaowei Liu,David Yifan Yao,Saurabh Gupta,Shenlong Wang*

Main category: cs.CV

TL;DR: VisualSync是一个基于多视角动态的优化框架，能够以毫秒级精度对齐未标定、未同步的视频，通过利用3D重建、特征匹配和密集跟踪来最小化极线误差。


<details>
  <summary>Details</summary>
Motivation: 随着消费级相机的普及，人们可以轻松记录各种重要时刻，但跨相机视频流的同步仍然具有挑战性。现有方法通常需要受控环境、特定目标、手动校正或昂贵硬件。

Method: VisualSync利用现成的3D重建、特征匹配和密集跟踪技术提取轨迹片段、相对姿态和跨视角对应关系，然后通过联合最小化极线误差来估计每个相机的时间偏移。

Result: 在四个多样化、具有挑战性的数据集上的实验表明，VisualSync优于基线方法，实现了中位数同步误差低于50毫秒的精度。

Conclusion: VisualSync提出了一种有效的视频同步框架，能够在非受控环境下实现高精度的时间对齐，为多视角视频处理提供了实用解决方案。

Abstract: Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.

</details>


### [9] [EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes](https://arxiv.org/abs/2512.00771)
*Xiaoshan Wu,Yifei Yu,Xiaoyang Lyu,Yihua Huang,Bo Wang,Baoheng Zhang,Zhongrui Wang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: EAG3R：结合异步事件流增强点图重建的鲁棒3D几何估计框架，在动态低光场景中显著优于RGB-only方法


<details>
  <summary>Details</summary>
Motivation: 现有RGB-only方法在真实世界动态物体和极端光照条件下表现不佳，传统相机固有局限性限制了其鲁棒性

Method: 基于MonST3R骨干网络，引入Retinex启发的图像增强模块、轻量级事件适配器与SNR感知融合机制，以及事件驱动的光度一致性损失

Result: 在单目深度估计、相机姿态跟踪和动态重建任务中显著优于最先进的RGB-only基线方法

Conclusion: EAG3R通过融合RGB和事件数据，无需夜间数据重新训练即可在挑战性动态低光场景中实现鲁棒的几何估计

Abstract: Robust 3D geometry estimation from videos is critical for applications such as autonomous navigation, SLAM, and 3D scene reconstruction. Recent methods like DUSt3R demonstrate that regressing dense pointmaps from image pairs enables accurate and efficient pose-free reconstruction. However, existing RGB-only approaches struggle under real-world conditions involving dynamic objects and extreme illumination, due to the inherent limitations of conventional cameras. In this paper, we propose EAG3R, a novel geometry estimation framework that augments pointmap-based reconstruction with asynchronous event streams. Built upon the MonST3R backbone, EAG3R introduces two key innovations: (1) a retinex-inspired image enhancement module and a lightweight event adapter with SNR-aware fusion mechanism that adaptively combines RGB and event features based on local reliability; and (2) a novel event-based photometric consistency loss that reinforces spatiotemporal coherence during global optimization. Our method enables robust geometry estimation in challenging dynamic low-light scenes without requiring retraining on night-time data. Extensive experiments demonstrate that EAG3R significantly outperforms state-of-the-art RGB-only baselines across monocular depth estimation, camera pose tracking, and dynamic reconstruction tasks.

</details>


### [10] [Data-Centric Visual Development for Self-Driving Labs](https://arxiv.org/abs/2512.02018)
*Anbang Liu,Guanzhong Hu,Jiayi Wang,Ping Guo,Han Liu*

Main category: cs.CV

TL;DR: 提出混合真实与虚拟数据生成管道，解决自驱实验室中气泡检测训练数据稀缺问题，特别是负样本不足，实现99.6%准确率


<details>
  <summary>Details</summary>
Motivation: 自驱实验室需要高精度模型，但训练数据特别是负样本难以获取。移液是SDL中最关键且精度敏感的操作，需要解决数据稀缺问题以实现稳健的气泡检测

Method: 构建混合管道融合真实和虚拟数据生成。真实轨道采用人机协同方案，结合自动采集和选择性人工验证；虚拟轨道使用参考条件提示引导的图像生成来增强真实数据，并进行筛选验证

Result: 在保留的真实测试集上，仅用自动采集的真实图像训练的模型达到99.6%准确率；混合真实和生成数据训练维持99.4%准确率，同时减少收集和审查工作量

Conclusion: 该方法为SDL工作流程提供可扩展且经济高效的视觉反馈数据供应策略，为罕见事件检测和更广泛的视觉任务中的数据稀缺问题提供实用解决方案

Abstract: Self-driving laboratories offer a promising path toward reducing the labor-intensive, time-consuming, and often irreproducible workflows in the biological sciences. Yet their stringent precision requirements demand highly robust models whose training relies on large amounts of annotated data. However, this kind of data is difficult to obtain in routine practice, especially negative samples. In this work, we focus on pipetting, the most critical and precision sensitive action in SDLs. To overcome the scarcity of training data, we build a hybrid pipeline that fuses real and virtual data generation. The real track adopts a human-in-the-loop scheme that couples automated acquisition with selective human verification to maximize accuracy with minimal effort. The virtual track augments the real data using reference-conditioned, prompt-guided image generation, which is further screened and validated for reliability. Together, these two tracks yield a class-balanced dataset that enables robust bubble detection training. On a held-out real test set, a model trained entirely on automatically acquired real images reaches 99.6% accuracy, and mixing real and generated data during training sustains 99.4% accuracy while reducing collection and review load. Our approach offers a scalable and cost-effective strategy for supplying visual feedback data to SDL workflows and provides a practical solution to data scarcity in rare event detection and broader vision tasks.

</details>


### [11] [ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species Classification from 2D Micro-CT Slices](https://arxiv.org/abs/2512.00912)
*Abdelghafour Halimi,Ali Alibrahim,Didier Barradas-Bautista,Ronell Sicat,Abdulkader M. Afifi*

Main category: cs.CV

TL;DR: 本研究提出一个深度学习流程，利用3D扫描衍生的2D微CT切片自动分类12种有孔虫物种，最终集成模型测试准确率达95.64%，并开发了交互式仪表板用于实时分类。


<details>
  <summary>Details</summary>
Motivation: 传统有孔虫分类依赖专家人工识别，效率低且主观性强。本研究旨在开发自动化深度学习系统，提高分类准确性和效率，为微体古生物学研究提供AI辅助工具。

Method: 1. 构建包含97个微CT扫描标本（27种物种）的数据集，选取12种代表性物种；2. 采用标本级数据分割防止数据泄露；3. 评估7种先进的2D CNN架构；4. 结合ConvNeXt-Large和EfficientNetV2-Small构建集成模型；5. 开发交互式仪表板支持实时分类和3D切片匹配。

Result: 集成模型在测试集上达到95.64%的准确率，top-3准确率99.6%，所有物种的ROC曲线下面积(AUC)为0.998。创建了包含109,617个高质量2D切片的数据集（44,103训练，14,046验证，51,468测试）。

Conclusion: 本研究为AI辅助微体古生物学识别设立了新基准，提供了完全可复现的有孔虫分类框架，弥合了深度学习与应用地球科学之间的差距，开发的交互式仪表板便于实际部署。

Abstract: This study presents a comprehensive deep learning pipeline for the automated classification of 12 foraminifera species using 2D micro-CT slices derived from 3D scans. We curated a scientifically rigorous dataset comprising 97 micro-CT scanned specimens across 27 species, selecting 12 species with sufficient representation for robust machine learning. To ensure methodological integrity and prevent data leakage, we employed specimen-level data splitting, resulting in 109,617 high-quality 2D slices (44,103 for training, 14,046 for validation, and 51,468 for testing). We evaluated seven state-of-the-art 2D convolutional neural network (CNN) architectures using transfer learning. Our final ensemble model, combining ConvNeXt-Large and EfficientNetV2-Small, achieved a test accuracy of 95.64%, with a top-3 accuracy of 99.6% and an area under the ROC curve (AUC) of 0.998 across all species. To facilitate practical deployment, we developed an interactive advanced dashboard that supports real-time slice classification and 3D slice matching using advanced similarity metrics, including SSIM, NCC, and the Dice coefficient. This work establishes new benchmarks for AI-assisted micropaleontological identification and provides a fully reproducible framework for foraminifera classification research, bridging the gap between deep learning and applied geosciences.

</details>


### [12] [Provenance-Driven Reliable Semantic Medical Image Vector Reconstruction via Lightweight Blockchain-Verified Latent Fingerprints](https://arxiv.org/abs/2512.00999)
*Mohsin Rasheed,Abdullah Al-Mamun*

Main category: cs.CV

TL;DR: 提出结合语义感知医学图像重建与区块链溯源框架，提升AI辅助诊断可靠性和可追溯性


<details>
  <summary>Details</summary>
Motivation: 现实医疗影像常受噪声、损坏和篡改影响，传统重建方法注重像素恢复但可能损害解剖结构保真度，影响临床诊断可靠性

Method: 提出语义感知医学图像重建框架，结合高层潜在嵌入与混合U-Net架构保持临床相关结构；集成轻量级区块链溯源层，采用无标度图设计记录重建过程

Result: 在多个数据集和损坏类型上评估，相比现有方法在结构一致性、重建精度和溯源完整性方面均有提升

Conclusion: 通过语义引导重建与安全可追溯性结合，推进医疗影像可靠AI发展，增强诊断信心和医疗环境合规性

Abstract: Medical imaging is essential for clinical diagnosis, yet real-world data frequently suffers from corruption, noise, and potential tampering, challenging the reliability of AI-assisted interpretation. Conventional reconstruction techniques prioritize pixel-level recovery and may produce visually plausible outputs while compromising anatomical fidelity, an issue that can directly impact clinical outcomes. We propose a semantic-aware medical image reconstruction framework that integrates high-level latent embeddings with a hybrid U-Net architecture to preserve clinically relevant structures during restoration. To ensure trust and accountability, we incorporate a lightweight blockchain-based provenance layer using scale-free graph design, enabling verifiable recording of each reconstruction event without imposing significant overhead. Extensive evaluation across multiple datasets and corruption types demonstrates improved structural consistency, restoration accuracy, and provenance integrity compared with existing approaches. By uniting semantic-guided reconstruction with secure traceability, our solution advances dependable AI for medical imaging, enhancing both diagnostic confidence and regulatory compliance in healthcare environments.

</details>


### [13] [Structural Prognostic Event Modeling for Multimodal Cancer Survival Analysis](https://arxiv.org/abs/2512.01116)
*Yilan Zhang,Li Nanbo,Changchun Yang,Jürgen Schmidhuber,Xin Gao*

Main category: cs.CV

TL;DR: SlotSPE：基于槽位的结构预后事件建模框架，通过压缩多模态输入为互斥槽位表示，有效捕捉稀疏但关键的预后事件，提升癌症生存预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以高效建模组织学图像和基因谱之间的复杂模态内和模态间交互，且难以捕捉决定患者预后的稀疏、患者特异性、未标注的结构性预后事件。

Method: 提出SlotSPE框架，受因子编码原理启发，使用槽注意力将每个患者的多模态输入压缩为紧凑、模态特异性、互斥的槽位集合，将这些槽位表示作为预后事件的编码。

Result: 在10个癌症基准测试中，SlotSPE在8个队列中优于现有方法，整体提升2.9%，在基因组数据缺失情况下保持鲁棒性，并通过结构化事件分解显著提升可解释性。

Conclusion: SlotSPE通过槽位表示有效建模复杂多模态交互，捕捉关键预后事件，为癌症生存预测提供高效、鲁棒且可解释的解决方案。

Abstract: The integration of histology images and gene profiles has shown great promise for improving survival prediction in cancer. However, current approaches often struggle to model intra- and inter-modal interactions efficiently and effectively due to the high dimensionality and complexity of the inputs. A major challenge is capturing critical prognostic events that, though few, underlie the complexity of the observed inputs and largely determine patient outcomes. These events, manifested as high-level structural signals such as spatial histologic patterns or pathway co-activations, are typically sparse, patient-specific, and unannotated, making them inherently difficult to uncover. To address this, we propose SlotSPE, a slot-based framework for structural prognostic event modeling. Specifically, inspired by the principle of factorial coding, we compress each patient's multimodal inputs into compact, modality-specific sets of mutually distinctive slots using slot attention. By leveraging these slot representations as encodings for prognostic events, our framework enables both efficient and effective modeling of complex intra- and inter-modal interactions, while also facilitating seamless incorporation of biological priors that enhance prognostic relevance. Extensive experiments on ten cancer benchmarks show that SlotSPE outperforms existing methods in 8 out of 10 cohorts, achieving an overall improvement of 2.9%. It remains robust under missing genomic data and delivers markedly improved interpretability through structured event decomposition.

</details>


### [14] [Optimizing Stroke Risk Prediction: A Machine Learning Pipeline Combining ROS-Balanced Ensembles and XAI](https://arxiv.org/abs/2512.01333)
*A S M Ahsanul Sarkar Akib,Raduana Khawla,Abdul Hasib*

Main category: cs.CV

TL;DR: 该研究开发了一个结合集成建模和可解释AI的机器学习框架，用于卒中风险预测，在卒中预测数据集上达到99.09%的准确率。


<details>
  <summary>Details</summary>
Motivation: 卒中是全球主要的死亡和永久性损伤原因，早期风险评估对于及时干预和有效预防策略至关重要。需要开发准确且可解释的预测模型来支持临床决策。

Method: 采用集成建模和可解释AI技术，包括特征工程和数据预处理（使用随机过采样解决类别不平衡），对10种不同机器学习模型进行5折交叉验证评估，最终构建优化的集成模型（随机森林+ExtraTrees+XGBoost），并使用LIME进行可解释性分析。

Result: 优化后的集成模型在卒中预测数据集上表现出色，达到99.09%的准确率。通过LIME可解释性分析识别出三个关键临床变量：年龄、高血压和血糖水平。

Conclusion: 研究表明，集成学习与可解释AI的结合能够提供高准确性和可解释性的卒中风险评估，通过早期预测支持数据驱动的预防和个性化临床决策，有潜力改变卒中预测和心血管风险管理。

Abstract: Stroke is a major cause of death and permanent impairment, making it a major worldwide health concern. For prompt intervention and successful preventative tactics, early risk assessment is essential. To address this challenge, we used ensemble modeling and explainable AI (XAI) techniques to create an interpretable machine learning framework for stroke risk prediction. A thorough evaluation of 10 different machine learning models using 5-fold cross-validation across several datasets was part of our all-inclusive strategy, which also included feature engineering and data pretreatment (using Random Over-Sampling (ROS) to solve class imbalance). Our optimized ensemble model (Random Forest + ExtraTrees + XGBoost) performed exceptionally well, obtaining a strong 99.09% accuracy on the Stroke Prediction Dataset (SPD). We improved the model's transparency and clinical applicability by identifying three important clinical variables using LIME-based interpretability analysis: age, hypertension, and glucose levels. Through early prediction, this study highlights how combining ensemble learning with explainable AI (XAI) can deliver highly accurate and interpretable stroke risk assessment. By enabling data-driven prevention and personalized clinical decisions, our framework has the potential to transform stroke prediction and cardiovascular risk management.

</details>


### [15] [CourtMotion: Learning Event-Driven Motion Representations from Skeletal Data for Basketball](https://arxiv.org/abs/2512.01478)
*Omer Sela,Michael Chertok,Lior Wolf*

Main category: cs.CV

TL;DR: CourtMotion：一个用于分析和预测职业篮球比赛中事件与战术发展的时空建模框架，通过骨骼追踪数据结合图神经网络和Transformer架构，显著提升了轨迹预测和篮球分析任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于球员位置的方法无法捕捉身体朝向、防守姿态或投篮准备动作等关键指标，而这些对于理解篮球比赛中的语义意义和预测事件发展至关重要。

Method: 采用两阶段方法：首先通过图神经网络处理骨骼追踪数据捕捉细微动作模式，然后使用带有专门注意力机制的Transformer架构建模球员交互，并引入事件投影头将球员动作与传球、投篮、抢断等篮球事件明确连接。

Result: 在NBA追踪数据上的实验显示：相比最先进的基于位置的模型，轨迹预测误差减少35%；在关键篮球分析任务（挡拆检测、投篮者识别、助攻预测、投篮位置分类、投篮类型识别）上均表现出显著性能提升。

Conclusion: CourtMotion框架通过结合物理动作模式与战术语义理解，为篮球事件分析和预测提供了强大基础，其预训练模型可作为多种下游任务的有效工具，显著优于现有方法。

Abstract: This paper presents CourtMotion, a spatiotemporal modeling framework for analyzing and predicting game events and plays as they develop in professional basketball. Anticipating basketball events requires understanding both physical motion patterns and their semantic significance in the context of the game. Traditional approaches that use only player positions fail to capture crucial indicators such as body orientation, defensive stance, or shooting preparation motions. Our two-stage approach first processes skeletal tracking data through Graph Neural Networks to capture nuanced motion patterns, then employs a Transformer architecture with specialized attention mechanisms to model player interactions. We introduce event projection heads that explicitly connect player movements to basketball events like passes, shots, and steals, training the model to associate physical motion patterns with their tactical purposes. Experiments on NBA tracking data demonstrate significant improvements over position-only baselines: 35% reduction in trajectory prediction error compared to state-of-the-art position-based models and consistent performance gains across key basketball analytics tasks. The resulting pretrained model serves as a powerful foundation for multiple downstream tasks, with pick detection, shot taker identification, assist prediction, shot location classification, and shot type recognition demonstrating substantial improvements over existing methods.

</details>


### [16] [FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing](https://arxiv.org/abs/2512.01755)
*Yucheng Liao,Jiajun Liang,Kaiqian Cui,Baoquan Zhao,Haoran Xie,Wei Liu,Qing Li,Xudong Mao*

Main category: cs.CV

TL;DR: FreqEdit是一个无需训练的图像编辑框架，通过高频特征注入、自适应注入策略和路径补偿机制，解决了多轮编辑中的高频信息丢失问题，实现了10+轮次的稳定编辑。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑模型在单次编辑中表现优异，但在多轮编辑中会出现严重的质量退化问题。研究发现高频信息的渐进性损失是导致质量下降的主要原因。

Method: FreqEdit包含三个协同组件：1）从参考速度场注入高频特征以保留细粒度细节；2）自适应注入策略，通过空间调制注入强度实现精确的区域控制；3）路径补偿机制，定期重新校准编辑轨迹以防止过度约束。

Result: 实验表明，FreqEdit在身份保持和指令遵循方面均优于7个最先进的基线方法，能够实现10+轮连续迭代的稳定编辑。

Conclusion: FreqEdit通过解决多轮编辑中的高频信息丢失问题，为基于自然语言的图像编辑提供了稳定、高质量的解决方案，显著提升了多轮编辑的性能。

Abstract: Instruction-based image editing through natural language has emerged as a powerful paradigm for intuitive visual manipulation. While recent models achieve impressive results on single edits, they suffer from severe quality degradation under multi-turn editing. Through systematic analysis, we identify progressive loss of high-frequency information as the primary cause of this quality degradation. We present FreqEdit, a training-free framework that enables stable editing across 10+ consecutive iterations. Our approach comprises three synergistic components: (1) high-frequency feature injection from reference velocity fields to preserve fine-grained details, (2) an adaptive injection strategy that spatially modulates injection strength for precise region-specific control, and (3) a path compensation mechanism that periodically recalibrates the editing trajectory to prevent over-constraint. Extensive experiments demonstrate that FreqEdit achieves superior performance in both identity preservation and instruction following compared to seven state-of-the-art baselines.

</details>


### [17] [Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights](https://arxiv.org/abs/2512.01816)
*Juanxi Tian,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.CV

TL;DR: 论文提出了Envision基准测试，用于评估多图像序列生成中的因果事件进展能力，发现当前模型在时空一致性方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型主要关注单图像生成，导致过度拟合静态模式匹配，缺乏对动态时间过程建模的能力，限制了世界知识的内化。

Method: 提出Envision基准测试，包含1000个四阶段提示，涵盖六个科学和人文领域，并引入Envision-Score综合指标评估多维度一致性、物理性和美学。

Result: 评估15个模型发现：专用T2I模型美学渲染能力强但缺乏世界知识；统一多模态模型在因果叙事连贯性上表现更好，但仍落后于闭源模型，时空一致性仍是核心挑战。

Conclusion: 专注于因果孤立的单图像会阻碍多帧推理和生成，促进静态模式匹配而非动态世界建模，最终限制世界知识的内化和生成能力。

Abstract: Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.

</details>


### [18] [PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models](https://arxiv.org/abs/2512.01843)
*Zeqing Wang,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文提出了PhyDetEx方法，通过构建物理不可行性检测数据集和微调视觉语言模型，来评估文本到视频生成模型对物理规律的遵循程度。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到视频生成模型在视频质量和长度方面取得了进展，但它们是否能理解物理规律并生成物理上合理的视频仍是一个问题。现有的视觉语言模型难以识别生成视频中的物理不可能内容。

Method: 构建了PID数据集（包含500个手动标注的测试视频和2,588个配对训练视频），通过改写真实视频的标题诱导T2V模型生成物理不合理内容。采用轻量级微调方法训练VLM，使其能够检测物理不合理事件并生成违反物理原理的文本解释。

Result: 开发了PhyDetEx物理合理性检测器和解释器，对一系列最先进的T2V模型进行基准测试。结果显示，虽然最近的T2V模型在生成物理合理内容方面取得了显著进展，但理解和遵循物理规律仍然是一个挑战，特别是对于开源模型。

Conclusion: 文本到视频生成模型在物理合理性方面仍有改进空间，提出的PhyDetEx方法为评估和提升T2V模型的物理理解能力提供了有效工具。数据集、训练代码和检查点已开源。

Abstract: Driven by the growing capacity and training scale, Text-to-Video (T2V) generation models have recently achieved substantial progress in video quality, length, and instruction-following capability. However, whether these models can understand physics and generate physically plausible videos remains a question. While Vision-Language Models (VLMs) have been widely used as general-purpose evaluators in various applications, they struggle to identify the physically impossible content from generated videos. To investigate this issue, we construct a \textbf{PID} (\textbf{P}hysical \textbf{I}mplausibility \textbf{D}etection) dataset, which consists of a \textit{test split} of 500 manually annotated videos and a \textit{train split} of 2,588 paired videos, where each implausible video is generated by carefully rewriting the caption of its corresponding real-world video to induce T2V models producing physically implausible content. With the constructed dataset, we introduce a lightweight fine-tuning approach, enabling VLMs to not only detect physically implausible events but also generate textual explanations on the violated physical principles. Taking the fine-tuned VLM as a physical plausibility detector and explainer, namely \textbf{PhyDetEx}, we benchmark a series of state-of-the-art T2V models to assess their adherence to physical laws. Our findings show that although recent T2V models have made notable progress toward generating physically plausible content, understanding and adhering to physical laws remains a challenging issue, especially for open-source models. Our dataset, training code, and checkpoints are available at \href{https://github.com/Zeqing-Wang/PhyDetEx}{https://github.com/Zeqing-Wang/PhyDetEx}.

</details>


### [19] [COACH: Collaborative Agents for Contextual Highlighting - A Multi-Agent Framework for Sports Video Analysis](https://arxiv.org/abs/2512.01853)
*Tsz-To Wong,Ching-Chun Huang,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出一个可重构的多智能体系统（MAS）作为体育视频理解的基础框架，通过多个专门化的智能体作为"认知工具"，实现从微观动作到宏观策略的跨任务分析。


<details>
  <summary>Details</summary>
Motivation: 现有端到端模型在处理体育视频的时序层次结构时存在局限性：缺乏泛化性、新任务开发成本高、可解释性差。需要一种能够灵活适应不同时间维度和任务的框架。

Method: 设计可重构的多智能体系统，每个智能体专门负责分析的不同方面。通过智能体的迭代调用和灵活组合，构建自适应管道，支持从短期分析推理（如回合问答）到长期生成摘要（如比赛总结）的各种任务。

Result: 在羽毛球分析的两个代表性任务中展示了该框架的适应性，证明其能够桥接细粒度事件检测和全局语义组织，实现了灵活、可扩展和可解释的跨任务体育视频智能分析。

Conclusion: 该工作提出了向灵活、可扩展和可解释的系统范式转变，为鲁棒的跨任务体育视频智能提供了新的解决方案，项目主页已公开。

Abstract: Intelligent sports video analysis demands a comprehensive understanding of temporal context, from micro-level actions to macro-level game strategies. Existing end-to-end models often struggle with this temporal hierarchy, offering solutions that lack generalization, incur high development costs for new tasks, and suffer from poor interpretability. To overcome these limitations, we propose a reconfigurable Multi-Agent System (MAS) as a foundational framework for sports video understanding. In our system, each agent functions as a distinct "cognitive tool" specializing in a specific aspect of analysis. The system's architecture is not confined to a single temporal dimension or task. By leveraging iterative invocation and flexible composition of these agents, our framework can construct adaptive pipelines for both short-term analytic reasoning (e.g., Rally QA) and long-term generative summarization (e.g., match summaries). We demonstrate the adaptability of this framework using two representative tasks in badminton analysis, showcasing its ability to bridge fine-grained event detection and global semantic organization. This work presents a paradigm shift towards a flexible, scalable, and interpretable system for robust, cross-task sports video intelligence.The project homepage is available at https://aiden1020.github.io/COACH-project-page

</details>


### [20] [TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals](https://arxiv.org/abs/2512.01885)
*Florian Bürger,Martim Dias Gomes,Nica Gutu,Adrián E. Granada,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: TransientTrack是一个基于深度学习的细胞追踪框架，专门用于处理具有瞬态荧光信号的多通道显微镜视频数据，能够检测细胞分裂和死亡事件，构建完整的细胞轨迹和谱系信息。


<details>
  <summary>Details</summary>
Motivation: 现有细胞追踪方法主要针对单一恒定信号的视频，无法检测细胞死亡等关键事件，且不适用于随时间波动的瞬态荧光信号（如细胞昼夜节律）。需要一种能够处理多通道瞬态信号并识别关键细胞事件的追踪方法。

Method: 使用深度学习框架，直接在细胞检测嵌入上进行匹配，无需量化追踪特异性特征。整合Transformer网络、使用所有检测框的多阶段匹配，以及用卡尔曼滤波器插补缺失的轨迹片段。

Result: 该框架在不同条件下表现出色，能有效追踪细胞并捕捉细胞分裂和死亡事件。在化疗药物疗效的单细胞分析中展示了应用价值。

Conclusion: TransientTrack为癌症细胞动力学定量研究提供了先进工具，能够详细表征治疗反应和耐药机制，代码已开源。

Abstract: Tracking cells in time-lapse videos is an essential technique for monitoring cell population dynamics at a single-cell level. Current methods for cell tracking are developed on videos with mostly single, constant signals and do not detect pivotal events such as cell death. Here, we present TransientTrack, a deep learning-based framework for cell tracking in multi-channel microscopy video data with transient fluorescent signals that fluctuate over time following processes such as the circadian rhythm of cells. By identifying key cellular events - mitosis (cell division) and apoptosis (cell death) our method allows us to build complete trajectories, including cell lineage information. TransientTrack is lightweight and performs matching on cell detection embeddings directly, without the need for quantification of tracking-specific cell features. Furthermore, our approach integrates Transformer Networks, multi-stage matching using all detection boxes, and the interpolation of missing tracklets with the Kalman Filter. This unified framework achieves strong performance across diverse conditions, effectively tracking cells and capturing cell division and death. We demonstrate the use of TransientTrack in an analysis of the efficacy of a chemotherapeutic drug at a single-cell level. The proposed framework could further advance quantitative studies of cancer cell dynamics, enabling detailed characterization of treatment response and resistance mechanisms. The code is available at https://github.com/bozeklab/TransientTrack.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [21] [S^2-KD: Semantic-Spectral Knowledge Distillation Spatiotemporal Forecasting](https://arxiv.org/abs/2512.00366)
*Wenshuo Wang,Yaomin Shen,Yingjie Tan,Yihao Chen*

Main category: cs.LG

TL;DR: S^2-KD：结合语义先验与频谱表示的知识蒸馏框架，通过多模态教师模型学习事件因果关系的语义理解和频谱分解，蒸馏到轻量级视觉学生模型中，提升时空预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法主要关注像素级信号的频谱特性（高频细节和低频趋势），但忽略了视觉模式背后的丰富语义和因果上下文信息，限制了预测模型的性能。

Method: 提出S^2-KD框架：1）训练特权多模态教师模型，利用大型多模态模型（LMM）的文本叙述进行事件因果关系推理，同时在潜在空间解耦频谱分量；2）设计新的蒸馏目标，将统一的语义-频谱知识转移到轻量级纯视觉学生模型中。

Result: 在WeatherBench和TaxiBJ+等基准测试中，S^2-KD显著提升了简单学生模型的性能，使其在长时域和复杂非平稳场景下超越现有最先进方法。

Conclusion: S^2-KD通过统一语义先验和频谱表示的知识蒸馏，使轻量级学生模型能够进行既频谱准确又语义连贯的预测，无需推理时的文本输入或架构开销，为时空预测提供了更有效的解决方案。

Abstract: Spatiotemporal forecasting often relies on computationally intensive models to capture complex dynamics. Knowledge distillation (KD) has emerged as a key technique for creating lightweight student models, with recent advances like frequency-aware KD successfully preserving spectral properties (i.e., high-frequency details and low-frequency trends). However, these methods are fundamentally constrained by operating on pixel-level signals, leaving them blind to the rich semantic and causal context behind the visual patterns. To overcome this limitation, we introduce S^2-KD, a novel framework that unifies Semantic priors with Spectral representations for distillation. Our approach begins by training a privileged, multimodal teacher model. This teacher leverages textual narratives from a Large Multimodal Model (LMM) to reason about the underlying causes of events, while its architecture simultaneously decouples spectral components in its latent space. The core of our framework is a new distillation objective that transfers this unified semantic-spectral knowledge into a lightweight, vision-only student. Consequently, the student learns to make predictions that are not only spectrally accurate but also semantically coherent, without requiring any textual input or architectural overhead at inference. Extensive experiments on benchmarks like WeatherBench and TaxiBJ+ show that S^2-KD significantly boosts the performance of simple student models, enabling them to outperform state-of-the-art methods, particularly in long-horizon and complex non-stationary scenarios.

</details>


### [22] [Developing Fairness-Aware Task Decomposition to Improve Equity in Post-Spinal Fusion Complication Prediction](https://arxiv.org/abs/2512.00598)
*Yining Yuan,J. Ben Tamo,Wenqi Shi,Yishan Zhong,Micky C. Nnamdi,B. Randall Brenn,Steven W. Hwang,May D. Wang*

Main category: cs.LG

TL;DR: FAIR-MTL：一种公平感知的多任务学习框架，通过数据驱动的亚组推断机制，在脊柱融合手术并发症预测中实现更公平、细粒度的预测


<details>
  <summary>Details</summary>
Motivation: 临床预测模型中的公平性问题持续存在，特别是在脊柱侧凸脊柱融合手术等高风险应用中。现有公平性方法依赖粗略的人口统计调整或事后校正，无法捕捉临床人群的潜在结构，可能无意中强化偏见。

Method: 提出FAIR-MTL框架，采用数据驱动的亚组推断机制：提取紧凑的人口统计嵌入，应用k-means聚类发现潜在患者亚组；在共享多任务架构中根据推断的亚组标签进行任务路由；通过逆频率加权缓解亚组不平衡，正则化防止对小群体过拟合。

Result: 在术后并发症预测（四个严重程度等级）中，FAIR-MTL达到AUC 0.86和准确率75%，优于单任务基线并显著减少偏见。性别方面：人口统计奇偶差异降至0.055，均衡几率降至0.094；年龄方面：分别降至0.056和0.148。SHAP和Gini重要性分析确保模型可解释性。

Conclusion: 将无监督亚组发现纳入多任务框架，能够为手术风险分层提供更公平、可解释且临床可操作的预测。

Abstract: Fairness in clinical prediction models remains a persistent challenge, particularly in high-stakes applications such as spinal fusion surgery for scoliosis, where patient outcomes exhibit substantial heterogeneity. Many existing fairness approaches rely on coarse demographic adjustments or post-hoc corrections, which fail to capture the latent structure of clinical populations and may unintentionally reinforce bias. We propose FAIR-MTL, a fairness-aware multitask learning framework designed to provide equitable and fine-grained prediction of postoperative complication severity.
  Instead of relying on explicit sensitive attributes during model training, FAIR-MTL employs a data-driven subgroup inference mechanism. We extract a compact demographic embedding, and apply k-means clustering to uncover latent patient subgroups that may be differentially affected by traditional models. These inferred subgroup labels determine task routing within a shared multitask architecture. During training, subgroup imbalance is mitigated through inverse-frequency weighting, and regularization prevents overfitting to smaller groups.
  Applied to postoperative complication prediction with four severity levels, FAIR-MTL achieves an AUC of 0.86 and an accuracy of 75%, outperforming single-task baselines while substantially reducing bias. For gender, the demographic parity difference decreases to 0.055 and equalized odds to 0.094; for age, these values reduce to 0.056 and 0.148, respectively. Model interpretability is ensured through SHAP and Gini importance analyses, which consistently highlight clinically meaningful predictors such as hemoglobin, hematocrit, and patient weight. Our findings show that incorporating unsupervised subgroup discovery into a multitask framework enables more equitable, interpretable, and clinically actionable predictions for surgical risk stratification.

</details>


### [23] [Towards Precision Protein-Ligand Affinity Prediction Benchmark: A Complete and Modification-Aware DAVIS Dataset](https://arxiv.org/abs/2512.00708)
*Ming-Hsiu Wu,Ziqian Xie,Shuiwang Ji,Degui Zhi*

Main category: cs.LG

TL;DR: 研究者创建了DAVIS-complete数据集，包含4,032个涉及蛋白质修饰的激酶-配体对，并设计了三个基准测试来评估模型在蛋白质修饰情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在药物发现任务（如蛋白质-配体结合亲和力预测）中过度拟合于简化的数据集，这些数据集不能代表自然发生且具有生物学相关性的蛋白质修饰。需要创建更真实的数据集来评估模型在生物现实条件下的表现。

Method: 1. 创建DAVIS-complete数据集：整合了4,032个涉及替代、插入、缺失和磷酸化事件的激酶-配体对。2. 设计三个基准测试：增强数据集预测、野生型到修饰的泛化、少样本修饰泛化。3. 广泛评估对接自由和对接依赖方法。

Result: 对接依赖模型在零样本设置下泛化更好；对接自由模型倾向于过度拟合野生型蛋白质，难以处理未见过的修饰，但在少量修饰样本上微调后表现显著改善。

Conclusion: DAVIS-complete数据集和基准测试为开发能更好泛化到蛋白质修饰的模型提供了宝贵基础，有望推动精准医疗在药物发现中的进展。

Abstract: Advancements in AI for science unlocks capabilities for critical drug discovery tasks such as protein-ligand binding affinity prediction. However, current models overfit to existing oversimplified datasets that does not represent naturally occurring and biologically relevant proteins with modifications. In this work, we curate a complete and modification-aware version of the widely used DAVIS dataset by incorporating 4,032 kinase-ligand pairs involving substitutions, insertions, deletions, and phosphorylation events. This enriched dataset enables benchmarking of predictive models under biologically realistic conditions. Based on this new dataset, we propose three benchmark settings-Augmented Dataset Prediction, Wild-Type to Modification Generalization, and Few-Shot Modification Generalization-designed to assess model robustness in the presence of protein modifications. Through extensive evaluation of both docking-free and docking-based methods, we find that docking-based model generalize better in zero-shot settings. In contrast, docking-free models tend to overfit to wild-type proteins and struggle with unseen modifications but show notable improvement when fine-tuned on a small set of modified examples. We anticipate that the curated dataset and benchmarks offer a valuable foundation for developing models that better generalize to protein modifications, ultimately advancing precision medicine in drug discovery. The benchmark is available at: https://github.com/ZhiGroup/DAVIS-complete

</details>


### [24] [Preventing Model Collapse via Contraction-Conditioned Neural Filters](https://arxiv.org/abs/2512.00757)
*Zongjian Han,Yiran Liang,Ruiwen Wang,Yiwei Luo,Yilin Huang,Xiaotong Song,Dongqing Wei*

Main category: cs.LG

TL;DR: 提出基于收缩算子的神经网络滤波器方法，解决生成模型递归训练中的模型崩溃问题，无需增加样本量即可实现概率收敛


<details>
  <summary>Details</summary>
Motivation: 现有方法如Xu等人需要超线性样本增长(O(t^{1+s}))，这在实际应用中不切实际。本文旨在消除对增加样本量的依赖，在无偏估计框架下解决模型崩溃问题

Method: 设计神经网络滤波器学习满足收缩条件，开发专门的神经网络架构和损失函数，使滤波器能够主动学习满足指数族分布中假设2.3的收缩条件

Result: 理论分析表明，当学习到的收缩条件满足时，即使使用恒定样本量，估计误差也能概率收敛。实验结果显示神经网络滤波器能有效学习收缩条件并在固定样本量设置下防止模型崩溃

Conclusion: 该方法为实际应用提供了端到端解决方案，完全消除了对增加样本量的依赖，在恒定样本量下实现了概率收敛，有效防止了模型崩溃

Abstract: This paper presents a neural network filter method based on contraction operators to address model collapse in recursive training of generative models. Unlike \cite{xu2024probabilistic}, which requires superlinear sample growth ($O(t^{1+s})$), our approach completely eliminates the dependence on increasing sample sizes within an unbiased estimation framework by designing a neural filter that learns to satisfy contraction conditions. We develop specialized neural network architectures and loss functions that enable the filter to actively learn contraction conditions satisfying Assumption 2.3 in exponential family distributions, thereby ensuring practical application of our theoretical results. Theoretical analysis demonstrates that when the learned contraction conditions are satisfied, estimation errors converge probabilistically even with constant sample sizes, i.e., $\limsup_{t\to\infty}\mathbb{P}(\|\mathbf{e}_t\|>δ)=0$ for any $δ>0$. Experimental results show that our neural network filter effectively learns contraction conditions and prevents model collapse under fixed sample size settings, providing an end-to-end solution for practical applications.

</details>


### [25] [Multi-Modal AI for Remote Patient Monitoring in Cancer Care](https://arxiv.org/abs/2512.00949)
*Yansong Liu,Ronnie Stafford,Pramit Khetrapal,Huriye Kocadag,Graça Carvalho,Patricia de Winter,Maryam Imran,Amelia Snook,Adamos Hadjivasiliou,D. Vijay Anand,Weining Lin,John Kelly,Yukun Zhou,Ivana Drobnjak*

Main category: cs.LG

TL;DR: 开发了一个用于癌症患者远程监测的多模态AI框架，通过整合人口统计、可穿戴设备、日常调查等多源数据，预测未来不良事件风险，准确率达83.9%


<details>
  <summary>Details</summary>
Motivation: 癌症患者在接受系统治疗期间，门诊就诊间隔存在监测空白，存在未被监测的副作用风险，需要远程监测解决方案来填补这一护理缺口

Method: 开发多模态AI框架，整合HALO-X平台的多模态数据（人口统计、可穿戴传感器、日常调查、临床事件），处理真实世界远程监测数据的异步性和不完整性，预测未来不良事件的连续风险

Result: 在84名患者、6,080患者日、210万数据点的观察性试验中，模型准确率达83.9%（AUROC=0.70），识别出既往治疗、健康检查、每日最大心率为关键预测特征，案例研究显示模型能在事件发生前提供风险升级预警

Conclusion: 这项工作证明了多模态AI远程监测在癌症护理中的可行性，为更主动的患者支持提供了路径

Abstract: For patients undergoing systemic cancer therapy, the time between clinic visits is full of uncertainties and risks of unmonitored side effects. To bridge this gap in care, we developed and prospectively trialed a multi-modal AI framework for remote patient monitoring (RPM). This system integrates multi-modal data from the HALO-X platform, such as demographics, wearable sensors, daily surveys, and clinical events. Our observational trial is one of the largest of its kind and has collected over 2.1 million data points (6,080 patient-days) of monitoring from 84 patients. We developed and adapted a multi-modal AI model to handle the asynchronous and incomplete nature of real-world RPM data, forecasting a continuous risk of future adverse events. The model achieved an accuracy of 83.9% (AUROC=0.70). Notably, the model identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features. A case study demonstrated the model's ability to provide early warnings by outputting escalating risk profiles prior to the event. This work establishes the feasibility of multi-modal AI RPM for cancer care and offers a path toward more proactive patient support.(Accepted at Europe NeurIPS 2025 Multimodal Representation Learning for Healthcare Workshop)

</details>


### [26] [ZIP-RC: Zero-overhead Inference-time Prediction of Reward and Cost for Adaptive and Interpretable Generation](https://arxiv.org/abs/2512.01457)
*Rohin Manvi,Joey Hong,Tim Seyde,Maxime Labonne,Mathias Lechner,Sergey Levine*

Main category: cs.LG

TL;DR: ZIP-RC：一种零开销自适应推理方法，通过重用LLM前向传播中的保留logits，实时预测奖励和成本，实现高效的自省式推理决策。


<details>
  <summary>Details</summary>
Motivation: 当前LLM缺乏人类的自省能力（如预测自身成功概率和所需计算量），导致无法智能地进行元认知决策。现有方法如Best-of-N固定采样预算效率低下，而学习验证器或奖励模型虽能提供置信度估计，但会增加额外成本和架构复杂度。

Method: ZIP-RC在每次token生成时，重用同一前向传播中保留或未使用的logits，输出最终奖励和剩余长度的联合分布。基于此分布计算采样效用函数（期望最大奖励、总计算量和延迟的线性组合），通过最大化该效用的元动作决定继续生成哪些token前缀或启动新采样。

Result: 在混合难度数学基准测试中，ZIP-RC在相同或更低平均成本下，比多数投票方法准确率提升高达12%，并在质量、计算量和延迟之间形成平滑的帕累托前沿。

Conclusion: ZIP-RC通过提供实时奖励-成本自省能力，实现了自适应、高效的推理，解决了LLM缺乏自省能力的问题，且无需额外模型、架构变更或推理开销。

Abstract: Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.

</details>


### [27] [Adaptive-lambda Subtracted Importance Sampled Scores in Machine Unlearning for DDPMs and VAEs](https://arxiv.org/abs/2512.01054)
*MohammadParsa Dini,Human Jafari,Sajjad Amini,MohammadMahdi Mojahedian*

Main category: cs.LG

TL;DR: 提出Adaptive-lambda SISS方法，通过动态推断混合权重lambda来改进机器遗忘，相比固定lambda方法在遗忘效果和保留质量间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于固定混合权重lambda的遗忘方法（如Static-lambda SISS）存在不足，因为不同样本和训练阶段所需的遗忘强度不同，需要更灵活的自适应机制。

Method: 将lambda作为潜在变量，通过轻量级推理网络动态推断，该网络基于瞬时SISS损失项（保留/遗忘损失及其梯度）的上下文特征参数化自适应后验分布，通过变分目标联合优化扩散模型和lambda推理机制。

Result: 在增强MNIST基准测试中，Adaptive-lambda SISS显著优于原始静态lambda SISS，在更好保留保留集生成质量的同时，实现了对遗忘类别更强的移除效果。

Conclusion: 自适应lambda机制为机器遗忘提供了更优的解决方案，并可扩展到基于分数的遗忘和多类别场景，同时提出了混合目标和强化学习等新方向。

Abstract: Machine Unlearning is essential for large generative models (VAEs, DDPMs) to comply with the right to be forgotten and prevent undesired content generation without costly retraining. Existing approaches, such as Static-lambda SISS for diffusion models, rely on a fixed mixing weight lambda, which is suboptimal because the required unlearning strength varies across samples and training stages.
  We propose Adaptive-lambda SISS, a principled extension that turns lambda into a latent variable dynamically inferred at each training step. A lightweight inference network parameterizes an adaptive posterior over lambda, conditioned on contextual features derived from the instantaneous SISS loss terms (retain/forget losses and their gradients). This enables joint optimization of the diffusion model and the lambda-inference mechanism via a variational objective, yielding significantly better trade-offs.
  We further extend the adaptive-lambda principle to score-based unlearning and introduce a multi-class variant of Score Forgetting Distillation. In addition, we present two new directions: (i) a hybrid objective combining the data-free efficiency of Score Forgetting Distillation with the direct gradient control of SISS, and (ii) a Reinforcement Learning formulation that treats unlearning as a sequential decision process, learning an optimal policy over a state space defined by the model's current memory of the forget set.
  Experiments on an augmented MNIST benchmark show that Adaptive-lambda SISS substantially outperforms the original static-lambda SISS, achieving stronger removal of forgotten classes while better preserving generation quality on the retain set.

</details>


### [28] [PIANO: Physics-informed Dual Neural Operator for Precipitation Nowcasting](https://arxiv.org/abs/2512.01062)
*Seokhyun Chin,Junghwan Park,Woojin Cho*

Main category: cs.LG

TL;DR: 提出PIANO模型，结合物理约束与神经网络，利用卫星图像进行降水临近预报，提高预测精度和物理一致性


<details>
  <summary>Details</summary>
Motivation: 当前降水临近预报方法计算成本高、限制多，许多国家难以获得。需要开发更准确、物理一致且可访问的预测方法

Method: 使用物理信息双神经算子(PIANO)结构，在训练中通过PINN损失强制实施平流-扩散基本方程预测卫星图像，然后用生成模型将卫星图像转换为雷达图像进行降水预报

Result: 相比基线模型，在中度降水(4mm/h)和短期强降水(8mm/h)事件预测方面有显著改进，预测季节性变化小，表明泛化能力强

Conclusion: PIANO模型展示了物理信息降水临近预报的潜力，为相关研究提供了良好基准

Abstract: Precipitation nowcasting, key for early warning of disasters, currently relies on computationally expensive and restrictive methods that limit access to many countries. To overcome this challenge, we propose precipitation nowcasting using satellite imagery with physics constraints for improved accuracy and physical consistency. We use a novel physics-informed dual neural operator (PIANO) structure to enforce the fundamental equation of advection-diffusion during training to predict satellite imagery using a PINN loss. Then, we use a generative model to convert satellite images to radar images, which are used for precipitation nowcasting. Compared to baseline models, our proposed model shows a notable improvement in moderate (4mm/h) precipitation event prediction alongside short-term heavy (8mm/h) precipitation event prediction. It also demonstrates low seasonal variability in predictions, indicating robustness for generalization. This study suggests the potential of the PIANO and serves as a good baseline for physics-informed precipitation nowcasting.

</details>


### [29] [ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models](https://arxiv.org/abs/2512.01672)
*Zhongyuan Wu,Jingyuan Wang,Zexuan Cheng,Yilong Zhou,Weizhi Wang,Juhua Pu,Chao Li,Changqing Ma*

Main category: cs.LG

TL;DR: 提出ICAD-LLM框架，利用大语言模型的上下文学习能力实现跨模态异常检测，无需重新训练即可适应新场景


<details>
  <summary>Details</summary>
Motivation: 现代系统在快速演变环境中产生多种互连数据模态（时间序列、系统日志、表格记录），现有异常检测方法通常专注于单一模态，缺乏处理异构数据格式和跨域泛化的能力

Method: 提出上下文异常检测（ICAD）新范式，基于异常样本与正常参考集的差异度定义异常；开发ICAD-LLM框架，利用大语言模型的上下文学习能力在单一模型中处理异构数据

Result: ICAD-LLM在实验中达到与任务特定方法相当的竞争性性能，对未见任务表现出强大泛化能力，显著降低部署成本并支持快速适应新环境

Conclusion: ICAD-LLM是首个能够跨领域和模态处理异常检测任务的模型，为解决异构数据环境中的异常检测问题提供了统一框架

Abstract: Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.

</details>


### [30] [Delays in Spiking Neural Networks: A State Space Model Approach](https://arxiv.org/abs/2512.01906)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 该论文提出了一个将延迟机制融入脉冲神经网络的通用框架，通过额外状态变量使神经元能够访问有限时间输入历史，在保持计算效率的同时提升时序数据处理能力。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNNs）作为生物启发的能量高效计算模型，在处理时序数据方面具有优势。延迟机制允许过去的输入直接影响当前的脉冲行为，能够捕捉更复杂的时序依赖关系，但现有方法缺乏通用且高效的延迟集成框架。

Method: 提出一个通用框架，通过为每个神经元引入额外的状态变量来整合延迟机制。该框架与神经元模型无关，可无缝集成到标准脉冲神经元模型（如LIF和adLIF）中。延迟持续时间和相关可学习参数可调节，框架分析了延迟机制引入的额外状态变量对网络架构的权衡。

Result: 在Spiking Heidelberg Digits (SHD)数据集上的实验表明，该机制在保持计算效率的同时，性能与现有基于延迟的SNNs相当。更重要的是，结果显示在较小的网络中，延迟的整合可以显著提升性能。

Conclusion: 提出的延迟集成框架为脉冲神经网络提供了一种通用且高效的方法来捕捉复杂时序依赖关系，特别适合资源受限的小型网络，在保持生物合理性和计算效率的同时提升了时序数据处理能力。

Abstract: Spiking neural networks (SNNs) are biologically inspired, event-driven models that are suitable for processing temporal data and offer energy-efficient computation when implemented on neuromorphic hardware. In SNNs, richer neuronal dynamic allows capturing more complex temporal dependencies, with delays playing a crucial role by allowing past inputs to directly influence present spiking behavior. We propose a general framework for incorporating delays into SNNs through additional state variables. The proposed mechanism enables each neuron to access a finite temporal input history. The framework is agnostic to neuron models and hence can be seamlessly integrated into standard spiking neuron models such as LIF and adLIF. We analyze how the duration of the delays and the learnable parameters associated with them affect the performance. We investigate the trade-offs in the network architecture due to additional state variables introduced by the delay mechanism. Experiments on the Spiking Heidelberg Digits (SHD) dataset show that the proposed mechanism matches the performance of existing delay-based SNNs while remaining computationally efficient. Moreover, the results illustrate that the incorporation of delays may substantially improve performance in smaller networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [31] [Probing the "Psyche'' of Large Reasoning Models: Understanding Through a Human Lens](https://arxiv.org/abs/2512.00729)
*Yuxiang Chen,Zuohan Wu,Ziwei Wang,Xiangning Yu,Xujia Li,Linyi Yang,Mengyue Yang,Jun Wang,Lei Chen*

Main category: cs.AI

TL;DR: 该论文提出了一个基于人类心理过程的分类法来理解大型推理模型，开发了自动标注框架CAPO，并分析了当前LRMs的推理行为，发现自我监控评估大多流于表面，建议采用多步反思来改进推理模型。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型展现出类似人类的推理行为，但缺乏系统性的分析框架。研究者希望从跨学科的人类心理过程角度，深入理解LRMs的"心理"特征，为改进推理模型提供理论基础。

Method: 1) 提出包含5组17类的人类心理过程分类法；2) 应用该分类法分析当前LRMs，创建包含277,534个原子推理步骤的标注数据集；3) 开发自动标注框架CAPO，利用LLMs生成分类法标注；4) 分析当代LRMs并提炼改进建议。

Result: 1) CAPO框架在标注一致性上优于基线方法，与人类专家更一致；2) 分析发现当前流行的后答案"双重检查"（自我监控评估）大多流于表面，很少产生实质性修订；3) 激励全面的多步反思比简单自我监控更有效。

Conclusion: 该分类法、CAPO框架和所得见解为理解和推进LRM推理提供了原则性、可扩展的路径。多步反思而非简单自我监控是改进推理模型训练和后训练的更有效方向。

Abstract: Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.

</details>


### [32] [A Fast Heuristic Search Approach for Energy-Optimal Profile Routing for Electric Vehicles](https://arxiv.org/abs/2512.01331)
*Saman Ahmadi,Mahdi Jalili*

Main category: cs.AI

TL;DR: 提出基于多目标A*搜索的能量最优路径规划方法，用于电动汽车在不确定初始能量情况下的路径规划，避免处理复杂能量剖面


<details>
  <summary>Details</summary>
Motivation: 传统电动汽车路径规划算法假设已知初始能量水平，但实际应用中存在初始能量不确定的情况，需要为所有可能的初始能量水平规划最优路径（能量最优剖面搜索）。现有方法通常依赖复杂的剖面合并过程，处理复杂剖面效率较低。

Method: 提出基于多目标A*搜索的标签设置方法，采用新颖的剖面支配规则，避免生成和处理复杂剖面。开发了四种变体方法。

Result: 在真实道路网络上使用实际能耗数据进行评估，实验结果表明能量剖面A*搜索的性能与已知初始能量水平的能量最优A*相当。

Conclusion: 提出的方法简单有效，能够处理电动汽车在不确定初始能量情况下的路径规划问题，性能与传统方法相当，避免了复杂剖面的处理。

Abstract: We study the energy-optimal shortest path problem for electric vehicles (EVs) in large-scale road networks, where recuperated energy along downhill segments introduces negative energy costs. While traditional point-to-point pathfinding algorithms for EVs assume a known initial energy level, many real-world scenarios involving uncertainty in available energy require planning optimal paths for all possible initial energy levels, a task known as energy-optimal profile search. Existing solutions typically rely on specialized profile-merging procedures within a label-correcting framework that results in searching over complex profiles. In this paper, we propose a simple yet effective label-setting approach based on multi-objective A* search, which employs a novel profile dominance rule to avoid generating and handling complex profiles. We develop four variants of our method and evaluate them on real-world road networks enriched with realistic energy consumption data. Experimental results demonstrate that our energy profile A* search achieves performance comparable to energy-optimal A* with a known initial energy level.

</details>


### [33] [A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale](https://arxiv.org/abs/2512.01440)
*Sylvain Marié,Pablo Knecht*

Main category: cs.AI

TL;DR: 提出一种新的状态转移事件时间序列（STE-ts）和选择性时序汉明距离（STH），避免对大型数据库进行代价高昂且失真的重采样，同时利用转移时间和状态持续时间信息。


<details>
  <summary>Details</summary>
Motivation: 离散事件系统普遍存在于自然观察、社会经济科学和工业系统中。现有分析方法通常未能充分利用其事件/状态双重特性：信号要么被建模为转移事件序列（强调事件顺序对齐），要么被建模为分类或有序状态时间序列（通常需要重采样，随着观测周期和事件数量的增加，这种操作既失真又代价高昂）。

Method: 定义状态转移事件时间序列（STE-ts），并提出新的选择性时序汉明距离（STH），该距离同时利用转移时间和状态持续时间信息，避免对大型数据库进行代价高昂且失真的重采样。

Result: STH能够泛化重采样汉明距离和Jaccard度量，具有更好的精度和计算时间，并且能够聚焦于多个感兴趣的状态。在模拟和真实世界数据集上验证了这些优势。

Conclusion: 提出的STE-ts和STH方法为离散事件系统分析提供了一种更高效、更精确的解决方案，避免了传统重采样方法的失真和计算成本问题，同时充分利用了系统的双重特性。

Abstract: Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.

</details>


### [34] [Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation](https://arxiv.org/abs/2512.01723)
*Saba Kublashvili*

Main category: cs.AI

TL;DR: HistoricalML：一个概率神经符号框架，通过贝叶斯不确定性量化、结构因果模型、合作博弈论和注意力机制，解决历史事件建模中的数据稀缺、异质测量、反事实缺失和可解释性挑战。


<details>
  <summary>Details</summary>
Motivation: 历史事件建模面临极端数据稀缺（N<100）、异质噪声测量、反事实缺失以及需要人类可解释解释等基本挑战。现有机器学习方法难以处理这些复杂的历史分析问题。

Method: 提出HistoricalML框架，整合四个核心组件：1）贝叶斯不确定性量化分离认知与偶然不确定性；2）结构因果模型处理混杂下的反事实推理；3）合作博弈论（Shapley值）进行公平分配建模；4）注意力神经网络进行上下文依赖因子加权。

Result: 理论分析表明：在稀疏数据下，当有强领域先验时，方法能实现一致估计；Shapley分配满足公理公平性保证。在两个历史案例中：19世纪非洲殖民（7个殖民国家）识别出德国+107.9%差异作为一战前结构性紧张；第二次布匿战争（2个派系）模拟显示迦太基在坎尼有57.3%胜率，罗马在扎马有57.8%胜率。

Conclusion: HistoricalML成功解决了历史建模的核心挑战，通过概率神经符号方法实现了可解释的历史分析。反事实分析揭示迦太基的政治支持（而非军事实力）是决定性因素，展示了框架在识别历史关键驱动因素方面的价值。

Abstract: Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.

</details>


### [35] [LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess](https://arxiv.org/abs/2512.01992)
*Sai Kolasani,Maxim Saplin,Nicholas Crispino,Kyle Montgomery,Jared Quincy Davis,Matei Zaharia,Chi Wang,Chenguang Wang*

Main category: cs.AI

TL;DR: LLM CHESS是一个评估框架，通过在象棋领域的扩展智能体交互来测试大语言模型的推理和指令遵循泛化能力，对50多个模型进行排名，发现即使顶级推理模型也难以完成游戏或取得稳定胜利。


<details>
  <summary>Details</summary>
Motivation: 现有静态基准测试容易过拟合和记忆化，且容易饱和。需要一种随机、动态的评估框架来减少这些问题，同时评估LLMs在复杂推理和指令遵循任务中的泛化能力。

Method: 开发LLM CHESS框架，让LLMs作为象棋智能体与随机对手对弈。使用多种行为指标评估：胜率、负率、走子质量、走子合法性、幻觉动作和游戏时长。对顶级推理模型，通过与可变技能配置的象棋引擎对弈来估算Elo评分。

Result: 对50多个开源和闭源模型进行排名。许多最先进的模型难以完成游戏或取得稳定胜利。实验显示推理模型和非推理模型之间存在明显差距。LLM CHESS的随机动态特性有效减少了过拟合和记忆化，即使对顶级推理模型也具有挑战性。

Conclusion: LLM CHESS提供了一个独特且具有挑战性的评估框架，能够有效测试LLMs的推理和指令遵循泛化能力。该框架减少了基准饱和问题，为未来研究提供了有价值的工具。作者发布了实验框架、公共排行榜和相关游戏数据集。

Abstract: We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [36] [OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion](https://arxiv.org/abs/2512.00234)
*Sai Koneru,Matthias Huck,Jan Niehues*

Main category: cs.CL

TL;DR: OmniFusion：融合多模态基础模型与翻译LLM的端到端多模态翻译系统，支持语音、图像到文本的翻译，相比级联流水线降低延迟并提升质量。


<details>
  <summary>Details</summary>
Motivation: 现有开源文本翻译LLM只能用于级联语音翻译流水线，导致额外延迟（对同传尤其关键）且无法利用图像等多模态上下文进行消歧。多模态基础模型虽具备跨模态感知推理能力，但缺乏专业翻译LLM的多语言覆盖和翻译性能。

Method: 提出端到端融合方法，将预训练多模态基础模型（Omni 2.5-7B）与翻译LLM（SeedX PPO-7B）连接。创新融合策略：将MMFM多个隐藏层状态连接到翻译LLM，实现联合端到端训练。

Result: OmniFusion能执行语音到文本、语音+图像到文本、文本+图像到文本翻译。实验表明：有效利用音频和视觉输入，在同传中相比级联流水线减少1秒延迟，同时提升整体翻译质量。

Conclusion: 通过融合多模态基础模型与专业翻译LLM，实现了高效的多模态翻译系统，解决了级联流水线的延迟问题，并能利用多模态上下文提升翻译性能。

Abstract: There has been significant progress in open-source text-only translation large language models (LLMs) with better language coverage and quality. However, these models can be only used in cascaded pipelines for speech translation (ST), performing automatic speech recognition first followed by translation. This introduces additional latency, which is particularly critical in simultaneous ST (SimulST), and prevents the model from exploiting multimodal context, such as images, which can aid disambiguation. Pretrained multimodal foundation models (MMFMs) already possess strong perception and reasoning capabilities across multiple modalities, but generally lack the multilingual coverage and specialized translation performance of dedicated translation LLMs. To build an effective multimodal translation system, we propose an end-to-end approach that fuses MMFMs with translation LLMs. We introduce a novel fusion strategy that connects hidden states from multiple layers of a pretrained MMFM to a translation LLM, enabling joint end-to-end training. The resulting model, OmniFusion, built on Omni 2.5-7B as the MMFM and SeedX PPO-7B as the translation LLM, can perform speech-to-text, speech-and-image-to-text, and text-and-image-to-text translation. Experiments demonstrate that OmniFusion effectively leverages both audio and visual inputs, achieves a 1-second latency reduction in SimulST compared to cascaded pipelines and also improves the overall translation quality\footnote{Code is available at https://github.com/saikoneru/OmniFusion}.

</details>


### [37] [Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems](https://arxiv.org/abs/2512.01661)
*Dengyun Peng,Qiguang Chen,Bofei Liu,Jiannan Guan,Libo Qin,Zheng Yan,Jinhao Liu,Jianshu Zhang,Wanxiang Che*

Main category: cs.CL

TL;DR: 论文提出UnsolvableQA数据集和UnsolvableRL框架，用于训练LLM区分可解问题与不可解问题，防止模型过度自信和幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前LLM难以区分客观不可解性（问题内在矛盾）和主观能力限制（超出模型能力的问题），导致幻觉和过度自信。需要让模型既能解决可解问题，又能识别不可解问题并谨慎拒绝超出能力范围的任务。

Method: 1) 构建UnsolvableQA数据集：通过双轨方法创建可解和不可解实例对，包括程序化生成逻辑谜题，以及新颖的"反向构造"方法在数学推理链中注入矛盾。2) 提出UnsolvableRL强化学习框架：包含三个奖励组件，共同考虑准确性、不可解性和难度。

Result: 实验结果显示，该方法实现了近乎完美的不可解性检测，同时提高了可解任务的准确性。关键发现是"能力崩溃"现象，表明明确暴露于不可解数据对于防止模型系统性过度自信是必不可少的。

Conclusion: 通过UnsolvableQA数据集和UnsolvableRL框架，可以有效训练LLM区分可解与不可解问题，提高模型可靠性，防止过度自信和幻觉。代码和数据已开源。

Abstract: Ensuring LLM reliability requires not only solving complex problems but also recognizing when a problem is unsolvable. Current models often struggle to distinguish objective unsolvability (inherent contradictions in the problem) from subjective capability limitations (problems beyond the model's competence), which leads to hallucinations and overconfidence. To address this, we propose UnsolvableQA and UnsolvableRL to solve feasible problems, detect inherent contradictions, and prudently refuse tasks beyond capability. Specifically, we construct UnsolvableQA, a dataset of paired solvable and unsolvable instances derived via a dual-track methodology: programmatic generation for logic puzzles and a novel "Reverse Construction" method that injects contradictions into valid reasoning chains for mathematics. Building on this dataset, we introduce UnsolvableRL, a reinforcement learning framework with three reward components jointly accounting for accuracy, unsolvability, and difficulty. Empirical results show that our approach achieves near-perfect unsolvability detection while also improving accuracy on solvable tasks. Crucially, we identify Capability Collapse, demonstrating that explicit exposure to unsolvable data is indispensable for preventing models from becoming systematically overconfident. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA.

</details>


### [38] [MMAG: Mixed Memory-Augmented Generation for Large Language Models Applications](https://arxiv.org/abs/2512.01710)
*Stefano Zeppieri*

Main category: cs.CL

TL;DR: 提出MMAG模式，为LLM智能体构建五层记忆系统，提升对话的连贯性、个性化和持续性


<details>
  <summary>Details</summary>
Motivation: LLM在单次提示中能生成连贯文本，但在长期交互中缺乏相关性、个性化和连续性。人类沟通依赖多种记忆形式，需要为LLM智能体构建类似的多层记忆系统

Method: 引入混合记忆增强生成(MMAG)模式，将记忆组织为五层：对话记忆、长期用户记忆、情景与事件关联记忆、感知与情境记忆、短期工作记忆。基于认知心理学原理，将这些层次映射到技术组件，并设计协调、优先级和冲突解决策略

Result: 在Heero对话智能体中实现MMAG，加密的长期用户档案和对话历史已能提升用户参与度和留存率

Conclusion: MMAG为构建记忆丰富的语言智能体提供了基础框架，使其更加连贯、主动并符合人类需求。同时讨论了存储、检索、隐私和延迟等实施问题及开放挑战

Abstract: Large Language Models (LLMs) excel at generating coherent text within a single prompt but fall short in sustaining relevance, personalization, and continuity across extended interactions. Human communication, however, relies on multiple forms of memory, from recalling past conversations to adapting to personal traits and situational context. This paper introduces the Mixed Memory-Augmented Generation (MMAG) pattern, a framework that organizes memory for LLM-based agents into five interacting layers: conversational, long-term user, episodic and event-linked, sensory and context-aware, and short-term working memory. Drawing inspiration from cognitive psychology, we map these layers to technical components and outline strategies for coordination, prioritization, and conflict resolution. We demonstrate the approach through its implementation in the Heero conversational agent, where encrypted long-term bios and conversational history already improve engagement and retention. We further discuss implementation concerns around storage, retrieval, privacy, and latency, and highlight open challenges. MMAG provides a foundation for building memory-rich language agents that are more coherent, proactive, and aligned with human needs.

</details>


### [39] [Reasoning About the Unsaid: Misinformation Detection with Omission-Aware Graph Inference](https://arxiv.org/abs/2512.01728)
*Zhengjia Wang,Danding Wang,Qiang Sheng,Jiaying Wu,Juan Cao*

Main category: cs.CL

TL;DR: OmiGraph：首个考虑信息遗漏的虚假信息检测框架，通过构建遗漏感知图、建模遗漏关系、消息传递聚合来检测基于信息遗漏的欺骗性内容。


<details>
  <summary>Details</summary>
Motivation: 虚假信息不仅通过明确捏造内容欺骗读者，还通过隐含地遗漏关键信息来误导判断。虽然前者已被广泛研究，但基于遗漏的欺骗方式在很大程度上被忽视，尽管它能在看似完整的信息中微妙地引导读者得出错误结论。

Method: 1. 构建遗漏感知图：利用捕捉同一事件互补视角的上下文环境为目标新闻构建图，揭示可能被遗漏的内容；2. 遗漏关系建模：识别内部上下文依赖关系和动态遗漏意图，形成全面的遗漏关系表示；3. 遗漏感知消息传递和聚合：整合遗漏内容和关系，建立全面的欺骗感知模式。

Result: 在两个大规模基准测试中，OmiGraph取得了显著性能提升，平均F1分数提高5.4%，准确率提高5.3%。

Conclusion: 通过考虑信息遗漏的视角，OmiGraph框架在虚假信息检测方面取得了突破性进展，证明了处理基于遗漏的欺骗对于全面虚假信息检测的重要性。

Abstract: This paper investigates the detection of misinformation, which deceives readers by explicitly fabricating misleading content or implicitly omitting important information necessary for informed judgment. While the former has been extensively studied, omission-based deception remains largely overlooked, even though it can subtly guide readers toward false conclusions under the illusion of completeness. To pioneer in this direction, this paper presents OmiGraph, the first omission-aware framework for misinformation detection. Specifically, OmiGraph constructs an omission-aware graph for the target news by utilizing a contextual environment that captures complementary perspectives of the same event, thereby surfacing potentially omitted contents. Based on this graph, omission-oriented relation modeling is then proposed to identify the internal contextual dependencies, as well as the dynamic omission intents, formulating a comprehensive omission relation representation. Finally, to extract omission patterns for detection, OmiGraph introduces omission-aware message-passing and aggregation that establishes holistic deception perception by integrating the omission contents and relations. Experiments show that, by considering the omission perspective, our approach attains remarkable performance, achieving average improvements of +5.4% F1 and +5.3% ACC on two large-scale benchmarks.

</details>


### [40] [OPOR-Bench: Evaluating Large Language Models on Online Public Opinion Report Generation](https://arxiv.org/abs/2512.01896)
*Jinzheng Yu,Yang Xu,Haozhen Li,Junqi Li,Yifan Feng,Ligu Zhu,Hao Shen,Lei Shi*

Main category: cs.CL

TL;DR: 该论文定义了在线舆情报告自动生成任务(OPOR-GEN)，构建了包含463个危机事件的基准数据集OPOR-BENCH，并提出了基于代理的评估框架OPOR-EVAL来模拟专家评估。


<details>
  <summary>Details</summary>
Motivation: 在线舆情报告对政府和企业的危机管理至关重要，虽然大语言模型使自动报告生成成为可能，但该领域缺乏系统研究，特别是正式的任务定义和相应的基准。

Method: 1. 定义OPOR-GEN任务；2. 构建事件中心的OPOR-BENCH数据集，包含463个危机事件及相关新闻、社交媒体帖子和参考摘要；3. 提出OPOR-EVAL评估框架，基于代理模拟人类专家评估。

Result: 实验表明，OPOR-EVAL框架与人类判断具有高度相关性，为前沿模型提供了有效的评估方法。

Conclusion: 该研究通过任务定义、基准数据集和评估框架，为在线舆情报告自动生成这一关键领域的研究奠定了坚实基础。

Abstract: Online Public Opinion Reports consolidate news and social media for timely crisis management by governments and enterprises. While large language models have made automated report generation technically feasible, systematic research in this specific area remains notably absent, particularly lacking formal task definitions and corresponding benchmarks. To bridge this gap, we define the Automated Online Public Opinion Report Generation (OPOR-GEN) task and construct OPOR-BENCH, an event-centric dataset covering 463 crisis events with their corresponding news articles, social media posts, and a reference summary. To evaluate report quality, we propose OPOR-EVAL, a novel agent-based framework that simulates human expert evaluation by analyzing generated reports in context. Experiments with frontier models demonstrate that our framework achieves high correlation with human judgments. Our comprehensive task definition, benchmark dataset, and evaluation framework provide a solid foundation for future research in this critical domain.

</details>


### [41] [Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling](https://arxiv.org/abs/2512.02010)
*Jack Cook,Junxian Guo,Guangxuan Xiao,Yujun Lin,Song Han*

Main category: cs.CL

TL;DR: 本文提出4/6方法改进NVFP4量化算法，通过评估每个数值块的两个缩放因子，减少量化误差，防止训练发散，提升推理性能。


<details>
  <summary>Details</summary>
Motivation: NVFP4等低精度数值格式因速度和内存优势而流行，但要求所有矩阵乘法操作数都量化为NVFP4，常导致训练发散和推理性能下降。浮点格式如FP4的最大量化误差出现在每个块的接近最大值处，这是下游性能下降的主要原因。

Method: 提出Four Over Six (4/6)方法，修改NVFP4量化算法，为每个数值块评估两个潜在的缩放因子。通过缩放到更小的FP4值使可表示值的分布更均匀，从而更好地表示接近最大值的数据。

Result: 4/6可在NVIDIA Blackwell GPU上高效实现。在transformer和混合模型架构的预训练实验中，4/6防止了多种情况下的训练发散，使训练损失显著接近BF16基准。4/6也能轻松集成到多种后训练量化方法中，普遍提升下游精度。

Conclusion: 4/6方法有效解决了NVFP4训练中的发散问题，提升了量化模型的性能，为未来使用NVFP4训练和部署模型提供了新思路。

Abstract: As large language models have grown larger, low-precision numerical formats such as NVFP4 have become increasingly popular due to the speed and memory benefits they provide. However, to accelerate computation with NVFP4, all matrix multiplication operands--weights and activations in the forward pass, and weights, activations, and gradients in the backward pass--must be quantized to NVFP4, often leading to divergence during training and performance degradation during inference. NVFP4 by evaluating multiple potential scale factors for each block of values. To address this issue, in this work we introduce Four Over Six (4/6), a modification to the NVFP4 quantization algorithm that evaluates two potential scale factors for each block of values. Unlike integer formats, floating-point formats such as FP4 have the most quantization error on near-maximal values in each block, which we find to be primarily responsible for downstream performance degradation. We find that for some blocks, scaling to smaller FP4 values makes the distribution of representable values more uniform, improving representation of near-maximal values. Importantly, 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, making it viable to use while training LLMs with NVFP4. In pre-training experiments with transformer and hybrid model architectures, we find that 4/6 prevents divergence in several cases, bringing training loss significantly closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. We also find that 4/6 can be easily incorporated into many different post-training quantization methods and generally improves downstream accuracy. We hope this inspires future work in training and deploying models with NVFP4.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [42] [Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning](https://arxiv.org/abs/2512.00074)
*Qiwei Liang,Boyang Cai,Minghao Lai,Sitong Zhuang,Tao Lin,Yan Qin,Yixuan Ye,Jiaming Liang,Renjing Xu*

Main category: cs.RO

TL;DR: AFRO是一个自监督的3D视觉预训练框架，通过生成扩散过程建模状态预测，联合建模前向和逆向动力学，无需动作或重建监督，显著提升机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D视觉预训练方法在机器人操作任务上表现不佳，主要原因是缺乏状态-动作-状态动态建模，以及显式几何重建带来的不必要冗余。

Method: AFRO将状态预测构建为生成扩散过程，在共享潜在空间中联合建模前向和逆向动力学以捕捉因果转移结构。采用特征差分和逆向一致性监督防止动作学习中的特征泄露。

Result: 与Diffusion Policy结合时，AFRO在16个模拟任务和4个真实世界任务中显著提高操作成功率，优于现有预训练方法，且能随数据量和任务复杂度良好扩展。

Conclusion: AFRO学习到语义丰富、判别性强的特征，为机器人领域的3D表示学习提供了有效的预训练解决方案。

Abstract: Despite strong results on recognition and segmentation, current 3D visual pre-training methods often underperform on robotic manipulation. We attribute this gap to two factors: the lack of state-action-state dynamics modeling and the unnecessary redundancy of explicit geometric reconstruction. We introduce AFRO, a self-supervised framework that learns dynamics-aware 3D representations without action or reconstruction supervision. AFRO casts state prediction as a generative diffusion process and jointly models forward and inverse dynamics in a shared latent space to capture causal transition structure. To prevent feature leakage in action learning, we employ feature differencing and inverse-consistency supervision, improving the quality and stability of visual features. When combined with Diffusion Policy, AFRO substantially increases manipulation success rates across 16 simulated and 4 real-world tasks, outperforming existing pre-training approaches. The framework also scales favorably with data volume and task complexity. Qualitative visualizations indicate that AFRO learns semantically rich, discriminative features, offering an effective pre-training solution for 3D representation learning in robotics. Project page: https://kolakivy.github.io/AFRO/

</details>


### [43] [Visibility-aware Cooperative Aerial Tracking with Decentralized LiDAR-based Swarms](https://arxiv.org/abs/2512.01280)
*Longji Yin,Yunfan Ren,Fangcheng Zhu,Liuyu Shi,Fanze Kong,Benxu Tang,Wenyi Liu,Ximin Lyu,Fu Zhang*

Main category: cs.RO

TL;DR: 提出一种去中心化的LiDAR无人机群目标跟踪框架，通过球形符号距离场(SSDF)表示环境遮挡，结合协同规划实现复杂环境中的可见性感知多无人机目标跟踪。


<details>
  <summary>Details</summary>
Motivation: 单无人机跟踪系统已得到广泛研究，但基于群体的目标跟踪仍未被充分探索。群体系统具有分布式感知、容错冗余和多方向目标覆盖等独特优势，在复杂环境中实现可见性感知的协同跟踪具有重要应用价值。

Method: 1) 提出SSDF-based的3D环境遮挡表示方法及实时更新算法；2) 支持异构LiDAR配置的FOV对齐成本函数；3) 基于静电势启发的分布度量实现3D多方向目标包围；4) 分层规划器结合运动学前端搜索器和时空SE(3)后端优化器生成无碰撞、可见性优化的轨迹。

Result: 在杂乱室外环境中进行真实世界实验验证，系统能够鲁棒地协同跟踪敏捷目标（无人机、人类），并实现优越的可见性维护。完全去中心化实现具有协作感知、分布式规划和动态群体可重构性。

Conclusion: 该研究填补了群体目标跟踪领域的空白，提出的去中心化LiDAR群体跟踪框架在复杂环境中实现了可见性感知的协同目标跟踪，为无人机群体在监视、电影摄影和工业检测等应用提供了有效解决方案。

Abstract: Autonomous aerial tracking with drones offers vast potential for surveillance, cinematography, and industrial inspection applications. While single-drone tracking systems have been extensively studied, swarm-based target tracking remains underexplored, despite its unique advantages of distributed perception, fault-tolerant redundancy, and multidirectional target coverage. To bridge this gap, we propose a novel decentralized LiDAR-based swarm tracking framework that enables visibility-aware, cooperative target tracking in complex environments, while fully harnessing the unique capabilities of swarm systems. To address visibility, we introduce a novel Spherical Signed Distance Field (SSDF)-based metric for 3-D environmental occlusion representation, coupled with an efficient algorithm that enables real-time onboard SSDF updating. A general Field-of-View (FOV) alignment cost supporting heterogeneous LiDAR configurations is proposed for consistent target observation. Swarm coordination is enhanced through cooperative costs that enforce inter-robot safe clearance, prevent mutual occlusions, and notably facilitate 3-D multidirectional target encirclement via a novel electrostatic-potential-inspired distribution metric. These innovations are integrated into a hierarchical planner, combining a kinodynamic front-end searcher with a spatiotemporal $SE(3)$ back-end optimizer to generate collision-free, visibility-optimized trajectories.Deployed on heterogeneous LiDAR swarms, our fully decentralized implementation features collaborative perception, distributed planning, and dynamic swarm reconfigurability. Validated through rigorous real-world experiments in cluttered outdoor environments, the proposed system demonstrates robust cooperative tracking of agile targets (drones, humans) while achieving superior visibility maintenance.

</details>
