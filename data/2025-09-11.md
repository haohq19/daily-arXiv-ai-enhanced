<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities](https://arxiv.org/abs/2509.08003)
*Shahid Shafi Dar,Bharat Kaurav,Arnav Jain,Chandravardhan Singh Raghaw,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

TL;DR: XFloodNet是一个基于深度学习的城市洪水分类框架，通过多模态特征融合和注意力机制，在三个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统洪水检测方法依赖单模态数据和静态规则系统，无法捕捉洪水事件的动态非线性关系，现有注意力机制和集成学习方法在层次细化、跨模态特征集成和对噪声环境的适应性方面存在局限。

Method: 提出XFloodNet框架，包含三个核心组件：层次化跨模态门控注意力机制、异构卷积自适应多尺度注意力模块、以及级联卷积Transformer特征细化技术。

Result: 在Chennai Floods、Rhine18 Floods和Harz17 Floods三个数据集上分别达到93.33%、82.24%和88.60%的F1分数，显著超越现有方法。

Conclusion: XFloodNet通过创新的深度学习技术有效解决了城市洪水分类问题，在多个数据集上表现出卓越性能，为城市洪水检测提供了新的解决方案。

Abstract: In an era of escalating climate change, urban flooding has emerged as a
critical challenge for sustainable cities, threatening lives, infrastructure,
and ecosystems. Traditional flood detection methods are constrained by their
reliance on unimodal data and static rule-based systems, which fail to capture
the dynamic, non-linear relationships inherent in flood events. Furthermore,
existing attention mechanisms and ensemble learning approaches exhibit
limitations in hierarchical refinement, cross-modal feature integration, and
adaptability to noisy or unstructured environments, resulting in suboptimal
flood classification performance. To address these challenges, we present
XFloodNet, a novel framework that redefines urban flood classification through
advanced deep-learning techniques. XFloodNet integrates three novel components:
(1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically
aligns visual and textual features, enabling precise multi-granularity
interactions and resolving contextual ambiguities; (2) a Heterogeneous
Convolutional Adaptive Multi-Scale Attention module, which leverages
frequency-enhanced channel attention and frequency-modulated spatial attention
to extract and prioritize discriminative flood-related features across spectral
and spatial domains; and (3) a Cascading Convolutional Transformer Feature
Refinement technique that harmonizes hierarchical features through adaptive
scaling and cascading operations, ensuring robust and noise-resistant flood
detection. We evaluate our proposed method on three benchmark datasets, such as
Chennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves
state-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively,
surpassing existing methods by significant margins.

</details>


### [2] [Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs](https://arxiv.org/abs/2509.08016)
*Hyungjin Chung,Hyelin Nam,Jiyeon Kim,Hyojun Go,Byeongjun Park,Junho Kim,Joonseok Lee,Seongsu Ha,Byung-Hoon Kim*

Main category: cs.CV

TL;DR: Video Parallel Scaling (VPS) 是一种推理时方法，通过并行处理视频帧子集来扩展VideoLLMs的感知带宽，避免长上下文带来的计算成本问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: VideoLLMs在处理更多输入帧以捕捉细粒度时间细节时面临计算成本过高和长上下文性能下降的瓶颈问题。

Method: VPS通过运行多个并行推理流，每个流处理视频帧的不同子集，然后聚合这些互补流的输出概率来整合更丰富的视觉信息。

Result: 在Video-MME和EventHallusion等基准测试中，VPS在各种模型架构和规模（2B-32B）上均能一致且显著地提升性能，比Self-consistency等其他并行方法更具扩展优势。

Conclusion: VPS提供了一个内存高效且鲁棒的框架，可增强VideoLLMs的时间推理能力，且与其他解码策略互补，无需额外训练即可改善性能。

Abstract: Video Large Language Models (VideoLLMs) face a critical bottleneck:
increasing the number of input frames to capture fine-grained temporal detail
leads to prohibitive computational costs and performance degradation from long
context lengths. We introduce Video Parallel Scaling (VPS), an inference-time
method that expands a model's perceptual bandwidth without increasing its
context window. VPS operates by running multiple parallel inference streams,
each processing a unique, disjoint subset of the video's frames. By aggregating
the output probabilities from these complementary streams, VPS integrates a
richer set of visual information than is possible with a single pass. We
theoretically show that this approach effectively contracts the Chinchilla
scaling law by leveraging uncorrelated visual evidence, thereby improving
performance without additional training. Extensive experiments across various
model architectures and scales (2B-32B) on benchmarks such as Video-MME and
EventHallusion demonstrate that VPS consistently and significantly improves
performance. It scales more favorably than other parallel alternatives (e.g.
Self-consistency) and is complementary to other decoding strategies, offering a
memory-efficient and robust framework for enhancing the temporal reasoning
capabilities of VideoLLMs.

</details>


### [3] [EVDI++: Event-based Video Deblurring and Interpolation via Self-Supervised Learning](https://arxiv.org/abs/2509.08260)
*Chi Zhang,Xiang Zhang,Chenxu Jiang,Gui-Song Xia,Lei Yu*

Main category: cs.CV

TL;DR: EVDI++是一个自监督的事件相机视频去模糊和插值框架，利用事件相机的高时间分辨率来减少运动模糊并预测中间帧，在合成和真实数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统帧相机长曝光时间导致的视觉模糊和信息丢失问题，提升视频质量。

Method: 提出Learnable Double Integral (LDI)网络估计参考帧与清晰潜在图像的映射关系，引入基于学习的除法重建模块优化结果，采用自适应无参数融合策略，构建自监督学习框架。

Result: 在合成和真实数据集上的大量实验表明，该方法在视频去模糊和插值任务中达到了最先进的性能。

Conclusion: EVDI++框架通过有效利用事件相机的高时间分辨率，成功解决了视频模糊和帧间信息丢失的问题，具有很好的泛化能力。

Abstract: Frame-based cameras with extended exposure times often produce perceptible
visual blurring and information loss between frames, significantly degrading
video quality. To address this challenge, we introduce EVDI++, a unified
self-supervised framework for Event-based Video Deblurring and Interpolation
that leverages the high temporal resolution of event cameras to mitigate motion
blur and enable intermediate frame prediction. Specifically, the Learnable
Double Integral (LDI) network is designed to estimate the mapping relation
between reference frames and sharp latent images. Then, we refine the coarse
results and optimize overall training efficiency by introducing a
learning-based division reconstruction module, enabling images to be converted
with varying exposure intervals. We devise an adaptive parameter-free fusion
strategy to obtain the final results, utilizing the confidence embedded in the
LDI outputs of concurrent events. A self-supervised learning framework is
proposed to enable network training with real-world blurry videos and events by
exploring the mutual constraints among blurry frames, latent images, and event
streams. We further construct a dataset with real-world blurry images and
events using a DAVIS346c camera, demonstrating the generalizability of the
proposed EVDI++ in real-world scenarios. Extensive experiments on both
synthetic and real-world datasets show that our method achieves
state-of-the-art performance in video deblurring and interpolation tasks.

</details>


### [4] [Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification at Test Time](https://arxiv.org/abs/2509.08436)
*Xia Yue,Anfeng Liu,Ning Chen,Chenjia Huang,Hui Liu,Zhou Huang,Leyuan Fang*

Main category: cs.CV

TL;DR: 提出了HyperTTA框架，通过多退化数据集、光谱-空间Transformer分类器和轻量级测试时自适应策略，显著提升了高光谱图像分类模型在各种退化条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类模型对噪声、模糊、压缩和大气效应等现实世界退化引起的分布偏移高度敏感，需要提高模型在多样化退化条件下的鲁棒性。

Method: 构建多退化高光谱数据集；设计光谱-空间Transformer分类器（SSTC）结合多级感受野机制和标签平滑正则化；提出置信度感知熵最小化LayerNorm适配器（CELA）进行轻量级测试时自适应。

Result: 在两个基准数据集上的广泛实验表明，HyperTTA在各种退化场景下均优于现有基线方法，验证了其分类主干和TTA方案的有效性。

Conclusion: HyperTTA框架通过系统性的数据集构建、先进的分类器设计和轻量级自适应策略，成功解决了高光谱图像分类在退化条件下的鲁棒性问题，为实际应用提供了有效解决方案。

Abstract: Hyperspectral image (HSI) classification models are highly sensitive to
distribution shifts caused by various real-world degradations such as noise,
blur, compression, and atmospheric effects. To address this challenge, we
propose HyperTTA, a unified framework designed to enhance model robustness
under diverse degradation conditions. Specifically, we first construct a
multi-degradation hyperspectral dataset that systematically simulates nine
representative types of degradations, providing a comprehensive benchmark for
robust classification evaluation. Based on this, we design a spectral-spatial
transformer classifier (SSTC) enhanced with a multi-level receptive field
mechanism and label smoothing regularization to jointly capture multi-scale
spatial context and improve generalization. Furthermore, HyperTTA incorporates
a lightweight test-time adaptation (TTA) strategy, the confidence-aware
entropy-minimized LayerNorm adapter (CELA), which updates only the affine
parameters of LayerNorm layers by minimizing prediction entropy on
high-confidence unlabeled target samples. This confidence-aware adaptation
prevents unreliable updates from noisy predictions, enabling robust and dynamic
adaptation without access to source data or target annotations. Extensive
experiments on two benchmark datasets demonstrate that HyperTTA outperforms
existing baselines across a wide range of degradation scenarios, validating the
effectiveness of both its classification backbone and the proposed TTA scheme.
Code will be made available publicly.

</details>


### [5] [Quantifying Accuracy of an Event-Based Star Tracker via Earth's Rotation](https://arxiv.org/abs/2509.08794)
*Dennis Melamed,Connor Hashemi,Scott McCloskey*

Main category: cs.CV

TL;DR: 事件相机在星迹踪系统中的精度分析，利用地球自转作为真实值对比，达到18.47秒的RMS锐差精度


<details>
  <summary>Details</summary>
Motivation: 解决事件相机在星迹踪中缺乏准确真实值的问题，利用地球规律运动作为参考标准

Method: 通过静态放置事件相机针对夜空，以地球自转作为唯一相机运动来源，将事件流处理生成方向估计

Result: 系统达到均方根锐差18.47秒，绝对锐差78.84秒的精度水平，显示了事件相机在星迹踪中的应用潜力

Conclusion: 事件相机具备低成本、低延迟、高动态范围等优势，该精度水平证明其适合用于实用化的星迹踪系统

Abstract: Event-based cameras (EBCs) are a promising new technology for star
tracking-based attitude determination, but prior studies have struggled to
determine accurate ground truth for real data. We analyze the accuracy of an
EBC star tracking system utilizing the Earth's motion as the ground truth for
comparison. The Earth rotates in a regular way with very small irregularities
which are measured to the level of milli-arcseconds. By keeping an event camera
static and pointing it through a ground-based telescope at the night sky, we
create a system where the only camera motion in the celestial reference frame
is that induced by the Earth's rotation. The resulting event stream is
processed to generate estimates of orientation which we compare to the
International Earth Rotation and Reference System (IERS) measured orientation
of the Earth. The event camera system is able to achieve a root mean squared
across error of 18.47 arcseconds and an about error of 78.84 arcseconds.
Combined with the other benefits of event cameras over framing sensors (reduced
computation due to sparser data streams, higher dynamic range, lower energy
consumption, faster update rates), this level of accuracy suggests the utility
of event cameras for low-cost and low-latency star tracking. We provide all
code and data used to generate our results:
https://gitlab.kitware.com/nest-public/telescope_accuracy_quantification.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital](https://arxiv.org/abs/2509.08140)
*Mihir Kumar,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Afriyie Kwesi Samuel,Fuat Alican,Yigit Ihlamur*

Main category: cs.LG

TL;DR: 提出一个结合大语言模型和多模型机器学习架构的框架，用于预测罕见高影响事件，在风险投资领域实现了9.8-11.1倍于随机基线的精确度。


<details>
  <summary>Details</summary>
Motivation: 解决风险投资中早期阶段数据有限且嘈杂的情况下，预测初创公司成功概率的挑战，需要结合黑盒模型的预测能力和可解释性决策需求。

Method: 使用LLM驱动的特征工程从非结构化数据中提取复杂信号，构建包含XGBoost、随机森林和线性回归的分层集成模型，首先生成连续的成功概率估计，然后通过阈值处理产生二元罕见事件预测。

Result: 模型在三个独立测试子集上实现了9.8-11.1倍于随机分类器基线的精确度。特征敏感性分析显示：初创公司类别列表占预测影响力的15.6%，创始人数量次之，教育水平和领域专业知识贡献较小但一致的影响。

Conclusion: 该框架成功整合了LLM和多模型ML架构，在罕见高影响事件预测方面表现出色，同时提供了可解释的成功驱动因素，为风险投资决策提供了可靠支持。

Abstract: This paper presents a framework for predicting rare, high-impact outcomes by
integrating large language models (LLMs) with a multi-model machine learning
(ML) architecture. The approach combines the predictive strength of black-box
models with the interpretability required for reliable decision-making. We use
LLM-powered feature engineering to extract and synthesize complex signals from
unstructured data, which are then processed within a layered ensemble of models
including XGBoost, Random Forest, and Linear Regression. The ensemble first
produces a continuous estimate of success likelihood, which is then thresholded
to produce a binary rare-event prediction. We apply this framework to the
domain of Venture Capital (VC), where investors must evaluate startups with
limited and noisy early-stage data. The empirical results show strong
performance: the model achieves precision between 9.8X and 11.1X the random
classifier baseline in three independent test subsets. Feature sensitivity
analysis further reveals interpretable success drivers: the startup's category
list accounts for 15.6% of predictive influence, followed by the number of
founders, while education level and domain expertise contribute smaller yet
consistent effects.

</details>


### [7] [Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics](https://arxiv.org/abs/2509.08461)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 视觉语言模型(VLMs)在识别高能物理实验中的中微子相互作用方面表现优于传统卷积神经网络(CNN)，同时提供更好的可解释性和多模态推理能力


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在处理结构化数据方面的能力，特别是将视觉语言模型应用于高能物理实验中的中微子相互作用识别任务

Method: 使用微调后的LLaMa 3.2视觉语言模型，与NOvA和DUNE实验中使用的先进卷积神经网络架构进行基准测试比较

Result: VLMs在分类性能上超越CNNs，同时提供更好的可解释性、灵活性以及基于推理的预测能力

Conclusion: VLMs有潜力成为物理事件分类的通用骨干网络，因其高性能、可解释性和泛化能力，为中微子物理实验中的多模态推理开辟了新途径

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated their
remarkable capacity to process and reason over structured and unstructured data
modalities beyond natural language. In this work, we explore the applications
of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa
3.2, to the task of identifying neutrino interactions in pixelated detector
data from high-energy physics (HEP) experiments. We benchmark this model
against a state-of-the-art convolutional neural network (CNN) architecture,
similar to those used in the NOvA and DUNE experiments, which have achieved
high efficiency and purity in classifying electron and muon neutrino events.
Our evaluation considers both the classification performance and
interpretability of the model predictions. We find that VLMs can outperform
CNNs, while also providing greater flexibility in integrating auxiliary textual
or semantic information and offering more interpretable, reasoning-based
predictions. This work highlights the potential of VLMs as a general-purpose
backbone for physics event classification, due to their high performance,
interpretability, and generalizability, which opens new avenues for integrating
multimodal reasoning in experimental neutrino physics.

</details>


### [8] [SHAining on Process Mining: Explaining Event Log Characteristics Impact on Algorithms](https://arxiv.org/abs/2509.08482)
*Andrea Maldonado,Christian M. M. Frey,Sai Anirudh Aryasomayajula,Ludwig Zellner,Stephan A. Fahrenkrog-Petersen,Thomas Seidl*

Main category: cs.LG

TL;DR: SHAining方法首次量化事件日志特征对流程挖掘算法指标的边际贡献，通过分析22,000多个事件日志发现特征对算法性能的影响，并评估算法鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常在固定的事件日志集上评估算法，缺乏对事件日志特征如何单独影响算法的系统性分析，且忽视了特征共现对评估指标的影响。

Method: 提出SHAining方法，使用流程发现作为下游任务，分析超过22,000个覆盖广泛特征的事件日志，量化事件日志特征对算法指标的边际贡献。

Result: 揭示了哪些事件日志特征对算法指标（如拟合度、精确度、复杂度）影响最大，并提供了特征值与贡献影响相关性的新见解。

Conclusion: SHAining方法能够系统评估事件日志特征对流程挖掘算法性能的影响，为算法选择和评估提供了更全面的分析框架。

Abstract: Process mining aims to extract and analyze insights from event logs, yet
algorithm metric results vary widely depending on structural event log
characteristics. Existing work often evaluates algorithms on a fixed set of
real-world event logs but lacks a systematic analysis of how event log
characteristics impact algorithms individually. Moreover, since event logs are
generated from processes, where characteristics co-occur, we focus on
associational rather than causal effects to assess how strong the overlapping
individual characteristic affects evaluation metrics without assuming isolated
causal effects, a factor often neglected by prior work. We introduce SHAining,
the first approach to quantify the marginal contribution of varying event log
characteristics to process mining algorithms' metrics. Using process discovery
as a downstream task, we analyze over 22,000 event logs covering a wide span of
characteristics to uncover which affect algorithms across metrics (e.g.,
fitness, precision, complexity) the most. Furthermore, we offer novel insights
about how the value of event log characteristics correlates with their
contributed impact, assessing the algorithm's robustness.

</details>


### [9] [A layered architecture for log analysis in complex IT systems](https://arxiv.org/abs/2509.08698)
*Thorsten Wittkopp*

Main category: cs.LG

TL;DR: 本文提出了一个三层次架构来支持DevOps团队进行故障解决，包括日志调查、异常检测和根因分析三个关键层面。


<details>
  <summary>Details</summary>
Motivation: 体系复杂性增加给DevOps团队带来了维护挑战，日志分析作为AIOps的核心元素，需要提供更有效的故障解决方案。

Method: 采用三层架构：1)日志调查层-自主日志标注和异常分类；2)异常检测层-适用于无监督、弱监督和有监督训练的灵活方法；3)根因分析层-识别描述故障的最小日志集。

Result: 异常检测在公共和行业数据集上达到F1分数0.98-1.0；根因分析在top10候选中检测到90-98%的根因日志行。

Conclusion: 通过集成三个关键层面，该架构为DevOps团队提供了坚固的方法来提高IT系统的可靠性和故障解决效率。

Abstract: In the evolving IT landscape, stability and reliability of systems are
essential, yet their growing complexity challenges DevOps teams in
implementation and maintenance. Log analysis, a core element of AIOps, provides
critical insights into complex behaviors and failures. This dissertation
introduces a three-layered architecture to support DevOps in failure
resolution. The first layer, Log Investigation, performs autonomous log
labeling and anomaly classification. We propose a method that labels log data
without manual effort, enabling supervised training and precise evaluation of
anomaly detection. Additionally, we define a taxonomy that groups anomalies
into three categories, ensuring appropriate method selection. The second layer,
Anomaly Detection, detects behaviors deviating from the norm. We propose a
flexible Anomaly Detection method adaptable to unsupervised, weakly supervised,
and supervised training. Evaluations on public and industry datasets show
F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third
layer, Root Cause Analysis, identifies minimal log sets describing failures,
their origin, and event sequences. By balancing training data and identifying
key services, our Root Cause Analysis method consistently detects 90-98% of
root cause log lines within the top 10 candidates, providing actionable
insights for mitigation. Our research addresses how log analysis methods can be
designed and optimized to help DevOps resolve failures efficiently. By
integrating these three layers, the architecture equips teams with robust
methods to enhance IT system reliability.

</details>


### [10] [A Survey of TinyML Applications in Beekeeping for Hive Monitoring and Management](https://arxiv.org/abs/2509.08822)
*Willy Sucipto,Jianlong Zhou,Ray Seung Min Kwon,Fang Chen*

Main category: cs.LG

TL;DR: 这篇综述论文系统梳理了TinyML技术在养蜂业中的应用，重点关注蜂群条件监测、蜜蜂行为识别、病虫害检测和分蜂预测四个功能领域，为可持续传粉媒介管理提供AI驱动的监测系统基础。


<details>
  <summary>Details</summary>
Motivation: 传统蜂箱检查方式劳动密集且具有干扰性，而基于云的监控方案在偏远或资源有限的养蜂场不实用。物联网和微型机器学习技术的发展为低功耗、实时边缘监控提供了可行的替代方案。

Method: 通过综述分析的方法，围绕四个关键功能领域（蜂群条件监测、蜜蜂行为识别、病虫害检测、分蜂预测）系统梳理TinyML在养蜂业中的创新应用，并考察相关数据集、轻量级模型架构和基准测试策略。

Result: 识别了当前研究的关键局限性，包括数据稀缺、泛化挑战以及在离网环境中的部署障碍，同时指出了超高效推理管道、自适应边缘学习和数据集标准化等新兴机遇。

Conclusion: 通过整合研究和工程实践，这项工作为构建可扩展、AI驱动且生态信息化的监测系统奠定了基础，有助于支持可持续的传粉媒介管理。

Abstract: Honey bee colonies are essential for global food security and ecosystem
stability, yet they face escalating threats from pests, diseases, and
environmental stressors. Traditional hive inspections are labor-intensive and
disruptive, while cloud-based monitoring solutions remain impractical for
remote or resource-limited apiaries. Recent advances in Internet of Things
(IoT) and Tiny Machine Learning (TinyML) enable low-power, real-time monitoring
directly on edge devices, offering scalable and non-invasive alternatives. This
survey synthesizes current innovations at the intersection of TinyML and
apiculture, organized around four key functional areas: monitoring hive
conditions, recognizing bee behaviors, detecting pests and diseases, and
forecasting swarming events. We further examine supporting resources, including
publicly available datasets, lightweight model architectures optimized for
embedded deployment, and benchmarking strategies tailored to field constraints.
Critical limitations such as data scarcity, generalization challenges, and
deployment barriers in off-grid environments are highlighted, alongside
emerging opportunities in ultra-efficient inference pipelines, adaptive edge
learning, and dataset standardization. By consolidating research and
engineering practices, this work provides a foundation for scalable, AI-driven,
and ecologically informed monitoring systems to support sustainable pollinator
management.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs](https://arxiv.org/abs/2509.08000)
*Debdeep Sanyal,Manodeep Ray,Murari Mandal*

Main category: cs.CL

TL;DR: AntiDote是一种双层优化方法，通过对抗性超网络训练LLM抵抗恶意微调攻击，在保持模型能力的同时显著提升安全性


<details>
  <summary>Details</summary>
Motivation: 开源权重LLM面临恶意微调生成有害内容的风险，现有安全措施难以在保持通用能力的同时抵抗拥有完整模型访问权限的对手

Method: 使用辅助对抗性超网络生成恶意LoRA权重，通过双层优化训练防御模型来抵消这些对抗性权重的影响，保持安全对齐

Result: 在52种红队攻击测试中，AntiDote比基准方法强27.4%，在MMLU等能力基准上性能下降小于0.5%

Conclusion: 该方法为构建安全性更强、计算高效的开源权重模型提供了实用方案

Abstract: The release of open-weight large language models (LLMs) creates a tension
between advancing accessible research and preventing misuse, such as malicious
fine-tuning to elicit harmful content. Current safety measures struggle to
preserve the general capabilities of the LLM while resisting a determined
adversary with full access to the model's weights and architecture, who can use
full-parameter fine-tuning to erase existing safeguards. To address this, we
introduce AntiDote, a bi-level optimization procedure for training LLMs to be
resistant to such tampering. AntiDote involves an auxiliary adversary
hypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA)
weights conditioned on the defender model's internal activations. The defender
LLM is then trained with an objective to nullify the effect of these
adversarial weight additions, forcing it to maintain its safety alignment. We
validate this approach against a diverse suite of 52 red-teaming attacks,
including jailbreak prompting, latent space manipulation, and direct
weight-space attacks. AntiDote is upto 27.4\% more robust against adversarial
attacks compared to both tamper-resistance and unlearning baselines. Crucially,
this robustness is achieved with a minimal trade-off in utility, incurring a
performance degradation of upto less than 0.5\% across capability benchmarks
including MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute
efficient methodology for building open-weight models where safety is a more
integral and resilient property.

</details>


### [12] [Bias after Prompting: Persistent Discrimination in Large Language Models](https://arxiv.org/abs/2509.08146)
*Nivedha Sivakumar,Natalie Mackraz,Samira Khorshidi,Krishna Patel,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: 研究发现偏见可以通过提示从预训练大语言模型转移到适应模型，现有提示去偏方法无法一致防止偏见转移，纠正内在模型偏见可能防止偏见传播到下游任务


<details>
  <summary>Details</summary>
Motivation: 先前关于偏见转移假设的研究可能错误地认为偏见不会从预训练LLM转移到适应模型，需要验证在提示适应场景下的偏见转移情况

Method: 研究因果模型在提示适应下的偏见转移，评估不同少样本组合参数（样本大小、刻板内容、职业分布等）的影响，测试多种提示去偏策略

Result: 偏见通过提示转移的相关性很强（性别ρ≥0.94，年龄ρ≥0.98，宗教ρ≥0.69），改变少样本参数后偏见仍强相关（ρ≥0.90），现有去偏方法无法一致减少偏见转移

Conclusion: 纠正内在模型的偏见可能防止偏见传播到下游任务，需要开发更有效的偏见缓解方法

Abstract: A dangerous assumption that can be made from prior work on the bias transfer
hypothesis (BTH) is that biases do not transfer from pre-trained large language
models (LLMs) to adapted models. We invalidate this assumption by studying the
BTH in causal models under prompt adaptations, as prompting is an extremely
popular and accessible adaptation strategy used in real-world applications. In
contrast to prior work, we find that biases can transfer through prompting and
that popular prompt-based mitigation methods do not consistently prevent biases
from transferring. Specifically, the correlation between intrinsic biases and
those after prompt adaptation remain moderate to strong across demographics and
tasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age
(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we
find that biases remain strongly correlated when varying few-shot composition
parameters, such as sample size, stereotypical content, occupational
distribution and representational balance (rho >= 0.90). We evaluate several
prompt-based debiasing strategies and find that different approaches have
distinct strengths, but none consistently reduce bias transfer across models,
tasks or demographics. These results demonstrate that correcting bias, and
potentially improving reasoning ability, in intrinsic models may prevent
propagation of biases to downstream tasks.

</details>


### [13] [Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications](https://arxiv.org/abs/2509.08604)
*Anran Li,Lingfei Qian,Mengmeng Du,Yu Yin,Yan Hu,Zihao Sun,Yihang Fu,Erica Stutz,Xuguang Ai,Qianqian Xie,Rui Zhu,Jimin Huang,Yifan Yang,Siru Liu,Yih-Chung Tham,Lucila Ohno-Machado,Hyunghoon Cho,Zhiyong Lu,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 这篇论文首次系统评估了大语言模型在医学领域的记忆问题，发现记忆现象比普通领域更为普遍且可分为有益、无信息和有害三类。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在医学领域应用广泛，但关于模型记忆医学训练数据的程度仍是个关键问题，需要系统评估其普遍性、特征、量级和影响。

Method: 系统分析了三种常见适配场景：医学语料续预训练、标准医学测试集细调、真实临床数据细调（包含超13,000份病人记录）。

Result: 记忆现象在所有适配场景中都很普遍，显著高于普通领域。可分为三类：有益记忆（临床指南等）、无信息记忆（模板化语言）、有害记忆（敏感临床信息）。

Conclusion: 提出实践建议：促进有益记忆提升领域知识准确性，减少无信息记忆促进深度学习，减轻有害记忆防止敏感信息泄漏。

Abstract: Large Language Models (LLMs) have demonstrated significant potential in
medicine. To date, LLMs have been widely applied to tasks such as diagnostic
assistance, medical question answering, and clinical information synthesis.
However, a key open question remains: to what extent do LLMs memorize medical
training data. In this study, we present the first comprehensive evaluation of
memorization of LLMs in medicine, assessing its prevalence (how frequently it
occurs), characteristics (what is memorized), volume (how much content is
memorized), and potential downstream impacts (how memorization may affect
medical applications). We systematically analyze common adaptation scenarios:
(1) continued pretraining on medical corpora, (2) fine-tuning on standard
medical benchmarks, and (3) fine-tuning on real-world clinical data, including
over 13,000 unique inpatient records from Yale New Haven Health System. The
results demonstrate that memorization is prevalent across all adaptation
scenarios and significantly higher than reported in the general domain.
Memorization affects both the development and adoption of LLMs in medicine and
can be categorized into three types: beneficial (e.g., accurate recall of
clinical guidelines and biomedical references), uninformative (e.g., repeated
disclaimers or templated medical document language), and harmful (e.g.,
regeneration of dataset-specific or sensitive clinical content). Based on these
findings, we offer practical recommendations to facilitate beneficial
memorization that enhances domain-specific reasoning and factual accuracy,
minimize uninformative memorization to promote deeper learning beyond
surface-level patterns, and mitigate harmful memorization to prevent the
leakage of sensitive or identifiable patient information.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [Deep Visual Odometry for Stereo Event Cameras](https://arxiv.org/abs/2509.08235)
*Sheng Zhong,Junkai Niu,Yi Zhou*

Main category: cs.RO

TL;DR: 基于深度学习的双目事件视觉量距系统Stereo-DEVO，通过静态双目关联策略和紧耦合束优化，实现了高精度实时位估计，在夜间HDR场景中也能稳定工作。


<details>
  <summary>Details</summary>
Motivation: 传统手工编程的事件视觉量距方法在低光HDR条件下可靠性不足，需要深度学习方法来应对动态范围大、信噪比变化的挑战。

Method: 提出Stereo-DEVO系统：1)新题高效静态双目关联策略进行稀疏深度估计；2)紧耦合束优化方案；3)利用循环网络通过voxel基事件表示进行光流估计和片区关联。

Result: 系统能够实时处理VGA分辨率的事件数据，在多个公开数据集和自收集数据上表现優秀，性能超过现有最先进事件量距方法，特别是在大规模夜间HDR场景中仍能稳定工作。

Conclusion: Stereo-DEVO系统通过深度学习方法有效解决了事件视觉量距在极端HDR条件下的可靠性问题，为野外机器人应用提供了可靠的实时位置估计能力。

Abstract: Event-based cameras are bio-inspired sensors with pixels that independently
and asynchronously respond to brightness changes at microsecond resolution,
offering the potential to handle state estimation tasks involving motion blur
and high dynamic range (HDR) illumination conditions. However, the versatility
of event-based visual odometry (VO) relying on handcrafted data association
(either direct or indirect methods) is still unreliable, especially in field
robot applications under low-light HDR conditions, where the dynamic range can
be enormous and the signal-to-noise ratio is spatially-and-temporally varying.
Leveraging deep neural networks offers new possibilities for overcoming these
challenges. In this paper, we propose a learning-based stereo event visual
odometry. Building upon Deep Event Visual Odometry (DEVO), our system (called
Stereo-DEVO) introduces a novel and efficient static-stereo association
strategy for sparse depth estimation with almost no additional computational
burden. By integrating it into a tightly coupled bundle adjustment (BA)
optimization scheme, and benefiting from the recurrent network's ability to
perform accurate optical flow estimation through voxel-based event
representations to establish reliable patch associations, our system achieves
high-precision pose estimation in metric scale. In contrast to the offline
performance of DEVO, our system can process event data of \zs{Video Graphics
Array} (VGA) resolution in real time. Extensive evaluations on multiple public
real-world datasets and self-collected data justify our system's versatility,
demonstrating superior performance compared to state-of-the-art event-based VO
methods. More importantly, our system achieves stable pose estimation even in
large-scale nighttime HDR scenarios.

</details>


### [15] [Dual-Stage Safe Herding Framework for Adversarial Attacker in Dynamic Environment](https://arxiv.org/abs/2509.08460)
*Wenqing Wang,Ye Zhang,Haoyu Li,Jingyu Wang*

Main category: cs.RO

TL;DR: 提出基于可达性博弈和局部运动规划的层次混合框架，用于在动态环境中安全引导对抗性智能体远离保护区并进入安全区域


<details>
  <summary>Details</summary>
Motivation: 传统固定编队的牧群方法在城市和障碍物丰富的场景中效果不佳且风险高，特别是在面对具有未知和自适应行为的对抗性智能体时

Method: 基于可达性博弈理论和局部运动规划的层次混合框架，包含虚拟遏制边界和事件触发的追逐机制，实现可扩展和鲁棒的多智能体协调

Result: 仿真结果表明所提出的方法能够安全高效地将对抗性智能体引导到指定区域

Conclusion: 该框架为解决复杂操作环境中对抗性智能体的安全引导问题提供了有效的解决方案

Abstract: Recent advances in robotics have enabled the widespread deployment of
autonomous robotic systems in complex operational environments, presenting both
unprecedented opportunities and significant security problems. Traditional
shepherding approaches based on fixed formations are often ineffective or risky
in urban and obstacle-rich scenarios, especially when facing adversarial agents
with unknown and adaptive behaviors. This paper addresses this challenge as an
extended herding problem, where defensive robotic systems must safely guide
adversarial agents with unknown strategies away from protected areas and into
predetermined safe regions, while maintaining collision-free navigation in
dynamic environments. We propose a hierarchical hybrid framework based on
reach-avoid game theory and local motion planning, incorporating a virtual
containment boundary and event-triggered pursuit mechanisms to enable scalable
and robust multi-agent coordination. Simulation results demonstrate that the
proposed approach achieves safe and efficient guidance of adversarial agents to
designated regions.

</details>


### [16] [FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast Marching Tree for Dynamic Replanning](https://arxiv.org/abs/2509.08521)
*Soheil Espahbodini Nia*

Main category: cs.RO

TL;DR: FMT^x是Fast Marching Tree算法的扩展版本，能够在动态环境中进行高效重规划，通过最小化修改保持渐进最优性和计算效率


<details>
  <summary>Details</summary>
Motivation: 动态环境中的路径规划是机器人技术核心挑战，传统FMT*算法单次规划无法适应实时变化，而完全重规划计算成本过高

Method: 修改FMT*的邻居选择规则，维护成本排序的优先队列，应用选择性更新条件来识别和重新评估潜在次优路径的节点

Result: FMT^x在动态事件中反应更迅速，计算开销更低，优于有影响力的重规划器RRT^x

Conclusion: FMT^x为不可预测环境中的实时机器人导航提供了更有效的解决方案，保持了FMT*的效率同时实现鲁棒适应性

Abstract: Path planning in dynamic environments remains a core challenge in robotics,
especially as autonomous systems are deployed in unpredictable spaces such as
warehouses and public roads. While algorithms like Fast Marching Tree
(FMT$^{*}$) offer asymptotically optimal solutions in static settings, their
single-pass design prevents path revisions which are essential for real-time
adaptation. On the other hand, full replanning is often too computationally
expensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching
Tree algorithm that enables efficient and consistent replanning in dynamic
environments. We revisit the neighbor selection rule of FMT$^{*}$ and
demonstrate that a minimal change overcomes its single-pass limitation,
enabling the algorithm to update cost-to-come values upon discovering better
connections without sacrificing asymptotic optimality or computational
efficiency. By maintaining a cost-ordered priority queue and applying a
selective update condition that uses an expanding neighbor to identify and
trigger the re-evaluation of any node with a potentially suboptimal path,
FMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the
environment evolves. This targeted strategy preserves the inherent efficiency
of FMT$^{*}$ while enabling robust adaptation to changes in obstacle
configuration. FMT$^{x}$ is proven to recover an asymptotically optimal
solution after environmental changes. Experimental results demonstrate that
FMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more
swiftly to dynamic events with lower computational overhead and thus offering a
more effective solution for real-time robotic navigation in unpredictable
worlds.

</details>
