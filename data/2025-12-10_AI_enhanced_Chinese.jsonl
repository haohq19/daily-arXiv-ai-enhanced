{"id": "2512.07844", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07844", "abs": "https://arxiv.org/abs/2512.07844", "authors": ["Jinping Wang", "Zhiqiang Gao", "Zhiwu Xie"], "title": "Space Alignment Matters: The Missing Piece for Inducing Neural Collapse in Long-Tailed Learning", "comment": null, "summary": "Recent studies on Neural Collapse (NC) reveal that, under class-balanced conditions, the class feature means and classifier weights spontaneously align into a simplex equiangular tight frame (ETF). In long-tailed regimes, however, severe sample imbalance tends to prevent the emergence of the NC phenomenon, resulting in poor generalization performance. Current efforts predominantly seek to recover the ETF geometry by imposing constraints on features or classifier weights, yet overlook a critical problem: There is a pronounced misalignment between the feature and the classifier weight spaces. In this paper, we theoretically quantify the harm of such misalignment through an optimal error exponent analysis. Built on this insight, we propose three explicit alignment strategies that plug-and-play into existing long-tail methods without architectural change. Extensive experiments on the CIFAR-10-LT, CIFAR-100-LT, and ImageNet-LT datasets consistently boost examined baselines and achieve the state-of-the-art performances.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u957f\u5c3e\u5206\u5e03\u4e2d\u795e\u7ecf\u574d\u7f29\u73b0\u8c61\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u7279\u5f81\u4e0e\u5206\u7c7b\u5668\u6743\u91cd\u7a7a\u95f4\u5bf9\u9f50\u6765\u63d0\u5347\u6027\u80fd\uff0c\u65e0\u9700\u6539\u53d8\u7f51\u7edc\u67b6\u6784\u3002", "motivation": "\u5728\u957f\u5c3e\u6570\u636e\u5206\u5e03\u4e2d\uff0c\u6837\u672c\u4e0d\u5e73\u8861\u963b\u788d\u4e86\u795e\u7ecf\u574d\u7f29\u73b0\u8c61\u7684\u51fa\u73b0\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6062\u590dETF\u51e0\u4f55\u7ed3\u6784\uff0c\u4f46\u5ffd\u89c6\u4e86\u7279\u5f81\u7a7a\u95f4\u4e0e\u5206\u7c7b\u5668\u6743\u91cd\u7a7a\u95f4\u4e4b\u95f4\u7684\u4e25\u91cd\u9519\u4f4d\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6700\u4f18\u8bef\u5dee\u6307\u6570\u5206\u6790\u7406\u8bba\u91cf\u5316\u9519\u4f4d\u7684\u5371\u5bb3\uff0c\u63d0\u51fa\u4e09\u79cd\u5373\u63d2\u5373\u7528\u7684\u663e\u5f0f\u5bf9\u9f50\u7b56\u7565\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u73b0\u6709\u957f\u5c3e\u5b66\u4e60\u65b9\u6cd5\u800c\u4e0d\u9700\u8981\u6539\u53d8\u7f51\u7edc\u67b6\u6784\u3002", "result": "\u5728CIFAR-10-LT\u3001CIFAR-100-LT\u548cImageNet-LT\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6301\u7eed\u63d0\u5347\u57fa\u7ebf\u6027\u80fd\uff0c\u5e76\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u7279\u5f81\u4e0e\u5206\u7c7b\u5668\u6743\u91cd\u7a7a\u95f4\u7684\u5bf9\u9f50\u5bf9\u4e8e\u957f\u5c3e\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff0c\u63d0\u51fa\u7684\u5373\u63d2\u5373\u7528\u5bf9\u9f50\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u957f\u5c3e\u5206\u5e03\u4e2d\u7684\u795e\u7ecf\u574d\u7f29\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.08147", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08147", "abs": "https://arxiv.org/abs/2512.08147", "authors": ["Henry Anand Septian Radityo", "Bernardus Willson", "Reynard Tanadi", "Latifa Dwiyanti", "Saiful Akbar"], "title": "Scalable Back-End for an AI-Based Diabetes Prediction Application", "comment": "This paper was accepted and presented at the 2025 IEEE International Conference on Data and Software Engineering (ICoDSE) on 28 October 2025 in Batam, Indonesia, and is currently awaiting publication", "summary": "The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While AI-powered prediction applications offer a promising solution, they require a responsive and scalable back-end architecture to serve a large user base effectively. This paper details the development and evaluation of a scalable back-end system designed for a mobile diabetes prediction application. The primary objective was to maintain a failure rate below 5% and an average latency of under 1000 ms. The architecture leverages horizontal scaling, database sharding, and asynchronous communication via a message queue. Performance evaluation showed that 83% of the system's features (20 out of 24) met the specified performance targets. Key functionalities such as user profile management, activity tracking, and read-intensive prediction operations successfully achieved the desired performance. The system demonstrated the ability to handle up to 10,000 concurrent users without issues, validating its scalability. The implementation of asynchronous communication using RabbitMQ proved crucial in minimizing the error rate for computationally intensive prediction requests, ensuring system reliability by queuing requests and preventing data loss under heavy load.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u7cd6\u5c3f\u75c5\u9884\u6d4b\u79fb\u52a8\u5e94\u7528\u7684\u6269\u5c55\u6027\u540e\u7aef\u7cfb\u7edf\uff0c\u91c7\u7528\u6c34\u5e73\u6269\u5c55\u3001\u6570\u636e\u5e93\u5206\u7247\u548c\u6d88\u606f\u961f\u5217\u5f02\u6b65\u901a\u4fe1\uff0c83%\u529f\u80fd\u8fbe\u5230\u6027\u80fd\u76ee\u6807\uff0c\u652f\u63011\u4e07\u5e76\u53d1\u7528\u6237\u3002", "motivation": "\u5168\u7403\u7cd6\u5c3f\u75c5\u60a3\u75c5\u7387\u4e0a\u5347\u9700\u8981\u65e9\u671f\u68c0\u6d4b\uff0cAI\u9884\u6d4b\u5e94\u7528\u9700\u8981\u54cd\u5e94\u8fc5\u901f\u4e14\u53ef\u6269\u5c55\u7684\u540e\u7aef\u67b6\u6784\u6765\u670d\u52a1\u5927\u89c4\u6a21\u7528\u6237\u7fa4\u3002", "method": "\u91c7\u7528\u6c34\u5e73\u6269\u5c55\u3001\u6570\u636e\u5e93\u5206\u7247\u548c\u901a\u8fc7\u6d88\u606f\u961f\u5217\uff08RabbitMQ\uff09\u7684\u5f02\u6b65\u901a\u4fe1\u67b6\u6784\uff0c\u8bbe\u8ba1\u53ef\u6269\u5c55\u7684\u540e\u7aef\u7cfb\u7edf\u3002", "result": "83%\u7684\u7cfb\u7edf\u529f\u80fd\uff0824\u4e2a\u4e2d\u768420\u4e2a\uff09\u8fbe\u5230\u6027\u80fd\u76ee\u6807\uff08\u6545\u969c\u7387<5%\uff0c\u5e73\u5747\u5ef6\u8fdf<1000ms\uff09\uff0c\u652f\u63011\u4e07\u5e76\u53d1\u7528\u6237\uff0c\u5f02\u6b65\u901a\u4fe1\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u5bc6\u96c6\u578b\u9884\u6d4b\u8bf7\u6c42\u7684\u9519\u8bef\u7387\u3002", "conclusion": "\u8be5\u53ef\u6269\u5c55\u540e\u7aef\u7cfb\u7edf\u6210\u529f\u6ee1\u8db3\u4e86\u7cd6\u5c3f\u75c5\u9884\u6d4b\u5e94\u7528\u7684\u6027\u80fd\u9700\u6c42\uff0c\u9a8c\u8bc1\u4e86\u67b6\u6784\u8bbe\u8ba1\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5f02\u6b65\u901a\u4fe1\u5728\u4fdd\u8bc1\u7cfb\u7edf\u53ef\u9760\u6027\u65b9\u9762\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2512.08123", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08123", "abs": "https://arxiv.org/abs/2512.08123", "authors": ["Sampriti Soor", "Suklav Ghosh", "Arijit Sur"], "title": "Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation", "comment": "10 pages", "summary": "Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable \"soft\" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u5bf9\u6297\u540e\u7f00\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u77edtoken\u5e8f\u5217\uff084-10\u4e2atoken\uff09\u6765\u964d\u4f4e\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5177\u6709\u5f88\u597d\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u96f6\u6837\u672c\u6216\u5c11\u6837\u672c\u5206\u7c7b\u5668\u65f6\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u5f88\u8106\u5f31\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u6216\u6a21\u578b\u4f18\u5316\u89e6\u53d1\u5668\uff0c\u5bfc\u81f4\u7ed3\u679c\u96be\u4ee5\u6bd4\u8f83\u4e14\u8fc1\u79fb\u6027\u6709\u9650\u3002", "method": "\u4f7f\u7528Gumbel-Softmax\u677e\u5f1b\u5b66\u4e60\u53ef\u5fae\u5206\u7684\"\u8f6f\"\u540e\u7f00\uff0c\u7136\u540e\u79bb\u6563\u5316\u7528\u4e8e\u63a8\u7406\u3002\u8bad\u7ec3\u65f6\u6700\u5927\u5316\u6807\u7b7e\u533a\u57df\u7684\u6821\u51c6\u4ea4\u53c9\u71b5\uff0c\u540c\u65f6\u5c4f\u853d\u9ec4\u91d1token\u9632\u6b62\u4fe1\u606f\u6cc4\u9732\uff0c\u5e76\u52a0\u5165\u71b5\u6b63\u5219\u5316\u907f\u514d\u5d29\u6e83\u3002", "result": "\u5355\u4e2a\u540e\u7f00\u5728\u4e00\u4e2a\u6a21\u578b\u4e0a\u8bad\u7ec3\u540e\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u5176\u4ed6\u6a21\u578b\uff0c\u6301\u7eed\u964d\u4f4e\u51c6\u786e\u7387\u548c\u6821\u51c6\u7f6e\u4fe1\u5ea6\u3002\u5728\u60c5\u611f\u5206\u6790\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3001\u91ca\u4e49\u68c0\u6d4b\u3001\u5e38\u8bc6\u95ee\u7b54\u548c\u7269\u7406\u63a8\u7406\u7b49\u4efb\u52a1\u4e0a\uff0c\u5bf9Qwen2-1.5B\u3001Phi-1.5\u548cTinyLlama-1.1B\u6a21\u578b\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u653b\u51fb\u6548\u679c\u3002", "conclusion": "\u901a\u7528\u5bf9\u6297\u540e\u7f00\u662f\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u8de8\u4efb\u52a1\u548c\u6a21\u578b\u5bb6\u65cf\u5b9e\u73b0\u4e00\u81f4\u7684\u653b\u51fb\u6548\u679c\u548c\u8fc1\u79fb\u6027\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2512.07853", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.07853", "abs": "https://arxiv.org/abs/2512.07853", "authors": ["Jinwoo Jeong", "Minchul Kang", "Younghun Go", "Changyong Shin", "Hyunho Lee", "Junho Yoon", "Gyeongsik Yang", "Chuck Yoo"], "title": "GPU Memory Prediction for Multimodal Model Training", "comment": "1st Workshop on Systems for Agentic AI (SAA '25), co-located with SOSP 2025", "summary": "As deep learning models in agentic AI systems grow in scale and complexity, GPU memory requirements increase and often exceed the available GPU memory capacity, so that out-of-memory (OoM) errors occur. It is well known that OoM interrupts the whole training itself and wastes substantial computational resources. Therefore, to prevent OoM, accurate prediction of GPU memory usage is essential. However, previous studies focus only on unimodal architectures and fail to generalize to multimodal models, even though the multimodal models are a common choice in agentic AI systems. To address this limitation, we propose a framework that predicts the peak GPU memory usage by analyzing the model architecture and training behavior of multimodal models. Specifically, the framework decomposes the multimodal model into its constituent layers and applies factorization to estimate the memory usage of each layer. Our evaluation shows that our framework achieves high prediction accuracy of ~8.7% average MAPE.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9884\u6d4b\u591a\u6a21\u6001\u6a21\u578bGPU\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6a21\u578b\u67b6\u6784\u548c\u5206\u6790\u8bad\u7ec3\u884c\u4e3a\u6765\u51c6\u786e\u9884\u6d4b\u5185\u5b58\u4f7f\u7528\uff0c\u9632\u6b62OOM\u9519\u8bef", "motivation": "\u968f\u7740\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u589e\u52a0\uff0cGPU\u5185\u5b58\u9700\u6c42\u7ecf\u5e38\u8d85\u8fc7\u53ef\u7528\u5bb9\u91cf\uff0c\u5bfc\u81f4\u5185\u5b58\u6ea2\u51fa(OOM)\u9519\u8bef\uff0c\u8fd9\u4f1a\u4e2d\u65ad\u8bad\u7ec3\u5e76\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u3002\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u5355\u6a21\u6001\u67b6\u6784\uff0c\u65e0\u6cd5\u63a8\u5e7f\u5230\u591a\u6a21\u6001\u6a21\u578b\uff0c\u800c\u591a\u6a21\u6001\u6a21\u578b\u5728\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u5f88\u5e38\u89c1\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u591a\u6a21\u6001\u6a21\u578b\u7684\u67b6\u6784\u548c\u8bad\u7ec3\u884c\u4e3a\u6765\u9884\u6d4bGPU\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u5c06\u591a\u6a21\u6001\u6a21\u578b\u5206\u89e3\u4e3a\u7ec4\u6210\u5c42\uff0c\u5e76\u5e94\u7528\u56e0\u5b50\u5316\u6765\u4f30\u8ba1\u6bcf\u5c42\u7684\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u7ea68.7%\u7684\u5e73\u5747MAPE\uff08\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff09\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u591a\u6a21\u6001\u6a21\u578b\u7684GPU\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\uff0c\u6709\u52a9\u4e8e\u9632\u6b62OOM\u9519\u8bef\uff0c\u63d0\u9ad8\u667a\u80fd\u4f53AI\u7cfb\u7edf\u8bad\u7ec3\u7684\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002"}}
{"id": "2512.08480", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08480", "abs": "https://arxiv.org/abs/2512.08480", "authors": ["Ju-Young Kim", "Ji-Hong Park", "Se-Yeon Lee", "Sujin Park", "Gun-Woo Kim"], "title": "Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models", "comment": "in Korean language, Published in the Proceedings of the 37th Annual Conference on Human and Language Technology, 2025, pp. 714-719. (English translation assisted by GPT)", "summary": "Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f6f\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\uff0c\u901a\u8fc7\u660e\u786e\u5b9a\u4e49\u63a8\u7406\u89c6\u89d2\u6765\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u7528\u4e8e\u97e9\u8bed\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\uff0c\u76f8\u6bd4\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u63d0\u5347\u7ea63.89%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u7ebf\u6e38\u620f\u548c\u533f\u540d\u793e\u533a\u4e2d\u4e0d\u5f53\u8a00\u8bba\u5e38\u5347\u7ea7\u4e3a\u8a00\u8bed\u66b4\u529b\u548c\u72af\u7f6a\u884c\u4e3a\uff0c\u9700\u8981\u68c0\u6d4b\u6280\u672f\u6765\u6784\u5efa\u66f4\u5b89\u5168\u7684\u4ea4\u6d41\u73af\u5883\u3002\u867d\u7136\u97e9\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5728\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u4ecd\u6709\u9650\u3002", "method": "\u63d0\u51fa\u8f6f\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\uff0c\u660e\u786e\u5b9a\u4e49\u63a8\u7406\u89c6\u89d2\u6765\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\uff0c\u4fc3\u8fdb\u7406\u6027\u51b3\u7b56\u5e76\u9632\u6b62\u63a8\u7406\u9519\u8bef\u3002\u4f7f\u7528\u8be5\u65b9\u6cd5\u5bf9\u97e9\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u8fdb\u884c\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\u7684\u5b9a\u91cf\u6027\u80fd\u6bd4\u8f83\u548c\u5b9a\u6027\u8bc4\u4f30\u3002", "result": "Kanana-1.5\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523087.0046\uff0c\u76f8\u6bd4\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u63d0\u5347\u7ea63.89%\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6a21\u4eff\u77e5\u8bc6\uff0c\u8fd8\u80fd\u901a\u8fc7\u7ea6\u675f\u63a8\u7406\u89c6\u89d2\u5b9e\u73b0\u66f4\u7cbe\u786e\u548c\u4e00\u81f4\u7684\u5224\u65ad\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f6f\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\u901a\u8fc7\u7ea6\u675f\u63a8\u7406\u89c6\u89d2\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u8d85\u8d8a\u7b80\u5355\u77e5\u8bc6\u6a21\u4eff\uff0c\u5b9e\u73b0\u66f4\u7cbe\u786e\u548c\u4e00\u81f4\u7684\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.08411", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.08411", "abs": "https://arxiv.org/abs/2512.08411", "authors": ["Mingwei Li", "Xiaoyuan Zhang", "Chengwei Yang", "Zilong Zheng", "Yaodong Yang"], "title": "Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems", "comment": null, "summary": "Model-based planning in robotic domains is fundamentally challenged by the hybrid nature of physical dynamics, where continuous motion is punctuated by discrete events such as contacts and impacts. Conventional latent world models typically employ monolithic neural networks that enforce global continuity, inevitably over-smoothing the distinct dynamic modes (e.g., sticking vs. sliding, flight vs. stance). For a planner, this smoothing results in catastrophic compounding errors during long-horizon lookaheads, rendering the search process unreliable at physical boundaries. To address this, we introduce the Prismatic World Model (PRISM-WM), a structured architecture designed to decompose complex hybrid dynamics into composable primitives. PRISM-WM leverages a context-aware Mixture-of-Experts (MoE) framework where a gating mechanism implicitly identifies the current physical mode, and specialized experts predict the associated transition dynamics. We further introduce a latent orthogonalization objective to ensure expert diversity, effectively preventing mode collapse. By accurately modeling the sharp mode transitions in system dynamics, PRISM-WM significantly reduces rollout drift. Extensive experiments on challenging continuous control benchmarks, including high-dimensional humanoids and diverse multi-task settings, demonstrate that PRISM-WM provides a superior high-fidelity substrate for trajectory optimization algorithms (e.g., TD-MPC), proving its potential as a powerful foundational model for next-generation model-based agents.", "AI": {"tldr": "PRISM-WM\uff1a\u4e00\u79cd\u7528\u4e8e\u673a\u5668\u4eba\u6df7\u5408\u52a8\u529b\u5b66\u7684\u7ed3\u6784\u5316\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\u5206\u89e3\u590d\u6742\u52a8\u6001\uff0c\u51cf\u5c11\u957f\u65f6\u57df\u89c4\u5212\u4e2d\u7684\u7d2f\u79ef\u8bef\u5dee\u3002", "motivation": "\u673a\u5668\u4eba\u9886\u57df\u4e2d\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u9762\u4e34\u6df7\u5408\u52a8\u529b\u5b66\u7684\u6839\u672c\u6311\u6218\u2014\u2014\u8fde\u7eed\u8fd0\u52a8\u4e0e\u79bb\u6563\u4e8b\u4ef6\uff08\u5982\u63a5\u89e6\u3001\u78b0\u649e\uff09\u4ea4\u7ec7\u3002\u4f20\u7edf\u6f5c\u5728\u4e16\u754c\u6a21\u578b\u4f7f\u7528\u5168\u5c40\u8fde\u7eed\u7684\u5355\u4f53\u795e\u7ecf\u7f51\u7edc\uff0c\u4e0d\u53ef\u907f\u514d\u5730\u8fc7\u5ea6\u5e73\u6ed1\u4e0d\u540c\u7684\u52a8\u6001\u6a21\u5f0f\uff08\u5982\u7c98\u9644vs\u6ed1\u52a8\u3001\u98de\u884cvs\u7ad9\u7acb\uff09\uff0c\u5bfc\u81f4\u89c4\u5212\u5668\u5728\u7269\u7406\u8fb9\u754c\u5904\u4ea7\u751f\u707e\u96be\u6027\u7684\u7d2f\u79ef\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u68f1\u955c\u4e16\u754c\u6a21\u578b\uff08PRISM-WM\uff09\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u67b6\u6784\u5c06\u590d\u6742\u6df7\u5408\u52a8\u529b\u5b66\u5206\u89e3\u4e3a\u53ef\u7ec4\u5408\u7684\u57fa\u672c\u5355\u5143\u3002\u5229\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u6846\u67b6\uff0c\u5176\u4e2d\u95e8\u63a7\u673a\u5236\u9690\u5f0f\u8bc6\u522b\u5f53\u524d\u7269\u7406\u6a21\u5f0f\uff0c\u4e13\u95e8\u5316\u7684\u4e13\u5bb6\u9884\u6d4b\u76f8\u5173\u8f6c\u79fb\u52a8\u6001\u3002\u5f15\u5165\u6f5c\u5728\u6b63\u4ea4\u5316\u76ee\u6807\u786e\u4fdd\u4e13\u5bb6\u591a\u6837\u6027\uff0c\u6709\u6548\u9632\u6b62\u6a21\u5f0f\u5d29\u6e83\u3002", "result": "PRISM-WM\u901a\u8fc7\u7cbe\u786e\u5efa\u6a21\u7cfb\u7edf\u52a8\u6001\u4e2d\u7684\u5c16\u9510\u6a21\u5f0f\u8f6c\u6362\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6eda\u52a8\u6f02\u79fb\u3002\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u9ad8\u7ef4\u4eba\u5f62\u673a\u5668\u4eba\u548c\u591a\u6837\u5316\u591a\u4efb\u52a1\u8bbe\u7f6e\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPRISM-WM\u4e3a\u8f68\u8ff9\u4f18\u5316\u7b97\u6cd5\uff08\u5982TD-MPC\uff09\u63d0\u4f9b\u4e86\u5353\u8d8a\u7684\u9ad8\u4fdd\u771f\u5ea6\u57fa\u7840\u3002", "conclusion": "PRISM-WM\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u6df7\u5408\u52a8\u529b\u5b66\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4e16\u754c\u6a21\u578b\u5728\u7269\u7406\u8fb9\u754c\u5904\u7684\u5e73\u6ed1\u95ee\u9898\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u65f6\u57df\u89c4\u5212\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.08228", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08228", "abs": "https://arxiv.org/abs/2512.08228", "authors": ["Jusheng Zhang", "Kaitong Cai", "Xiaoyang Guo", "Sidi Liu", "Qinhan Lv", "Ruiqi Chen", "Jing Yang", "Yijia Fan", "Xiaofei Sun", "Jian Wang", "Ziliang Chen", "Liang Lin", "Keze Wang"], "title": "MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models", "comment": null, "summary": "The ability to perform Chain-of-Thought (CoT) reasoning marks a major milestone for multimodal models (MMs), enabling them to solve complex visual reasoning problems. Yet a critical question remains: is such reasoning genuinely grounded in visual evidence and logically coherent? Existing benchmarks emphasize generation but neglect verification, i.e., the capacity to assess whether a reasoning chain is both visually consistent and logically valid. To fill this gap, we introduce MM-CoT, a diagnostic benchmark specifically designed to probe the visual grounding and logical coherence of CoT reasoning in MMs. Instead of generating free-form explanations, models must select the sole event chain that satisfies two orthogonal constraints: (i) visual consistency, ensuring all steps are anchored in observable evidence, and (ii) logical coherence, ensuring causal and commonsense validity. Adversarial distractors are engineered to violate one of these constraints, exposing distinct reasoning failures. We evaluate leading vision-language models on MM-CoT and find that even the most advanced systems struggle, revealing a sharp discrepancy between generative fluency and true reasoning fidelity. MM-CoT shows low correlation with existing benchmarks, confirming that it measures a unique combination of visual grounding and logical reasoning. This benchmark provides a foundation for developing future models that reason not just plausibly, but faithfully and coherently within the visual world.", "AI": {"tldr": "MM-CoT\u662f\u4e00\u4e2a\u8bca\u65ad\u6027\u57fa\u51c6\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u89c6\u89c9\u57fa\u7840\u548c\u903b\u8f91\u8fde\u8d2f\u6027\uff0c\u901a\u8fc7\u8981\u6c42\u6a21\u578b\u9009\u62e9\u540c\u65f6\u6ee1\u8db3\u89c6\u89c9\u4e00\u81f4\u6027\u548c\u903b\u8f91\u8fde\u8d2f\u6027\u7684\u4e8b\u4ef6\u94fe\u6765\u6d4b\u8bd5\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u751f\u6210\u80fd\u529b\u800c\u5ffd\u89c6\u9a8c\u8bc1\u80fd\u529b\uff0c\u65e0\u6cd5\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u662f\u5426\u771f\u6b63\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u4e14\u903b\u8f91\u8fde\u8d2f\u3002\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u8bca\u65ad\u63a8\u7406\u7684\u89c6\u89c9\u57fa\u7840\u548c\u903b\u8f91\u6709\u6548\u6027\u3002", "method": "\u8bbe\u8ba1MM-CoT\u57fa\u51c6\uff0c\u8981\u6c42\u6a21\u578b\u4ece\u591a\u4e2a\u4e8b\u4ef6\u94fe\u4e2d\u9009\u62e9\u552f\u4e00\u6ee1\u8db3\u4e24\u4e2a\u6b63\u4ea4\u7ea6\u675f\u7684\u9009\u9879\uff1a\u89c6\u89c9\u4e00\u81f4\u6027\uff08\u6240\u6709\u6b65\u9aa4\u90fd\u57fa\u4e8e\u53ef\u89c2\u5bdf\u8bc1\u636e\uff09\u548c\u903b\u8f91\u8fde\u8d2f\u6027\uff08\u56e0\u679c\u548c\u5e38\u8bc6\u6709\u6548\u6027\uff09\u3002\u901a\u8fc7\u8bbe\u8ba1\u8fdd\u53cd\u5176\u4e2d\u4e00\u4e2a\u7ea6\u675f\u7684\u5bf9\u6297\u6027\u5e72\u6270\u9879\u6765\u66b4\u9732\u4e0d\u540c\u7684\u63a8\u7406\u5931\u8d25\u3002", "result": "\u8bc4\u4f30\u9886\u5148\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53d1\u73b0\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u7cfb\u7edf\u4e5f\u5728MM-CoT\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u751f\u6210\u6d41\u7545\u6027\u4e0e\u771f\u5b9e\u63a8\u7406\u4fdd\u771f\u5ea6\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\u3002MM-CoT\u4e0e\u73b0\u6709\u57fa\u51c6\u76f8\u5173\u6027\u4f4e\uff0c\u786e\u8ba4\u5176\u6d4b\u91cf\u7684\u662f\u89c6\u89c9\u57fa\u7840\u548c\u903b\u8f91\u63a8\u7406\u7684\u72ec\u7279\u7ec4\u5408\u3002", "conclusion": "MM-CoT\u4e3a\u5f00\u53d1\u672a\u6765\u6a21\u578b\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u8fd9\u4e9b\u6a21\u578b\u4e0d\u4ec5\u80fd\u591f\u8fdb\u884c\u770b\u4f3c\u5408\u7406\u7684\u63a8\u7406\uff0c\u800c\u4e14\u80fd\u591f\u5728\u89c6\u89c9\u4e16\u754c\u4e2d\u5fe0\u5b9e\u4e14\u8fde\u8d2f\u5730\u8fdb\u884c\u63a8\u7406\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u9a8c\u8bc1\u80fd\u529b\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.08592", "categories": ["cs.AI", "cs.CY", "cs.HC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08592", "abs": "https://arxiv.org/abs/2512.08592", "authors": ["Laxmiraju Kandikatla", "Branislav Radeljic"], "title": "The SMART+ Framework for AI Systems", "comment": null, "summary": "Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming finance through real-time fraud detection, automated loan risk assessment, and algorithmic decision-making. Similarly, in manufacturing, AI enables predictive maintenance to reduce equipment downtime, enhances quality control through computer-vision inspection, and optimizes production workflows using real-time operational data. While these technologies enhance operational efficiency, they introduce new challenges regarding safety, accountability, and regulatory compliance. To address these concerns, we introduce the SMART+ Framework - a structured model built on the pillars of Safety, Monitoring, Accountability, Reliability, and Transparency, and further enhanced with Privacy & Security, Data Governance, Fairness & Bias, and Guardrails. SMART+ offers a practical, comprehensive approach to evaluating and governing AI systems across industries. This framework aligns with evolving mechanisms and regulatory guidance to integrate operational safeguards, oversight procedures, and strengthened privacy and governance controls. SMART+ demonstrates risk mitigation, trust-building, and compliance readiness. By enabling responsible AI adoption and ensuring auditability, SMART+ provides a robust foundation for effective AI governance in clinical research.", "AI": {"tldr": "SMART+\u6846\u67b6\uff1a\u4e00\u4e2a\u57fa\u4e8e\u5b89\u5168\u3001\u76d1\u63a7\u3001\u95ee\u8d23\u3001\u53ef\u9760\u3001\u900f\u660e\u7b49\u652f\u67f1\uff0c\u5e76\u589e\u5f3a\u9690\u79c1\u5b89\u5168\u3001\u6570\u636e\u6cbb\u7406\u3001\u516c\u5e73\u6027\u3001\u62a4\u680f\u7684\u7efc\u5408\u6027AI\u6cbb\u7406\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u533b\u7597\u3001\u91d1\u878d\u3001\u5236\u9020\u7b49\u591a\u4e2a\u884c\u4e1a\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u5404\u884c\u4e1a\u5e7f\u6cdb\u5e94\u7528\uff08\u533b\u7597\u3001\u91d1\u878d\u3001\u5236\u9020\u7b49\uff09\u63d0\u9ad8\u4e86\u8fd0\u8425\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u5b89\u5168\u3001\u95ee\u8d23\u548c\u76d1\u7ba1\u5408\u89c4\u7b49\u65b0\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u5168\u9762\u7684\u6cbb\u7406\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e9b\u98ce\u9669\u3002", "method": "\u63d0\u51faSMART+\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u4e94\u5927\u652f\u67f1\uff08\u5b89\u5168\u3001\u76d1\u63a7\u3001\u95ee\u8d23\u3001\u53ef\u9760\u3001\u900f\u660e\uff09\uff0c\u5e76\u589e\u5f3a\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\uff08\u9690\u79c1\u4e0e\u5b89\u5168\u3001\u6570\u636e\u6cbb\u7406\u3001\u516c\u5e73\u6027\u4e0e\u504f\u89c1\u3001\u62a4\u680f\uff09\uff0c\u4e3aAI\u7cfb\u7edf\u63d0\u4f9b\u7ed3\u6784\u5316\u8bc4\u4f30\u548c\u6cbb\u7406\u6a21\u578b\u3002", "result": "SMART+\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u98ce\u9669\u7f13\u89e3\u3001\u5efa\u7acb\u4fe1\u4efb\u548c\u5408\u89c4\u51c6\u5907\uff0c\u901a\u8fc7\u6574\u5408\u8fd0\u8425\u4fdd\u969c\u3001\u76d1\u7763\u7a0b\u5e8f\u4ee5\u53ca\u5f3a\u5316\u7684\u9690\u79c1\u548c\u6cbb\u7406\u63a7\u5236\uff0c\u4e3a\u6709\u6548AI\u6cbb\u7406\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\u3002", "conclusion": "SMART+\u6846\u67b6\u4e3a\u8de8\u884c\u4e1aAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u5168\u9762\u7684\u8bc4\u4f30\u548c\u6cbb\u7406\u65b9\u6cd5\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u7684AI\u91c7\u7528\u5e76\u786e\u4fdd\u53ef\u5ba1\u8ba1\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e34\u5e8a\u7814\u7a76\u7b49\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2512.07880", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07880", "abs": "https://arxiv.org/abs/2512.07880", "authors": ["Huanran Li", "Manh Nguyen", "Daniel Pimentel-Alarc\u00f3n"], "title": "Semi-Supervised Contrastive Learning with Orthonormal Prototypes", "comment": null, "summary": "Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first identify a critical learning-rate threshold, beyond which standard contrastive losses converge to collapsed solutions. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP improves performance in image classification and object detection tasks while also exhibiting greater stability across different learning rates and batch sizes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCLOP\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u4fc3\u8fdb\u7c7b\u522b\u5d4c\u5165\u5f62\u6210\u6b63\u4ea4\u7ebf\u6027\u5b50\u7a7a\u95f4\u6765\u9632\u6b62\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u7ef4\u5ea6\u574d\u7f29\u95ee\u9898\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5bf9\u6bd4\u5b66\u4e60\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ef4\u5ea6\u574d\u7f29\u95ee\u9898\uff08\u5d4c\u5165\u6536\u655b\u5230\u4f4e\u7ef4\u7a7a\u95f4\uff09\u5728\u81ea\u76d1\u7763\u548c\u534a\u76d1\u7763\u8bbe\u7f6e\u4e2d\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5b66\u4e60\u7387\u4e0b\u4f1a\u5bfc\u81f4\u574d\u7f29\u89e3\u3002", "method": "\u9996\u5148\u8bc6\u522b\u4e86\u5bfc\u81f4\u7ef4\u5ea6\u574d\u7f29\u7684\u5173\u952e\u5b66\u4e60\u7387\u9608\u503c\uff0c\u7136\u540e\u63d0\u51faCLOP\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u4fc3\u8fdb\u7c7b\u522b\u5d4c\u5165\u5f62\u6210\u6b63\u4ea4\u7ebf\u6027\u5b50\u7a7a\u95f4\u6765\u9632\u6b62\u7ef4\u5ea6\u574d\u7f29\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCLOP\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u5b66\u4e60\u7387\u548c\u6279\u91cf\u5927\u5c0f\u4e0b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "CLOP\u901a\u8fc7\u9632\u6b62\u7ef4\u5ea6\u574d\u7f29\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u8868\u793a\u5b66\u4e60\u7684\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08108", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08108", "abs": "https://arxiv.org/abs/2512.08108", "authors": ["Kwanyoung Park", "Seohong Park", "Youngwoon Lee", "Sergey Levine"], "title": "Scalable Offline Model-Based RL with Action Chunks", "comment": "22 pages, 7 figures", "summary": "In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion, can provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. Model-based value expansion fits an on-policy value function using length-n imaginary rollouts generated by the current policy and a learned dynamics model. While larger n reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions. We address this trade-off with an \\emph{action-chunk} model that predicts a future state from a sequence of actions (an \"action chunk\") instead of a single action, which reduces compounding errors. In addition, instead of directly training a policy to maximize rewards, we employ rejection sampling from an expressive behavioral action-chunk policy, which prevents model exploitation from out-of-distribution actions. We call this recipe \\textbf{Model-Based RL with Action Chunks (MAC)}. Through experiments on highly challenging tasks with large-scale datasets of up to 100M transitions, we show that MAC achieves the best performance among offline model-based RL algorithms, especially on challenging long-horizon tasks.", "AI": {"tldr": "MAC\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u4f5c\u5757\u6a21\u578b\u51cf\u5c11\u957f\u671f\u9884\u6d4b\u8bef\u5dee\uff0c\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u9632\u6b62\u6a21\u578b\u5229\u7528\uff0c\u5728\u590d\u6742\u957f\u65f6\u57df\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\uff08\u7279\u522b\u662f\u57fa\u4e8e\u6a21\u578b\u7684\u4ef7\u503c\u6269\u5c55\uff09\u80fd\u5426\u4e3a\u79bb\u7ebfRL\u4e2d\u7684\u590d\u6742\u957f\u65f6\u57df\u4efb\u52a1\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u51cf\u5c11\u4ef7\u503c\u5f15\u5bfc\u504f\u5dee\uff08\u901a\u8fc7\u589e\u5927n\uff09\u548c\u7d2f\u79ef\u6a21\u578b\u8bef\u5dee\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "method": "\u63d0\u51faMAC\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u52a8\u4f5c\u5757\u6a21\u578b\uff0c\u9884\u6d4b\u52a8\u4f5c\u5e8f\u5217\uff08\u800c\u975e\u5355\u4e2a\u52a8\u4f5c\uff09\u540e\u7684\u672a\u6765\u72b6\u6001\uff0c\u51cf\u5c11\u590d\u5408\u8bef\u5dee\uff1b2\uff09\u91c7\u7528\u62d2\u7edd\u91c7\u6837\u4ece\u8868\u8fbe\u6027\u884c\u4e3a\u52a8\u4f5c\u5757\u7b56\u7565\u4e2d\u91c7\u6837\uff0c\u9632\u6b62\u6a21\u578b\u5229\u7528\u548c\u5206\u5e03\u5916\u52a8\u4f5c\u95ee\u9898\u3002", "result": "\u5728\u5305\u542b\u9ad8\u8fbe1\u4ebf\u4e2a\u8f6c\u79fb\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u9ad8\u5ea6\u6311\u6218\u6027\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cMAC\u5728\u79bb\u7ebf\u57fa\u4e8e\u6a21\u578bRL\u7b97\u6cd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u5728\u6311\u6218\u6027\u957f\u65f6\u57df\u4efb\u52a1\u4e0a\u3002", "conclusion": "MAC\u901a\u8fc7\u52a8\u4f5c\u5757\u6a21\u578b\u548c\u62d2\u7edd\u91c7\u6837\u7684\u7ec4\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u4e8e\u6a21\u578b\u4ef7\u503c\u6269\u5c55\u4e2d\u7684\u504f\u5dee-\u8bef\u5dee\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u79bb\u7ebfRL\u4e2d\u7684\u590d\u6742\u957f\u65f6\u57df\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08475", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08475", "abs": "https://arxiv.org/abs/2512.08475", "authors": ["Weiqi Guan", "Junlin He"], "title": "Solving Over-Smoothing in GNNs via Nonlocal Message Passing: Algebraic Smoothing and Depth Scalability", "comment": "18 pages, 4 figures", "summary": "The relationship between Layer Normalization (LN) placement and the over-smoothing phenomenon remains underexplored. We identify a critical dilemma: Pre-LN architectures avoid over-smoothing but suffer from the curse of depth, while Post-LN architectures bypass the curse of depth but experience over-smoothing.\n  To resolve this, we propose a new method based on Post-LN that induces algebraic smoothing, preventing over-smoothing without the curse of depth. Empirical results across five benchmarks demonstrate that our approach supports deeper networks (up to 256 layers) and improves performance, requiring no additional parameters.\n  Key contributions:\n  Theoretical Characterization: Analysis of LN dynamics and their impact on over-smoothing and the curse of depth.\n  A Principled Solution: A parameter-efficient method that induces algebraic smoothing and avoids over-smoothing and the curse of depth.\n  Empirical Validation: Extensive experiments showing the effectiveness of the method in deeper GNNs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8ePost-LN\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bf1\u5bfc\u4ee3\u6570\u5e73\u6ed1\u6765\u89e3\u51b3\u6df1\u5ea6GNN\u4e2d\u7684\u8fc7\u5e73\u6ed1\u548c\u6df1\u5ea6\u8bc5\u5492\u95ee\u9898\uff0c\u652f\u6301\u9ad8\u8fbe256\u5c42\u7684\u7f51\u7edc\u4e14\u65e0\u9700\u989d\u5916\u53c2\u6570\u3002", "motivation": "\u5c42\u5f52\u4e00\u5316(LN)\u653e\u7f6e\u4e0e\u8fc7\u5e73\u6ed1\u73b0\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002Pre-LN\u67b6\u6784\u907f\u514d\u8fc7\u5e73\u6ed1\u4f46\u53d7\u6df1\u5ea6\u8bc5\u5492\u5f71\u54cd\uff0c\u800cPost-LN\u67b6\u6784\u7ed5\u8fc7\u6df1\u5ea6\u8bc5\u5492\u4f46\u7ecf\u5386\u8fc7\u5e73\u6ed1\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u56f0\u5883\u3002", "method": "\u57fa\u4e8ePost-LN\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u8bf1\u5bfc\u4ee3\u6570\u5e73\u6ed1\u4ee5\u9632\u6b62\u8fc7\u5e73\u6ed1\uff0c\u540c\u65f6\u907f\u514d\u6df1\u5ea6\u8bc5\u5492\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u53c2\u6570\uff0c\u652f\u6301\u6784\u5efa\u66f4\u6df1\u5c42\u7f51\u7edc\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u652f\u6301\u66f4\u6df1\u5c42\u7f51\u7edc\uff08\u9ad8\u8fbe256\u5c42\uff09\u5e76\u63d0\u5347\u6027\u80fd\uff0c\u65e0\u9700\u989d\u5916\u53c2\u6570\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86LN\u653e\u7f6e\u7684\u56f0\u5883\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u65e2\u80fd\u907f\u514d\u8fc7\u5e73\u6ed1\u53c8\u80fd\u7ed5\u8fc7\u6df1\u5ea6\u8bc5\u5492\uff0c\u4e3a\u6784\u5efa\u66f4\u6df1\u5c42GNN\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.08869", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.08869", "abs": "https://arxiv.org/abs/2512.08869", "authors": ["Anantaa Kotal", "Anupam Joshi"], "title": "Differentially Private Synthetic Data Generation Using Context-Aware GANs", "comment": null, "summary": "The widespread use of big data across sectors has raised major privacy concerns, especially when sensitive information is shared or analyzed. Regulations such as GDPR and HIPAA impose strict controls on data handling, making it difficult to balance the need for insights with privacy requirements. Synthetic data offers a promising solution by creating artificial datasets that reflect real patterns without exposing sensitive information. However, traditional synthetic data methods often fail to capture complex, implicit rules that link different elements of the data and are essential in domains like healthcare. They may reproduce explicit patterns but overlook domain-specific constraints that are not directly stated yet crucial for realism and utility. For example, prescription guidelines that restrict certain medications for specific conditions or prevent harmful drug interactions may not appear explicitly in the original data. Synthetic data generated without these implicit rules can lead to medically inappropriate or unrealistic profiles. To address this gap, we propose ContextGAN, a Context-Aware Differentially Private Generative Adversarial Network that integrates domain-specific rules through a constraint matrix encoding both explicit and implicit knowledge. The constraint-aware discriminator evaluates synthetic data against these rules to ensure adherence to domain constraints, while differential privacy protects sensitive details from the original data. We validate ContextGAN across healthcare, security, and finance, showing that it produces high-quality synthetic data that respects domain rules and preserves privacy. Our results demonstrate that ContextGAN improves realism and utility by enforcing domain constraints, making it suitable for applications that require compliance with both explicit patterns and implicit rules under strict privacy guarantees.", "AI": {"tldr": "ContextGAN\uff1a\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5dee\u5206\u9690\u79c1\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u901a\u8fc7\u7ea6\u675f\u77e9\u9635\u6574\u5408\u9886\u57df\u7279\u5b9a\u89c4\u5219\uff0c\u751f\u6210\u65e2\u4fdd\u62a4\u9690\u79c1\u53c8\u7b26\u5408\u9886\u57df\u7ea6\u675f\u7684\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u3002", "motivation": "\u5927\u6570\u636e\u5e94\u7528\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\uff0cGDPR/HIPAA\u7b49\u6cd5\u89c4\u5bf9\u6570\u636e\u5904\u7406\u6709\u4e25\u683c\u8981\u6c42\u3002\u4f20\u7edf\u5408\u6210\u6570\u636e\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u7684\u9690\u5f0f\u9886\u57df\u89c4\u5219\uff08\u5982\u533b\u7597\u4e2d\u7684\u5904\u65b9\u6307\u5357\u3001\u836f\u7269\u76f8\u4e92\u4f5c\u7528\uff09\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u6570\u636e\u53ef\u80fd\u4e0d\u73b0\u5b9e\u6216\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51faContextGAN\uff08\u4e0a\u4e0b\u6587\u611f\u77e5\u5dee\u5206\u9690\u79c1\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff09\uff0c\u901a\u8fc7\u7ea6\u675f\u77e9\u9635\u7f16\u7801\u663e\u5f0f\u548c\u9690\u5f0f\u9886\u57df\u77e5\u8bc6\uff0c\u4f7f\u7528\u7ea6\u675f\u611f\u77e5\u5224\u522b\u5668\u8bc4\u4f30\u5408\u6210\u6570\u636e\u662f\u5426\u7b26\u5408\u9886\u57df\u89c4\u5219\uff0c\u540c\u65f6\u5e94\u7528\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u539f\u59cb\u6570\u636e\u7684\u654f\u611f\u4fe1\u606f\u3002", "result": "\u5728\u533b\u7597\u3001\u5b89\u5168\u548c\u91d1\u878d\u9886\u57df\u9a8c\u8bc1\u8868\u660e\uff0cContextGAN\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\uff0c\u65e2\u5c0a\u91cd\u9886\u57df\u89c4\u5219\u53c8\u4fdd\u62a4\u9690\u79c1\u3002\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u7684\u771f\u5b9e\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "ContextGAN\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u9886\u57df\u7ea6\u675f\uff0c\u5728\u4e25\u683c\u9690\u79c1\u4fdd\u8bc1\u4e0b\u751f\u6210\u7b26\u5408\u663e\u5f0f\u6a21\u5f0f\u548c\u9690\u5f0f\u89c4\u5219\u7684\u5408\u6210\u6570\u636e\uff0c\u9002\u7528\u4e8e\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u548c\u9886\u57df\u5408\u89c4\u6027\u7684\u5e94\u7528\u573a\u666f\u3002"}}
