<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 28]
- [cs.LG](#cs.LG) [Total: 20]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CL](#cs.CL) [Total: 6]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ControlEvents: Controllable Synthesis of Event Camera Datawith Foundational Prior from Image Diffusion Models](https://arxiv.org/abs/2509.22864)
*Yixuan Hu,Yuxuan Xue,Simon Klenk,Daniel Cremers,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: ControlEvents是一个基于扩散模型的生成模型，能够通过文本标签、2D骨架和3D身体姿态等控制信号合成高质量的事件数据，解决了事件相机数据标注成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率和高动态范围等生物启发特性，但获取大规模标注的事件数据仍然具有挑战性且成本高昂。

Method: 利用Stable Diffusion等基础模型的扩散先验，通过最小化微调和有限标注数据实现高质量事件数据生成，支持文本标签、2D骨架和3D姿态等多种控制信号。

Result: 实验表明合成的标注事件数据在视觉识别、2D骨架估计和3D姿态估计任务中都能提升模型性能，并且能够基于训练中未见过的文本标签生成事件数据。

Conclusion: 该方法简化了数据生成流程，显著降低了标注事件数据集的成本，继承了基础模型强大的基于文本的生成能力。

Abstract: In recent years, event cameras have gained significant attention due to their
bio-inspired properties, such as high temporal resolution and high dynamic
range. However, obtaining large-scale labeled ground-truth data for event-based
vision tasks remains challenging and costly. In this paper, we present
ControlEvents, a diffusion-based generative model designed to synthesize
high-quality event data guided by diverse control signals such as class text
labels, 2D skeletons, and 3D body poses. Our key insight is to leverage the
diffusion prior from foundation models, such as Stable Diffusion, enabling
high-quality event data generation with minimal fine-tuning and limited labeled
data. Our method streamlines the data generation process and significantly
reduces the cost of producing labeled event datasets. We demonstrate the
effectiveness of our approach by synthesizing event data for visual
recognition, 2D skeleton estimation, and 3D body pose estimation. Our
experiments show that the synthesized labeled event data enhances model
performance in all tasks. Additionally, our approach can generate events based
on unseen text labels during training, illustrating the powerful text-based
generation capabilities inherited from foundation models.

</details>


### [2] [Soft-Di[M]O: Improving One-Step Discrete Image Generation with Soft Embeddings](https://arxiv.org/abs/2509.22925)
*Yuanzhi Zhu,Xi Wang,Stéphane Lathuilière,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: 本文提出了软嵌入方法，通过将离散令牌替换为生成器输出分布下的期望嵌入，解决了单步生成器的梯度流阻塞问题，使其能够进行对抗训练、奖励微调等后蒸馏优化。


<details>
  <summary>Details</summary>
Motivation: 单步生成器虽然实现了高效的文本和图像合成，但存在两个关键限制：继承教师模型的建模偏差，以及离散令牌输出阻塞梯度流，无法进行后蒸馏优化。

Method: 引入软嵌入方法，用生成器输出分布下的期望嵌入替代离散令牌，创建完全可微的连续代理，与教师主干和令牌解码器兼容。

Result: 在多个MDM教师模型上，Soft-Di[M]O实现了最先进的单步结果：改进的类别到图像性能，在ImageNet-256上通过GAN优化达到FID 1.56，文本到图像任务获得更高的GenEval和HPS分数，并通过TTEO获得进一步增益。

Conclusion: 软嵌入使单步生成器端到端可训练，支持GAN优化、可微奖励微调和TTEO，显著提升生成质量。

Abstract: One-step generators distilled from Masked Diffusion Models (MDMs) compress
multiple sampling steps into a single forward pass, enabling efficient text and
image synthesis. However, they suffer two key limitations: they inherit
modeling bias from the teacher, and their discrete token outputs block gradient
flow, preventing post-distillation refinements such as adversarial training,
reward-based fine-tuning, and Test-Time Embedding Optimization (TTEO). In this
work, we introduce soft embeddings, a simple relaxation that replaces discrete
tokens with the expected embeddings under the generator's output distribution.
Soft embeddings preserve representation fidelity for one-step discrete
generator while providing a fully differentiable continuous surrogate that is
compatible with teacher backbones and tokenizer decoders. Integrating soft
embeddings into the Di[M]O distillation framework (denoted Soft-Di[M]O) makes
one-step generators end-to-end trainable and enables straightforward
application of GAN-based refinement, differentiable reward fine-tuning, and
TTEO. Empirically, across multiple MDM teachers (e.g., MaskBit, MaskGen),
Soft-Di[M]O achieves state-of-the-art one-step results: improved class-to-image
performance, a one-step FID of 1.56 on ImageNet-256 with GAN-based refinement,
along with higher GenEval and HPS scores on text-to-image with reward
fine-tuning, and further gains from TTEO.

</details>


### [3] [GeLoc3r: Enhancing Relative Camera Pose Regression with Geometric Consistency Regularization](https://arxiv.org/abs/2509.23038)
*Jingxing Li,Yongjae Lee,Deliang Fan*

Main category: cs.CV

TL;DR: GeLoc3r通过几何一致性正则化增强相对相机姿态回归方法，在保持ReLoc3R快速推理速度的同时接近MASt3R的高精度，解决了速度-精度权衡问题。


<details>
  <summary>Details</summary>
Motivation: ReLoc3R虽然具有快速推理和先进回归精度，但其内部表示存在几何不一致性，无法达到基于对应关系方法的精度上限。

Method: 训练期间使用真实深度生成密集3D-2D对应关系，通过FusionTransformer学习对应关系重要性，使用加权RANSAC计算几何一致姿态，创建一致性损失将几何知识转移到回归网络中。

Result: 在多个基准测试中显著优于ReLoc3R，CO3Dv2数据集AUC@5°从34.85%提升至40.45%(相对提升16%)，RealEstate10K从66.70%提升至68.66%，MegaDepth1500从49.60%提升至50.45%。

Conclusion: 通过在训练中教授几何一致性而非在推理时强制执行，GeLoc3r代表了神经网络学习相机几何的新范式，同时具备回归方法的速度和对应关系方法的几何理解能力。

Abstract: Prior ReLoc3R achieves breakthrough performance with fast 25ms inference and
state-of-the-art regression accuracy, yet our analysis reveals subtle geometric
inconsistencies in its internal representations that prevent reaching the
precision ceiling of correspondence-based methods like MASt3R (which require
300ms per pair). In this work, we present GeLoc3r, a novel approach to relative
camera pose estimation that enhances pose regression methods through Geometric
Consistency Regularization (GCR). GeLoc3r overcomes the speed-accuracy dilemma
by training regression networks to produce geometrically consistent poses
without inference-time geometric computation. During training, GeLoc3r
leverages ground-truth depth to generate dense 3D-2D correspondences, weights
them using a FusionTransformer that learns correspondence importance, and
computes geometrically-consistent poses via weighted RANSAC. This creates a
consistency loss that transfers geometric knowledge into the regression
network. Unlike FAR method which requires both regression and geometric solving
at inference, GeLoc3r only uses the enhanced regression head at test time,
maintaining ReLoc3R's fast speed and approaching MASt3R's high accuracy. On
challenging benchmarks, GeLoc3r consistently outperforms ReLoc3R, achieving
significant improvements including 40.45% vs. 34.85% AUC@5{\deg} on the CO3Dv2
dataset (16% relative improvement), 68.66% vs. 66.70% AUC@5{\deg} on
RealEstate10K, and 50.45% vs. 49.60% on MegaDepth1500. By teaching geometric
consistency during training rather than enforcing it at inference, GeLoc3r
represents a paradigm shift in how neural networks learn camera geometry,
achieving both the speed of regression and the geometric understanding of
correspondence methods.

</details>


### [4] [Stochastic Interpolants via Conditional Dependent Coupling](https://arxiv.org/abs/2509.23122)
*Chenrui Ma,Xi Xiao,Tianyang Wang,Xiao Wang,Yanning Shen*

Main category: cs.CV

TL;DR: 提出了一种基于条件依赖耦合策略的统一多阶段生成框架，通过将生成过程分解为多阶段的插值轨迹，在确保准确分布学习的同时实现端到端优化。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在计算成本与保真度之间存在权衡问题：基于VAE的模型存在信息丢失和细节有限问题，而像素空间模型计算成本过高，级联模型则无法有效进行端到端优化。

Method: 使用条件依赖耦合策略将生成过程分解为多阶段插值轨迹，整个流程建模为单一统一的扩散变换器，避免模块分离并实现知识共享。

Result: 大量实验表明该方法在多个分辨率下同时实现了高保真度和高效率。

Conclusion: 提出的统一多阶段生成框架成功解决了现有模型在计算效率与生成质量之间的权衡问题，实现了端到端优化和知识共享。

Abstract: Existing image generation models face critical challenges regarding the
trade-off between computation and fidelity. Specifically, models relying on a
pretrained Variational Autoencoder (VAE) suffer from information loss, limited
detail, and the inability to support end-to-end training. In contrast, models
operating directly in the pixel space incur prohibitive computational cost.
Although cascade models can mitigate computational cost, stage-wise separation
prevents effective end-to-end optimization, hampers knowledge sharing, and
often results in inaccurate distribution learning within each stage. To address
these challenges, we introduce a unified multistage generative framework based
on our proposed Conditional Dependent Coupling strategy. It decomposes the
generative process into interpolant trajectories at multiple stages, ensuring
accurate distribution learning while enabling end-to-end optimization.
Importantly, the entire process is modeled as a single unified Diffusion
Transformer, eliminating the need for disjoint modules and also enabling
knowledge sharing. Extensive experiments demonstrate that our method achieves
both high fidelity and efficiency across multiple resolutions.

</details>


### [5] [Patch Rebirth: Toward Fast and Transferable Model Inversion of Vision Transformers](https://arxiv.org/abs/2509.23235)
*Seongsoo Heo,Dong-Wan Choi*

Main category: cs.CV

TL;DR: 提出了Patch Rebirth Inversion (PRI)方法，通过渐进式分离重要补丁来构建稀疏合成图像，同时允许剩余补丁继续演化，比标准密集模型反演快10倍，比稀疏模型反演快2倍，且性能更优。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏模型反演(SMI)方法过早丢弃看似不重要的补丁，但研究发现即使是随机选择的补丁也能通过持续反演获得可迁移知识，因此需要更高效的策略来平衡类无关和类特定特征。

Method: PRI在反演过程中逐步分离最重要的补丁来构建稀疏图像，同时让剩余补丁继续演化以供未来选择，实现渐进式知识积累。

Result: PRI比标准密集模型反演快10倍，比稀疏模型反演快2倍，在准确率上持续优于SMI并匹配DMI性能。

Conclusion: PRI通过渐进式补丁分离策略有效平衡了效率和知识提取，实现了更高效和准确的模型反演。

Abstract: Model inversion is a widely adopted technique in data-free learning that
reconstructs synthetic inputs from a pretrained model through iterative
optimization, without access to original training data. Unfortunately, its
application to state-of-the-art Vision Transformers (ViTs) poses a major
computational challenge, due to their expensive self-attention mechanisms. To
address this, Sparse Model Inversion (SMI) was proposed to improve efficiency
by pruning and discarding seemingly unimportant patches, which were even
claimed to be obstacles to knowledge transfer. However, our empirical findings
suggest the opposite: even randomly selected patches can eventually acquire
transferable knowledge through continued inversion. This reveals that
discarding any prematurely inverted patches is inefficient, as it suppresses
the extraction of class-agnostic features essential for knowledge transfer,
along with class-specific features. In this paper, we propose Patch Rebirth
Inversion (PRI), a novel approach that incrementally detaches the most
important patches during the inversion process to construct sparse synthetic
images, while allowing the remaining patches to continue evolving for future
selection. This progressive strategy not only improves efficiency, but also
encourages initially less informative patches to gradually accumulate more
class-relevant knowledge, a phenomenon we refer to as the Re-Birth effect,
thereby effectively balancing class-agnostic and class-specific knowledge.
Experimental results show that PRI achieves up to 10x faster inversion than
standard Dense Model Inversion (DMI) and 2x faster than SMI, while consistently
outperforming SMI in accuracy and matching the performance of DMI.

</details>


### [6] [Seeing the Unseen in Low-light Spike Streams](https://arxiv.org/abs/2509.23304)
*Liwen Hu,Yang Li,Mianzhi Liu,Yijia Guo,Shenghao Xie,Ziluo Ding,Tiejun Huang,Lei Ma*

Main category: cs.CV

TL;DR: Diff-SPK是首个基于扩散模型的脉冲相机重建方法，通过增强纹理提取和ControlNet生成，有效解决低光照高速场景下脉冲流重建的噪声和信息稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 传统脉冲相机重建方法在低光照高速场景下难以处理严重噪声和稀疏信息，需要新的重建技术来生成人眼可感知的高质量图像。

Method: 首先使用ETFI从低光照脉冲流中聚合稀疏信息，然后将其作为ControlNet的条件输入来生成高速场景，并在生成过程中引入ETFI特征融合模块提升质量。

Result: 在真实低光照脉冲流上的性能表现证明了Diff-SPK的优越性，并建立了首个低光照脉冲流重建基准数据集。

Conclusion: Diff-SPK成功利用生成先验补充低光照条件下的纹理信息，为脉冲相机在低光照高速视觉任务中的应用提供了有效解决方案。

Abstract: Spike camera, a type of neuromorphic sensor with high-temporal resolution,
shows great promise for high-speed visual tasks. Unlike traditional cameras,
spike camera continuously accumulates photons and fires asynchronous spike
streams. Due to unique data modality, spike streams require reconstruction
methods to become perceptible to the human eye.
  However, lots of methods struggle to handle spike streams in low-light
high-speed scenarios due to severe noise and sparse information. In this work,
we propose Diff-SPK, the first diffusion-based reconstruction method for spike
camera. Diff-SPK effectively leverages generative priors to supplement texture
information in low-light conditions. Specifically, it first employs an
\textbf{E}nhanced \textbf{T}exture \textbf{f}rom Inter-spike \textbf{I}nterval
(ETFI) to aggregate sparse information from low-light spike streams. Then, ETFI
serves as a conditioning input for ControlNet to generate the high-speed
scenes. To improve the quality of results, we introduce an ETFI-based feature
fusion module during the generation process.
  Moreover, we establish the first bona fide benchmark for the low-light spike
stream reconstruction task. It significantly surpasses existing reconstruction
datasets in scale and provides quantitative illumination information. The
performance on real low-light spike streams demonstrates the superiority of
Diff-SPK.

</details>


### [7] [Seeing Symbols, Missing Cultures: Probing Vision-Language Models' Reasoning on Fire Imagery and Cultural Meaning](https://arxiv.org/abs/2509.23311)
*Haorui Yu,Qiufeng Yi,Yijia Chu,Yang Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一个诊断框架来评估视觉语言模型在文化图像理解方面的能力，发现模型存在系统性偏见，能识别主流西方节日但难以理解非西方文化事件，甚至可能将紧急场景误判为庆祝活动。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型表面上表现出文化能力，但实际上依赖肤浅的模式匹配而非真正的文化理解。作者旨在揭示这种表面能力背后的风险，强调需要超越准确率指标的文化评估。

Method: 引入诊断框架，通过分类和解释分析来探测视觉语言模型对火主题文化图像的理解能力。测试了多个模型在西方节日、非西方传统和紧急场景上的表现。

Result: 模型存在系统性偏见：能正确识别主流西方节日，但在代表性不足的文化事件上表现不佳，经常提供模糊标签或危险地将紧急情况误分类为庆祝活动。

Conclusion: 这些失败暴露了符号捷径的风险，强调需要超越准确率指标的文化评估，以确保可解释和公平的多模态系统。

Abstract: Vision-Language Models (VLMs) often appear culturally competent but rely on
superficial pattern matching rather than genuine cultural understanding. We
introduce a diagnostic framework to probe VLM reasoning on fire-themed cultural
imagery through both classification and explanation analysis. Testing multiple
models on Western festivals, non-Western traditions, and emergency scenes
reveals systematic biases: models correctly identify prominent Western
festivals but struggle with underrepresented cultural events, frequently
offering vague labels or dangerously misclassifying emergencies as
celebrations. These failures expose the risks of symbolic shortcuts and
highlight the need for cultural evaluation beyond accuracy metrics to ensure
interpretable and fair multimodal systems.

</details>


### [8] [C3-OWD: A Curriculum Cross-modal Contrastive Learning Framework for Open-World Detection](https://arxiv.org/abs/2509.23316)
*Siheng Wang,Zhengdao Li,Yanshu Li,Canran Xiao,Haibo Zhan,Zhengtao Yao,Xuzhi Zhang,Jiale Kang,Linshan Li,Weiming Liu,Zhikang Dong,Jifeng Shen,Junhao Dong,Qiang Sun,Piotr Koniusz*

Main category: cs.CV

TL;DR: C3-OWD是一个课程跨模态对比学习框架，通过两阶段训练同时解决目标检测的鲁棒性和泛化性问题，在RGB-T数据和视觉-语言对齐上取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界目标检测面临两个主要挑战：对未见类别的泛化能力差，以及在恶劣条件下的鲁棒性不足。现有研究分别处理这两个问题，但难以同时实现鲁棒性和多样性。

Method: 提出两阶段课程学习框架：第一阶段使用RGBT数据进行预训练以增强鲁棒性；第二阶段通过视觉-语言对齐提高泛化能力；引入指数移动平均机制防止灾难性遗忘。

Result: 在FLIR数据集上达到80.1 AP50，在OV-COCO上达到48.6 AP50_Novel，在OV-LVIS上达到35.7 mAPr，在鲁棒性和多样性评估中都表现出竞争力。

Conclusion: C3-OWD成功统一了鲁棒性和泛化性的优势，通过课程跨模态对比学习框架在多个数据集上取得了优异的性能表现。

Abstract: Object detection has advanced significantly in the closed-set setting, but
real-world deployment remains limited by two challenges: poor generalization to
unseen categories and insufficient robustness under adverse conditions. Prior
research has explored these issues separately: visible-infrared detection
improves robustness but lacks generalization, while open-world detection
leverages vision-language alignment strategy for category diversity but
struggles under extreme environments. This trade-off leaves robustness and
diversity difficult to achieve simultaneously. To mitigate these issues, we
propose \textbf{C3-OWD}, a curriculum cross-modal contrastive learning
framework that unifies both strengths. Stage~1 enhances robustness by
pretraining with RGBT data, while Stage~2 improves generalization via
vision-language alignment. To prevent catastrophic forgetting between two
stages, we introduce an Exponential Moving Average (EMA) mechanism that
theoretically guarantees preservation of pre-stage performance with bounded
parameter lag and function consistency. Experiments on FLIR, OV-COCO, and
OV-LVIS demonstrate the effectiveness of our approach: C3-OWD achieves $80.1$
AP$^{50}$ on FLIR, $48.6$ AP$^{50}_{\text{Novel}}$ on OV-COCO, and $35.7$
mAP$_r$ on OV-LVIS, establishing competitive performance across both robustness
and diversity evaluations. Code available at:
https://github.com/justin-herry/C3-OWD.git.

</details>


### [9] [SPIKE-RL: Video-LLMs meet Bayesian Surprise](https://arxiv.org/abs/2509.23433)
*Sahithya Ravi,Aditya Chinchure,Raymond T. Ng,Leonid Sigal,Vered Shwartz*

Main category: cs.CV

TL;DR: SPIKE是一个推理时框架，通过量化贝叶斯惊喜来识别视频中的关键时刻，并基于惊喜权重进行帧采样，在多个下游基准测试中优于均匀采样。


<details>
  <summary>Details</summary>
Motivation: 现实世界视频通常包含常规活动和令人难忘的惊喜事件，但现有的Video-LLMs通过均匀采样帧可能错过定义视频叙事的关键时刻。

Method: 引入SPIKE框架量化贝叶斯惊喜（新视觉证据引发的信念更新），并开发SPIKE-RL使用GRPO优化信念假设，基于视频标题的奖励信号进行惊喜加权帧采样。

Result: SPIKE能有效定位视频中的惊喜时刻，与人类在正负惊喜基准上高度相关。惊喜加权帧采样在五个下游基准测试中持续优于均匀采样。

Conclusion: 通过让Video-LLMs跟踪信念并注册惊喜，为构建更鲁棒的模型铺平了道路，这些模型能够根据新信息修正理解。

Abstract: Real-world videos often show routine activities punctuated by memorable,
surprising events. However, most Video-LLMs process videos by sampling frames
uniformly, likely missing critical moments that define a video's narrative. We
introduce SPIKE, an inference-time framework that quantifies Bayesian Surprise
as the belief update triggered by new visual evidence in the video stream,
identifying moments where new visual evidence conflicts with prior beliefs.
SPIKE effectively localizes surprise in videos, strongly correlated with humans
on positive (FunQA) and negative (Oops!) surprise benchmarks. Since the beliefs
of zero-shot Video-LLMs are often suboptimal, we develop SPIKE-RL, which
leverages GRPO to optimize belief hypotheses based on a reward signal from the
video caption. SPIKE and SPIKE-RL guide query-agnostic surprise-weighted frame
sampling, which allocates more frames to interesting moments in the video. With
this strategy, we achieve consistent performance gains on five downstream
benchmarks over uniform sampling. By enabling Video-LLMs to track beliefs and
register surprise, our work paves the way for more robust models that can
revise their understanding in response to new information.

</details>


### [10] [Robust Multi-Modal Face Anti-Spoofing with Domain Adaptation: Tackling Missing Modalities, Noisy Pseudo-Labels, and Model Degradation](https://arxiv.org/abs/2509.23475)
*Ming-Tsung Hsu,Fang-Yu Hsu,Yi-Ting Lin,Kai-Heng Chien,Jun-Ren Chen,Cheng-Hsiang Su,Yi-Chen Ou,Chiou-Ting Hsu,Pei-Kai Huang*

Main category: cs.CV

TL;DR: 提出了MFAS-DANet框架，解决多模态人脸反欺诈在域自适应场景下的三个主要挑战：模态缺失、噪声伪标签和模型退化。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态人脸反欺诈模型难以检测来自新目标域的未知攻击，且域自适应方法在多模态场景中尚未被探索。

Method: 1) 从其他模态提取互补特征来替代缺失模态或增强现有特征；2) 利用多模态预测不确定性生成可靠伪标签；3) 设计自适应机制动态调整损失权重。

Result: 大量实验证明MFAS-DANet的有效性和最先进性能。

Conclusion: 该框架成功解决了多模态人脸反欺诈在域自适应中的关键挑战，实现了优异的性能。

Abstract: Recent multi-modal face anti-spoofing (FAS) methods have investigated the
potential of leveraging multiple modalities to distinguish live and spoof
faces. However, pre-adapted multi-modal FAS models often fail to detect unseen
attacks from new target domains. Although a more realistic domain adaptation
(DA) scenario has been proposed for single-modal FAS to learn specific spoof
attacks during inference, DA remains unexplored in multi-modal FAS methods. In
this paper, we propose a novel framework, MFAS-DANet, to address three major
challenges in multi-modal FAS under the DA scenario: missing modalities, noisy
pseudo labels, and model degradation. First, to tackle the issue of missing
modalities, we propose extracting complementary features from other modalities
to substitute missing modality features or enhance existing ones. Next, to
reduce the impact of noisy pseudo labels during model adaptation, we propose
deriving reliable pseudo labels by leveraging prediction uncertainty across
different modalities. Finally, to prevent model degradation, we design an
adaptive mechanism that decreases the loss weight during unstable adaptations
and increasing it during stable ones. Extensive experiments demonstrate the
effectiveness and state-of-the-art performance of our proposed MFAS-DANet.

</details>


### [11] [Calibrated and Resource-Aware Super-Resolution for Reliable Driver Behavior Analysis](https://arxiv.org/abs/2509.23535)
*Ibne Farabi Shihab,Weiheng Chai,Jiyang Wang,Sanjeda Akter,Senem Velipasalar Gursoy,Anuj Sharma*

Main category: cs.CV

TL;DR: 提出了一种资源感知的自适应超分辨率框架，用于优化驾驶员监控系统中的模型校准和关键事件检测精度，在安全关键指标上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 驾驶员监控系统不仅需要高精度，还需要可靠的置信度分数以确保安全关键部署。直接低分辨率训练虽然整体精度高，但预测校准差，在安全关键场景中可能造成危险。

Method: 采用资源感知的自适应超分辨率框架，结合轻量级伪影检测器（0.3M参数，5.2ms开销）来过滤超分辨率引起的幻觉。

Result: 在安全中心指标上达到最先进性能：最佳校准（ECE 5.8% vs 基线6.2%）、最高AUPR用于困倦检测（0.78 vs 0.74）、手机使用检测的精确率-召回率更优（0.74 vs 0.71）。

Conclusion: 虽然低分辨率训练的视频模型是强大的通用基线，但我们的自适应框架在可靠性至关重要的安全关键应用中代表了最先进的解决方案。

Abstract: Driver monitoring systems require not just high accuracy but reliable,
well-calibrated confidence scores for safety-critical deployment. While direct
low-resolution training yields high overall accuracy, it produces poorly
calibrated predictions that can be dangerous in safety-critical scenarios. We
propose a resource-aware adaptive super-resolution framework that optimizes for
model calibration and high precision-recall on critical events. Our approach
achieves state-of-the-art performance on safety-centric metrics: best
calibration (ECE of 5.8\% vs 6.2\% for LR-trained baselines), highest AUPR for
drowsiness detection (0.78 vs 0.74), and superior precision-recall for phone
use detection (0.74 vs 0.71). A lightweight artifact detector (0.3M parameters,
5.2ms overhead) provides additional safety by filtering SR-induced
hallucinations. While LR-trained video models serve as strong general-purpose
baselines, our adaptive framework represents the state-of-the-art solution for
safety-critical applications where reliability is paramount.

</details>


### [12] [OVSeg3R: Learn Open-vocabulary Instance Segmentation from 2D via 3D Reconstruction](https://arxiv.org/abs/2509.23541)
*Hongyang Li,Jinyuan Qu,Lei Zhang*

Main category: cs.CV

TL;DR: OVSeg3R是一种从2D感知模型学习开放词汇3D实例分割的训练方案，利用3D重建技术将2D实例掩码投影到3D空间生成标注，通过视图级实例分区和2D实例边界感知超点聚类等技术，在ScanNet200基准上实现了+2.3 mAP的整体提升。


<details>
  <summary>Details</summary>
Motivation: 为了从成熟的2D感知模型中学习开放词汇的3D实例分割，避免昂贵的手动标注，并使输入与真实世界应用对齐。

Method: 利用3D重建模型提供的2D到3D对应关系，将2D开放词汇模型的实例掩码预测投影到3D空间生成标注；提出视图级实例分区算法避免错误监督；引入2D实例边界感知超点聚类防止超点跨越实例边界。

Result: 在ScanNet200基准上整体提升+2.3 mAP，尾类和头类性能差距显著缩小；在标准开放词汇设置下，新类性能比先前方法提升约+7.1 mAP。

Conclusion: OVSeg3R成功将最先进的封闭词汇3D实例分割模型扩展到开放词汇，显著提升了整体性能和新类识别能力，验证了该方法的有效性。

Abstract: In this paper, we propose a training scheme called OVSeg3R to learn
open-vocabulary 3D instance segmentation from well-studied 2D perception models
with the aid of 3D reconstruction. OVSeg3R directly adopts reconstructed scenes
from 2D videos as input, avoiding costly manual adjustment while aligning input
with real-world applications. By exploiting the 2D to 3D correspondences
provided by 3D reconstruction models, OVSeg3R projects each view's 2D instance
mask predictions, obtained from an open-vocabulary 2D model, onto 3D to
generate annotations for the view's corresponding sub-scene. To avoid
incorrectly introduced false positives as supervision due to partial
annotations from 2D to 3D, we propose a View-wise Instance Partition algorithm,
which partitions predictions to their respective views for supervision,
stabilizing the training process. Furthermore, since 3D reconstruction models
tend to over-smooth geometric details, clustering reconstructed points into
representative super-points based solely on geometry, as commonly done in
mainstream 3D segmentation methods, may overlook geometrically non-salient
objects. We therefore introduce 2D Instance Boundary-aware Superpoint, which
leverages 2D masks to constrain the superpoint clustering, preventing
superpoints from violating instance boundaries. With these designs, OVSeg3R not
only extends a state-of-the-art closed-vocabulary 3D instance segmentation
model to open-vocabulary, but also substantially narrows the performance gap
between tail and head classes, ultimately leading to an overall improvement of
+2.3 mAP on the ScanNet200 benchmark. Furthermore, under the standard
open-vocabulary setting, OVSeg3R surpasses previous methods by about +7.1 mAP
on the novel classes, further validating its effectiveness.

</details>


### [13] [Fast Feature Field ($\text{F}^3$): A Predictive Representation of Events](https://arxiv.org/abs/2509.25146)
*Richeek Das,Kostas Daniilidis,Pratik Chaudhari*

Main category: cs.CV

TL;DR: 提出F³（Fast Feature Field）表示方法，从事件相机数据中学习特征表示，通过预测未来事件来保留场景结构和运动信息，在多种视觉任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效处理事件相机稀疏数据、对噪声和事件率变化具有鲁棒性的表示方法，以支持多种下游视觉任务。

Method: 利用多分辨率哈希编码和深度集合思想，将事件数据表示为连续时空体积内的多通道图像，通过预测未来事件来学习特征表示。

Result: 在HD分辨率下达到120Hz，VGA分辨率下达到440Hz的计算效率；在光流估计、语义分割和单目深度估计等任务上获得最先进性能，支持25-75Hz的实时预测。

Conclusion: F³是一种高效、鲁棒的事件数据表示方法，能够在多种机器人平台、光照条件和环境下实现高性能的视觉任务处理。

Abstract: This paper develops a mathematical argument and algorithms for building
representations of data from event-based cameras, that we call Fast Feature
Field ($\text{F}^3$). We learn this representation by predicting future events
from past events and show that it preserves scene structure and motion
information. $\text{F}^3$ exploits the sparsity of event data and is robust to
noise and variations in event rates. It can be computed efficiently using ideas
from multi-resolution hash encoding and deep sets - achieving 120 Hz at HD and
440 Hz at VGA resolutions. $\text{F}^3$ represents events within a contiguous
spatiotemporal volume as a multi-channel image, enabling a range of downstream
tasks. We obtain state-of-the-art performance on optical flow estimation,
semantic segmentation, and monocular metric depth estimation, on data from
three robotic platforms (a car, a quadruped robot and a flying platform),
across different lighting conditions (daytime, nighttime), environments
(indoors, outdoors, urban, as well as off-road) and dynamic vision sensors
(resolutions and event rates). Our implementations can predict these tasks at
25-75 Hz at HD resolution.

</details>


### [14] [Uni4D-LLM: A Unified SpatioTemporal-Aware VLM for 4D Understanding and Generation](https://arxiv.org/abs/2509.23828)
*Hanyu Zhou,Gim Hee Lee*

Main category: cs.CV

TL;DR: Uni4D-LLM是首个统一的视觉语言模型框架，通过共享表示和架构，在单一Transformer框架中同时处理4D场景理解和生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有3D和4D方法通常将场景几何分别嵌入自回归模型进行语义理解和扩散模型进行内容生成，这种范式差距阻碍了单一模型同时处理理解和生成任务，特别是在需要时空建模的动态4D场景中。

Method: 1) 使用共享表示：提取语义特征用于理解，噪声注入的外观特征用于生成，结合4D几何线索，通过自适应交叉注意力融合为时空感知的视觉表示；2) 使用共享架构：将自回归和扩散都构建在Transformer骨干网络上，集成到单一LLM中，配备任务特定头部。

Result: 在多个基准测试上的广泛实验表明，Uni4D-LLM相比最先进模型取得了竞争性或更优的结果，并首次实现了4D场景理解和生成的真正统一。

Conclusion: Uni4D-LLM通过共享表示和架构的设计，结合指令微调，成功实现了4D场景理解和生成的统一，为物理世界的视觉语言建模提供了新的解决方案。

Abstract: Vision-language models (VLMs) have demonstrated strong performance in 2D
scene understanding and generation, but extending this unification to the
physical world remains an open challenge. Existing 3D and 4D approaches
typically embed scene geometry into autoregressive model for semantic
understanding and diffusion model for content generation. This paradigm gap
prevents a single model from jointly handling both tasks, especially in dynamic
4D settings where spatiotemporal modeling is critical. We propose Uni4D-LLM,
the first unified VLM framework with spatiotemporal awareness for 4D scene
understanding and generation. Our design is guided by two key insights: 1)
Unification requires a shared representation. We extract semantic features for
understanding and noisy-injected appearance features for generation,
incorporate 4D geometric cues, and fuse them into a spatiotemporal-aware visual
representation through adaptive cross-attention. 2) Unification requires a
shared architecture. Both autoregression and diffusion are built on Transformer
backbones, and this enables integration into a single LLM with task-specific
heads. By aligning visual and linguistic representations, our Uni4D-LLM
produces predictions for both understanding and generation within one
Transformer-based framework. We further apply instruction fine-tuning on
diverse 4D vision-language datasets to improve generalization across tasks.
Extensive experiments on multiple benchmarks demonstrate that Uni4D-LLM
achieves competitive or superior results compared to state-of-the-art models
and offers the first true unification of 4D scene understanding and generation.

</details>


### [15] [EYE-DEX: Eye Disease Detection and EXplanation System](https://arxiv.org/abs/2509.24136)
*Youssef Sabiri,Walid Houmaidi,Amine Abouaomar*

Main category: cs.CV

TL;DR: EYE-DEX是一个基于深度学习的视网膜疾病自动诊断框架，使用预训练CNN模型在21,577张眼底图像上对10种视网膜疾病进行分类，达到了92.36%的最先进测试准确率，并通过Grad-CAM提供可视化解释。


<details>
  <summary>Details</summary>
Motivation: 视网膜疾病诊断对预防视力丧失和减轻社会经济负担至关重要。传统手动分级方法耗时且主观，而深度学习可以自动化视网膜图像分析并达到专家级性能。

Method: 使用VGG16、VGG19和ResNet50三种预训练CNN模型在大规模视网膜疾病数据集上进行微调，并集成Grad-CAM技术生成可视化解释。

Result: 微调后的VGG16模型达到了92.36%的全球基准测试准确率，优于其他模型。

Conclusion: EYE-DEX框架在视网膜疾病分类方面实现了最先进的性能，并通过可视化解释增强了AI辅助诊断的透明度和可信度，有助于建立临床医生的信任。

Abstract: Retinal disease diagnosis is critical in preventing vision loss and reducing
socioeconomic burdens. Globally, over 2.2 billion people are affected by some
form of vision impairment, resulting in annual productivity losses estimated at
$411 billion. Traditional manual grading of retinal fundus images by
ophthalmologists is time-consuming and subjective. In contrast, deep learning
has revolutionized medical diagnostics by automating retinal image analysis and
achieving expert-level performance. In this study, we present EYE-DEX, an
automated framework for classifying 10 retinal conditions using the large-scale
Retinal Disease Dataset comprising 21,577 eye fundus images. We benchmark three
pre-trained Convolutional Neural Network (CNN) models--VGG16, VGG19, and
ResNet50--with our finetuned VGG16 achieving a state-of-the-art global
benchmark test accuracy of 92.36%. To enhance transparency and explainability,
we integrate the Gradient-weighted Class Activation Mapping (Grad-CAM)
technique to generate visual explanations highlighting disease-specific
regions, thereby fostering clinician trust and reliability in AI-assisted
diagnostics.

</details>


### [16] [Dynamic Orchestration of Multi-Agent System for Real-World Multi-Image Agricultural VQA](https://arxiv.org/abs/2509.24350)
*Yan Ke,Xin Yu,Heming Du,Scott Chapman,Helen Huang*

Main category: cs.CV

TL;DR: 提出了一种自反思自改进的多智能体框架，用于解决农业视觉问答中多图像输入和外部知识不足的问题，在AgMMU基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有农业视觉问答方法主要针对文本查询或单图像场景，无法处理需要多图像互补视角和生长阶段信息的真实农业场景，且缺乏系统质量控制和外部知识更新能力。

Method: 设计包含检索器、反思器、回答器和改进器的四角色多智能体框架，通过协作实现上下文丰富、反思推理、答案草拟和迭代改进。

Result: 在AgMMU基准测试中，该框架在多图像农业问答任务上取得了有竞争力的性能表现。

Conclusion: 该自反思自改进的多智能体框架能有效处理农业视觉问答中的多图像输入和知识不完整问题，为真实农业场景提供了可行的解决方案。

Abstract: Agricultural visual question answering is essential for providing farmers and
researchers with accurate and timely knowledge. However, many existing
approaches are predominantly developed for evidence-constrained settings such
as text-only queries or single-image cases. This design prevents them from
coping with real-world agricultural scenarios that often require multi-image
inputs with complementary views across spatial scales, and growth stages.
Moreover, limited access to up-to-date external agricultural context makes
these systems struggle to adapt when evidence is incomplete. In addition, rigid
pipelines often lack systematic quality control. To address this gap, we
propose a self-reflective and self-improving multi-agent framework that
integrates four roles, the Retriever, the Reflector, the Answerer, and the
Improver. They collaborate to enable context enrichment, reflective reasoning,
answer drafting, and iterative improvement.
  A Retriever formulates queries and gathers external information, while a
Reflector assesses adequacy and triggers sequential reformulation and renewed
retrieval. Two Answerers draft candidate responses in parallel to reduce bias.
The Improver refines them through iterative checks while ensuring that
information from multiple images is effectively aligned and utilized.
Experiments on the AgMMU benchmark show that our framework achieves competitive
performance on multi-image agricultural QA.

</details>


### [17] [Real-Aware Residual Model Merging for Deepfake Detection](https://arxiv.org/abs/2509.24367)
*Jinhee Park,Guisik Kim,Choongsang Cho,Junseok Kwon*

Main category: cs.CV

TL;DR: 提出了一种无需训练的模型融合框架R²M，用于深度伪造检测，通过分解专家模型的参数空间来共享真实图像特征并聚合伪造特征残差，解决了深度伪造生成器快速演变带来的重复训练问题。


<details>
  <summary>Details</summary>
Motivation: 深度伪造生成器快速演变，使得收集数据和重复训练变得不切实际。模型融合是深度伪造检测的自然选择，因为专家模型共享相同的二元决策，只在生成器特定伪影上有所不同。

Method: 提出Real-aware Residual Model Merging (R²M)框架：通过任务向量的低秩分解估计共享的真实组件，将每个专家模型分解为真实对齐部分和伪造残差，使用层间秩截断对残差去噪，并通过每任务范数匹配聚合以防止单个生成器主导。

Result: 在分布内、跨数据集和未见数据集上，R²M优于联合训练和其他融合基线方法。

Conclusion: R²M是可组合的：当出现新的伪造家族时，只需微调一个专家模型并重新融合，无需重新训练整个系统。

Abstract: Deepfake generators evolve quickly, making exhaustive data collection and
repeated retraining impractical. We argue that model merging is a natural fit
for deepfake detection: unlike generic multi-task settings with disjoint
labels, deepfake specialists share the same binary decision and differ in
generator-specific artifacts. Empirically, we show that simple weight averaging
preserves Real representations while attenuating Fake-specific cues. Building
upon these findings, we propose Real-aware Residual Model Merging (R$^2$M), a
training-free parameter-space merging framework. R$^2$M estimates a shared Real
component via a low-rank factorization of task vectors, decomposes each
specialist into a Real-aligned part and a Fake residual, denoises residuals
with layerwise rank truncation, and aggregates them with per-task norm matching
to prevent any single generator from dominating. A concise rationale explains
why a simple head suffices: the Real component induces a common separation
direction in feature space, while truncated residuals contribute only minor
off-axis variations. Across in-distribution, cross-dataset, and unseen-dataset,
R$^2$M outperforms joint training and other merging baselines. Importantly,
R$^2$M is also composable: when a new forgery family appears, we fine-tune one
specialist and re-merge, eliminating the need for retraining.

</details>


### [18] [Beyond Isolated Facts: Synthesizing Narrative and Grounded Supervision for VideoQA](https://arxiv.org/abs/2509.24445)
*Jianxin Liang,Tan Yue,Yuxuan Wang,Yueqian Wang,Zhihan Yin,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CV

TL;DR: 提出了一种新的VideoQA训练框架，通过问题转述和问题描述两种策略，从孤立的事实问答对中合成更丰富的监督信号，显著提升了模型性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统VideoQA模型的监督信号局限于孤立的事实问答对，无法捕捉视频的叙事结构和因果关系，限制了模型对视频内容的深度理解。

Method: 提出两种互补策略：问题转述将多样化问题合成为整体叙事段落重构事件结构；问题描述为每个问题生成细粒度视觉依据，将答案锚定在具体证据上。利用生成模型合成数据，在统一的下一个token预测目标下训练VideoQA模型。

Result: 在STAR和NExT-QA数据集上的实验验证了方法的有效性，显著提升准确率并建立新的SOTA结果，如3B模型在STAR上达到72.5%（+4.9%），7B模型在NExT-QA上达到80.8%。QBP和QBC都大幅增强了跨数据集泛化能力，QBP还加速模型收敛2.5倍以上。

Conclusion: 将数据合成从孤立事实转向叙事连贯性和有依据的推理，能够产生更准确、高效和可泛化的训练范式。

Abstract: The performance of Video Question Answering (VideoQA) models is fundamentally
constrained by the nature of their supervision, which typically consists of
isolated, factual question-answer pairs. This "bag-of-facts" approach fails to
capture the underlying narrative and causal structure of events, limiting
models to a shallow understanding of video content. To move beyond this
paradigm, we introduce a framework to synthesize richer supervisory signals. We
propose two complementary strategies: Question-Based Paraphrasing (QBP), which
synthesizes the diverse inquiries (what, how, why) from a video's existing set
of question-answer pairs into a holistic narrative paragraph that reconstructs
the video's event structure; and Question-Based Captioning (QBC), which
generates fine-grained visual rationales, grounding the answer to each question
in specific, relevant evidence. Leveraging powerful generative models, we use
this synthetic data to train VideoQA models under a unified next-token
prediction objective. Extensive experiments on STAR and NExT-QA validate our
approach, demonstrating significant accuracy gains and establishing new
state-of-the-art results, such as improving a 3B model to 72.5\% on STAR
(+4.9\%) and a 7B model to 80.8\% on NExT-QA. Beyond accuracy, our analysis
reveals that both QBP and QBC substantially enhance cross-dataset
generalization, with QBP additionally accelerating model convergence by over
2.5x. These results demonstrate that shifting data synthesis from isolated
facts to narrative coherence and grounded rationales yields a more accurate,
efficient, and generalizable training paradigm.

</details>


### [19] [REALIGN: Regularized Procedure Alignment with Matching Video Embeddings via Partial Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2509.24382)
*Soumyadeep Chandra,Kaushik Roy*

Main category: cs.CV

TL;DR: REALIGN是一个基于正则化融合部分Gromov-Wasserstein最优传输的自监督程序学习框架，能够处理程序视频中的背景片段、重复动作和非单调步骤顺序问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的教学视频通常包含背景片段、重复动作和乱序步骤，这种变异性违反了传统对齐方法的强单调性假设。现有方法如OPEL仅依赖特征相似性，无法捕捉任务的高阶时间结构。

Method: 提出R-FPGWOT（正则化融合部分Gromov-Wasserstein最优传输）方法，联合建模视觉对应关系和时间关系，通过部分对齐方案处理无关帧、重复动作和非单调步骤顺序。结合序列间对比学习来稳定训练。

Result: 在EgoProceL、ProceL和CrossTask基准测试中，REALIGN实现了高达18.9%的平均F1分数提升和超过30%的时间IoU增益，同时生成更可解释的传输映射。

Conclusion: REALIGN通过联合建模视觉和时间关系，有效解决了程序视频学习中的对齐挑战，在多个基准测试中表现出色，并提供了更可解释的结果。

Abstract: Learning from procedural videos remains a core challenge in self-supervised
representation learning, as real-world instructional data often contains
background segments, repeated actions, and steps presented out of order. Such
variability violates the strong monotonicity assumptions underlying many
alignment methods. Prior state-of-the-art approaches, such as OPEL, leverage
Kantorovich Optimal Transport (KOT) to build frame-to-frame correspondences,
but rely solely on feature similarity and fail to capture the higher-order
temporal structure of a task. In this paper, we introduce REALIGN, a
self-supervised framework for procedure learning based on Regularized Fused
Partial Gromov-Wasserstein Optimal Transport (R-FPGWOT). In contrast to KOT,
our formulation jointly models visual correspondences and temporal relations
under a partial alignment scheme, enabling robust handling of irrelevant
frames, repeated actions, and non-monotonic step orders common in instructional
videos. To stabilize training, we integrate FPGWOT distances with
inter-sequence contrastive learning, avoiding the need for multiple
regularizers and preventing collapse to degenerate solutions. Across egocentric
(EgoProceL) and third-person (ProceL, CrossTask) benchmarks, REALIGN achieves
up to 18.9% average F1-score improvements and over 30% temporal IoU gains,
while producing more interpretable transport maps that preserve key-step
orderings and filter out noise.

</details>


### [20] [Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs](https://arxiv.org/abs/2509.24640)
*Mohamad Ballout,Okajevo Wilfred,Seyedalireza Yaghoubi,Nohayr Muhammad Abdelmoneim,Julius Mayer,Elia Bruni*

Main category: cs.CV

TL;DR: SPLICE是一个基于COIN教学视频数据集的人类标注基准，用于评估多维度事件推理能力。研究发现VLMs在事件排序任务中表现远低于人类，且更依赖语言先验而非视觉理解。


<details>
  <summary>Details</summary>
Motivation: 构建一个全面的基准来评估事件推理能力，包括时间、因果、空间、上下文和常识推理等多个维度，揭示当前视觉语言模型在视觉推理方面的局限性。

Method: 从COIN数据集中筛选3,381个视频，分为12个类别和180个子类别，分割成11,423个事件片段。通过重新排列这些片段来评估人类和VLMs的事件推理能力。

Result: 人类表现显著优于VLMs。虽然人类标注的文本描述能提高模型准确率，但不影响人类表现，表明模型更依赖语言先验。VLMs在时间因果推理主导的视频中表现相对较好，在专业任务中表现较差。

Conclusion: 当前VLMs在视觉推理方面仍存在显著差距，特别是在上下文和空间推理方面。模型过度依赖语言先验而非真正的视觉理解，需要进一步改进视觉推理能力。

Abstract: In this work, we introduce SPLICE, a human-curated benchmark derived from the
COIN instructional video dataset, designed to probe event-based reasoning
across multiple dimensions: temporal, causal, spatial, contextual, and general
knowledge. SPLICE includes 3,381 human-filtered videos spanning 12 categories
and 180 sub-categories, such as sports, engineering, and housework. These
videos are segmented into a total of 11,423 event clips. We evaluate both human
participants and state-of-the-art vision-language models (VLMs) on the task of
rearranging these clips into coherent event sequences to assess visual
reasoning capabilities. Results reveal a significant gap: VLMs struggle to
match human performance. While human-annotated textual descriptions improve
model accuracy, they do not affect human performance, suggesting that models
rely more on language priors than on visual understanding. Even with
annotations, VLMs fall short of human-level reasoning, underscoring persistent
challenges in visual reasoning. A deeper analysis across sub-categories shows
that VLMs perform relatively better on videos where temporal and causal
reasoning are dominant, compared to those where contextual and spatial
reasoning are dominant. They also perform better on everyday tasks than on
specialized ones.

</details>


### [21] [VNODE: A Piecewise Continuous Volterra Neural Network](https://arxiv.org/abs/2509.24659)
*Siddharth Roheda,Aniruddha Bala,Rohit Chowdhury,Rohan Jaiswal*

Main category: cs.CV

TL;DR: VNODE是一种结合非线性Volterra滤波和神经ODE的混合模型，通过交替离散特征提取和连续状态演化，在图像分类任务中实现高性能且参数更少。


<details>
  <summary>Details</summary>
Motivation: 受视觉皮层中离散事件处理与连续积分交替的启发，旨在开发一种既能捕捉复杂模式又参数更少的深度学习架构。

Method: 将非线性Volterra滤波与连续时间神经ODE结合，交替进行离散Volterra特征提取和ODE驱动的状态演化。

Result: 在CIFAR10和Imagenet1K等基准数据集上持续优于最先进模型，且计算复杂度更低。

Conclusion: VNODE通过混合离散-连续建模方法，在保持高性能的同时显著减少了参数数量，为深度学习提供了更高效的架构选择。

Abstract: This paper introduces Volterra Neural Ordinary Differential Equations
(VNODE), a piecewise continuous Volterra Neural Network that integrates
nonlinear Volterra filtering with continuous time neural ordinary differential
equations for image classification. Drawing inspiration from the visual cortex,
where discrete event processing is interleaved with continuous integration,
VNODE alternates between discrete Volterra feature extraction and ODE driven
state evolution. This hybrid formulation captures complex patterns while
requiring substantially fewer parameters than conventional deep architectures.
VNODE consistently outperforms state of the art models with improved
computational complexity as exemplified on benchmark datasets like CIFAR10 and
Imagenet1K.

</details>


### [22] [IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?](https://arxiv.org/abs/2509.24709)
*Yang Chen,Minghao Liu,Yufan Shen,Yunwen Li,Tianyuan Huang,Xinyu Fang,Tianyu Zheng,Wenxuan Huang,Cheng Yang,Daocheng Fu,Jianbiao Mei,Rong Wu,Licheng Wen,Xuemeng Yang,Song Mao,Qunshu Lin,Zhi Yu,Yongliang Shen,Yu Qiao,Botian Shi*

Main category: cs.CV

TL;DR: 提出了IWR-Bench基准测试，用于评估大型视觉语言模型从视频重建交互式网页的能力，包含113个任务，结果显示现有模型在功能正确性方面表现较差。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注静态截图到代码的任务，忽视了真实网页应用中的动态交互特性，需要新的基准来评估模型对交互逻辑的理解能力。

Method: 构建包含113个任务的基准，涵盖真实网站的交互视频和静态资源，使用代理作为评判框架自动评估生成网页的功能正确性和视觉保真度。

Result: 对28个LVLM的测试显示，最佳模型总体得分仅36.35%，功能正确性得分(24.39%)远低于视觉保真度得分(64.25%)。

Conclusion: 当前模型在理解时间动态和合成事件驱动逻辑方面存在严重局限，IWR-Bench为视觉语言研究设立了具有挑战性的前沿基准。

Abstract: The webpage-to-code task requires models to understand visual representations
of webpages and generate corresponding code. However, existing benchmarks
primarily focus on static screenshot-to-code tasks, thereby overlooking the
dynamic interactions fundamental to real-world web applications. To address
this limitation, this paper introduces IWR-Bench, a novel benchmark for
evaluating the capabilities of Large Vision-Language Models (LVLMs) in
interactive webpage reconstruction from video. IWR-Bench comprises 113
meticulously curated tasks from 100 real-world websites, with 1,001 actions and
featuring diverse interaction complexities (e.g., web games), visual styles,
and domains. Aligning with standard web development practices, each task
includes not only user interaction videos but also all crawled static assets
(e.g., images, videos). This benchmark evaluates models on two fundamental
challenges: comprehensive multi-modal reasoning to infer interaction logic from
video and assets, and advanced code generation to translate this logic into
functional code. An agent-as-a-judge framework with a comprehensive metric
system automatically assesses the functional correctness and visual fidelity of
generated webpages. Extensive experiments on 28 LVLMs reveal a significant
challenge: the best model achieves an overall score of only 36.35%, as
functional correctness (24.39% IFS) lags significantly behind visual fidelity
(64.25% VFS). These results highlight critical limitations in current models'
ability to reason about temporal dynamics and synthesize event-driven logic,
establishing IWR-Bench as a challenging frontier for vision-language research.
The benchmark and evaluation code will be made publicly available. Code is
available at https://github.com/L-O-I/IWR-Bench.

</details>


### [23] [Vision Function Layer in Multimodal LLMs](https://arxiv.org/abs/2509.24791)
*Cheng Shi,Yizhou Yu,Sibei Yang*

Main category: cs.CV

TL;DR: 研究发现多模态大语言模型中视觉相关功能解码分布在不同的解码器层，每种视觉功能（如计数、定位、OCR识别）集中在2-3个特定层（Vision Function Layers）。这些VFL的深度和顺序在不同MLLMs中呈现一致模式，与人类行为模式相符。基于此开发了VFL-LoRA和VFL-select方法，显著提升模型训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 理解多模态大语言模型中视觉功能的具体分布机制，探索如何利用这种分布模式来优化模型训练和应用。

Method: 提出视觉令牌交换（Visual Token Swapping）分析框架，通过修改特定KV缓存条目来精确揭示解码过程中各层的功能。基于VFL发现开发了VFL-LoRA（选择性训练相关功能层）和VFL-select（自动数据分类选择）方法。

Result: 发现不同视觉功能集中在特定2-3个解码层，且层间顺序在不同模型中一致（识别→计数→定位）。VFL-LoRA优于全参数LoRA训练，防止功能遗忘。VFL-select仅用20%数据即可达到98%全数据性能，超越人工数据选择。

Conclusion: 该研究深化了对MLLM视觉处理机制的理解，为开发更高效、可解释和鲁棒的模型提供了理论基础和实践方法。

Abstract: This study identifies that visual-related functional decoding is distributed
across different decoder layers in Multimodal Large Language Models (MLLMs).
Typically, each function, such as counting, grounding, or OCR recognition,
narrows down to two or three layers, which we define as Vision Function Layers
(VFL). Additionally, the depth and its order of different VFLs exhibits a
consistent pattern across different MLLMs, which is well-aligned with human
behaviors (e.g., recognition occurs first, followed by counting, and then
grounding). These findings are derived from Visual Token Swapping, our novel
analytical framework that modifies targeted KV cache entries to precisely
elucidate layer-specific functions during decoding. Furthermore, these insights
offer substantial utility in tailoring MLLMs for real-world downstream
applications. For instance, when LoRA training is selectively applied to VFLs
whose functions align with the training data, VFL-LoRA not only outperform
full-LoRA but also prevent out-of-domain function forgetting. Moreover, by
analyzing the performance differential on training data when particular VFLs
are ablated, VFL-select automatically classifies data by function, enabling
highly efficient data selection to directly bolster corresponding capabilities.
Consequently, VFL-select surpasses human experts in data selection, and
achieves 98% of full-data performance with only 20% of the original dataset.
This study delivers deeper comprehension of MLLM visual processing, fostering
the creation of more efficient, interpretable, and robust models.

</details>


### [24] [StreamForest: Efficient Online Video Understanding with Persistent Event Memory](https://arxiv.org/abs/2509.24871)
*Xiangyu Zeng,Kefan Qiu,Qingyu Zhang,Xinhao Li,Jing Wang,Jiaxin Li,Ziang Yan,Kun Tian,Meng Tian,Xinhai Zhao,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: StreamForest是一个专为流媒体视频理解设计的新架构，通过持久事件记忆森林和细粒度时空窗口解决历史视觉特征存储和实时时空推理不足的问题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视频理解方面取得了显著进展，但在实时流媒体场景中由于历史视觉特征存储限制和实时时空推理不足而效果有限。

Method: 提出StreamForest架构，核心是持久事件记忆森林机制，通过基于时间距离、内容相似性和合并频率的惩罚函数自适应地将视频帧组织成多个事件级树结构；引入细粒度时空窗口捕获详细的短期视觉线索；还提出了专门用于流媒体视频任务的指令调优数据集OnlineIT。

Result: 在StreamingBench上达到77.3%准确率，OVBench上60.5%，OVO-Bench上55.6%；即使在极端视觉token压缩（限制为1024个token）下，模型仍能保持默认设置下平均准确率的96.8%。

Conclusion: StreamForest在流媒体视频理解方面表现出强大的鲁棒性、高效性和泛化能力，为实时视频分析提供了有效的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have recently achieved remarkable
progress in video understanding. However, their effectiveness in real-time
streaming scenarios remains limited due to storage constraints of historical
visual features and insufficient real-time spatiotemporal reasoning. To address
these challenges, we propose StreamForest, a novel architecture specifically
designed for streaming video understanding. Central to StreamForest is the
Persistent Event Memory Forest, a memory mechanism that adaptively organizes
video frames into multiple event-level tree structures. This process is guided
by penalty functions based on temporal distance, content similarity, and merge
frequency, enabling efficient long-term memory retention under limited
computational resources. To enhance real-time perception, we introduce a
Fine-grained Spatiotemporal Window, which captures detailed short-term visual
cues to improve current scene perception. Additionally, we present OnlineIT, an
instruction-tuning dataset tailored for streaming video tasks. OnlineIT
significantly boosts MLLM performance in both real-time perception and future
prediction. To evaluate generalization in practical applications, we introduce
ODV-Bench, a new benchmark focused on real-time streaming video understanding
in autonomous driving scenarios. Experimental results demonstrate that
StreamForest achieves the state-of-the-art performance, with accuracies of
77.3% on StreamingBench, 60.5% on OVBench, and 55.6% on OVO-Bench. In
particular, even under extreme visual token compression (limited to 1024
tokens), the model retains 96.8% of its average accuracy in eight benchmarks
relative to the default setting. These results underscore the robustness,
efficiency, and generalizability of StreamForest for streaming video
understanding.

</details>


### [25] [Event-based Facial Keypoint Alignment via Cross-Modal Fusion Attention and Self-Supervised Multi-Event Representation Learning](https://arxiv.org/abs/2509.24968)
*Donghwa Kang,Junho Kim,Dongwoo Kang*

Main category: cs.CV

TL;DR: 提出基于跨模态融合注意力和自监督多事件表示学习的事件相机面部关键点对齐框架，在真实和合成事件数据集上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 事件相机在低光照和快速运动条件下具有优势，但现有RGB方法在事件数据上表现不佳，且事件数据空间信息有限，缺乏标注数据集

Method: 使用跨模态融合注意力整合RGB数据指导特征提取，结合自监督多事件表示学习从无标签事件数据中学习特征

Result: 在真实E-SIE数据集和合成WFLW-V基准测试中，在多个评估指标上持续超越最先进方法

Conclusion: 该框架有效解决了事件数据空间信息有限和标注数据缺乏的问题，实现了优越的面部关键点对齐性能

Abstract: Event cameras offer unique advantages for facial keypoint alignment under
challenging conditions, such as low light and rapid motion, due to their high
temporal resolution and robustness to varying illumination. However, existing
RGB facial keypoint alignment methods do not perform well on event data, and
training solely on event data often leads to suboptimal performance because of
its limited spatial information. Moreover, the lack of comprehensive labeled
event datasets further hinders progress in this area. To address these issues,
we propose a novel framework based on cross-modal fusion attention (CMFA) and
self-supervised multi-event representation learning (SSMER) for event-based
facial keypoint alignment. Our framework employs CMFA to integrate
corresponding RGB data, guiding the model to extract robust facial features
from event input images. In parallel, SSMER enables effective feature learning
from unlabeled event data, overcoming spatial limitations. Extensive
experiments on our real-event E-SIE dataset and a synthetic-event version of
the public WFLW-V benchmark show that our approach consistently surpasses
state-of-the-art methods across multiple evaluation metrics.

</details>


### [26] [SDPose: Exploiting Diffusion Priors for Out-of-Domain and Robust Pose Estimation](https://arxiv.org/abs/2509.24980)
*Shuang Liang,Jing He,Chuanmeizhi Wang,Lejun Liao,Guo Zhang,Yingcong Chen,Yuan Yuan*

Main category: cs.CV

TL;DR: SDPose是一个基于Stable Diffusion的微调框架，利用预训练扩散先验进行人体姿态估计，在少量训练下达到SOTA性能，并具有出色的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型提供了丰富的多尺度潜在特征，但它们在结构化输出（如人体姿态估计）方面的潜力尚未充分探索。现有方法如Marigold和Lotus主要关注密集预测，而SDPose旨在充分利用扩散先验进行姿态估计。

Method: 1. 直接在SD U-Net的图像潜在空间中预测关键点热图，保留原始生成先验；2. 通过轻量级卷积姿态头将潜在特征映射到关键点热图；3. 加入辅助RGB重建分支以防止过拟合并增强跨域鲁棒性。

Result: 仅使用Sapiens五分之一训练时间，在COCO验证集上达到Sapiens-1B/2B同等水平，在HumanArt和COCO-OOD跨域基准上创下新SOTA。还能作为零样本姿态标注器用于可控生成任务。

Conclusion: SDPose证明了预训练扩散模型作为视觉骨干在结构化预测任务中的强大潜力，通过保留生成先验实现了优异的性能和跨域泛化能力。

Abstract: Pre-trained diffusion models provide rich multi-scale latent features and are
emerging as powerful vision backbones. While recent works such as
Marigold~\citep{ke2024repurposing} and Lotus~\citep{he2024lotus} adapt
diffusion priors for dense prediction with strong cross-domain generalization,
their potential for structured outputs (e.g., human pose estimation) remains
underexplored. In this paper, we propose \textbf{SDPose}, a fine-tuning
framework built upon Stable Diffusion to fully exploit pre-trained diffusion
priors for human pose estimation. First, rather than modifying cross-attention
modules or introducing learnable embeddings, we directly predict keypoint
heatmaps in the SD U-Net's image latent space to preserve the original
generative priors. Second, we map these latent features into keypoint heatmaps
through a lightweight convolutional pose head, which avoids disrupting the
pre-trained backbone. Finally, to prevent overfitting and enhance
out-of-distribution robustness, we incorporate an auxiliary RGB reconstruction
branch that preserves domain-transferable generative semantics. To evaluate
robustness under domain shift, we further construct \textbf{COCO-OOD}, a
style-transferred variant of COCO with preserved annotations. With just
one-fifth of the training schedule used by Sapiens on COCO, SDPose attains
parity with Sapiens-1B/2B on the COCO validation set and establishes a new
state of the art on the cross-domain benchmarks HumanArt and COCO-OOD.
Furthermore, we showcase SDPose as a zero-shot pose annotator for downstream
controllable generation tasks, including ControlNet-based image synthesis and
video generation, where it delivers qualitatively superior pose guidance.

</details>


### [27] [VideoAnchor: Reinforcing Subspace-Structured Visual Cues for Coherent Visual-Spatial Reasoning](https://arxiv.org/abs/2509.25151)
*Zhaozhi Wang,Tong Zhang,Mingyue Guo,Yaowei Wang,Qixiang Ye*

Main category: cs.CV

TL;DR: VideoAnchor是一个即插即用的模块，通过利用子空间亲和性来增强跨帧的视觉线索，无需重新训练即可有效锚定注意力到共享的视觉结构。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉-语言对齐方面取得了显著进展，但在视觉空间推理方面仍然有限。这种限制源于注意力机制：视觉标记被语言标记所掩盖，阻止模型跨帧一致地识别相同的视觉线索。

Method: 提出了VideoAnchor模块，将稀疏子空间聚类中的自表达特性与Transformer中的注意力机制联系起来，利用子空间亲和性来强化跨帧的视觉线索。

Result: 在多个基准测试和骨干模型上的广泛实验显示了一致的性能提升，例如在VSI-Bench和Video-MME（空间相关任务）上分别实现了3.2%和4.6%的改进。定性分析展示了更连贯的子空间分区和更强的视觉基础。

Conclusion: VideoAnchor通过子空间亲和性有效解决了多模态大语言模型在视觉空间推理中的限制，显著提升了性能，同时保持了模型的原有结构。

Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive progress in
vision-language alignment, yet they remain limited in visual-spatial reasoning.
We first identify that this limitation arises from the attention mechanism:
visual tokens are overshadowed by language tokens, preventing the model from
consistently recognizing the same visual cues across frames. To address this
challenge, we draw a novel connection between the self-expressiveness property
in sparse subspace clustering and the attention mechanism in Transformers.
Building on this insight, we propose VideoAnchor, a plug-and-play module that
leverages subspace affinities to reinforce visual cues across frames without
retraining, effectively anchoring attention to shared visual structures.
Extensive experiments across benchmarks and backbone models show consistent
performance gains -- $e.g.$, 3.2% and 4.6% improvements on VSI-Bench and
Video-MME (spatial-related tasks) with InternVL2-8B and Qwen2.5VL-72B -- while
qualitative analyses demonstrate more coherent subspace partitions and stronger
visual grounding. Our codes will be made public available at
https://github.com/feufhd/VideoAnchor.

</details>


### [28] [FlashI2V: Fourier-Guided Latent Shifting Prevents Conditional Image Leakage in Image-to-Video Generation](https://arxiv.org/abs/2509.25187)
*Yunyang Ge,Xinhua Cheng,Chengshu Zhao,Xianyi He,Shenghai Yuan,Bin Lin,Bin Zhu,Li Yuan*

Main category: cs.CV

TL;DR: FlashI2V是一种新的图像到视频生成方法，通过潜在偏移和傅里叶引导来解决条件图像泄漏问题，在域外数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的I2V方法存在条件图像泄漏问题，导致运动缓慢、颜色不一致等性能下降，并且在域外场景中表现不佳。

Method: 提出FlashI2V，包含：(1) 潜在偏移：通过从噪声潜在中减去条件图像信息来修改流匹配的源分布和目标分布；(2) 傅里叶引导：使用傅里叶变换获得的高频幅度特征来加速收敛并调整生成视频的细节水平。

Result: 实验结果表明，该方法有效克服了条件图像泄漏问题，在Vbench-I2V上动态度得分达到53.01，超越了CogVideoX1.5-5B-I2V和Wan2.1-I2V-14B-480P。

Conclusion: FlashI2V仅用1.3B参数就在各种I2V范式中实现了最佳的泛化能力和性能，特别是在域外数据上表现出色。

Abstract: In Image-to-Video (I2V) generation, a video is created using an input image
as the first-frame condition. Existing I2V methods concatenate the full
information of the conditional image with noisy latents to achieve high
fidelity. However, the denoisers in these methods tend to shortcut the
conditional image, which is known as conditional image leakage, leading to
performance degradation issues such as slow motion and color inconsistency. In
this work, we further clarify that conditional image leakage leads to
overfitting to in-domain data and decreases the performance in out-of-domain
scenarios. Moreover, we introduce Fourier-Guided Latent Shifting I2V, named
FlashI2V, to prevent conditional image leakage. Concretely, FlashI2V consists
of: (1) Latent Shifting. We modify the source and target distributions of flow
matching by subtracting the conditional image information from the noisy
latents, thereby incorporating the condition implicitly. (2) Fourier Guidance.
We use high-frequency magnitude features obtained by the Fourier Transform to
accelerate convergence and enable the adjustment of detail levels in the
generated video. Experimental results show that our method effectively
overcomes conditional image leakage and achieves the best generalization and
performance on out-of-domain data among various I2V paradigms. With only 1.3B
parameters, FlashI2V achieves a dynamic degree score of 53.01 on Vbench-I2V,
surpassing CogVideoX1.5-5B-I2V and Wan2.1-I2V-14B-480P. Github page:
https://pku-yuangroup.github.io/FlashI2V/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [OptiMind: Teaching LLMs to Think Like Optimization Experts](https://arxiv.org/abs/2509.22979)
*Zeyi Chen,Xinzhi Zhang,Humishka Zope,Hugo Barbalho,Konstantina Mellou,Marco Molinaro,Janardhan Kulkarni,Ishai Menache,Sirui Li*

Main category: cs.LG

TL;DR: 本文提出了一种结合领域知识的LLM方法，通过数据清洗和多轮推理策略来提升混合整数线性规划问题的自然语言到可执行模型的转换准确率。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的数学编程自动化方法准确率有限，主要受限于训练数据的稀缺性和噪声，且未能充分利用优化领域的专业知识。

Method: 1. 基于类别的错误分析清洗训练数据，防止常见错误；2. 开发多轮推理策略，利用类别特定错误总结和求解器反馈指导LLM进行迭代优化。

Result: 实验表明，结合清洗数据和领域知识提示的方法，平均可将公式化准确率提升14个百分点。

Conclusion: 该方法在多个基础LLM上验证有效，为实现稳健的LLM辅助优化公式化迈出了重要一步。

Abstract: Mathematical programming -- the task of expressing operations and
decision-making problems in precise mathematical language -- is fundamental
across domains, yet remains a skill-intensive process requiring operations
research expertise. Recent advances in large language models for complex
reasoning have spurred interest in automating this task, translating natural
language into executable optimization models. Current approaches, however,
achieve limited accuracy, hindered by scarce and noisy training data without
leveraging domain knowledge. In this work, we systematically integrate
optimization expertise to improve formulation accuracy for mixed-integer linear
programming, a key family of mathematical programs. Our approach first cleans
training data through class-based error analysis to explicitly prevent common
mistakes within each optimization class. We then develop multi-turn inference
strategies that guide LLMs with class-specific error summaries and solver
feedback, enabling iterative refinement. Experiments across multiple base LLMs
demonstrate that combining cleaned data with domain-informed prompting and
feedback improves formulation accuracy by 14 percentage points on average,
enabling further progress toward robust LLM-assisted optimization formulation.

</details>


### [30] [C$^2$GSPG: Confidence-calibrated Group Sequence Policy Gradient towards Self-aware Reasoning](https://arxiv.org/abs/2509.23129)
*Haotian Liu,Shuo Wang,Hongteng Xu*

Main category: cs.LG

TL;DR: 提出了C²GSPG方法，通过置信度校准和组序列策略梯度来解决强化学习中推理模型的过度自信问题，提升推理性能和置信度校准效果。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法（如GRPO及其变体）存在严重的过度自信问题，阻碍了自感知推理模型的发展。

Method: 提出组序列策略梯度（GSPG）框架消除token级偏差，定义基于归一化序列级概率的模型置信度，应用交叉熵正则器将模型置信度校准到序列奖励。

Result: 在逻辑和数学推理任务中，C²GSPG在推理准确性和置信度校准方面均优于最先进方法。

Conclusion: C²GSPG方法有效解决了强化学习推理模型中的过度自信问题，实现了推理性能和置信度校准的双重提升。

Abstract: Reinforcement Learning (RL) methods, exemplified by Group Relative Policy
Optimization (GRPO) and its variants, play a central role in developing
reasoning models. However, these methods often suffer from a critical
overconfidence issue, which prevents them from achieving self-aware reasoning
models. In this study, we propose a simple yet effective confidence-calibration
group sequence policy gradient method, called C$^2$GSPG, which simultaneously
enhances reasoning performance while suppressing overconfidence. In principle,
we propose a Group Sequence Policy Gradient (GSPG) framework for learning
reasoning models, which eliminates the token-level bias commonly appearing in
GRPO and its variants. In this framework, we define the model confidence for
each reasoning problem using the normalized sequence-level probability, and
then apply a cross-entropy regularizer to calibrate the model confidence to the
sequence's reward. We demonstrate that the confidence calibration regularizer
and GSPG are collaborative for binary rewards, as their objectives always share
the same gradient direction. For non-binary rewards, we apply nonlinear reward
normalization and adaptive regularizer clipping, mitigating the potential
conflict between the two objectives. Applying C$^2$GSPG to post-train large
language models in logical and mathematical reasoning tasks, we show its
superiority over state-of-the-art methods in both reasoning accuracy and
confidence calibration. The code of C$^2$GSPG is available at
https://github.com/HaotianLiu123/CCGSPG.

</details>


### [31] [ZeroSiam: An Efficient Siamese for Test-Time Entropy Optimization without Collapse](https://arxiv.org/abs/2509.23183)
*Guohao Chen,Shuaicheng Niu,Deyu Chen,Jiahao Yang,Zitian Zhang,Mingkui Tan,Pengcheng Wu,Zhiqi Shen*

Main category: cs.LG

TL;DR: ZeroSiam是一种用于测试时熵最小化的非对称孪生网络架构，通过非对称散度对齐防止模型崩溃，在视觉适应和大型语言模型推理任务中表现稳定高效。


<details>
  <summary>Details</summary>
Motivation: 纯熵最小化方法容易导致模型崩溃，比如通过膨胀logit范数或将所有预测推向主导类别来减少熵，这会形成无意义的常数输出，而非真正的学习。

Method: 提出ZeroSiam非对称孪生架构，使用可学习的预测器和分类器前的停止梯度操作来实现非对称散度对齐，防止崩溃。

Result: ZeroSiam不仅能防止崩溃，还能吸收和正则化有偏学习信号，在各种测试场景和不同模型（包括易崩溃的小模型）中表现稳定，计算开销极小。

Conclusion: ZeroSiam是一种简单有效的测试时熵最小化方法，通过非对称设计防止模型崩溃，在多种任务中展现出优越性能。

Abstract: Test-time entropy minimization helps adapt a model to novel environments and
incentivize its reasoning capability, unleashing the model's potential during
inference by allowing it to evolve and improve in real-time using its own
predictions, achieving promising performance. However, pure entropy
minimization can favor non-generalizable shortcuts, such as inflating the logit
norm and driving all predictions to a dominant class to reduce entropy, risking
collapsed solutions (e.g., constant one-hot outputs) that trivially minimize
the objective without meaningful learning. In this paper, we introduce
ZeroSiam, an efficient asymmetric Siamese architecture tailored for test-time
entropy minimization. ZeroSiam prevents collapse through asymmetric divergence
alignment, which is efficiently achieved by a learnable predictor and a
stop-gradient operator before the classifier. We provide empirical and
theoretical evidence that ZeroSiam not only prevents collapse solutions, but
also absorbs and regularizes biased learning signals, enhancing performance
even when no collapse occurs. Despite its simplicity, extensive results show
that ZeroSiam performs more stably over prior methods using negligible
overhead, demonstrating efficacy on both vision adaptation and large language
model reasoning tasks across challenging test scenarios and diverse models,
including tiny models that are particularly collapse-prone.

</details>


### [32] [One-Shot Multi-Label Causal Discovery in High-Dimensional Event Sequences](https://arxiv.org/abs/2509.23213)
*Hugo Math,Robin Schön,Rainer Lienhart*

Main category: cs.LG

TL;DR: OSCAR是一种一次性因果自回归方法，使用两个预训练Transformer作为密度估计器来推断每个序列的马尔可夫边界，实现了高效、并行的因果发现，无需昂贵的全局条件独立性测试。


<details>
  <summary>Details</summary>
Motivation: 在医疗、网络安全或车辆诊断等领域，理解具有数千个稀疏事件类型的事件序列中的因果关系至关重要，但现有方法无法扩展到如此大规模的数据。

Method: 使用两个预训练Transformer作为密度估计器，通过一次性因果自回归方法推断每个序列的马尔可夫边界，避免了昂贵的全局条件独立性测试。

Result: 在包含29,100个事件和474个标签的真实世界汽车数据集上，OSCAR在几分钟内恢复了可解释的因果结构，而经典方法无法扩展。

Conclusion: OSCAR能够在生产规模下实现实用的科学诊断，解决了大规模事件序列因果发现的可扩展性问题。

Abstract: Understanding causality in event sequences with thousands of sparse event
types is critical in domains such as healthcare, cybersecurity, or vehicle
diagnostics, yet current methods fail to scale. We present OSCAR, a one-shot
causal autoregressive method that infers per-sequence Markov Boundaries using
two pretrained Transformers as density estimators. This enables efficient,
parallel causal discovery without costly global CI testing. On a real-world
automotive dataset with 29,100 events and 474 labels, OSCAR recovers
interpretable causal structures in minutes, while classical methods fail to
scale, enabling practical scientific diagnostics at production scale.

</details>


### [33] [Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal Transfer With Adversarial Scheduling](https://arxiv.org/abs/2509.23325)
*Jonas Ngnawé,Maxime Heuillet,Sabyasachi Sahoo,Yann Pequignot,Ola Ahmad,Audrey Durand,Frédéric Precioso,Christian Gagné*

Main category: cs.LG

TL;DR: 研究发现，使用鲁棒目标对非鲁棒预训练模型进行微调会导致次优迁移问题，特别是在挑战性场景下可能完全失败。作者提出了Epsilon-Scheduling方法和expected robustness指标来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 尽管开源库中有大量非鲁棒预训练模型，但它们在鲁棒微调（RFT）中的潜力尚未被充分理解。本文旨在系统性地研究从非鲁棒模型进行RFT的问题。

Method: 提出了Epsilon-Scheduling方法，这是一种在训练过程中对扰动强度进行调度的启发式策略，以促进最优迁移。同时引入了expected robustness指标来全面评估模型在测试时的准确性与鲁棒性权衡。

Result: 在广泛的配置（6个预训练模型和5个数据集）上的实验表明，Epsilon-Scheduling成功防止了次优迁移，并持续提高了预期鲁棒性。

Conclusion: Epsilon-Scheduling是一种有效的策略，能够解决从非鲁棒预训练模型进行鲁棒微调时的次优迁移问题，显著提升模型性能。

Abstract: Fine-tuning pretrained models is a standard and effective workflow in modern
machine learning. However, robust fine-tuning (RFT), which aims to
simultaneously achieve adaptation to a downstream task and robustness to
adversarial examples, remains challenging. Despite the abundance of non-robust
pretrained models in open-source repositories, their potential for RFT is less
understood. We address this knowledge gap by systematically examining RFT from
such non-robust models. Our experiments reveal that fine-tuning non-robust
models with a robust objective, even under small perturbations, can lead to
poor performance, a phenomenon that we dub \emph{suboptimal transfer}. In
challenging scenarios (eg, difficult tasks, high perturbation), the resulting
performance can be so low that it may be considered a transfer failure. We find
that fine-tuning using a robust objective impedes task adaptation at the
beginning of training and eventually prevents optimal transfer. However, we
propose a novel heuristic, \emph{Epsilon-Scheduling}, a schedule over
perturbation strength used during training that promotes optimal transfer.
Additionally, we introduce \emph{expected robustness}, a metric that captures
performance across a range of perturbations, providing a more comprehensive
evaluation of the accuracy-robustness trade-off for diverse models at test
time. Extensive experiments on a wide range of configurations (six pretrained
models and five datasets) show that \emph{Epsilon-Scheduling} successfully
prevents \emph{suboptimal transfer} and consistently improves expected
robustness.

</details>


### [34] [PATCH: Learnable Tile-level Hybrid Sparsity for LLMs](https://arxiv.org/abs/2509.23410)
*Younes Hourri,Mohammad Mozaffari,Maryam Mehri Dehnavi*

Main category: cs.LG

TL;DR: PATCH是一种混合稀疏框架，通过将权重矩阵划分为块并学习选择密集块或2:4稀疏块，实现了0%-50%的连续稀疏率，在保持准确性的同时提供实际加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有模型剪枝方法面临两难：非结构化稀疏保持准确性但无法GPU加速，而2:4稀疏硬件友好但强制50%模式会降低模型质量。需要一种能平衡准确性与加速的灵活稀疏方法。

Method: 将权重矩阵划分为块，通过可学习的掩码选择机制为每个块分配密集或2:4稀疏模式，支持跨层非均匀稀疏分布和细粒度精度-加速权衡控制。

Result: 在0.5B到8B参数模型上，PATCH持续缩小与密集模型的准确性差距并提供实际加速。在LLaMA-2 7B上，相比密集基线实现1.18x-1.38x端到端加速，相比最先进的2:4剪枝方法MaskLLM准确性提升0.37%-2.96%。

Conclusion: PATCH框架成功解决了现有稀疏方法的局限性，通过混合稀疏策略在保持模型质量的同时实现了有效的计算加速，为大语言模型的高效部署提供了实用解决方案。

Abstract: Large language models (LLMs) deliver impressive performance but incur
prohibitive memory and compute costs at deployment. Model pruning is an
effective way to reduce these overheads, yet existing approaches face
challenges: unstructured sparsity, where nonzeros can appear anywhere,
preserves accuracy but yields irregular access patterns that prevent GPU
acceleration, while semi-structured 2:4 sparsity is hardware-friendly but
enforces a rigid 50% pattern that degrades model quality. To bridge this gap,
we introduce PATCH, a hybrid sparsity framework that enables a continuous
sparsity ratio between 0% and 50%. PATCH partitions weight matrices into tiles,
assigning each tile to be either dense or 2:4 sparse via a learnable mask
selection mechanism. This design provides fine-grained control over
accuracy-acceleration tradeoffs and supports non-uniform sparsity across
layers, leading to superior overall quality. Across models from 0.5B to 8B
parameters, PATCH consistently narrows the gap to dense accuracy while
delivering practical speedups. For instance, on LLaMA-2 7B with an A6000 GPU,
PATCH achieves 1.18x-1.38x end-to-end speedup over dense baselines while
improving accuracy by 0.37%-2.96% compared to the state-of-the-art 2:4 pruning
method, MaskLLM.

</details>


### [35] [Calibration Meets Reality: Making Machine Learning Predictions Trustworthy](https://arxiv.org/abs/2509.23665)
*Kristina P. Sinaga,Arjun S. Nair*

Main category: cs.LG

TL;DR: 本文对后验校准方法进行了理论分析，重点研究了Platt缩放和保序回归，推导了收敛保证和计算复杂度界限，并通过实验验证了特征信息量对校准性能的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管后验校准方法被广泛使用，但其在不同数据集和模型架构上的性能缺乏全面的理论理解，特别是特征质量与校准性能之间的关系尚未深入研究。

Method: 采用理论分析推导Platt缩放和保序回归的收敛保证和计算复杂度界限，并通过控制合成实验和真实世界数据集评估特征信息量对校准性能的影响。

Result: 实验表明校准方法在各种场景下都能持续改进校准指标，通过比较仅使用信息特征与包含噪声维度的完整特征空间，揭示了不同校准方法的稳健性和可靠性。

Conclusion: 研究结果为基于数据集特征和计算约束选择适当的校准方法提供了实用指南，弥合了不确定性量化中理论理解与实际实施之间的差距。

Abstract: Post-hoc calibration methods are widely used to improve the reliability of
probabilistic predictions from machine learning models. Despite their
prevalence, a comprehensive theoretical understanding of these methods remains
elusive, particularly regarding their performance across different datasets and
model architectures. Input features play a crucial role in shaping model
predictions and, consequently, their calibration. However, the interplay
between feature quality and calibration performance has not been thoroughly
investigated. In this work, we present a rigorous theoretical analysis of
post-hoc calibration methods, focusing on Platt scaling and isotonic
regression. We derive convergence guarantees, computational complexity bounds,
and finite-sample performance metrics for these methods. Furthermore, we
explore the impact of feature informativeness on calibration performance
through controlled synthetic experiments. Our empirical evaluation spans a
diverse set of real-world datasets and model architectures, demonstrating
consistent improvements in calibration metrics across various scenarios. By
examining calibration performance under varying feature conditions utilizing
only informative features versus complete feature spaces including noise
dimensions, we provide fundamental insights into the robustness and reliability
of different calibration approaches. Our findings offer practical guidelines
for selecting appropriate calibration methods based on dataset characteristics
and computational constraints, bridging the gap between theoretical
understanding and practical implementation in uncertainty quantification. Code
and experimental data are available at:
https://github.com/Ajwebdevs/calibration-analysis-experiments.

</details>


### [36] [FraudTransformer: Time-Aware GPT for Transaction Fraud Detection](https://arxiv.org/abs/2509.23712)
*Gholamali Aminian,Andrew Elliott,Tiger Li,Timothy Cheuk Hin Wong,Victor Claude Dehon,Lukasz Szpruch,Carsten Maple,Christopher Read,Martin Brown,Gesine Reinert,Mo Mamouei*

Main category: cs.LG

TL;DR: FraudTransformer是一个用于实时支付欺诈检测的序列模型，通过结合时间编码和位置编码来利用事件顺序和时间间隔信息，在工业数据集上超越了传统方法和简化版transformer。


<details>
  <summary>Details</summary>
Motivation: 现实银行流中的支付欺诈检测需要能够同时利用事件顺序和事件间不规则时间间隔的模型。

Method: 在标准GPT架构基础上增加：(i)专用时间编码器，嵌入绝对时间戳或事件间时间值；(ii)学习的位置编码器，保持相对顺序。

Result: 在包含数千万交易和辅助事件的大型工业数据集上，FraudTransformer超越了四个强基线（逻辑回归、XGBoost、LightGBM）以及省略时间或位置组件的transformer变体，在测试集上获得最高的AUROC和PRAUC。

Conclusion: FraudTransformer通过有效利用序列顺序和时间信息，在支付欺诈检测任务中表现出色，证明了时间感知transformer架构的有效性。

Abstract: Detecting payment fraud in real-world banking streams requires models that
can exploit both the order of events and the irregular time gaps between them.
We introduce FraudTransformer, a sequence model that augments a vanilla
GPT-style architecture with (i) a dedicated time encoder that embeds either
absolute timestamps or inter-event values, and (ii) a learned positional
encoder that preserves relative order. Experiments on a large industrial
dataset -- tens of millions of transactions and auxiliary events -- show that
FraudTransformer surpasses four strong classical baselines (Logistic
Regression, XGBoost and LightGBM) as well as transformer ablations that omit
either the time or positional component. On the held-out test set it delivers
the highest AUROC and PRAUC.

</details>


### [37] [Tequila: Trapping-free Ternary Quantization for Large Language Models](https://arxiv.org/abs/2509.23809)
*Hong Huang,Decheng Wu,Rui Cen,Guanghua Yu,Zonghang Li,Kai Liu,Jianchen Zhu,Peng Chen,Xue Liu,Dapeng Wu*

Main category: cs.LG

TL;DR: Tequila是一种针对大语言模型的三元量化方法，通过将死区陷阱权重重新用作动态偏置，解决了传统三元量化导致的精度损失问题，在几乎不增加推理开销的情况下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决三元量化中权重被困在死区边界的问题，这种死区陷阱导致大量权重只能接收噪声梯度信号，严重限制了模型容量和优化效果。

Method: 提出Tequila方法，将死区陷阱权重重新用作动态偏置，使这些权重在前向传播中提供连续信号，在反向传播中接收有意义的梯度信号。

Result: 在五个基准测试中优于最先进的三元量化方法，在ARC基准上比SOTA基线提升>4%准确率，接近全精度性能（差距<1%），推理速度提升3.0倍。

Conclusion: Tequila为在资源受限环境中部署先进LLMs提供了高度实用和高效的实现方案。

Abstract: Quantization techniques are essential for the deployment of Large Language
Models (LLMs) on edge devices. However, prevailing methods often rely on
mixed-precision multiplication that lacks efficient hardware support, making it
not feasible. Ternary weight quantization addresses this by constraining
weights to {-1, 0, 1}, replacing expensive multiplications with
hardware-efficient additions. However, such aggressive compression leads to
significant accuracy degradation, even after costly quantization-aware training
with massive data. We identify the core issue as deadzone trapping: a large
number of weights are trapped at the deadzone boundary. This occurs because
these weights receive only noisy, uninformative gradients, preventing stable
escape from the deadzone and severely impeding model capacity and optimization.
To address this issue, we propose Tequila, a trapping-free quantization
optimization method that reactivates deadzone-trapped weights by repurposing
them as dynamic biases. This allows the repurposed weights to provide a
continuous signal in the forward pass and, critically, receive direct,
meaningful gradient signals during backpropagation, thereby enhancing model
capacity and optimization with nearly zero inference overhead. Extensive
evaluations demonstrate that Tequila outperforms state-of-the-art (SOTA)
ternary quantization methods across five benchmarks. Specifically, on the ARC
benchmark, it achieves >4% accuracy gain over the SOTA baseline, nearly
matching full-precision performance (within <1% gap) with a 3.0x inference
speedup. Consequently, Tequila offers a highly practical and efficient
implementation for the deployment of advanced LLMs in resource-constrained
environments. The code is available at https://github.com/Tencent/AngelSlim.

</details>


### [38] [A Small Math Model: Recasting Strategy Choice Theory in an LLM-Inspired Architecture](https://arxiv.org/abs/2509.24068)
*Roussel Rahman,Jeff Shrager*

Main category: cs.LG

TL;DR: 将策略选择理论重新构建为基于神经网络的小数学模型，扩展了原理论并展示了计数与加法之间的建设性和破坏性干扰。


<details>
  <summary>Details</summary>
Motivation: 将传统的策略选择理论现代化，使用类似大语言模型的神经网络架构来研究儿童算术学习过程。

Method: 开发小数学模型，包含计数练习、数字符号嵌入和门控注意力机制，基于神经网络架构。

Result: 模型展示了计数与加法之间的建设性和破坏性干扰，以及随着求和回忆能力提高而出现的类似波浪状的手指计数使用模式。

Conclusion: 小数学模型为研究数学推理中数值特征和关系的理解提供了一个统一平台，计划扩展到策略选择和发现等更高级功能。

Abstract: Strategy Choice Theory (SCT)\footnote{``Strategy Choice Theory'',
``Distributions of Associations'', and ``Overlapping Wave Theory'' have been
used to refer to this line of work, emphasizing different
aspects.}\citep[e.g.,][]{siegler1984strategychoices, siegler2000rebirth}
explains important aspects of children's arithmetic learning based upon
principles including learning from developmentally naturalistic data,
probabilistic representation, confidence-based retrieval, and the phase-like
importance of scaffolding strategies, such as finger-counting. Here we recast
SCT as a ``Small Math Model'' (SMM), employing a neural-network-based
architecture analogous to LLMs. The SMM extends SCT to include counting
practice\footnote{The original SCT model was pre-biased in accordance with the
supposed experience of counting.}, symbol (number) embedding, and gated
attention. Similar to earlier work, the SMM demonstrates constructive and
destructive interference between counting and addition, and the ``wave-like''
use of finger-counting as sum recall improves. We plan to extend the SMM to
later aspects of the decades-long SCT program, including adaptive strategy
choice and eventually strategy discovery, providing a unified platform to
investigate the understanding of numerical characteristics and relationships
essential for mathematical reasoning -- as it can emerge in LLM-based agents.

</details>


### [39] [AQUAIR: A High-Resolution Indoor Environmental Quality Dataset for Smart Aquaculture Monitoring](https://arxiv.org/abs/2509.24069)
*Youssef Sabiri,Walid Houmaidi,Ouail El Maadi,Yousra Chtouki*

Main category: cs.LG

TL;DR: AQUAIR是一个开放获取的室内水产养殖环境质量数据集，包含6个IEQ变量，在摩洛哥水产养殖设施中每5分钟采样一次，为智能水产养殖研究提供基准数据。


<details>
  <summary>Details</summary>
Motivation: 由于描述室内养殖池周围空气环境的公共数据集稀缺，限制了结合空气条件与水质动态的预测和异常检测工具的开发。

Method: 使用单个Awair HOME监测器在摩洛哥水产养殖设施中每5分钟采样，记录6个IEQ变量，采用ISO标准安装高度，通过开源处理管道进行质量控制。

Result: 获得了超过23,000个时间戳观测数据，显示稳定环境条件（中位CO2=758 ppm；PM2.5=12微克/立方米）和明显的喂食时间峰值。

Conclusion: AQUAIR填补了智能水产养殖信息学的关键空白，为数据驱动的机器学习课程和环境传感研究提供了可复现的基准。

Abstract: Smart aquaculture systems depend on rich environmental data streams to
protect fish welfare, optimize feeding, and reduce energy use. Yet public
datasets that describe the air surrounding indoor tanks remain scarce, limiting
the development of forecasting and anomaly-detection tools that couple
head-space conditions with water-quality dynamics. We therefore introduce
AQUAIR, an open-access public dataset that logs six Indoor Environmental
Quality (IEQ) variables--air temperature, relative humidity, carbon dioxide,
total volatile organic compounds, PM2.5 and PM10--inside a fish aquaculture
facility in Amghass, Azrou, Morocco. A single Awair HOME monitor sampled every
five minutes from 14 October 2024 to 9 January 2025, producing more than 23,000
time-stamped observations that are fully quality-controlled and publicly
archived on Figshare. We describe the sensor placement, ISO-compliant mounting
height, calibration checks against reference instruments, and an open-source
processing pipeline that normalizes timestamps, interpolates short gaps, and
exports analysis-ready tables. Exploratory statistics show stable conditions
(median CO2 = 758 ppm; PM2.5 = 12 micrograms/m3) with pronounced feeding-time
peaks, offering rich structure for short-horizon forecasting, event detection,
and sensor drift studies. AQUAIR thus fills a critical gap in smart aquaculture
informatics and provides a reproducible benchmark for data-centric machine
learning curricula and environmental sensing research focused on head-space
dynamics in recirculating aquaculture systems.

</details>


### [40] [Echo Flow Networks](https://arxiv.org/abs/2509.24122)
*Hongbo Liu,Jia Xu*

Main category: cs.LG

TL;DR: 提出了Echo Flow Networks (EFNs)，一种基于扩展回声状态网络(X-ESNs)的框架，通过新型矩阵门控复合随机激活(MCRA)和双流架构，在保持计算效率的同时显著提升时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列预测中长程依赖关系捕获的挑战，传统方法在计算复杂度和信息保留能力之间存在权衡，而传统ESNs虽然高效但表达能力有限。

Method: 使用扩展回声状态网络(X-ESNs)与MLP读出层，引入矩阵门控复合随机激活(MCRA)实现复杂的神经元特定时间动态，采用双流架构让近期输入历史动态选择来自无限时域记忆的特征。

Result: 在五个基准数据集上评估，EFNs相比PatchTST等方法训练速度快4倍，模型大小小3倍，预测误差从43%降至35%(相对改进20%)。EchoFormer在ETTh、ETTm、DMV、Weather和Air Quality数据集上达到新的最先进性能。

Conclusion: EFNs框架在保持计算效率的同时显著提升了时间序列预测的准确性和长期稳定性，为长序列建模提供了有效的解决方案。

Abstract: At the heart of time-series forecasting (TSF) lies a fundamental challenge:
how can models efficiently and effectively capture long-range temporal
dependencies across ever-growing sequences? While deep learning has brought
notable progress, conventional architectures often face a trade-off between
computational complexity and their ability to retain accumulative information
over extended horizons.
  Echo State Networks (ESNs), a class of reservoir computing models, have
recently regained attention for their exceptional efficiency, offering constant
memory usage and per-step training complexity regardless of input length. This
makes them particularly attractive for modeling extremely long-term event
history in TSF. However, traditional ESNs fall short of state-of-the-art
performance due to their limited nonlinear capacity, which constrains both
their expressiveness and stability.
  We introduce Echo Flow Networks (EFNs), a framework composed of a group of
extended Echo State Networks (X-ESNs) with MLP readouts, enhanced by our novel
Matrix-Gated Composite Random Activation (MCRA), which enables complex,
neuron-specific temporal dynamics, significantly expanding the network's
representational capacity without compromising computational efficiency. In
addition, we propose a dual-stream architecture in which recent input history
dynamically selects signature reservoir features from an infinite-horizon
memory, leading to improved prediction accuracy and long-term stability.
  Extensive evaluations on five benchmarks demonstrate that EFNs achieve up to
4x faster training and 3x smaller model size compared to leading methods like
PatchTST, reducing forecasting error from 43% to 35%, a 20% relative
improvement. One instantiation of our framework, EchoFormer, consistently
achieves new state-of-the-art performance across five benchmark datasets: ETTh,
ETTm, DMV, Weather, and Air Quality.

</details>


### [41] [Rethinking JEPA: Compute-Efficient Video SSL with Frozen Teachers](https://arxiv.org/abs/2509.24317)
*Xianhang Li,Chen Huang,Chun-Liang Li,Eran Malach,Josh Susskind,Vimal Thilak,Etai Littwin*

Main category: cs.LG

TL;DR: 提出SALT方法，通过两阶段训练（像素重建教师+掩码潜在预测学生）替代EMA自蒸馏，实现更高效、可扩展的视频表示学习


<details>
  <summary>Details</summary>
Motivation: V-JEPA使用EMA更新的教师防止表示崩溃，但增加了模型选择复杂性并耦合了师生架构。作者重新审视掩码潜在预测，发现冻结教师已足够

Method: 两阶段训练：1) 用像素重建目标训练教师编码器；2) 冻结教师，训练学生预测教师对掩码区域的潜在表示

Result: SALT学生在多个基准测试中优于V-JEPA 2编码器，计算效率更高，在相同FLOPs下获得更高准确率，且对教师质量具有鲁棒性

Conclusion: SALT是EMA自蒸馏的简单、可扩展且计算高效的替代方案，建议将计算预算主要分配给学生而非教师

Abstract: Video Joint Embedding Predictive Architectures (V-JEPA) learn generalizable
off-the-shelf video representation by predicting masked regions in latent space
with an exponential moving average (EMA)-updated teacher. While EMA prevents
representation collapse, it complicates scalable model selection and couples
teacher and student architectures. We revisit masked-latent prediction and show
that a frozen teacher suffices. Concretely, we (i) train a target encoder with
a simple pixel-reconstruction objective under V-JEPA masking, then (ii) freeze
it and train a student to predict the teacher's latents on masked regions. This
leads to a two-stage, unregularized scheme that we refer to as SALT
(Static-teacher Asymmetric Latent Training). SALT decouples optimization into
pixel reconstruction (teacher) and masked latent prediction (student),
increasing transparency, efficiency, and scalability while preserving the
ability of representation to generalize under frozen evaluation. Empirically,
our student models outperform recently proposed V-JEPA 2 encoders under frozen
backbone evaluation across diverse benchmarks. They are also more
compute-optimal: at matched pretraining FLOPs, our method achieves higher
probing accuracy, and its scaling curves dominate V-JEPA's accuracy-FLOPs
Pareto frontier. Finally, we find that student quality is remarkably robust to
teacher quality: high-performing students emerge even with small, sub-optimal
teachers. This points to a compute budget allocation that should overwhelmingly
favor the student. These results position SALT as a simple, scalable, and
compute-efficient alternative to EMA-based self-distillation for video
representation learning.

</details>


### [42] [Muon: Training and Trade-offs with Latent Attention and MoE](https://arxiv.org/abs/2509.24406)
*Sushant Mehta,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.LG

TL;DR: Muon优化器在训练小型到中型Transformer解码器时，相比AdamW节省48-52%的计算量，同时保持或改善困惑度。与MLA和MoE结合时，能实现68%内存减少和3.2倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 研究Muon优化器的理论基础和实际性能，验证其在计算效率方面的优势，特别是在与现代化架构优化技术结合时的协同效应。

Method: 提供严格的理论分析包括收敛率证明、谱正则化特性、与Stiefel流形上自然梯度下降的联系，以及在谱范数下与最速梯度下降的等价性。通过100+训练运行进行稳定性分析。

Result: Muon在保持或改善最终困惑度的同时，仅需AdamW 48-52%的训练计算量。与MLA+MoE结合时，实现68%内存减少、3.2倍推理加速和8-12%困惑度改善。

Conclusion: Muon是一个有理论基础、稳健的AdamW替代方案，特别在与现代化效率技术和大批量训练机制结合时表现优异。

Abstract: We present a comprehensive theoretical and empirical study of the Muon
optimizer for training transformers only with a small to medium decoder (30M -
200M parameters), with an emphasis on its mathematical foundations, convergence
properties and synergistic interactions with modern architectural
optimizations. Building on recent work showing Muon's scalability, we provide
rigorous theoretical analysis including: (i)showing the convergence rate under
standard assumptions, (ii) spectral regularization properties that prevent
gradient explosion, (iii) connection to natural gradient descent on the Stiefel
manifold, and (iv) equivalence to steepest gradient descent under the spectral
norm. Crucially, we demonstrate that Muon expands the Pareto frontier in the
compute-time trade-off by maintaining superior data efficiency at large batch
sizes, a key finding of~\cite{essentialai2025muon} that we validate across our
model scales. Empirically, Muon reaches the target loss with 48-52\% of the
training calculated by AdamW while maintaining or improving the final
perplexity, consistent with larger-scale results. When combined with Multi-Head
Latent Attention (MLA) and Mixture-of-Experts (MoE), we observe multiplicative
efficiency gains: MLA+MoE+Muon achieves 68\% memory reduction and 3.2$\times$
inference speedup, while improving perplexity by 8-12\%. We provide detailed
procedures on 15 architectural and optimizer components, stability analyzes
across 100+ training runs, and practical implementation guidelines including
Newton-Schulz coefficients $(3.4445, -4.7750, 2.0315)$ optimized
by~\cite{su2024muonblog}. Our theoretical analysis and comprehensive
experiments establish Muon as a principled, robust alternative to AdamW that
particularly excels when combined with modern efficiency techniques and
large-batch training regimes.

</details>


### [43] [LEAF: A Robust Expert-Based Framework for Few-Shot Continual Event Detection](https://arxiv.org/abs/2509.24547)
*Bao-Ngoc Dao,Quang Nguyen,Luyen Ngo Dinh,Minh Le,Linh Ngo Van*

Main category: cs.LG

TL;DR: LEAF是一个用于少样本持续事件检测的专家混合框架，通过LoRA参数化专家、语义感知专家选择、对比学习和知识蒸馏来缓解灾难性遗忘和提升有限数据下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在少样本持续事件检测中由于完全微调共享基础模型导致的知识干扰和灾难性遗忘问题，以及数据增强策略可能引入不自然或语义扭曲输入的问题。

Method: 1) 在基础模型中集成专家混合架构，每个专家使用LoRA矩阵参数化；2) 语义感知专家选择机制动态路由实例到最相关专家；3) 基于标签描述的对比学习目标；4) 知识蒸馏策略防止内存缓冲区过拟合。

Result: 在多个FCED基准测试上的广泛实验表明，LEAF始终达到最先进的性能。

Conclusion: LEAF通过专家专业化、语义引导学习和知识蒸馏，有效解决了少样本持续事件检测中的知识干扰和灾难性遗忘问题。

Abstract: Few-shot Continual Event Detection (FCED) poses the dual challenges of
learning from limited data and mitigating catastrophic forgetting across
sequential tasks. Existing approaches often suffer from severe forgetting due
to the full fine-tuning of a shared base model, which leads to knowledge
interference between tasks. Moreover, they frequently rely on data augmentation
strategies that can introduce unnatural or semantically distorted inputs. To
address these limitations, we propose LEAF, a novel and robust expert-based
framework for FCED. LEAF integrates a specialized mixture of experts
architecture into the base model, where each expert is parameterized with
low-rank adaptation (LoRA) matrices. A semantic-aware expert selection
mechanism dynamically routes instances to the most relevant experts, enabling
expert specialization and reducing knowledge interference. To improve
generalization in limited-data settings, LEAF incorporates a contrastive
learning objective guided by label descriptions, which capture high-level
semantic information about event types. Furthermore, to prevent overfitting on
the memory buffer, our framework employs a knowledge distillation strategy that
transfers knowledge from previous models to the current one. Extensive
experiments on multiple FCED benchmarks demonstrate that LEAF consistently
achieves state-of-the-art performance.

</details>


### [44] [Circuit-Aware Reward Training: A Mechanistic Framework for Longtail Robustness in RLHF](https://arxiv.org/abs/2509.24713)
*Jing Liu*

Main category: cs.LG

TL;DR: 提出了一个机制可解释性框架来识别奖励模型中负责罕见事件处理的专门神经回路，并引入Circuit-Aware Reward Training (CART)方法来提高长尾分布的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于人类反馈的强化学习(RLHF)奖励模型在长尾分布上存在系统性失败，导致奖励黑客攻击和错位问题。

Method: 使用机制可解释性框架识别专门神经回路，提出CART方法，通过回路分析指导数据增强、正则化和集成策略。

Result: 建立了回路专门化、奖励泛化边界和长尾性能之间的形式化联系。

Conclusion: 该方法为理解奖励模型失败提供了理论洞见，并为提高长尾鲁棒性提供了实际干预措施。

Abstract: Reinforcement Learning from Human Feedback (RLHF) reward models exhibit
systematic failures on longtail distributions, leading to reward hacking and
misalignment. We propose a mechanistic interpretability framework that
identifies specialized neural circuits responsible for rare-event processing in
reward models. Drawing from recent advances showing distributed specialization
for rare tokens in language models\citep{liu2025no, liu2025emergent}, we
hypothesize that reward models also develop functionally distinct circuits for
longtail scenarios. Our theoretical framework establishes formal connections
between circuit specialization, reward generalization bounds, and longtail
performance. We introduce \textbf{Circuit-Aware Reward Training (CART)}, which
uses circuit analysis to guide data augmentation, regularization, and ensemble
strategies. This approach provides both theoretical insights into reward model
failures and practical interventions for improving longtail robustness.

</details>


### [45] [A TRIANGLE Enables Multimodal Alignment Beyond Cosine Similarity](https://arxiv.org/abs/2509.24734)
*Giordano Cicchetti,Eleonora Grassucci,Danilo Comminiello*

Main category: cs.LG

TL;DR: 提出TRIANGLE相似性度量方法，通过三角形面积相似性改进三种模态的联合对齐，在对比损失中替代余弦相似度，显著提升多模态建模性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型存在模态对齐不足的问题，某些模态可能未被有效对齐，导致模型在下游任务中无法充分利用多模态信息。

Method: TRIANGLE：直接在模态嵌入的高维空间中计算三角形面积相似性，避免额外的融合层或成对相似性计算，通过对比损失实现三种模态的联合对齐。

Result: 在视频-文本、音频-文本检索和音频-视频分类等三模态任务中，TRIANGLE取得最先进结果，比基于余弦相似度的方法Recall@1提升高达9个百分点。

Conclusion: TRIANGLE相似性度量能有效提升多模态对齐性能，同时提供可解释的对齐原理，是多模态学习的重要进展。

Abstract: Multimodal learning plays a pivotal role in advancing artificial intelligence
systems by incorporating information from multiple modalities to build a more
comprehensive representation. Despite its importance, current state-of-the-art
models still suffer from severe limitations that prevent the successful
development of a fully multimodal model. Such methods may not provide
indicators that all the involved modalities are effectively aligned. As a
result, some modalities may not be aligned, undermining the effectiveness of
the model in downstream tasks where multiple modalities should provide
additional information that the model fails to exploit. In this paper, we
present TRIANGLE: TRI-modAl Neural Geometric LEarning, the novel proposed
similarity measure that is directly computed in the higher-dimensional space
spanned by the modality embeddings. TRIANGLE improves the joint alignment of
three modalities via a triangle-area similarity, avoiding additional fusion
layers or pairwise similarities. When incorporated in contrastive losses
replacing cosine similarity, TRIANGLE significantly boosts the performance of
multimodal modeling, while yielding interpretable alignment rationales.
Extensive evaluation in three-modal tasks such as video-text and audio-text
retrieval or audio-video classification, demonstrates that TRIANGLE achieves
state-of-the-art results across different datasets improving the performance of
cosine-based methods up to 9 points of Recall@1.

</details>


### [46] [In-Context Learning of Temporal Point Processes with Foundation Inference Models](https://arxiv.org/abs/2509.24762)
*David Berghaus,Patrick Seifner,Kostadin Cvejoski,César Ojeda,Ramsés J. Sánchez*

Main category: cs.LG

TL;DR: 提出了一种基于摊销推理和上下文学习的预训练深度神经网络FIM-PP，能够通过上下文推断事件序列的条件强度函数，无需为目标系统单独训练模型。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络方法需要为每个目标系统训练专门的MTPP模型，我们追求一种完全不同的方法：利用摊销推理和上下文学习来预训练一个通用模型。

Method: 在广泛的Hawkes过程分布上生成的大型合成数据集上预训练深度神经网络，使其能够通过上下文推断事件历史的条件强度函数。

Result: 实验表明，这种摊销方法在常见基准数据集上的下一事件预测任务中与专门模型性能相当。

Conclusion: FIM-PP能够无需额外训练就估计真实数据的MTPP，或快速微调到目标系统，为事件序列建模提供了新的通用方法。

Abstract: Modeling event sequences of multiple event types with marked temporal point
processes (MTPPs) provides a principled way to uncover governing dynamical
rules and predict future events. Current neural network approaches to MTPP
inference rely on training separate, specialized models for each target system.
We pursue a radically different approach: drawing on amortized inference and
in-context learning, we pretrain a deep neural network to infer, in-context,
the conditional intensity functions of event histories from a context defined
by sets of event sequences. Pretraining is performed on a large synthetic
dataset of MTPPs sampled from a broad distribution of Hawkes processes. Once
pretrained, our Foundation Inference Model for Point Processes (FIM-PP) can
estimate MTPPs from real-world data without any additional training, or be
rapidly finetuned to target systems. Experiments show that this amortized
approach matches the performance of specialized models on next-event prediction
across common benchmark datasets.
  Our pretrained model, repository and tutorials will soon be available online

</details>


### [47] [MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models](https://arxiv.org/abs/2509.24779)
*Kacper Kapuśniak,Cristian Gabellini,Michael Bronstein,Prudencio Tossou,Francesco Di Giovanni*

Main category: cs.LG

TL;DR: 提出了一种新的生成模型MSM Emulators，通过马尔可夫状态模型学习离散状态间的转移，相比传统分子动力学模拟实现了两个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟计算成本高昂，现有生成模型学习固定滞后转移密度，训练信号被频繁但无信息的转移主导。

Method: 引入MSM Emulators类生成模型，基于马尔可夫状态模型学习离散状态间的转移，具体实现为Markov Space Flow Matching (MarS-FM)。

Result: MarS-FM在结构观测指标（RMSD、回转半径、二级结构含量）上优于现有方法，在500个残基以内的蛋白质域上表现优异，训练测试集序列差异大时仍能良好泛化。

Conclusion: MSM Emulators框架有效解决了分子动力学模拟的高成本问题，MarS-FM在生成轨迹质量和计算效率方面显著优于现有方法。

Abstract: Molecular Dynamics (MD) is a powerful computational microscope for probing
protein functions. However, the need for fine-grained integration and the long
timescales of biomolecular events make MD computationally expensive. To address
this, several generative models have been proposed to generate surrogate
trajectories at lower cost. Yet, these models typically learn a fixed-lag
transition density, causing the training signal to be dominated by frequent but
uninformative transitions. We introduce a new class of generative models, MSM
Emulators, which instead learn to sample transitions across discrete states
defined by an underlying Markov State Model (MSM). We instantiate this class
with Markov Space Flow Matching (MarS-FM), whose sampling offers more than two
orders of magnitude speedup compared to implicit- or explicit-solvent MD
simulations. We benchmark Mars-FM ability to reproduce MD statistics through
structural observables such as RMSD, radius of gyration, and secondary
structure content. Our evaluation spans protein domains (up to 500 residues)
with significant chemical and structural diversity, including unfolding events,
and enforces strict sequence dissimilarity between training and test sets to
assess generalization. Across all metrics, MarS-FM outperforms existing
methods, often by a substantial margin.

</details>


### [48] [Assessing the risk of future Dunkelflaute events for Germany using generative deep learning](https://arxiv.org/abs/2509.24788)
*Felix Strnad,Jonathan Schmidt,Fabian Mockert,Philipp Hennig,Nicole Ludwig*

Main category: cs.LG

TL;DR: 该研究使用深度学习框架对CMIP6气候模拟进行降尺度，分析德国未来Dunkelflaute事件（低风能和太阳能发电期）的变化趋势。结果表明，在SSP2-4.5和SSP5-8.5排放情景下，这些事件的频率和持续时间与历史时期相比基本保持不变。


<details>
  <summary>Details</summary>
Motivation: 欧洲电网向可再生能源转型，但风能和太阳能的天气依赖性对电网稳定性构成挑战，特别是Dunkelflaute事件可能导致电力供应短缺。研究旨在评估这些事件对未来德国电力生产的影响。

Method: 采用生成式深度学习框架对CMIP6气候模拟进行降尺度，首先与ERA5历史数据统计比较，然后使用降尺度模拟评估德国未来Dunkelflaute事件的发生情况。

Result: 分析表明，在SSP2-4.5和SSP5-8.5排放情景下，德国Dunkelflaute事件的频率和持续时间在集合平均中与历史时期相比基本保持不变。

Conclusion: 在所考虑的气候情景下，Dunkelflaute事件相关的风险预计在整个世纪内保持稳定。

Abstract: The European electricity power grid is transitioning towards renewable energy
sources, characterized by an increasing share of off- and onshore wind and
solar power. However, the weather dependency of these energy sources poses a
challenge to grid stability, with so-called Dunkelflaute events -- periods of
low wind and solar power generation -- being of particular concern due to their
potential to cause electricity supply shortages. In this study, we investigate
the impact of these events on the German electricity production in the years
and decades to come. For this purpose, we adapt a recently developed generative
deep learning framework to downscale climate simulations from the CMIP6
ensemble. We first compare their statistics to the historical record taken from
ERA5 data. Next, we use these downscaled simulations to assess plausible future
occurrences of Dunkelflaute events in Germany under the optimistic low
(SSP2-4.5) and high (SSP5-8.5) emission scenarios. Our analysis indicates that
both the frequency and duration of Dunkelflaute events in Germany in the
ensemble mean are projected to remain largely unchanged compared to the
historical period. This suggests that, under the considered climate scenarios,
the associated risk is expected to remain stable throughout the century.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [49] [AI-Enhanced Distributed Channel Access for Collision Avoidance in Future Wi-Fi 8](https://arxiv.org/abs/2509.23154)
*Jinzhe Pan,Jingqing Wang,Yuehui Ouyang,Wenchi Cheng,Wei Zhang*

Main category: cs.AI

TL;DR: 提出基于多智能体强化学习的Wi-Fi信道接入优化框架，通过动态退避选择和公平性量化指标，在保持与传统设备兼容的同时显著降低碰撞概率并保证公平性。


<details>
  <summary>Details</summary>
Motivation: 当前Wi-Fi系统使用的二进制指数退避机制在密集部署中碰撞解决效果不佳，且存在公平性问题，需要改进分布式信道接入机制以满足新兴应用的高可靠性需求。

Method: 开发动态退避选择机制，结合集中训练分散执行架构，使用约束多智能体近端策略优化算法，整合邻域活动模式作为观测输入，同时引入基于EDCA原则的公平性量化指标。

Result: 实验结果表明，相比传统BEB机制，该方案显著降低碰撞概率，保持与商用Wi-Fi设备的向后兼容性，公平性指标有效消除了异构场景中的饥饿风险。

Conclusion: 该AI优化框架成功解决了Wi-Fi密集部署中的碰撞和公平性问题，为下一代无线网络提供了可行的智能信道接入解决方案。

Abstract: The exponential growth of wireless devices and stringent reliability
requirements of emerging applications demand fundamental improvements in
distributed channel access mechanisms for unlicensed bands. Current Wi-Fi
systems, which rely on binary exponential backoff (BEB), suffer from suboptimal
collision resolution in dense deployments and persistent fairness challenges
due to inherent randomness. This paper introduces a multi-agent reinforcement
learning framework that integrates artificial intelligence (AI) optimization
with legacy device coexistence. We first develop a dynamic backoff selection
mechanism that adapts to real-time channel conditions through access deferral
events while maintaining full compatibility with conventional CSMA/CA
operations. Second, we introduce a fairness quantification metric aligned with
enhanced distributed channel access (EDCA) principles to ensure equitable
medium access opportunities. Finally, we propose a centralized training
decentralized execution (CTDE) architecture incorporating neighborhood activity
patterns as observational inputs, optimized via constrained multi-agent
proximal policy optimization (MAPPO) to jointly minimize collisions and
guarantee fairness. Experimental results demonstrate that our solution
significantly reduces collision probability compared to conventional BEB while
preserving backward compatibility with commercial Wi-Fi devices. The proposed
fairness metric effectively eliminates starvation risks in heterogeneous
scenarios.

</details>


### [50] [Beyond Embeddings: Interpretable Feature Extraction for Binary Code Similarity](https://arxiv.org/abs/2509.23449)
*Charles E. Gagnon,Steven H. H. Ding,Philippe Charland,Benjamin C. M. Fung*

Main category: cs.AI

TL;DR: 提出了一种基于语言模型的二进制代码相似性检测方法，通过结构化推理分析汇编代码生成可解释特征，解决了现有方法在可解释性、泛化性和可扩展性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有二进制代码相似性检测方法存在可解释性、泛化性和可扩展性之间的权衡：手工特征可解释但泛化性差，嵌入方法泛化性好但不可解释且面临可扩展性-精度权衡。

Method: 使用语言模型代理对汇编代码进行结构化推理分析，生成输入/输出类型、副作用、显著常数和算法意图等可解释特征，这些特征可直接用于倒排或关系索引搜索。

Result: 无需匹配训练，在跨架构和跨优化任务中分别达到42%和62%的recall@1，与需要训练的嵌入方法相当（39%和34%）。与嵌入方法结合后显著优于现有最优方法。

Conclusion: 该方法证明了准确性、可扩展性和可解释性可以共存，为二进制代码相似性检测提供了新的解决方案。

Abstract: Binary code similarity detection is a core task in reverse engineering. It
supports malware analysis and vulnerability discovery by identifying
semantically similar code in different contexts. Modern methods have progressed
from manually engineered features to vector representations. Hand-crafted
statistics (e.g., operation ratios) are interpretable, but shallow and fail to
generalize. Embedding-based methods overcome this by learning robust
cross-setting representations, but these representations are opaque vectors
that prevent rapid verification. They also face a scalability-accuracy
trade-off, since high-dimensional nearest-neighbor search requires
approximations that reduce precision. Current approaches thus force a
compromise between interpretability, generalizability, and scalability.
  We bridge these gaps using a language model-based agent to conduct structured
reasoning analysis of assembly code and generate features such as input/output
types, side effects, notable constants, and algorithmic intent. Unlike
hand-crafted features, they are richer and adaptive. Unlike embeddings, they
are human-readable, maintainable, and directly searchable with inverted or
relational indexes. Without any matching training, our method respectively
achieves 42% and 62% for recall@1 in cross-architecture and cross-optimization
tasks, comparable to embedding methods with training (39% and 34%). Combined
with embeddings, it significantly outperforms the state-of-the-art,
demonstrating that accuracy, scalability, and interpretability can coexist.

</details>


### [51] [AgentGuard: Runtime Verification of AI Agents](https://arxiv.org/abs/2509.23864)
*Roham Koohestani*

Main category: cs.AI

TL;DR: AgentGuard是一个用于自主AI系统运行时验证的框架，通过动态概率保证提供连续定量保证，将代理的原始I/O抽象为状态模型中的形式化事件，并使用在线学习构建马尔可夫决策过程来建模代理的涌现行为。


<details>
  <summary>Details</summary>
Motivation: 自主AI系统的快速演进带来了显著风险，其固有的不可预测性和涌现行为使得传统验证方法不足，需要转向概率保证来评估系统在给定约束下的失败概率。

Method: AgentGuard作为检查层观察代理的原始I/O，将其抽象为状态模型转换的形式化事件，使用在线学习动态构建和更新马尔可夫决策过程来形式化建模代理的涌现行为，并通过概率模型检查实时验证定量属性。

Result: 该框架能够提供连续、定量的运行时保证，通过动态概率保证范式有效应对自主AI系统的不可预测性。

Conclusion: AgentGuard为自主AI系统的运行时验证提供了一种有效的方法，通过动态概率保证解决了传统验证方法在处理涌现行为方面的不足。

Abstract: The rapid evolution to autonomous, agentic AI systems introduces significant
risks due to their inherent unpredictability and emergent behaviors; this also
renders traditional verification methods inadequate and necessitates a shift
towards probabilistic guarantees where the question is no longer if a system
will fail, but the probability of its failure within given constraints. This
paper presents AgentGuard, a framework for runtime verification of Agentic AI
systems that provides continuous, quantitative assurance through a new paradigm
called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection
layer that observes an agent's raw I/O and abstracts it into formal events
corresponding to transitions in a state model. It then uses online learning to
dynamically build and update a Markov Decision Process (MDP) that formally
models the agent's emergent behavior. Using probabilistic model checking, the
framework then verifies quantitative properties in real-time.

</details>


### [52] [A Systematic Review of Digital Twin-Driven Predictive Maintenance in Industrial Engineering: Taxonomy, Architectural Elements, and Future Research Directions](https://arxiv.org/abs/2509.24443)
*Leila Ismail,Abdelmoneim Abdelmoti,Arkaprabha Basu,Aymen Dia Eddine Berini,Mohammad Naouss*

Main category: cs.AI

TL;DR: 本文回顾了数字孪生技术在工业工程预测性维护中的发展历程，分析了其应用、中间件和技术需求，提出了分层架构和分类体系，并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着工业系统复杂性增加，传统反应式和预防性维护已无法满足需求，需要利用物联网、人工智能和大数据分析等技术实现高效的预测性维护，而数字孪生技术在其中扮演关键角色。

Method: 采用回顾性分析方法，梳理数字孪生技术在工业工程预测性维护中的时间演化过程，包括应用、中间件和技术需求，提出分层架构和技术分类体系。

Result: 构建了数字孪生技术的分层架构，对技术驱动的工业工程应用系统、中间件和使用的AI算法进行了分类，为实现可信高效的智能数字孪生工业工程生态系统提供了见解。

Conclusion: 数字孪生技术在工业工程预测性维护中具有重要价值，未来需要在数字孪生自学习模型、可信度等方面进行深入研究，以推动智能工业工程生态系统的发展。

Abstract: With the increasing complexity of industrial systems, there is a pressing
need for predictive maintenance to avoid costly downtime and disastrous
outcomes that could be life-threatening in certain domains. With the growing
popularity of the Internet of Things, Artificial Intelligence, machine
learning, and real-time big data analytics, there is a unique opportunity for
efficient predictive maintenance to forecast equipment failures for real-time
intervention and optimize maintenance actions, as traditional reactive and
preventive maintenance practices are often inadequate to meet the requirements
for the industry to provide quality-of-services of operations. Central to this
evolution is digital twin technology, an adaptive virtual replica that
continuously monitors and integrates sensor data to simulate and improve asset
performance. Despite remarkable progress in digital twin implementations, such
as considering DT in predictive maintenance for industrial engineering. This
paper aims to address this void. We perform a retrospective analysis of the
temporal evolution of the digital twin in predictive maintenance for industrial
engineering to capture the applications, middleware, and technological
requirements that led to the development of the digital twin from its inception
to the AI-enabled digital twin and its self-learning models. We provide a
layered architecture of the digital twin technology, as well as a taxonomy of
the technology-enabled industrial engineering applications systems, middleware,
and the used Artificial Intelligence algorithms. We provide insights into these
systems for the realization of a trustworthy and efficient smart digital-twin
industrial engineering ecosystem. We discuss future research directions in
digital twin for predictive maintenance in industrial engineering.

</details>


### [53] [TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models](https://arxiv.org/abs/2509.24803)
*Tong Guan,Zijie Meng,Dianqi Li,Shiyu Wang,Chao-Han Huck Yang,Qingsong Wen,Zuozhu Liu,Sabato Marco Siniscalchi,Ming Jin,Shirui Pan*

Main category: cs.AI

TL;DR: 提出了TSR-Suite时间序列推理套件，包含四个原子任务和三个核心能力（感知、外推、决策），并基于此开发了首个统一推理模型TimeOmni-1，在因果发现和事件感知预测等任务上显著优于GPT-4.1。


<details>
  <summary>Details</summary>
Motivation: 现有多模态时间序列数据集大多停留在表面对齐和问答层面，缺乏真正需要推理的任务定义和高质量数据，限制了时间序列推理模型的发展。

Method: 构建TSR-Suite套件，包含23K+样本（其中2.3K经过人工标注），定义四个原子任务和三个推理能力；开发TimeOmni-1模型，采用多阶段训练，结合任务场景混合、新奖励函数和定制优化。

Result: TimeOmni-1在所有任务上表现出强大的分布外泛化能力，因果发现准确率显著提升（64.0% vs 35.9%），事件感知预测任务的有效响应率比GPT-4.1提高超过6%。

Conclusion: TSR-Suite是首个全面的时间序列推理套件，TimeOmni-1作为首个统一推理模型，在时间序列推理任务上取得了显著进展，为实际应用提供了有力工具。

Abstract: Recent advances in multimodal time series learning underscore a paradigm
shift from analytics centered on basic patterns toward advanced time series
understanding and reasoning. However, existing multimodal time series datasets
mostly remain at the level of surface alignment and question answering, without
reaching the depth of genuine reasoning. The absence of well-defined tasks that
genuinely require time series reasoning, along with the scarcity of
high-quality data, has limited progress in building practical time series
reasoning models (TSRMs). To this end, we introduce Time Series Reasoning Suite
(TSR-Suite), which formalizes four atomic tasks that span three fundamental
capabilities for reasoning with time series: (1) perception, acquired through
scenario understanding and causality discovery; (2) extrapolation, realized via
event-aware forecasting; and (3) decision-making, developed through
deliberation over perception and extrapolation. TSR-Suite is the first
comprehensive time series reasoning suite that supports not only thorough
evaluation but also the data pipeline and training of TSRMs. It contains more
than 23K samples, of which 2.3K are carefully curated through a human-guided
hierarchical annotation process. Building on this foundation, we introduce
TimeOmni-1, the first unified reasoning model designed to address diverse
real-world problems demanding time series reasoning. The model is trained in
multiple stages, integrating a mixture of task scenarios, novel reward
functions, and tailored optimizations. Experiments show that TimeOmni-1
delivers strong out-of-distribution generalization across all tasks and
achieves a high rate of valid responses. It significantly improves causality
discovery accuracy (64.0% vs. 35.9% with GPT-4.1) and raises the valid response
rate by over 6% compared to GPT-4.1 on the event-aware forecasting task.

</details>


### [54] [UniAPL: A Unified Adversarial Preference Learning Framework for Instruct-Following](https://arxiv.org/abs/2509.25148)
*FaQiang Qian,WeiKun Zhang,Ziliang Wang,Kang An,Xuhui Zheng,Liangjian Wen,Mengya Gao,Yong Dai,Yichao Wu*

Main category: cs.AI

TL;DR: UniAPL是一个统一对抗偏好学习框架，通过单阶段训练同时利用演示偏好和比较偏好数据，解决传统SFT+RL流程中的分布不匹配问题，实现了更好的性能和行为对齐。


<details>
  <summary>Details</summary>
Motivation: 传统SFT后接RL的流程存在关键问题：SFT使用静态专家数据，但策略演化时生成分布会漂移，导致SFT知识脆弱；后续RL缺乏对专家演示中丰富真实知识的直接访问，造成低效、无基础的更新。这种分离阻碍了数据源之间的相互正则化。

Method: 将对齐问题重构为约束优化问题，提出UniAPL框架，通过单阶段统一训练目标，从混合的SFT和偏好数据批次中联合学习。在每个梯度步骤中，密集的专家演示直接基础和正则化在线探索，固有地解决分布不匹配并最大化数据协同。

Result: 在指令跟随任务上评估UniAPL，使用Qwen3-235B-Instruct-2507作为教师模型。UniAPL模型匹配或超过强GRPO基线：Qwen3-0.6B上提升5.77%（匹配32B模型性能），Qwen3-4B上提升3.75%，甚至超过教师模型。响应长度和对数概率分布分析确认UniAPL输出紧密模仿专家演示。

Conclusion: UniAPL通过统一框架同时利用两种偏好数据，有效解决了传统方法中的分布不匹配问题，实现了更强的性能和更好的行为对齐，证明了统一偏好学习方法的有效性。

Abstract: Shaping powerful LLMs to be beneficial and safe is central to AI alignment.
We argue that post-training alignment is fundamentally a unified Preference
Learning problem, involving two modalities: demonstrated preferences (e.g.,
Supervised Fine-Tuning, SFT) and comparative preferences (e.g., Reinforcement
Learning, RL).The standard sequential pipeline-SFT followed by RL-is flawed due
to a critical distributional mismatch: SFT uses static expert data, but as the
policy evolves, its generation distribution drifts, making SFT knowledge
brittle. Subsequent RL then explores without direct access to the rich,
ground-truth knowledge in expert demonstrations, leading to inefficient,
ungrounded updates. This separation prevents mutual regularization between data
sources. To address this, we reframe alignment as a constrained optimization
problem and propose Unified Adversarial Preference Learning (UniAPL),a novel
framework that dynamically aligns the policy's distribution with the expert's.
UniAPL implements a single-stage unified training objective, jointly learning
from mixed batches of SFT and preference data. In every gradient step, dense
expert demonstrations directly ground and regularize online exploration,
inherently resolving distributional mismatch and maximizing data synergy.We
evaluate UniAPL on instruction-following tasks using Qwen3-235B-Instruct-2507
as the teacher. Our models match or exceed strong GRPO baselines: +5.77% on
Qwen3-0.6B (matching a 32B model) and +3.75% on Qwen3-4B,even outperforming the
teacher. Analyses of response length and log-probability distributions confirm
that UniAPL outputs closely mimic expert demonstrations, achieving both
stronger performance and better behavioral alignment.

</details>


### [55] [Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective](https://arxiv.org/abs/2509.22613)
*Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen*

Main category: cs.AI

TL;DR: 该论文通过图抽象分析强化学习在LLM规划中的理论机制，发现SFT会产生虚假解，RL通过探索实现正确规划，但PG存在多样性崩溃问题，而Q学习能保持多样性且避免奖励黑客。


<details>
  <summary>Details</summary>
Motivation: 当前RL方法显著提升了LLM的规划能力，但其理论有效性基础尚不明确，需要从理论层面分析RL的益处和局限性。

Method: 采用可处理的图抽象方法，重点分析策略梯度(PG)和Q学习方法，并在Blocksworld规划基准上进行实证验证。

Result: 理论分析表明：SFT引入基于共现的虚假解；RL通过探索实现正确规划；PG存在多样性崩溃问题；Q学习具有离策略学习和多样性保持优势；需要精心设计奖励函数防止奖励黑客。

Conclusion: 探索在RL规划中具有关键作用，Q学习相比PG在保持多样性方面更具优势，但需要谨慎的奖励设计来确保有效性。

Abstract: Recent reinforcement learning (RL) methods have substantially enhanced the
planning capabilities of Large Language Models (LLMs), yet the theoretical
basis for their effectiveness remains elusive. In this work, we investigate
RL's benefits and limitations through a tractable graph-based abstraction,
focusing on policy gradient (PG) and Q-learning methods. Our theoretical
analyses reveal that supervised fine-tuning (SFT) may introduce
co-occurrence-based spurious solutions, whereas RL achieves correct planning
primarily through exploration, underscoring exploration's role in enabling
better generalization. However, we also show that PG suffers from diversity
collapse, where output diversity decreases during training and persists even
after perfect accuracy is attained. By contrast, Q-learning provides two key
advantages: off-policy learning and diversity preservation at convergence. We
further demonstrate that careful reward design is necessary to prevent reward
hacking in Q-learning. Finally, applying our framework to the real-world
planning benchmark Blocksworld, we confirm that these behaviors manifest in
practice.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [56] [A2D: Any-Order, Any-Step Safety Alignment for Diffusion Language Models](https://arxiv.org/abs/2509.23286)
*Wonje Jeung,Sangyeon Yoon,Yoonjun Cho,Dongjae Jeon,Sangwoo Shin,Hyesoo Hong,Albert No*

Main category: cs.CL

TL;DR: A2D是一种针对扩散大语言模型的令牌级安全对齐方法，通过在任意位置检测有害内容并发出[EOS]拒绝信号，有效防御任意解码顺序和预填充攻击。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型的任意顺序生成特性扩大了攻击面，有害内容可能出现在任意位置，且模板预填充攻击如DIJA能够绕过响应级拒绝机制。

Method: 采用令牌级对齐方法，在随机掩码条件下训练模型在检测到有害内容时发出[EOS]拒绝信号，实现实时监控和自动终止不安全生成。

Result: 在安全基准测试中，A2D将DIJA攻击成功率从80%以上降至接近零（LLaDA-8B-Instruct为1.3%，Dream-v0-Instruct-7B为0.0%），并通过阈值[EOS]概率实现早期拒绝，安全终止速度提升高达19.3倍。

Conclusion: A2D方法有效解决了扩散大语言模型的安全对齐问题，提供了对任意顺序和任意步骤攻击的鲁棒防御，同时支持实时安全监控。

Abstract: Diffusion large language models (dLLMs) enable any-order generation, but this
flexibility enlarges the attack surface: harmful spans may appear at arbitrary
positions, and template-based prefilling attacks such as DIJA bypass
response-level refusals. We introduce A2D (Any-Order, Any-Step Defense), a
token-level alignment method that aligns dLLMs to emit an [EOS] refusal signal
whenever harmful content arises. By aligning safety directly at the token-level
under randomized masking, A2D achieves robustness to both any-decoding-order
and any-step prefilling attacks under various conditions. It also enables
real-time monitoring: dLLMs may begin a response but automatically terminate if
unsafe continuation emerges. On safety benchmarks, A2D consistently prevents
the generation of harmful outputs, slashing DIJA success rates from over 80% to
near-zero (1.3% on LLaDA-8B-Instruct, 0.0% on Dream-v0-Instruct-7B), and
thresholded [EOS] probabilities allow early rejection, yielding up to 19.3x
faster safe termination.

</details>


### [57] [Assessing Large Language Models in Updating Their Forecasts with New Information](https://arxiv.org/abs/2509.23936)
*Zhangdie Yuan,Zifeng Ding,Andreas Vlachos*

Main category: cs.CL

TL;DR: EVOLVECAST框架评估大语言模型在新信息出现时是否适当调整预测，发现LLM的预测更新往往不一致或过于保守，置信度估计远未达到人类标准。


<details>
  <summary>Details</summary>
Motivation: 现有研究将未来事件预测视为静态任务，忽视了随着新证据出现预测和置信度应如何演变的问题。

Method: 使用EVOLVECAST框架，以人类预测者为参考基准，分析LLM在更新上下文下的预测偏移和置信度校准。

Result: LLM对新信息有一定响应性，但更新往往不一致或过于保守；口头表达和基于logits的置信度估计均未显著优于对方，且都远低于人类标准。

Conclusion: 模型普遍表现出保守偏差，需要更稳健的信念更新方法。

Abstract: Prior work has largely treated future event prediction as a static task,
failing to consider how forecasts and the confidence in them should evolve as
new evidence emerges. To address this gap, we introduce EVOLVECAST, a framework
for evaluating whether large language models appropriately revise their
predictions in response to new information. In particular, EVOLVECAST assesses
whether LLMs adjust their forecasts when presented with information released
after their training cutoff. We use human forecasters as a comparative
reference to analyze prediction shifts and confidence calibration under updated
contexts. While LLMs demonstrate some responsiveness to new information, their
updates are often inconsistent or overly conservative. We further find that
neither verbalized nor logits-based confidence estimates consistently
outperform the other, and both remain far from the human reference standard.
Across settings, models tend to express conservative bias, underscoring the
need for more robust approaches to belief updating.

</details>


### [58] [Toward Preference-aligned Large Language Models via Residual-based Model Steering](https://arxiv.org/abs/2509.23982)
*Lucio La Cava,Andrea Tagarelli*

Main category: cs.CL

TL;DR: PaLRS是一种无需训练的大语言模型偏好对齐方法，通过提取残差流中的偏好信号来创建轻量级转向向量，在推理时引导模型产生偏好行为。


<details>
  <summary>Details</summary>
Motivation: 现有偏好对齐方法（如RLHF、DPO）需要精心策划的数据和昂贵的参数优化，导致任务特定的模型。PaLRS旨在提供更高效、灵活的训练免费替代方案。

Method: 从少量偏好对中提取残差流中的偏好信号，创建轻量级即插即用转向向量，在推理时应用这些向量来引导模型行为。

Result: PaLRS对齐的模型在数学推理和代码生成基准上获得一致提升，同时保持基线通用性能。与DPO对齐模型相比表现更好且节省大量时间。

Conclusion: PaLRS为偏好对齐提供了有效、高效且灵活的替代方案，仅需最少数据即可实现训练免费的即插即用对齐机制。

Abstract: Preference alignment is a critical step in making Large Language Models
(LLMs) useful and aligned with (human) preferences. Existing approaches such as
Reinforcement Learning from Human Feedback or Direct Preference Optimization
typically require curated data and expensive optimization over billions of
parameters, and eventually lead to persistent task-specific models. In this
work, we introduce Preference alignment of Large Language Models via Residual
Steering (PaLRS), a training-free method that exploits preference signals
encoded in the residual streams of LLMs. From as few as one hundred preference
pairs, PaLRS extracts lightweight, plug-and-play steering vectors that can be
applied at inference time to push models toward preferred behaviors. We
evaluate PaLRS on various small-to-medium-scale open-source LLMs, showing that
PaLRS-aligned models achieve consistent gains on mathematical reasoning and
code generation benchmarks while preserving baseline general-purpose
performance. Moreover, when compared to DPO-aligned models, they perform better
with huge time savings. Our findings highlight that PaLRS offers an effective,
much more efficient and flexible alternative to standard preference
optimization pipelines, offering a training-free, plug-and-play mechanism for
alignment with minimal data.

</details>


### [59] [SparseD: Sparse Attention for Diffusion Language Models](https://arxiv.org/abs/2509.24014)
*Zeqing Wang,Gongfan Fang,Xinyin Ma,Xingyi Yang,Xinchao Wang*

Main category: cs.CL

TL;DR: 提出了SparseD方法，通过利用扩散语言模型中注意力模式的特定特性（头部特异性、跨步相似性、早期步骤关键性），实现了无损加速，在64k上下文长度下比FlashAttention快1.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有的开源扩散语言模型存在高推理延迟问题，主要原因是注意力机制在长上下文中的二次复杂度。虽然稀疏注意力在自回归模型中已有应用，但扩散语言模型中的注意力模式具有不同的稀疏特性，需要专门的方法。

Method: SparseD方法：1）预计算头部特定的稀疏模式并跨步重用；2）早期步骤使用全注意力，后期切换为稀疏注意力以保持生成质量。

Result: 实验结果显示SparseD实现了无损加速，在64k上下文长度和1024去噪步骤下，比FlashAttention快1.5倍。

Conclusion: SparseD是一个实用高效的解决方案，可用于在长上下文应用中部署扩散语言模型。

Abstract: While diffusion language models (DLMs) offer a promising alternative to
autoregressive models (ARs), existing open-source DLMs suffer from high
inference latency. This bottleneck is mainly due to the attention's quadratic
complexity with respect to context length in computing all query-key pairs.
Intuitively, to reduce this complexity, a natural strategy is to restrict
attention to sparse patterns that retain only the most relevant connections.
Such approaches are well-established in ARs, where attention follows fixed and
clearly defined sparse patterns. However, in DLMs, we observe distinct sparsity
behaviors: (1) attention patterns vary across heads, (2) attention patterns in
each head remain highly similar across denoising steps, and (3) early denoising
steps are critical for generation. These findings render sparse attention
methods designed for ARs largely incompatible with DLMs, as they fail to
capture head-specific structures and risk degrading generation when applied in
early denoising steps. To address these challenges, we propose SparseD, a novel
sparse attention method for DLMs. Leveraging the observations, SparseD only
requires pre-computing head-specific sparse patterns one time, and reuses them
across all steps. This prevents recomputing sparse patterns at each denoising
step. Meanwhile, SparseD uses full attention in the early steps, then switches
to sparse attention later to maintain generation quality. Together, these
establish SparseD as a practical and efficient solution for deploying DLMs in
long-context applications. Experimental results demonstrate that SparseD
achieves lossless acceleration, delivering up to $1.50\times$ speedup over
FlashAttention at a 64k context length with 1,024 denoising steps.

</details>


### [60] [KnowGuard: Knowledge-Driven Abstention for Multi-Round Clinical Reasoning](https://arxiv.org/abs/2509.24816)
*Xilin Dang,Kexin Chen,Xiaorui Su,Ayush Noori,Iñaki Arango,Lucas Vittor,Xinyi Long,Yuyang Du,Marinka Zitnik,Pheng Ann Heng*

Main category: cs.CL

TL;DR: KnowGuard是一个新颖的"调查-再弃权"范式，通过系统性的知识图谱探索来改进临床决策中的弃权机制，显著提高了诊断准确性并减少了不必要的交互。


<details>
  <summary>Details</summary>
Motivation: 在临床实践中，医生会在患者信息不足时选择弃权以避免误诊，但现有的大型语言模型缺乏有效的弃权机制，经常在信息不完整时给出过度自信的回答。

Method: 提出KnowGuard方法，包含两个关键阶段：1)证据发现阶段通过图谱扩展和直接检索系统探索医学知识空间；2)证据评估阶段使用多因素对证据进行排序，根据患者上下文和对话历史自适应调整探索策略。

Result: KnowGuard在开放式多轮临床基准测试中表现优异，相比最先进的弃权方法，诊断准确率提高了3.93%，平均减少了7.27次不必要的交互。

Conclusion: KnowGuard通过系统性的知识图谱探索有效改进了LLMs在临床决策中的弃权能力，为医疗AI提供了更安全可靠的决策支持。

Abstract: In clinical practice, physicians refrain from making decisions when patient
information is insufficient. This behavior, known as abstention, is a critical
safety mechanism preventing potentially harmful misdiagnoses. Recent
investigations have reported the application of large language models (LLMs) in
medical scenarios. However, existing LLMs struggle with the abstentions,
frequently providing overconfident responses despite incomplete information.
This limitation stems from conventional abstention methods relying solely on
model self-assessments, which lack systematic strategies to identify knowledge
boundaries with external medical evidences. To address this, we propose
\textbf{KnowGuard}, a novel \textit{investigate-before-abstain} paradigm that
integrates systematic knowledge graph exploration for clinical decision-making.
Our approach consists of two key stages operating on a shared contextualized
evidence pool: 1) an evidence discovery stage that systematically explores the
medical knowledge space through graph expansion and direct retrieval, and 2) an
evidence evaluation stage that ranks evidence using multiple factors to adapt
exploration based on patient context and conversation history. This two-stage
approach enables systematic knowledge graph exploration, allowing models to
trace structured reasoning paths and recognize insufficient medical evidence.
We evaluate our abstention approach using open-ended multi-round clinical
benchmarks that mimic realistic diagnostic scenarios, assessing abstention
quality through accuracy-efficiency trade-offs beyond existing closed-form
evaluations. Experimental evidences clearly demonstrate that KnowGuard
outperforms state-of-the-art abstention approaches, improving diagnostic
accuracy by 3.93\% while reducing unnecessary interaction by 7.27 turns on
average.

</details>


### [61] [Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202)
*Shubhashis Roy Dipta,Francis Ferraro*

Main category: cs.CL

TL;DR: Q2E是一种查询到事件分解方法，用于零样本多语言文本到视频检索，通过分解查询来增强对简化人类查询的理解，并整合视觉和语音信息。


<details>
  <summary>Details</summary>
Motivation: 改进复杂现实世界事件相关视频的识别和检索，通过自动提取关于这些事件的潜在参数知识。

Method: 使用嵌入在LLMs和VLMs中的知识分解查询，采用基于熵的融合评分进行零样本融合，适用于视觉和语音输入。

Result: 在两个多样化数据集和多个检索指标上的评估表明，Q2E优于多个最先进的基线方法，音频信息的整合显著改善了文本到视频检索。

Conclusion: Q2E方法通过分解查询和整合多模态知识，有效提升了零样本多语言文本到视频检索的性能。

Abstract: Recent approaches have shown impressive proficiency in extracting and
leveraging parametric knowledge from Large-Language Models (LLMs) and
Vision-Language Models (VLMs). In this work, we consider how we can improve the
identification and retrieval of videos related to complex real-world events by
automatically extracting latent parametric knowledge about those events. We
present Q2E: a Query-to-Event decomposition method for zero-shot multilingual
text-to-video retrieval, adaptable across datasets, domains, LLMs, or VLMs. Our
approach demonstrates that we can enhance the understanding of otherwise overly
simplified human queries by decomposing the query using the knowledge embedded
in LLMs and VLMs. We additionally show how to apply our approach to both visual
and speech-based inputs. To combine this varied multimodal knowledge, we adopt
entropy-based fusion scoring for zero-shot fusion. Through evaluations on two
diverse datasets and multiple retrieval metrics, we demonstrate that Q2E
outperforms several state-of-the-art baselines. Our evaluation also shows that
integrating audio information can significantly improve text-to-video
retrieval. We have released code and data for future research.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [62] [FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task](https://arxiv.org/abs/2509.23112)
*Ryo Watanabe,Maxime Alvarez,Pablo Ferreiro,Pavel Savkin,Genki Sano*

Main category: cs.RO

TL;DR: 提出了一种多模态模仿学习策略，通过将力/力矩传感与Action Chunking Transformer结合，改进零售环境中机器人对直立饮料瓶的抓取和重定向任务。


<details>
  <summary>Details</summary>
Motivation: 零售环境中机械臂在接触丰富的边缘案例（如直立饮料瓶操作）中仍需要昂贵的人工遥控操作，纯视觉线索不足以解决精确操作所需的细微接触事件。

Method: 开发多模态模仿学习策略，将力/力矩传感集成到Action Chunking Transformer中，实现图像、关节状态、力/力矩的端到端学习，在Telexistence公司的Ghost单臂平台上部署。

Result: 硬件实验显示相比基线方法（仅匹配ACT观测空间）有更高的任务成功率，力/力矩信号在视觉可观测性受限的按压和放置阶段特别有益。

Conclusion: 通过将现代模仿学习架构与轻量级力/力矩传感相结合，为扩展零售操作提供了一条实用路径，支持将交互力作为接触丰富技能的补充模态。

Abstract: Manipulator robots are increasingly being deployed in retail environments,
yet contact rich edge cases still trigger costly human teleoperation. A
prominent example is upright lying beverage bottles, where purely visual cues
are often insufficient to resolve subtle contact events required for precise
manipulation. We present a multimodal Imitation Learning policy that augments
the Action Chunking Transformer with force and torque sensing, enabling
end-to-end learning over images, joint states, and forces and torques. Deployed
on Ghost, single-arm platform by Telexistence Inc, our approach improves
Pick-and-Reorient bottle task by detecting and exploiting contact transitions
during pressing and placement. Hardware experiments demonstrate greater task
success compared to baseline matching the observation space of ACT as an
ablation and experiments indicate that force and torque signals are beneficial
in the press and place phases where visual observability is limited, supporting
the use of interaction forces as a complementary modality for contact rich
skills. The results suggest a practical path to scaling retail manipulation by
combining modern imitation learning architectures with lightweight force and
torque sensing.

</details>


### [63] [Preventing Robotic Jailbreaking via Multimodal Domain Adaptation](https://arxiv.org/abs/2509.23281)
*Francesco Marchiori,Rohan Sinha,Christopher Agia,Alexander Robey,George J. Pappas,Mauro Conti,Marco Pavone*

Main category: cs.RO

TL;DR: J-DAPT是一个轻量级多模态越狱检测框架，通过注意力融合和领域自适应技术，在机器人环境中有效防御LLM和VLM的安全漏洞攻击。


<details>
  <summary>Details</summary>
Motivation: LLM和VLM在机器人环境中部署时容易受到越狱攻击，绕过安全机制导致现实世界中的不安全行为。现有的数据驱动防御方法在专业数据集稀缺的领域泛化能力不足。

Method: J-DAPT整合文本和视觉嵌入来捕捉语义意图和环境背景，同时将通用越狱数据集与领域特定参考数据进行对齐，采用注意力融合和领域自适应技术。

Result: 在自动驾驶、海洋机器人和四足导航等领域的评估显示，J-DAPT将检测准确率提升至接近100%，且开销极小。

Conclusion: J-DAPT为机器人应用中保护VLM提供了实用的防御解决方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) are
increasingly deployed in robotic environments but remain vulnerable to
jailbreaking attacks that bypass safety mechanisms and drive unsafe or
physically harmful behaviors in the real world. Data-driven defenses such as
jailbreak classifiers show promise, yet they struggle to generalize in domains
where specialized datasets are scarce, limiting their effectiveness in robotics
and other safety-critical contexts. To address this gap, we introduce J-DAPT, a
lightweight framework for multimodal jailbreak detection through
attention-based fusion and domain adaptation. J-DAPT integrates textual and
visual embeddings to capture both semantic intent and environmental grounding,
while aligning general-purpose jailbreak datasets with domain-specific
reference data. Evaluations across autonomous driving, maritime robotics, and
quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100%
with minimal overhead. These results demonstrate that J-DAPT provides a
practical defense for securing VLMs in robotic applications. Additional
materials are made available at: https://j-dapt.github.io.

</details>


### [64] [Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras](https://arxiv.org/abs/2509.24094)
*Vignesh Ramanathan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Flash是一个轻量级视觉位置识别系统，使用亚毫秒级事件数据通过二进制帧编码和快速位运算实现快速位置识别


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的VPR方法依赖密集表示且需要数十到数百毫秒的事件数据，Flash旨在打破这一范式，实现亚毫秒级的位置识别

Method: 利用活跃像素位置作为判别特征，通过二进制帧编码这些位置，使用快速位运算计算相似度，并根据查询和参考帧的相对事件活动进行归一化

Result: 在室内QCR-Event-Dataset上Recall@1提升11.33倍，在8公里Brisbane-Event-VPR数据集上提升5.92倍，显著减少了机器人无位置感知的运行时间

Conclusion: 这是首个展示使用事件相机实现亚毫秒级VPR的工作，通过轻量级方法显著提升了位置识别速度和准确性

Abstract: Visual Place Recognition (VPR) enables systems to identify previously visited
locations within a map, a fundamental task for autonomous navigation. Prior
works have developed VPR solutions using event cameras, which asynchronously
measure per-pixel brightness changes with microsecond temporal resolution.
However, these approaches rely on dense representations of the inherently
sparse camera output and require tens to hundreds of milliseconds of event data
to predict a place. Here, we break this paradigm with Flash, a lightweight VPR
system that predicts places using sub-millisecond slices of event data. Our
method is based on the observation that active pixel locations provide strong
discriminative features for VPR. Flash encodes these active pixel locations
using efficient binary frames and computes similarities via fast bitwise
operations, which are then normalized based on the relative event activity in
the query and reference frames. Flash improves Recall@1 for sub-millisecond VPR
over existing baselines by 11.33x on the indoor QCR-Event-Dataset and 5.92x on
the 8 km Brisbane-Event-VPR dataset. Moreover, our approach reduces the
duration for which the robot must operate without awareness of its position, as
evidenced by a localization latency metric we term Time to Correct Match (TCM).
To the best of our knowledge, this is the first work to demonstrate
sub-millisecond VPR using event cameras.

</details>


### [65] [Ancestry Tree Clustering for Particle Filter Diversity Maintenance](https://arxiv.org/abs/2509.24124)
*Ilari Vallivaara,Bingnan Duan,Yinhuan Dong,Tughrul Arslan*

Main category: cs.RO

TL;DR: 提出一种基于粒子祖先树拓扑结构的线性时间多样性维护方法，通过聚类相关粒子来防止多模态环境中的过早收敛。


<details>
  <summary>Details</summary>
Motivation: 解决粒子滤波中多样性损失问题，避免在多模态环境中过早收敛，同时保持估计的紧凑性。

Method: 基于粒子祖先树拓扑结构进行聚类：将密切相关的粒子在足够大的子树中分组，结合簇内适应度共享和保护未聚类粒子。

Result: 在多模态机器人仿真和真实室内环境中验证，相比确定性重采样和粒子高斯混合等方法，实现了高成功率且对紧凑性影响很小。

Conclusion: 该方法在不同领域和挑战性初始条件下表现出特别鲁棒性，能有效维持多样性而不显著影响估计质量。

Abstract: We propose a method for linear-time diversity maintenance in particle
filtering. It clusters particles based on ancestry tree topology: closely
related particles in sufficiently large subtrees are grouped together. The main
idea is that the tree structure implicitly encodes similarity without the need
for spatial or other domain-specific metrics. This approach, when combined with
intra-cluster fitness sharing and the protection of particles not included in a
cluster, effectively prevents premature convergence in multimodal environments
while maintaining estimate compactness. We validate our approach in a
multimodal robotics simulation and a real-world multimodal indoor environment.
We compare the performance to several diversity maintenance algorithms from the
literature, including Deterministic Resampling and Particle Gaussian Mixtures.
Our algorithm achieves high success rates with little to no negative effect on
compactness, showing particular robustness to different domains and challenging
initial conditions.

</details>


### [66] [SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework](https://arxiv.org/abs/2509.24763)
*Xiangyi Meng,Delun Li,Zihao Mao,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: SSR-ZSON是一种基于TARE分层探索框架的空间语义相对零样本物体导航方法，通过平衡空间覆盖和语义密度的视点生成策略与基于LLM的全局引导机制，解决了零样本物体导航中的语义引导不足和空间记忆受限问题。


<details>
  <summary>Details</summary>
Motivation: 零样本物体导航面临两个主要挑战：语义引导不足导致探索效率低下，环境结构造成的空间记忆受限导致局部区域困陷。

Method: 提出SSR-ZSON方法，包含两个关键创新：1）视点生成策略优先考虑可遍历子区域内高语义密度区域以最大化空间覆盖；2）结合基于LLM的全局引导机制评估语义关联，引导导航朝向高价值空间。

Result: 在Matterport3D和Habitat-Matterport3D数据集上，相比最先进方法，成功率分别提升18.5%和11.2%，路径长度加权成功率分别提升0.181和0.140。

Conclusion: SSR-ZSON实现了实时操作和优越性能，通过平衡空间覆盖和语义密度的视点生成策略与LLM全局引导，有效解决了零样本物体导航中的探索效率低下和局部困陷问题。

Abstract: Zero-shot object navigation in unknown environments presents significant
challenges, mainly due to two key limitations: insufficient semantic guidance
leads to inefficient exploration, while limited spatial memory resulting from
environmental structure causes entrapment in local regions. To address these
issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object
navigation method based on the TARE hierarchical exploration framework,
integrating a viewpoint generation strategy balancing spatial coverage and
semantic density with an LLM-based global guidance mechanism. The performance
improvement of the proposed method is due to two key innovations. First, the
viewpoint generation strategy prioritizes areas of high semantic density within
traversable sub-regions to maximize spatial coverage and minimize invalid
exploration. Second, coupled with an LLM-based global guidance mechanism, it
assesses semantic associations to direct navigation toward high-value spaces,
preventing local entrapment and ensuring efficient exploration. Deployed on
hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves
real-time operation and superior performance. On Matterport3D and
Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\% and
11.2\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140,
respectively, over state-of-the-art methods.

</details>
