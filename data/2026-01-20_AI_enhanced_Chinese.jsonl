{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.", "AI": {"tldr": "\u5f00\u53d1AI\u4ee3\u7406\u5e2e\u52a9\u6c42\u804c\u8005\u5728\u4e13\u4e1a\u793e\u533a\u64b0\u5199\u6709\u6548\u7684\u63a8\u8350\u8bf7\u6c42\uff0c\u901a\u8fc7\u6539\u8fdb\u4ee3\u7406\u91cd\u5199\u8bf7\u6c42\u3001\u8bc4\u4f30\u4ee3\u7406\u9884\u6d4b\u6210\u529f\u7387\uff0c\u7ed3\u5408RAG\u6280\u672f\u63d0\u5347\u5f31\u8bf7\u6c42\u6210\u529f\u738714%\u800c\u4e0d\u5f71\u54cd\u5f3a\u8bf7\u6c42", "motivation": "\u5e2e\u52a9\u6c42\u804c\u8005\u5728\u4e13\u4e1a\u5728\u7ebf\u793e\u533a\u4e2d\u64b0\u5199\u66f4\u6709\u6548\u7684\u63a8\u8350\u8bf7\u6c42\uff0c\u63d0\u9ad8\u83b7\u5f97\u63a8\u8350\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u901a\u8fc7AI\u8f85\u52a9\u63d0\u4f9b\u4f4e\u6210\u672c\u7684\u8d28\u91cf\u8bc4\u4f30\u4fe1\u53f7", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u7cfb\u7edf\uff1a\u6539\u8fdb\u4ee3\u7406\u91cd\u5199\u63a8\u8350\u8bf7\u6c42\uff0c\u8bc4\u4f30\u4ee3\u7406\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u9884\u6d4b\u63a5\u6536\u63a8\u8350\u7684\u6982\u7387\uff1b\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\u4f18\u5316LLM\u7684\u7f16\u8f91\u6548\u679c", "result": "LLM\u4fee\u8ba2\u80fd\u63d0\u9ad8\u5f31\u8bf7\u6c42\u7684\u9884\u6d4b\u6210\u529f\u7387\uff0c\u4f46\u4f1a\u964d\u4f4e\u5f3a\u8bf7\u6c42\u7684\u6210\u529f\u7387\uff1b\u7ed3\u5408RAG\u540e\u80fd\u9632\u6b62\u5bf9\u5f3a\u8bf7\u6c42\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u540c\u65f6\u5c06\u5f31\u8bf7\u6c42\u7684\u9884\u6d4b\u6210\u529f\u7387\u63d0\u534714%", "conclusion": "AI\u4ee3\u7406\u7ed3\u5408RAG\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347\u6c42\u804c\u63a8\u8350\u8bf7\u6c42\u7684\u8d28\u91cf\uff0c\u4e3a\u5b9e\u9645\u7528\u6237\u5b9e\u9a8c\u63d0\u4f9b\u4f4e\u6210\u672c\u7684\u524d\u671f\u4fe1\u53f7\uff0c\u5c3d\u7ba1\u6a21\u578b\u9884\u6d4b\u7684\u6539\u8fdb\u4e0d\u4e00\u5b9a\u4fdd\u8bc1\u5b9e\u9645\u83b7\u5f97\u66f4\u591a\u63a8\u8350"}}
{"id": "2601.10863", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10863", "abs": "https://arxiv.org/abs/2601.10863", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Beyond Accuracy: A Stability-Aware Metric for Multi-Horizon Forecasting", "comment": null, "summary": "Traditional time series forecasting methods optimize for accuracy alone. This objective neglects temporal consistency, in other words, how consistently a model predicts the same future event as the forecast origin changes. We introduce the forecast accuracy and coherence score (forecast AC score for short) for measuring the quality of probabilistic multi-horizon forecasts in a way that accounts for both multi-horizon accuracy and stability. Our score additionally provides for user-specified weights to balance accuracy and consistency requirements. As an example application, we implement the score as a differentiable objective function for training seasonal ARIMA models and evaluate it on the M4 Hourly benchmark dataset. Results demonstrate substantial improvements over traditional maximum likelihood estimation. Our AC-optimized models achieve a 75\\% reduction in forecast volatility for the same target timestamps while maintaining comparable or improved point forecast accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6982\u7387\u591a\u6b65\u9884\u6d4b\u8bc4\u4f30\u6307\u6807\u2014\u2014\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u4e00\u81f4\u6027\u8bc4\u5206\uff08AC\u8bc4\u5206\uff09\uff0c\u8be5\u6307\u6807\u540c\u65f6\u8003\u8651\u591a\u6b65\u9884\u6d4b\u51c6\u786e\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u5e76\u53ef\u901a\u8fc7\u7528\u6237\u6307\u5b9a\u6743\u91cd\u5e73\u8861\u4e24\u8005\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u4ec5\u4f18\u5316\u51c6\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u65f6\u95f4\u4e00\u81f4\u6027\uff08\u5373\u968f\u7740\u9884\u6d4b\u8d77\u70b9\u53d8\u5316\uff0c\u6a21\u578b\u5bf9\u540c\u4e00\u672a\u6765\u4e8b\u4ef6\u7684\u9884\u6d4b\u7a33\u5b9a\u6027\uff09\u3002\u8fd9\u79cd\u5355\u4e00\u76ee\u6807\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u9884\u6d4b\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7a33\u5b9a\u51b3\u7b56\u7684\u5e94\u7528\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u4e00\u81f4\u6027\u8bc4\u5206\uff08AC\u8bc4\u5206\uff09\uff0c\u8be5\u8bc4\u5206\u6307\u6807\u80fd\u591f\u540c\u65f6\u8bc4\u4f30\u591a\u6b65\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u65f6\u95f4\u7a33\u5b9a\u6027\u3002\u5c06AC\u8bc4\u5206\u5b9e\u73b0\u4e3a\u53ef\u5fae\u5206\u76ee\u6807\u51fd\u6570\uff0c\u7528\u4e8e\u8bad\u7ec3\u5b63\u8282\u6027ARIMA\u6a21\u578b\uff0c\u5e76\u5728M4 Hourly\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4e0e\u4f20\u7edf\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u76f8\u6bd4\uff0cAC\u4f18\u5316\u6a21\u578b\u5728\u4fdd\u6301\u76f8\u5f53\u6216\u6539\u8fdb\u7684\u70b9\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5bf9\u76f8\u540c\u76ee\u6807\u65f6\u95f4\u6233\u7684\u9884\u6d4b\u6ce2\u52a8\u6027\u964d\u4f4e\u4e8675%\u3002", "conclusion": "AC\u8bc4\u5206\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5168\u9762\u7684\u6982\u7387\u591a\u6b65\u9884\u6d4b\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u5e73\u8861\u51c6\u786e\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u9700\u6c42\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u7a33\u5b9a\u6027\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002"}}
{"id": "2601.10832", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.10832", "abs": "https://arxiv.org/abs/2601.10832", "authors": ["Anis R. Shakkour", "David Hexner", "Yehuda Bitton", "Avishai Sintov"], "title": "IMU-based Real-Time Crutch Gait Phase and Step Detections in Lower-Limb Exoskeletons", "comment": null, "summary": "Lower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a minimalist framework utilizing a single, low cost Inertial-Measurement Unit (IMU) integrated into the crutch hand grip, eliminating the need for mechanical modifications. We propose a five phase classification system, including standard gait phases and a non locomotor auxiliary state, to prevent undesired motion. Three deep learning architectures were benchmarked on both a PC and an embedded system. To improve performance under data constrained conditions, models were augmented with a Finite State Machine (FSM) to enforce biomechanical consistency. The Temporal Convolutional Network (TCN) emerged as the superior architecture, yielding the highest success rates and lowest latency. Notably, the model generalized to a paralyzed user despite being trained exclusively on healthy participants. Achieving a 94% success rate in detecting crutch steps, this system provides a high performance, cost effective solution for real time exoskeleton control.", "AI": {"tldr": "\u4f7f\u7528\u5355\u4e2a\u4f4e\u6210\u672cIMU\u96c6\u6210\u5728\u62d0\u6756\u624b\u67c4\u4e2d\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u6709\u9650\u72b6\u6001\u673a\u5b9e\u73b0\u5b9e\u65f6\u6b65\u6001\u76f8\u4f4d\u68c0\u6d4b\uff0c\u65e0\u9700\u673a\u68b0\u6539\u9020\uff0c\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e0a\u8fbe\u523094%\u6210\u529f\u7387\u3002", "motivation": "\u4e0b\u80a2\u5916\u9aa8\u9abc\u548c\u5047\u80a2\u9700\u8981\u7cbe\u786e\u7684\u5b9e\u65f6\u6b65\u6001\u76f8\u4f4d\u548c\u6b65\u6001\u68c0\u6d4b\u4ee5\u786e\u4fdd\u540c\u6b65\u8fd0\u52a8\u548c\u4f7f\u7528\u8005\u5b89\u5168\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u529b\u4f20\u611f\u786c\u4ef6\uff0c\u4f1a\u5f15\u5165\u63a7\u5236\u5ef6\u8fdf\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u673a\u68b0\u6539\u9020\u7684\u7b80\u7ea6\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7b80\u7ea6\u6846\u67b6\uff1a\u5728\u62d0\u6756\u624b\u67c4\u96c6\u6210\u5355\u4e2a\u4f4e\u6210\u672cIMU\uff0c\u91c7\u7528\u4e94\u76f8\u4f4d\u5206\u7c7b\u7cfb\u7edf\uff08\u5305\u62ec\u6807\u51c6\u6b65\u6001\u76f8\u4f4d\u548c\u975e\u8fd0\u52a8\u8f85\u52a9\u72b6\u6001\uff09\u3002\u57fa\u51c6\u6d4b\u8bd5\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u5728\u6570\u636e\u53d7\u9650\u6761\u4ef6\u4e0b\u4f7f\u7528\u6709\u9650\u72b6\u6001\u673a\u589e\u5f3a\u6a21\u578b\u4ee5\u4fdd\u6301\u751f\u7269\u529b\u5b66\u4e00\u81f4\u6027\u3002", "result": "\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\uff08TCN\uff09\u8868\u73b0\u6700\u4f73\uff0c\u5728PC\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e0a\u5747\u83b7\u5f97\u6700\u9ad8\u6210\u529f\u7387\u548c\u6700\u4f4e\u5ef6\u8fdf\u3002\u6a21\u578b\u5728\u4ec5\u4f7f\u7528\u5065\u5eb7\u53c2\u4e0e\u8005\u6570\u636e\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u6cdb\u5316\u5230\u762b\u75ea\u7528\u6237\u3002\u7cfb\u7edf\u8fbe\u523094%\u7684\u62d0\u6756\u6b65\u6001\u68c0\u6d4b\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5b9e\u65f6\u5916\u9aa8\u9abc\u63a7\u5236\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u3001\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u7528\u5355\u4e2aIMU\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u65e0\u9700\u673a\u68b0\u6539\u9020\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.11037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11037", "abs": "https://arxiv.org/abs/2601.11037", "authors": ["Shiyu Liu", "Yongjing Yin", "Jianhao Yan", "Yunbo Tang", "Qinggang Zhang", "Bei Li", "Xin Chen", "Jingang Wang", "Xunliang Cai", "Jinsong Su"], "title": "BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search", "comment": "Code is available at https://github.com/Liushiyu-0709/BAPO-Reliable-Search", "summary": "RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.", "AI": {"tldr": "BAPO\uff1a\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u7b56\u7565\u4f18\u5316\u63d0\u5347\u57fa\u4e8eRL\u7684\u667a\u80fd\u641c\u7d22\u4ee3\u7406\u7684\u53ef\u9760\u6027\uff0c\u4f7f\u5176\u5728\u8bc1\u636e\u4e0d\u8db3\u65f6\u80fd\u591f\u627f\u8ba4\"\u6211\u4e0d\u77e5\u9053\"", "motivation": "\u57fa\u4e8eRL\u7684\u667a\u80fd\u641c\u7d22\u4ee3\u7406\u5728\u5904\u7406\u590d\u6742\u95ee\u9898\u65f6\u867d\u7136\u51c6\u786e\u6027\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u53ef\u9760\u6027\u8fb9\u754c\u610f\u8bc6\uff0c\u5373\u4f7f\u8bc1\u636e\u4e0d\u8db3\u4e5f\u5f88\u5c11\u627f\u8ba4\"\u6211\u4e0d\u77e5\u9053\"\uff0c\u5bfc\u81f4\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u4f46\u4e0d\u53ef\u9760\u7684\u7b54\u6848\uff0c\u8fd9\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5b58\u5728\u91cd\u5927\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u8fb9\u754c\u611f\u77e5\u7b56\u7565\u4f18\u5316(BAPO)\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1)\u57fa\u4e8e\u7fa4\u4f53\u7684\u8fb9\u754c\u611f\u77e5\u5956\u52b1\u673a\u5236\uff0c\u9f13\u52b1\u4ee3\u7406\u5728\u63a8\u7406\u8fbe\u5230\u6781\u9650\u65f6\u7ed9\u51faIDK\u54cd\u5e94\uff1b2)\u81ea\u9002\u5e94\u5956\u52b1\u8c03\u8282\u5668\uff0c\u5728\u65e9\u671f\u63a2\u7d22\u9636\u6bb5\u7b56\u7565\u6027\u5730\u6682\u505c\u8be5\u5956\u52b1\uff0c\u9632\u6b62\u6a21\u578b\u5c06IDK\u4f5c\u4e3a\u6377\u5f84\u5229\u7528\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cBAPO\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u641c\u7d22\u4ee3\u7406\u7684\u6574\u4f53\u53ef\u9760\u6027\u3002", "conclusion": "BAPO\u6846\u67b6\u80fd\u591f\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u57f9\u517b\u53ef\u9760\u7684\u8fb9\u754c\u610f\u8bc6\uff0c\u89e3\u51b3\u4e86\u5f53\u524dRL\u667a\u80fd\u641c\u7d22\u4ee3\u7406\u5728\u53ef\u9760\u6027\u65b9\u9762\u7684\u91cd\u8981\u7f3a\u9677\u3002"}}
{"id": "2601.10973", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10973", "abs": "https://arxiv.org/abs/2601.10973", "authors": ["Zain ul Abdeen", "Waris Gill", "Ming Jin"], "title": "Toward Adaptive Grid Resilience: A Gradient-Free Meta-RL Framework for Critical Load Restoration", "comment": null, "summary": "Restoring critical loads after extreme events demands adaptive control to maintain distribution-grid resilience, yet uncertainty in renewable generation, limited dispatchable resources, and nonlinear dynamics make effective restoration difficult. Reinforcement learning (RL) can optimize sequential decisions under uncertainty, but standard RL often generalizes poorly and requires extensive retraining for new outage configurations or generation patterns. We propose a meta-guided gradient-free RL (MGF-RL) framework that learns a transferable initialization from historical outage experiences and rapidly adapts to unseen scenarios with minimal task-specific tuning. MGF-RL couples first-order meta-learning with evolutionary strategies, enabling scalable policy search without gradient computation while accommodating nonlinear, constrained distribution-system dynamics. Experiments on IEEE 13-bus and IEEE 123-bus test systems show that MGF-RL outperforms standard RL, MAML-based meta-RL, and model predictive control across reliability, restoration speed, and adaptation efficiency under renewable forecast errors. MGF-RL generalizes to unseen outages and renewable patterns while requiring substantially fewer fine-tuning episodes than conventional RL. We also provide sublinear regret bounds that relate adaptation efficiency to task similarity and environmental variation, supporting the empirical gains and motivating MGF-RL for real-time load restoration in renewable-rich distribution grids.", "AI": {"tldr": "\u63d0\u51faMGF-RL\u6846\u67b6\uff0c\u7ed3\u5408\u5143\u5b66\u4e60\u548c\u8fdb\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u65e0\u9700\u68af\u5ea6\u7684\u53ef\u8fc1\u79fb\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5feb\u901f\u9002\u5e94\u65b0\u505c\u7535\u573a\u666f\uff0c\u63d0\u5347\u914d\u7535\u7f51\u6062\u590d\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u6781\u7aef\u4e8b\u4ef6\u540e\u6062\u590d\u5173\u952e\u8d1f\u8377\u9700\u8981\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u4f46\u53ef\u518d\u751f\u80fd\u6e90\u4e0d\u786e\u5b9a\u6027\u3001\u53ef\u8c03\u5ea6\u8d44\u6e90\u6709\u9650\u548c\u975e\u7ebf\u6027\u52a8\u6001\u4f7f\u6062\u590d\u56f0\u96be\u3002\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u5bf9\u65b0\u573a\u666f\u9700\u8981\u5927\u91cf\u91cd\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u5143\u5f15\u5bfc\u65e0\u68af\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e00\u9636\u5143\u5b66\u4e60\u548c\u8fdb\u5316\u7b56\u7565\uff0c\u4ece\u5386\u53f2\u505c\u7535\u7ecf\u9a8c\u5b66\u4e60\u53ef\u8fc1\u79fb\u521d\u59cb\u5316\uff0c\u5feb\u901f\u9002\u5e94\u672a\u89c1\u573a\u666f\uff0c\u65e0\u9700\u68af\u5ea6\u8ba1\u7b97\u4e14\u80fd\u5904\u7406\u975e\u7ebf\u6027\u7ea6\u675f\u3002", "result": "\u5728IEEE 13\u603b\u7ebf\u548c123\u603b\u7ebf\u6d4b\u8bd5\u7cfb\u7edf\u4e2d\uff0cMGF-RL\u5728\u53ef\u9760\u6027\u3001\u6062\u590d\u901f\u5ea6\u548c\u9002\u5e94\u6548\u7387\u4e0a\u4f18\u4e8e\u6807\u51c6RL\u3001MAML\u5143RL\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff0c\u6cdb\u5316\u5230\u672a\u89c1\u505c\u7535\u548c\u53ef\u518d\u751f\u80fd\u6e90\u6a21\u5f0f\uff0c\u4e14\u9700\u8981\u66f4\u5c11\u5fae\u8c03\u3002", "conclusion": "MGF-RL\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u4e30\u5bcc\u7684\u914d\u7535\u7f51\u5b9e\u65f6\u8d1f\u8377\u6062\u590d\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7406\u8bba\u9057\u61be\u754c\u8bc1\u660e\u9002\u5e94\u6548\u7387\u4e0e\u4efb\u52a1\u76f8\u4f3c\u5ea6\u7684\u5173\u7cfb\uff0c\u652f\u6301\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.11093", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11093", "abs": "https://arxiv.org/abs/2601.11093", "authors": ["Ashish Raj Shekhar", "Shiven Agarwal", "Priyanuj Bordoloi", "Yash Shah", "Tejas Anvekar", "Vivek Gupta"], "title": "Integrity Shield A System for Ethical AI Use & Authorship Transparency in Assessments", "comment": null, "summary": "Large Language Models (LLMs) can now solve entire exams directly from uploaded PDF assessments, raising urgent concerns about academic integrity and the reliability of grades and credentials. Existing watermarking techniques either operate at the token level or assume control over the model's decoding process, making them ineffective when students query proprietary black-box systems with instructor-provided documents. We present Integrity Shield, a document-layer watermarking system that embeds schema-aware, item-level watermarks into assessment PDFs while keeping their human-visible appearance unchanged. These watermarks consistently prevent MLLMs from answering shielded exam PDFs and encode stable, item-level signatures that can be reliably recovered from model or student responses. Across 30 exams spanning STEM, humanities, and medical reasoning, Integrity Shield achieves exceptionally high prevention (91-94% exam-level blocking) and strong detection reliability (89-93% signature retrieval) across four commercial MLLMs. Our demo showcases an interactive interface where instructors upload an exam, preview watermark behavior, and inspect pre/post AI performance & authorship evidence.", "AI": {"tldr": "Integrity Shield\u662f\u4e00\u79cd\u6587\u6863\u5c42\u6c34\u5370\u7cfb\u7edf\uff0c\u53ef\u5728\u8bc4\u4f30PDF\u4e2d\u5d4c\u5165\u6a21\u5f0f\u611f\u77e5\u3001\u9879\u76ee\u7ea7\u6c34\u5370\uff0c\u9632\u6b62\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u53d7\u4fdd\u62a4\u7684\u8003\u8bd5PDF\uff0c\u540c\u65f6\u4fdd\u6301\u4eba\u7c7b\u53ef\u89c1\u5916\u89c2\u4e0d\u53d8\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u73b0\u5728\u53ef\u4ee5\u76f4\u63a5\u4ece\u4e0a\u4f20\u7684PDF\u8bc4\u4f30\u4e2d\u89e3\u51b3\u6574\u4e2a\u8003\u8bd5\uff0c\u8fd9\u5f15\u53d1\u4e86\u5b66\u672f\u8bda\u4fe1\u548c\u6210\u7ee9\u8bc1\u4e66\u53ef\u9760\u6027\u7684\u7d27\u8feb\u62c5\u5fe7\u3002\u73b0\u6709\u7684\u6c34\u5370\u6280\u672f\u8981\u4e48\u5728\u4ee4\u724c\u7ea7\u522b\u64cd\u4f5c\uff0c\u8981\u4e48\u5047\u8bbe\u63a7\u5236\u6a21\u578b\u7684\u89e3\u7801\u8fc7\u7a0b\uff0c\u5f53\u5b66\u751f\u4f7f\u7528\u6559\u5e08\u63d0\u4f9b\u7684\u6587\u6863\u67e5\u8be2\u4e13\u6709\u9ed1\u76d2\u7cfb\u7edf\u65f6\u65e0\u6548\u3002", "method": "\u63d0\u51faIntegrity Shield\u6587\u6863\u5c42\u6c34\u5370\u7cfb\u7edf\uff0c\u5728\u8bc4\u4f30PDF\u4e2d\u5d4c\u5165\u6a21\u5f0f\u611f\u77e5\u3001\u9879\u76ee\u7ea7\u6c34\u5370\uff0c\u4fdd\u6301\u4eba\u7c7b\u53ef\u89c1\u5916\u89c2\u4e0d\u53d8\u3002\u8fd9\u4e9b\u6c34\u5370\u80fd\u6301\u7eed\u963b\u6b62MLLMs\u56de\u7b54\u53d7\u4fdd\u62a4\u7684\u8003\u8bd5PDF\uff0c\u5e76\u7f16\u7801\u7a33\u5b9a\u7684\u9879\u76ee\u7ea7\u7b7e\u540d\uff0c\u53ef\u4ece\u6a21\u578b\u6216\u5b66\u751f\u56de\u7b54\u4e2d\u53ef\u9760\u6062\u590d\u3002", "result": "\u5728\u6db5\u76d6STEM\u3001\u4eba\u6587\u548c\u533b\u5b66\u63a8\u7406\u768430\u4e2a\u8003\u8bd5\u4e2d\uff0cIntegrity Shield\u5b9e\u73b0\u4e86\u6781\u9ad8\u7684\u9884\u9632\u6548\u679c\uff0891-94%\u8003\u8bd5\u7ea7\u522b\u963b\u6b62\uff09\u548c\u5f3a\u5927\u7684\u68c0\u6d4b\u53ef\u9760\u6027\uff0889-93%\u7b7e\u540d\u68c0\u7d22\uff09\uff0c\u5728\u56db\u4e2a\u5546\u4e1aMLLMs\u4e0a\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "Integrity Shield\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6587\u6863\u5c42\u6c34\u5370\u89e3\u51b3\u65b9\u6848\uff0c\u65e2\u80fd\u9632\u6b62AI\u4f5c\u5f0a\uff0c\u53c8\u80fd\u53ef\u9760\u68c0\u6d4b\u4f5c\u5f0a\u884c\u4e3a\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u754c\u9762\u5e2e\u52a9\u6559\u5e08\u4fdd\u62a4\u8003\u8bd5\u5b8c\u6574\u6027\u3002"}}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u6846\u67b6\uff0c\u901a\u8fc7\u591aKPI\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u63ed\u793a\u4e86LLM\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u548c\u8bad\u7ec3\u8f68\u8ff9\u5185\u90e8\u5173\u8054\u8fdb\u884c\u9ad8\u9636\u63a8\u7406\u7684\u673a\u5236\u3002", "motivation": "\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u65e8\u5728\u9884\u6d4b\u8fdb\u884c\u4e2d\u6d41\u7a0b\u7684\u7ed3\u679c\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u5148\u524d\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u5168\u9762\u8bc4\u4f30\u5176\u6cdb\u5316\u80fd\u529b\u3001\u8bed\u4e49\u5229\u7528\u548c\u63a8\u7406\u673a\u5236\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u591a\u4e2a\u5173\u952e\u7ee9\u6548\u6307\u6807\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5b9e\u73b0\u591aKPI\u9884\u6d4b\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u91cd\u70b9\u5173\u6ce8\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u4e24\u4e2aKPI\uff0c\u7279\u522b\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\uff08\u4ec5100\u6761\u8f68\u8ff9\uff09\u4e0b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5728\u6570\u636e\u7a00\u7f3a\u8bbe\u7f6e\u4e2d\uff0cLLM\u8d85\u8d8a\u4e86\u57fa\u51c6\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660eLLM\u65e2\u5229\u7528\u4e86\u5176\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e5f\u5229\u7528\u4e86\u8bad\u7ec3\u8f68\u8ff9\u95f4\u7684\u5185\u90e8\u76f8\u5173\u6027\u3002\u6a21\u578b\u63a8\u7406\u7b56\u7565\u5206\u6790\u663e\u793aLLM\u5e76\u975e\u7b80\u5355\u590d\u5236\u73b0\u6709\u9884\u6d4b\u65b9\u6cd5\uff0c\u800c\u662f\u6267\u884c\u9ad8\u9636\u63a8\u7406\u6765\u751f\u6210\u9884\u6d4b\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u6846\u67b6\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u8bed\u4e49\u77e5\u8bc6\u548c\u5185\u90e8\u76f8\u5173\u6027\u8fdb\u884c\u9ad8\u9636\u63a8\u7406\uff0c\u4e3a\u591aKPI\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11254", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11254", "abs": "https://arxiv.org/abs/2601.11254", "authors": ["Cheng-Zhuang Liu", "Si-Bao Chen", "Qing-Ling Shu", "Chris Ding", "Jin Tang", "Bin Luo"], "title": "FTDMamba: Frequency-Assisted Temporal Dilation Mamba for Unmanned Aerial Vehicle Video Anomaly Detection", "comment": null, "summary": "Recent advances in video anomaly detection (VAD) mainly focus on ground-based surveillance or unmanned aerial vehicle (UAV) videos with static backgrounds, whereas research on UAV videos with dynamic backgrounds remains limited. Unlike static scenarios, dynamically captured UAV videos exhibit multi-source motion coupling, where the motion of objects and UAV-induced global motion are intricately intertwined. Consequently, existing methods may misclassify normal UAV movements as anomalies or fail to capture true anomalies concealed within dynamic backgrounds. Moreover, many approaches do not adequately address the joint modeling of inter-frame continuity and local spatial correlations across diverse temporal scales. To overcome these limitations, we propose the Frequency-Assisted Temporal Dilation Mamba (FTDMamba) network for UAV VAD, including two core components: (1) a Frequency Decoupled Spatiotemporal Correlation Module, which disentangles coupled motion patterns and models global spatiotemporal dependencies through frequency analysis; and (2) a Temporal Dilation Mamba Module, which leverages Mamba's sequence modeling capability to jointly learn fine-grained temporal dynamics and local spatial structures across multiple temporal receptive fields. Additionally, unlike existing UAV VAD datasets which focus on static backgrounds, we construct a large-scale Moving UAV VAD dataset (MUVAD), comprising 222,736 frames with 240 anomaly events across 12 anomaly types. Extensive experiments demonstrate that FTDMamba achieves state-of-the-art (SOTA) performance on two public static benchmarks and the new MUVAD dataset. The code and MUVAD dataset will be available at: https://github.com/uavano/FTDMamba.", "AI": {"tldr": "\u63d0\u51faFTDMamba\u7f51\u7edc\u7528\u4e8e\u52a8\u6001\u80cc\u666f\u4e0b\u7684\u65e0\u4eba\u673a\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u9891\u7387\u89e3\u8026\u65f6\u7a7a\u76f8\u5173\u6a21\u5757\u548c\u65f6\u5e8f\u6269\u5f20Mamba\u6a21\u5757\u89e3\u51b3\u591a\u6e90\u8fd0\u52a8\u8026\u5408\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u52a8\u6001\u80cc\u666f\u65e0\u4eba\u673a\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6MUVAD\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u80cc\u666f\u7684\u76d1\u63a7\u6216\u65e0\u4eba\u673a\u89c6\u9891\uff0c\u800c\u52a8\u6001\u80cc\u666f\u4e0b\u7684\u65e0\u4eba\u673a\u89c6\u9891\u7814\u7a76\u6709\u9650\u3002\u52a8\u6001\u65e0\u4eba\u673a\u89c6\u9891\u5b58\u5728\u591a\u6e90\u8fd0\u52a8\u8026\u5408\u95ee\u9898\uff08\u7269\u4f53\u8fd0\u52a8\u4e0e\u65e0\u4eba\u673a\u5168\u5c40\u8fd0\u52a8\u4ea4\u7ec7\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u5bb9\u6613\u5c06\u6b63\u5e38\u65e0\u4eba\u673a\u8fd0\u52a8\u8bef\u5224\u4e3a\u5f02\u5e38\uff0c\u6216\u65e0\u6cd5\u68c0\u6d4b\u52a8\u6001\u80cc\u666f\u4e2d\u9690\u85cf\u7684\u771f\u5b9e\u5f02\u5e38\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5efa\u6a21\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0b\u7684\u5e27\u95f4\u8fde\u7eed\u6027\u548c\u5c40\u90e8\u7a7a\u95f4\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51faFTDMamba\u7f51\u7edc\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u9891\u7387\u89e3\u8026\u65f6\u7a7a\u76f8\u5173\u6a21\u5757\uff1a\u901a\u8fc7\u9891\u7387\u5206\u6790\u89e3\u8026\u8026\u5408\u7684\u8fd0\u52a8\u6a21\u5f0f\uff0c\u5efa\u6a21\u5168\u5c40\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff1b2) \u65f6\u5e8f\u6269\u5f20Mamba\u6a21\u5757\uff1a\u5229\u7528Mamba\u7684\u5e8f\u5217\u5efa\u6a21\u80fd\u529b\uff0c\u8054\u5408\u5b66\u4e60\u591a\u4e2a\u65f6\u95f4\u611f\u53d7\u91ce\u4e0b\u7684\u7ec6\u7c92\u5ea6\u65f6\u5e8f\u52a8\u6001\u548c\u5c40\u90e8\u7a7a\u95f4\u7ed3\u6784\u3002\u540c\u65f6\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u52a8\u6001\u80cc\u666f\u65e0\u4eba\u673a\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6MUVAD\u3002", "result": "FTDMamba\u5728\u4e24\u4e2a\u516c\u5f00\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u548c\u65b0\u7684MUVAD\u6570\u636e\u96c6\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002MUVAD\u6570\u636e\u96c6\u5305\u542b222,736\u5e27\u56fe\u50cf\uff0c\u6db5\u76d612\u79cd\u5f02\u5e38\u7c7b\u578b\u7684240\u4e2a\u5f02\u5e38\u4e8b\u4ef6\u3002", "conclusion": "FTDMamba\u7f51\u7edc\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u80cc\u666f\u65e0\u4eba\u673a\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u591a\u6e90\u8fd0\u52a8\u8026\u5408\u95ee\u9898\uff0c\u901a\u8fc7\u9891\u7387\u5206\u6790\u548c\u65f6\u5e8f\u6269\u5f20Mamba\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u65f6\u7a7a\u5efa\u6a21\u3002\u65b0\u6784\u5efa\u7684MUVAD\u6570\u636e\u96c6\u586b\u8865\u4e86\u52a8\u6001\u80cc\u666f\u65e0\u4eba\u673a\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2601.11492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.", "AI": {"tldr": "BoxMind\u662f\u4e00\u4e2a\u7528\u4e8e\u62f3\u51fb\u6218\u672f\u5206\u6790\u7684\u95ed\u73afAI\u4e13\u5bb6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9a\u4e49\u539f\u5b50\u62f3\u51fb\u4e8b\u4ef6\u3001\u6784\u5efa\u5c42\u6b21\u5316\u6280\u672f\u6218\u672f\u6307\u6807\uff0c\u5e76\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6bd4\u8d5b\u7ed3\u679c\uff0c\u6700\u7ec8\u751f\u6210\u53ef\u6267\u884c\u7684\u6218\u672f\u8c03\u6574\u5efa\u8bae\uff0c\u57282024\u5e74\u5df4\u9ece\u5965\u8fd0\u4f1a\u4e0a\u5e2e\u52a9\u4e2d\u56fd\u56fd\u5bb6\u961f\u53d6\u5f97\u5386\u53f2\u6027\u6210\u7ee9\u3002", "motivation": "\u683c\u6597\u7c7b\u8fd0\u52a8\u5982\u62f3\u51fb\u5728AI\u9a71\u52a8\u7684\u6218\u672f\u5206\u6790\u65b9\u9762\u53d1\u5c55\u4e0d\u8db3\uff0c\u4e3b\u8981\u56e0\u4e3a\u52a8\u4f5c\u52a8\u6001\u590d\u6742\u4e14\u7f3a\u4e4f\u7ed3\u6784\u5316\u7684\u6218\u672f\u8868\u793a\u65b9\u6cd5\u3002\u9700\u8981\u5c06\u975e\u7ed3\u6784\u5316\u89c6\u9891\u6570\u636e\u8f6c\u5316\u4e3a\u6218\u7565\u667a\u80fd\uff0c\u5f25\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u7ade\u6280\u4f53\u80b2\u51b3\u7b56\u652f\u6301\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "1) \u5b9a\u4e49\u5177\u6709\u7cbe\u786e\u65f6\u95f4\u8fb9\u754c\u548c\u7a7a\u95f4\u6280\u672f\u5c5e\u6027\u7684\u539f\u5b50\u62f3\u51fb\u4e8b\u4ef6\uff0c\u5c06\u6bd4\u8d5b\u89c6\u9891\u89e3\u6790\u4e3a18\u4e2a\u5c42\u6b21\u5316\u6280\u672f\u6218\u672f\u6307\u6807\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u878d\u5408\u663e\u6027\u6280\u672f\u6218\u672f\u7279\u5f81\u4e0e\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u53d8\u5316\u6f5c\u5728\u5d4c\u5165\uff0c\u6355\u6349\u62f3\u624b\u5bf9\u6297\u52a8\u6001\uff1b3) \u5c06\u6bd4\u8d5b\u7ed3\u679c\u5efa\u6a21\u4e3a\u6280\u672f\u6218\u672f\u6307\u6807\u7684\u53ef\u5fae\u5206\u51fd\u6570\uff0c\u5c06\u83b7\u80dc\u6982\u7387\u68af\u5ea6\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6218\u672f\u8c03\u6574\u3002", "result": "\u7ed3\u679c\u9884\u6d4b\u6a21\u578b\u5728BoxerGraph\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523069.8%\u51c6\u786e\u7387\uff0c\u5728\u5965\u8fd0\u6bd4\u8d5b\u4e0a\u8fbe\u523087.5%\u51c6\u786e\u7387\u3002\u7cfb\u7edf\u751f\u6210\u7684\u6218\u7565\u5efa\u8bae\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u3002\u57282024\u5e74\u5df4\u9ece\u5965\u8fd0\u4f1a\u95ed\u73af\u90e8\u7f72\u4e2d\uff0c\u76f4\u63a5\u5e2e\u52a9\u4e2d\u56fd\u56fd\u5bb6\u961f\u83b7\u5f973\u91d12\u94f6\u7684\u5386\u53f2\u6027\u6210\u7ee9\u3002", "conclusion": "BoxMind\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u590d\u5236\u7684\u8303\u5f0f\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u89c6\u9891\u6570\u636e\u8f6c\u5316\u4e3a\u6218\u7565\u667a\u80fd\uff0c\u5f25\u5408\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u7ade\u6280\u4f53\u80b2\u51b3\u7b56\u652f\u6301\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u683c\u6597\u7c7b\u8fd0\u52a8\u7684AI\u9a71\u52a8\u6218\u672f\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11322", "categories": ["cs.CV", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.11322", "abs": "https://arxiv.org/abs/2601.11322", "authors": ["Pavana Pradeep", "Krishna Kant", "Suya Yu"], "title": "Enhancing Vision Language Models with Logic Reasoning for Situational Awareness", "comment": "Accepted for publication in IEEE Transactions on AI", "summary": "Vision-Language Models (VLMs) offer the ability to generate high-level, interpretable descriptions of complex activities from images and videos, making them valuable for situational awareness (SA) applications. In such settings, the focus is on identifying infrequent but significant events with high reliability and accuracy, while also extracting fine-grained details and assessing recognition quality. In this paper, we propose an approach that integrates VLMs with traditional computer vision methods through explicit logic reasoning to enhance SA in three key ways: (a) extracting fine-grained event details, (b) employing an intelligent fine-tuning (FT) strategy that achieves substantially higher accuracy than uninformed selection, and (c) generating justifications for VLM outputs during inference. We demonstrate that our intelligent FT mechanism improves the accuracy and provides a valuable means, during inferencing, to either confirm the validity of the VLM output or indicate why it may be questionable.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u903b\u8f91\u63a8\u7406\u589e\u5f3a\u60c5\u5883\u611f\u77e5\uff0c\u5305\u62ec\u7ec6\u7c92\u5ea6\u4e8b\u4ef6\u7ec6\u8282\u63d0\u53d6\u3001\u667a\u80fd\u5fae\u8c03\u7b56\u7565\u548c\u63a8\u7406\u65f6\u751f\u6210\u89e3\u91ca", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u80fd\u751f\u6210\u56fe\u50cf\u548c\u89c6\u9891\u4e2d\u590d\u6742\u6d3b\u52a8\u7684\u9ad8\u5c42\u53ef\u89e3\u91ca\u63cf\u8ff0\uff0c\u9002\u7528\u4e8e\u60c5\u5883\u611f\u77e5\u5e94\u7528\u3002\u8fd9\u7c7b\u5e94\u7528\u9700\u8981\u53ef\u9760\u51c6\u786e\u5730\u8bc6\u522b\u7f55\u89c1\u4f46\u91cd\u8981\u4e8b\u4ef6\uff0c\u540c\u65f6\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7ec6\u8282\u5e76\u8bc4\u4f30\u8bc6\u522b\u8d28\u91cf", "method": "\u901a\u8fc7\u663e\u5f0f\u903b\u8f91\u63a8\u7406\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u6cd5\u96c6\u6210\uff0c\u5305\u62ec\uff1a(a)\u63d0\u53d6\u7ec6\u7c92\u5ea6\u4e8b\u4ef6\u7ec6\u8282\uff1b(b)\u91c7\u7528\u667a\u80fd\u5fae\u8c03\u7b56\u7565\uff0c\u6bd4\u65e0\u4fe1\u606f\u9009\u62e9\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff1b(c)\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e3aVLM\u8f93\u51fa\u751f\u6210\u89e3\u91ca", "result": "\u667a\u80fd\u5fae\u8c03\u673a\u5236\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\uff0c\u5e76\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u624b\u6bb5\uff0c\u53ef\u4ee5\u786e\u8ba4VLM\u8f93\u51fa\u7684\u6709\u6548\u6027\u6216\u6307\u51fa\u5176\u53ef\u80fd\u5b58\u5728\u7684\u95ee\u9898", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408VLM\u4e0e\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u53ca\u903b\u8f91\u63a8\u7406\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u60c5\u5883\u611f\u77e5\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u7ec6\u7c92\u5ea6\u4e8b\u4ef6\u8bc6\u522b\u548c\u8f93\u51fa\u53ef\u9760\u6027\u9a8c\u8bc1\u65b9\u9762"}}
{"id": "2601.11451", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11451", "abs": "https://arxiv.org/abs/2601.11451", "authors": ["Oishee Bintey Hoque", "Nibir Chandra Mandal", "Kyle Luong", "Amanda Wilson", "Samarth Swarup", "Madhav Marathe", "Abhijin Adiga"], "title": "PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs", "comment": null, "summary": "Large-scale livestock operations pose significant risks to human health and the environment, while also being vulnerable to threats such as infectious diseases and extreme weather events. As the number of such operations continues to grow, accurate and scalable mapping has become increasingly important. In this work, we present an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. Our method (1) detects candidate infrastructure (e.g., barns, feedlots, manure lagoons, silos) with a domain-tuned YOLOv8 detector, then derives SAM2 masks from these boxes and filters component-specific criteria, (2) extracts structured descriptors (e.g., counts, areas, orientations, and spatial relations) and fuses them with deep visual features using a lightweight spatial cross-attention classifier, and (3) outputs both CAFO type predictions and mask-level attributions that link decisions to visible infrastructure. Through comprehensive evaluation, we show that our approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best performing baseline by up to 15\\%. Beyond strong predictive performance across diverse U.S. regions, we run systematic gradient--activation analyses that quantify the impact of domain priors and show ho", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u68c0\u6d4b\u57fa\u7840\u8bbe\u65bd\uff08\u755c\u820d\u3001\u9972\u6599\u573a\u3001\u7caa\u6c60\u7b49\uff09\u6765\u8bc6\u522b\u548c\u8868\u5f81\u96c6\u4e2d\u52a8\u7269\u9972\u517b\u573a\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63cf\u8ff0\u7b26\u548c\u6df1\u5ea6\u89c6\u89c9\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u755c\u7267\u4f5c\u4e1a\u5bf9\u4eba\u7c7b\u5065\u5eb7\u548c\u73af\u5883\u6784\u6210\u91cd\u5927\u98ce\u9669\uff0c\u4e14\u6613\u53d7\u4f20\u67d3\u75c5\u548c\u6781\u7aef\u5929\u6c14\u5a01\u80c1\u3002\u968f\u7740\u6b64\u7c7b\u4f5c\u4e1a\u6570\u91cf\u589e\u957f\uff0c\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u6620\u5c04\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002", "method": "1) \u4f7f\u7528\u9886\u57df\u8c03\u4f18\u7684YOLOv8\u68c0\u6d4b\u5668\u68c0\u6d4b\u5019\u9009\u57fa\u7840\u8bbe\u65bd\uff0c\u4ece\u68c0\u6d4b\u6846\u751f\u6210SAM2\u63a9\u7801\u5e76\u8fc7\u6ee4\u7ec4\u4ef6\u7279\u5b9a\u6807\u51c6\uff1b2) \u63d0\u53d6\u7ed3\u6784\u5316\u63cf\u8ff0\u7b26\uff08\u6570\u91cf\u3001\u9762\u79ef\u3001\u65b9\u5411\u3001\u7a7a\u95f4\u5173\u7cfb\uff09\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u7c7b\u5668\u4e0e\u6df1\u5ea6\u89c6\u89c9\u7279\u5f81\u878d\u5408\uff1b3) \u8f93\u51faCAFO\u7c7b\u578b\u9884\u6d4b\u548c\u63a9\u7801\u7ea7\u5f52\u56e0\uff0c\u5c06\u51b3\u7b56\u4e0e\u53ef\u89c1\u57fa\u7840\u8bbe\u65bd\u5173\u8054\u3002", "result": "\u65b9\u6cd5\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0cSwin-B+PRISM-CAFO\u6bd4\u6700\u4f73\u57fa\u7ebf\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe15%\u3002\u5728\u591a\u6837\u5316\u7f8e\u56fd\u5730\u533a\u8868\u73b0\u51fa\u5f3a\u5927\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u68af\u5ea6\u6fc0\u6d3b\u5206\u6790\u91cf\u5316\u9886\u57df\u5148\u9a8c\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u7840\u8bbe\u65bd\u4f18\u5148\u3001\u53ef\u89e3\u91ca\u7ba1\u9053\u80fd\u6709\u6548\u8bc6\u522b\u548c\u8868\u5f81CAFOs\uff0c\u4e3a\u5927\u89c4\u6a21\u755c\u7267\u4f5c\u4e1a\u76d1\u6d4b\u63d0\u4f9b\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5177\u5907\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2601.11258", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11258", "abs": "https://arxiv.org/abs/2601.11258", "authors": ["Pingzhi Tang", "Yiding Wang", "Muhan Zhang"], "title": "Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation", "comment": null, "summary": "Large Language Models (LLMs) face the \"knowledge cutoff\" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.", "AI": {"tldr": "PaST\u6846\u67b6\u901a\u8fc7\u63d0\u53d6\u9886\u57df\u65e0\u5173\u7684\u6280\u80fd\u5411\u91cf\uff0c\u5728\u8f7b\u91cfSFT\u540e\u7ebf\u6027\u6ce8\u5165\u77e5\u8bc6\u64cd\u4f5c\u6280\u80fd\uff0c\u89e3\u51b3LLM\u77e5\u8bc6\u66f4\u65b0\u4e2dSFT\u548cRL\u6b63\u4ea4\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u77e5\u8bc6\u9002\u5e94\u3002", "motivation": "LLM\u9762\u4e34\"\u77e5\u8bc6\u622a\u6b62\"\u6311\u6218\uff0cSFT\u66f4\u65b0\u4e8b\u5b9e\u5185\u5bb9\u4f46\u65e0\u6cd5\u53ef\u9760\u63d0\u5347\u95ee\u7b54\u63a8\u7406\u80fd\u529b\uff0cRL\u8ba1\u7b97\u6210\u672c\u9ad8\u4e0d\u9002\u5408\u5728\u7ebf\u9002\u5e94\uff0c\u4e14SFT\u548cRL\u7684\u53c2\u6570\u66f4\u65b0\u51e0\u4e4e\u6b63\u4ea4\u3002", "method": "\u63d0\u51fa\u53c2\u6570\u5316\u6280\u80fd\u8f6c\u79fb(PaST)\u6846\u67b6\uff1a\u4ece\u6e90\u9886\u57df\u63d0\u53d6\u9886\u57df\u65e0\u5173\u7684\u6280\u80fd\u5411\u91cf\uff0c\u5728\u76ee\u6807\u6a21\u578b\u7ecf\u8fc7\u8f7b\u91cfSFT\u540e\uff0c\u7ebf\u6027\u6ce8\u5165\u77e5\u8bc6\u64cd\u4f5c\u6280\u80fd\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u6280\u80fd\u8f6c\u79fb\u3002", "result": "\u5728SQuAD\u4e0a\u6bd4SOTA\u81ea\u7f16\u8f91SFT\u57fa\u7ebf\u63d0\u53479.9\u5206\uff1b\u5728LooGLE\u957f\u4e0a\u4e0b\u6587QA\u4e0a\u83b7\u5f978.0\u5206\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\uff1b\u5728ToolBench\u4e0a\u96f6\u6837\u672c\u6210\u529f\u7387\u5e73\u5747\u63d0\u534710.3\u5206\uff0c\u8de8\u5de5\u5177\u7c7b\u522b\u4e00\u81f4\u589e\u76ca\u3002", "conclusion": "PaST\u6846\u67b6\u901a\u8fc7\u6280\u80fd\u5411\u91cf\u5b9e\u73b0\u4e86\u9ad8\u6548\u6709\u6548\u7684\u77e5\u8bc6\u9002\u5e94\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u53ef\u6269\u5c55\u6027\u548c\u8de8\u9886\u57df\u53ef\u8f6c\u79fb\u6027\uff0c\u4e3aLLM\u77e5\u8bc6\u66f4\u65b0\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
