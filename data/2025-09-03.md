<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 12]
- [cs.LG](#cs.LG) [Total: 20]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data](https://arxiv.org/abs/2509.00213)
*Farhan Fuad Abir,Abigail Elliott Daly,Kyle Anderman,Tolga Ozmen,Laura J. Brattain*

Main category: cs.CV

TL;DR: 提出多模态深度学习框架，整合乳腺超声图像和临床数据，提高叶状肿瘤分类准确率，减少不必要的手术切除。


<details>
  <summary>Details</summary>
Motivation: 叶状肿瘤在影像学上与良性纤维腺瘤相似，术前分类困难，常导致不必要的手术切除，需要开发更准确的诊断方法。

Method: 开发双分支神经网络，从81例确诊患者的超声图像和临床数据中提取并融合特征，采用类别感知采样和分层交叉验证防止数据偏差。

Result: 多模态方法优于单模态基线，ConvNeXt和ResNet18表现最佳，AUC-ROC分别达0.9427和0.9349，F1分数分别为0.6720和0.7294。

Conclusion: 多模态AI有潜力作为无创诊断工具，减少不必要的活检，改善乳腺肿瘤管理的临床决策。

Abstract: Phyllodes tumors (PTs) are rare fibroepithelial breast lesions that are
difficult to classify preoperatively due to their radiological similarity to
benign fibroadenomas. This often leads to unnecessary surgical excisions. To
address this, we propose a multimodal deep learning framework that integrates
breast ultrasound (BUS) images with structured clinical data to improve
diagnostic accuracy. We developed a dual-branch neural network that extracts
and fuses features from ultrasound images and patient metadata from 81 subjects
with confirmed PTs. Class-aware sampling and subject-stratified 5-fold
cross-validation were applied to prevent class imbalance and data leakage. The
results show that our proposed multimodal method outperforms unimodal baselines
in classifying benign versus borderline/malignant PTs. Among six image
encoders, ConvNeXt and ResNet18 achieved the best performance in the multimodal
setting, with AUC-ROC scores of 0.9427 and 0.9349, and F1-scores of 0.6720 and
0.7294, respectively. This study demonstrates the potential of multimodal AI to
serve as a non-invasive diagnostic tool, reducing unnecessary biopsies and
improving clinical decision-making in breast tumor management.

</details>


### [2] [A Modality-agnostic Multi-task Foundation Model for Human Brain Imaging](https://arxiv.org/abs/2509.00549)
*Peirong Liu,Oula Puonti,Xiaoling Hu,Karthik Gopinath,Annabel Sorby-Adams,Daniel C. Alexander,W. Taylor Kimberly,Juan E. Iglesias*

Main category: cs.CV

TL;DR: BrainFM是一个多任务视觉基础模型，通过创新的"轻度到重度"生成和"真实-合成"混合训练策略，能够处理多种脑成像任务，对不同的模态、对比度、分辨率等具有强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型方法在校准医学成像（如CT）中表现优异，但在未校准模态（特别是MRI）中泛化能力差，对MR对比度、分辨率和方向的差异敏感，限制了在多样化临床协议中的广泛应用。

Method: 提出BrainFM模型，采用"轻度到重度"的受试者内部生成和"真实-合成"混合训练策略，使模型对获取图像的外观变化（模态、对比度、变形、分辨率、伪影）具有鲁棒性。

Result: 在11个公共数据集上评估，BrainFM在所有任务和输入模态上都表现出强大的鲁棒性和有效性，能够直接应用于图像合成、解剖分割、头皮到皮层距离、偏置场估计和配准等五个基础脑成像任务。

Conclusion: BrainFM作为一个模态无关的多任务视觉基础模型，为解决未校准医学成像模态的泛化问题提供了有效解决方案，具有广泛的临床应用潜力。

Abstract: Recent learning-based approaches have made astonishing advances in calibrated
medical imaging like computerized tomography (CT), yet they struggle to
generalize in uncalibrated modalities -- notably magnetic resonance (MR)
imaging, where performance is highly sensitive to the differences in MR
contrast, resolution, and orientation. This prevents broad applicability to
diverse real-world clinical protocols. Here we introduce BrainFM, a
modality-agnostic, multi-task vision foundation model for human brain imaging.
With the proposed "mild-to-severe" intra-subject generation and "real-synth"
mix-up training strategy, BrainFM is resilient to the appearance of acquired
images (e.g., modality, contrast, deformation, resolution, artifacts), and can
be directly applied to five fundamental brain imaging tasks, including image
synthesis for CT and T1w/T2w/FLAIR MRI, anatomy segmentation, scalp-to-cortical
distance, bias field estimation, and registration. We evaluate the efficacy of
BrainFM on eleven public datasets, and demonstrate its robustness and
effectiveness across all tasks and input modalities. Code is available at
https://github.com/jhuldr/BrainFM.

</details>


### [3] [EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions](https://arxiv.org/abs/2509.00751)
*Dinh-Khoi Vo,Van-Loc Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: 提出多阶段检索框架，结合密集文章检索、事件感知语言模型重排序和语义匹配，在EVENTA 2025挑战赛中取得最佳成绩


<details>
  <summary>Details</summary>
Motivation: 传统视觉语言检索方法在处理描述抽象事件、隐含因果关系、时间上下文或复杂叙事的自由形式字幕时表现不足

Method: 多阶段检索框架：密集文章检索→事件感知语言模型重排序→高效图像收集→字幕引导语义匹配→排序感知选择，使用Qwen3系列模型并融合多配置输出

Result: 在EVENTA 2025 Grand Challenge Track 2的私有测试集上获得top-1分数

Conclusion: 结合基于语言的推理和多模态检索的方法对于复杂真实世界图像理解非常有效

Abstract: Event-based image retrieval from free-form captions presents a significant
challenge: models must understand not only visual features but also latent
event semantics, context, and real-world knowledge. Conventional
vision-language retrieval approaches often fall short when captions describe
abstract events, implicit causality, temporal context, or contain long, complex
narratives. To tackle these issues, we introduce a multi-stage retrieval
framework combining dense article retrieval, event-aware language model
reranking, and efficient image collection, followed by caption-guided semantic
matching and rank-aware selection. We leverage Qwen3 for article search,
Qwen3-Reranker for contextual alignment, and Qwen2-VL for precise image
scoring. To further enhance performance and robustness, we fuse outputs from
multiple configurations using Reciprocal Rank Fusion (RRF). Our system achieves
the top-1 score on the private test set of Track 2 in the EVENTA 2025 Grand
Challenge, demonstrating the effectiveness of combining language-based
reasoning and multimodal retrieval for complex, real-world image understanding.
The code is available at https://github.com/vdkhoi20/EVENT-Retriever.

</details>


### [4] [CompSlider: Compositional Slider for Disentangled Multiple-Attribute Image Generation](https://arxiv.org/abs/2509.01028)
*Zixin Zhu,Kevin Duarte,Mamshad Nayeem Rizve,Chengyuan Xu,Ratheesh Kalarot,Junsong Yuan*

Main category: cs.CV

TL;DR: CompSlider是一个基于滑块的文本到图像生成方法，通过解耦多个属性来实现精确的多属性同时控制，无需重新训练基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有的滑块方法通常为每个属性单独训练适配器，忽略了多个属性之间的纠缠问题，导致不同属性间存在干扰，无法实现多属性的精确联合控制。

Method: 提出CompSlider方法，在条件先验空间中生成条件先验来控制多个属性，引入新颖的解耦损失和结构损失来组合多个属性变化同时保持图像结构一致性。

Result: 该方法在多种图像属性上进行了评估，并展示了其通用性，可扩展到视频生成领域。

Conclusion: CompSlider通过在潜在空间中操作，减少了训练和推理的计算负担，实现了更可靠和独立的属性操控。

Abstract: In text-to-image (T2I) generation, achieving fine-grained control over
attributes - such as age or smile - remains challenging, even with detailed
text prompts. Slider-based methods offer a solution for precise control of
image attributes. Existing approaches typically train individual adapter for
each attribute separately, overlooking the entanglement among multiple
attributes. As a result, interference occurs among different attributes,
preventing precise control of multiple attributes together. To address this
challenge, we aim to disentangle multiple attributes in slider-based generation
to enbale more reliable and independent attribute manipulation. Our approach,
CompSlider, can generate a conditional prior for the T2I foundation model to
control multiple attributes simultaneously. Furthermore, we introduce novel
disentanglement and structure losses to compose multiple attribute changes
while maintaining structural consistency within the image. Since CompSlider
operates in the latent space of the conditional prior and does not require
retraining the foundation model, it reduces the computational burden for both
training and inference. We evaluate our approach on a variety of image
attributes and highlight its generality by extending to video generation.

</details>


### [5] [Ensemble-Based Event Camera Place Recognition Under Varying Illumination](https://arxiv.org/abs/2509.01968)
*Therese Joseph,Tobias Fischer,Michael Milford*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于集成学习的事件相机地点识别方法，通过结合多种事件到帧重建、VPR特征提取器和时间分辨率，在严重光照变化条件下实现了更高的回归准确度，达到了白天到夜晚过渡情况下57%的相对收益。


<details>
  <summary>Details</summary>
Motivation: 虽然事件相机在视觉地点识别方面具有潜力，但在严重光照变化条件下开发稳健的VPR框架仍是一个挑战。需要一种更加稳健的方法来处理不同光照条件下的地点识别问题。

Method: 采用集成学习方法，结合多种事件到帧重建方法、VPR特征提取器和时间分辨率。与以前仅使用时间分辨率的集成方法不同，这种更广泛的融合策略提供了更好的性能。还提出了对标准序列匹配框架的修改，以在更长序列长度下提高性能。

Result: 在2个长期驾驶数据集（8公里每次辆过）上进行评估，保持了速度和停死持续时间的自然变化。在不同光照条件（下午、黄昏、夜晚）下实现了更高的稳健性，在白天到夜晚过渡情况下Recall@1指标获得57%的相对收益。

Conclusion: 该研究提供了一种有效的集成学习方法，显著提高了事件相机地点识别在严重光照变化条件下的稳健性。通过对关键设计选择的全面分析，确定了对稳健性能最为关键的组件。该方法为事件相机VPR领域的未来研究提供了有价值的参考。

Abstract: Compared to conventional cameras, event cameras provide a high dynamic range
and low latency, offering greater robustness to rapid motion and challenging
lighting conditions. Although the potential of event cameras for visual place
recognition (VPR) has been established, developing robust VPR frameworks under
severe illumination changes remains an open research problem. In this paper, we
introduce an ensemble-based approach to event camera place recognition that
combines sequence-matched results from multiple event-to-frame reconstructions,
VPR feature extractors, and temporal resolutions. Unlike previous event-based
ensemble methods, which only utilise temporal resolution, our broader fusion
strategy delivers significantly improved robustness under varied lighting
conditions (e.g., afternoon, sunset, night), achieving a 57% relative
improvement in Recall@1 across day-night transitions. We evaluate our approach
on two long-term driving datasets (with 8 km per traverse) without metric
subsampling, thereby preserving natural variations in speed and stop duration
that influence event density. We also conduct a comprehensive analysis of key
design choices, including binning strategies, polarity handling, reconstruction
methods, and feature extractors, to identify the most critical components for
robust performance. Additionally, we propose a modification to the standard
sequence matching framework that enhances performance at longer sequence
lengths. To facilitate future research, we will release our codebase and
benchmarking framework.

</details>


### [6] [FocusDPO: Dynamic Preference Optimization for Multi-Subject Personalized Image Generation via Adaptive Focus](https://arxiv.org/abs/2509.01181)
*Qiaoqiao Jin,Siming Fu,Dong She,Weinan Jia,Hualiang Wang,Mu Liu,Jidong Jiang*

Main category: cs.CV

TL;DR: FocusDPO是一个多主体个性化图像生成框架，通过动态语义对应和自适应焦点区域识别，在无需测试时优化的条件下实现多主体的精细独立控制。


<details>
  <summary>Details</summary>
Motivation: 解决多主体个性化图像生成中主体保真度保持和跨主体属性泄漏的问题，实现更好的独立控制能力。

Method: 基于动态语义对应和监督图像复杂度自适应识别焦点区域，在训练过程中根据噪声时间步渐进调整焦点区域，采用加权策略奖励信息丰富区域并惩罚低置信度区域。

Result: 在现有预训练个性化生成模型基础上显著提升性能，在单主体和多主体个性化图像合成基准测试中达到最先进水平。

Conclusion: 该方法有效缓解属性泄漏问题，在不同生成场景下保持优异的主体保真度，推动了可控多主体图像合成的前沿发展。

Abstract: Multi-subject personalized image generation aims to synthesize customized
images containing multiple specified subjects without requiring test-time
optimization. However, achieving fine-grained independent control over multiple
subjects remains challenging due to difficulties in preserving subject fidelity
and preventing cross-subject attribute leakage. We present FocusDPO, a
framework that adaptively identifies focus regions based on dynamic semantic
correspondence and supervision image complexity. During training, our method
progressively adjusts these focal areas across noise timesteps, implementing a
weighted strategy that rewards information-rich patches while penalizing
regions with low prediction confidence. The framework dynamically adjusts focus
allocation during the DPO process according to the semantic complexity of
reference images and establishes robust correspondence mappings between
generated and reference subjects. Extensive experiments demonstrate that our
method substantially enhances the performance of existing pre-trained
personalized generation models, achieving state-of-the-art results on both
single-subject and multi-subject personalized image synthesis benchmarks. Our
method effectively mitigates attribute leakage while preserving superior
subject fidelity across diverse generation scenarios, advancing the frontier of
controllable multi-subject image synthesis.

</details>


### [7] [ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization](https://arxiv.org/abs/2509.01259)
*Thinh-Phuc Nguyen,Thanh-Hai Nguyen,Gia-Huy Dinh,Lam-Huy Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: ReCap是一个新颖的事件增强图像检索和字幕生成系统，通过整合相关文章的上下文信息来生成叙事丰富、事实准确的字幕，解决了传统视觉语言模型缺乏时间、社会和历史背景的问题。


<details>
  <summary>Details</summary>
Motivation: 传统图像字幕系统往往生成通用描述，无法捕捉对新闻报道和数字存档等应用至关重要的事件级语义，需要整合更广泛的上下文信息。

Method: ReCap包含三部分：1) 基于DINOv2嵌入的两阶段文章检索系统；2) 从文章摘要、通用字幕和源元数据中提取上下文的框架；3) 基于大语言模型并采用语义高斯归一化的字幕生成系统。

Result: 在EVENTA 2025大挑战赛Track 1的OpenEvents V1数据集上，ReCap获得了0.54666的综合得分，在私有测试集上排名第二。

Conclusion: ReCap有效连接了视觉感知与现实世界知识，为高风险领域中的上下文感知图像理解提供了实用解决方案。

Abstract: Image captioning systems often produce generic descriptions that fail to
capture event-level semantics which are crucial for applications like news
reporting and digital archiving. We present ReCap, a novel pipeline for
event-enriched image retrieval and captioning that incorporates broader
contextual information from relevant articles to generate narrative-rich,
factually grounded captions. Our approach addresses the limitations of standard
vision-language models that typically focus on visible content while missing
temporal, social, and historical contexts. ReCap comprises three integrated
components: (1) a robust two-stage article retrieval system using DINOv2
embeddings with global feature similarity for initial candidate selection
followed by patch-level mutual nearest neighbor similarity re-ranking; (2) a
context extraction framework that synthesizes information from article
summaries, generic captions, and original source metadata; and (3) a large
language model-based caption generation system with Semantic Gaussian
Normalization to enhance fluency and relevance. Evaluated on the OpenEvents V1
dataset as part of Track 1 in the EVENTA 2025 Grand Challenge, ReCap achieved a
strong overall score of 0.54666, ranking 2nd on the private test set. These
results highlight ReCap's effectiveness in bridging visual perception with
real-world knowledge, offering a practical solution for context-aware image
understanding in high-stakes domains. The code is available at
https://github.com/Noridom1/EVENTA2025-Event-Enriched-Image-Captioning.

</details>


### [8] [SoccerHigh: A Benchmark Dataset for Automatic Soccer Video Summarization](https://arxiv.org/abs/2509.01439)
*Artur Díaz-Juan,Coloma Ballester,Gloria Haro*

Main category: cs.CV

TL;DR: 该论文针对足球视频摘要任务，提出了一个包含237场比赛的标注数据集和基线模型，同时引入了一个受摘要长度约束的新评估指标。


<details>
  <summary>Details</summary>
Motivation: 体育视频摘要缺乏公开数据集，特别是足球领域，这阻碍了鲁棒模型的发展。论文旨在填补这一空白，为足球视频摘要提供基准数据集。

Method: 使用SoccerNet数据集中的广播视频素材，为西班牙、法国和意大利联赛的237场比赛标注镜头边界，并设计了专门的基线模型。

Result: 基线模型在测试集上达到了0.3956的F1分数，同时提出了受摘要长度约束的新评估指标。

Conclusion: 该研究为足球视频摘要任务提供了首个公开基准数据集和基线模型，推动了该领域的发展，数据集和代码已公开。

Abstract: Video summarization aims to extract key shots from longer videos to produce
concise and informative summaries. One of its most common applications is in
sports, where highlight reels capture the most important moments of a game,
along with notable reactions and specific contextual events. Automatic summary
generation can support video editors in the sports media industry by reducing
the time and effort required to identify key segments. However, the lack of
publicly available datasets poses a challenge in developing robust models for
sports highlight generation. In this paper, we address this gap by introducing
a curated dataset for soccer video summarization, designed to serve as a
benchmark for the task. The dataset includes shot boundaries for 237 matches
from the Spanish, French, and Italian leagues, using broadcast footage sourced
from the SoccerNet dataset. Alongside the dataset, we propose a baseline model
specifically designed for this task, which achieves an F1 score of 0.3956 in
the test set. Furthermore, we propose a new metric constrained by the length of
each target summary, enabling a more objective evaluation of the generated
content. The dataset and code are available at
https://ipcv.github.io/SoccerHigh/.

</details>


### [9] [RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events](https://arxiv.org/abs/2509.01907)
*Zhenyuan Chen,Chenxi Wang,Ningyu Zhang,Feng Zhang*

Main category: cs.CV

TL;DR: 提出了RSCC数据集，包含62,315对灾前灾后遥感图像对和详细文本标注，用于训练和评估视觉语言模型在灾害监测中的应用


<details>
  <summary>Details</summary>
Motivation: 现有遥感数据集缺乏时间序列图像对和详细文本标注，无法捕捉灾害动态影响

Method: 构建大规模基准数据集RSCC，包含地震、洪水、野火等多种灾害的灾前灾后图像对，并配有人工编写的详细变化描述

Result: RSCC数据集能够支持详细的灾害相关分析，为遥感领域的视觉语言应用提供更准确、可解释和可扩展的解决方案

Conclusion: RSCC填补了遥感数据在时间和语义上的空白，为灾害感知的双时相理解提供了重要资源，代码和数据集已开源

Abstract: Remote sensing is critical for disaster monitoring, yet existing datasets
lack temporal image pairs and detailed textual annotations. While
single-snapshot imagery dominates current resources, it fails to capture
dynamic disaster impacts over time. To address this gap, we introduce the
Remote Sensing Change Caption (RSCC) dataset, a large-scale benchmark
comprising 62,315 pre-/post-disaster image pairs (spanning earthquakes, floods,
wildfires, and more) paired with rich, human-like change captions. By bridging
the temporal and semantic divide in remote sensing data, RSCC enables robust
training and evaluation of vision-language models for disaster-aware
bi-temporal understanding. Our results highlight RSCC's ability to facilitate
detailed disaster-related analysis, paving the way for more accurate,
interpretable, and scalable vision-language applications in remote sensing.
Code and dataset are available at https://github.com/Bili-Sakura/RSCC.

</details>


### [10] [HydroVision: Predicting Optically Active Parameters in Surface Water Using Computer Vision](https://arxiv.org/abs/2509.01882)
*Shubham Laxmikant Deshmukh,Matthew Wilchek,Feras A. Batarseh*

Main category: cs.CV

TL;DR: HydroVision是一个基于深度学习的场景分类框架，使用RGB图像估计多种水质参数，为水质监测提供了一种可扩展、成本效益高的替代方案。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉和深度学习的进步使得非接触式水质评估成为可能，这对于灾害响应和公共卫生保护至关重要。传统多光谱和超光谱遥感方法成本高且不易获取，需要更经济高效的解决方案。

Method: 使用超过50万张季节性变化的RGB图像训练模型，评估了四种卷积神经网络（VGG-16、ResNet50、MobileNetV2、DenseNet121）和一个Vision Transformer，通过迁移学习确定最佳架构。

Result: DenseNet121在验证中表现最佳，预测CDOM的R2分数达到0.89，展示了该框架在各种条件下进行实际水质监测的潜力。

Conclusion: HydroVision证明了使用广泛可用的RGB图像进行水质监测的可行性，为监管机构提供了有效的监测工具。未来工作将重点提高在低光和遮挡场景下的鲁棒性。

Abstract: Ongoing advancements in computer vision, particularly in pattern recognition
and scene classification, have enabled new applications in environmental
monitoring. Deep learning now offers non-contact methods for assessing water
quality and detecting contamination, both critical for disaster response and
public health protection. This work introduces HydroVision, a deep
learning-based scene classification framework that estimates optically active
water quality parameters including Chlorophyll-Alpha, Chlorophylls, Colored
Dissolved Organic Matter (CDOM), Phycocyanins, Suspended Sediments, and
Turbidity from standard Red-Green-Blue (RGB) images of surface water.
HydroVision supports early detection of contamination trends and strengthens
monitoring by regulatory agencies during external environmental stressors,
industrial activities, and force majeure events. The model is trained on more
than 500,000 seasonally varied images collected from the United States
Geological Survey Hydrologic Imagery Visualization and Information System
between 2022 and 2024. This approach leverages widely available RGB imagery as
a scalable, cost-effective alternative to traditional multispectral and
hyperspectral remote sensing. Four state-of-the-art convolutional neural
networks (VGG-16, ResNet50, MobileNetV2, DenseNet121) and a Vision Transformer
are evaluated through transfer learning to identify the best-performing
architecture. DenseNet121 achieves the highest validation performance, with an
R2 score of 0.89 in predicting CDOM, demonstrating the framework's promise for
real-world water quality monitoring across diverse conditions. While the
current model is optimized for well-lit imagery, future work will focus on
improving robustness under low-light and obstructed scenarios to expand its
operational utility.

</details>


### [11] [MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement](https://arxiv.org/abs/2509.01977)
*Dong She,Siming Fu,Mushui Liu,Qiaoqiao Jin,Hualiang Wang,Mu Liu,Jidong Jiang*

Main category: cs.CV

TL;DR: MOSAIC是一个面向多主体个性化生成的表示中心框架，通过语义对应和正交特征解耦解决身份混合和属性泄漏问题，在4+主体情况下仍保持高保真度


<details>
  <summary>Details</summary>
Motivation: 现有方法在多主体个性化生成中存在身份混合和属性泄漏问题，主要原因是缺乏对多个参考主体在共享表示空间中如何交互的充分建模

Method: 提出语义对应注意力损失确保精确的点对点语义对齐，开发多参考解耦损失将不同主体推入正交注意力子空间以防止特征干扰，并引入SemAlign-MS数据集提供细粒度语义对应

Result: 在多个基准测试中达到最先进性能，在4+参考主体情况下仍保持高保真度，而现有方法通常在3个主体以上性能下降

Conclusion: MOSAIC通过表示层面的精确语义对齐和特征解耦，成功解决了多主体生成中的身份保真和语义连贯性问题，为复杂多主体合成应用开辟了新可能性

Abstract: Multi-subject personalized generation presents unique challenges in
maintaining identity fidelity and semantic coherence when synthesizing images
conditioned on multiple reference subjects. Existing methods often suffer from
identity blending and attribute leakage due to inadequate modeling of how
different subjects should interact within shared representation spaces. We
present MOSAIC, a representation-centric framework that rethinks multi-subject
generation through explicit semantic correspondence and orthogonal feature
disentanglement. Our key insight is that multi-subject generation requires
precise semantic alignment at the representation level - knowing exactly which
regions in the generated image should attend to which parts of each reference.
To enable this, we introduce SemAlign-MS, a meticulously annotated dataset
providing fine-grained semantic correspondences between multiple reference
subjects and target images, previously unavailable in this domain. Building on
this foundation, we propose the semantic correspondence attention loss to
enforce precise point-to-point semantic alignment, ensuring high consistency
from each reference to its designated regions. Furthermore, we develop the
multi-reference disentanglement loss to push different subjects into orthogonal
attention subspaces, preventing feature interference while preserving
individual identity characteristics. Extensive experiments demonstrate that
MOSAIC achieves state-of-the-art performance on multiple benchmarks. Notably,
while existing methods typically degrade beyond 3 subjects, MOSAIC maintains
high fidelity with 4+ reference subjects, opening new possibilities for complex
multi-subject synthesis applications.

</details>


### [12] [SegFormer Fine-Tuning with Dropout: Advancing Hair Artifact Removal in Skin Lesion Analysis](https://arxiv.org/abs/2509.02156)
*Asif Mohammed Saad,Umme Niraj Mahi*

Main category: cs.CV

TL;DR: 提出基于SegFormer的改进模型SegformerWithDropout，通过dropout正则化实现皮肤镜图像中毛发伪影的精确分割，在多项指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 皮肤镜图像中的毛发伪影会遮挡关键诊断特征，影响皮肤病变分析的准确性，需要有效的毛发分割方法来提升预处理效果。

Method: 使用微调的SegFormer模型，采用MiT-B2编码器（ImageNet预训练），在分割头中加入0.3概率的dropout正则化。使用500张带精细毛发标注的皮肤镜图像，采用10折交叉验证、AdamW优化器（学习率0.001）和交叉熵损失进行训练。

Result: 模型在交叉验证中表现稳健：平均Dice系数约0.96，IoU值0.93，PSNR约34dB，SSIM 0.97，LPIPS仅0.06，显示出优异的毛发分割性能。

Conclusion: 该方法能有效分割皮肤镜图像中的毛发伪影，具有提升下游皮肤癌检测任务预处理效果的潜力。

Abstract: Hair artifacts in dermoscopic images present significant challenges for
accurate skin lesion analysis, potentially obscuring critical diagnostic
features in dermatological assessments. This work introduces a fine-tuned
SegFormer model augmented with dropout regularization to achieve precise hair
mask segmentation. The proposed SegformerWithDropout architecture leverages the
MiT-B2 encoder, pretrained on ImageNet, with an in-channel count of 3 and 2
output classes, incorporating a dropout probability of 0.3 in the segmentation
head to prevent overfitting. Training is conducted on a specialized dataset of
500 dermoscopic skin lesion images with fine-grained hair mask annotations,
employing 10-fold cross-validation, AdamW optimization with a learning rate of
0.001, and cross-entropy loss. Early stopping is applied based on validation
loss, with a patience of 3 epochs and a maximum of 20 epochs per fold.
Performance is evaluated using a comprehensive suite of metrics, including
Intersection over Union (IoU), Dice coefficient, Peak Signal-to-Noise Ratio
(PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch
Similarity (LPIPS). Experimental results from the cross-validation demonstrate
robust performance, with average Dice coefficients reaching approximately 0.96
and IoU values of 0.93, alongside favorable PSNR (around 34 dB), SSIM (0.97),
and low LPIPS (0.06), highlighting the model's effectiveness in accurate hair
artifact segmentation and its potential to enhance preprocessing for downstream
skin cancer detection tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Experimental Assessment of a Multi-Class AI/ML Architecture for Real-Time Characterization of Cyber Events in a Live Research Reactor](https://arxiv.org/abs/2509.00076)
*Zachery Dahm,Konstantinos Vasili,Vasileios Theos,Konstantinos Gkouliaras,William Richards,True Miller,Brian Jowers,Stylianos Chatzidakis*

Main category: cs.LG

TL;DR: 本文提出了一种多层AI/ML架构，通过整合信息技术和运营技术数据来识别、特征化和区分核工业中的网络安全事件与运营异常。在PUR-1研究反应堆上进行了实验验证，包含14种系统状态和1380万多元数据点。


<details>
  <summary>Details</summary>
Motivation: 核工业对AI/ML的需求增长，但现有研究少有在运行核反应堆上验证AI/ML工具的可行性。需要一种能够区分网络安全事件和其他运营异常的综合解决方案。

Method: 设计多层AI/ML架构，整合IT和OT数据流，在PUR-1研究反应堆上进行实验。包含多种并发的假数据注入和拒绝服务攻击场景，涵盖14种系统状态和1380万多元数据点。

Result: AI/ML能够在具有挑战性的条件下（如拒绝服务攻击）区分正常、异常和网络安全相关事件。结合IT和OT数据提高了分类准确性，但在某些网络事件中面临同步和收集挑战。

Conclusion: 研究证明了AI/ML在核网络安全中的强大潜力，但同时指出需要进一步精炼处理复杂事件区分和多类架构的技术。

Abstract: There is increased interest in applying Artificial Intelligence and Machine
Learning (AI/ML) within the nuclear industry and nuclear engineering community.
Effective implementation of AI/ML could offer benefits to the nuclear domain,
including enhanced identification of anomalies, anticipation of system
failures, and operational schedule optimization. However, limited work has been
done to investigate the feasibility and applicability of AI/ML tools in a
functioning nuclear reactor. Here, we go beyond the development of a single
model and introduce a multi-layered AI/ML architecture that integrates both
information technology and operational technology data streams to identify,
characterize, and differentiate (i) among diverse cybersecurity events and (ii)
between cyber events and other operational anomalies. Leveraging Purdue
Universitys research reactor, PUR-1, we demonstrate this architecture through a
representative use case that includes multiple concurrent false data injections
and denial-of-service attacks of increasing complexity under realistic reactor
conditions. The use case includes 14 system states (1 normal, 13 abnormal) and
over 13.8 million multi-variate operational and information technology data
points. The study demonstrated the capability of AI/ML to distinguish between
normal, abnormal, and cybersecurity-related events, even under challenging
conditions such as denial-of-service attacks. Combining operational and
information technology data improved classification accuracy but posed
challenges related to synchronization and collection during certain cyber
events. While results indicate significant promise for AI/ML in nuclear
cybersecurity, the findings also highlight the need for further refinement in
handling complex event differentiation and multi-class architectures.

</details>


### [14] [Data Cartography for Detecting Memorization Hotspots and Guiding Data Interventions in Generative Models](https://arxiv.org/abs/2509.00083)
*Laksh Patel,Neel Shanbhag*

Main category: cs.LG

TL;DR: GenDataCarto框架通过难度和记忆化评分对预训练数据进行分类，针对性剪枝和权重调整，在仅剪枝10%数据的情况下将合成测试提取成功率降低40%以上，验证困惑度仅增加0.5%。


<details>
  <summary>Details</summary>
Motivation: 现代生成模型存在过拟合和无意记忆罕见训练样本的风险，这些样本可能被攻击者提取或夸大基准性能，需要数据中心的解决方案来缓解泄露问题。

Method: 提出生成数据制图(GenDataCarto)框架，为每个预训练样本分配难度分数(早期epoch损失)和记忆化分数(遗忘事件频率)，将样本划分为四个象限来指导针对性剪枝和上下权重调整。

Result: 实证显示，在仅剪枝10%数据的情况下，合成测试提取成功率降低40%以上，验证困惑度仅增加不到0.5%。理论证明记忆化分数在平滑假设下是经典影响的下界，下权重高记忆化热点可通过均匀稳定性界限降低泛化差距。

Conclusion: 有原则的数据干预可以显著减轻泄露，同时对生成性能的影响最小，证明了数据中心方法在生成模型安全中的有效性。

Abstract: Modern generative models risk overfitting and unintentionally memorizing rare
training examples, which can be extracted by adversaries or inflate benchmark
performance. We propose Generative Data Cartography (GenDataCarto), a
data-centric framework that assigns each pretraining sample a difficulty score
(early-epoch loss) and a memorization score (frequency of ``forget events''),
then partitions examples into four quadrants to guide targeted pruning and
up-/down-weighting. We prove that our memorization score lower-bounds classical
influence under smoothness assumptions and that down-weighting
high-memorization hotspots provably decreases the generalization gap via
uniform stability bounds. Empirically, GenDataCarto reduces synthetic canary
extraction success by over 40\% at just 10\% data pruning, while increasing
validation perplexity by less than 0.5\%. These results demonstrate that
principled data interventions can dramatically mitigate leakage with minimal
cost to generative performance.

</details>


### [15] [Optimized Weight Initialization on the Stiefel Manifold for Deep ReLU Neural Networks](https://arxiv.org/abs/2509.00362)
*Hyungu Lee,Taehyeong Kim,Hayoung Choi*

Main category: cs.LG

TL;DR: 提出了一种针对ReLU网络的优化正交初始化方法，通过Stiefel流形上的优化问题来校准预激活统计量，解决了深度网络中神经元失活和梯度消失问题


<details>
  <summary>Details</summary>
Motivation: 传统初始化方法（如He、Xavier、正交初始化）在深度ReLU网络中无法有效调节预激活均值和控制激活稀疏性，导致神经元永久失活（dying ReLU）和梯度不稳定问题

Method: 在Stiefel流形上求解优化问题，推导出闭式解和高效采样方案，专门为ReLU激活函数优化正交初始化，从初始化阶段就保持尺度并校准预激活统计量

Result: 理论分析表明该方法能防止dying ReLU问题、减缓激活方差衰减、缓解梯度消失，在MNIST、Fashion-MNIST、表格数据集、少样本设置和ReLU族激活函数上均优于现有初始化方法

Conclusion: 该方法显著提升了深度ReLU网络的训练稳定性和性能，为深度网络提供了更有效的初始化策略

Abstract: Stable and efficient training of ReLU networks with large depth is highly
sensitive to weight initialization. Improper initialization can cause permanent
neuron inactivation dying ReLU and exacerbate gradient instability as network
depth increases. Methods such as He, Xavier, and orthogonal initialization
preserve variance or promote approximate isometry. However, they do not
necessarily regulate the pre-activation mean or control activation sparsity,
and their effectiveness often diminishes in very deep architectures. This work
introduces an orthogonal initialization specifically optimized for ReLU by
solving an optimization problem on the Stiefel manifold, thereby preserving
scale and calibrating the pre-activation statistics from the outset. A family
of closed-form solutions and an efficient sampling scheme are derived.
Theoretical analysis at initialization shows that prevention of the dying ReLU
problem, slower decay of activation variance, and mitigation of gradient
vanishing, which together stabilize signal and gradient flow in deep
architectures. Empirically, across MNIST, Fashion-MNIST, multiple tabular
datasets, few-shot settings, and ReLU-family activations, our method
outperforms previous initializations and enables stable training in deep
networks.

</details>


### [16] [Curriculum Guided Personalized Subgraph Federated Learning](https://arxiv.org/abs/2509.00402)
*Minku Kang,Hogun Park*

Main category: cs.LG

TL;DR: CUFL是一个新的个性化子图联邦学习框架，通过课程学习逐步暴露模型给通用和特定客户端子结构，防止早期过拟合，并使用细粒度结构指标改进加权聚合。


<details>
  <summary>Details</summary>
Motivation: 解决子图联邦学习中由于数据异构性导致的快速过拟合问题，防止客户端相似度矩阵停滞或崩溃，使聚合能够有效利用多样知识。

Method: 采用课程学习自适应选择边进行训练，先暴露给通用跨客户端子结构，再暴露给客户端特定子结构；使用随机参考图上重构的细粒度结构指标估计客户端相似度。

Result: 在六个基准数据集上的广泛实验证实，CUFL相比相关基线方法取得了优越的性能。

Conclusion: CUFL通过调节个性化过程，有效防止了早期过拟合，改进了加权聚合效果，为子图联邦学习提供了有效的解决方案。

Abstract: Subgraph Federated Learning (FL) aims to train Graph Neural Networks (GNNs)
across distributed private subgraphs, but it suffers from severe data
heterogeneity. To mitigate data heterogeneity, weighted model aggregation
personalizes each local GNN by assigning larger weights to parameters from
clients with similar subgraph characteristics inferred from their current model
states. However, the sparse and biased subgraphs often trigger rapid
overfitting, causing the estimated client similarity matrix to stagnate or even
collapse. As a result, aggregation loses effectiveness as clients reinforce
their own biases instead of exploiting diverse knowledge otherwise available.
To this end, we propose a novel personalized subgraph FL framework called
Curriculum guided personalized sUbgraph Federated Learning (CUFL). On the
client side, CUFL adopts Curriculum Learning (CL) that adaptively selects edges
for training according to their reconstruction scores, exposing each GNN first
to easier, generic cross-client substructures and only later to harder,
client-specific ones. This paced exposure prevents early overfitting to biased
patterns and enables gradual personalization. By regulating personalization,
the curriculum also reshapes server aggregation from exchanging generic
knowledge to propagating client-specific knowledge. Further, CUFL improves
weighted aggregation by estimating client similarity using fine-grained
structural indicators reconstructed on a random reference graph. Extensive
experiments on six benchmark datasets confirm that CUFL achieves superior
performance compared to relevant baselines. Code is available at
https://github.com/Kang-Min-Ku/CUFL.git.

</details>


### [17] [TranCIT: Transient Causal Interaction Toolbox](https://arxiv.org/abs/2509.00602)
*Salar Nouri,Kaidi Shao,Shervin Safavi*

Main category: cs.LG

TL;DR: TranCIT是一个开源Python工具箱，用于从非平稳神经信号中量化瞬态因果交互作用，解决了传统方法对短暂神经事件分析不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理短暂神经事件时往往不足，而先进的特定事件技术在Python生态系统中缺乏可访问的实现，需要开发一个综合的分析工具来填补这一空白。

Method: TranCIT实现了包括Granger因果性、传递熵以及更稳健的基于结构因果模型的动态因果强度(DCS)和相对动态因果强度(rDCS)在内的综合分析流程，用于准确检测事件驱动的因果效应。

Result: TranCIT在高同步状态下成功捕捉到传统方法无法检测的因果关系，并在真实数据中识别出海马CA3到CA1在尖波涟漪事件期间的已知瞬态信息流。

Conclusion: 该软件包提供了一个用户友好且经过验证的解决方案，用于研究控制复杂系统的瞬态因果动力学。

Abstract: Quantifying transient causal interactions from non-stationary neural signals
is a fundamental challenge in neuroscience. Traditional methods are often
inadequate for brief neural events, and advanced, event-specific techniques
have lacked accessible implementations within the Python ecosystem. Here, we
introduce trancit (Transient Causal Interaction Toolbox), an open-source Python
package designed to bridge this gap. TranCIT implements a comprehensive
analysis pipeline, including Granger Causality, Transfer Entropy, and the more
robust Structural Causal Model-based Dynamic Causal Strength (DCS) and relative
Dynamic Causal Strength (rDCS) for accurately detecting event-driven causal
effects. We demonstrate TranCIT's utility by successfully capturing causality
in high-synchrony regimes where traditional methods fail and by identifying the
known transient information flow from hippocampal CA3 to CA1 during sharp-wave
ripple events in real-world data. The package offers a user-friendly, validated
solution for investigating the transient causal dynamics that govern complex
systems.

</details>


### [18] [AMCR: A Framework for Assessing and Mitigating Copyright Risks in Generative Models](https://arxiv.org/abs/2509.00641)
*Zhipeng Yin,Zichong Wang,Avash Palikhe,Zhen Liu,Jun Liu,Wenbin Zhang*

Main category: cs.LG

TL;DR: AMCR框架通过系统重构风险提示、注意力相似性分析和自适应风险缓解，有效检测和减轻生成模型中的版权风险，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 生成模型在文本到图像任务中取得显著进展，但严重依赖大规模训练数据，可能无意中复制受版权保护的内容，带来法律和伦理挑战。现有基于提示的方法在处理微妙侵权情况时效果有限。

Method: 提出AMCR综合框架：1）系统重构风险提示为安全形式；2）通过注意力相似性分析检测部分侵权；3）在生成过程中自适应缓解风险。

Result: 大量实验验证了AMCR在揭示和减轻潜在版权风险方面的有效性，为生成模型的安全部署提供了实用见解和基准。

Conclusion: AMCR框架为解决生成模型中的版权问题提供了全面解决方案，能够在保持图像质量的同时有效减少版权侵权风险。

Abstract: Generative models have achieved impressive results in text to image tasks,
significantly advancing visual content creation. However, this progress comes
at a cost, as such models rely heavily on large-scale training data and may
unintentionally replicate copyrighted elements, creating serious legal and
ethical challenges for real-world deployment. To address these concerns,
researchers have proposed various strategies to mitigate copyright risks, most
of which are prompt based methods that filter or rewrite user inputs to prevent
explicit infringement. While effective in handling obvious cases, these
approaches often fall short in more subtle situations, where seemingly benign
prompts can still lead to infringing outputs. To address these limitations,
this paper introduces Assessing and Mitigating Copyright Risks (AMCR), a
comprehensive framework which i) builds upon prompt-based strategies by
systematically restructuring risky prompts into safe and non-sensitive forms,
ii) detects partial infringements through attention-based similarity analysis,
and iii) adaptively mitigates risks during generation to reduce copyright
violations without compromising image quality. Extensive experiments validate
the effectiveness of AMCR in revealing and mitigating latent copyright risks,
offering practical insights and benchmarks for the safer deployment of
generative models.

</details>


### [19] [Robust Spatiotemporal Forecasting Using Adaptive Deep-Unfolded Variational Mode Decomposition](https://arxiv.org/abs/2509.00703)
*Osama Ahmad,Lukas Wesemann,Fabian Waschkowski,Zubair Khalid*

Main category: cs.LG

TL;DR: MAGN模型通过将变分模态分解转化为可训练的神经网络模块，解决了传统分解方法计算效率低和需要手动调参的问题，在大型时空预测任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络在时空预测中面临复杂波动模式和频谱纠缠问题，而现有的分解集成方法如VMGCN虽然提高了精度，但存在计算效率低下和需要手动超参数调优的局限性。

Method: 提出模式自适应图网络(MAGN)，包含两个关键创新：1) 展开变分模态分解(UVMD)模块，用固定深度网络替代迭代优化；2) 模式特定的可学习带宽约束，自适应空间异质性并防止频谱重叠。

Result: 在LargeST基准测试(6,902个传感器，2.41亿观测值)上，MAGN相比VMGCN减少了85-95%的预测误差，分解时间减少了250倍，并优于最先进的基线方法。

Conclusion: MAGN成功解决了传统分解方法的计算效率和调参问题，为大规模时空预测提供了高效准确的解决方案。

Abstract: Accurate spatiotemporal forecasting is critical for numerous complex systems
but remains challenging due to complex volatility patterns and spectral
entanglement in conventional graph neural networks (GNNs). While
decomposition-integrated approaches like variational mode graph convolutional
network (VMGCN) improve accuracy through signal decomposition, they suffer from
computational inefficiency and manual hyperparameter tuning. To address these
limitations, we propose the mode adaptive graph network (MAGN) that transforms
iterative variational mode decomposition (VMD) into a trainable neural module.
Our key innovations include (1) an unfolded VMD (UVMD) module that replaces
iterative optimization with a fixed-depth network to reduce the decomposition
time (by 250x for the LargeST benchmark), and (2) mode-specific learnable
bandwidth constraints ({\alpha}k ) adapt spatial heterogeneity and eliminate
manual tuning while preventing spectral overlap. Evaluated on the LargeST
benchmark (6,902 sensors, 241M observations), MAGN achieves an 85-95% reduction
in the prediction error over VMGCN and outperforms state-of-the-art baselines.

</details>


### [20] [ProCause: Generating Counterfactual Outcomes to Evaluate Prescriptive Process Monitoring Methods](https://arxiv.org/abs/2509.00797)
*Jakob De Moor,Hans Weytjens,Johannes De Smedt*

Main category: cs.LG

TL;DR: ProCause是一个新的生成式深度学习方法，用于评估规范性流程监控方法，通过整合多种因果推理架构和时序模型来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的RealCause方法在评估规范性流程监控方法时存在两个主要问题：忽略流程数据中的时序依赖性，以及仅依赖单一的TARNet因果推理模型架构，限制了评估效果。

Method: 提出ProCause方法，支持序列模型（如LSTM）和非序列模型，整合多种因果推理架构（S-Learner、T-Learner、TARNet和集成模型），通过模拟器和真实数据分析进行验证。

Result: 研究发现TARNet并非总是最佳选择，集成模型提供更一致的可靠性，当存在时序依赖性时，使用LSTM模型可以改善评估效果。真实数据分析验证了ProCause的实用有效性。

Conclusion: ProCause为规范性流程监控方法提供了更可靠的评估框架，通过支持多种模型架构和时序处理能力，解决了现有方法的局限性，确保了评估结果的准确性和一致性。

Abstract: Prescriptive Process Monitoring (PresPM) is the subfield of Process Mining
that focuses on optimizing processes through real-time interventions based on
event log data. Evaluating PresPM methods is challenging due to the lack of
ground-truth outcomes for all intervention actions in datasets. A generative
deep learning approach from the field of Causal Inference (CI), RealCause, has
been commonly used to estimate the outcomes for proposed intervention actions
to evaluate a new policy. However, RealCause overlooks the temporal
dependencies in process data, and relies on a single CI model architecture,
TARNet, limiting its effectiveness. To address both shortcomings, we introduce
ProCause, a generative approach that supports both sequential (e.g., LSTMs) and
non-sequential models while integrating multiple CI architectures (S-Learner,
T-Learner, TARNet, and an ensemble). Our research using a simulator with known
ground truths reveals that TARNet is not always the best choice; instead, an
ensemble of models offers more consistent reliability, and leveraging LSTMs
shows potential for improved evaluations when temporal dependencies are
present. We further validate ProCause's practical effectiveness through a
real-world data analysis, ensuring a more reliable evaluation of PresPM
methods.

</details>


### [21] [CCE: Confidence-Consistency Evaluation for Time Series Anomaly Detection](https://arxiv.org/abs/2509.01098)
*Zhijie Zhong,Zhiwen Yu,Yiu-ming Cheung,Kaixiang Yang*

Main category: cs.LG

TL;DR: 时间序列异常检测评估指标存在识别力不足、超参数依赖性强、对干扰敏感和计算复杂度高等问题。本文提出信心一致性评估(CCE)指标，通过贝叶斯估计量化异常分数的不确定性，构建全局和事件级的信心一致性评分，具有严格有界性、Lipschitz稳健性和线性时间复杂度。同时建立RankEval排名评测基准，为评估指标提供标准化可复现的评估流程。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测评估指标存在四个主要问题：识别力不足、强超参数依赖性、对干扰敏感性高、计算复杂度高。这些限制了模型评估的准确性和可靠性。

Method: 提出信心一致性评估(CCE)指标，通过贝叶斯估计量化异常分数的不确定性。方法包括：1)构建全局和事件级的信心分数；2)构建一致性分数；3)组合成简洁的CCE指标。

Result: 理论和实验证明CCE具有：1)严格有界性；2)Lipschitz稳健性（对分数干扰具有稳健性）；3)线性时间复杂度O(n)。同时建立了RankEval排名评测基准，为各种评估指标提供标准化可复现的评估流程。

Conclusion: CCE指标充分解决了现有时间序列异常检测评估指标的四大问题，具有优秀的数学特性和计算效率。RankEval基准的建立为评估指标的对比提供了标准化平台。两者的开源实现促进了领域的可复现研究。

Abstract: Time Series Anomaly Detection metrics serve as crucial tools for model
evaluation. However, existing metrics suffer from several limitations:
insufficient discriminative power, strong hyperparameter dependency,
sensitivity to perturbations, and high computational overhead. This paper
introduces Confidence-Consistency Evaluation (CCE), a novel evaluation metric
that simultaneously measures prediction confidence and uncertainty consistency.
By employing Bayesian estimation to quantify the uncertainty of anomaly scores,
we construct both global and event-level confidence and consistency scores for
model predictions, resulting in a concise CCE metric. Theoretically and
experimentally, we demonstrate that CCE possesses strict boundedness, Lipschitz
robustness against score perturbations, and linear time complexity
$\mathcal{O}(n)$. Furthermore, we establish RankEval, a benchmark for comparing
the ranking capabilities of various metrics. RankEval represents the first
standardized and reproducible evaluation pipeline that enables objective
comparison of evaluation metrics. Both CCE and RankEval implementations are
fully open-source.

</details>


### [22] [Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks](https://arxiv.org/abs/2509.01257)
*Andrea Fox,Francesco De Pellegrini,Eitan Altman*

Main category: cs.LG

TL;DR: 提出了一种去中心化的多智能体强化学习框架，通过共享约束向量实现隐式协调，解决了边缘计算中资源竞争问题，在有限观测和通信约束下表现优异


<details>
  <summary>Details</summary>
Motivation: 边缘计算系统中，自主智能体需要在共享资源竞争环境下快速做出本地决策。现有MARL方法依赖集中式评论家或频繁通信，在有限可观测性和通信约束下效果不佳

Method: 每个智能体解决约束马尔可夫决策过程(CMDP)，通过共享约束向量进行隐式协调。约束条件防止共享服务器资源过载，约束更新频率低，作为轻量级协调机制。使用安全强化学习使智能体学习满足本地和全局目标的策略

Result: 在温和假设下建立了理论保证，实验验证显示该方法在大型设置中优于集中式和独立基线方法，性能显著提升

Conclusion: 该去中心化框架通过共享约束机制实现了有效的隐式协调，在有限通信条件下仍能保持良好性能，特别适合大规模边缘计算场景

Abstract: In edge computing systems, autonomous agents must make fast local decisions
while competing for shared resources. Existing MARL methods often resume to
centralized critics or frequent communication, which fail under limited
observability and communication constraints. We propose a decentralized
framework in which each agent solves a constrained Markov decision process
(CMDP), coordinating implicitly through a shared constraint vector. For the
specific case of offloading, e.g., constraints prevent overloading shared
server resources. Coordination constraints are updated infrequently and act as
a lightweight coordination mechanism. They enable agents to align with global
resource usage objectives but require little direct communication. Using safe
reinforcement learning, agents learn policies that meet both local and global
goals. We establish theoretical guarantees under mild assumptions and validate
our approach experimentally, showing improved performance over centralized and
independent baselines, especially in large-scale settings.

</details>


### [23] [DPF-CM: A Data Processing Framework with Privacy-Preserving Vector Databases for Chinese Medical LLMs Training and Deployment](https://arxiv.org/abs/2509.01354)
*Wei Huang,Anda Cheng,Zhao Zhang,Yinggui Wang*

Main category: cs.LG

TL;DR: DPF-CM是一个针对中文医疗大语言模型训练和部署的全面数据处理框架，包含训练数据处理和隐私保护两个核心模块，显著提升模型性能并减少隐私泄露风险。


<details>
  <summary>Details</summary>
Motivation: 当前开源的中文医疗语言模型训练流程主要关注训练方法优化，但缺乏对训练数据处理的全面探索，需要解决指令内容缺乏和隐私保护问题。

Method: 提出DPF-CM框架，包含两个模块：(1)训练数据处理管道，采用链式示例上下文学习策略生成问题导向指令，并使用集成过滤机制进行偏好数据筛选；(2)隐私保护模块，通过隐私保护向量数据库(PPVD)方法，包括模型记忆搜索、高风险数据库构建、安全数据库构建和匹配替换四个阶段。

Result: 实验结果显示DPF-CM显著提高模型准确性，使训练的中文医疗LLM在开源模型中达到最先进性能，同时将训练数据隐私泄露减少27%。

Conclusion: DPF-CM框架有效解决了中文医疗LLM训练中的数据质量和隐私保护问题，为医疗领域大语言模型的训练和部署提供了全面的数据处理解决方案。

Abstract: Current open-source training pipelines for Chinese medical language models
predominantly emphasize optimizing training methodologies to enhance the
performance of large language models (LLMs), yet lack comprehensive exploration
into training data processing. To address this gap, we propose DPF-CM, a
holistic Data Processing Framework for Chinese Medical LLMs training and
deployment. DPF-CM comprises two core modules. The first module is a data
processing pipeline tailored for model training. Beyond standard data
processing operations, we (1) introduce a chained examples context-learning
strategy to generate question-oriented instructions to mitigate the lack of
instruction content, and (2) implement an ensemble-based filtering mechanism
for preference data curation that averages multiple reward models to suppress
noisy samples. The second module focuses on privacy preservation during model
deployment. To prevent privacy risks from the inadvertent exposure of training
data, we propose a Privacy Preserving Vector Database (PPVD) approach, which
involves model memory search, high-risk database construction, secure database
construction, and match-and-replace, four key stages to minimize privacy
leakage during inference collectively. Experimental results show that DPF-CM
significantly improves model accuracy, enabling our trained Chinese medical LLM
to achieve state-of-the-art performance among open-source counterparts.
Moreover, the framework reduces training data privacy leakage by 27%.

</details>


### [24] [Graph Contrastive Learning versus Untrained Baselines: The Role of Dataset Size](https://arxiv.org/abs/2509.01541)
*Smayan Khanna,Doruk Efe Gökmen,Risi Kondor,Vincenzo Vitelli*

Main category: cs.LG

TL;DR: 研究发现图对比学习(GCL)的优势严重依赖数据集大小和任务难度，在标准数据集上未训练的GNN、简单MLP甚至手工统计特征都能与GCL媲美或超越，只有在大型分子数据集上GCL才显示出优势


<details>
  <summary>Details</summary>
Motivation: 质疑GCL是否真的优于未经训练的基线方法，探究GCL在不同数据集规模和任务难度下的实际表现

Method: 在标准数据集、大型分子数据集(ogbg-molhiv)和合成数据集上比较GCL与未训练GNN、简单MLP和手工统计特征的性能

Result: GCL优势与数据集大小强相关：小规模时表现不佳，超过数千个图时开始领先但最终达到性能平台；在合成数据集上GCL准确率近似与图数量对数成正比，性能差距随任务复杂度变化

Conclusion: 需要在基准测试和应用中明确数据集规模的作用，并设计避免性能平台的GCL算法

Abstract: Graph Contrastive Learning (GCL) has emerged as a leading paradigm for self-
supervised learning on graphs, with strong performance reported on standardized
datasets and growing applications ranging from genomics to drug discovery. We
ask a basic question: does GCL actually outperform untrained baselines? We find
that GCL's advantage depends strongly on dataset size and task difficulty. On
standard datasets, untrained Graph Neural Networks (GNNs), simple multilayer
perceptrons, and even handcrafted statistics can rival or exceed GCL. On the
large molecular dataset ogbg-molhiv, we observe a crossover: GCL lags at small
scales but pulls ahead beyond a few thousand graphs, though this gain
eventually plateaus. On synthetic datasets, GCL accuracy approximately scales
with the logarithm of the number of graphs and its performance gap (compared
with untrained GNNs) varies with respect to task complexity. Moving forward, it
is crucial to identify the role of dataset size in benchmarks and applications,
as well as to design GCL algorithms that avoid performance plateaus.

</details>


### [25] [Model Unmerging: Making Your Models Unmergeable for Secure Model Sharing](https://arxiv.org/abs/2509.01548)
*Zihao Wang,Enneng Yang,Lu Yin,Shiwei Liu,Li Shen*

Main category: cs.LG

TL;DR: MergeLock是一种主动保护机制，通过扰乱模型参数使其无法被合并，从而防止未经授权的模型合并。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的微调模型公开可用，模型合并的安全性引发关注。未经授权的合并可能侵犯开发者权益并泄露敏感个人信息。现有方法主要检测合并模型是否源自特定源模型，但无法有效防止非法合并。

Method: 利用Transformer模型中注意力机制的固有对称性，随机采样两对可逆矩阵并应用到Query-Key和Value-Output分支，这种变换保持模型输出不变但将其推离其他微调模型的共享参数空间。

Result: 在视觉和语言任务上的大量实验表明，MergeLock在大多数情况下可以使涉及受保护模型的合并模型性能下降超过95%。被MergeLock保护的合并模型无法通过低成本恢复方法有效恢复。

Conclusion: MergeLock提供了一种有效的主动保护机制，能够直接防止未经授权的模型合并，具有很好的鲁棒性和实用性。

Abstract: Model merging leverages multiple finetuned expert models to construct a
multi-task model with low cost, and is gaining increasing attention. However,
as a growing number of finetuned models become publicly available, concerns
about the safety of model merging have emerged. Unauthorized merging may
infringe on developers' rights and risk leaking sensitive personal information.
Most existing methods focus on detecting whether a merged model originates from
a specific source model, but fail to effectively prevent illegal merging. In
this paper, we propose MergeLock, an active protection mechanism that disrupts
model parameters to render them unmergeable, thereby directly preventing
unauthorized model merging. Specifically, leveraging the inherent symmetry of
the attention mechanism in Transformer-based models, we randomly sample two
pairs of invertible matrices and apply them to the Query-Key (QK) and
Value-Output (VO) branches. This transformation keeps the model's output
unchanged while pushing it away from the shared parameter space of other
finetuned models. Extensive experiments across both vision and language tasks
demonstrate that MergeLock can degrade the performance of merged models by over
95% when a protected model is involved in most cases, demonstrating its
effectiveness. Moreover, we further demonstrate that merged models protected by
MergeLock cannot be effectively recovered using low-cost restoration methods,
further enhancing robustness against unauthorized merging. The code is
available at https://github.com/hetailang/Merge-Lock.

</details>


### [26] [Succeed or Learn Slowly: Sample Efficient Off-Policy Reinforcement Learning for Mobile App Control](https://arxiv.org/abs/2509.01720)
*Georgios Papoudakis,Thomas Coste,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.LG

TL;DR: SoLS是一种新颖的离线强化学习算法，通过区分正负样本采用不同的策略更新方式，在移动应用控制任务中显著提升了样本效率和性能


<details>
  <summary>Details</summary>
Motivation: 基于基础模型的强化学习在多轮任务中存在稀疏奖励和策略梯度更新的局限性，特别是负样本更新会损害模型性能

Method: 提出SoLS算法：对正样本采用直接策略更新，对负样本采用保守正则化更新；并引入成功转换回放(STR)机制优先学习成功交互

Result: 在AndroidWorld基准测试中显著优于现有方法（相对提升至少17%），计算资源需求大幅减少，推理速度比GPT-4o方法快5-60倍

Conclusion: SoLS通过智能区分正负样本的更新策略，有效解决了基础模型在强化学习中的性能退化问题，实现了高效的移动应用界面导航

Abstract: Reinforcement learning (RL) using foundation models for policy approximations
in multi-turn tasks remains challenging. We identify two main limitations
related to sparse reward settings and policy gradient updates, based on which
we formulate a key insight: updates from positive samples with high returns
typically do not require policy regularisation, whereas updates from negative
samples, reflecting undesirable behaviour, can harm model performance. This
paper introduces Succeed or Learn Slowly (SoLS), a novel off-policy RL
algorithm evaluated on mobile app control tasks. SoLS improves sample
efficiency when fine-tuning foundation models for user interface navigation via
a modified off-policy actor-critic approach, applying direct policy updates for
positive samples and conservative, regularised updates for negative ones to
prevent model degradation. We augment SoLS with Successful Transition Replay
(STR), which prioritises learning from successful interactions, further
improving sample efficiency. We evaluate SoLS on the AndroidWorld benchmark,
where it significantly outperforms existing methods (at least 17% relative
increase), including prompt-engineering and RL approaches, while requiring
substantially fewer computational resources than GPT-4o-based methods with
5-60x faster inference.

</details>


### [27] [A Multi-target Bayesian Transformer Framework for Predicting Cardiovascular Disease Biomarkers during Pandemics](https://arxiv.org/abs/2509.01794)
*Trusting Inekwe,Emmanuel Agu,Winnie Mkandawire,Andres Colubri*

Main category: cs.LG

TL;DR: 提出了MBT-CB模型，一种基于BERT的多目标贝叶斯Transformer，用于从电子健康记录中联合预测CVD生物标志物，在COVID-19疫情期间表现出色。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行对心血管疾病患者的生物标志物产生了显著影响，需要准确建模这些变化来预测疾病进展和指导预防护理。现有方法未能同时处理多目标预测、生物标志物相互依赖关系、时间模式和预测不确定性。

Method: 开发了MBT-CB模型，结合贝叶斯变分推理估计不确定性，使用嵌入捕获时间关系，采用DeepMTR模型捕捉生物标志物相互关系。基于预训练的BERT transformer框架联合预测LDL-C、HbA1c、BMI和SysBP四个CVD生物标志物。

Result: 在3,390份CVD患者记录上评估，MBT-CB优于其他BERT-based基线模型，MAE为0.00887，RMSE为0.0135，MSE为0.00027，有效捕获了数据和模型不确定性、患者生物标志物相互关系和时间动态。

Conclusion: MBT-CB的优越性能表明其在改善CVD生物标志物预测和支持大流行期间临床决策方面具有巨大潜力。

Abstract: The COVID-19 pandemic disrupted healthcare systems worldwide,
disproportionately impacting individuals with chronic conditions such as
cardiovascular disease (CVD). These disruptions -- through delayed care and
behavioral changes, affected key CVD biomarkers, including LDL cholesterol
(LDL-C), HbA1c, BMI, and systolic blood pressure (SysBP). Accurate modeling of
these changes is crucial for predicting disease progression and guiding
preventive care. However, prior work has not addressed multi-target prediction
of CVD biomarker from Electronic Health Records (EHRs) using machine learning
(ML), while jointly capturing biomarker interdependencies, temporal patterns,
and predictive uncertainty. In this paper, we propose MBT-CB, a Multi-target
Bayesian Transformer (MBT) with pre-trained BERT-based transformer framework to
jointly predict LDL-C, HbA1c, BMI and SysBP CVD biomarkers from EHR data. The
model leverages Bayesian Variational Inference to estimate uncertainties,
embeddings to capture temporal relationships and a DeepMTR model to capture
biomarker inter-relationships. We evaluate MBT-CT on retrospective EHR data
from 3,390 CVD patient records (304 unique patients) in Central Massachusetts
during the Covid-19 pandemic. MBT-CB outperformed a comprehensive set of
baselines including other BERT-based ML models, achieving an MAE of 0.00887,
RMSE of 0.0135 and MSE of 0.00027, while effectively capturing data and model
uncertainty, patient biomarker inter-relationships, and temporal dynamics via
its attention and embedding mechanisms. MBT-CB's superior performance
highlights its potential to improve CVD biomarker prediction and support
clinical decision-making during pandemics.

</details>


### [28] [GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping](https://arxiv.org/abs/2509.01842)
*Qifu Wen,Xi Zeng,Zihan Zhou,Shuaijun Liu,Mehdi Hosseinzadeh,Reza Rawassizadeh*

Main category: cs.LG

TL;DR: GradES是一种基于梯度的早期停止方法，通过监控Transformer组件中投影矩阵的梯度幅度，在梯度低于阈值时逐个冻结参数，无需验证推理即可加速训练并提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统早期停止方法需要监控全局验证损失并同时停止所有参数更新，对于大型Transformer来说验证推理计算成本高昂。不同组件在微调过程中收敛速度不同，需要更精细的停止策略。

Method: 在Transformer的注意力投影和Feed-Forward层矩阵中跟踪反向传播梯度幅度。当某个投影矩阵的梯度低于收敛阈值τ时，单独排除该矩阵的更新，允许收敛慢的矩阵继续学习。

Result: GradES将训练时间加速1.57-7.22倍，同时通过早期防止过拟合提高泛化能力，平均准确率提升1.2%。

Conclusion: 基于梯度的组件级早期停止策略能有效减少计算成本，同时改善模型性能，为大型Transformer的高效微调提供了新思路。

Abstract: Early stopping monitors global validation loss and halts all parameter
updates simultaneously, which is computationally costly for large transformers
due to the extended time required for validation inference. We propose GradES,
a novel gradient-based early stopping approach that operates within transformer
components (attention projections and Feed-Forward layer matrices). We found
that different components converge at varying rates during fine-tuning. GradES
tracks the magnitude of gradients in backpropagation for these matrices during
training. When a projection matrix's gradients fall below a convergence
threshold $\tau$, we exclude that projection matrix from further updates
individually, eliminating costly validation passes while allowing slow
converging matrices to continue learning. By strategically freezing parameters
when their gradients converge, GradES speeds up training time by
1.57--7.22$\times$ while simultaneously enhancing generalization through early
prevention of overfitting, resulting in 1.2% higher average accuracy.

</details>


### [29] [LUCIE-3D: A three-dimensional climate emulator for forced responses](https://arxiv.org/abs/2509.02061)
*Haiwen Guan,Troy Arcomano,Ashesh Chattopadhyay,Romit Maulik*

Main category: cs.LG

TL;DR: LUCIE-3D是一个轻量级三维气候模拟器，基于SFNO架构，能够捕捉大气垂直结构，响应气候变化强迫，并保持计算效率和长期稳定性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够模拟大气三维结构、响应气候变化强迫、同时保持计算效率的轻量级气候模拟器，以支持快速实验和耦合气候动力学研究。

Method: 基于原始LUCIE-2D框架，采用球面傅里叶神经算子（SFNO）主干网络，使用30年ERA5再分析数据在8个垂直σ层上进行训练，整合CO2作为强迫变量，并可选择整合海表温度。

Result: 成功再现气候平均值、变异性和长期气候变化信号，包括CO2浓度增加下的地表变暖和平流层冷却；捕捉关键动力学过程如赤道开尔文波、MJO和环形模；在极端事件统计中表现出可信行为；在4个GPU上训练时间少于5小时。

Conclusion: LUCIE-3D结合了稳定性、物理一致性和可访问性，是快速实验、消融研究和耦合气候动力学探索的宝贵工具，在古气候研究和未来地球系统模拟中具有潜在应用价值。

Abstract: We introduce LUCIE-3D, a lightweight three-dimensional climate emulator
designed to capture the vertical structure of the atmosphere, respond to
climate change forcings, and maintain computational efficiency with long-term
stability. Building on the original LUCIE-2D framework, LUCIE-3D employs a
Spherical Fourier Neural Operator (SFNO) backbone and is trained on 30 years of
ERA5 reanalysis data spanning eight vertical {\sigma}-levels. The model
incorporates atmospheric CO2 as a forcing variable and optionally integrates
prescribed sea surface temperature (SST) to simulate coupled ocean--atmosphere
dynamics. Results demonstrate that LUCIE-3D successfully reproduces
climatological means, variability, and long-term climate change signals,
including surface warming and stratospheric cooling under increasing CO2
concentrations. The model further captures key dynamical processes such as
equatorial Kelvin waves, the Madden--Julian Oscillation, and annular modes,
while showing credible behavior in the statistics of extreme events. Despite
requiring longer training than its 2D predecessor, LUCIE-3D remains efficient,
training in under five hours on four GPUs. Its combination of stability,
physical consistency, and accessibility makes it a valuable tool for rapid
experimentation, ablation studies, and the exploration of coupled climate
dynamics, with potential applications extending to paleoclimate research and
future Earth system emulation.

</details>


### [30] [Differentiable Expectation-Maximisation and Applications to Gaussian Mixture Model Optimal Transport](https://arxiv.org/abs/2509.02109)
*Samuel Boïté,Eloi Tanguy,Julie Delon,Agnès Desolneux,Rémi Flamary*

Main category: cs.LG

TL;DR: 本文提出了EM算法的可微分版本，使其能够集成到需要端到端梯度传播的现代学习流程中，并应用于高斯混合模型的Wasserstein距离计算。


<details>
  <summary>Details</summary>
Motivation: EM算法在统计学和机器学习中广泛应用，但通常被视为不可微分的黑盒，无法在现代学习流程中实现端到端梯度传播。

Method: 提出并比较了多种EM算法微分策略，从完全自动微分到近似方法，评估其准确性和计算效率。将可微分EM应用于高斯混合模型的Wasserstein距离计算。

Result: 在重心计算、颜色和风格迁移、图像生成、纹理合成等数值实验中展示了所提方法在不同设置下的多功能性和有效性。

Conclusion: 通过使EM算法可微分，成功将其集成到现代学习流程中，为高斯混合模型的Wasserstein距离计算提供了实用的解决方案，并获得了理论稳定性保证。

Abstract: The Expectation-Maximisation (EM) algorithm is a central tool in statistics
and machine learning, widely used for latent-variable models such as Gaussian
Mixture Models (GMMs). Despite its ubiquity, EM is typically treated as a
non-differentiable black box, preventing its integration into modern learning
pipelines where end-to-end gradient propagation is essential. In this work, we
present and compare several differentiation strategies for EM, from full
automatic differentiation to approximate methods, assessing their accuracy and
computational efficiency. As a key application, we leverage this differentiable
EM in the computation of the Mixture Wasserstein distance $\mathrm{MW}_2$
between GMMs, allowing $\mathrm{MW}_2$ to be used as a differentiable loss in
imaging and machine learning tasks. To complement our practical use of
$\mathrm{MW}_2$, we contribute a novel stability result which provides
theoretical justification for the use of $\mathrm{MW}_2$ with EM, and also
introduce a novel unbalanced variant of $\mathrm{MW}_2$. Numerical experiments
on barycentre computation, colour and style transfer, image generation, and
texture synthesis illustrate the versatility and effectiveness of the proposed
approach in different settings.

</details>


### [31] [Conditional-$t^3$VAE: Equitable Latent Space Allocation for Fair Generation](https://arxiv.org/abs/2509.02154)
*Aymene Mohammed Bouayed,Samuel Deslauriers-Gauthier,Adrian Iaccovelli,David Naccache*

Main category: cs.LG

TL;DR: Conditional-$t^3$VAE通过为每个类别定义Student's t联合先验分布，解决了VAE在类别不平衡数据集上生成公平性的问题，显著提高了极端不平衡情况下的生成质量和公平性。


<details>
  <summary>Details</summary>
Motivation: 传统VAE及其变体$t^3$VAE在类别不平衡数据集上，潜在空间分配与训练集类别频率成正比，导致尾部类别表示不足，生成公平性降低。

Method: 提出Conditional-$t^3$VAE模型，为每个类别定义Student's t联合先验分布，使用γ-散度推导的闭式目标函数进行优化，并推导等权重的潜在混合Student's t分布用于类别平衡生成。

Result: 在SVHN-LT、CIFAR100-LT和CelebA数据集上，Conditional-$t^3$VAE始终获得比$t^3$VAE和高斯基VAE基线更低的FID分数，特别是在严重类别不平衡情况下。在每类F1评估中也优于条件高斯VAE。

Conclusion: 虽然高斯基模型在轻度不平衡情况下仍有竞争力，但Conditional-$t^3$VAE在更极端的不平衡情况下显著提高了生成公平性和多样性。

Abstract: Variational Autoencoders (VAEs) with global priors mirror the training set's
class frequency in latent space, underrepresenting tail classes and reducing
generative fairness on imbalanced datasets. While $t^3$VAE improves robustness
via heavy-tailed Student's t-distribution priors, it still allocates latent
volume proportionally to the class frequency.In this work, we address this
issue by explicitly enforcing equitable latent space allocation across classes.
To this end, we propose Conditional-$t^3$VAE, which defines a per-class
\mbox{Student's t} joint prior over latent and output variables, preventing
dominance by majority classes. Our model is optimized using a closed-form
objective derived from the $\gamma$-power divergence. Moreover, for
class-balanced generation, we derive an equal-weight latent mixture of
Student's t-distributions. On SVHN-LT, CIFAR100-LT, and CelebA,
Conditional-$t^3$VAE consistently achieves lower FID scores than both $t^3$VAE
and Gaussian-based VAE baselines, particularly under severe class imbalance. In
per-class F1 evaluations, Conditional-$t^3$VAE also outperforms the conditional
Gaussian VAE across all highly imbalanced settings. While Gaussian-based models
remain competitive under mild imbalance ratio ($\rho \lesssim 3$), our approach
substantially improves generative fairness and diversity in more extreme
regimes.

</details>


### [32] [Balanced Multimodal Learning: An Unidirectional Dynamic Interaction Perspective](https://arxiv.org/abs/2509.02281)
*Shijie Wang,Li Zhang,Xinyan Liang,Yuhua Qian,Shen Hu*

Main category: cs.LG

TL;DR: 提出UDI方法解决多模态学习中模态不平衡问题，通过单向动态交互替代传统联合损失，实现更好的模态协同和性能提升


<details>
  <summary>Details</summary>
Motivation: 传统多模态联合学习会导致模态不平衡，强势模态压制弱势模态，限制了各模态信息和模态间交互信息的充分利用

Method: UDI采用顺序训练策略：先训练锚定模态至收敛，然后用其学习表示通过无监督损失指导其他模态，动态调整模态交互

Result: 实验结果表明UDI在处理模态不平衡方面优于现有方法，在多模态学习任务中实现了性能改进

Conclusion: UDI通过解耦模态优化和启用定向信息流，有效防止单一模态主导，促进跨模态特征学习，为多模态不平衡学习提供了新思路

Abstract: Multimodal learning typically utilizes multimodal joint loss to integrate
different modalities and enhance model performance. However, this joint
learning strategy can induce modality imbalance, where strong modalities
overwhelm weaker ones and limit exploitation of individual information from
each modality and the inter-modality interaction information.Existing
strategies such as dynamic loss weighting, auxiliary objectives and gradient
modulation mitigate modality imbalance based on joint loss. These methods
remain fundamentally reactive, detecting and correcting imbalance after it
arises, while leaving the competitive nature of the joint loss untouched. This
limitation drives us to explore a new strategy for multimodal imbalance
learning that does not rely on the joint loss, enabling more effective
interactions between modalities and better utilization of information from
individual modalities and their interactions. In this paper, we introduce
Unidirectional Dynamic Interaction (UDI), a novel strategy that abandons the
conventional joint loss in favor of a proactive, sequential training scheme.
UDI first trains the anchor modality to convergence, then uses its learned
representations to guide the other modality via unsupervised loss. Furthermore,
the dynamic adjustment of modality interactions allows the model to adapt to
the task at hand, ensuring that each modality contributes optimally. By
decoupling modality optimization and enabling directed information flow, UDI
prevents domination by any single modality and fosters effective cross-modal
feature learning. Our experimental results demonstrate that UDI outperforms
existing methods in handling modality imbalance, leading to performance
improvement in multimodal learning tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces](https://arxiv.org/abs/2509.00287)
*Brian Wang,Mani Srivastava*

Main category: cs.AI

TL;DR: SIGMUS系统利用大语言模型自动整合城市多模态传感器数据，构建知识图谱来识别和推理城市事件，无需依赖人工规则。


<details>
  <summary>Details</summary>
Motivation: 城市多模态传感器数据丰富但分散，传统方法依赖人工推理来识别事件与数据间的关系，难以有效整合和利用这些数据来理解和预测城市事件。

Method: 开发SIGMUS系统，使用大语言模型生成必要的世界知识，自动识别城市事件与多模态数据间的关系，并将组织化的知识表示为知识图谱。

Result: 系统能够合理连接5种不同数据源（新闻文本、监控图像、空气质量、天气和交通测量）与同时同地发生的相关事件。

Conclusion: SIGMUS通过LLM驱动的自动化方法成功解决了多模态城市数据整合的挑战，为城市事件识别和预测提供了有效解决方案。

Abstract: Modern urban spaces are equipped with an increasingly diverse set of sensors,
all producing an abundance of multimodal data. Such multimodal data can be used
to identify and reason about important incidents occurring in urban landscapes,
such as major emergencies, cultural and social events, as well as natural
disasters. However, such data may be fragmented over several sources and
difficult to integrate due to the reliance on human-driven reasoning for
identifying relationships between the multimodal data corresponding to an
incident, as well as understanding the different components which define an
incident. Such relationships and components are critical to identifying the
causes of such incidents, as well as producing forecasting the scale and
intensity of future incidents as they begin to develop. In this work, we create
SIGMUS, a system for Semantic Integration for Knowledge Graphs in Multimodal
Urban Spaces. SIGMUS uses Large Language Models (LLMs) to produce the necessary
world knowledge for identifying relationships between incidents occurring in
urban spaces and data from different modalities, allowing us to organize
evidence and observations relevant to an incident without relying and
human-encoded rules for relating multimodal sensory data with incidents. This
organized knowledge is represented as a knowledge graph, organizing incidents,
observations, and much more. We find that our system is able to produce
reasonable connections between 5 different data sources (new article text, CCTV
images, air quality, weather, and traffic measurements) and relevant incidents
occurring at the same time and location.

</details>


### [34] [CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs](https://arxiv.org/abs/2509.00971)
*Jay Vaghasiya,Omkar Ghugarkar,Vishvesh Bhat,Vipul Dholaria,Julian McAuley*

Main category: cs.AI

TL;DR: CoreThink是一个基于通用符号推理方法的新型推理层，在工具调用、代码生成和规划任务上实现SOTA性能，无需微调或训练成本即可提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如测试时扩展、监督微调、强化学习）在LLM性能提升上会出现收益递减，需要开发新的推理技术来突破性能瓶颈。

Method: 采用通用符号推理（General Symbolics）方法，构建专门的推理层，专注于工具调用、代码生成和规划三个核心用例。

Result: 在7个基准测试中表现优异：Livecodebench v6达到66.66%、指令跟随评估89%、ARC-AGI-2达到24.4%，基于该技术开发的智能编码IDE在SWE-Bench Lite上达到62.3%的准确率。

Conclusion: CoreThink提供纯性能提升，确保模型推理任务准确性不受负面影响，为推理密集型应用提供了新的解决方案，模型已可供使用。

Abstract: We introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel
reasoning method called General Symbolics. This approach diverges from
reasoning paradigms such as test-time scaling, Supervised Fine-Tuning (SFT),
and Reinforcement Learning with Verifiable Rewards (RLVR). CoreThink General
Symbolic Reasoner (GSR) is specifically structured around three key use cases:
tool-calling, code generation, and planning, demonstrating exemplary
performance across a total of seven benchmarks in their respective areas.
Notably, we are achieving SOTA scores of 66.66\% on Livecodebench v6, 89\% on
Instruction-Following Evals, and 24.4\% on ARC-AGI-2. We also present an
agentic coding IDE, developed using the principles of General Symbolics, which
achieves a state-of-the-art accuracy of 62.3\% on \texttt{SWE-Bench Lite}. We
are able to achieve these improvements without any finetuning or training
costs. Our Reasoning Layer is designed to provide a pure performance uplift,
ensuring that a model's accuracy on reasoning tasks is never negatively
impacted. We argue that incumbent methods will eventually lead to diminishing
returns in LLM performance, necessitating the development of new reasoning
techniques. This technical report details our approach at a high level and the
availability of the CoreThink models for reasoning-intensive use cases.

</details>


### [35] [Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models](https://arxiv.org/abs/2509.01909)
*Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue*

Main category: cs.AI

TL;DR: 提出了Constructive Safety Alignment (CSA)框架，通过游戏论预测、风险边界发现和可解释推理控制，在保持安全性的同时为心理困扰用户提供建设性指导，而非简单拒绝。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制主要针对恶意攻击者，采用防御性拒绝策略，但忽视了非恶意但心理困扰用户的需求。简单拒绝可能导致用户重复尝试、升级行为或转向不安全平台，造成更严重后果。

Method: 引入Constructive Safety Alignment (CSA)范式，结合游戏论用户反应预测、细粒度风险边界发现和可解释推理控制。在Oyster-I (Oy1)模型中实现，将安全转化为信任建立过程。

Result: Oy1在开源模型中达到最先进的安全水平，同时保持高通用能力。在Constructive Benchmark上展示出接近GPT-5的建设性参与度，在Strata-Sword越狱数据集上具有接近GPT-o1水平的鲁棒性。

Conclusion: CSA从拒绝优先转向指导优先的安全模式，重新定义了模型与用户的关系，旨在构建不仅安全而且有意义的帮助性系统。发布了Oy1模型、代码和基准测试以支持负责任、以用户为中心的AI发展。

Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent
harmful content generation. Most current approaches focus narrowly on risks
posed by malicious actors, often framing risks as adversarial events and
relying on defensive refusals. However, in real-world settings, risks also come
from non-malicious users seeking help while under psychological distress (e.g.,
self-harm intentions). In such cases, the model's response can strongly
influence the user's next actions. Simple refusals may lead them to repeat,
escalate, or move to unsafe platforms, creating worse outcomes. We introduce
Constructive Safety Alignment (CSA), a human-centric paradigm that protects
against malicious misuse while actively guiding vulnerable users toward safe
and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic
anticipation of user reactions, fine-grained risk boundary discovery, and
interpretable reasoning control, turning safety into a trust-building process.
Oy1 achieves state-of-the-art safety among open models while retaining high
general capabilities. On our Constructive Benchmark, it shows strong
constructive engagement, close to GPT-5, and unmatched robustness on the
Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from
refusal-first to guidance-first safety, CSA redefines the model-user
relationship, aiming for systems that are not just safe, but meaningfully
helpful. We release Oy1, code, and the benchmark to support responsible,
user-centered AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [36] [Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation](https://arxiv.org/abs/2509.02510)
*Erfan Baghaei Potraghloo,Seyedarmin Azizi,Souvik Kundu,Massoud Pedram*

Main category: cs.CL

TL;DR: 提出了一种名为top-H解码的新采样方法，通过熵约束质量最大化理论解决LLM在开放文本生成中平衡创造性和逻辑性的问题，相比现有方法性能提升显著


<details>
  <summary>Details</summary>
Motivation: 现有截断采样技术（如温度缩放、top-p采样、min-p采样）在平衡文本生成多样性和逻辑连贯性方面存在局限，特别是未能有效利用模型置信度信息

Method: 首先建立熵约束最小散度问题的理论框架，证明其等价于NP难的熵约束质量最大化问题，然后提出计算高效的高贪心算法top-H解码来解决该问题

Result: 在创意写作基准测试中比最先进的min-p采样方法性能提升高达25.63%，在GPQA、GSM8K和MT-Bench等问答数据集上保持鲁棒性，LLM作为评判者的评估确认了在高温度下仍能产生连贯输出

Conclusion: top-H解码在开放文本生成方面推进了最先进技术，可轻松集成到创意写作应用中，有效平衡了创造性和连贯性

Abstract: Large language models (LLMs), despite their impressive performance across a
wide range of tasks, often struggle to balance two competing objectives in
open-ended text generation: fostering diversity and creativity while preserving
logical coherence. Existing truncated sampling techniques, including
temperature scaling, top-\$p\$ (nucleus) sampling, and min-\$p\$ sampling, aim
to manage this trade-off. However, they exhibit limitations, particularly in
the effective incorporation of the confidence of the model into the
corresponding sampling strategy. For example, min-\$p\$ sampling relies on a
single top token as a heuristic for confidence, eventually underutilizing the
information of the probability distribution. Toward effective incorporation of
the confidence of the model, in this paper, we present **top-H** decoding. We
first establish the theoretical foundation of the interplay between creativity
and coherence in truncated sampling by formulating an **entropy-constrained
minimum divergence** problem. We then prove this minimization problem to be
equivalent to an **entropy-constrained mass maximization** (ECMM) problem,
which is NP-hard. Finally, we present top-H decoding, a computationally
efficient greedy algorithm to solve the ECMM problem. Extensive empirical
evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)
alternative of min-\$p\$ sampling by up to **25.63%** on creative writing
benchmarks, while maintaining robustness on question-answering datasets such as
GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms
that top-H indeed produces coherent outputs even at higher temperatures, where
creativity is especially critical. In summary, top-H advances SoTA in
open-ended text generation and can be *easily integrated* into creative writing
applications. The code is available at
https://github.com/ErfanBaghaei/Top-H-Decoding.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [37] [Robotic Fire Risk Detection based on Dynamic Knowledge Graph Reasoning: An LLM-Driven Approach with Graph Chain-of-Thought](https://arxiv.org/abs/2509.00054)
*Haimei Pan,Jiyun Zhang,Qinxi Wei,Xiongnan Jin,Chen Xinkai,Jie Cheng*

Main category: cs.RO

TL;DR: 该论文提出了Insights-on-Graph(IOG)框架，通过结合知识图谱和大规模多模态模型，实现火灾场景的智能感知和应急响应规划，有效提升火灾风险检测和救援决策能力。


<details>
  <summary>Details</summary>
Motivation: 当前火灾预防和救援研究面临感知不完整、态势认知不足和响应延迟等挑战，需要开发更智能的感知和响应系统来保护人类救援人员。

Method: 首先利用大语言模型构建火灾知识图谱，整合防火指南和救援任务信息；然后提出IOG框架，结合知识图谱的结构化信息和多模态模型，从实时场景图像生成感知驱动的风险图。

Result: 大量仿真和真实实验表明，IOG在火灾风险检测和救援决策方面具有良好的适用性和实际应用价值。

Conclusion: IOG框架能够实现早期火灾风险检测，并根据动态风险情况为任务模块和机器人组件配置提供可解释的应急响应，显著提升火灾场景的智能化水平。

Abstract: Fire is a highly destructive disaster, but effective prevention can
significantly reduce its likelihood of occurrence. When it happens, deploying
emergency robots in fire-risk scenarios can help minimize the danger to human
responders. However, current research on pre-disaster warnings and
disaster-time rescue still faces significant challenges due to incomplete
perception, inadequate fire situational awareness, and delayed response. To
enhance intelligent perception and response planning for robots in fire
scenarios, we first construct a knowledge graph (KG) by leveraging large
language models (LLMs) to integrate fire domain knowledge derived from fire
prevention guidelines and fire rescue task information from robotic emergency
response documents. We then propose a new framework called Insights-on-Graph
(IOG), which integrates the structured fire information of KG and Large
Multimodal Models (LMMs). The framework generates perception-driven risk graphs
from real-time scene imagery to enable early fire risk detection and provide
interpretable emergency responses for task module and robot component
configuration based on the evolving risk situation. Extensive simulations and
real-world experiments show that IOG has good applicability and practical
application value in fire risk detection and rescue decision-making.

</details>


### [38] [A Framework for Task and Motion Planning based on Expanding AND/OR Graphs](https://arxiv.org/abs/2509.00317)
*Fulvio Mastrogiovanni,Antony Thomas*

Main category: cs.RO

TL;DR: 提出基于AND/OR图扩展的TMP-EAOG框架，用于空间机器人任务与运动规划，具有抗不确定性、可控自主性和有限灵活性等特点


<details>
  <summary>Details</summary>
Motivation: 空间环境中的机器人自主性面临感知运动不确定性、严格运动学约束和有限人工干预机会等独特挑战，需要任务与运动规划(TMP)来整合离散动作序列和连续运动可行性评估

Method: TMP-EAOG框架在AND/OR图中编码任务级抽象，迭代扩展图结构，执行在线运动规划评估来确定可行性

Result: 在模拟移动机械臂上的评估表明，TMP-EAOG能够处理基准测试中的各种挑战，展现出良好的适应性

Conclusion: TMP-EAOG框架具有抗不确定性、可控自主性和有限灵活性等理想特性，适用于空间自主机器人任务规划

Abstract: Robot autonomy in space environments presents unique challenges, including
high perception and motion uncertainty, strict kinematic constraints, and
limited opportunities for human intervention. Therefore, Task and Motion
Planning (TMP) may be critical for autonomous servicing, surface operations, or
even in-orbit missions, just to name a few, as it models tasks as discrete
action sequencing integrated with continuous motion feasibility assessments. In
this paper, we introduce a TMP framework based on expanding AND/OR graphs,
referred to as TMP-EAOG, and demonstrate its adaptability to different
scenarios. TMP-EAOG encodes task-level abstractions within an AND/OR graph,
which expands iteratively as the plan is executed, and performs in-the-loop
motion planning assessments to ascertain their feasibility. As a consequence,
TMP-EAOG is characterised by the desirable properties of (i) robustness to a
certain degree of uncertainty, because AND/OR graph expansion can accommodate
for unpredictable information about the robot environment, (ii) controlled
autonomy, since an AND/OR graph can be validated by human experts, and (iii)
bounded flexibility, in that unexpected events, including the assessment of
unfeasible motions, can lead to different courses of action as alternative
paths in the AND/OR graph. We evaluate TMP-EAOG on two benchmark domains. We
use a simulated mobile manipulator as a proxy for space-grade autonomous
robots. Our evaluation shows that TMP-EAOG can deal with a wide range of
challenges in the benchmarks.

</details>


### [39] [Safe and Efficient Lane-Changing for Autonomous Vehicles: An Improved Double Quintic Polynomial Approach with Time-to-Collision Evaluation](https://arxiv.org/abs/2509.00582)
*Rui Bai,Rui Xu,Teng Rui,Jiale Liu,Qi Wei Oung,Hoi Leong Lee,Zhen Tian,Fujiang Yuan*

Main category: cs.RO

TL;DR: 改进的双五次多项式轨迹规划方法，通过在优化过程中直接嵌入时间到碰撞(TTC)评估，实现混合交通环境下的安全高效变道。


<details>
  <summary>Details</summary>
Motivation: 解决自主驾驶车辆在混合交通环境下与人驾车辆交互时的安全和舒适性问题，特别是变道操作中的安全问题。

Method: 使用改进的双五次多项式方法，将TTC基于的评估机制直接集成到轨迹优化过程中，包括状态估计、轨迹生成、实时TTC计算和适应性轨迹评估。

Result: 在多种交通场景下进行了涉广法模拟，证明该方法在安全性、效率和舒适性方面都优于传统方法，能够避免碰撞并保证平滑过渡。

Conclusion: 该方法填补了模型基于和适应性轨迹规划方法之间的空白，为实际自主驾驶应用提供了稳定的解决方案。

Abstract: Autonomous driving technology has made significant advancements in recent
years, yet challenges remain in ensuring safe and comfortable interactions with
human-driven vehicles (HDVs), particularly during lane-changing maneuvers. This
paper proposes an improved double quintic polynomial approach for safe and
efficient lane-changing in mixed traffic environments. The proposed method
integrates a time-to-collision (TTC) based evaluation mechanism directly into
the trajectory optimization process, ensuring that the ego vehicle proactively
maintains a safe gap from surrounding HDVs throughout the maneuver. The
framework comprises state estimation for both the autonomous vehicle (AV) and
HDVs, trajectory generation using double quintic polynomials, real-time TTC
computation, and adaptive trajectory evaluation. To the best of our knowledge,
this is the first work to embed an analytic TTC penalty directly into the
closed-form double-quintic polynomial solver, enabling real-time safety-aware
trajectory generation without post-hoc validation. Extensive simulations
conducted under diverse traffic scenarios demonstrate the safety, efficiency,
and comfort of the proposed approach compared to conventional methods such as
quintic polynomials, Bezier curves, and B-splines. The results highlight that
the improved method not only avoids collisions but also ensures smooth
transitions and adaptive decision-making in dynamic environments. This work
bridges the gap between model-based and adaptive trajectory planning
approaches, offering a stable solution for real-world autonomous driving
applications.

</details>


### [40] [Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gröbner Systems](https://arxiv.org/abs/2509.00823)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 提出使用计算机代数解决6自由度机器人逆运动学问题的新方法，扩展了可求解的机器人类型范围


<details>
  <summary>Details</summary>
Motivation: 传统方法要求三个连续旋转关节轴线相交于一点才能分解位置和姿态问题，限制了可求解的机器人类型

Method: 使用综合Gröbner系统（CGS），将机器人关节参数作为系数参数，避免重复计算Gröbner基

Result: 方法扩展了可求解逆运动学问题的6自由度机器人类型，实验证明了有效性

Conclusion: 该方法能够更高效地解决更广泛类型的6自由度机器人逆运动学问题

Abstract: We propose an effective method for solving the inverse kinematic problem of a
specific model of 6-degree-of-freedom (6-DOF) robot manipulator using computer
algebra. It is known that when the rotation axes of three consecutive
rotational joints of a manipulator intersect at a single point, the inverse
kinematics problem can be divided into determining position and orientation. We
extend this method to more general manipulators in which the rotational axes of
two consecutive joints intersect. This extension broadens the class of 6-DOF
manipulators for which the inverse kinematics problem can be solved, and is
expected to enable more efficient solutions. The inverse kinematic problem is
solved using the Comprehensive Gr\"obner System (CGS) with joint parameters of
the robot appearing as parameters in the coefficients to prevent repetitive
calculations of the Gr\"obner bases. The effectiveness of the proposed method
is shown by experiments.

</details>


### [41] [Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment](https://arxiv.org/abs/2509.01836)
*Md Mahbub Alam,Jose F. Rodrigues-Jr,Gabriel Spadon*

Main category: cs.RO

TL;DR: 基于Transformer的多船艇轨迹预测框架，统算动力学特征、空间变换和混合位置嵌入，支持碰撞风险分析


<details>
  <summary>Details</summary>
Motivation: 现有模型主要关注单船艇预测，忽视了船艇互动、航行规则和碰撞风险评估，需要提高海事安全情况意识

Method: 使用Transformer框架，通过并行流编码动力学和物理特征，采用因果卷积处理时间局部性，空间变换进行位置编码，混合位置嵌入捕捉局部运动模式和长程依赖关系

Result: 在大规模实际AIS数据上评估，模型在聚合多船艇指标上显示优越预测能力，超越传统单船艇位移误差

Conclusion: 通过模拟预测轨迹间的交互作用，框架能够量化潜在碰撞风险，为提升海事安全和决策支持提供可操作性见解

Abstract: Accurate vessel trajectory prediction is essential for enhancing situational
awareness and preventing collisions. Still, existing data-driven models are
constrained mainly to single-vessel forecasting, overlooking vessel
interactions, navigation rules, and explicit collision risk assessment. We
present a transformer-based framework for multi-vessel trajectory prediction
with integrated collision risk analysis. For a given target vessel, the
framework identifies nearby vessels. It jointly predicts their future
trajectories through parallel streams encoding kinematic and derived physical
features, causal convolutions for temporal locality, spatial transformations
for positional encoding, and hybrid positional embeddings that capture both
local motion patterns and long-range dependencies. Evaluated on large-scale
real-world AIS data using joint multi-vessel metrics, the model demonstrates
superior forecasting capabilities beyond traditional single-vessel displacement
errors. By simulating interactions among predicted trajectories, the framework
further quantifies potential collision risks, offering actionable insights to
strengthen maritime safety and decision support.

</details>


### [42] [Hybrid Autonomy Framework for a Future Mars Science Helicopter](https://arxiv.org/abs/2509.01980)
*Luca Di Pierno,Robert Hewitt,Stephan Weiss,Roland Brockers*

Main category: cs.RO

TL;DR: 提出了一种用于火星科学直升机的高层控制框架，结合有限状态机和行为树，实现可扩展、鲁棒且计算高效的自主体系统，通过蒙特卡洛模拟和实地测试验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于地球-火星通信延迟显著且任务复杂，需要先进的自主体框架来确保火星科学直升机在无人干预的情况下，能够基于任务目标和实时条件持续调整行为，实现安全高效的操作。

Method: 采用有限状态机（FSM）与行为树（BT）混合的自主体框架，通过状态转换和动态行为调整来实现反应式和上下文感知的响应，支持与F-Prime等系统的集成。

Result: 蒙特卡洛模拟和实地测试验证了该框架的鲁棒性和适应性，能够有效处理离散事件和实时系统反馈，触发状态转换或动态调整行为执行。

Conclusion: 该FSM-BT混合框架为深空探索等关键场景提供了可扩展、鲁棒且计算高效的自主体解决方案，不仅适用于航空机器人，还具有更广泛的应用潜力。

Abstract: Autonomous aerial vehicles, such as NASA's Ingenuity, enable rapid planetary
surface exploration beyond the reach of ground-based robots. Thus, NASA is
studying a Mars Science Helicopter (MSH), an advanced concept capable of
performing long-range science missions and autonomously navigating challenging
Martian terrain. Given significant Earth-Mars communication delays and mission
complexity, an advanced autonomy framework is required to ensure safe and
efficient operation by continuously adapting behavior based on mission
objectives and real-time conditions, without human intervention. This study
presents a deterministic high-level control framework for aerial exploration,
integrating a Finite State Machine (FSM) with Behavior Trees (BTs) to achieve a
scalable, robust, and computationally efficient autonomy solution for critical
scenarios like deep space exploration. In this paper we outline key
capabilities of a possible MSH and detail the FSM-BT hybrid autonomy framework
which orchestrates them to achieve the desired objectives. Monte Carlo
simulations and real field tests validate the framework, demonstrating its
robustness and adaptability to both discrete events and real-time system
feedback. These inputs trigger state transitions or dynamically adjust behavior
execution, enabling reactive and context-aware responses. The framework is
middleware-agnostic, supporting integration with systems like F-Prime and
extending beyond aerial robotics.

</details>


### [43] [Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals](https://arxiv.org/abs/2509.02275)
*Fengyi Wang,Xiangyu Fu,Nitish Thakor,Gordon Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种配备多模态传感器的仿人软体手，采用神经形态编码和脉冲神经网络处理，在物体识别和材料分类方面取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 受人类体感系统整合触觉、本体感觉和温度信号的多模态感知机制启发，旨在为机器人系统实现高效、鲁棒且类人的感知能力。

Method: 开发了配备多种传感器的仿人软体手，采用生物启发的编码方案将多模态感觉数据转换为脉冲序列，利用脉冲神经网络进行高效处理，并引入了新型微分神经元模型来捕捉动态热响应。

Result: 该系统在不同姿态下的物体识别准确率达到97.14%，显著优于以往软体手研究，同时在材料分类方面也表现出色。

Conclusion: 多模态感觉融合和神经形态方法在实现机器人系统高效、鲁棒和类人感知方面具有巨大潜力。

Abstract: The human somatosensory system integrates multimodal sensory feedback,
including tactile, proprioceptive, and thermal signals, to enable comprehensive
perception and effective interaction with the environment. Inspired by the
biological mechanism, we present a sensorized soft anthropomorphic hand
equipped with diverse sensors designed to emulate the sensory modalities of the
human hand. This system incorporates biologically inspired encoding schemes
that convert multimodal sensory data into spike trains, enabling
highly-efficient processing through Spiking Neural Networks (SNNs). By
utilizing these neuromorphic signals, the proposed framework achieves 97.14%
accuracy in object recognition across varying poses, significantly
outperforming previous studies on soft hands. Additionally, we introduce a
novel differentiator neuron model to enhance material classification by
capturing dynamic thermal responses. Our results demonstrate the benefits of
multimodal sensory fusion and highlight the potential of neuromorphic
approaches for achieving efficient, robust, and human-like perception in
robotic systems.

</details>
