<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach](https://arxiv.org/abs/2509.02851)
*Sadra Saremi,Amirhossein Ahmadkhan Kordbacheh*

Main category: cs.CV

TL;DR: 提出基于HG-TNet的混合多尺度深度学习架构，结合胶囊网络、图注意力机制、Transformer模块和残差学习，用于结肠癌病理图像分类，在LC25000数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 结肠癌是全球最恶性的癌症类型之一，早期检测对预防病情恶化至关重要。需要开发更准确的分类模型来提升结肠癌病理图像的诊断性能。

Method: 采用HG-TNet混合架构，结合Transformer和CNN的优势：Transformer分支通过卷积补丁嵌入提取全局上下文信息，CNN分支捕获细粒度局部细节，并集成胶囊网络保持空间顺序关系，结合自监督旋转预测目标。

Result: 模型在准确率和损失函数方面均表现出更好的性能，通过胶囊网络有效保持了空间顺序并理解了各元素如何组合形成整体结构。

Conclusion: 提出的混合多尺度深度学习架构在结肠癌病理图像分类任务中超越了标准架构，为结肠癌早期诊断提供了更强大的工具。

Abstract: Colon cancer also known as Colorectal cancer, is one of the most malignant
types of cancer worldwide. Early-stage detection of colon cancer is highly
crucial to prevent its deterioration. This research presents a hybrid
multi-scale deep learning architecture that synergizes capsule networks, graph
attention mechanisms, transformer modules, and residual learning to advance
colon cancer classification on the Lung and Colon Cancer Histopathological
Image Dataset (LC25000) dataset. The proposed model in this paper utilizes the
HG-TNet model that introduces a hybrid architecture that joins strength points
in transformers and convolutional neural networks to capture multi-scale
features in histopathological images. Mainly, a transformer branch extracts
global contextual bonds by partitioning the image into patches by
convolution-based patch embedding and then processing these patches through a
transformer encoder. Analogously, a dedicated CNN branch captures fine-grained,
local details through successive Incorporation these diverse features, combined
with a self-supervised rotation prediction objective, produce a robust
diagnostic representation that surpasses standard architectures in performance.
Results show better performance not only in accuracy or loss function but also
in these algorithms by utilizing capsule networks to preserve spatial orders
and realize how each element individually combines and forms whole structures.

</details>


### [2] [Backdoor Poisoning Attack Against Face Spoofing Attack Detection Methods](https://arxiv.org/abs/2509.03108)
*Shota Iwamatsu,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 本文提出了一种针对人脸反欺骗检测系统的后门投毒攻击方法，通过在活体人脸图像中嵌入欺骗攻击特征，使特定欺骗攻击能够绕过检测而不引起视觉变化。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统容易受到使用用户照片的欺骗攻击，现有反欺骗检测方法依赖深度学习需要大量训练数据，如果训练数据被恶意注入，可能导致特定欺骗攻击被误分类为活体。

Method: 提出后门投毒攻击方法，将欺骗攻击的人脸图像特征嵌入到活体人脸图像中，不产生可察觉的视觉变化，从而使特定欺骗攻击能够绕过检测。

Result: 在公共数据集上的实验表明，该方法对现有欺骗攻击检测系统构成现实威胁。

Conclusion: 该方法展示了人脸反欺骗检测中后门投毒的潜在威胁，需要加强对此类攻击的防御措施。

Abstract: Face recognition systems are robust against environmental changes and noise,
and thus may be vulnerable to illegal authentication attempts using user face
photos, such as spoofing attacks. To prevent such spoofing attacks, it is
crucial to discriminate whether the input image is a live user image or a
spoofed image prior to the face recognition process. Most existing spoofing
attack detection methods utilize deep learning, which necessitates a
substantial amount of training data. Consequently, if malicious data is
injected into a portion of the training dataset, a specific spoofing attack may
be erroneously classified as live, leading to false positives.In this paper, we
propose a novel backdoor poisoning attack method to demonstrate the latent
threat of backdoor poisoning within face anti-spoofing detection. The proposed
method enables certain spoofing attacks to bypass detection by embedding
features extracted from the spoofing attack's face image into a live face image
without inducing any perceptible visual alterations.Through experiments
conducted on public datasets, we demonstrate that the proposed method
constitutes a realistic threat to existing spoofing attack detection systems.

</details>


### [3] [Time-Scaling State-Space Models for Dense Video Captioning](https://arxiv.org/abs/2509.03426)
*AJ Piergiovanni,Ganesh Satish Mallya,Dahun Kim,Anelia Angelova*

Main category: cs.CV

TL;DR: 时间缩放状态空间模型(SSM)来处理长视频的密集视频描述任务，通过转移状态技术扩展SSM的上下文长度，支持在线流式处理且计算效率提升7倍


<details>
  <summary>Details</summary>
Motivation: 现有密集视频描述方法面临长视频处理的计算复杂度和内存限制，且需要整个视频作为输入无法实现在线处理

Method: 提出带有转移状态的状态空间模型(SSMs)，结合SSM的长序列和递归特性，解决SSM在很长上下文中无法维持状态的限制

Result: 方法适合在线流式生成描述，无需等待整个视频处理完成，在密集视频描述任务中使用计算量减少7倍

Conclusion: 该方法通过扩展SSM的时间缩放能力，有效解决了长视频密集描述的计算挑战，实现了更高效的在线处理能力

Abstract: Dense video captioning is a challenging video understanding task which aims
to simultaneously segment the video into a sequence of meaningful consecutive
events and to generate detailed captions to accurately describe each event.
Existing methods often encounter difficulties when working with the long videos
associated with dense video captioning, due to the computational complexity and
memory limitations. Furthermore, traditional approaches require the entire
video as input, in order to produce an answer, which precludes online
processing of the video. We address these challenges by time-scaling
State-Space Models (SSMs) to even longer sequences than before. Our approach,
State-Space Models with Transfer State, combines both the long-sequence and
recurrent properties of SSMs and addresses the main limitation of SSMs which
are otherwise not able to sustain their state for very long contexts,
effectively scaling SSMs further in time. The proposed model is particularly
suitable for generating captions on-the-fly, in an online or streaming manner,
without having to wait for the full video to be processed, which is more
beneficial in practice. When applied to dense video captioning, our approach
scales well with video lengths and uses 7x fewer FLOPs.

</details>


### [4] [Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data](https://arxiv.org/abs/2509.03501)
*Honglu Zhou,Xiangyu Peng,Shrikant Kendre,Michael S. Ryoo,Silvio Savarese,Caiming Xiong,Juan Carlos Niebles*

Main category: cs.CV

TL;DR: Strefer是一个合成指令数据生成框架，旨在为视频大语言模型提供时空引用和推理能力，无需使用专有模型或昂贵的人工标注。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在细粒度时空推理方面存在不足，特别是在处理基于时间的事件引用和手势线索的空间锚定时表现不佳，这限制了下一代AI伴侣在动态现实环境中的应用。

Method: 使用数据引擎伪标注时间密集的细粒度视频元数据，以结构化方式捕获丰富的空间和时间信息，包括主体、对象、位置（masklets）以及动作描述和时间线。

Result: 实验评估显示，使用Strefer生成数据训练的模型在需要时空消歧的任务上优于基线模型，并展现出增强的时空感知推理能力。

Conclusion: Strefer为感知基础、指令调优的视频大语言模型建立了新的基础，推动了更通用、时空感知的推理能力发展。

Abstract: Next-generation AI companions must go beyond general video understanding to
resolve spatial and temporal references in dynamic, real-world environments.
Existing Video Large Language Models (Video LLMs), while capable of
coarse-level comprehension, struggle with fine-grained, spatiotemporal
reasoning, especially when user queries rely on time-based event references for
temporal anchoring, or gestural cues for spatial anchoring to clarify object
references and positions. To bridge this critical gap, we introduce Strefer, a
synthetic instruction data generation framework designed to equip Video LLMs
with spatiotemporal referring and reasoning capabilities. Strefer produces
diverse instruction-tuning data using a data engine that pseudo-annotates
temporally dense, fine-grained video metadata, capturing rich spatial and
temporal information in a structured manner, including subjects, objects, their
locations as masklets, and their action descriptions and timelines. Our
approach enhances the ability of Video LLMs to interpret spatial and temporal
references, fostering more versatile, space-time-aware reasoning essential for
real-world AI companions. Without using proprietary models, costly human
annotation, or the need to annotate large volumes of new videos, experimental
evaluations show that models trained with data produced by Strefer outperform
baselines on tasks requiring spatial and temporal disambiguation. Additionally,
these models exhibit enhanced space-time-aware reasoning, establishing a new
foundation for perceptually grounded, instruction-tuned Video LLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Event Detection and Classification for Long Range Sensing of Elephants Using Seismic Signal](https://arxiv.org/abs/2509.02920)
*Jaliya L. Wijayaraja,Janaka L. Wijekoon,Malitha Wijesundara*

Main category: cs.LG

TL;DR: 通过地震信号检测大象脚步的分类框架，采用上下文自适应窗口技术和SVM分类器，在自然环境中达到140米检测范围和70-99%的准确率


<details>
  <summary>Details</summary>
Motivation: 解决人象冲突问题，克服依赖人工分类的限制，开发适合资源受限环境的实时大象脚步检测方案

Method: 提出上下文自适应窗口(CCW)事件检测技术，使用支持向量机(SVM)进行分类，并与STA/LTA方法进行对比评估

Result: 检测范围控制环境155.6米，自然环境140米；SVM分类准确率控制环境99%，自然生境中73%，人象冲突区域70%；零点交叉数和DTW对齐成本是最重要特征

Conclusion: 该框架能够在资源受限环境中实现高效大象脚步检测，为人象冲突解决提供了可靠的技术支撑

Abstract: Detecting elephants through seismic signals is an emerging research topic
aimed at developing solutions for Human-Elephant Conflict (HEC). Despite the
promising results, such solutions heavily rely on manual classification of
elephant footfalls, which limits their applicability for real-time
classification in natural settings. To address this limitation and build on our
previous work, this study introduces a classification framework targeting
resource-constrained implementations, prioritizing both accuracy and
computational efficiency. As part of this framework, a novel event detection
technique named Contextually Customized Windowing (CCW), tailored specifically
for detecting elephant footfalls, was introduced, and evaluations were
conducted by comparing it with the Short-Term Average/Long-Term Average
(STA/LTA) method. The yielded results show that the maximum validated detection
range was 155.6 m in controlled conditions and 140 m in natural environments.
Elephant footfall classification using Support Vector Machine (SVM) with a
Radial Basis Function (RBF) kernel demonstrated superior performance across
multiple settings, achieving an accuracy of 99% in controlled environments, 73%
in natural elephant habitats, and 70% in HEC-prone human habitats, the most
challenging scenario. Furthermore, feature impact analysis using explainable AI
identified the number of Zero Crossings and Dynamic Time Warping (DTW)
Alignment Cost as the most influential factors in all experiments, while
Predominant Frequency exhibited significant influence in controlled settings.

</details>


### [6] [A Narrative Review of Clinical Decision Support Systems in Offloading Footwear for Diabetes-Related Foot Ulcers](https://arxiv.org/abs/2509.02923)
*Kunal Kumar,Muhammad Ashad Kabir,Luke Donnan,Sayed Ahmed*

Main category: cs.LG

TL;DR: 本文通过系统回顾45篇关于糖尿病足溃疡减压鞋具处方决策的研究，提出了一个五部分的临床决策支持系统框架，旨在解决当前决策碎片化、个性化有限和评估方法不统一的问题。


<details>
  <summary>Details</summary>
Motivation: 糖尿病足溃疡减压鞋具的处方决策存在特征选择不一致、个性化程度有限、评估方法碎片化等问题，需要建立一个统一的临床决策支持系统框架来改善决策质量。

Method: 对截至2025年8月的45项研究进行叙述性综述，包括12个指南/协议、25个基于知识的系统和8个机器学习应用，通过主题分析知识类型、决策逻辑、评估方法和使能技术。

Result: 发现指南强调足底压力阈值但缺乏可操作的特征级输出；基于知识的系统使用规则和传感器驱动逻辑；机器学习模型计算精度高但可解释性和临床验证有限；评估方法碎片化。

Conclusion: 提出了包含最小可行数据集、混合架构、结构化特征级输出、持续验证评估以及临床工作流整合的五部分CDSS框架，旨在实现可扩展、以患者为中心的糖尿病足溃疡护理决策支持。

Abstract: Offloading footwear helps prevent and treat diabetic foot ulcers (DFUs) by
lowering plantar pressure (PP), yet prescription decisions remain fragmented:
feature selection varies, personalization is limited, and evaluation practices
differ. We performed a narrative review of 45 studies (12 guidelines/protocols,
25 knowledge-based systems, 8 machine-learning applications) published to Aug
2025. We thematically analyzed knowledge type, decision logic, evaluation
methods, and enabling technologies. Guidelines emphasize PP thresholds (<=200
kPa or >=25--30\% reduction) but rarely yield actionable, feature-level
outputs. Knowledge-based systems use rule- and sensor-driven logic, integrating
PP monitoring, adherence tracking, and usability testing. ML work introduces
predictive, optimization, and generative models with high computational
accuracy but limited explainability and clinical validation. Evaluation remains
fragmented: protocols prioritize biomechanical tests; knowledge-based systems
assess usability/adherence; ML studies focus on technical accuracy with weak
linkage to long-term outcomes. From this synthesis we propose a five-part CDSS
framework: (1) a minimum viable dataset; (2) a hybrid architecture combining
rules, optimization, and explainable ML; (3) structured feature-level outputs;
(4) continuous validation and evaluation; and (5) integration with clinical and
telehealth workflows. This framework aims to enable scalable, patient-centered
CDSSs for DFU care; prioritizing interoperable datasets, explainable models,
and outcome-focused evaluation will be key to clinical adoption.

</details>


### [7] [Evaluation of Stress Detection as Time Series Events -- A Novel Window-Based F1-Metric](https://arxiv.org/abs/2509.03240)
*Harald Vilhelm Skat-Rørdam,Sneha Das,Kathrine Sofie Rasmussen,Nicole Nadine Lønfeldt,Line Clemmensen*

Main category: cs.LG

TL;DR: 提出窗口基于F1指标(F1$_w$)，解决时间序列事件检测中因地靠标签为单点事件而导致的评估偏差问题


<details>
  <summary>Details</summary>
Motivation: 现有F1和点调整F1指标在时间序列事件检测中存在限制，特别是当地靠标签为单点事件而实际现象是渐进性时，标准指标容易误导模型性能评估

Method: 设计了窗口基于F1指标(F1$_w$)，给予时间容寍度，在三个生理数据集(ADARP、Wrist Angel、ROAD)中进行实验分析

Result: F1$_w$能够显示传统指标无法发现的有意义模型性能模式，在野外应用场景中显示出统计上显著的改进

Conclusion: 评估指标的选择强烈影响模型性能的解释，F1$_w$为健康养护应用提供了更健壮的时间序列评估方法

Abstract: Accurate evaluation of event detection in time series is essential for
applications such as stress monitoring with wearable devices, where ground
truth is typically annotated as single-point events, even though the underlying
phenomena are gradual and temporally diffused. Standard metrics like F1 and
point-adjusted F1 (F1$_{pa}$) often misrepresent model performance in such
real-world, imbalanced datasets. We introduce a window-based F1 metric (F1$_w$)
that incorporates temporal tolerance, enabling a more robust assessment of
event detection when exact alignment is unrealistic. Empirical analysis in
three physiological datasets, two in-the-wild (ADARP, Wrist Angel) and one
experimental (ROAD), indicates that F1$_w$ reveals meaningful model performance
patterns invisible to conventional metrics, while its window size can be
adapted to domain knowledge to avoid overestimation. We show that the choice of
evaluation metric strongly influences the interpretation of model performance:
using predictions from TimesFM, only our temporally tolerant metrics reveal
statistically significant improvements over random and null baselines in the
two in-the-wild use cases. This work addresses key gaps in time series
evaluation and provides practical guidance for healthcare applications where
requirements for temporal precision vary by context.

</details>


### [8] [HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling](https://arxiv.org/abs/2509.03260)
*Minjung Park,Gyuyeon Na,Soyoun Kim,Sunyoung Moon,HyeonJeong Cha,Sangmi Chai*

Main category: cs.LG

TL;DR: HyPV-LEAD是一个用于加密货币异常交易检测的超早期预警框架，通过窗口-时间建模、峰值-谷值采样和双曲嵌入技术，在比特币交易数据上实现了0.9624的PR-AUC性能。


<details>
  <summary>Details</summary>
Motivation: 加密货币异常交易（如混币服务、欺诈转账和拉盘砸盘）对金融完整性构成日益增长的风险，但现有方法主要是模型中心化和事后检测，缺乏预防价值。

Method: HyPV-LEAD框架包含三个创新：(1)窗口-时间建模确保可操作的提前预警；(2)峰值-谷值采样缓解类别不平衡同时保持时间连续性；(3)双曲嵌入捕捉区块链交易网络的层次和无标度特性。

Result: 在大规模比特币交易数据上的实证评估显示，HyPV-LEAD始终优于最先进的基线方法，实现了0.9624的PR-AUC，在精确率和召回率方面都有显著提升。消融研究证实每个组件都提供互补效益。

Conclusion: 通过将异常检测从被动分类转向主动预警，HyPV-LEAD为实时风险管理、反洗钱合规和动态区块链环境中的金融安全建立了坚实基础。

Abstract: Abnormal cryptocurrency transactions - such as mixing services, fraudulent
transfers, and pump-and-dump operations -- pose escalating risks to financial
integrity but remain notoriously difficult to detect due to class imbalance,
temporal volatility, and complex network dependencies. Existing approaches are
predominantly model-centric and post hoc, flagging anomalies only after they
occur and thus offering limited preventive value. This paper introduces
HyPV-LEAD (Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection), a
data-driven early-warning framework that explicitly incorporates lead time into
anomaly detection. Unlike prior methods, HyPV-LEAD integrates three
innovations: (1) window-horizon modeling to guarantee actionable lead-time
alerts, (2) Peak-Valley (PV) sampling to mitigate class imbalance while
preserving temporal continuity, and (3) hyperbolic embedding to capture the
hierarchical and scale-free properties of blockchain transaction networks.
Empirical evaluation on large-scale Bitcoin transaction data demonstrates that
HyPV-LEAD consistently outperforms state-of-the-art baselines, achieving a
PR-AUC of 0.9624 with significant gains in precision and recall. Ablation
studies further confirm that each component - PV sampling, hyperbolic
embedding, and structural-temporal modeling - provides complementary benefits,
with the full framework delivering the highest performance. By shifting anomaly
detection from reactive classification to proactive early-warning, HyPV-LEAD
establishes a robust foundation for real-time risk management, anti-money
laundering (AML) compliance, and financial security in dynamic blockchain
environments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network](https://arxiv.org/abs/2509.03060)
*Md. Jahidul Islam Razin,Md. Abdul Karim,M. F. Mridha,S M Rafiuddin,Tahira Alam*

Main category: cs.CL

TL;DR: 本文应用长短期记忆网络(LSTM)进行商业情感分析，通过改进RNN模型解决渐消梯度问题，在产品评论数据集上达到91.33%的准确率，性能超过传统RNN模型。


<details>
  <summary>Details</summary>
Motivation: 商业情感分析是自然语言处理的重要领域，传统RNN模型存在渐消梯度问题，需要改进模型提高商业情感分析的准确性和效果。

Method: 采用LSTM网络结构对传统RNN进行改进，使用产品评论数据集，70%数据用于训练，30%用于测试，并与其他传统RNN模型进行性能对比。

Result: 改进的LSTM模型达到了91.33%的准确率，表现超过了所有传统RNN模型，有效解决了渐消梯度问题。

Conclusion: 提出的改进LSTM模型在商业情感分析中表现优异，可帮助企业分析客户评价、优化营销策略，具有良好的应用前景。

Abstract: Business sentiment analysis (BSA) is one of the significant and popular
topics of natural language processing. It is one kind of sentiment analysis
techniques for business purposes. Different categories of sentiment analysis
techniques like lexicon-based techniques and different types of machine
learning algorithms are applied for sentiment analysis on different languages
like English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM)
is applied for business sentiment analysis, where a recurrent neural network is
used. An LSTM model is used in a modified approach to prevent the vanishing
gradient problem rather than applying the conventional recurrent neural network
(RNN). To apply the modified RNN model, product review dataset is used. In this
experiment, 70\% of the data is trained for the LSTM and the rest 30\% of the
data is used for testing. The result of this modified RNN model is compared
with other conventional RNN models, and a comparison is made among the results.
It is noted that the proposed model performs better than the other conventional
RNN models. Here, the proposed model, i.e., the modified RNN model approach has
achieved around 91.33\% of accuracy. By applying this model, any business
company or e-commerce business site can identify the feedback from their
customers about different types of products that customers like or dislike.
Based on the customer reviews, a business company or e-commerce platform can
evaluate its marketing strategy.

</details>


### [10] [From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models](https://arxiv.org/abs/2509.03122)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Xiaoling Wang,Linlin Wang*

Main category: cs.CL

TL;DR: 通过知识编辑注入指纹保护LLM知识产权，提出FSFT方法减少细调时指纹退化，性能提升10%


<details>
  <summary>Details</summary>
Motivation: 传统指令循环注入指纹方法存在模型性能下降、计算资源消耗大、指纹持续性差等问题，需要轻量级替代方案

Method: 首次应用知识编辑技术进行指纹注入，使用类似动态编码的类似文本作为指纹，并提出Fingerprint Subspace-aware Fine-Tuning (FSFT)方法来限制指纹子空间的更新

Result: FSFT方法在最坏情况下也能超过普通细调方法10%，但发现注入指纹的模型因特征相似度高而难以区分指纹和相似文本

Conclusion: 知识编辑是一种轻量级的LLM指纹注入方法，FSFT有效减少细调时指纹退化，但仍需更稳健和细粒度的指纹注入方法

Abstract: The intellectual property (IP) protection of Large Language Models (LLMs) is
increasingly critical. Injecting specialized fingerprints into LLMs through
instruction tuning is a common IP protection technique. However, this may
significantly degrade model performance, requires substantial computational
resources, and exhibits poor persistence under model modifications. We argue
that knowledge editing offers a lightweight alternative that is more suitable
for fingerprint injection. Accordingly, we apply knowledge editing to
fingerprint injection for the first time and demonstrate its strong capability.
Despite using scrambled text as fingerprints to prevent them from being
overwritten during fine-tuning, degradation still occurs under large-scale
fine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning
(FSFT), which reduces fingerprint degradation by constraining the update of the
fingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even
in the worst-case scenario. Additionally, we observe that the
fingerprint-injected models struggle to distinguish between fingerprints and
similar texts due to the high similarity of their features. This finding
underscores the urgent need for more robust and fine-grained fingerprinting
injection methods for LLMs.

</details>


### [11] [Domain Adaptation of LLMs for Process Data](https://arxiv.org/abs/2509.03161)
*Rafael Seidi Oyamada,Jari Peeperkorn,Jochen De Weerdt,Johannes De Smedt*

Main category: cs.CL

TL;DR: 本研究探索了直接使用预训练大语言模型处理过程数据的方法，通过参数高效微调技术在预测性过程监控任务中取得了优于RNN和基于叙事风格方法的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注提示工程或将事件日志转换为叙事数据集来利用LLMs的语义能力，但本研究希望直接利用LLMs生成token序列的能力来处理过程数据，避免自然语言重构。

Method: 采用参数高效微调技术来降低计算开销，专注于预测性过程监控任务，包括单任务和多任务预测设置。

Result: 实验结果显示在预测性能上优于最先进的RNN方法和近期基于叙事风格的解决方案，特别是在多任务设置中表现更佳。微调模型收敛更快且需要更少的超参数优化。

Conclusion: 直接微调预训练LLMs处理过程数据是可行的，参数高效微调技术能有效降低计算成本，在多任务预测场景中表现出色，为过程挖掘领域提供了新的有效方法。

Abstract: In recent years, Large Language Models (LLMs) have emerged as a prominent
area of interest across various research domains, including Process Mining
(PM). Current applications in PM have predominantly centered on prompt
engineering strategies or the transformation of event logs into narrative-style
datasets, thereby exploiting the semantic capabilities of LLMs to address
diverse tasks. In contrast, this study investigates the direct adaptation of
pretrained LLMs to process data without natural language reformulation,
motivated by the fact that these models excel in generating sequences of
tokens, similar to the objective in PM. More specifically, we focus on
parameter-efficient fine-tuning techniques to mitigate the computational
overhead typically associated with such models. Our experimental setup focuses
on Predictive Process Monitoring (PPM), and considers both single- and
multi-task predictions. The results demonstrate a potential improvement in
predictive performance over state-of-the-art recurrent neural network (RNN)
approaches and recent narrative-style-based solutions, particularly in the
multi-task setting. Additionally, our fine-tuned models exhibit faster
convergence and require significantly less hyperparameter optimization.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [12] [Improving the Resilience of Quadrotors in Underground Environments by Combining Learning-based and Safety Controllers](https://arxiv.org/abs/2509.02808)
*Isaac Ronald Ward,Mark Paral,Kristopher Riordan,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 通过正规化流环境前置分布的运行监控器，在地下环境中自主切换学习控制器和安全控制器，以平衡速度与安全性。


<details>
  <summary>Details</summary>
Motivation: 学习基于控制器在大规模地下环境中应用潜力巨大，但经常无法良好地泛化到训练分布外的环境。需要一种方法来确保在未知环境中的安全性。

Method: 训练一个基于正规化流的环境前置分布，用于评估四旋翼飞行器的分布偏离程度。将这个评估作为运行时监控器，当分布偏离超过阈值时切换到安全控制器。

Result: 在基于DARPA地下挑战赛真实点云数据的模拟洞穴环境中，结合控制器既保持了学习控制器的高效性，又确保了安全控制器的避撕能力。

Conclusion: 通过环境前置分布的运行时监控，可以实现学习控制器和安全控制器的动态切换，在地下自主导航任务中同时体现速度与安全性的平衡。

Abstract: Autonomously controlling quadrotors in large-scale subterranean environments
is applicable to many areas such as environmental surveying, mining operations,
and search and rescue. Learning-based controllers represent an appealing
approach to autonomy, but are known to not generalize well to
`out-of-distribution' environments not encountered during training. In this
work, we train a normalizing flow-based prior over the environment, which
provides a measure of how far out-of-distribution the quadrotor is at any given
time. We use this measure as a runtime monitor, allowing us to switch between a
learning-based controller and a safe controller when we are sufficiently
out-of-distribution. Our methods are benchmarked on a point-to-point navigation
task in a simulated 3D cave environment based on real-world point cloud data
from the DARPA Subterranean Challenge Final Event Dataset. Our experimental
results show that our combined controller simultaneously possesses the liveness
of the learning-based controller (completing the task quickly) and the safety
of the safety controller (avoiding collision).

</details>


### [13] [Real-Time Instrument Planning and Perception for Novel Measurements of Dynamic Phenomena](https://arxiv.org/abs/2509.03500)
*Itai Zilberstein,Alberto Candela,Steve Chien*

Main category: cs.RO

TL;DR: 通过自动化检测和轨迹规划流程，实现卫星对火山烟柱等动态现象的高分辨率迟踪观测，使观测效果提升10倍


<details>
  <summary>Details</summary>
Motivation: 利用边缘计算能力实现对稀有、瞬态、粒度细小的动态科学现象的自主检测与观测

Method: 综合使用传统机器学习算法和卷积神经网络进行分类，开发多种轨迹规划算法跟踪烟柱形态特征，并与分类器集成

Result: 模拟实验显示，高分辨率仪器的利用效果粗对基线提升了一个数量级，同时保持了高效的运行时间

Conclusion: 该自动化流程能够有效提升卫星对动态现象的观测能力，为火山监测等领域提供了新的技术手段

Abstract: Advancements in onboard computing mean remote sensing agents can employ
state-of-the-art computer vision and machine learning at the edge. These
capabilities can be leveraged to unlock new rare, transient, and pinpoint
measurements of dynamic science phenomena. In this paper, we present an
automated workflow that synthesizes the detection of these dynamic events in
look-ahead satellite imagery with autonomous trajectory planning for a
follow-up high-resolution sensor to obtain pinpoint measurements. We apply this
workflow to the use case of observing volcanic plumes. We analyze
classification approaches including traditional machine learning algorithms and
convolutional neural networks. We present several trajectory planning
algorithms that track the morphological features of a plume and integrate these
algorithms with the classifiers. We show through simulation an order of
magnitude increase in the utility return of the high-resolution instrument
compared to baselines while maintaining efficient runtimes.

</details>
