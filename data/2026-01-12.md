<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.CL](#cs.CL) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SceneFoundry: Generating Interactive Infinite 3D Worlds](https://arxiv.org/abs/2601.05810)
*ChunTeng Chen,YiChen Hsu,YiWen Liu,WeiFang Sun,TsaiChing Ni,ChunYi Lee,Min Sun,YuanFu Yang*

Main category: cs.CV

TL;DR: SceneFoundry是一个语言引导的扩散框架，用于生成公寓规模的3D世界，包含功能可动家具和语义多样布局，用于机器人训练。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法难以捕捉真实室内环境的功能复杂性，特别是包含对机器人物体操作和导航至关重要的可动部件的物体。自动生成大规模、交互式、物理真实的3D环境对推进机器人学习和具身智能至关重要。

Method: 使用语言引导的扩散框架：LLM模块控制楼层布局生成，基于扩散的后验采样从大规模3D资源库中高效填充可动资产。采用可微分指导函数来调节物体数量、防止关节碰撞、保持足够的机器人可通行空间。

Result: 框架能够生成结构有效、语义连贯、功能交互的环境，适用于多种场景类型和条件，支持可扩展的具身AI研究。

Conclusion: SceneFoundry能够生成包含功能可动家具的大规模3D环境，为机器人训练和具身智能研究提供了可扩展的解决方案。

Abstract: The ability to automatically generate large-scale, interactive, and physically realistic 3D environments is crucial for advancing robotic learning and embodied intelligence. However, existing generative approaches often fail to capture the functional complexity of real-world interiors, particularly those containing articulated objects with movable parts essential for manipulation and navigation. This paper presents SceneFoundry, a language-guided diffusion framework that generates apartment-scale 3D worlds with functionally articulated furniture and semantically diverse layouts for robotic training. From natural language prompts, an LLM module controls floor layout generation, while diffusion-based posterior sampling efficiently populates the scene with articulated assets from large-scale 3D repositories. To ensure physical usability, SceneFoundry employs differentiable guidance functions to regulate object quantity, prevent articulation collisions, and maintain sufficient walkable space for robotic navigation. Extensive experiments demonstrate that our framework generates structurally valid, semantically coherent, and functionally interactive environments across diverse scene types and conditions, enabling scalable embodied AI research.

</details>


### [2] [MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding](https://arxiv.org/abs/2601.05495)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CV

TL;DR: MMViR提出了一种多模态、多粒度结构化表示方法，用于解决长视频理解中的计算复杂性和信息冗余问题，通过关键转折点分割和三级描述实现高效检索和理解。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在处理长视频时面临挑战：直接编码计算成本过高，简单的视频转文本方法会产生冗余或碎片化内容，难以处理长视频中的复杂事件、多样场景和长程依赖关系。

Method: MMViR通过识别关键转折点来分割视频，构建三级描述结构：全局叙事与细粒度视觉细节相结合，支持基于查询的高效检索，并能泛化到多种场景。

Result: 在问答、摘要和检索三个任务上的广泛评估表明，MMViR超越了先前最强方法，在小时级视频理解上实现了19.67%的性能提升，同时将处理延迟降低到原来的45.4%。

Conclusion: MMViR为长视频理解提供了一种有效的多模态、多粒度结构化表示方法，显著提升了理解性能并降低了计算成本，具有良好的泛化能力。

Abstract: Long videos, ranging from minutes to hours, present significant challenges for current Multi-modal Large Language Models (MLLMs) due to their complex events, diverse scenes, and long-range dependencies. Direct encoding of such videos is computationally too expensive, while simple video-to-text conversion often results in redundant or fragmented content. To address these limitations, we introduce MMViR, a novel multi-modal, multi-grained structured representation for long video understanding. MMViR identifies key turning points to segment the video and constructs a three-level description that couples global narratives with fine-grained visual details. This design supports efficient query-based retrieval and generalizes well across various scenarios. Extensive evaluations across three tasks, including QA, summarization, and retrieval, show that MMViR outperforms the prior strongest method, achieving a 19.67% improvement in hour-long video understanding while reducing processing latency to 45.4% of the original.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting](https://arxiv.org/abs/2601.05353)
*Shovito Barua Soumma,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: GlyRAG是一个基于检索增强的上下文感知血糖预测框架，利用LLM从CGM数据中提取临床语义，结合多模态Transformer和检索机制，显著提升血糖预测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前血糖预测模型将CGM数据视为数值序列，忽略了上下文信息，或依赖难以大规模收集的额外传感器。LLM在时间序列预测中展现出潜力，但在糖尿病护理中作为上下文提取器的角色尚未充分探索。

Method: 提出GlyRAG框架：1) 使用LLM作为上下文提取器从CGM轨迹生成临床总结；2) 通过语言模型嵌入总结文本；3) 在多模态Transformer架构中将文本嵌入与基于patch的血糖表示融合，使用交叉翻译损失对齐文本和生理学嵌入；4) 检索模块在学习的嵌入空间中识别相似历史事件，通过交叉注意力整合这些案例类比后进行预测。

Result: 在两个T1D队列上的评估显示：1) GlyRAG持续优于最先进方法，RMSE降低达39%，比基线进一步降低1.7%；2) 临床评估显示85%的预测位于安全区域，预测血糖异常事件的性能提升51%。

Conclusion: LLM驱动的上下文提取和CGM轨迹检索能够在不依赖额外传感器的情况下，显著提高长期血糖预测的准确性和临床可靠性，为未来糖尿病管理的智能决策支持工具提供支持。

Abstract: Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role as agentic context extractors in diabetes care remains largely unexplored. To address these limitations, we propose GlyRAG, a context-aware, retrieval-augmented forecasting framework that derives semantic understanding of blood glucose dynamics directly from CGM traces without requiring additional sensor modalities. GlyRAG employs an LLM as a contextualization agent to generate clinical summaries. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer architecture with a cross translation loss aligining textual and physiological embeddings. A retrieval module then identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues prior to making a forecasting inference. Extensive evaluations on two T1D cohorts show that GlyRAG consistently outperforms state-of-the art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows that GlyRAG places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts. These results indicate that LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, thus supporting future agentic decision-support tools for diabetes management.

</details>


### [4] [Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management](https://arxiv.org/abs/2601.05521)
*Jiayu Fang,Zhiqi Shao,Haoning Xi,Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: MLA-STNet：基于Mamba注意力机制的多城市事故风险预测统一框架，通过双模块设计处理城市数据异质性和时空波动，在纽约和芝加哥数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 城市事故数据具有异质性、报告不一致、聚类稀疏、周期性和噪声等固有特性，加上治理碎片化和报告标准不兼容，阻碍了跨城市事故预防系统的开发。

Method: 提出MLA-STNet统一系统，将事故风险预测构建为多城市多任务学习问题。包含两个互补模块：STG-MA（时空地理Mamba注意力）抑制不稳定时空波动并增强长程时间依赖；STS-MA（时空语义Mamba注意力）通过共享参数设计缓解跨城市异质性，同时保留个体语义表示空间。

Result: 在纽约和芝加哥真实数据集上进行75个实验，涵盖全天和高频事故时段两种预测场景。相比最先进基线，MLA-STNet实现RMSE降低6%、Recall提高8%、MAP提高5%，在50%输入噪声下性能变化小于1%。

Conclusion: MLA-STNet有效统一了异构城市数据集，构建了可扩展、鲁棒且可解释的跨城市事故预防系统，为协调和数据驱动的城市安全管理铺平了道路。

Abstract: The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose the Mamba Local-ttention Spatial-Temporal Network MLA-STNet, a unified system that formulates accident risk prediction as a multi-task learning problem across multiple cities. MLA-STNet integrates two complementary modules: (i)the Spatio-Temporal Geographical Mamba-Attention (STG-MA), which suppresses unstable spatio-temporal fluctuations and strengthens long-range temporal dependencies; and (ii) the Spatio-Temporal Semantic Mamba-Attention (STS-MA), which mitigates cross-city heterogeneity through a shared-parameter design that jointly trains all cities while preserving individual semantic representation spaces. We validate the proposed framework through 75 experiments under two forecasting scenarios, full-day and high-frequency accident periods, using real-world datasets from New York City and Chicago. Compared with the state-of-the-art baselines, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP, while maintaining less than 1% performance variation under 50% input noise. These results demonstrate that MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, paving the way for coordinated and data-driven urban safety management.

</details>


### [5] [Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts](https://arxiv.org/abs/2601.05537)
*Wei Zhou,Hong Huang,Ruize Shi,Bang Liu*

Main category: cs.LG

TL;DR: HOPE框架通过可学习的原型路由和专家正交化解决异构图神经网络中的线性投影瓶颈问题，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有HGNNs的解码/投影阶段仍使用单一的共享线性头，假设它能将丰富的节点嵌入映射到标签。但在异质图中，上下文多样性和长尾分布使得全局头会错过细粒度语义，过拟合中心节点，而对尾部节点服务不足

Method: 提出HOPE框架：1）使用可学习的基于原型的路由机制，通过相似度将实例分配给专家，让专家使用遵循自然的长尾分布；2）添加专家正交化来鼓励多样性并防止专家崩溃

Result: 在四个真实数据集上的实验表明，HOPE在多个SOTA HGNN骨干网络上都能带来一致的性能提升，且开销最小

Conclusion: HOPE作为一个即插即用的预测头替代方案，有效解决了异构图神经网络中的线性投影瓶颈问题，通过原型路由和专家正交化机制更好地处理了异质图中的上下文多样性和长尾分布挑战

Abstract: Heterogeneous Graph Neural Networks(HGNNs) have advanced mainly through better encoders, yet their decoding/projection stage still relies on a single shared linear head, assuming it can map rich node embeddings to labels. We call this the Linear Projection Bottleneck: in heterogeneous graphs, contextual diversity and long-tail shifts make a global head miss fine semantics, overfit hub nodes, and underserve tail nodes. While Mixture-of-Experts(MoE) could help, naively applying it clashes with structural imbalance and risks expert collapse. We propose a Heterogeneous-aware Orthogonal Prototype Experts framework named HOPE, a plug-and-play replacement for the standard prediction head. HOPE uses learnable prototype-based routing to assign instances to experts by similarity, letting expert usage follow the natural long-tail distribution, and adds expert orthogonalization to encourage diversity and prevent collapse. Experiments on four real datasets show consistent gains across SOTA HGNN backbones with minimal overhead.

</details>


### [6] [Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR](https://arxiv.org/abs/2601.05607)
*Zijun Min,Bingshuai Liu,Ante Wang,Long Zhang,Anxiang Zeng,Haibo Zhang,Jinsong Su*

Main category: cs.LG

TL;DR: DHPO提出了一种动态混合策略优化方法，结合了GRPO的token级重要性比率和GSPO的序列级重要性比率，通过加权机制和分支特定裁剪策略，在数学推理任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR算法在粒度上各有优缺点：GRPO使用token级重要性比率保留了细粒度信用分配但方差高不稳定；GSPO使用序列级重要性比率匹配序列级奖励但牺牲了token级信用分配。需要一种方法结合两者的优势。

Method: 提出DHPO（动态混合策略优化），在单一裁剪代理目标中桥接GRPO和GSPO。结合token级和序列级重要性比率，探索了平均混合和熵引导混合两种变体。采用分支特定裁剪策略，在混合前分别约束两种比率在各自的信任区域内。

Result: 在七个具有挑战性的数学推理基准测试中，在Qwen3系列的密集和MoE模型上的实验表明，DHPO一致优于GRPO和GSPO。

Conclusion: DHPO成功结合了token级和序列级重要性比率的优势，通过动态混合机制和稳定化策略，在强化学习验证奖励框架中实现了更好的性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising framework for optimizing large language models in reasoning tasks. However, existing RLVR algorithms focus on different granularities, and each has complementary strengths and limitations. Group Relative Policy Optimization (GRPO) updates the policy with token-level importance ratios, which preserves fine-grained credit assignment but often suffers from high variance and instability. In contrast, Group Sequence Policy Optimization (GSPO) applies single sequence-level importance ratios across all tokens in a response that better matches sequence-level rewards, but sacrifices token-wise credit assignment. In this paper, we propose Dynamic Hybrid Policy Optimization (DHPO) to bridge GRPO and GSPO within a single clipped surrogate objective. DHPO combines token-level and sequence-level importance ratios using weighting mechanisms. We explore two variants of the mixing mechanism, including an averaged mixing and an entropy-guided mixing. To further stabilize training, we employ a branch-specific clipping strategy that constrains token-level and sequence-level ratios within separate trust regions before mixing, preventing outliers in either branch from dominating the update. Across seven challenging mathematical reasoning benchmarks, experiments on both dense and MoE models from the Qwen3 series show that DHPO consistently outperforms GRPO and GSPO. We will release our code upon acceptance of this paper.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [7] [CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems](https://arxiv.org/abs/2601.05520)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: 提出CHisAgent多智能体框架，通过三阶段分解方法自动构建中国古代历史事件分类体系，解决大语言模型在历史文化推理中的局限性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在历史文化推理方面能力有限，特别是在非英语语境如中国历史中。分类结构能有效组织历史知识，但手动构建成本高且难以扩展

Method: CHisAgent多智能体框架将分类构建分解为三个阶段：自下而上的归纳器从原始历史语料推导初始层次结构，自上而下的扩展器利用LLM世界知识引入缺失的中层概念，证据引导的丰富器整合外部结构化历史资源确保忠实性

Result: 基于《二十四史》构建了大规模、领域感知的中国古代事件分类体系，涵盖政治、军事、外交和社会生活。评估显示结构连贯性和覆盖范围得到改善，分类体系支持跨文化对齐

Conclusion: CHisAgent框架能有效自动构建历史分类体系，解决LLM在历史文化推理中的局限性，支持跨文化知识对齐

Abstract: Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \textbf{CHisAgent}, a multi-agent LLM framework for historical taxonomy construction in ancient Chinese contexts. CHisAgent decomposes taxonomy construction into three role-specialized stages: a bottom-up \textit{Inducer} that derives an initial hierarchy from raw historical corpora, a top-down \textit{Expander} that introduces missing intermediate concepts using LLM world knowledge, and an evidence-guided \textit{Enricher} that integrates external structured historical resources to ensure faithfulness. Using the \textit{Twenty-Four Histories}, we construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life in ancient China. Extensive reference-free and reference-based evaluations demonstrate improved structural coherence and coverage, while further analysis shows that the resulting taxonomy supports cross-cultural alignment.

</details>


### [8] [GIFT: Games as Informal Training for Generalizable LLMs](https://arxiv.org/abs/2601.05633)
*Nuoyan Lyu,Bingbing Xu,Weihao Meng,Yige Yuan,Yang Zhang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CL

TL;DR: 提出使用游戏作为LLM非正式学习环境，通过嵌套训练框架解决多任务学习中的性能退化问题，提升模型的泛化能力


<details>
  <summary>Details</summary>
Motivation: LLM在形式化学习任务（如数学、代码生成）上表现出色，但缺乏人类认知中的"实践智慧"和泛化智能（如战略创造力和社交推理）。这种差距源于缺乏非正式学习，而游戏环境可以提供互动反馈和抽象复杂性来培养多样化能力。

Method: 提出将游戏作为LLM非正式学习的主要环境，利用其内在奖励信号和抽象复杂性。为解决多任务学习中的性能退化问题，引入了嵌套训练框架，通过顺序任务组合强制执行明确的"AND"目标，而不是简单的任务混合优化隐含的"OR"目标。

Result: 使用GRPO强化学习在Matrix Games、TicTacToe和Who's the Spy游戏中验证，游戏基础的非正式学习不仅能防止任务干扰，还能显著增强模型在广泛能力导向基准测试中的泛化能力。

Conclusion: 游戏环境为LLM非正式学习提供了有效途径，嵌套训练框架成功解决了多任务学习中的性能退化问题，提升了模型的综合能力和泛化性能。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the "practical wisdom" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit "OR" objective, our framework employs sequential task composition to enforce an explicit "AND" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.

</details>
