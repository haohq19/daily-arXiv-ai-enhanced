<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Big Data, Tiny Targets: An Exploratory Study in Machine Learning-enhanced Detection of Microplastic from Filters](https://arxiv.org/abs/2510.18089)
*Paul-Tiberiu Miclea,Martin Sboron,Hardik Vaghasiya,Hoang Thinh Nguyen,Meet Gadara,Thomas Schmid*

Main category: cs.CV

TL;DR: 本研究探索了结合SEM成像和基于YOLO的机器学习对象检测方法在微塑料检测中的潜力、局限性和未来方向，重点关注具有对称重复背景图案的过滤场景。


<details>
  <summary>Details</summary>
Motivation: 微塑料作为普遍污染物对生态系统和人类健康构成威胁，但其微小尺寸使得检测和分类变得困难。传统方法需要人工分析，无法高效应用于大规模筛选研究，因此需要开发自动化检测技术。

Method: 采用扫描电子显微镜(SEM)成像与基于YOLO的机器学习对象检测相结合的方法，专注于具有对称重复背景图案的过滤场景，并优化预处理流程。

Result: 研究发现不同YOLO模型在微塑料检测任务中的性能存在差异，预处理优化对检测质量有重要影响。同时识别出专家标注数据量有限是训练可靠机器学习模型的主要挑战。

Conclusion: 机器学习特别是YOLO模型在微塑料检测中具有应用潜力，但需要解决数据标注不足和预处理优化等挑战，未来需要更多专家标注数据来提升模型可靠性。

Abstract: Microplastics (MPs) are ubiquitous pollutants with demonstrated potential to
impact ecosystems and human health. Their microscopic size complicates
detection, classification, and removal, especially in biological and
environmental samples. While techniques like optical microscopy, Scanning
Electron Microscopy (SEM), and Atomic Force Microscopy (AFM) provide a sound
basis for detection, applying these approaches requires usually manual analysis
and prevents efficient use in large screening studies. To this end, machine
learning (ML) has emerged as a powerful tool in advancing microplastic
detection. In this exploratory study, we investigate potential, limitations and
future directions of advancing the detection and quantification of MP particles
and fibres using a combination of SEM imaging and machine learning-based object
detection. For simplicity, we focus on a filtration scenario where image
backgrounds exhibit a symmetric and repetitive pattern. Our findings indicate
differences in the quality of YOLO models for the given task and the relevance
of optimizing preprocessing. At the same time, we identify open challenges,
such as limited amounts of expert-labeled data necessary for reliable training
of ML models.

</details>


### [2] [StreamingTOM: Streaming Token Compression for Efficient Video Understanding](https://arxiv.org/abs/2510.18269)
*Xueyi Chen,Keda Tao,Kele Shao,Huan Wang*

Main category: cs.CV

TL;DR: StreamingTOM是一个无需训练、即插即用的两阶段框架，通过因果时间缩减和在线量化内存技术，解决流式视频视觉语言模型中的因果性和累积性问题，显著降低计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 流式视频视觉语言模型面临两个基本约束：因果性（无法访问未来帧）和累积性（token无限增长导致效率瓶颈）。现有方法只调控LLM后的kv-cache，而忽略了成本高昂的LLM前预填充阶段。

Method: 提出两阶段框架：1）因果时间缩减：基于相邻帧变化和token显著性选择token，每帧只处理紧凑的视觉token子集；2）在线量化内存：以4位格式存储token，按需检索相关组并反量化，保持活跃kv-cache有界。

Result: 实验显示：实现15.7倍kv-cache压缩，峰值内存降低1.2倍，TTFT速度提升2倍。在离线基准测试中平均准确率63.8%，在RVS上达到55.8%/3.7，在无需训练方法中保持最先进准确率。

Conclusion: StreamingTOM的两阶段方法为高效流式视频理解提供了实用优势，实现了有界增长的计算效率。

Abstract: Unlike offline processing, streaming video vision-language models face two
fundamental constraints: causality and accumulation. Causality prevents access
to future frames that offline methods exploit, while accumulation causes tokens
to grow unbounded, creating efficiency bottlenecks. However, existing
approaches only regulate post-LLM kv-cache, leaving costly pre-LLM prefill
unchanged. We introduce StreamingTOM, a training-free, plug-and-play two-stage
framework that addresses both pre-LLM and post-LLM bottlenecks with predictable
latency. Causal Temporal Reduction imposes a fixed per-frame budget and selects
tokens based on adjacent-frame changes and token saliency, drastically reducing
per-frame prefill cost by processing only a compact subset of visual tokens per
frame instead of all visual tokens. Online Quantized Memory stores tokens in
4-bit format, retrieves relevant groups on demand, and dequantizes them,
keeping the active kv-cache bounded regardless of stream length. Experiments
demonstrate our method achieves $15.7\times$ kv-cache compression, $1.2\times$
lower peak memory and $2\times$ faster TTFT compared to prior SOTA.
StreamingTOM maintains state-of-the-art accuracy among training-free methods
with an average of $63.8\%$ on offline benchmarks and $55.8\%/3.7$ on RVS.
These results highlight the practical benefits of our two-stage approach for
efficient streaming video understanding with bounded growth.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Fine-tuning Flow Matching Generative Models with Intermediate Feedback](https://arxiv.org/abs/2510.18072)
*Jiajun Fan,Chaoran Cheng,Shuaike Shen,Xiangxin Zhou,Ge Liu*

Main category: cs.LG

TL;DR: AC-Flow是一个稳健的actor-critic框架，通过奖励塑造、双稳定性机制和可扩展的评论家加权方案，解决了流匹配模型在中间反馈微调中的信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流匹配的文本到图像生成模型在利用中间反馈进行微调时面临挑战，主要存在信用分配问题和训练不稳定性。

Method: 提出了三个关键创新：奖励塑造提供标准化学习信号；双稳定性机制结合优势裁剪和预热阶段；可扩展的广义评论家加权方案结合Wasserstein正则化。

Result: 在Stable Diffusion 3上的实验表明，AC-Flow在文本-图像对齐任务中达到最先进性能，并能泛化到未见的人类偏好模型。

Conclusion: 即使使用计算高效的评论家模型，也能稳健地微调流模型，而不损害生成质量、多样性或稳定性。

Abstract: Flow-based generative models have shown remarkable success in text-to-image
generation, yet fine-tuning them with intermediate feedback remains
challenging, especially for continuous-time flow matching models. Most existing
approaches solely learn from outcome rewards, struggling with the credit
assignment problem. Alternative methods that attempt to learn a critic via
direct regression on cumulative rewards often face training instabilities and
model collapse in online settings. We present AC-Flow, a robust actor-critic
framework that addresses these challenges through three key innovations: (1)
reward shaping that provides well-normalized learning signals to enable stable
intermediate value learning and gradient control, (2) a novel dual-stability
mechanism that combines advantage clipping to prevent destructive policy
updates with a warm-up phase that allows the critic to mature before
influencing the actor, and (3) a scalable generalized critic weighting scheme
that extends traditional reward-weighted methods while preserving model
diversity through Wasserstein regularization. Through extensive experiments on
Stable Diffusion 3, we demonstrate that AC-Flow achieves state-of-the-art
performance in text-to-image alignment tasks and generalization to unseen human
preference models. Our results demonstrate that even with a computationally
efficient critic model, we can robustly finetune flow models without
compromising generative quality, diversity, or stability.

</details>


### [4] [Provably Optimal Reinforcement Learning under Safety Filtering](https://arxiv.org/abs/2510.18082)
*Donggeon David Oh,Duy P. Nguyen,Haimin Hu,Jaime F. Fisac*

Main category: cs.LG

TL;DR: 本文证明了在强化学习中使用足够宽松的安全过滤器不会降低渐近性能，实现了安全性和性能的完全分离。


<details>
  <summary>Details</summary>
Motivation: 强化学习在复杂任务中应用广泛，但缺乏形式化安全保证限制了其在安全关键场景中的使用。安全过滤器虽然能防止失败，但通常被认为会牺牲性能和阻碍学习过程。

Method: 提出了安全关键马尔可夫决策过程（SC-MDP）和过滤MDP的框架，证明在过滤MDP中学习是安全的，标准RL收敛性仍然成立，且最优策略在过滤MDP中能达到与SC-MDP中最佳安全策略相同的渐近回报。

Result: 在Safety Gymnasium上的实验验证了理论，训练过程中零违规，最终性能匹配或超过了无过滤基线。

Conclusion: 为安全强化学习提供了一个简单而原则性的方法：使用可用的最宽松安全过滤器来训练和部署RL策略。

Abstract: Recent advances in reinforcement learning (RL) enable its use on increasingly
complex tasks, but the lack of formal safety guarantees still limits its
application in safety-critical settings. A common practical approach is to
augment the RL policy with a safety filter that overrides unsafe actions to
prevent failures during both training and deployment. However, safety filtering
is often perceived as sacrificing performance and hindering the learning
process. We show that this perceived safety-performance tradeoff is not
inherent and prove, for the first time, that enforcing safety with a
sufficiently permissive safety filter does not degrade asymptotic performance.
We formalize RL safety with a safety-critical Markov decision process (SC-MDP),
which requires categorical, rather than high-probability, avoidance of
catastrophic failure states. Additionally, we define an associated filtered MDP
in which all actions result in safe effects, thanks to a safety filter that is
considered to be a part of the environment. Our main theorem establishes that
(i) learning in the filtered MDP is safe categorically, (ii) standard RL
convergence carries over to the filtered MDP, and (iii) any policy that is
optimal in the filtered MDP-when executed through the same filter-achieves the
same asymptotic return as the best safe policy in the SC-MDP, yielding a
complete separation between safety enforcement and performance optimization. We
validate the theory on Safety Gymnasium with representative tasks and
constraints, observing zero violations during training and final performance
matching or exceeding unfiltered baselines. Together, these results shed light
on a long-standing question in safety-filtered learning and provide a simple,
principled recipe for safe RL: train and deploy RL policies with the most
permissive safety filter that is available.

</details>


### [5] [MEG-GPT: A transformer-based foundation model for magnetoencephalography data](https://arxiv.org/abs/2510.18080)
*Rukuang Huang,Sungjun Cho,Chetan Gohil,Oiwi Parker Jones,Mark Woolrich*

Main category: cs.LG

TL;DR: MEG-GPT：基于Transformer的脑磁图基础模型，通过时间注意力和下一时间点预测来建模大规模脑动力学，在解码任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉脑磁图等模态中复杂的时空模式，而深度学习基础模型在其他领域已取得显著进展，因此需要开发专门用于脑电生理数据的基础模型。

Method: 提出MEG-GPT，使用时间注意力和下一时间点预测的Transformer架构，并开发了新的数据驱动分词器来保持连续MEG信号的高时间分辨率。

Result: 模型能生成具有真实时空频谱特性的数据，在解码任务中表现优异，跨会话准确率从0.54提升至0.59，跨被试准确率从0.41提升至0.49，且能通过微调进一步提升性能。

Conclusion: 这项工作为电生理数据建立了强大的基础模型，为计算神经科学和神经解码应用铺平了道路。

Abstract: Modelling the complex spatiotemporal patterns of large-scale brain dynamics
is crucial for neuroscience, but traditional methods fail to capture the rich
structure in modalities such as magnetoencephalography (MEG). Recent advances
in deep learning have enabled significant progress in other domains, such as
language and vision, by using foundation models at scale. Here, we introduce
MEG-GPT, a transformer based foundation model that uses time-attention and next
time-point prediction. To facilitate this, we also introduce a novel
data-driven tokeniser for continuous MEG data, which preserves the high
temporal resolution of continuous MEG signals without lossy transformations. We
trained MEG-GPT on tokenised brain region time-courses extracted from a
large-scale MEG dataset (N=612, eyes-closed rest, Cam-CAN data), and show that
the learnt model can generate data with realistic spatio-spectral properties,
including transient events and population variability. Critically, it performs
well in downstream decoding tasks, improving downstream supervised prediction
task, showing improved zero-shot generalisation across sessions (improving
accuracy from 0.54 to 0.59) and subjects (improving accuracy from 0.41 to 0.49)
compared to a baseline methods. Furthermore, we show the model can be
efficiently fine-tuned on a smaller labelled dataset to boost performance in
cross-subject decoding scenarios. This work establishes a powerful foundation
model for electrophysiological data, paving the way for applications in
computational neuroscience and neural decoding.

</details>


### [6] [ACTG-ARL: Differentially Private Conditional Text Generation with RL-Boosted Control](https://arxiv.org/abs/2510.18232)
*Yuzheng Hu,Ryan McKenna,Da Yu,Shanshan Wu,Han Zhao,Zheng Xu,Peter Kairouz*

Main category: cs.LG

TL;DR: 提出了ACTG-ARL框架，通过分层方法和强化学习改进差分隐私下的文本生成质量与控制能力


<details>
  <summary>Details</summary>
Motivation: 解决现有差分隐私文本生成方法在保持统计属性、减少噪声影响和精细控制生成方面的不足

Method: 分层框架分解为特征学习和条件文本生成两个子任务，使用DP表格合成器和DP微调条件生成器，并引入锚定RL方法提升控制能力

Result: 在强隐私保证下，DP合成文本质量提升20%（MAUVE指标），条件生成器的控制能力显著增强

Conclusion: ACTG-ARL框架在差分隐私文本生成的质量和控制方面都取得了显著进步

Abstract: Generating high-quality synthetic text under differential privacy (DP) is
critical for training and evaluating language models without compromising user
privacy. Prior work on synthesizing DP datasets often fail to preserve key
statistical attributes, suffer utility loss from the noise required by DP, and
lack fine-grained control over generation. To address these challenges, we make
two contributions. First, we introduce a hierarchical framework that decomposes
DP synthetic text generation into two subtasks: feature learning and
conditional text generation. This design explicitly incorporates learned
features into the generation process and simplifies the end-to-end synthesis
task. Through systematic ablations, we identify the most effective
configuration: a rich tabular schema as feature, a DP tabular synthesizer, and
a DP fine-tuned conditional generator, which we term ACTG
(Attribute-Conditioned Text Generation). Second, we propose Anchored RL (ARL),
a post-training method that improves the instruction-following ability of ACTG
for conditional generation. ARL combines RL to boost control with an SFT anchor
on best-of-$N$ data to prevent reward hacking. Together, these components form
our end-to-end algorithm ACTG-ARL, which advances both the quality of DP
synthetic text (+20% MAUVE over prior work) and the control of the conditional
generator under strong privacy guarantees.

</details>


### [7] [Learning with Dual-level Noisy Correspondence for Multi-modal Entity Alignment](https://arxiv.org/abs/2510.18240)
*Haobin Li,Yijie Lin,Peng Hu,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 提出RULE框架解决多模态实体对齐中的双重噪声对应问题，包括实体-属性和图间对应关系的噪声，通过可靠性估计和对应推理模块提升对齐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设实体内部和图间对应关系完美无缺，但现实中的多模态知识图谱依赖专家标注，存在双重噪声对应问题，影响对齐效果。

Method: RULE框架通过两阶段原则估计对应关系的可靠性，在属性融合时减轻实体内部噪声影响，在消除图间差异时避免对噪声对应过度拟合，并加入对应推理模块发现图间属性连接。

Result: 在五个基准数据集上的实验表明，RULE相比七种最先进方法能有效应对双重噪声对应问题。

Conclusion: RULE框架通过可靠性估计和对应推理有效解决了多模态实体对齐中的双重噪声对应问题，显著提升了实体对齐的准确性。

Abstract: Multi-modal entity alignment (MMEA) aims to identify equivalent entities
across heterogeneous multi-modal knowledge graphs (MMKGs), where each entity is
described by attributes from various modalities. Existing methods typically
assume that both intra-entity and inter-graph correspondences are faultless,
which is often violated in real-world MMKGs due to the reliance on expert
annotations. In this paper, we reveal and study a highly practical yet
under-explored problem in MMEA, termed Dual-level Noisy Correspondence (DNC).
DNC refers to misalignments in both intra-entity (entity-attribute) and
inter-graph (entity-entity and attribute-attribute) correspondences. To address
the DNC problem, we propose a robust MMEA framework termed RULE. RULE first
estimates the reliability of both intra-entity and inter-graph correspondences
via a dedicated two-fold principle. Leveraging the estimated reliabilities,
RULE mitigates the negative impact of intra-entity noise during attribute
fusion and prevents overfitting to noisy inter-graph correspondences during
inter-graph discrepancy elimination. Beyond the training-time designs, RULE
further incorporates a correspondence reasoning module that uncovers the
underlying attribute-attribute connection across graphs, guaranteeing more
accurate equivalent entity identification. Extensive experiments on five
benchmarks verify the effectiveness of our method against the DNC compared with
seven state-of-the-art methods.The code is available at
\href{https://github.com/XLearning-SCU/RULE}{XLearning-SCU/RULE}

</details>


### [8] [Prototyping an End-to-End Multi-Modal Tiny-CNN for Cardiovascular Sensor Patches](https://arxiv.org/abs/2510.18668)
*Mustafa Fuad Rifet Ibrahim,Tunc Alkanat,Maurice Meijer,Felix Manthey,Alexander Schlaefer,Peer Stelldinger*

Main category: cs.LG

TL;DR: 该研究提出了一种用于心电信号和心音信号分类的轻量级卷积神经网络，在资源受限的医疗边缘设备上实现了三个数量级的内存和计算成本降低，同时保持竞争性准确率。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病早期检测至关重要，可穿戴传感器设备能持续监测但需要高效准确的数据分析。深度学习可自动化数据解释，减轻临床医生负担，但需要在资源受限的边缘设备上实现。

Method: 提出采用早期数据融合的卷积神经网络，用于同步心电图和心音图的二元分类问题，在Physionet Challenge 2016数据集上进行训练和验证。

Result: 相比现有技术，方法减少了三个数量级的内存占用和计算成本，同时在微控制器和实验传感器设备上验证了能耗优势，证明设备端推理比连续数据流更节能。

Conclusion: 该方法证明了在医疗边缘设备上应用深度学习进行心电和心音信号分类的可行性，为可穿戴健康监测提供了高效节能的解决方案。

Abstract: The vast majority of cardiovascular diseases may be preventable if early
signs and risk factors are detected. Cardiovascular monitoring with body-worn
sensor devices like sensor patches allows for the detection of such signs while
preserving the freedom and comfort of patients. However, the analysis of the
sensor data must be robust, reliable, efficient, and highly accurate. Deep
learning methods can automate data interpretation, reducing the workload of
clinicians. In this work, we analyze the feasibility of applying deep learning
models to the classification of synchronized electrocardiogram (ECG) and
phonocardiogram (PCG) recordings on resource-constrained medical edge devices.
We propose a convolutional neural network with early fusion of data to solve a
binary classification problem. We train and validate our model on the
synchronized ECG and PCG recordings from the Physionet Challenge 2016 dataset.
Our approach reduces memory footprint and compute cost by three orders of
magnitude compared to the state-of-the-art while maintaining competitive
accuracy. We demonstrate the applicability of our proposed model on medical
edge devices by analyzing energy consumption on a microcontroller and an
experimental sensor device setup, confirming that on-device inference can be
more energy-efficient than continuous data streaming.

</details>


### [9] [A Unified Perspective on Optimization in Machine Learning and Neuroscience: From Gradient Descent to Neural Adaptation](https://arxiv.org/abs/2510.18812)
*Jesús García Fernández,Nasir Ahmad,Marcel van Gerven*

Main category: cs.LG

TL;DR: 该综述提供了一个关于迭代优化的统一视角，连接经典理论与神经网络训练和生物学习，特别关注零阶优化方法在AI和生物学习中的重要性。


<details>
  <summary>Details</summary>
Motivation: 梯度方法虽然主导机器学习，但计算需求高且在生物学上不可信，而零阶优化方法计算更轻量且与生物学习机制更相似，为理解大脑学习提供了数学原理视角。

Method: 将优化方法按导数信息使用程度分类，从一阶、二阶到高阶梯度方法，再到零阶方法，并探索这些方法如何适应神经网络训练挑战和学习动态。

Result: 现代零阶方法能有效逼近梯度，在神经网络模型中达到与反向传播竞争的性能，其随机探索和反馈引导适应机制与生物学习核心机制平行。

Conclusion: 零阶优化范式将大脑固有噪声作为计算资源，不仅照亮了对自然智能的理解，还对神经形态硬件设计具有深远影响，有助于设计利用硬件噪声的快速节能AI系统。

Abstract: Iterative optimization is central to modern artificial intelligence (AI) and
provides a crucial framework for understanding adaptive systems. This review
provides a unified perspective on this subject, bridging classic theory with
neural network training and biological learning. Although gradient-based
methods, powered by the efficient but biologically implausible backpropagation
(BP), dominate machine learning, their computational demands can hinder
scalability in high-dimensional settings. In contrast, derivative-free or
zeroth-order (ZO) optimization feature computationally lighter approaches that
rely only on function evaluations and randomness. While generally less sample
efficient, recent breakthroughs demonstrate that modern ZO methods can
effectively approximate gradients and achieve performance competitive with BP
in neural network models. This ZO paradigm is also particularly relevant for
biology. Its core principles of random exploration (probing) and
feedback-guided adaptation (reinforcing) parallel key mechanisms of biological
learning, offering a mathematically principled perspective on how the brain
learns. In this review, we begin by categorizing optimization approaches based
on the order of derivative information they utilize, ranging from first-,
second-, and higher-order gradient-based to ZO methods. We then explore how
these methods are adapted to the unique challenges of neural network training
and the resulting learning dynamics. Finally, we build upon these insights to
view biological learning through an optimization lens, arguing that a ZO
paradigm leverages the brain's intrinsic noise as a computational resource.
This framework not only illuminates our understanding of natural intelligence
but also holds vast implications for neuromorphic hardware, helping us design
fast and energy-efficient AI systems that exploit intrinsic hardware noise.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Subject-Event Ontology Without Global Time: Foundations and Execution Semantics](https://arxiv.org/abs/2510.18040)
*Alexander Boldachev*

Main category: cs.AI

TL;DR: 提出了一种基于主体-事件的本体论形式化方法，用于建模复杂动态系统，无需依赖全局时间。核心原则包括事件作为固定行为、因果顺序、可执行本体、模型作为认知过滤器、以及真值假设。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂动态系统中全局时间依赖的问题，提供一种基于事件和因果关系的建模方法，适用于分布式系统、微服务架构等场景。

Method: 通过九个公理（A1-A9）确保可执行本体的正确性，包括历史单调性、因果无环性和可追溯性。采用基于模型的方法进行事件验证、参与者授权和因果链自动构建。

Result: 在boldsea系统中实现了理论构建，这是一个用于可执行本体的工作流引擎，使用BSL语言实现。该方法适用于分布式系统、微服务架构和多方视角场景。

Conclusion: 该形式化方法为复杂动态系统提供了一种不依赖全局时间的建模框架，通过事件和因果关系实现确定性计算，具有广泛的应用前景。

Abstract: A formalization of a subject-event ontology is proposed for modeling complex
dynamic systems without reliance on global time. Key principles: (1) event as
an act of fixation - a subject discerns and fixes changes according to models
(conceptual templates) available to them; (2) causal order via happens-before -
the order of events is defined by explicit dependencies, not timestamps; (3)
making the ontology executable via a declarative dataflow mechanism, ensuring
determinism; (4) models as epistemic filters - a subject can only fix what
falls under its known concepts and properties; (5) presumption of truth - the
declarative content of an event is available for computation from the moment of
fixation, without external verification. The formalization includes nine axioms
(A1-A9), ensuring the correctness of executable ontologies: monotonicity of
history (I1), acyclicity of causality (I2), traceability (I3). Special
attention is given to the model-based approach (A9): event validation via
schemas, actor authorization, automatic construction of causal chains (W3)
without global time. Practical applicability is demonstrated on the boldsea
system - a workflow engine for executable ontologies, where the theoretical
constructs are implemented in BSL (Boldsea Semantic Language). The
formalization is applicable to distributed systems, microservice architectures,
DLT platforms, and multiperspectivity scenarios (conflicting facts from
different subjects).

</details>


### [11] [LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer Behavior](https://arxiv.org/abs/2510.18155)
*Man-Lin Chu,Lucian Terhorst,Kadin Reed,Tom Ni,Weiwei Chen,Rongyu Lin*

Main category: cs.AI

TL;DR: 提出基于LLM的多智能体模拟框架，用于模拟消费者决策和社会动态，替代传统的基于规则的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的事后分析和基于规则的智能体模型难以捕捉人类行为和社会互动的复杂性，需要更有效的营销策略预测试工具。

Method: 利用大型语言模型在沙盒环境中构建多智能体模拟框架，让生成智能体能够互动、表达内部推理、形成习惯并进行购买决策，无需预定义规则。

Result: 在价格折扣营销场景中，系统提供了可操作的策略测试结果，并揭示了传统方法无法捕捉的新兴社会模式。

Conclusion: 该方法为营销人员提供了一个可扩展、低风险的预实施测试工具，减少了对耗时的事后评估的依赖，并降低了营销活动表现不佳的风险。

Abstract: Simulating consumer decision-making is vital for designing and evaluating
marketing strategies before costly real-world deployment. However, post-event
analyses and rule-based agent-based models (ABMs) struggle to capture the
complexity of human behavior and social interaction. We introduce an
LLM-powered multi-agent simulation framework that models consumer decisions and
social dynamics. Building on recent advances in large language model simulation
in a sandbox environment, our framework enables generative agents to interact,
express internal reasoning, form habits, and make purchasing decisions without
predefined rules. In a price-discount marketing scenario, the system delivers
actionable strategy-testing outcomes and reveals emergent social patterns
beyond the reach of conventional methods. This approach offers marketers a
scalable, low-risk tool for pre-implementation testing, reducing reliance on
time-intensive post-event evaluations and lowering the risk of underperforming
campaigns.

</details>


### [12] [ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.18342)
*Peng Tang,Xiaoxiao Yan,Xiaobin Hu,Yuning Cui,Donghao Luo,Jiangning Zhang,Pengcheng Xu,Jinlong Peng,Qingdong He,Feiyue Huang,Song Xue,Tobias Lasser*

Main category: cs.AI

TL;DR: 提出ShortcutBreaker框架解决多类无监督异常检测中的身份捷径问题，通过低秩噪声瓶颈和全局扰动注意力机制防止特征直接复制，在多个数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 多类无监督异常检测需要统一模型检测多类异常，但现有Transformer架构存在身份捷径问题——直接复制输入到输出，导致正常与异常样本的重建误差差异缩小，难以区分。

Method: 1. 基于矩阵秩不等式设计低秩噪声瓶颈(LRNB)，将高维特征投影到低秩潜在空间，理论上防止平凡身份复制；2. 利用ViT的全局建模能力，引入全局扰动注意力防止解码器中的信息捷径。

Result: 在四个基准数据集上测试：MVTec-AD(99.8%)、ViSA(98.9%)、Real-IAD(90.6%)和Universal Medical(87.8%)的图像级AUROC，均优于先前方法。

Conclusion: ShortcutBreaker通过解决身份捷径问题，在多类无监督异常检测任务中实现了卓越性能，为统一模型开发提供了有效解决方案。

Abstract: Multi-class unsupervised anomaly detection (MUAD) has garnered growing
research interest, as it seeks to develop a unified model for anomaly detection
across multiple classes, i.e., eliminating the need to train separate models
for distinct objects and thereby saving substantial computational resources.
Under the MUAD setting, while advanced Transformer-based architectures have
brought significant performance improvements, identity shortcuts persist: they
directly copy inputs to outputs, narrowing the gap in reconstruction errors
between normal and abnormal cases, and thereby making the two harder to
distinguish. Therefore, we propose ShortcutBreaker, a novel unified
feature-reconstruction framework for MUAD tasks, featuring two key innovations
to address the issue of shortcuts. First, drawing on matrix rank inequality, we
design a low-rank noisy bottleneck (LRNB) to project highdimensional features
into a low-rank latent space, and theoretically demonstrate its capacity to
prevent trivial identity reproduction. Second, leveraging ViTs global modeling
capability instead of merely focusing on local features, we incorporate a
global perturbation attention to prevent information shortcuts in the decoders.
Extensive experiments are performed on four widely used anomaly detection
benchmarks, including three industrial datasets (MVTec-AD, ViSA, and Real-IAD)
and one medical dataset (Universal Medical). The proposed method achieves a
remarkable image-level AUROC of 99.8%, 98.9%, 90.6%, and 87.8% on these four
datasets, respectively, consistently outperforming previous MUAD methods across
different scenarios.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [CMT-Bench: Cricket Multi-Table Generation Benchmark for Probing Robustness in Large Language Models](https://arxiv.org/abs/2510.18173)
*Ritam Upadhyay,Naman Ahuja,Rishabh Baral,Aparna Garimella,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出了CMT-Bench基准测试，用于评估LLM在动态文本转表格任务中的鲁棒性，发现现有模型在提取线索缺失、长上下文和实体形式变化时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有文本转表格系统依赖提示工程或迭代事件提取，计算成本高且难以理解模型如何对时序演变叙事进行推理。需要开发能测试模型鲁棒性的诊断基准。

Method: 基于板球评论构建CMT-Bench基准，包含三个语义保持维度：提取线索消融、时间前缀化和实体形式扰动，测试模型在不同条件下的表现。

Result: 各种先进LLM在没有提取摘要时性能大幅下降，输入长度增加时单调退化，实体形式变化下准确率一致下降。分布测试显示数值错误模式显著变化。

Conclusion: 当前LLM在动态文本转表格生成中表现脆弱，需要优先考虑鲁棒性评估，以开发高效可扩展的方法。

Abstract: LLM Driven text-to-table (T2T) systems often rely on extensive
prompt-engineering or iterative event extraction in code-parsable formats,
which boosts scores but are computationally expensive and obscure how models
actually reason over temporal evolving narratives to summarise key information.
We present CMT-Bench, a diagnostic benchmark built from live cricket commentary
that requires dynamic table generation across two evolving schemas under a
dense, rule-governed policy. CMT-Bench is designed to probe robustness via
three semantics-preserving dimensions: (i) extractive-cue ablation to separate
extractive shortcuts from state tracking, (ii) temporal prefixing to test
long-context stability, and (iii) entity-form perturbations (anonymization,
outof-distribution substitutions, role-entangling paraphrases) to assess
sensitivity to surface variation. Across diverse long-context stateof-the-art
LLMs, we find large drops without extractive summaries, monotonic degradation
with input length, and consistent accuracy drop under entity-form changes.
Complementary distributional tests confirm significant shifts in numeric error
patterns, indicating drift in reasoning rather than mere noise. Our results
show that current LLMs are brittle in dynamic Textto-table generation,
motivating robustness-first evaluation as a prerequisite for developing
efficient and scalable approaches for this task.

</details>


### [14] [Contrastive Decoding Mitigates Score Range Bias in LLM-as-a-Judge](https://arxiv.org/abs/2510.18196)
*Yoshinari Fujinuma*

Main category: cs.CL

TL;DR: 该论文研究发现LLM作为评估器时存在评分范围偏差问题，并提出使用对比解码方法来缓解这种偏差，显著提高了与人类判断的相关性。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估器在各种应用中被广泛使用，但其评估结果的可靠性仍面临挑战。特别是在无参考的直接评估中，LLM评判结果对预定义评分范围高度敏感，存在评分范围偏差问题。

Method: 首先识别LLM评判输出存在评分范围偏差问题，然后通过对比解码方法来缓解这种偏差。

Result: 使用对比解码方法后，在不同评分范围内与人类判断的Spearman相关性平均相对提高了11.3%。

Conclusion: LLM作为评估器时确实存在评分范围偏差问题，但通过对比解码方法可以有效缓解这种偏差，提高评估结果的可靠性。

Abstract: Large Language Models (LLMs) are commonly used as evaluators in various
applications, but the reliability of the outcomes remains a challenge. One such
challenge is using LLMs-as-judges for direct assessment, i.e., assigning scores
from a specified range without any references. We first show that this
challenge stems from LLM judge outputs being associated with score range bias,
i.e., LLM judge outputs are highly sensitive to pre-defined score ranges,
preventing the search for optimal score ranges. We also show that similar
biases exist among models from the same family. We then mitigate this bias
through contrastive decoding, achieving up to 11.3% relative improvement on
average in Spearman correlation with human judgments across different score
ranges.

</details>


### [15] [MARCUS: An Event-Centric NLP Pipeline that generates Character Arcs from Narratives](https://arxiv.org/abs/2510.18201)
*Sriharsh Bhyravajjula,Ujwal Narayan,Manish Shrivastava*

Main category: cs.CL

TL;DR: 提出了MARCUS系统，用于从叙事文本中计算生成以事件为中心、基于关系的角色弧线，并在《哈利波特》和《指环王》系列中进行验证。


<details>
  <summary>Details</summary>
Motivation: 角色弧线是文学研究中的重要理论工具，但缺乏计算表示方法。本研究旨在为这一理论概念提供量化表示，为后续应用铺平道路。

Method: 开发了MARCUS NLP流水线，提取事件、参与角色、隐含情感和情绪，建模角色间关系，并在叙事过程中跟踪聚合这些关系，以图形化方式生成角色弧线。

Result: 成功从《哈利波特》和《指环王》两个长篇奇幻系列中生成了角色弧线，并对方法进行了评估。

Conclusion: 展示了计算生成角色弧线的可行性，指出了现有挑战，并讨论了该流水线的应用前景和未来工作方向。

Abstract: Character arcs are important theoretical devices employed in literary studies
to understand character journeys, identify tropes across literary genres, and
establish similarities between narratives. This work addresses the novel task
of computationally generating event-centric, relation-based character arcs from
narratives. Providing a quantitative representation for arcs brings tangibility
to a theoretical concept and paves the way for subsequent applications. We
present MARCUS (Modelling Arcs for Understanding Stories), an NLP pipeline that
extracts events, participant characters, implied emotion, and sentiment to
model inter-character relations. MARCUS tracks and aggregates these relations
across the narrative to generate character arcs as graphical plots. We generate
character arcs from two extended fantasy series, Harry Potter and Lord of the
Rings. We evaluate our approach before outlining existing challenges,
suggesting applications of our pipeline, and discussing future work.

</details>


### [16] [DART: A Structured Dataset of Regulatory Drug Documents in Italian for Clinical NLP](https://arxiv.org/abs/2510.18475)
*Mariano Barone,Antonio Laudante,Giuseppe Riccio,Antonio Romano,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 提出了DART，首个基于意大利药品管理局官方文件的意大利语药品特性摘要结构化语料库，用于填补非英语药理学知识提取的资源空白。


<details>
  <summary>Details</summary>
Motivation: 当前药理学知识提取研究主要依赖英语语料库如DrugBank，缺乏针对其他医疗系统的资源，特别是意大利语资源。

Method: 通过可复现的流程构建数据集，包括网络规模文档检索、监管章节语义分割，以及使用低温度解码的少样本调优大语言模型进行临床摘要。

Result: DART提供了关键药理学领域（如适应症、不良反应、药物相互作用）的结构化信息，基于该数据集的LLM药物相互作用检查器能够准确推断潜在相互作用及其临床意义。

Conclusion: 指令调优的LLMs在基于DART结构化文本字段时能够准确推断潜在相互作用及其临床影响，填补了意大利语药理学知识提取的资源空白。

Abstract: The extraction of pharmacological knowledge from regulatory documents has
become a key focus in biomedical natural language processing, with applications
ranging from adverse event monitoring to AI-assisted clinical decision support.
However, research in this field has predominantly relied on English-language
corpora such as DrugBank, leaving a significant gap in resources tailored to
other healthcare systems. To address this limitation, we introduce DART (Drug
Annotation from Regulatory Texts), the first structured corpus of Italian
Summaries of Product Characteristics derived from the official repository of
the Italian Medicines Agency (AIFA). The dataset was built through a
reproducible pipeline encompassing web-scale document retrieval, semantic
segmentation of regulatory sections, and clinical summarization using a
few-shot-tuned large language model with low-temperature decoding. DART
provides structured information on key pharmacological domains such as
indications, adverse drug reactions, and drug-drug interactions. To validate
its utility, we implemented an LLM-based drug interaction checker that
leverages the dataset to infer clinically meaningful interactions. Experimental
results show that instruction-tuned LLMs can accurately infer potential
interactions and their clinical implications when grounded in the structured
textual fields of DART. We publicly release our code on GitHub:
https://github.com/PRAISELab-PicusLab/DART.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [17] [EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval](https://arxiv.org/abs/2510.18546)
*Zebin Yang,Sunjian Zheng,Tong Xie,Tianshi Xu,Bo Yu,Fan Wang,Jie Tang,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: 提出了EfficientNav方法，通过语义感知内存检索和离散内存缓存技术，使小型LLM能够在本地设备上高效执行零样本目标导航任务，显著提升成功率和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的目标导航方法依赖云端巨型LLM，无法在本地设备部署。小型LLM由于模型容量有限，在理解复杂导航地图时成功率显著下降，且长提示导致高规划延迟。

Method: 1. 语义感知内存检索：修剪导航地图中的冗余信息，帮助小型LLM更好理解环境
2. 离散内存缓存和基于注意力的内存聚类：高效保存和重用KV缓存，减少规划延迟

Result: 在HM3D基准测试中，相比基于GPT-4的基线方法，成功率达到11.1%的提升；相比GPT-4规划器，实时延迟降低6.7倍，端到端延迟降低4.7倍。

Conclusion: EfficientNav方法成功解决了小型LLM在本地设备上执行目标导航任务时的性能瓶颈，实现了高效、低延迟的零样本导航。

Abstract: Object-goal navigation (ObjNav) tasks an agent with navigating to the
location of a specific object in an unseen environment. Embodied agents
equipped with large language models (LLMs) and online constructed navigation
maps can perform ObjNav in a zero-shot manner. However, existing agents heavily
rely on giant LLMs on the cloud, e.g., GPT-4, while directly switching to small
LLMs, e.g., LLaMA3.2-11b, suffer from significant success rate drops due to
limited model capacity for understanding complex navigation maps, which
prevents deploying ObjNav on local devices. At the same time, the long prompt
introduced by the navigation map description will cause high planning latency
on local devices. In this paper, we propose EfficientNav to enable on-device
efficient LLM-based zero-shot ObjNav. To help the smaller LLMs better
understand the environment, we propose semantics-aware memory retrieval to
prune redundant information in navigation maps. To reduce planning latency, we
propose discrete memory caching and attention-based memory clustering to
efficiently save and re-use the KV cache. Extensive experimental results
demonstrate that EfficientNav achieves 11.1% improvement in success rate on
HM3D benchmark over GPT-4-based baselines, and demonstrates 6.7x real-time
latency reduction and 4.7x end-to-end latency reduction over GPT-4 planner. Our
code will be released soon.

</details>


### [18] [Least Restrictive Hyperplane Control Barrier Functions](https://arxiv.org/abs/2510.18643)
*Mattias Trende,Petter Ögren*

Main category: cs.RO

TL;DR: 提出了一种最小限制超平面控制屏障函数方法，通过同时优化CBF和安全控制，在保证安全性的前提下尽可能接近期望控制，解决了传统CBF方法在处理复杂不安全区域时的保守性问题。


<details>
  <summary>Details</summary>
Motivation: 传统控制屏障函数方法在处理复杂形状不安全区域时，通常需要保守地近似不安全区域为超平面形式，这会导致控制约束过于严格，限制了系统的性能表现。

Method: 提出同时优化CBF和安全控制的框架，而不是先选择CBF再选择安全控制。通过创建CBF族的平滑参数化，优化得到最小限制的超平面CBF。

Result: 在具有加速度约束的双积分器动态系统上验证了该方法，能够有效处理任意形状的静态和动态障碍物，在保证安全性的同时减少控制约束的限制。

Conclusion: 该方法提供了一种在保证安全性的同时最小化控制约束限制的有效途径，特别适用于处理复杂不安全区域的高阶CBF设计问题。

Abstract: Control Barrier Functions (CBFs) can provide provable safety guarantees for
dynamic systems. However, finding a valid CBF for a system of interest is often
non-trivial, especially if the shape of the unsafe region is complex and the
CBFs are of higher order. A common solution to this problem is to make a
conservative approximation of the unsafe region in the form of a
line/hyperplane, and use the corresponding conservative Hyperplane-CBF when
deciding on safe control actions. In this letter, we note that conservative
constraints are only a problem if they prevent us from doing what we want.
Thus, instead of first choosing a CBF and then choosing a safe control with
respect to the CBF, we optimize over a combination of CBFs and safe controls to
get as close as possible to our desired control, while still having the safety
guarantee provided by the CBF. We call the corresponding CBF the least
restrictive Hyperplane-CBF. Finally, we also provide a way of creating a smooth
parameterization of the CBF-family for the optimization, and illustrate the
approach on a double integrator dynamical system with acceleration constraints,
moving through a group of arbitrarily shaped static and moving obstacles.

</details>


### [19] [Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations](https://arxiv.org/abs/2510.18697)
*Phuoc Nguyen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 提出了事件基础图（EGG）框架，将事件交互与场景空间特征连接起来，使机器人能够感知、推理和响应复杂的时空查询。


<details>
  <summary>Details</summary>
Motivation: 当前语义场景表示方法缺乏空间特征与动态事件之间的连接，限制了机器人对环境的深度理解。

Method: 开发事件基础图（EGG）框架，将事件交互基础化到场景的空间特征上。

Result: 使用真实机器人数据的实验表明，EGG能够检索相关信息并准确响应关于环境和事件的查询。

Conclusion: EGG框架有效连接了空间特征和动态事件，提升了机器人的场景理解和响应能力，相关代码和数据集已开源。

Abstract: A fundamental aspect for building intelligent autonomous robots that can
assist humans in their daily lives is the construction of rich environmental
representations. While advances in semantic scene representations have enriched
robotic scene understanding, current approaches lack a connection between
spatial features and dynamic events; e.g., connecting the blue mug to the event
washing a mug. In this work, we introduce the event-grounding graph (EGG), a
framework grounding event interactions to spatial features of a scene. This
representation allows robots to perceive, reason, and respond to complex
spatio-temporal queries. Experiments using real robotic data demonstrate EGG's
capability to retrieve relevant information and respond accurately to human
inquiries concerning the environment and events within. Furthermore, the EGG
framework's source code and evaluation dataset are released as open-source at:
https://github.com/aalto-intelligent-robotics/EGG.

</details>
