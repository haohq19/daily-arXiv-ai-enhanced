<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva](https://arxiv.org/abs/2512.20042)
*Nguyen Lam Phu Quy,Pham Phu Hoa,Tran Chi Nguyen,Dao Sy Duy Minh,Nguyen Hoang Minh Ngoc,Huynh Trung Kiet*

Main category: cs.CV

TL;DR: 提出多模态管道，通过检索相似图像和外部文本知识来增强图像描述，生成包含事件背景、时间线索等上下文信息的丰富描述


<details>
  <summary>Details</summary>
Motivation: 现实世界图像描述通常缺乏上下文深度，省略了事件背景、时间线索、结果和命名实体等关键细节，限制了在新闻、教育等领域的应用效果

Method: 使用BEIT-3和SigLIP检索语义相似图像，ORB和SIFT进行几何对齐重排序，从相关文章中提取上下文信息，通过微调的Qwen3模型整合上下文与Instruct BLIP生成的基础描述

Result: 在OpenEvents v1数据集上评估，相比传统方法生成了显著更丰富的信息描述，显示出在需要深度视觉-文本理解的实际应用中的强大潜力

Conclusion: 提出的多模态管道通过结合视觉输入和外部文本知识，能够生成事件丰富、上下文感知的图像描述，有效解决了传统图像描述缺乏上下文深度的问题

Abstract: Real-world image captions often lack contextual depth, omitting crucial details such as event background, temporal cues, outcomes, and named entities that are not visually discernible. This gap limits the effectiveness of image understanding in domains like journalism, education, and digital archives, where richer, more informative descriptions are essential. To address this, we propose a multimodal pipeline that augments visual input with external textual knowledge. Our system retrieves semantically similar images using BEIT-3 (Flickr30k-384 and COCO-384) and SigLIP So-384, reranks them using ORB and SIFT for geometric alignment, and extracts contextual information from related articles via semantic search. A fine-tuned Qwen3 model with QLoRA then integrates this context with base captions generated by Instruct BLIP (Vicuna-7B) to produce event-enriched, context-aware descriptions. Evaluated on the OpenEvents v1 dataset, our approach generates significantly more informative captions compared to traditional methods, showing strong potential for real-world applications requiring deeper visual-textual understanding

</details>


### [2] [LADLE-MM: Limited Annotation based Detector with Learned Ensembles for Multimodal Misinformation](https://arxiv.org/abs/2512.20257)
*Daniele Cardullo,Simone Teglia,Irene Amerini*

Main category: cs.CV

TL;DR: LADLE-MM是一种轻量级多模态虚假信息检测器，在有限标注数据和计算资源下，通过模型集成和BLIP多模态嵌入，在DGM4和VERITE数据集上达到或超越SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 随着多媒体生成工具普及，跨模态的合成内容操纵成为广泛威胁，用于扭曲重要事件叙事和传播虚假信息。现有检测方法通常需要大量计算资源或标注数据，难以在实际场景中应用。

Method: 提出LADLE-MM：基于有限标注的学习集成多模态虚假信息检测器。采用模型集成初始化，包含两个单模态分支和一个多模态分支，利用BLIP提取的多模态嵌入作为固定参考空间来增强图像和文本表示。

Result: 在DGM4基准测试中，使用比先前SOTA模型少60.3%的可训练参数，在二元和多标签分类任务上达到竞争性性能；在VERITE数据集上超越使用更复杂大型视觉语言模型的现有方法，显示出优秀的泛化能力和对单模态偏差的鲁棒性。

Conclusion: LADLE-MM证明了在有限标注设置下，通过轻量级架构和有效的多模态表示增强，可以实现高性能的虚假信息检测，为实际部署提供了可行的解决方案。

Abstract: With the rise of easily accessible tools for generating and manipulating multimedia content, realistic synthetic alterations to digital media have become a widespread threat, often involving manipulations across multiple modalities simultaneously. Recently, such techniques have been increasingly employed to distort narratives of important events and to spread misinformation on social media, prompting the development of misinformation detectors. In the context of misinformation conveyed through image-text pairs, several detection methods have been proposed. However, these approaches typically rely on computationally intensive architectures or require large amounts of annotated data. In this work we introduce LADLE-MM: Limited Annotation based Detector with Learned Ensembles for Multimodal Misinformation, a model-soup initialized multimodal misinformation detector designed to operate under a limited annotation setup and constrained training resources. LADLE-MM is composed of two unimodal branches and a third multimodal one that enhances image and text representations with additional multimodal embeddings extracted from BLIP, serving as fixed reference space. Despite using 60.3% fewer trainable parameters than previous state-of-the-art models, LADLE-MM achieves competitive performance on both binary and multi-label classification tasks on the DGM4 benchmark, outperforming existing methods when trained without grounding annotations. Moreover, when evaluated on the VERITE dataset, LADLE-MM outperforms current state-of-the-art approaches that utilize more complex architectures involving Large Vision-Language-Models, demonstrating the effective generalization ability in an open-set setting and strong robustness to unimodal bias.

</details>


### [3] [High Dimensional Data Decomposition for Anomaly Detection of Textured Images](https://arxiv.org/abs/2512.20432)
*Ji Song,Xing Wang,Jianguo Wu,Xiaowei Yue*

Main category: cs.CV

TL;DR: 提出TBSD方法用于纹理图像异常检测，通过纹理基函数学习准周期纹理模式，减少误识别，降低训练数据需求，在仿真和真实数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法在处理纹理缺陷图像时存在误识别、鲁棒性低、过度依赖大规模结构化数据集等局限性，需要针对纹理图像背景平滑、异常稀疏的特点开发更有效的方法。

Method: 提出纹理基集成平滑分解(TBSD)方法，包含两个主要过程：1) 学习纹理基函数以有效提取准周期纹理模式；2) 利用纹理基作为先验知识进行异常检测，防止纹理误识别并高精度捕捉潜在异常。

Result: 该方法在基准测试中表现优异，具有更少的误识别、更小的训练数据集需求，在仿真和真实数据集上都展现出优越的异常检测性能。

Conclusion: TBSD方法为纹理图像异常检测提供了一种高效解决方案，通过数学建模准周期性并利用纹理基函数，有效克服了传统方法的局限性，在工业制造系统中具有重要应用价值。

Abstract: In the realm of diverse high-dimensional data, images play a significant role across various processes of manufacturing systems where efficient image anomaly detection has emerged as a core technology of utmost importance. However, when applied to textured defect images, conventional anomaly detection methods have limitations including non-negligible misidentification, low robustness, and excessive reliance on large-scale and structured datasets. This paper proposes a texture basis integrated smooth decomposition (TBSD) approach, which is targeted at efficient anomaly detection in textured images with smooth backgrounds and sparse anomalies. Mathematical formulation of quasi-periodicity and its theoretical properties are investigated for image texture estimation. TBSD method consists of two principal processes: the first process learns the texture basis functions to effectively extract quasi-periodic texture patterns; the subsequent anomaly detection process utilizes that texture basis as prior knowledge to prevent texture misidentification and capture potential anomalies with high accuracy.The proposed method surpasses benchmarks with less misidentification, smaller training dataset requirement, and superior anomaly detection performance on both simulation and real-world datasets.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach](https://arxiv.org/abs/2512.19737)
*Clément Elliker,Jesse Read,Sonia Vanier,Albert Bifet*

Main category: cs.LG

TL;DR: 提出DCIL算法，通过距离漂移校正的模仿学习进行列车延误预测，在比利时铁路数据集上表现优于传统方法


<details>
  <summary>Details</summary>
Motivation: 列车延误的可靠预测对提升铁路运输系统的鲁棒性和效率至关重要，需要同时考虑序列性和不确定性特征

Method: 将延误预测重构为随机模拟任务，提出DCIL算法，在DAgger基础上加入距离漂移校正，无需外部预言机或对抗方案

Result: 在包含300多万列车运行的比利时铁路数据集上，DCIL在30分钟预测范围内优于传统回归模型和行为克隆方法

Conclusion: DCIL成功结合事件驱动模型的动态保真度和数据驱动方法的表示能力，能够有效捕捉大规模网络中延误传播的序列性和不确定性

Abstract: Reliable prediction of train delays is essential for enhancing the robustness and efficiency of railway transportation systems. In this work, we reframe delay forecasting as a stochastic simulation task, modeling state-transition dynamics through imitation learning. We introduce Drift-Corrected Imitation Learning (DCIL), a novel self-supervised algorithm that extends DAgger by incorporating distance-based drift correction, thereby mitigating covariate shift during rollouts without requiring access to an external oracle or adversarial schemes. Our approach synthesizes the dynamical fidelity of event-driven models with the representational capacity of data-driven methods, enabling uncertainty-aware forecasting via Monte Carlo simulation. We evaluate DCIL using a comprehensive real-world dataset from \textsc{Infrabel}, the Belgian railway infrastructure manager, which encompasses over three million train movements. Our results, focused on predictions up to 30 minutes ahead, demonstrate superior predictive performance of DCIL over traditional regression models and behavioral cloning on deep learning architectures, highlighting its effectiveness in capturing the sequential and uncertain nature of delay propagation in large-scale networks.

</details>


### [5] [Guardrailed Uplift Targeting: A Causal Optimization Playbook for Marketing Strategy](https://arxiv.org/abs/2512.19805)
*Deepit Sapru*

Main category: cs.LG

TL;DR: 提出一个营销决策框架，将异质性处理提升转化为约束性目标策略，在遵守业务护栏的同时最大化收入和留存率


<details>
  <summary>Details</summary>
Motivation: 需要将因果推断的异质性处理效果转化为实际的营销决策，在预算、销售下降等业务约束下优化目标策略

Method: 使用提升学习器估计条件平均处理效果(CATE)，然后通过约束分配优化决定目标人群和优惠策略

Result: 在留存消息、事件奖励和消费阈值分配等应用中，框架在离线评估中持续优于倾向性和静态基线方法；在线A/B测试验证了在保持用户体验约束的同时提升收入和完成率

Conclusion: 该框架为营销人员提供了一个可重复使用的操作手册，用于规模化实施因果目标策略、设置业务护栏，并使营销活动与战略KPI保持一致

Abstract: This paper introduces a marketing decision framework that converts heterogeneous-treatment uplift into constrained targeting strategies to maximize revenue and retention while honoring business guardrails. The approach estimates Conditional Average Treatment Effects (CATE) with uplift learners and then solves a constrained allocation to decide who to target and which offer to deploy under limits such as budget or acceptable sales deterioration. Applied to retention messaging, event rewards, and spend-threshold assignment, the framework consistently outperforms propensity and static baselines in offline evaluations using uplift AUC, Inverse Propensity Scoring (IPS), and Self-Normalized IPS (SNIPS). A production-scale online A/B test further validates strategic lift on revenue and completion while preserving customer-experience constraints. The result is a reusable playbook for marketers to operationalize causal targeting at scale, set guardrails, and align campaigns with strategic KPIs.

</details>


### [6] [Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance](https://arxiv.org/abs/2512.20006)
*Sukumar Kishanthan,Asela Hevapathige*

Main category: cs.LG

TL;DR: 提出OGAB激活函数，通过正交性和分组感知偏置学习缓解深度学习中的类别不平衡问题，无需显式标签信息即可增强特征区分度。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是机器学习和数据挖掘中的常见挑战，会导致分类器性能下降。尽管深度学习在特征提取方面表现出色，但在不平衡数据下性能仍然会恶化。现有方法通常通过预处理数据修改或后处理校正来解决类别不平衡，但作者希望直接在训练阶段嵌入学习层面解决这一问题。

Method: 提出OGAB激活函数，包含两个关键组件：1）正交变换：通过保持特征独立性来保留少数类信息，防止多数类在嵌入空间中占主导地位；2）分组感知偏置机制：自动识别数据聚类并调整嵌入以增强类别可分性，无需显式监督。该方法在训练阶段直接处理类别不平衡问题。

Result: 在真实世界和合成的类别不平衡数据集上验证了OGAB的有效性，相比传统和可学习激活函数，都取得了持续的性能改进。

Conclusion: 激活函数可以引入强归纳偏置来解决复杂数据挑战，超越传统的非线性功能。OGAB通过正交变换和分组感知偏置学习，能够在无需显式标签信息的情况下缓解类别不平衡问题，为深度学习中的类别不平衡问题提供了新的训练阶段解决方案。

Abstract: Class imbalance is a common challenge in machine learning and data mining, often leading to suboptimal performance in classifiers. While deep learning excels in feature extraction, its performance still deteriorates under imbalanced data. In this work, we propose a novel activation function, named OGAB, designed to alleviate class imbalance in deep learning classifiers. OGAB incorporates orthogonality and group-aware bias learning to enhance feature distinguishability in imbalanced scenarios without explicitly requiring label information. Our key insight is that activation functions can be used to introduce strong inductive biases that can address complex data challenges beyond traditional non-linearity. Our work demonstrates that orthogonal transformations can preserve information about minority classes by maintaining feature independence, thereby preventing the dominance of majority classes in the embedding space. Further, the proposed group-aware bias mechanism automatically identifies data clusters and adjusts embeddings to enhance class separability without the need for explicit supervision. Unlike existing approaches that address class imbalance through preprocessing data modifications or post-processing corrections, our proposed approach tackles class imbalance during the training phase at the embedding learning level, enabling direct integration with the learning process. We demonstrate the effectiveness of our solution on both real-world and synthetic imbalanced datasets, showing consistent performance improvements over both traditional and learnable activation functions.

</details>


### [7] [BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples](https://arxiv.org/abs/2512.20403)
*Xuan-An Le,Minh-Nam Tran,Son Nguyen*

Main category: cs.LG

TL;DR: BRIDGE框架通过两阶段知识蒸馏解决大模型到小模型的知识迁移问题：第一阶段用少量数据训练中等规模教师助手，第二阶段用该助手免费生成大量训练数据来训练小模型，显著降低API成本同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 从大型专有模型（如GPT-4）向小型可部署模型（小于1B参数）蒸馏知识面临容量预算陷阱：师生模型1000倍容量差距阻碍直接迁移，而API成本又限制数据收集。

Method: 两阶段框架：1）用3-5%数据训练中等规模教师助手（约7B），通过零API成本管道选择平衡难度和多样性的数据；2）利用教师助手免费生成完整数据集的合成推理过程来训练小模型，并采用指令调优课程建立行为对齐。

Result: 在医疗、法律和金融基准测试中，BRIDGE使学生模型性能提升28-41%，将能力差距缩小12-16%，同时使用10倍更少的教师查询。仅用5%资源就超越了使用100%预算的直接蒸馏基线。

Conclusion: BRIDGE通过战略中间化和预算不对称，突破了传统成本-性能边界，为大规模专有模型到小型可部署模型的知识蒸馏提供了高效解决方案。

Abstract: Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.

</details>


### [8] [Machine Learning to Predict Digital Frustration from Clickstream Data](https://arxiv.org/abs/2512.20438)
*Jibin Joseph*

Main category: cs.LG

TL;DR: 使用电商点击流数据预测用户会话是否受挫，XGBoost和LSTM模型均能达到90%以上准确率，LSTM在仅20-30次交互后即可可靠预测


<details>
  <summary>Details</summary>
Motivation: 移动应用和网站的用户受挫会导致销售损失和投诉，企业需要预测用户受挫会话以改善用户体验

Method: 基于点击流数据定义受挫规则（愤怒爆发、来回导航、购物车流失、搜索困难、长时间徘徊），构建表格特征训练XGBoost等分类器，同时使用完整事件序列训练LSTM分类器

Result: XGBoost达到约90%准确率和0.9579 ROC AUC，LSTM表现最佳，达到约91%准确率和0.9705 ROC AUC，且仅需前20-30次交互即可可靠预测受挫

Conclusion: 点击流数据能有效预测用户受挫，LSTM模型在早期预测方面表现优异，有助于企业及时干预改善用户体验

Abstract: Many businesses depend on their mobile apps and websites, so user frustration while trying to complete a task on these channels can cause lost sales and complaints. In this research, I use clickstream data from a real e-commerce site to predict whether a session is frustrated or not. Frustration is defined using certain rules based on rage bursts, back and forth navigation (U turns), cart churn, search struggle, and long wandering sessions, and applies these rules to 5.4 million raw clickstream events (304,881 sessions). From each session, I build tabular features and train standard classifier models. I also use the full event sequence to train a discriminative LSTM classifier. XGBoost reaches about 90% accuracy, ROC AUC of 0.9579, while the LSTM performs best with about 91% accuracy and a ROC AUC of 0.9705. Finally, the research shows that with only the first 20 to 30 interactions, the LSTM already predicts frustration reliably.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach](https://arxiv.org/abs/2512.20056)
*Hao Li,Fabian Deuser,Wenping Yin,Steffen Knoblauch,Wufan Zhao,Filip Biljecki,Yong Xue,Wei Huang*

Main category: cs.AI

TL;DR: 提出ProbGLC概率跨视角地理定位方法，结合概率和确定性模型，提高灾害响应中的定位准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致灾害事件频发加剧，快速准确的灾害位置识别对应急响应和资源分配至关重要，需要提高地理定位的准确性和可解释性。

Method: 提出ProbGLC概率跨视角地理定位框架，将概率模型和确定性模型统一结合，通过不确定性量化和局部化评分增强模型可解释性，支持多种灾害类型的跨视角定位。

Result: 在两个跨视角灾害数据集（MultiIAN和SAGAINDisaster）上验证，达到0.86的Acc@1km和0.97的Acc@25km定位精度，同时提供概率分布和局部化评分增强可解释性。

Conclusion: ProbGLC方法在灾害地理定位中表现出优越性能，通过生成式跨视角方法增强位置感知能力，有望促进更快更好的灾害响应。

Abstract: As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC

</details>


### [10] [Benchmarking LLMs for Predictive Applications in the Intensive Care Units](https://arxiv.org/abs/2512.20520)
*Chehak Malhotra,Mehak Gopal,Akshaya Devadiga,Pradeep Singh,Ridam Pal,Ritwik Kashyap,Tavpritesh Sethi*

Main category: cs.AI

TL;DR: LLMs与SLMs在预测ICU患者休克风险上的性能对比研究，发现两者表现相当，GatorTron-Base表现最佳但优势有限。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在NLP任务中表现出色，但在临床预测任务中的应用研究较少。及时预测休克能够实现早期干预，改善患者预后，因此需要评估LLMs在临床预测中的实际价值。

Method: 使用MIMIC III数据库中17,294例ICU住院患者的文本数据，筛选出LOS>24小时且休克指数>0.7的患者（正常组355例，异常组87例）。比较了GatorTron-Base、Llama 8B、Mistral 7B等LLMs与BioBERT、DocBERT、BioClinicalBERT、Word2Vec、Doc2Vec等SLMs的性能。使用focal loss和交叉熵损失解决类别不平衡问题。

Result: GatorTron-Base获得了最高的加权召回率80.5%，但LLMs和SLMs的整体性能指标相当。这表明LLMs在预测未来临床事件方面并不天然优于SLMs。

Conclusion: LLMs在临床预测任务中并未展现出对SLMs的明显优势。未来训练LLMs应重点关注开发能够预测临床轨迹的模型，而非简单的NER或表型识别任务，以实现有意义的临床结果。

Abstract: With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.

</details>
