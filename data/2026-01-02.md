<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 8]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Factorized Learning for Temporally Grounded Video-Language Models](https://arxiv.org/abs/2512.24097)
*Wenzheng Zeng,Difei Gao,Mike Zheng Shou,Hwee Tou Ng*

Main category: cs.CV

TL;DR: D²VLM：通过解耦学习和因子化偏好优化，提升视频语言模型的事件级时间定位能力


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型在事件级感知的时间定位方面存在困难，且时间定位和文本响应这两个关键任务通常耦合处理，缺乏清晰的逻辑层次结构，导致目标优化不理想

Method: 提出D²VLM框架，采用"先定位后回答并引用证据"范式，引入证据令牌进行证据定位；开发因子化偏好优化（FPO）算法，将概率时间定位建模显式纳入优化目标；构建合成数据集支持因子化偏好学习

Result: 在多个任务上的实验表明该方法具有明显优势

Conclusion: 通过解耦学习和因子化偏好优化，D²VLM显著提升了视频语言模型的时间定位能力和文本响应质量

Abstract: Recent video-language models have shown great potential for video understanding, but still struggle with accurate temporal grounding for event-level perception. We observe that two main factors in video understanding (i.e., temporal grounding and textual response) form a logical hierarchy: accurate temporal evidence grounding lays the foundation for reliable textual response. However, existing works typically handle these two tasks in a coupled manner without a clear logical structure, leading to sub-optimal objectives. We address this from a factorized learning perspective. We first propose D$^2$VLM, a framework that decouples the learning of these two tasks while also emphasizing their inherent dependency. We adopt a "grounding then answering with evidence referencing" paradigm and introduce evidence tokens for evidence grounding, which emphasize event-level visual semantic capture beyond the focus on timestamp representation in existing works. To further facilitate the learning of these two tasks, we introduce a novel factorized preference optimization (FPO) algorithm. Unlike standard preference optimization, FPO explicitly incorporates probabilistic temporal grounding modeling into the optimization objective, enabling preference learning for both temporal grounding and textual response. We also construct a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding. Experiments on various tasks demonstrate the clear advantage of our approach. Our source code is available at https://github.com/nusnlp/d2vlm.

</details>


### [2] [Enhancing LLM-Based Neural Network Generation: Few-Shot Prompting and Efficient Validation for Automated Architecture Design](https://arxiv.org/abs/2512.24120)
*Chandini Vysyaraju,Raghuvir Duvvuri,Avi Goyal,Dmitry Ignatov,Radu Timofte*

Main category: cs.CV

TL;DR: 论文提出FSAP方法系统研究LLM生成视觉架构的示例数量，发现n=3最佳；引入轻量去重验证方法；在7个视觉基准上生成1900个架构，建立平衡评估方法。


<details>
  <summary>Details</summary>
Motivation: 自动化神经网络架构设计在计算机视觉中仍具挑战性。任务多样性和计算约束需要高效架构和搜索方法。LLM为计算密集的NAS提供了有前景的替代方案，但在计算机视觉架构生成中的应用尚未系统研究，特别是在提示工程和验证策略方面。

Method: 1. 提出Few-Shot Architecture Prompting (FSAP)，首次系统研究LLM生成架构时支持示例数量(n=1-6)；2. 引入Whitespace-Normalized Hash Validation，轻量去重方法(小于1ms)，比AST解析快100倍；3. 在7个计算机视觉基准上进行大规模实验；4. 提出数据集平衡评估方法，解决异构视觉任务架构比较问题。

Result: 发现n=3示例在架构多样性和上下文聚焦之间达到最佳平衡；生成1900个独特架构；轻量去重方法显著加速验证过程；建立了LLM在计算机视觉架构搜索中的实用指南和严格评估实践。

Conclusion: 这些贡献为计算机视觉中基于LLM的架构搜索提供了可操作指南，并建立了严格的评估实践，使计算资源有限的研究者更容易进行自动化设计。

Abstract: Automated neural network architecture design remains a significant challenge in computer vision. Task diversity and computational constraints require both effective architectures and efficient search methods. Large Language Models (LLMs) present a promising alternative to computationally intensive Neural Architecture Search (NAS), but their application to architecture generation in computer vision has not been systematically studied, particularly regarding prompt engineering and validation strategies. Building on the task-agnostic NNGPT/LEMUR framework, this work introduces and validates two key contributions for computer vision. First, we present Few-Shot Architecture Prompting (FSAP), the first systematic study of the number of supporting examples (n = 1, 2, 3, 4, 5, 6) for LLM-based architecture generation. We find that using n = 3 examples best balances architectural diversity and context focus for vision tasks. Second, we introduce Whitespace-Normalized Hash Validation, a lightweight deduplication method (less than 1 ms) that provides a 100x speedup over AST parsing and prevents redundant training of duplicate computer vision architectures. In large-scale experiments across seven computer vision benchmarks (MNIST, CIFAR-10, CIFAR-100, CelebA, ImageNette, SVHN, Places365), we generated 1,900 unique architectures. We also introduce a dataset-balanced evaluation methodology to address the challenge of comparing architectures across heterogeneous vision tasks. These contributions provide actionable guidelines for LLM-based architecture search in computer vision and establish rigorous evaluation practices, making automated design more accessible to researchers with limited computational resources.

</details>


### [3] [Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning](https://arxiv.org/abs/2512.24146)
*Chubin Chen,Sujie Hu,Jiashu Zhu,Meiqi Wu,Jintao Chen,Yanxun Li,Nisha Huang,Chengyu Fang,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: 本文提出D²-Align框架，通过方向性解耦对齐解决文本到图像扩散模型在人类反馈强化学习中出现的偏好模式崩溃问题，保持生成多样性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型通过人类反馈强化学习实现偏好对齐，但容易导致偏好模式崩溃——模型收敛到狭窄的高分输出（如单一风格或过度曝光），严重损害生成多样性。

Method: 提出方向性解耦对齐框架：1）在奖励模型嵌入空间中学习方向性修正，保持模型冻结；2）在优化过程中应用修正后的奖励信号，防止模型塌缩到特定模式。

Result: 通过质量和多样性的定性与定量评估，D²-Align在保持多样性的同时实现了与人类偏好的更好对齐，优于现有方法。

Conclusion: 方向性解耦对齐能有效缓解偏好模式崩溃问题，在文本到图像扩散模型的人类偏好对齐中实现质量与多样性的更好平衡。

Abstract: Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model's inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D$^2$-Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model's embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D$^2$-Align achieves superior alignment with human preference.

</details>


### [4] [MambaSeg: Harnessing Mamba for Accurate and Efficient Image-Event Semantic Segmentation](https://arxiv.org/abs/2512.24243)
*Fuqiang Gu,Yuanke Li,Xianlei Long,Kangping Ji,Chao Chen,Qingyi Gu,Zhenliang Ni*

Main category: cs.CV

TL;DR: MambaSeg：一种新颖的双分支语义分割框架，使用并行Mamba编码器处理RGB图像和事件流，通过双维交互模块（DDIM）进行时空融合，在DDD17和DSEC数据集上实现最先进的性能，同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: RGB方法在快速运动、低光或高动态范围条件下性能下降，而事件相机缺乏颜色和纹理信息。现有多模态融合方法计算昂贵且主要关注空间融合，忽略了事件流的时序动态特性。

Method: 提出MambaSeg框架，使用并行Mamba编码器分别处理RGB图像和事件流。引入双维交互模块（DDIM），包含跨空间交互模块（CSIM）和跨时序交互模块（CTIM），在空间和时序维度上进行细粒度融合，改善跨模态对齐并减少模糊性。

Result: 在DDD17和DSEC数据集上的实验表明，MambaSeg实现了最先进的语义分割性能，同时显著降低了计算成本，展示了其在高效、可扩展和鲁棒的多模态感知方面的潜力。

Conclusion: MambaSeg通过并行Mamba编码器和双维交互模块，有效融合RGB和事件数据的互补特性，在保持高性能的同时降低计算复杂度，为高效的多模态感知提供了有前景的解决方案。

Abstract: Semantic segmentation is a fundamental task in computer vision with wide-ranging applications, including autonomous driving and robotics. While RGB-based methods have achieved strong performance with CNNs and Transformers, their effectiveness degrades under fast motion, low-light, or high dynamic range conditions due to limitations of frame cameras. Event cameras offer complementary advantages such as high temporal resolution and low latency, yet lack color and texture, making them insufficient on their own. To address this, recent research has explored multimodal fusion of RGB and event data; however, many existing approaches are computationally expensive and focus primarily on spatial fusion, neglecting the temporal dynamics inherent in event streams. In this work, we propose MambaSeg, a novel dual-branch semantic segmentation framework that employs parallel Mamba encoders to efficiently model RGB images and event streams. To reduce cross-modal ambiguity, we introduce the Dual-Dimensional Interaction Module (DDIM), comprising a Cross-Spatial Interaction Module (CSIM) and a Cross-Temporal Interaction Module (CTIM), which jointly perform fine-grained fusion along both spatial and temporal dimensions. This design improves cross-modal alignment, reduces ambiguity, and leverages the complementary properties of each modality. Extensive experiments on the DDD17 and DSEC datasets demonstrate that MambaSeg achieves state-of-the-art segmentation performance while significantly reducing computational cost, showcasing its promise for efficient, scalable, and robust multimodal perception.

</details>


### [5] [DyStream: Streaming Dyadic Talking Heads Generation via Flow Matching-based Autoregressive Model](https://arxiv.org/abs/2512.24408)
*Bohong Chen,Haiyang Liu*

Main category: cs.CV

TL;DR: DyStream：基于流匹配的自回归模型，实现实时双人对话头部视频生成，延迟低于100ms


<details>
  <summary>Details</summary>
Motivation: 现有基于分块的方法需要完整的非因果上下文窗口，导致显著延迟，无法满足实时对话中非语言反馈的需求

Method: 采用流友好的自回归框架，结合流匹配头部进行概率建模；提出因果编码器增强模块，通过前瞻模块引入短期未来上下文（如60ms）以提升质量同时保持低延迟

Result: 每帧生成时间34ms，系统总延迟低于100ms；在HDTF数据集上获得离线8.13和在线7.61的唇部同步置信度分数，达到最先进的唇部同步质量

Conclusion: DyStream通过流匹配自回归框架和因果编码器增强，实现了实时、高质量的对话头部视频生成，显著优于其他因果策略

Abstract: Generating realistic, dyadic talking head video requires ultra-low latency. Existing chunk-based methods require full non-causal context windows, introducing significant delays. This high latency critically prevents the immediate, non-verbal feedback required for a realistic listener. To address this, we present DyStream, a flow matching-based autoregressive model that could generate video in real-time from both speaker and listener audio. Our method contains two key designs: (1) we adopt a stream-friendly autoregressive framework with flow-matching heads for probabilistic modeling, and (2) We propose a causal encoder enhanced by a lookahead module to incorporate short future context (e.g., 60 ms) to improve quality while maintaining low latency. Our analysis shows this simple-and-effective method significantly surpass alternative causal strategies, including distillation and generative encoder. Extensive experiments show that DyStream could generate video within 34 ms per frame, guaranteeing the entire system latency remains under 100 ms. Besides, it achieves state-of-the-art lip-sync quality, with offline and online LipSync Confidence scores of 8.13 and 7.61 on HDTF, respectively. The model, weights and codes are available.

</details>


### [6] [From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation](https://arxiv.org/abs/2512.24639)
*Siyang Wang,Hanting Li,Wei Li,Jie Hu,Xinghao Chen,Feng Zhao*

Main category: cs.CV

TL;DR: RadAR提出了一种基于径向拓扑的并行自回归视觉生成框架，通过环形分组和嵌套注意力机制，在保持生成质量的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型在视觉生成中采用顺序解码机制，导致推理效率低下。视觉token具有强烈的局部依赖性和空间相关性，但标准光栅扫描解码顺序未能充分利用这一特性。

Method: 采用径向拓扑结构：选择初始token作为中心点，将所有其他token按空间距离分组到多个同心环中。按环顺序生成（从内到外），同一环内的token可并行预测。引入嵌套注意力机制动态修正不一致预测，防止错误累积。

Result: RadAR框架显著提高了生成效率，同时保持了自回归模型的表示能力，通过并行化加速了视觉生成过程。

Conclusion: 径向并行预测结合动态输出修正的RadAR框架，在保持视觉场景结构局部性和空间连贯性的同时，大幅提升了自回归视觉生成的效率。

Abstract: Inspired by the remarkable success of autoregressive models in language modeling, this paradigm has been widely adopted in visual generation. However, the sequential token-by-token decoding mechanism inherent in traditional autoregressive models leads to low inference efficiency.In this paper, we propose RadAR, an efficient and parallelizable framework designed to accelerate autoregressive visual generation while preserving its representational capacity. Our approach is motivated by the observation that visual tokens exhibit strong local dependencies and spatial correlations with their neighbors--a property not fully exploited in standard raster-scan decoding orders. Specifically, we organize the generation process around a radial topology: an initial token is selected as the starting point, and all other tokens are systematically grouped into multiple concentric rings according to their spatial distances from this center. Generation then proceeds in a ring-wise manner, from inner to outer regions, enabling the parallel prediction of all tokens within the same ring. This design not only preserves the structural locality and spatial coherence of visual scenes but also substantially increases parallelization. Furthermore, to address the risk of inconsistent predictions arising from simultaneous token generation with limited context, we introduce a nested attention mechanism. This mechanism dynamically refines implausible outputs during the forward pass, thereby mitigating error accumulation and preventing model collapse. By integrating radial parallel prediction with dynamic output correction, RadAR significantly improves generation efficiency.

</details>


### [7] [EchoFoley: Event-Centric Hierarchical Control for Video Grounded Creative Sound Generation](https://arxiv.org/abs/2512.24731)
*Bingxuan Li,Yiming Cui,Yicheng He,Yiwei Wang,Shu Zhang,Longyin Wen,Yulei Niu*

Main category: cs.CV

TL;DR: EchoFoley是一个新的视频声音生成任务，通过符号化表示实现细粒度控制，EchoVidia框架在可控性和感知质量上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频文本到音频（VT2A）方法存在三个主要问题：视觉和文本条件不平衡导致视觉主导；缺乏细粒度可控生成的具体定义；指令理解和跟随能力弱，因为现有数据集依赖简短的分类标签。

Method: 提出EchoFoley任务，使用符号化表示指定声音事件的时间、内容和方式；构建EchoFoley-6k大规模专家标注数据集；开发EchoVidia框架，采用慢-快思维策略的以声音事件为中心的智能生成方法。

Result: EchoVidia在可控性上比现有VT2A模型提升40.7%，在感知质量上提升12.5%。

Conclusion: EchoFoley任务和EchoVidia框架有效解决了现有VT2A方法的局限性，实现了细粒度可控的视频声音生成，为多模态叙事提供了更好的声音效果生成能力。

Abstract: Sound effects build an essential layer of multimodal storytelling, shaping the emotional atmosphere and the narrative semantics of videos. Despite recent advancement in video-text-to-audio (VT2A), the current formulation faces three key limitations: First, an imbalance between visual and textual conditioning that leads to visual dominance; Second, the absence of a concrete definition for fine-grained controllable generation; Third, weak instruction understanding and following, as existing datasets rely on brief categorical tags. To address these limitations, we introduce EchoFoley, a new task designed for video-grounded sound generation with both event level local control and hierarchical semantic control. Our symbolic representation for sounding events specifies when, what, and how each sound is produced within a video or instruction, enabling fine-grained controls like sound generation, insertion, and editing. To support this task, we construct EchoFoley-6k, a large-scale, expert-curated benchmark containing over 6,000 video-instruction-annotation triplets. Building upon this foundation, we propose EchoVidia a sounding-event-centric agentic generation framework with slow-fast thinking strategy. Experiments show that EchoVidia surpasses recent VT2A models by 40.7% in controllability and 12.5% in perceptual quality.

</details>


### [8] [Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection](https://arxiv.org/abs/2512.24922)
*Bartłomiej Olber,Jakub Winter,Paweł Wawrzyński,Andrii Gamalii,Daniel Górniak,Marcin Łojek,Robert Nowak,Krystian Radlak*

Main category: cs.CV

TL;DR: 提出基于神经元激活模式的LiDAR域自适应方法，仅需标注目标域中少量代表性样本即可达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 3D目标检测器在自动驾驶中至关重要，但在不同地理区域间泛化能力差（如美国训练的模型在亚洲或欧洲表现不佳），需要有效的域自适应方法

Method: 基于神经元激活模式的LiDAR域自适应方法，通过选择目标域中少量代表性且多样化的样本进行标注，结合持续学习启发的后训练技术防止权重漂移

Result: 该方法在实证评估中优于线性探测和现有最先进的域自适应技术，且仅需极小的标注预算

Conclusion: 通过神经元激活模式选择少量代表性样本进行标注，结合持续学习技术，可以实现高效的LiDAR域自适应，显著提升模型在新地理区域的性能

Abstract: 3D object detectors are fundamental components of perception systems in autonomous vehicles. While these detectors achieve remarkable performance on standard autonomous driving benchmarks, they often struggle to generalize across different domains - for instance, a model trained in the U.S. may perform poorly in regions like Asia or Europe. This paper presents a novel lidar domain adaptation method based on neuron activation patterns, demonstrating that state-of-the-art performance can be achieved by annotating only a small, representative, and diverse subset of samples from the target domain if they are correctly selected. The proposed approach requires very small annotation budget and, when combined with post-training techniques inspired by continual learning prevent weight drift from the original model. Empirical evaluation shows that the proposed domain adaptation approach outperforms both linear probing and state-of-the-art domain adaptation techniques.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [HINTS: Extraction of Human Insights from Time-Series Without External Sources](https://arxiv.org/abs/2512.23755)
*Sheo Yon Jhin,Noseong Park*

Main category: cs.LG

TL;DR: HINTS：一种自监督学习框架，无需外部数据，从时间序列残差中提取潜在人类因素（如社会影响、记忆和偏见），通过FJ意见动力学模型作为结构归纳偏置，提升时间序列预测精度。


<details>
  <summary>Details</summary>
Motivation: 人类决策、情感和集体心理是影响金融经济系统时间动态的复杂因素。现有方法依赖外部数据（如新闻、社交媒体）来捕捉这些因素，但会产生高昂的数据依赖成本（财务、计算、实践）。需要一种无需外部数据就能内生提取这些潜在因素的方法。

Method: 提出HINTS自监督学习框架：1）从时间序列残差中内生提取潜在人类因素；2）使用Friedkin-Johnsen（FJ）意见动力学模型作为结构归纳偏置，建模演化中的社会影响、记忆和偏见模式；3）将提取的人类因素作为注意力图集成到最先进的骨干模型中。

Result: 在9个真实世界和基准数据集上的实验表明，HINTS能持续提升预测准确性。多个案例研究和消融研究验证了HINTS的可解释性，显示提取的因素与现实世界事件有强语义对齐，证明了其实用价值。

Conclusion: HINTS框架成功实现了无需外部数据就能从时间序列残差中内生提取人类因素，通过FJ意见动力学模型提供结构偏置，不仅提升了预测性能，还保持了良好的可解释性，为时间序列预测提供了实用且成本效益高的解决方案。

Abstract: Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.

</details>


### [10] [FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading](https://arxiv.org/abs/2512.23773)
*Molei Qin,Xinyu Cai,Yewen Li,Haochong Xia,Chuqiao Zong,Shuo Sun,Xinrun Wang,Bo An*

Main category: cs.LG

TL;DR: FineFT提出三阶段集成强化学习框架，解决加密货币期货交易中高杠杆带来的训练不稳定和风险控制问题，在保持盈利能力的同时显著降低风险。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要针对现货市场，无法直接应用于高杠杆的期货市场，面临两大挑战：1）高杠杆放大奖励波动，导致训练随机且难以收敛；2）缺乏对能力边界的自我认知，在新市场状态（如黑天鹅事件）下可能遭受重大损失。

Method: 提出三阶段集成RL框架：阶段I通过集成TD误差选择性更新Q学习器以改善收敛；阶段II基于盈利能力筛选Q学习器，并训练VAE识别市场状态以确定能力边界；阶段III根据训练的VAE指导，从筛选后的集成策略和保守策略中选择，以维持盈利能力并降低新市场状态下的风险。

Result: 在高频交易环境下对加密货币期货进行5倍杠杆实验，FineFT在6个金融指标上优于12个SOTA基线，风险降低超过40%的同时实现优于第二名的盈利能力。可视化显示不同智能体专注于不同市场动态，消融研究证实VAE路由有效降低最大回撤，选择性更新改善收敛和性能。

Conclusion: FineFT成功解决了高杠杆期货交易中的训练不稳定和风险管理问题，通过三阶段集成框架实现了稳定训练、能力边界识别和风险控制，为加密货币期货交易提供了有效的强化学习解决方案。

Abstract: Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.

</details>


### [11] [GARDO: Reinforcing Diffusion Models without Reward Hacking](https://arxiv.org/abs/2512.24138)
*Haoran He,Yuxiao Ye,Jie Liu,Jiajun Liang,Zhiyong Wang,Ziyang Yuan,Xintao Wang,Hangyu Mao,Pengfei Wan,Ling Pan*

Main category: cs.LG

TL;DR: GARDO框架通过选择性惩罚高不确定性样本、自适应更新参考模型、以及奖励高多样性高质量样本，解决了扩散模型在线强化学习中的奖励黑客攻击、探索不足和模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 在扩散模型的在线强化学习中，由于视觉任务的真实目标难以精确指定，通常使用代理奖励进行优化。这种不匹配导致奖励黑客攻击（代理分数上升但真实图像质量下降）、生成多样性崩溃，而现有基于参考策略的正则化方法又会影响样本效率和探索能力。

Method: 提出GARDO框架：1）选择性正则化：仅惩罚高不确定性样本；2）自适应正则化：定期更新参考模型以匹配在线策略能力；3）多样性感知优化：奖励高质量且高多样性的样本以鼓励模式覆盖。

Result: 在多种代理奖励和未见指标上的广泛实验表明，GARDO能有效缓解奖励黑客攻击，增强生成多样性，同时不牺牲样本效率或探索能力，证明了其有效性和鲁棒性。

Conclusion: GARDO通过创新的选择性正则化、自适应参考模型更新和多样性感知优化，成功解决了扩散模型强化学习中的关键挑战，为平衡样本效率、探索能力和奖励黑客攻击缓解提供了有效解决方案。

Abstract: Fine-tuning diffusion models via online reinforcement learning (RL) has shown great potential for enhancing text-to-image alignment. However, since precisely specifying a ground-truth objective for visual tasks remains challenging, the models are often optimized using a proxy reward that only partially captures the true goal. This mismatch often leads to reward hacking, where proxy scores increase while real image quality deteriorates and generation diversity collapses. While common solutions add regularization against the reference policy to prevent reward hacking, they compromise sample efficiency and impede the exploration of novel, high-reward regions, as the reference policy is usually sub-optimal. To address the competing demands of sample efficiency, effective exploration, and mitigation of reward hacking, we propose Gated and Adaptive Regularization with Diversity-aware Optimization (GARDO), a versatile framework compatible with various RL algorithms. Our key insight is that regularization need not be applied universally; instead, it is highly effective to selectively penalize a subset of samples that exhibit high uncertainty. To address the exploration challenge, GARDO introduces an adaptive regularization mechanism wherein the reference model is periodically updated to match the capabilities of the online policy, ensuring a relevant regularization target. To address the mode collapse issue in RL, GARDO amplifies the rewards for high-quality samples that also exhibit high diversity, encouraging mode coverage without destabilizing the optimization process. Extensive experiments across diverse proxy rewards and hold-out unseen metrics consistently show that GARDO mitigates reward hacking and enhances generation diversity without sacrificing sample efficiency or exploration, highlighting its effectiveness and robustness.

</details>


### [12] [Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning](https://arxiv.org/abs/2512.24404)
*Soham Pahari,M. Srinivas*

Main category: cs.LG

TL;DR: 本文提出ViReLoc框架，通过视觉推理进行地理一致的视觉规划，仅使用视觉表示完成导航和定位任务，无需实时GPS数据。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理系统主要依赖文本信息进行推理，限制了在空间任务（如视觉导航和地理定位）中的有效性。文本推理难以理解空间依赖和几何关系。

Method: 提出ViReLoc框架，通过视觉表示进行规划和定位。采用强化学习目标优化，在视觉域中进行逐步推理编码。集成对比学习和自适应特征交互来对齐跨视角并减少视角差异。

Result: 在多种导航和定位场景实验中，空间推理准确性和跨视角检索性能均获得一致提升。

Conclusion: 视觉推理可作为导航和定位的强大补充方法，无需实时GPS数据即可完成任务，提供更安全的导航解决方案。

Abstract: Multimodal intelligence development recently show strong progress in visual understanding and high level reasoning. Though, most reasoning system still reply on textual information as the main medium for inference. This limit their effectiveness in spatial tasks such as visual navigation and geo-localization. This work discuss about the potential scope of this field and eventually propose an idea visual reasoning paradigm Geo-Consistent Visual Planning, our introduced framework called Visual Reasoning for Localization, or ViReLoc, which performs planning and localization using only visual representations. The proposed framework learns spatial dependencies and geometric relations that text based reasoning often suffer to understand. By encoding step by step inference in the visual domain and optimizing with reinforcement based objectives, ViReLoc plans routes between two given ground images. The system also integrates contrastive learning and adaptive feature interaction to align cross view perspectives and reduce viewpoint differences. Experiments across diverse navigation and localization scenarios show consistent improvements in spatial reasoning accuracy and cross view retrieval performance. These results establish visual reasoning as a strong complementary approach for navigation and localization, and show that such tasks can be performed without real time global positioning system data, leading to more secure navigation solutions.

</details>


### [13] [Scaling Open-Ended Reasoning to Predict the Future](https://arxiv.org/abs/2512.25070)
*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

Main category: cs.LG

TL;DR: 训练语言模型进行开放式预测，使用自动化新闻数据生成训练集，开发OpenForecaster 8B模型，在准确率、校准和一致性方面匹配更大规模专有模型


<details>
  <summary>Details</summary>
Motivation: 高风险的决策需要在不确定性下对未来进行推理。当前需要训练语言模型进行开放式预测，但缺乏大规模训练数据，且需要防止未来信息泄露的问题

Method: 1. 从每日新闻中自动化合成预测问题；2. 使用离线新闻语料库防止信息泄露；3. 训练Qwen3思维模型；4. 结合检索增强；5. 改进强化学习的奖励函数；6. 在2025年5-8月进行保留测试

Result: OpenForecaster 8B模型在准确率、校准和一致性方面匹配更大规模专有模型，预测训练带来的校准改进在多个基准测试中具有泛化性

Conclusion: 通过自动化数据生成和专门的训练方法，可以开发出高效的语言模型预测系统，开源模型、代码和数据将促进语言模型预测研究的广泛可及性

Abstract: High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [14] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化代理框架，通过将LLM集成到"计划-执行-总结"认知范式中，将进化搜索映射为推理密集型过程，显著提高进化效率并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法缺乏结构化推理，导致过早收敛和高维代码空间探索效率低下，阻碍了从静态LLM向自改进代理的过渡。

Method: 1) 集成LLM到"计划-执行-总结"认知范式；2) 采用混合进化记忆系统，结合多岛模型、MAP-Elites和自适应玻尔兹曼选择；3) 实例化为通用代理（算法发现）和ML代理（管道优化）。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow比OpenEvolve、ShinkaEvolve等基线方法进化效率提高达60%，并发现更优解决方案。

Conclusion: LoongFlow代表了自主科学发现的重要进展，能够以更低计算开销生成专家级解决方案，实现了从静态LLM到自进化代理的有效过渡。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning](https://arxiv.org/abs/2512.23765)
*Tiancheng Su,Meicong Zhang,Guoxiu He*

Main category: cs.CL

TL;DR: 提出EASD方法，通过动态熵惩罚机制改进推测解码，在保持效率的同时超越目标模型性能


<details>
  <summary>Details</summary>
Motivation: 传统推测解码中草稿模型与目标模型过度对齐，限制了性能只能达到目标模型水平，需要突破这一限制

Method: 基于标准推测解码，引入动态熵惩罚机制，利用采样分布的熵量化模型不确定性，当两个模型都高熵且top-N预测重叠时拒绝token并由目标模型重新采样

Result: 在多个推理基准测试中，EASD持续优于现有推测解码方法，大多数情况下超越目标LLM本身，同时效率与标准推测解码相当

Conclusion: EASD通过草稿模型验证机制，实现了超越目标模型固有性能的可能性，为推测解码提供了有效的训练免费增强方案

Abstract: Speculative decoding (SD) accelerates large language model (LLM) reasoning by using a small draft model to generate candidate tokens, which the target LLM either accepts directly or regenerates upon rejection. However, excessive alignment between the draft and target models constrains SD to the performance of the target LLM. To address this limitation, we propose Entropy-Aware Speculative Decoding (EASD), a training-free enhancement. Building on standard SD, EASD incorporates a dynamic entropy-based penalty. At each decoding step, we employ the entropy of the sampling distribution to quantify model uncertainty. When both models exhibit high entropy with substantial overlap among their top-N predictions, the corresponding token is rejected and re-sampled by the target LLM. This penalty prevents low-confidence errors from propagating. By incorporating draft-model verification, EASD enables the possibility of surpassing the target model's inherent performance. Experiments across multiple reasoning benchmarks demonstrate that EASD consistently outperforms existing SD methods and, in most cases, surpasses the target LLM itself. We further prove that the efficiency of EASD is comparable to that of SD. The code can be found in the Supplementary Materials.

</details>


### [16] [Modeling Language as a Sequence of Thoughts](https://arxiv.org/abs/2512.25026)
*Nasim Borazjanizadeh,James McClelland*

Main category: cs.CL

TL;DR: 提出Thought Gestalt模型，一种双层次循环Transformer，在token和句子级"思想"状态上建模语言，通过记忆机制提升语言模型的全局一致性和数据效率


<details>
  <summary>Details</summary>
Motivation: 传统Transformer语言模型主要依赖表层共现统计，缺乏对实体和事件的全局一致潜在表示，导致关系方向泛化差、上下文错误和数据效率低。受认知科学启发，人类理解语言时会将其转换为紧凑的事件式表示，而逐字形式短暂存在

Method: 提出Thought Gestalt模型：1) 循环Transformer架构，在token和句子级"思想"状态两个抽象层次建模语言；2) 逐句生成token，同时交叉关注先前句子表示的记忆；3) 使用相同参数集生成token和句子表示，通过单一目标（下一个token交叉熵）训练；4) 保留写入记忆的句子表示计算图，使未来token损失的梯度通过交叉注意力反向传播优化早期句子向量生成参数

Result: 1) 在扩展实验中，TG始终比匹配的GPT-2运行更高效，扩展拟合表明GPT-2需要多5-8%的数据和33-42%的参数才能达到TG的损失水平；2) TG在父子关系反转诅咒探针上减少了关系方向泛化错误

Conclusion: Thought Gestalt模型通过引入句子级"思想"状态的双层次表示，模仿人类认知过程，显著提升了语言模型的全局一致性、数据效率和关系方向泛化能力，为构建更健壮、认知合理的语言模型提供了新方向

Abstract: Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim form is short-lived. Motivated by this view, we introduce Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels of abstraction - tokens and sentence-level "thought" states. TG generates the tokens of one sentence at a time while cross-attending to a memory of prior sentence representations. In TG, token and sentence representations are generated using the same set of model parameters and trained with a single objective, the next-token cross-entropy: by retaining the computation graph of sentence representations written to memory, gradients from future token losses flow backward through cross-attention to optimize the parameters generating earlier sentence vectors. In scaling experiments, TG consistently improves efficiency over matched GPT-2 runs, among other baselines, with scaling fits indicating GPT-2 requires ~5-8% more data and ~33-42% more parameters to match TG's loss. TG also reduces errors on relational direction generalization on a father-son reversal curse probe.

</details>
