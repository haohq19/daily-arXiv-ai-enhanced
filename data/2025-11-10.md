<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear](https://arxiv.org/abs/2511.04779)
*Andrea Aspesi,Andrea Simpsi,Aaron Tognoli,Simone Mentasti,Luca Merigo,Matteo Matteucci*

Main category: cs.CV

TL;DR: 提出EETnet，一种基于事件相机的眼动追踪卷积神经网络，能够在资源受限的微控制器上运行，并提供分类和回归两种架构版本。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的眼动追踪解决方案大多依赖强大的GPU，无法在嵌入式设备上部署。需要开发能够在资源受限的微控制器上运行的高效眼动追踪算法。

Method: 设计EETnet卷积神经网络，使用纯事件数据进行眼动追踪；提出训练、评估和量化方法；开发两种架构：基于网格的分类模型和基于像素的回归模型。

Result: 成功开发出能够在微控制器上运行的EETnet网络，实现了基于事件相机的嵌入式眼动追踪解决方案。

Conclusion: EETnet证明了在资源受限的嵌入式设备上实现高效眼动追踪的可行性，为低功耗眼动追踪应用提供了实用解决方案。

Abstract: Event-based cameras are becoming a popular solution for efficient, low-power
eye tracking. Due to the sparse and asynchronous nature of event data, they
require less processing power and offer latencies in the microsecond range.
However, many existing solutions are limited to validation on powerful GPUs,
with no deployment on real embedded devices. In this paper, we present EETnet,
a convolutional neural network designed for eye tracking using purely
event-based data, capable of running on microcontrollers with limited
resources. Additionally, we outline a methodology to train, evaluate, and
quantize the network using a public dataset. Finally, we propose two versions
of the architecture: a classification model that detects the pupil on a grid
superimposed on the original image, and a regression model that operates at the
pixel level.

</details>


### [2] [What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs](https://arxiv.org/abs/2511.05292)
*Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: CuisineSense是一个通过智能手表和智能眼镜融合手部动作与头部动态来分类中餐类型的系统，采用两阶段检测流程，在27.5小时的数据集上实现了高精度的进食状态检测和食物分类。


<details>
  <summary>Details</summary>
Motivation: 传统自我报告方法存在回忆偏差，基于摄像头的方法涉及隐私问题，现有可穿戴方法主要针对有限食物类型，无法应对中餐多样性。

Method: 集成智能手表的手部动作和智能眼镜的头部动态，设计两阶段检测流程：第一阶段识别进食状态，第二阶段基于进食动作进行细粒度食物类型识别。

Result: 在包含11个食物类别和10名参与者的27.5小时IMU记录数据集上，CuisineSense在进食状态检测和食物分类方面都取得了高精度。

Conclusion: CuisineSense为无干扰、基于可穿戴设备的饮食监测提供了一个实用解决方案，系统代码已公开。

Abstract: Accurate food intake detection is vital for dietary monitoring and chronic
disease prevention. Traditional self-report methods are prone to recall bias,
while camera-based approaches raise concerns about privacy. Furthermore,
existing wearable-based methods primarily focus on a limited number of food
types, such as hamburgers and pizza, failing to address the vast diversity of
Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that
classifies Chinese food types by integrating hand motion cues from a smartwatch
with head dynamics from smart glasses. To filter out irrelevant daily
activities, we design a two-stage detection pipeline. The first stage
identifies eating states by distinguishing characteristic temporal patterns
from non-eating behaviors. The second stage then conducts fine-grained food
type recognition based on the motions captured during food intake. To evaluate
CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings
across 11 food categories and 10 participants. Experiments demonstrate that
CuisineSense achieves high accuracy in both eating state detection and food
classification, offering a practical solution for unobtrusive, wearable-based
dietary monitoring.The system code is publicly available at
https://github.com/joeeeeyin/CuisineSense.git.

</details>


### [3] [EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes](https://arxiv.org/abs/2511.05467)
*Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won*

Main category: cs.CV

TL;DR: 提出基于神经形态传感器的实时流态分类框架，利用事件数据检测流动边缘变化，在精度和速度上优于传统图像方法，LSTM模型达到97.6%准确率和0.28ms处理时间。


<details>
  <summary>Details</summary>
Motivation: 流沸腾是高效传热机制，但流态突变会破坏热性能和系统可靠性，需要准确低延迟的实时监测。传统光学成像方法计算需求高、时间分辨率不足，无法捕捉瞬态流动行为。

Method: 使用神经形态传感器检测像素亮度变化，开发五种分类模型比较传统图像数据和事件数据，建立异步处理流水线支持连续低延迟预测。

Result: 基于事件数据的模型优于帧基方法，事件LSTM模型达到97.6%分类准确率，处理时间仅0.28ms，通过多数投票机制提供稳定输出。

Conclusion: 神经形态传感器的事件数据对动态流动特征敏感，支持可靠实时反馈，适用于实验控制和智能热管理。

Abstract: Flow boiling is an efficient heat transfer mechanism capable of dissipating
high heat loads with minimal temperature variation, making it an ideal thermal
management method. However, sudden shifts between flow regimes can disrupt
thermal performance and system reliability, highlighting the need for accurate
and low-latency real-time monitoring. Conventional optical imaging methods are
limited by high computational demands and insufficient temporal resolution,
making them inadequate for capturing transient flow behavior. To address this,
we propose a real-time framework based on signals from neuromorphic sensors for
flow regime classification. Neuromorphic sensors detect changes in brightness
at individual pixels, which typically correspond to motion at edges, enabling
fast and efficient detection without full-frame reconstruction, providing
event-based information. We develop five classification models using both
traditional image data and event-based data, demonstrating that models
leveraging event data outperform frame-based approaches due to their
sensitivity to dynamic flow features. Among these models, the event-based long
short-term memory model provides the best balance between accuracy and speed,
achieving 97.6% classification accuracy with a processing time of 0.28 ms. Our
asynchronous processing pipeline supports continuous, low-latency predictions
and delivers stable output through a majority voting mechanisms, enabling
reliable real-time feedback for experimental control and intelligent thermal
management.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting](https://arxiv.org/abs/2511.04722)
*Qianyang Li,Xingjun Zhang,Peng Tao,Shaoxun Wang,Yancheng Pan,Jia Wei*

Main category: cs.LG

TL;DR: AWEMixer是一个自适应小波增强的混合网络，用于解决物联网环境中长期时间序列预测的挑战。它通过频率路由器和相干门控融合块，结合全局频率信息和局部小波子带，实现精确的时频定位，在七个公开基准测试中优于现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中传感器信号的非平稳性和多尺度特性使得长期时间序列预测具有挑战性。传统方法局限于时域操作，而傅里叶变换获得的全局频率信息被视为平稳信号，会模糊瞬态事件的时间模式。误差累积也会导致预测质量随预测时间延长而下降。

Method: AWEMixer包含两个创新组件：1）频率路由器，利用快速傅里叶变换获得的全局周期性模式自适应加权局部小波子带；2）相干门控融合块，通过交叉注意力和门控机制实现突出频率特征与多尺度时间表示的选择性集成，在保持对噪声鲁棒性的同时实现精确的时频定位。

Result: 在七个公开基准测试中，AWEMixer比最近的最先进模型更有效。与基于Transformer和基于MLP的最先进模型相比，在长序列时间序列预测中持续实现性能提升。

Conclusion: AWEMixer通过结合全局频率信息和局部小波分析，有效解决了物联网环境中长期时间序列预测的挑战，在多个基准测试中表现出优于现有方法的性能。

Abstract: Forecasting long-term time series in IoT environments remains a significant
challenge due to the non-stationary and multi-scale characteristics of sensor
signals. Furthermore, error accumulation causes a decrease in forecast quality
when predicting further into the future. Traditional methods are restricted to
operate in time-domain, while the global frequency information achieved by
Fourier transform would be regarded as stationary signals leading to blur the
temporal patterns of transient events. We propose AWEMixer, an Adaptive
Wavelet-Enhanced Mixer Network including two innovative components: 1) a
Frequency Router designs to utilize the global periodicity pattern achieved by
Fast Fourier Transform to adaptively weight localized wavelet subband, and 2) a
Coherent Gated Fusion Block to achieve selective integration of prominent
frequency features with multi-scale temporal representation through
cross-attention and gating mechanism, which realizes accurate time-frequency
localization while remaining robust to noise. Seven public benchmarks validate
that our model is more effective than recent state-of-the-art models.
Specifically, our model consistently achieves performance improvement compared
with transformer-based and MLP-based state-of-the-art models in long-sequence
time series forecasting. Code is available at
https://github.com/hit636/AWEMixer

</details>


### [5] [Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques](https://arxiv.org/abs/2511.04971)
*Esha Chowdhury*

Main category: cs.LG

TL;DR: 本研究提出了一种结合机器学习和混合深度学习方法的心血管疾病风险预测模型，专门针对糖尿病患者。使用BRFSS数据集，XGBoost和LSTM模型均达到了0.9050的最高准确率，部分模型实现了完美的召回率。


<details>
  <summary>Details</summary>
Motivation: 糖尿病与心脏病之间存在强关联，且糖尿病患病率不断增长，因此需要开发高效的心血管疾病风险预测模型来改善医疗决策。

Method: 使用BRFSS数据集，进行数据预处理（去重、处理缺失值、特征识别）和PCA特征提取。评估了多种ML模型（DT、RF、KNN、SVM、AdaBoost、XGBoost）和DL模型（ANN、DNN、RNN、CNN、LSTM、BiLSTM、GRU），以及CNN与LSTM、BiLSTM、GRU的混合模型。

Result: XGBoost和LSTM模型均达到最高准确率0.9050，部分模型实现了完美召回率1.00。高准确率和F1分数证明了这些模型的有效性。

Conclusion: 机器学习和深度学习模型在预测糖尿病患者心血管疾病风险方面具有显著效果，能够自动化和增强临床决策，改善个性化风险管理和预防策略。

Abstract: Accurate prediction of cardiovascular disease (CVD) risk is crucial for
healthcare institutions. This study addresses the growing prevalence of
diabetes and its strong link to heart disease by proposing an efficient CVD
risk prediction model for diabetic patients using machine learning (ML) and
hybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by
removing duplicates, handling missing values, identifying categorical and
numerical features, and applying Principal Component Analysis (PCA) for feature
extraction. Several ML models, including Decision Trees (DT), Random Forest
(RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and
XGBoost, were implemented, with XGBoost achieving the highest accuracy of
0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep
Neural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural
Networks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and
Gated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM,
BiLSTM, and GRU, were also explored. Some of these models achieved perfect
recall (1.00), with the LSTM model achieving the highest accuracy of 0.9050.
Our research highlights the effectiveness of ML and DL models in predicting CVD
risk among diabetic patients, automating and enhancing clinical
decision-making. High accuracy and F1 scores demonstrate these models'
potential to improve personalized risk management and preventive strategies.

</details>


### [6] [OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](https://arxiv.org/abs/2511.05028)
*Dongjin Park,Hasung Yeo,Joon-Woo Lee*

Main category: cs.LG

TL;DR: OvA-LP是一个用于联邦微调(FFT)的简约框架，通过线性探测和一对多头部设计，在源头上抑制客户端数据分布不均导致的局部漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦微调方法在异构客户端数据分布下容易产生局部漂移，导致全局模型出现系统性偏差和方差放大，现有的事后校正方法在极端非IID条件下表现脆弱。

Method: OvA-LP结合冻结编码器上的线性探测与一对多头部设计，采用两阶段程序，保留预训练特征几何结构并解耦逻辑值，防止漂移放大机制。

Result: 在CIFAR-100数据集上，OvA-LP在非IID条件下保持95.9%的IID准确率，而现有最佳方法PFPT和FFT-MoE仅分别保持10.1%和34.5%。该方法还对标签噪声具有鲁棒性，且计算成本几乎与编码器大小无关。

Conclusion: OvA-LP为异构环境下的鲁棒联邦微调提供了原则性和高效的基础框架。

Abstract: Federated fine-tuning (FFT) adapts foundation models to decentralized data
but remains fragile under heterogeneous client distributions due to local
drift, i.e., client-level update divergences that induce systematic bias and
amplified variance in the global model. Existing aggregation and
personalization methods largely correct drift post hoc, which proves brittle
under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework
that is, to our knowledge, the first explicitly designed to suppress drift at
its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing
on a frozen encoder with a one-vs-all head and a simple two-stage procedure,
preserving pretrained feature geometry and decoupling logits to prevent the
mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over
shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of
its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%
(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains
resilience under both symmetric and asymmetric label noise. In addition,
precomputing encoder features makes per-round cost nearly independent of
encoder size. Together, these results demonstrate that OvA-LP provides a
principled and efficient basis for robust FFT under heterogeneity.

</details>


### [7] [Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting](https://arxiv.org/abs/2511.05289)
*Marius Fracarolli,Michael Staniek,Stefan Riezler*

Main category: cs.LG

TL;DR: 本研究探讨了数据增强如何减轻时间序列预测模型中的成员推理攻击，发现通过ZOO-PCA方法生成的合成数据能显著降低攻击者的真阳性/假阳性比率，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 在电子健康记录时间序列预测任务中，需要在强隐私保护和高预测性能之间取得平衡。成员推理攻击会泄露训练数据隐私，因此需要找到有效防御方法。

Method: 研究了多种数据增强策略：零阶优化(ZOO)、基于主成分分析的ZOO变体(ZOO-PCA)和MixUp方法，通过生成与原始训练数据相似但包含足够新颖性的合成样本来增强模型鲁棒性。

Result: 实验结果显示，ZOO-PCA方法在成员推理攻击中实现了最佳的TPR/FPR比率降低效果，同时没有牺牲测试数据的预测性能。

Conclusion: 数据增强特别是ZOO-PCA方法能有效防御成员推理攻击，在保护隐私的同时维持时间序列预测模型的准确性。

Abstract: Balancing strong privacy guarantees with high predictive performance is
critical for time series forecasting (TSF) tasks involving Electronic Health
Records (EHR). In this study, we explore how data augmentation can mitigate
Membership Inference Attacks (MIA) on TSF models. We show that retraining with
synthetic data can substantially reduce the effectiveness of loss-based MIAs by
reducing the attacker's true-positive to false-positive ratio. The key
challenge is generating synthetic samples that closely resemble the original
training data to confuse the attacker, while also introducing enough novelty to
enhance the model's ability to generalize to unseen data. We examine multiple
augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO
constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to
strengthen model resilience without sacrificing accuracy. Our experimental
results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA
attacks without sacrificing performance on test data.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [8] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 本文提出了一种获取中文常见情感事件的方法，通过收集情感事件指示词，使用中文大语言模型生成情感事件，训练过滤器确保质量，最终构建了包含102,218个高质量情感事件的知识库。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识对提升应用效果很重要，但难以获取，特别是与上下文无关的常见情感事件。本文旨在获取中文常见情感事件如'获奖'和'被批评'。

Method: 收集中文情感事件指示词列表，使用中文大语言模型生成情感事件，训练过滤器剔除无效结果，使用不同技术将情感事件分类为积极事件和消极事件。

Result: 构建了包含102,218个高质量常见情感事件的知识库，这是唯一大规模的中文情感事件常识知识库。内在评估显示方法有效，外在用例展示了在情感原因提取领域的潜力。

Conclusion: 本文方法能有效获取中文常见情感事件，构建的知识库对情感相关应用具有重要价值，相关资源将在论文发表后发布。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [9] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 提出了MIMIC-SR-ICD11数据集和LL-Rank重排序框架，用于基于临床报告进行疾病诊断，通过似然重排序方法显著提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 疾病诊断是现代医疗的核心，但电子健康记录(EHR)文档往往会丢失临床重要信号。自述报告能保留这些被模板化EHR衰减或遗漏的细微但重要的细节。

Method: 引入MIMIC-SR-ICD11数据集，并提出LL-Rank框架——一种基于似然的重排序方法，计算给定临床报告上下文的每个标签的长度归一化联合似然，并减去相应的无报告先验似然。

Result: 在七个模型骨干上，LL-Rank始终优于强大的生成加映射基线(GenMap)。消融实验表明LL-Rank的改进主要来自其基于PMI的评分，该评分将语义兼容性与标签频率偏差分离开来。

Conclusion: LL-Rank框架通过似然重排序有效提升了临床诊断的准确性，特别是通过PMI评分机制解决了标签频率偏差问题。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [10] [Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space](https://arxiv.org/abs/2511.05203)
*Linus Nwankwo,Björn Ellensohn,Christian Rauch,Elmar Rueckert*

Main category: cs.RO

TL;DR: 提出共生交互学习(SIL)方法，使人类和具身智能体在共享潜在任务空间中共同适应，超越传统主从模式，实现双向交互学习。


<details>
  <summary>Details</summary>
Motivation: 当前自主智能体虽然能理解自然语言指令并执行长程任务，但采用的主从交互模式缺乏人类间多轮交互的共适应动态特性，限制了交互的自然性和效率。

Method: 将SIL形式化为共享潜在任务空间中的共适应过程，使用预训练基础模型进行空间感知和推理，结合轻量级潜在编码器和记忆架构防止任务表示遗忘。

Result: 在模拟和真实世界具身任务中验证了SIL的有效性，包括指令跟随、信息检索、查询导向推理和交互对话等场景。

Conclusion: SIL方法使智能体从被动执行转向主动澄清、适应性建议和共享计划细化，实现了更自然、高效的人机交互。

Abstract: Today's autonomous agents can understand free-form natural language
instructions and execute long-horizon tasks in a manner akin to human-level
reasoning. These capabilities are mostly driven by large-scale pre-trained
foundation models (FMs). However, the approaches with which these models are
grounded for human-robot interaction (HRI) perpetuate a master-apprentice
model, where the apprentice (embodied agent) passively receives and executes
the master's (human's) commands without reciprocal learning. This reactive
interaction approach does not capture the co-adaptive dynamics inherent in
everyday multi-turn human-human interactions. To address this, we propose a
Symbiotic Interactive Learning (SIL) approach that enables both the master and
the apprentice to co-adapt through mutual, bidirectional interactions. We
formalised SIL as a co-adaptation process within a shared latent task space,
where the agent and human maintain joint belief states that evolve based on
interaction history. This enables the agent to move beyond reactive execution
to proactive clarification, adaptive suggestions, and shared plan refinement.
To realise these novel behaviours, we leveraged pre-trained FMs for spatial
perception and reasoning, alongside a lightweight latent encoder that grounds
the models' outputs into task-specific representations. Furthermore, to ensure
stability as the tasks evolve, we augment SIL with a memory architecture that
prevents the forgetting of learned task-space representations. We validate SIL
on both simulated and real-world embodied tasks, including instruction
following, information retrieval, query-oriented reasoning, and interactive
dialogues. Demos and resources are public
at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

</details>
