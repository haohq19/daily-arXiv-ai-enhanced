<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts](https://arxiv.org/abs/2601.08881)
*Yu Xu,Hongbin Yan,Juan Cao,Yiji Cheng,Tiankai Hang,Runze He,Zijin Yin,Shiyi Zhang,Yuxin Zhang,Jintao Li,Chunyu Wang,Qinglin Lu,Tong-Yee Lee,Fan Tang*

Main category: cs.CV

TL;DR: 提出一种在稀疏混合专家模型中注入语义意图的新框架，通过层次化任务语义标注和预测对齐正则化，使路由决策与高层任务语义对齐，有效缓解图像生成与编辑中的任务干扰问题。


<details>
  <summary>Details</summary>
Motivation: 统一的图像生成和编辑模型在密集扩散变换器架构中存在严重的任务干扰问题，共享参数空间需要在冲突目标（如局部编辑与主体驱动生成）之间妥协。虽然稀疏混合专家范式是有前景的解决方案，但其门控网络仍然是任务无关的，仅基于局部特征操作，不了解全局任务意图，这阻碍了有意义的专业化并无法解决任务干扰。

Method: 提出一个新颖框架，将语义意图注入MoE路由中。引入层次化任务语义标注方案来创建结构化任务描述符（如范围、类型、保留要求）。设计预测对齐正则化，使内部路由决策与任务的高层语义对齐，将门控网络从任务无关执行器演变为调度中心。

Result: 模型有效缓解了任务干扰，在保真度和质量方面优于密集基线模型。分析表明，专家自然发展出清晰且语义相关的专业化能力。

Conclusion: 通过将语义意图注入MoE路由，提出的框架成功解决了图像生成和编辑模型中的任务干扰问题，使稀疏混合专家模型能够实现有意义的任务专业化，提高了模型性能。

Abstract: Unified image generation and editing models suffer from severe task interference in dense diffusion transformers architectures, where a shared parameter space must compromise between conflicting objectives (e.g., local editing v.s. subject-driven generation). While the sparse Mixture-of-Experts (MoE) paradigm is a promising solution, its gating networks remain task-agnostic, operating based on local features, unaware of global task intent. This task-agnostic nature prevents meaningful specialization and fails to resolve the underlying task interference. In this paper, we propose a novel framework to inject semantic intent into MoE routing. We introduce a Hierarchical Task Semantic Annotation scheme to create structured task descriptors (e.g., scope, type, preservation). We then design Predictive Alignment Regularization to align internal routing decisions with the task's high-level semantics. This regularization evolves the gating network from a task-agnostic executor to a dispatch center. Our model effectively mitigates task interference, outperforming dense baselines in fidelity and quality, and our analysis shows that experts naturally develop clear and semantically correlated specializations.

</details>


### [2] [Hybrid guided variational autoencoder for visual place recognition](https://arxiv.org/abs/2601.09248)
*Ni Wang,Zihan You,Emre Neftci,Thorben Schoepe*

Main category: cs.CV

TL;DR: 提出一种基于事件相机和变分自编码器的视觉地点识别方法，使用脉冲神经网络编码器，在室内环境中实现高效、鲁棒的地点识别，具有良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车、机器人和无人机需要在GPS受限的室内环境中精确定位。现有视觉地点识别模型要么内存占用大难以移动部署，要么紧凑模型缺乏鲁棒性和泛化能力。

Method: 结合事件相机和引导变分自编码器，编码器采用脉冲神经网络模型，兼容低功耗神经形态硬件。在新建的室内VPR数据集上训练，成功解耦16个不同地点的视觉特征。

Result: 模型分类性能与最先进方法相当，在不同光照条件下表现鲁棒。对未知场景的新视觉输入也能区分不同地点，展示了通过学习地点本质特征的高泛化能力。

Conclusion: 紧凑、鲁棒且具有泛化能力的引导VAE为视觉地点识别提供了有前景的模型，可显著增强移动机器人在已知和未知室内环境中的导航能力。

Abstract: Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of our model is based on a spiking neural network model which is compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in our new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while, showing robust performance also under various illumination conditions. When tested with novel visual inputs from unknown scenes, our model can distinguish between these places, which demonstrates a high generalization capability by learning the essential features of location. Our compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [DriftGuard: A Hierarchical Framework for Concept Drift Detection and Remediation in Supply Chain Forecasting](https://arxiv.org/abs/2601.08928)
*Shahnawaz Alam,Mohammed Abdul Rahman,Bareera Sadeqa*

Main category: cs.LG

TL;DR: DriftGuard是一个端到端的供应链预测漂移管理系统，通过集成多种检测方法、层次传播分析、SHAP根因诊断和成本感知重训练策略，实现早期漂移检测、根因解释和自动修复。


<details>
  <summary>Details</summary>
Motivation: 供应链预测模型会随时间退化（概念漂移），导致库存问题但无系统警告。现有方法仅关注检测，忽略诊断和修复，且未考虑供应链数据的层次结构。需要端到端系统来检测、解释并自动修复漂移。

Method: 提出DriftGuard五模块框架：1）集成四种互补检测方法（基于误差监控、统计检验、自编码器异常检测、CUSUM变点分析）；2）层次传播分析定位产品线漂移位置；3）SHAP分析诊断根因；4）成本感知重训练策略选择性更新受影响模型；5）端到端系统整合。

Result: 在M5零售数据集的30,000多个时间序列上评估，DriftGuard在4.2天内实现97.8%的检测召回率，通过针对性修复获得高达417的投资回报率。

Conclusion: DriftGuard解决了供应链预测中概念漂移的完整生命周期管理问题，提供早期检测、根因解释和自动修复的端到端解决方案，显著优于现有手动监控和定期重训练方法。

Abstract: Supply chain forecasting models degrade over time as real-world conditions change. Promotions shift, consumer preferences evolve, and supply disruptions alter demand patterns, causing what is known as concept drift. This silent degradation leads to stockouts or excess inventory without triggering any system warnings. Current industry practice relies on manual monitoring and scheduled retraining every 3-6 months, which wastes computational resources during stable periods while missing rapid drift events. Existing academic methods focus narrowly on drift detection without addressing diagnosis or remediation, and they ignore the hierarchical structure inherent in supply chain data. What retailers need is an end-to-end system that detects drift early, explains its root causes, and automatically corrects affected models. We propose DriftGuard, a five-module framework that addresses the complete drift lifecycle. The system combines an ensemble of four complementary detection methods, namely error-based monitoring, statistical tests, autoencoder anomaly detection, and Cumulative Sum (CUSUM) change-point analysis, with hierarchical propagation analysis to identify exactly where drift occurs across product lines. Once detected, Shapley Additive Explanations (SHAP) analysis diagnoses the root causes, and a cost-aware retraining strategy selectively updates only the most affected models. Evaluated on over 30,000 time series from the M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.

</details>


### [4] [Physics-Guided Counterfactual Explanations for Large-Scale Multivariate Time Series: Application in Scalable and Interpretable SEP Event Prediction](https://arxiv.org/abs/2601.08999)
*Pranjal Patil,Anli Ji,Berkay Aydin*

Main category: cs.LG

TL;DR: 提出物理引导的反事实解释框架，用于太阳高能粒子事件预测，在保持物理合理性的同时提升解释质量与效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在空间天气预测中表现良好，但缺乏领域特定的可行性约束。反事实解释方法通常忽略物理合理性，难以在实际科学领域应用。

Method: 提出物理引导的反事实解释框架，在时间序列分类任务中生成符合物理原理的反事实解释，应用于太阳高能粒子事件预测。

Result: 相比DiCE等基线方法，动态时间规整距离减少80%以上，反事实解释稀疏性更高，运行时间减少近50%，且确保物理合理性和可操作性。

Conclusion: 该框架生成既有效又物理一致的反事实解释，为大数据环境中的可扩展反事实生成奠定基础，提升科学领域模型的可解释性和实用性。

Abstract: Accurate prediction of solar energetic particle events is vital for safeguarding satellites, astronauts, and space-based infrastructure. Modern space weather monitoring generates massive volumes of high-frequency, multivariate time series (MVTS) data from sources such as the Geostationary perational Environmental Satellites (GOES). Machine learning (ML) models trained on this data show strong predictive power, but most existing methods overlook domain-specific feasibility constraints. Counterfactual explanations have emerged as a key tool for improving model interpretability, yet existing approaches rarely enforce physical plausibility. This work introduces a Physics-Guided Counterfactual Explanation framework, a novel method for generating counterfactual explanations in time series classification tasks that remain consistent with underlying physical principles. Applied to solar energetic particles (SEP) forecasting, this framework achieves over 80% reduction in Dynamic Time Warping (DTW) distance increasing the proximity, produces counterfactual explanations with higher sparsity, and reduces runtime by nearly 50% compared to state-of-the-art baselines such as DiCE. Beyond numerical improvements, this framework ensures that generated counterfactual explanations are physically plausible and actionable in scientific domains. In summary, the framework generates counterfactual explanations that are both valid and physically consistent, while laying the foundation for scalable counterfactual generation in big data environments.

</details>


### [5] [Interpretable Probability Estimation with LLMs via Shapley Reconstruction](https://arxiv.org/abs/2601.09151)
*Yang Nan,Qihao Wen,Jiahao Wang,Pengfei He,Ravi Tandon,Yong Ge,Han Xu*

Main category: cs.LG

TL;DR: PRISM框架通过Shapley值分解LLM的概率估计，提高预测准确性和透明度


<details>
  <summary>Details</summary>
Motivation: LLM具有估计不确定事件概率的潜力，但直接提示存在输出噪声大、预测过程不透明的挑战，需要提高概率估计的准确性和可解释性

Method: 提出PRISM框架：使用Shapley值量化每个输入因素的边际贡献，然后聚合这些因素级贡献来重构校准后的最终估计

Result: PRISM在金融、医疗、农业等多个领域优于直接提示和其他基线方法，提高了预测准确性，同时提供了透明的预测流程

Conclusion: PRISM框架为LLM概率估计带来了透明度和精确性，有助于建立对基于LLM的决策支持系统的信任

Abstract: Large Language Models (LLMs) demonstrate potential to estimate the probability of uncertain events, by leveraging their extensive knowledge and reasoning capabilities. This ability can be applied to support intelligent decision-making across diverse fields, such as financial forecasting and preventive healthcare. However, directly prompting LLMs for probability estimation faces significant challenges: their outputs are often noisy, and the underlying predicting process is opaque. In this paper, we propose PRISM: Probability Reconstruction via Shapley Measures, a framework that brings transparency and precision to LLM-based probability estimation. PRISM decomposes an LLM's prediction by quantifying the marginal contribution of each input factor using Shapley values. These factor-level contributions are then aggregated to reconstruct a calibrated final estimate. In our experiments, we demonstrate PRISM improves predictive accuracy over direct prompting and other baselines, across multiple domains including finance, healthcare, and agriculture. Beyond performance, PRISM provides a transparent prediction pipeline: our case studies visualize how individual factors shape the final estimate, helping build trust in LLM-based decision support systems.

</details>


### [6] [From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences](https://arxiv.org/abs/2601.09220)
*Xinzi Tan,Kejian Zhang,Junhan Yu,Doudou Zhou*

Main category: cs.LG

TL;DR: 提出Hawkes Attention，从多元Hawkes过程理论推导的新型注意力算子，用可学习的每类型神经核调制查询、键和值投影，替代传统注意力，统一事件时间和内容交互，在MTPP中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的方法主要通过位置编码注入时间信息，依赖共享或参数化衰减结构，限制了捕捉异构和类型特定时间效应的能力。

Method: 从多元Hawkes过程理论推导Hawkes Attention算子，使用可学习的每类型神经核调制查询、键和值投影，替代传统注意力相应部分，统一事件时间和内容交互。

Result: 实验结果显示该方法相比基线获得更好性能，除了通用MTPP外，注意力机制也能轻松应用于特定时间结构如时间序列预测。

Conclusion: Hawkes Attention通过从Hawkes过程理论推导，用可学习神经核调制注意力机制，有效捕捉异构时间效应和类型特定激发模式，在MTPP任务中表现优异。

Abstract: Marked Temporal Point Processes (MTPPs) arise naturally in medical, social, commercial, and financial domains. However, existing Transformer-based methods mostly inject temporal information only via positional encodings, relying on shared or parametric decay structures, which limits their ability to capture heterogeneous and type-specific temporal effects. Inspired by this observation, we derive a novel attention operator called Hawkes Attention from the multivariate Hawkes process theory for MTPP, using learnable per-type neural kernels to modulate query, key and value projections, thereby replacing the corresponding parts in the traditional attention. Benefited from the design, Hawkes Attention unifies event timing and content interaction, learning both the time-relevant behavior and type-specific excitation patterns from the data. The experimental results show that our method achieves better performance compared to the baselines. In addition to the general MTPP, our attention mechanism can also be easily applied to specific temporal structures, such as time series forecasting.

</details>


### [7] [Energy-Entropy Regularization: The True Power of Minimal Looped Transformers](https://arxiv.org/abs/2601.09588)
*Wai-Lun Lam*

Main category: cs.LG

TL;DR: 提出基于Tsallis熵和哈密顿动力学的训练框架，成功训练单头循环Transformer解决归纳头任务，揭示了其推理能力的内部机制。


<details>
  <summary>Details</summary>
Motivation: 当前单头循环Transformer在基准任务上训练经常失败或性能不佳，原因是损失函数高度非凸且不规则，优化容易陷入局部极小值和鞍点，且其内部机制不明确，从头训练具有挑战性。

Method: 提出新颖的训练框架，利用Tsallis熵和哈密顿动力学来转换损失函数的地形几何。将参数更新视为物理流动，成功训练了模型维度d=8的单头循环Transformer。

Result: 成功训练单头循环Transformer解决输入序列长度为1000个token的归纳头任务，揭示了其优越推理能力背后的内部机制。

Conclusion: 通过Tsallis熵和哈密顿动力学转换损失函数地形的方法，能够有效训练单头循环Transformer，解决了传统优化方法面临的困难，并揭示了这类模型的内部工作机制。

Abstract: Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The internal mechanisms of these single-head looped transformer models remain poorly understood, and training them from scratch remains a significant challenge. In this paper, we propose a novel training framework that leverages Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape. By treating the parameter updates as a physical flow, we successfully trained a single-head looped Transformer with model dimension $d = 8$ to solve induction head task with input sequence length of 1000 tokens. This success reveals the internal mechanism behind the superior reasoning capability.

</details>


### [8] [From Prompt to Protocol: Fast Charging Batteries with Large Language Models](https://arxiv.org/abs/2601.09626)
*Ge Lei,Ferran Brosa Planella,Sterling G. Baird,Samuel J. Cooper*

Main category: cs.LG

TL;DR: LLM驱动的电池充电协议优化方法P2O和P2P，相比传统方法在相同评估预算下实现约4.2%的健康状态提升。


<details>
  <summary>Details</summary>
Motivation: 电池充电协议优化面临评估缓慢、成本高、不可微分的挑战，现有方法过度约束搜索空间限制了协议多样性，阻碍了高性能解决方案的发现。

Method: 提出两种无梯度、LLM驱动的闭环方法：P2O使用LLM生成小型神经网络协议代码并通过内循环训练；P2P直接编写电流的显式函数及其标量参数。

Result: LLM引导的P2O在多个案例中优于贝叶斯优化、进化算法和随机搜索设计的神经网络；在快速充电场景中，P2O和P2P相比最先进的多步恒流基线实现了约4.2%的健康状态提升。

Conclusion: LLM能够扩展协议函数形式空间，整合基于语言的约束，并在高成本实验设置中实现高效优化。

Abstract: Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model](https://arxiv.org/abs/2601.09100)
*Lixiang Zhang,Chenggong Zhao,Qing Gao,Xiaoke Zhao,Gengyi Bai,Jinhu Lv*

Main category: cs.AI

TL;DR: 本文提出DScheLLM，一种基于微调大语言模型的双系统（快-慢）推理架构，用于处理动态生产调度中的各类扰动，在标准作业车间调度基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统生产调度方法对动态扰动（如加工时间变化、机器可用性变化、意外任务插入）的适应性有限，通常依赖特定事件模型和显式分析公式，难以泛化到未见过的扰动情况。

Method: 构建统一的大语言模型框架处理动态事件，使用运筹学求解器获得的精确调度生成快慢推理模式的训练数据集，基于华为OpenPangu Embedded-7B模型，采用LoRA技术在混合推理范式下进行微调。

Result: 在标准作业车间调度基准上的实验评估表明，快思考模式能高效生成高质量调度方案，慢思考模式能产生与求解器兼容且格式良好的决策输入。

Conclusion: 这是最早将大语言模型应用于动态环境作业车间调度的研究之一，凸显了大语言模型在智能自适应调度优化中的巨大潜力。

Abstract: Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.

</details>


### [10] [STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models](https://arxiv.org/abs/2601.09281)
*Jingjing Zhou,Gaoxiang Cong,Li Su,Liang Li*

Main category: cs.AI

TL;DR: STaR是一个无需参数的推理时遗忘框架，专门针对大型推理模型中的隐私保护问题，通过语义检测、安全提示前缀、轨迹感知抑制和自适应过滤等技术，在推理过程中全面移除敏感信息。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型能够生成复杂的思维链轨迹，但这也带来了严重的隐私风险，敏感信息可能深嵌于推理过程中。现有的LLM遗忘方法通常只修改最终答案，无法移除中间步骤的敏感内容，导致持续的隐私泄露和安全问题。

Method: STaR框架包含四个关键步骤：1) 语义感知检测识别敏感内容；2) 通过安全提示前缀注入全局安全约束；3) 轨迹感知抑制动态阻断整个推理链中的敏感内容；4) 令牌级自适应过滤防止生成精确和转述的敏感令牌。此外还提出了两个新评估指标：多解码一致性评估和多粒度成员推理攻击评估。

Result: 在R-TOFU基准测试上的实验表明，STaR实现了全面稳定的遗忘效果，同时保持了最小的效用损失，为LRMs中的隐私保护推理设立了新标准。

Conclusion: STaR框架有效解决了大型推理模型中的隐私保护挑战，通过推理时的轨迹级遗忘机制，在保持模型效用的同时实现了全面的隐私保护，为隐私保护推理提供了新的解决方案。

Abstract: Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.

</details>


### [11] [Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments](https://arxiv.org/abs/2601.09382)
*Qinglong Shi,Donghai Wang,Hantao Zhou,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.AI

TL;DR: 提出主动式任务导向智能体新范式，通过意图条件监控和事件触发跟进，解决现有LLM智能体在动态环境中长期意图保持的不足，并创建ChronosBench基准验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型智能体主要采用被动响应范式，只能在短期会话中响应用户即时查询，无法在动态环境中长期保持用户意图并适应环境变化，这限制了智能体的实际应用能力。

Method: 提出主动式任务导向智能体新范式，包含两个核心能力：1）意图条件监控：智能体基于对话历史自主制定触发条件；2）事件触发跟进：检测到有用环境更新时主动与用户互动。同时构建高质量数据合成管道生成动态环境中的复杂多轮对话数据，并创建ChronosBench基准进行评估。

Result: 使用合成数据进行监督学习微调的模型在包含用户意图转变的复杂任务中达到85.19%的任务完成率，优于其他测试模型。同时揭示了当前领先闭源和开源模型在长期任务导向交互中的缺陷。

Conclusion: 提出的主动式智能体范式和数据驱动策略有效解决了动态环境中长期任务导向交互的挑战，验证了意图条件监控和事件触发跟进机制的重要性，为未来智能体发展提供了新方向。

Abstract: Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.

</details>


### [12] [Automating Supply Chain Disruption Monitoring via an Agentic AI Approach](https://arxiv.org/abs/2601.09680)
*Sara AlMahri,Liming Xu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: 提出一个基于多智能体AI的供应链风险监控框架，能够自动检测、分析和应对多层级供应链中断，相比传统人工分析将响应时间缩短三个数量级。


<details>
  <summary>Details</summary>
Motivation: 现代供应链面临地缘政治、需求冲击、贸易限制和自然灾害等多种中断风险，但大多数公司缺乏一级供应商之外的可见性，无法及时发现上游漏洞，导致中断影响向下游级联传播。

Method: 引入一个最小监督的智能体AI框架，包含七个由大语言模型和确定性工具驱动的专业智能体，共同从非结构化新闻中检测中断信号，将其映射到多层级供应商网络，基于网络结构评估暴露风险，并推荐缓解措施如替代采购选项。

Result: 在30个合成场景（涵盖三家汽车制造商和五类中断）中评估，系统在核心任务上达到高准确率（F1分数0.962-0.991），端到端分析平均耗时3.83分钟，每次中断成本0.0836美元。相比行业基准（多日的人工驱动评估），响应时间缩短三个数量级以上。2022年俄乌冲突的真实案例进一步证明了操作适用性。

Conclusion: 这项工作为构建能够管理深层网络中断的弹性、主动和自主供应链奠定了基础，实现了从被动恢复到主动弹性的转变。

Abstract: Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [SITA: Learning Speaker-Invariant and Tone-Aware Speech Representations for Low-Resource Tonal Languages](https://arxiv.org/abs/2601.09050)
*Tianyi Xu,Xuan Ouyang,Binwei Yao,Shoua Xiong,Sara Misurelli,Maichou Lor,Junjie Hu*

Main category: cs.CL

TL;DR: SITA是一种轻量级适配方法，通过强制说话人不变性和音调感知来改进预训练语音编码器对低资源声调语言的处理能力。


<details>
  <summary>Details</summary>
Motivation: 声调低资源语言在现代语音技术中服务不足，现有模型难以在保持说话人不变性的同时有效捕捉音调信息，导致词汇意义混淆。

Method: 采用分阶段多目标训练：1)跨性别对比学习促进词汇一致性，音调排斥损失防止音调崩溃；2)基于CTC的ASR目标与蒸馏稳定识别相关结构。

Result: 在苗语（高度声调且资源严重不足）上，SITA提高了跨性别词汇检索准确率，同时保持可用的ASR准确率；在普通话上也观察到类似改进。

Conclusion: SITA是一种通用、即插即用的方法，可用于将多语言语音编码器适配到声调语言，有效解决低资源声调语言的语音表示问题。

Abstract: Tonal low-resource languages are widely spoken yet remain underserved by modern speech technology. A key challenge is learning representations that are robust to nuisance variation such as gender while remaining tone-aware for different lexical meanings. To address this, we propose SITA, a lightweight adaptation recipe that enforces Speaker-Invariance and Tone-Awareness for pretrained wav2vec-style encoders. SITA uses staged multi-objective training: (i) a cross-gender contrastive objective encourages lexical consistency across speakers, while a tone-repulsive loss prevents tone collapse by explicitly separating same-word different-tone realizations; and (ii) an auxiliary Connectionist Temporal Classification (CTC)-based ASR objective with distillation stabilizes recognition-relevant structure. We evaluate primarily on Hmong, a highly tonal and severely under-resourced language where off-the-shelf multilingual encoders fail to represent tone effectively. On a curated Hmong word corpus, SITA improves cross-gender lexical retrieval accuracy, while maintaining usable ASR accuracy relative to an ASR-adapted XLS-R teacher. We further observe similar gains when transferring the same recipe to Mandarin, suggesting SITA is a general, plug-in approach for adapting multilingual speech encoders to tonal languages.

</details>


### [14] [ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection](https://arxiv.org/abs/2601.09195)
*Tao Liu,Taiqiang Wu,Runming Yang,Shaoning Sun,Junjie Wang,Yujiu Yang*

Main category: cs.CL

TL;DR: ProFit通过选择性掩码低概率token来缓解SFT中的单参考过拟合问题，提升LLM对齐效果


<details>
  <summary>Details</summary>
Motivation: 传统SFT使用单一参考答案，忽略了语言的一对多特性，导致模型过度拟合非核心表达。虽然多参考答案可以缓解此问题，但数据计算成本过高，需要更高效的方法来缓解单参考过拟合

Method: 提出ProFit方法：基于token概率与语义重要性的内在联系，选择性掩码低概率token（通常是可替换表达），防止表面层过拟合，同时保留高概率token（承载核心逻辑框架）

Result: 在通用推理和数学基准测试中，ProFit一致优于传统SFT基线方法

Conclusion: 通过利用token概率与语义重要性的相关性，ProFit有效缓解了SFT中的单参考过拟合问题，为LLM对齐提供了一种高效且有效的方法

Abstract: Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. However, traditional SFT often ignores the one-to-many nature of language by forcing alignment with a single reference answer, leading to the model overfitting to non-core expressions. Although our empirical analysis suggests that introducing multiple reference answers can mitigate this issue, the prohibitive data and computational costs necessitate a strategic shift: prioritizing the mitigation of single-reference overfitting over the costly pursuit of answer diversity. To achieve this, we reveal the intrinsic connection between token probability and semantic importance: high-probability tokens carry the core logical framework, while low-probability tokens are mostly replaceable expressions. Based on this insight, we propose ProFit, which selectively masks low-probability tokens to prevent surface-level overfitting. Extensive experiments confirm that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.

</details>


### [15] [Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs](https://arxiv.org/abs/2601.09365)
*Biswesh Mohapatra,Théo Charlot,Giovanni Duca,Mayank Palan,Laurent Romary,Justine Cassell*

Main category: cs.CL

TL;DR: 该论文研究如何在情境对话中显式表示和存储共同基础，以支持后续的实体关系引用，并提出了改进共同基础建立和利用的方法。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明LLMs能够执行澄清请求或确认等基础行为，但缺乏对共同基础如何显式表示和存储以供后续使用的研究。没有这样的机制，无法确定确认或澄清行为是否真正反映基于共同基础的理解。

Method: 在情境对话中评估模型通过关系引用建立和利用共同基础的能力，测试多种共同基础表示方法，并提出改进共同基础建立和后续使用的方法。

Result: 论文评估了模型在情境对话中建立和利用共同基础的能力，并提出了改进方法，但摘要中未提供具体的实验结果数据。

Conclusion: 需要显式表示和存储共同基础机制来确保对话系统真正理解情境，提出的方法有助于改进对话系统在情境对话中的共同基础处理能力。

Abstract: Common ground plays a critical role in situated spoken dialogues, where interlocutors must establish and maintain shared references to entities, events, and relations to sustain coherent interaction. For dialog systems, the ability to correctly ground conversational content in order to refer back to it later is particularly important. Prior studies have demonstrated that LLMs are capable of performing grounding acts such as requesting clarification or producing acknowledgments, yet relatively little work has investigated how common ground can be explicitly represented and stored for later use. Without such mechanisms, it remains unclear whether acknowledgment or clarification behaviors truly reflect a grounded understanding. In this work, we evaluate a model's ability to establish and exploit common ground through relational references to entities within the shared context in a situational dialogue. We test multiple methods for representing common ground in situated dialogues and further propose approaches to improve both the establishment of common ground and its subsequent use in the conversation.

</details>


### [16] [The Imperfective Paradox in Large Language Models](https://arxiv.org/abs/2601.09373)
*Bolei Ma,Yusuke Miyao*

Main category: cs.CL

TL;DR: LLMs在处理进行时悖论时表现出系统性目标导向偏见，倾向于幻觉目标事件的完成，缺乏真正的体态语义理解。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正理解事件的组合语义，还是仅仅依赖表面概率启发式。通过进行时悖论这一逻辑现象来测试模型对体态语义的掌握程度。

Method: 引入ImperfectiveNLI诊断数据集，评估最先进的开源模型在处理进行时悖论时的表现。通过表示分析研究内部嵌入特征，并尝试基于提示的干预方法。

Result: 发现普遍存在的目标导向偏见：模型系统性幻觉目标导向事件的完成，经常覆盖明确的文本否定。表示分析显示内部嵌入能区分过程和结果，但推理决策被强烈的目标达成先验主导。提示干预能减少幻觉完成，但也会增加对有效蕴涵的错误拒绝。

Conclusion: 当前LLMs缺乏结构性体态意识，作为预测性叙事引擎而非忠实逻辑推理器运行，未能真正理解进行时悖论所体现的体态语义区别。

Abstract: Do Large Language Models (LLMs) genuinely grasp the compositional semantics of events, or do they rely on surface-level probabilistic heuristics? We investigate the Imperfective Paradox, a logical phenomenon where the past progressive aspect entails event realization for activities (e.g., running $\to$ ran) but not for accomplishments (e.g., building $\nrightarrow$ built). We introduce ImperfectiveNLI, a diagnostic dataset designed to probe this distinction across diverse semantic classes. Evaluating state-of-the-art open-weight models, we uncover a pervasive Teleological Bias: models systematically hallucinate completion for goal-oriented events, often overriding explicit textual negation. Representational analyses show that while internal embeddings often distinguish process from result, inference decisions are dominated by strong priors about goal attainment. We further find that prompting-based interventions reduce hallucinated completions but also increase incorrect rejections of valid entailments. Our findings suggest that current LLMs lack structural aspectual awareness, operating as predictive narrative engines rather than faithful logical reasoners.

</details>


### [17] [Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models](https://arxiv.org/abs/2601.09445)
*Minh Vu Pham,Hsuvas Borkakoty,Yufang Hou*

Main category: cs.CL

TL;DR: 本文提出基于机制可解释性方法的框架，用于定位语言模型中预训练期间产生的内部知识冲突，并展示如何通过因果干预控制推理时的冲突知识。


<details>
  <summary>Details</summary>
Motivation: 语言模型中存在内部知识冲突问题，即同一事件的不一致信息被编码在模型的参数知识中。先前研究主要关注解决模型内部知识与外部资源之间的冲突，而预训练期间产生的内部冲突在模型表示中的定位问题尚未被探索。

Method: 设计基于机制可解释性方法的框架，用于识别预训练数据中的冲突知识在语言模型中的编码位置和方式。利用机制可解释性方法进行因果干预，控制推理时的冲突知识。

Result: 发现语言模型的特定内部组件负责编码预训练中的冲突知识，并证明机制可解释性方法可用于因果干预和控制推理时的冲突知识。

Conclusion: 该研究为理解语言模型中内部知识冲突的编码机制提供了新视角，展示了机制可解释性方法在定位和干预模型内部知识冲突方面的实用价值。

Abstract: In language models (LMs), intra-memory knowledge conflict largely arises when inconsistent information about the same event is encoded within the model's parametric knowledge. While prior work has primarily focused on resolving conflicts between a model's internal knowledge and external resources through approaches such as fine-tuning or knowledge editing, the problem of localizing conflicts that originate during pre-training within the model's internal representations remain unexplored. In this work, we design a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from the pre-training data is encoded within LMs. Our findings contribute to a growing body of evidence that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and we demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping](https://arxiv.org/abs/2601.09578)
*Jiajun Sun,Yangyi Ou,Haoyuan Zheng,Chao yang,Yue Ma*

Main category: cs.RO

TL;DR: 提出一种新颖的语义增强3D点云地图方法，通过融合可见光和红外图像，将热信息作为语义层添加到LiDAR点云地图中，实现环境几何和温度语义的双重理解。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，自主机器人导航和环境感知对SLAM技术提出了更高要求。需要不仅提供几何信息，还能理解环境语义特征（如热源）的地图，以支持灾害评估、工业预防性维护等特定应用。

Method: 1. 在像素级融合可见光和红外图像；2. 将实时LiDAR点云投影到融合图像流上；3. 在热通道中分割热源特征，实时识别高温目标；4. 将温度信息作为语义层应用到最终的3D地图中。

Result: 生成的地图不仅具有精确的几何结构，还包含对环境的语义理解（特别是热源信息），能够实时识别高温目标，为快速灾害评估和工业预防性维护等应用提供重要价值。

Conclusion: 该方法成功地将热信息作为语义层集成到3D点云地图中，实现了几何准确性和语义理解的双重目标，为特定应用场景（如灾害评估和工业维护）提供了更丰富、更有价值的环境感知能力。

Abstract: In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.

</details>
