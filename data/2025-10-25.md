<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 12]
- [cs.CL](#cs.CL) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Filter-Based Reconstruction of Images from Events](https://arxiv.org/abs/2510.20071)
*Bernd Pfrommer*

Main category: cs.CV

TL;DR: 提出FIBAR方法，一种基于滤波器的异步重建方法，用于从移动事件相机的事件重建强度图像，相比神经网络方法更简单且可在CPU上高效运行。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的事件图像重建方法通常需要GPU且复杂，需要一种更简单、可在CPU上高效运行的异步重建方法。

Method: 使用时间数字IIR滤波器整合事件强度变化，通过新颖算法检测过时像素并调节最近更新像素窗口，对过时像素应用高斯滤波以减少重建噪声。

Result: FIBAR在笔记本电脑CPU上以约42-140百万事件/秒的速度运行，重建图像比神经网络方法噪声更大且存在重影，但足以完成某些任务如基准标记检测。

Conclusion: FIBAR提供了一种简单高效的异步事件图像重建替代方案，虽然质量不如神经网络方法，但在某些应用场景下足够使用。

Abstract: Reconstructing an intensity image from the events of a moving event camera is
a challenging task that is typically approached with neural networks deployed
on graphics processing units. This paper presents a much simpler, FIlter Based
Asynchronous Reconstruction method (FIBAR). First, intensity changes signaled
by events are integrated with a temporal digital IIR filter. To reduce
reconstruction noise, stale pixels are detected by a novel algorithm that
regulates a window of recently updated pixels. Arguing that for a moving
camera, the absence of events at a pixel location likely implies a low image
gradient, stale pixels are then blurred with a Gaussian filter. In contrast to
most existing methods, FIBAR is asynchronous and permits image read-out at an
arbitrary time. It runs on a modern laptop CPU at about 42(140) million
events/s with (without) spatial filtering enabled. A few simple qualitative
experiments are presented that show the difference in image reconstruction
between FIBAR and a neural network-based approach (FireNet). FIBAR's
reconstruction is noisier than neural network-based methods and suffers from
ghost images. However, it is sufficient for certain tasks such as the detection
of fiducial markers. Code is available at
https://github.com/ros-event-camera/event_image_reconstruction_fibar

</details>


### [2] [DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering](https://arxiv.org/abs/2510.20285)
*Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu*

Main category: cs.CV

TL;DR: 提出DMC³框架，通过反事实样本构建和对比优化解决第一人称视频问答中的多事件理解和手物交互识别挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了第一人称视角带来的独特挑战，如理解多个事件和识别手物交互。

Method: 包含反事实样本构建模块（通过事件描述改写和核心交互挖掘生成正负样本）和对比优化模块（使用对比损失优化特征距离）。

Result: 在EgoTaskQA的normal和indirect分割上分别达到52.51%和46.04%，在QAEGO4D上达到13.2%，均达到最先进性能。

Conclusion: DMC³框架有效提升了第一人称视频问答的性能，解决了第一人称视角的独特挑战。

Abstract: Egocentric Video Question Answering (Egocentric VideoQA) plays an important
role in egocentric video understanding, which refers to answering questions
based on first-person videos. Although existing methods have made progress
through the paradigm of pre-training and fine-tuning, they ignore the unique
challenges posed by the first-person perspective, such as understanding
multiple events and recognizing hand-object interactions. To deal with these
challenges, we propose a Dual-Modal Counterfactual Contrastive Construction
(DMC$^3$) framework, which contains an egocentric videoqa baseline, a
counterfactual sample construction module and a counterfactual sample-involved
contrastive optimization. Specifically, We first develop a counterfactual
sample construction module to generate positive and negative samples for
textual and visual modalities through event description paraphrasing and core
interaction mining, respectively. Then, We feed these samples together with the
original samples into the baseline. Finally, in the counterfactual
sample-involved contrastive optimization module, we apply contrastive loss to
minimize the distance between the original sample features and the positive
sample features, while maximizing the distance from the negative samples.
Experiments show that our method achieve 52.51\% and 46.04\% on the
\textit{normal} and \textit{indirect} splits of EgoTaskQA, and 13.2\% on
QAEGO4D, both reaching the state-of-the-art performance.

</details>


### [3] [Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation](https://arxiv.org/abs/2510.20596)
*Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: 提出基于相似性原型的跨模态分割框架，通过类别原型学习和相似性约束来解决领域适应问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在面对未见数据时性能会急剧下降，而无监督领域适应可以避免对未见领域进行昂贵标注，同时减少领域差异。

Method: 在嵌入空间中学习类别原型，引入相似性约束使原型对每个语义类别具有代表性且不同类别间可分离；使用字典存储来自不同图像的原型，避免类别缺失问题并实现原型对比学习。

Result: 大量实验表明，该方法比其他最先进方法取得了更好的结果。

Conclusion: 基于相似性原型的跨模态分割框架能够有效解决领域适应问题，提升模型在未见数据上的性能。

Abstract: Deep learning models have achieved great success on various vision
challenges, but a well-trained model would face drastic performance degradation
when applied to unseen data. Since the model is sensitive to domain shift,
unsupervised domain adaptation attempts to reduce the domain gap and avoid
costly annotation of unseen domains. This paper proposes a novel framework for
cross-modality segmentation via similarity-based prototypes. In specific, we
learn class-wise prototypes within an embedding space, then introduce a
similarity constraint to make these prototypes representative for each semantic
class while separable from different classes. Moreover, we use dictionaries to
store prototypes extracted from different images, which prevents the
class-missing problem and enables the contrastive learning of prototypes, and
further improves performance. Extensive experiments show that our method
achieves better results than other state-of-the-art methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications](https://arxiv.org/abs/2510.20019)
*Curtis Lee Shull,Merrick Green*

Main category: cs.LG

TL;DR: 使用监督学习和决策树分类在CAD建模的平面图中对RFID信号进行位置推断，以解决国防资产存储中的安全监控问题。


<details>
  <summary>Details</summary>
Motivation: RFID跟踪技术存在传感器特异性差的问题（如远距离检测、欺骗和伪造漏洞），可能导致错误检测和操作安全事件，需要开发可靠的定位方法。

Method: 采用监督学习模拟，使用真实的RSSI数据和决策树分类，在CAD建模的平面图中对12个实验室区域进行分类，通过类别权重处理类别不平衡问题。

Result: 模型在5000个平衡观测样本上训练，总体准确率为34.2%，多个区域（F、G、H等）的F1分数超过0.40，但稀有类别（特别是LabZoneC）经常被错误分类。

Conclusion: 基于RSSI的决策树可在实际模拟中应用于区域级异常检测或误放监控，通过改进天线布局或增加传感器融合可提升低覆盖区域的分类性能。

Abstract: Radio Frequency Identification (RFID) tracking may be a viable solution for
defense assets that must be stored in accordance with security guidelines.
However, poor sensor specificity (vulnerabilities include long range detection,
spoofing, and counterfeiting) can lead to erroneous detection and operational
security events. We present a supervised learning simulation with realistic
Received Signal Strength Indicator (RSSI) data and Decision Tree classification
in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some
of the challenges encountered in defense storage. In this work, we focused on
classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw
dataset had approximately 980,000 reads. Class frequencies were imbalanced, and
class weights were calculated to account for class imbalance in this
multi-class setting. The model, trained on stratified subsamples to 5,000
balanced observations, yielded an overall accuracy of 34.2% and F1-scores
greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare
classes (most notably LabZoneC) were often misclassified, even with the use of
class weights. An adjacency-aware confusion matrix was calculated to allow
better interpretation of physically adjacent zones. These results suggest that
RSSI-based decision trees can be applied in realistic simulations to enable
zone-level anomaly detection or misplacement monitoring for defense supply
logistics. Reliable classification performance in low-coverage and low-signal
zones could be improved with better antenna placement or additional sensors and
sensor fusion with other modalities.

</details>


### [5] [Speculative Sampling for Parametric Temporal Point Processes](https://arxiv.org/abs/2510.20031)
*Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 提出了一种基于拒绝采样的新算法，能够从现有TPP模型中并行、精确地采样多个未来值，无需架构更改或重新训练


<details>
  <summary>Details</summary>
Motivation: 传统时序点过程模型采用自回归方式采样，效率低下且无法并行化，限制了大规模应用

Method: 基于拒绝采样的并行采样算法，能够同时生成多个未来事件时间点

Result: 在真实数据集上实现了经验加速，同时保持理论保证

Conclusion: 该方法在保持表达性建模的同时，为大规模TPP应用提供了高效的并行生成能力

Abstract: Temporal point processes are powerful generative models for event sequences
that capture complex dependencies in time-series data. They are commonly
specified using autoregressive models that learn the distribution of the next
event from the previous events. This makes sampling inherently sequential,
limiting efficiency. In this paper, we propose a novel algorithm based on
rejection sampling that enables exact sampling of multiple future values from
existing TPP models, in parallel, and without requiring any architectural
changes or retraining. Besides theoretical guarantees, our method demonstrates
empirical speedups on real-world datasets, bridging the gap between expressive
modeling and efficient parallel generation for large-scale TPP applications.

</details>


### [6] [Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning](https://arxiv.org/abs/2510.20108)
*Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 提出了一种完全解耦的训练策略来解决原型自监督学习中的原型崩溃问题，通过分离原型和编码器的优化目标来获得更多样化的原型和更好的下游性能。


<details>
  <summary>Details</summary>
Motivation: 原型自监督学习方法普遍存在部分原型崩溃问题，即多个原型收敛到几乎相同的表示，这削弱了提供多样化目标的核心目的，导致实践中需要过度参数化原型集或添加临时正则化器。

Method: 引入完全解耦的训练策略，将原型和编码器在独立目标下学习。具体来说，将原型建模为高斯混合模型，使用在线EM风格过程独立于编码器损失进行更新。

Result: 这种简单而原则性的解耦消除了原型崩溃，无需显式正则化，产生了一致多样化的原型和更强的下游性能。

Conclusion: 通过打破原型和编码器的联合优化，解决了原型崩溃的根本原因，提供了一种更有效的自监督学习框架。

Abstract: Prototypical self-supervised learning methods consistently suffer from
partial prototype collapse, where multiple prototypes converge to nearly
identical representations. This undermines their central purpose -- providing
diverse and informative targets to guide encoders toward rich representations
-- and has led practitioners to over-parameterize prototype sets or add ad-hoc
regularizers, which mitigate symptoms rather than address the root cause. We
empirically trace the collapse to the joint optimization of encoders and
prototypes, which encourages a type of shortcut learning: early in training
prototypes drift toward redundant representations that minimize loss without
necessarily enhancing representation diversity. To break the joint
optimization, we introduce a fully decoupled training strategy that learns
prototypes and encoders under separate objectives. Concretely, we model
prototypes as a Gaussian mixture updated with an online EM-style procedure,
independent of the encoder's loss. This simple yet principled decoupling
eliminates prototype collapse without explicit regularization and yields
consistently diverse prototypes and stronger downstream performance.

</details>


### [7] [Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents](https://arxiv.org/abs/2510.20199)
*Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 提出一个基于优化确定性等价的风险感知约束强化学习框架，通过强拉格朗日对偶性确保与原约束问题的等价性，并开发了可包装标准RL求解器的简单算法。


<details>
  <summary>Details</summary>
Motivation: 传统约束优化RL仅关注期望累积奖励，忽略了奖励分布尾部的风险事件，无法满足高风险应用中对异常值风险的关键需求。

Method: 使用优化确定性等价在奖励值和时间上联合展现每阶段鲁棒性，构建参数化强拉格朗日对偶框架，开发可包装PPO等标准RL求解器的算法。

Result: 在适当约束条件下确保与原约束问题的精确等价性，建立了算法收敛性，并通过数值实验验证了方法的风险感知特性。

Conclusion: 该框架为高风险应用提供了有效的风险感知约束RL解决方案，具有良好的理论保证和实际性能。

Abstract: Constrained optimization provides a common framework for dealing with
conflicting objectives in reinforcement learning (RL). In most of these
settings, the objectives (and constraints) are expressed though the expected
accumulated reward. However, this formulation neglects risky or even possibly
catastrophic events at the tails of the reward distribution, and is often
insufficient for high-stakes applications in which the risk involved in
outliers is critical. In this work, we propose a framework for risk-aware
constrained RL, which exhibits per-stage robustness properties jointly in
reward values and time using optimized certainty equivalents (OCEs). Our
framework ensures an exact equivalent to the original constrained problem
within a parameterized strong Lagrangian duality framework under appropriate
constraint qualifications, and yields a simple algorithmic recipe which can be
wrapped around standard RL solvers, such as PPO. Lastly, we establish the
convergence of the proposed algorithm under common assumptions, and verify the
risk-aware properties of our approach through several numerical experiments.

</details>


### [8] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 该研究评估了使用金毛猎犬寿命研究队列的常规实验室数据进行癌症风险分类的可行性，发现机器学习模型虽然能检测到统计显著的癌症信号，但由于信号太弱且与正常衰老等混淆，无法实现可靠的临床分类。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、可及的犬类癌症早期筛查工具面临挑战，常规实验室数据虽然易得，但存在生物标志物非特异性和严重类别不平衡的问题。

Method: 系统比较了126种分析流程，包括不同机器学习模型、特征选择方法和数据平衡技术，使用患者级别数据划分防止数据泄露，最优模型为带类别加权的逻辑回归分类器。

Result: 最优模型显示出中等排序能力（AUROC=0.815），但临床分类性能差（F1分数=0.25，阳性预测值=0.15），阴性预测值高（0.98）但召回率不足（0.79）。

Conclusion: 常规实验室数据中存在的癌症信号太弱且易混淆，无法实现可靠的临床鉴别，需要整合多模态数据源才能在计算兽医肿瘤学中取得有意义的进展。

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [9] [Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes](https://arxiv.org/abs/2510.20414)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang*

Main category: cs.LG

TL;DR: 提出了一种针对标记时间点过程的阈值方法，通过调整标记概率来优化不平衡数据下的下一个事件预测，特别是对稀有标记事件的预测。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了现实应用中事件标记分布高度不平衡的问题，这给下一个事件预测（特别是稀有标记事件）带来了重大挑战。

Method: 提出阈值方法学习阈值来调整标记概率，先预测标记再预测时间；开发了新的神经MTPP模型，支持有效时间采样和标记概率估计，无需计算昂贵的数值积分。

Result: 在真实世界数据集上的广泛实验表明，该方法在下一个事件标记和时间预测方面优于各种基线方法。

Conclusion: 所提出的解决方案能有效处理标记分布不平衡问题，提高下一个事件预测性能，特别是对稀有标记事件的预测。

Abstract: Marked Temporal Point Process (MTPP) has been well studied to model the event
distribution in marked event streams, which can be used to predict the mark and
arrival time of the next event. However, existing studies overlook that the
distribution of event marks is highly imbalanced in many real-world
applications, with some marks being frequent but others rare. The imbalance
poses a significant challenge to the performance of the next event prediction,
especially for events of rare marks. To address this issue, we propose a
thresholding method, which learns thresholds to tune the mark probability
normalized by the mark's prior probability to optimize mark prediction, rather
than predicting the mark directly based on the mark probability as in existing
studies. In conjunction with this method, we predict the mark first and then
the time. In particular, we develop a novel neural MTPP model to support
effective time sampling and estimation of mark probability without
computationally expensive numerical improper integration. Extensive experiments
on real-world datasets demonstrate the superior performance of our solution
against various baselines for the next event mark and time prediction. The code
is available at https://github.com/undes1red/IFNMTPP.

</details>


### [10] [MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction](https://arxiv.org/abs/2510.20448)
*Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan*

Main category: cs.LG

TL;DR: MolBridge是一个基于原子级联合图优化的DDI事件预测框架，通过构建药物对的联合图直接建模分子间关联，解决了现有方法无法显式建模跨分子原子级交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有DDI预测方法依赖孤立的药物表示，无法显式建模原子级跨分子交互，限制了在不同分子复杂度和DDI类型分布下的有效性。

Method: 构建药物对的联合图整合原子结构，引入结构一致性模块迭代优化节点特征同时保持全局结构上下文，有效学习局部和全局交互模式。

Result: 在两个基准数据集上的广泛实验表明，MolBridge在长尾和归纳场景下均优于现有最优基线，实现了卓越性能。

Conclusion: 细粒度图优化显著提高了DDI事件预测的准确性、鲁棒性和机制可解释性，为药物-药物相互作用网络的挖掘和分析提供了基于图的方法。

Abstract: Drug combinations offer therapeutic benefits but also carry the risk of
adverse drug-drug interactions (DDIs), especially under complex molecular
structures. Accurate DDI event prediction requires capturing fine-grained
inter-drug relationships, which are critical for modeling metabolic mechanisms
such as enzyme-mediated competition. However, existing approaches typically
rely on isolated drug representations and fail to explicitly model atom-level
cross-molecular interactions, limiting their effectiveness across diverse
molecular complexities and DDI type distributions. To address these
limitations, we propose MolBridge, a novel atom-level joint graph refinement
framework for robust DDI event prediction. MolBridge constructs a joint graph
that integrates atomic structures of drug pairs, enabling direct modeling of
inter-drug associations. A central challenge in such joint graph settings is
the potential loss of information caused by over-smoothing when modeling
long-range atomic dependencies. To overcome this, we introduce a structure
consistency module that iteratively refines node features while preserving the
global structural context. This joint design allows MolBridge to effectively
learn both local and global interaction outperforms state-of-the-art baselines,
achieving superior performance across long-tail and inductive scenarios.
patterns, yielding robust representations across both frequent and rare DDI
types. Extensive experiments on two benchmark datasets show that MolBridge
consistently. These results demonstrate the advantages of fine-grained graph
refinement in improving the accuracy, robustness, and mechanistic
interpretability of DDI event prediction.This work contributes to Web Mining
and Content Analysis by developing graph-based methods for mining and analyzing
drug-drug interaction networks.

</details>


### [11] [Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval](https://arxiv.org/abs/2510.20486)
*Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng*

Main category: cs.LG

TL;DR: 提出Hurdle-IMDL框架解决降水反演中的标签不平衡问题，通过分解零膨胀和长尾分布，有效改善强降水的反演性能。


<details>
  <summary>Details</summary>
Motivation: 人工智能在定量遥感中面临标签分布不平衡的挑战，传统训练模型偏向常见样本，导致对罕见样本（如强降水）的反演性能下降。

Method: 采用分而治之策略：使用hurdle模型处理零膨胀（非降水样本主导），提出IMDL方法处理长尾分布（轻降水样本过多），将学习目标转化为无偏理想逆模型。

Result: 通过统计指标和案例研究验证，Hurdle-IMDL优于传统、成本敏感、生成和多任务学习方法，有效缓解系统低估问题，显著改善强到极端降水的反演。

Conclusion: IMDL为处理环境变量分布不平衡提供了通用方法，能够增强对罕见但高影响事件的检索能力。

Abstract: Artificial intelligence has advanced quantitative remote sensing, yet its
effectiveness is constrained by imbalanced label distribution. This imbalance
leads conventionally trained models to favor common samples, which in turn
degrades retrieval performance for rare ones. Rainfall retrieval exemplifies
this issue, with performance particularly compromised for heavy rain. This
study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.
Following a divide-and-conquer strategy, imbalance in the rain distribution is
decomposed into two components: zero inflation, defined by the predominance of
non-rain samples; and long tail, defined by the disproportionate abundance of
light-rain samples relative to heavy-rain samples. A hurdle model is adopted to
handle the zero inflation, while IMDL is proposed to address the long tail by
transforming the learning object into an unbiased ideal inverse model.
Comprehensive evaluation via statistical metrics and case studies investigating
rainy weather in eastern China confirms Hurdle-IMDL's superiority over
conventional, cost-sensitive, generative, and multi-task learning methods. Its
key advancements include effective mitigation of systematic underestimation and
a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a
generalizable approach for addressing imbalance in distributions of
environmental variables, enabling enhanced retrieval of rare yet high-impact
events.

</details>


### [12] [Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach](https://arxiv.org/abs/2510.20629)
*Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu*

Main category: cs.LG

TL;DR: 提出了一种公平感知生存建模方法FASM，旨在减轻生存分析中的算法偏见，特别是在组内和跨组风险排名方面，应用于乳腺癌预后数据并取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在医疗领域的应用增加，临床数据中存在的结构性不平等和社会偏见可能被数据驱动模型延续甚至放大。生存分析中的删失和时间动态性进一步增加了公平模型开发的复杂性，现有公平性方法往往忽视跨组排名差异问题。

Method: 提出了公平感知生存建模方法FASM，专门设计用于减轻算法偏见，关注组内和跨组风险排名的时间动态性。使用乳腺癌预后作为代表性案例，并将FASM应用于SEER乳腺癌数据。

Result: FASM显著提高了公平性，同时保持了与不考虑公平性的生存模型相当的判别性能。时间分层评估显示，FASM在10年时间范围内保持了稳定的公平性，在随访中期观察到最大的改进效果。

Conclusion: 该方法能够开发出在临床决策中同时优先考虑准确性和公平性的生存模型，将公平性作为临床护理的核心原则推进。

Abstract: As machine learning models become increasingly integrated into healthcare,
structural inequities and social biases embedded in clinical data can be
perpetuated or even amplified by data-driven models. In survival analysis,
censoring and time dynamics can further add complexity to fair model
development. Additionally, algorithmic fairness approaches often overlook
disparities in cross-group rankings, e.g., high-risk Black patients may be
ranked below lower-risk White patients who do not experience the event of
mortality. Such misranking can reinforce biological essentialism and undermine
equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed
to mitigate algorithmic bias regarding both intra-group and cross-group risk
rankings over time. Using breast cancer prognosis as a representative case and
applying FASM to SEER breast cancer data, we show that FASM substantially
improves fairness while preserving discrimination performance comparable to
fairness-unaware survival models. Time-stratified evaluations show that FASM
maintains stable fairness over a 10-year horizon, with the greatest
improvements observed during the mid-term of follow-up. Our approach enables
the development of survival models that prioritize both accuracy and equity in
clinical decision-making, advancing fairness as a core principle in clinical
care.

</details>


### [13] [xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion](https://arxiv.org/abs/2510.20651)
*Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: xTime是一个用于时间序列极端事件预测的新框架，通过知识蒸馏和专家混合机制，显著提升了对罕见极端事件的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列中的极端事件（如洪水、热浪、医疗紧急事件）具有重要实际意义，但现有预测模型通常关注整体性能而难以准确预测极端事件，主要挑战是数据不平衡和忽视极端事件前的中介事件信息。

Method: 提出xTime框架，利用知识蒸馏从训练在较低稀有度事件上的模型转移信息，并引入专家混合(MoE)机制动态选择和融合不同稀有度级别的专家模型输出。

Result: 在多个数据集上的实验表明，xTime实现了持续改进，极端事件的预测准确率从3%提升到78%。

Conclusion: xTime框架通过知识蒸馏和专家混合机制有效解决了极端事件预测中的数据不平衡问题，显著提升了预测性能。

Abstract: Extreme events frequently occur in real-world time series and often carry
significant practical implications. In domains such as climate and healthcare,
these events, such as floods, heatwaves, or acute medical episodes, can lead to
serious consequences. Accurate forecasting of such events is therefore of
substantial importance. Most existing time series forecasting models are
optimized for overall performance within the prediction window, but often
struggle to accurately predict extreme events, such as high temperatures or
heart rate spikes. The main challenges are data imbalance and the neglect of
valuable information contained in intermediate events that precede extreme
events. In this paper, we propose xTime, a novel framework for extreme event
forecasting in time series. xTime leverages knowledge distillation to transfer
information from models trained on lower-rarity events, thereby improving
prediction performance on rarer ones. In addition, we introduce a mixture of
experts (MoE) mechanism that dynamically selects and fuses outputs from expert
models across different rarity levels, which further improves the forecasting
performance for extreme events. Experiments on multiple datasets show that
xTime achieves consistent improvements, with forecasting accuracy on extreme
events improving from 3% to 78%.

</details>


### [14] [Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool](https://arxiv.org/abs/2510.20714)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究通过数据驱动建模方法改进约翰霍普金斯跌倒风险评估工具(JHFRAT)，使用约束评分优化模型结合临床评估数据和电子健康记录变量，显著提升了跌倒风险预测性能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过数据驱动方法更好地将JHFRAT跌倒风险预测与临床有意义的指标对齐，改进住院患者跌倒预防协议和患者安全。

Method: 对54,209例住院患者进行回顾性分析，使用约束评分优化(CSO)模型结合JHFRAT评估数据和电子健康记录变量，并与基准黑盒模型(XGBoost)进行比较。

Result: CSO模型预测性能显著优于当前JHFRAT(AUC-ROC=0.91 vs 0.86)，与XGBoost性能相近(AUC-ROC=0.94)但具有更好的风险标签变化鲁棒性。

Conclusion: 这种基于证据的方法为医疗系统使用数据驱动优化技术系统性地增强住院患者跌倒预防协议和患者安全提供了坚实基础。

Abstract: In this study we aim to better align fall risk prediction from the Johns
Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically
meaningful measures via a data-driven modelling approach. We conducted a
retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins
Health System hospitals between March 2022 and October 2023. A total of 20,208
admissions were included as high fall risk encounters, and 13,941 were included
as low fall risk encounters. To incorporate clinical knowledge and maintain
interpretability, we employed constrained score optimization (CSO) models on
JHFRAT assessment data and additional electronic health record (EHR) variables.
The model demonstrated significant improvements in predictive performance over
the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained
score optimization models performed similarly with and without the EHR
variables. Although the benchmark black-box model (XGBoost), improves upon the
performance metrics of the knowledge-based constrained logistic regression
(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk
labelling. This evidence-based approach provides a robust foundation for health
systems to systematically enhance inpatient fall prevention protocols and
patient safety using data-driven optimization techniques, contributing to
improved risk assessment and resource allocation in healthcare settings.

</details>


### [15] [Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series](https://arxiv.org/abs/2510.20718)
*Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder*

Main category: cs.LG

TL;DR: 提出了两种新颖的半导体制造异常预测方法：基于N-BEATS的单变量预测和基于图神经网络的多变量关系建模，GNN方法在性能和效率上均优于N-BEATS。


<details>
  <summary>Details</summary>
Motivation: 半导体制造过程复杂且精度要求高，现有异常检测方法面临高维数据、类别不平衡和变量间复杂依赖关系的挑战，需要从异常检测向异常预测发展以实现实时过程校正。

Method: 采用两阶段框架：首先在无异常数据集上训练预测模型，然后对未见时间序列进行预测，将预测值与实际值偏差超过阈值的点标记为异常。比较了N-BEATS单变量预测和GNN多变量关系建模两种方法。

Result: 两种模型在20个时间点内表现出强预测性能，在50个时间点内保持稳定的异常预测能力。GNN在性能上持续优于N-BEATS，且所需可训练参数更少、计算成本更低。

Conclusion: GNN方法为在线异常预测提供了有前景的解决方案，适合在制造环境中部署，能够有效处理半导体制造中的复杂变量依赖关系。

Abstract: Semiconductor manufacturing is an extremely complex and precision-driven
process, characterized by thousands of interdependent parameters collected
across diverse tools and process steps. Multi-variate time-series analysis has
emerged as a critical field for real-time monitoring and fault detection in
such environments. However, anomaly prediction in semiconductor fabrication
presents several critical challenges, including high dimensionality of sensor
data and severe class imbalance due to the rarity of true faults. Furthermore,
the complex interdependencies between variables complicate both anomaly
prediction and root-cause-analysis. This paper proposes two novel approaches to
advance the field from anomaly detection to anomaly prediction, an essential
step toward enabling real-time process correction and proactive fault
prevention. The proposed anomaly prediction framework contains two main stages:
(a) training a forecasting model on a dataset assumed to contain no anomalies,
and (b) performing forecast on unseen time series data. The forecast is
compared with the forecast of the trained signal. Deviations beyond a
predefined threshold are flagged as anomalies. The two approaches differ in the
forecasting model employed. The first assumes independence between variables by
utilizing the N-BEATS model for univariate time series forecasting. The second
lifts this assumption by utilizing a Graph Neural Network (GNN) to capture
inter-variable relationships. Both models demonstrate strong forecasting
performance up to a horizon of 20 time points and maintain stable anomaly
prediction up to 50 time points. The GNN consistently outperforms the N-BEATS
model while requiring significantly fewer trainable parameters and lower
computational cost. These results position the GNN as promising solution for
online anomaly forecasting to be deployed in manufacturing environments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [An Expert-grounded benchmark of General Purpose LLMs in LCA](https://arxiv.org/abs/2510.19886)
*Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard*

Main category: cs.CL

TL;DR: 本研究首次通过专家基准测试评估了11个通用大语言模型在生命周期评估(LCA)中的表现，发现37%的回答包含不准确或误导性信息，幻觉率高达40%，揭示了在LCA中天真应用LLM的风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI和LLM在生命周期评估(LCA)中的应用日益增多，但缺乏对其可靠性、鲁棒性和可用性的系统性证据，且该领域缺乏标准化的评估框架和明确的地面真实值。

Method: 评估了11个通用LLM（商业和开源模型）在22个LCA相关任务上的表现，由17位经验丰富的从业者根据科学准确性、解释质量、鲁棒性、可验证性和指令遵循等标准审查模型输出，共收集168份专家评审。

Result: 专家判定37%的回答包含不准确或误导信息；准确性和解释质量评分普遍为平均或良好；幻觉率差异显著，某些模型的引用幻觉率高达40%；开源模型在准确性和解释质量等标准上与闭源模型表现相当或更优。

Conclusion: 研究强调了在LCA中天真应用LLM的风险，特别是当将其视为自由形式的神谕时，但也显示了其在解释质量和减轻简单任务劳动强度方面的益处。没有基础机制支持的通用LLM使用存在风险。

Abstract: Purpose: Artificial intelligence (AI), and in particular large language
models (LLMs), are increasingly being explored as tools to support life cycle
assessment (LCA). While demonstrations exist across environmental and social
domains, systematic evidence on their reliability, robustness, and usability
remains limited. This study provides the first expert-grounded benchmark of
LLMs in LCA, addressing the absence of standardized evaluation frameworks in a
field where no clear ground truth or consensus protocols exist.
  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial
and open-source families, across 22 LCA-related tasks. Seventeen experienced
practitioners reviewed model outputs against criteria directly relevant to LCA
practice, including scientific accuracy, explanation quality, robustness,
verifiability, and adherence to instructions. We collected 168 expert reviews.
  Results: Experts judged 37% of responses to contain inaccurate or misleading
information. Ratings of accuracy and quality of explanation were generally
rated average or good on many models even smaller models, and format adherence
was generally rated favourably. Hallucination rates varied significantly, with
some models producing hallucinated citations at rates of up to 40%. There was
no clear-cut distinction between ratings on open-weight versus closed-weight
LLMs, with open-weight models outperforming or competing on par with
closed-weight models on criteria such as accuracy and quality of explanation.
  Conclusion: These findings highlight the risks of applying LLMs na\"ively in
LCA, such as when LLMs are treated as free-form oracles, while also showing
benefits especially around quality of explanation and alleviating labour
intensiveness of simple tasks. The use of general-purpose LLMs without
grounding mechanisms presents ...

</details>


### [17] [Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models](https://arxiv.org/abs/2510.20033)
*David Dukić*

Main category: cs.CL

TL;DR: 本博士论文通过引入多任务模型、架构修改方法和生成式上下文微调框架，改进了预训练神经语言模型在序列标注任务中的迁移学习性能。


<details>
  <summary>Details</summary>
Motivation: 提升预训练神经语言模型在序列标注任务中的迁移学习效果，解决传统方法在领域迁移、信息流限制和模型适应性方面的不足。

Method: 1) 多任务模型：整合领域无关文本处理系统的额外信号；2) 架构修改：在自回归大语言模型中实现跨层双向信息流；3) 生成式监督上下文微调框架：结合响应导向的适应策略。

Result: 提出的模型、方法和框架表明，通过针对性迁移学习范式适应的预训练神经语言模型在序列标注任务中达到最佳性能。

Conclusion: 预训练神经语言模型在序列标注任务中的最佳性能需要通过针对性的迁移学习范式来实现，本文提出的三种改进方法有效提升了迁移学习效果。

Abstract: This doctoral thesis improves the transfer learning for sequence labeling
tasks by adapting pre-trained neural language models. The proposed improvements
in transfer learning involve introducing a multi-task model that incorporates
an additional signal, a method based on architectural modifications in
autoregressive large language models, and a sequence labeling framework for
autoregressive large language models utilizing supervised in-context
fine-tuning combined with response-oriented adaptation strategies. The first
improvement is given in the context of domain transfer for the event trigger
detection task. The domain transfer of the event trigger detection task can be
improved by incorporating an additional signal obtained from a
domain-independent text processing system into a multi-task model. The second
improvement involves modifying the model's architecture. For that purpose, a
method is proposed to enable bidirectional information flow across layers of
autoregressive large language models. The third improvement utilizes
autoregressive large language models as text generators through a generative
supervised in-context fine-tuning framework. The proposed model, method, and
framework demonstrate that pre-trained neural language models achieve their
best performance on sequence labeling tasks when adapted through targeted
transfer learning paradigms.

</details>


### [18] [ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering](https://arxiv.org/abs/2510.20036)
*Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth*

Main category: cs.CL

TL;DR: ToolScope通过工具合并和检索机制解决LLM工具使用中的冗余和上下文限制问题，显著提升工具选择准确率


<details>
  <summary>Details</summary>
Motivation: 现实工具集中存在冗余工具，工具名称和描述重叠导致歧义，降低选择准确性；同时LLM面临严格的输入上下文限制，无法有效处理大型工具集

Method: 包含ToolScopeMerger（带自动校正功能）自动审计和修复工具合并以减少冗余；ToolScopeRetriever对每个查询进行工具排序和选择，压缩工具集以适应上下文限制

Result: 在三个最先进LLM和三个开源工具使用基准测试中，工具选择准确率提升了8.38%到38.6%

Conclusion: ToolScope能有效增强LLM工具使用能力，解决工具冗余和上下文限制问题

Abstract: Large language model (LLM) agents rely on external tools to solve complex
tasks, but real-world toolsets often contain redundant tools with overlapping
names and descriptions, introducing ambiguity and reducing selection accuracy.
LLMs also face strict input context limits, preventing efficient consideration
of large toolsets. To address these challenges, we propose ToolScope, which
includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and
fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and
select only the most relevant tools for each query, compressing toolsets to fit
within context limits without sacrificing accuracy. Evaluations on three
state-of-the-art LLMs and three open-source tool-use benchmarks show gains of
8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's
effectiveness in enhancing LLM tool use.

</details>
