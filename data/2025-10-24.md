<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 12]
- [cs.CL](#cs.CL) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Filter-Based Reconstruction of Images from Events](https://arxiv.org/abs/2510.20071)
*Bernd Pfrommer*

Main category: cs.CV

TL;DR: 提出FIBAR方法，一种基于滤波器的异步重建方法，用于从移动事件相机的事件中重建强度图像，无需神经网络，可在CPU上高效运行。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的强度图像重建方法通常部署在GPU上，计算复杂。需要一种更简单、异步且能在CPU上高效运行的重建方法。

Method: 使用时间数字IIR滤波器积分事件强度变化，通过新颖算法检测陈旧像素并调节最近更新像素窗口，对陈旧像素应用高斯滤波以减少重建噪声。

Result: FIBAR在笔记本电脑CPU上运行速度约42-140百万事件/秒，重建图像比神经网络方法更嘈杂且存在重影，但足以完成某些任务如检测基准标记。

Conclusion: FIBAR提供了一种简单高效的异步图像重建替代方案，虽然重建质量不如神经网络方法，但在某些应用场景下足够实用。

Abstract: Reconstructing an intensity image from the events of a moving event camera is
a challenging task that is typically approached with neural networks deployed
on graphics processing units. This paper presents a much simpler, FIlter Based
Asynchronous Reconstruction method (FIBAR). First, intensity changes signaled
by events are integrated with a temporal digital IIR filter. To reduce
reconstruction noise, stale pixels are detected by a novel algorithm that
regulates a window of recently updated pixels. Arguing that for a moving
camera, the absence of events at a pixel location likely implies a low image
gradient, stale pixels are then blurred with a Gaussian filter. In contrast to
most existing methods, FIBAR is asynchronous and permits image read-out at an
arbitrary time. It runs on a modern laptop CPU at about 42(140) million
events/s with (without) spatial filtering enabled. A few simple qualitative
experiments are presented that show the difference in image reconstruction
between FIBAR and a neural network-based approach (FireNet). FIBAR's
reconstruction is noisier than neural network-based methods and suffers from
ghost images. However, it is sufficient for certain tasks such as the detection
of fiducial markers. Code is available at
https://github.com/ros-event-camera/event_image_reconstruction_fibar

</details>


### [2] [DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering](https://arxiv.org/abs/2510.20285)
*Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu*

Main category: cs.CV

TL;DR: 提出了DMC³框架，通过反事实样本构建和对比优化来解决第一人称视频问答中的多事件理解和手-物交互识别挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了第一人称视角带来的独特挑战，如理解多个事件和识别手-物交互。

Method: 包含反事实样本构建模块（通过事件描述改写和核心交互挖掘生成正负样本）和反事实样本参与对比优化模块（使用对比损失优化特征距离）。

Result: 在EgoTaskQA的normal和indirect分割上分别达到52.51%和46.04%，在QAEGO4D上达到13.2%，均达到最先进性能。

Conclusion: DMC³框架有效解决了第一人称视频问答中的关键挑战，显著提升了模型性能。

Abstract: Egocentric Video Question Answering (Egocentric VideoQA) plays an important
role in egocentric video understanding, which refers to answering questions
based on first-person videos. Although existing methods have made progress
through the paradigm of pre-training and fine-tuning, they ignore the unique
challenges posed by the first-person perspective, such as understanding
multiple events and recognizing hand-object interactions. To deal with these
challenges, we propose a Dual-Modal Counterfactual Contrastive Construction
(DMC$^3$) framework, which contains an egocentric videoqa baseline, a
counterfactual sample construction module and a counterfactual sample-involved
contrastive optimization. Specifically, We first develop a counterfactual
sample construction module to generate positive and negative samples for
textual and visual modalities through event description paraphrasing and core
interaction mining, respectively. Then, We feed these samples together with the
original samples into the baseline. Finally, in the counterfactual
sample-involved contrastive optimization module, we apply contrastive loss to
minimize the distance between the original sample features and the positive
sample features, while maximizing the distance from the negative samples.
Experiments show that our method achieve 52.51\% and 46.04\% on the
\textit{normal} and \textit{indirect} splits of EgoTaskQA, and 13.2\% on
QAEGO4D, both reaching the state-of-the-art performance.

</details>


### [3] [Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation](https://arxiv.org/abs/2510.20596)
*Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: 提出基于相似性原型的跨模态分割框架，通过类别原型学习和相似性约束来解决领域适应问题，在嵌入空间中实现语义类别的可区分性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在面对未见数据时性能会急剧下降，对领域偏移敏感。无监督领域适应旨在减小领域差距并避免对新领域的昂贵标注。

Method: 在嵌入空间中学习类别原型，引入相似性约束使原型具有代表性且类别间可分。使用字典存储不同图像提取的原型，防止类别缺失问题并支持原型对比学习。

Result: 大量实验表明，该方法比其他最先进方法取得了更好的结果。

Conclusion: 提出的基于相似性原型的框架有效提升了跨模态分割的性能，通过原型对比学习进一步改善了模型表现。

Abstract: Deep learning models have achieved great success on various vision
challenges, but a well-trained model would face drastic performance degradation
when applied to unseen data. Since the model is sensitive to domain shift,
unsupervised domain adaptation attempts to reduce the domain gap and avoid
costly annotation of unseen domains. This paper proposes a novel framework for
cross-modality segmentation via similarity-based prototypes. In specific, we
learn class-wise prototypes within an embedding space, then introduce a
similarity constraint to make these prototypes representative for each semantic
class while separable from different classes. Moreover, we use dictionaries to
store prototypes extracted from different images, which prevents the
class-missing problem and enables the contrastive learning of prototypes, and
further improves performance. Extensive experiments show that our method
achieves better results than other state-of-the-art methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications](https://arxiv.org/abs/2510.20019)
*Curtis Lee Shull,Merrick Green*

Main category: cs.LG

TL;DR: 使用监督学习和决策树分类器，基于RFID的RSSI数据进行位置推断，在模拟国防存储环境中对12个实验室区域进行分类，总体准确率34.2%，部分区域F1分数超过0.40。


<details>
  <summary>Details</summary>
Motivation: 解决RFID跟踪在国防资产存储中的安全挑战，包括传感器特异性差导致的错误检测和操作安全问题。

Method: 在CAD建模的平面图上使用监督学习模拟，采用决策树分类器处理RSSI数据，使用类别权重处理类别不平衡问题，训练集为5000个平衡观测值。

Result: 总体准确率34.2%，多个区域（F、G、H等）的F1分数超过0.40，但稀有类别（特别是LabZoneC）经常被错误分类。

Conclusion: 基于RSSI的决策树可在现实模拟中实现区域级异常检测或错位监控，通过改进天线布局或增加传感器融合可提高低覆盖区域的分类性能。

Abstract: Radio Frequency Identification (RFID) tracking may be a viable solution for
defense assets that must be stored in accordance with security guidelines.
However, poor sensor specificity (vulnerabilities include long range detection,
spoofing, and counterfeiting) can lead to erroneous detection and operational
security events. We present a supervised learning simulation with realistic
Received Signal Strength Indicator (RSSI) data and Decision Tree classification
in a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some
of the challenges encountered in defense storage. In this work, we focused on
classifying 12 lab zones (LabZoneA-L) to perform location inference. The raw
dataset had approximately 980,000 reads. Class frequencies were imbalanced, and
class weights were calculated to account for class imbalance in this
multi-class setting. The model, trained on stratified subsamples to 5,000
balanced observations, yielded an overall accuracy of 34.2% and F1-scores
greater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare
classes (most notably LabZoneC) were often misclassified, even with the use of
class weights. An adjacency-aware confusion matrix was calculated to allow
better interpretation of physically adjacent zones. These results suggest that
RSSI-based decision trees can be applied in realistic simulations to enable
zone-level anomaly detection or misplacement monitoring for defense supply
logistics. Reliable classification performance in low-coverage and low-signal
zones could be improved with better antenna placement or additional sensors and
sensor fusion with other modalities.

</details>


### [5] [Speculative Sampling for Parametric Temporal Point Processes](https://arxiv.org/abs/2510.20031)
*Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 提出了一种基于拒绝采样的新算法，能够从现有TPP模型中并行、精确地采样多个未来值，无需架构更改或重新训练


<details>
  <summary>Details</summary>
Motivation: 传统时序点过程模型采用自回归方式采样，效率低下且无法并行化，限制了在大规模应用中的实用性

Method: 基于拒绝采样的算法，利用现有TPP模型进行并行采样，保持采样精确性

Result: 在真实世界数据集上实现了经验性加速，证明了方法的有效性

Conclusion: 该方法弥合了表达性建模与高效并行生成之间的差距，为大规模TPP应用提供了解决方案

Abstract: Temporal point processes are powerful generative models for event sequences
that capture complex dependencies in time-series data. They are commonly
specified using autoregressive models that learn the distribution of the next
event from the previous events. This makes sampling inherently sequential,
limiting efficiency. In this paper, we propose a novel algorithm based on
rejection sampling that enables exact sampling of multiple future values from
existing TPP models, in parallel, and without requiring any architectural
changes or retraining. Besides theoretical guarantees, our method demonstrates
empirical speedups on real-world datasets, bridging the gap between expressive
modeling and efficient parallel generation for large-scale TPP applications.

</details>


### [6] [Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning](https://arxiv.org/abs/2510.20108)
*Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera*

Main category: cs.LG

TL;DR: 提出一种完全解耦的训练策略来解决原型自监督学习中的原型坍塌问题，通过将原型学习和编码器训练分离，使用在线EM算法更新原型，无需显式正则化即可获得多样化的原型和更好的下游性能。


<details>
  <summary>Details</summary>
Motivation: 原型自监督学习方法普遍存在部分原型坍塌问题，即多个原型收敛到几乎相同的表示，这破坏了提供多样化目标来指导编码器学习丰富表示的核心目的。现有方法通过过度参数化原型集或添加临时正则化来缓解症状，但未解决根本原因。

Method: 提出完全解耦的训练策略，将原型和编码器的学习分离。原型被建模为高斯混合模型，通过在线EM风格的过程独立更新，不受编码器损失的影响。

Result: 这种解耦方法无需显式正则化即可消除原型坍塌，产生持续多样化的原型和更强的下游性能。

Conclusion: 通过打破原型和编码器的联合优化，解决了原型坍塌的根本原因，提供了一种简单而原则性的解决方案。

Abstract: Prototypical self-supervised learning methods consistently suffer from
partial prototype collapse, where multiple prototypes converge to nearly
identical representations. This undermines their central purpose -- providing
diverse and informative targets to guide encoders toward rich representations
-- and has led practitioners to over-parameterize prototype sets or add ad-hoc
regularizers, which mitigate symptoms rather than address the root cause. We
empirically trace the collapse to the joint optimization of encoders and
prototypes, which encourages a type of shortcut learning: early in training
prototypes drift toward redundant representations that minimize loss without
necessarily enhancing representation diversity. To break the joint
optimization, we introduce a fully decoupled training strategy that learns
prototypes and encoders under separate objectives. Concretely, we model
prototypes as a Gaussian mixture updated with an online EM-style procedure,
independent of the encoder's loss. This simple yet principled decoupling
eliminates prototype collapse without explicit regularization and yields
consistently diverse prototypes and stronger downstream performance.

</details>


### [7] [Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents](https://arxiv.org/abs/2510.20199)
*Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 提出了一个基于优化确定性等价的风险感知约束强化学习框架，通过强拉格朗日对偶性确保与原约束问题的等价性，并可与标准RL求解器结合使用。


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习仅关注期望累积奖励，忽略了奖励分布尾部的风险事件，无法满足高风险应用中对于异常风险的关键需求。

Method: 使用优化确定性等价在奖励值和时间上实现每阶段鲁棒性，基于强拉格朗日对偶框架确保与原约束问题的等价性，可包装在标准RL求解器上。

Result: 在适当约束条件下建立了与原问题的精确等价关系，算法在常见假设下收敛，数值实验验证了方法的风险感知特性。

Conclusion: 该框架为高风险应用提供了有效的风险感知约束强化学习解决方案，能够处理奖励分布尾部的风险事件。

Abstract: Constrained optimization provides a common framework for dealing with
conflicting objectives in reinforcement learning (RL). In most of these
settings, the objectives (and constraints) are expressed though the expected
accumulated reward. However, this formulation neglects risky or even possibly
catastrophic events at the tails of the reward distribution, and is often
insufficient for high-stakes applications in which the risk involved in
outliers is critical. In this work, we propose a framework for risk-aware
constrained RL, which exhibits per-stage robustness properties jointly in
reward values and time using optimized certainty equivalents (OCEs). Our
framework ensures an exact equivalent to the original constrained problem
within a parameterized strong Lagrangian duality framework under appropriate
constraint qualifications, and yields a simple algorithmic recipe which can be
wrapped around standard RL solvers, such as PPO. Lastly, we establish the
convergence of the proposed algorithm under common assumptions, and verify the
risk-aware properties of our approach through several numerical experiments.

</details>


### [8] [Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset](https://arxiv.org/abs/2510.20209)
*Shumin Li*

Main category: cs.LG

TL;DR: 该研究评估了使用金毛寻回犬寿命研究队列的常规实验室数据进行癌症风险分类的可行性，发现虽然存在可检测的癌症信号，但性能不足以用于可靠的临床筛查。


<details>
  <summary>Details</summary>
Motivation: 开发用于犬类早期癌症检测的无创筛查工具面临挑战，常规实验室数据成本低但受限于生物标志物非特异性和严重的类别不平衡问题。

Method: 系统比较了126个分析流程，包括不同机器学习模型、特征选择方法和数据平衡技术，使用患者级数据分区防止数据泄露，最优模型为带类别加权的逻辑回归分类器。

Result: 最优模型显示出中等排序能力（AUROC = 0.815）但临床分类性能较差（F1-score = 0.25，阳性预测值 = 0.15），阴性预测值高（0.98）但召回率不足（0.79）。

Conclusion: 常规实验室数据中存在的癌症信号太弱且易混淆，无法可靠区分正常衰老或其他炎症状况，需要整合多模态数据源才能在计算兽医学肿瘤学中取得有意义的进展。

Abstract: The development of accessible screening tools for early cancer detection in
dogs represents a significant challenge in veterinary medicine. Routine
laboratory data offer a promising, low-cost source for such tools, but their
utility is hampered by the non-specificity of individual biomarkers and the
severe class imbalance inherent in screening populations. This study assesses
the feasibility of cancer risk classification using the Golden Retriever
Lifetime Study (GRLS) cohort under real-world constraints, including the
grouping of diverse cancer types and the inclusion of post-diagnosis samples. A
comprehensive benchmark evaluation was conducted, systematically comparing 126
analytical pipelines that comprised various machine learning models, feature
selection methods, and data balancing techniques. Data were partitioned at the
patient level to prevent leakage. The optimal model, a Logistic Regression
classifier with class weighting and recursive feature elimination, demonstrated
moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical
classification performance (F1-score = 0.25, Positive Predictive Value = 0.15).
While a high Negative Predictive Value (0.98) was achieved, insufficient recall
(0.79) precludes its use as a reliable rule-out test. Interpretability analysis
with SHapley Additive exPlanations (SHAP) revealed that predictions were driven
by non-specific features like age and markers of inflammation and anemia. It is
concluded that while a statistically detectable cancer signal exists in routine
lab data, it is too weak and confounded for clinically reliable discrimination
from normal aging or other inflammatory conditions. This work establishes a
critical performance ceiling for this data modality in isolation and
underscores that meaningful progress in computational veterinary oncology will
require integration of multi-modal data sources.

</details>


### [9] [Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes](https://arxiv.org/abs/2510.20414)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang*

Main category: cs.LG

TL;DR: 提出一种针对标记时间点过程中事件标记分布不平衡问题的阈值方法，通过调整标记概率来优化预测性能，特别针对稀有标记事件。


<details>
  <summary>Details</summary>
Motivation: 现实应用中事件标记分布高度不平衡，现有方法难以准确预测稀有标记事件，这严重影响了下一事件预测的性能。

Method: 提出阈值方法，学习阈值来调整按标记先验概率归一化的标记概率，而不是直接基于标记概率预测；采用先预测标记再预测时间的策略；开发新的神经MTPP模型支持有效时间采样和标记概率估计。

Result: 在真实世界数据集上的广泛实验表明，该方法在下一事件标记和时间预测方面优于各种基线方法。

Conclusion: 所提出的解决方案能有效处理事件标记分布不平衡问题，显著提升稀有标记事件的预测性能。

Abstract: Marked Temporal Point Process (MTPP) has been well studied to model the event
distribution in marked event streams, which can be used to predict the mark and
arrival time of the next event. However, existing studies overlook that the
distribution of event marks is highly imbalanced in many real-world
applications, with some marks being frequent but others rare. The imbalance
poses a significant challenge to the performance of the next event prediction,
especially for events of rare marks. To address this issue, we propose a
thresholding method, which learns thresholds to tune the mark probability
normalized by the mark's prior probability to optimize mark prediction, rather
than predicting the mark directly based on the mark probability as in existing
studies. In conjunction with this method, we predict the mark first and then
the time. In particular, we develop a novel neural MTPP model to support
effective time sampling and estimation of mark probability without
computationally expensive numerical improper integration. Extensive experiments
on real-world datasets demonstrate the superior performance of our solution
against various baselines for the next event mark and time prediction. The code
is available at https://github.com/undes1red/IFNMTPP.

</details>


### [10] [MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction](https://arxiv.org/abs/2510.20448)
*Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan*

Main category: cs.LG

TL;DR: MolBridge是一个用于药物相互作用预测的原子级联合图精炼框架，通过构建药物对的联合图来直接建模分子间关联，解决了现有方法无法显式建模原子级跨分子交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有药物相互作用预测方法通常依赖孤立的药物表示，无法显式建模原子级的跨分子交互，限制了在不同分子复杂度和DDI类型分布下的有效性。

Method: 提出MolBridge框架，构建药物对的联合图整合原子结构，引入结构一致性模块迭代精炼节点特征同时保持全局结构上下文，有效学习局部和全局交互模式。

Result: 在两个基准数据集上的广泛实验表明，MolBridge在长尾和归纳场景中均优于现有最先进基线，实现了优越性能。

Conclusion: 这项工作证明了细粒度图精炼在提高DDI事件预测准确性、鲁棒性和机制可解释性方面的优势，为Web挖掘和内容分析领域贡献了基于图的药物相互作用网络挖掘方法。

Abstract: Drug combinations offer therapeutic benefits but also carry the risk of
adverse drug-drug interactions (DDIs), especially under complex molecular
structures. Accurate DDI event prediction requires capturing fine-grained
inter-drug relationships, which are critical for modeling metabolic mechanisms
such as enzyme-mediated competition. However, existing approaches typically
rely on isolated drug representations and fail to explicitly model atom-level
cross-molecular interactions, limiting their effectiveness across diverse
molecular complexities and DDI type distributions. To address these
limitations, we propose MolBridge, a novel atom-level joint graph refinement
framework for robust DDI event prediction. MolBridge constructs a joint graph
that integrates atomic structures of drug pairs, enabling direct modeling of
inter-drug associations. A central challenge in such joint graph settings is
the potential loss of information caused by over-smoothing when modeling
long-range atomic dependencies. To overcome this, we introduce a structure
consistency module that iteratively refines node features while preserving the
global structural context. This joint design allows MolBridge to effectively
learn both local and global interaction outperforms state-of-the-art baselines,
achieving superior performance across long-tail and inductive scenarios.
patterns, yielding robust representations across both frequent and rare DDI
types. Extensive experiments on two benchmark datasets show that MolBridge
consistently. These results demonstrate the advantages of fine-grained graph
refinement in improving the accuracy, robustness, and mechanistic
interpretability of DDI event prediction.This work contributes to Web Mining
and Content Analysis by developing graph-based methods for mining and analyzing
drug-drug interaction networks.

</details>


### [11] [Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval](https://arxiv.org/abs/2510.20486)
*Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng*

Main category: cs.LG

TL;DR: 提出Hurdle-IMDL框架解决遥感降雨反演中的标签不平衡问题，通过分解为零膨胀和长尾分布两个组件，分别用hurdle模型和逆模型去偏学习来处理，显著改善了强降雨的检索性能。


<details>
  <summary>Details</summary>
Motivation: 人工智能在定量遥感中面临标签分布不平衡的挑战，传统训练模型偏向常见样本，导致对罕见样本（如强降雨）的检索性能下降。

Method: 采用分而治之策略：1）用hurdle模型处理零膨胀（非降雨样本占主导）；2）提出IMDL方法处理长尾分布（轻降雨样本过多），将学习目标转化为无偏的理想逆模型。

Result: 通过统计指标和案例研究验证，Hurdle-IMDL优于传统方法、代价敏感学习、生成方法和多任务学习方法，有效缓解系统性低估，显著改善强到极端降雨的检索。

Conclusion: IMDL为处理环境变量分布不平衡提供了通用方法，能够增强对罕见但高影响事件的检索能力。

Abstract: Artificial intelligence has advanced quantitative remote sensing, yet its
effectiveness is constrained by imbalanced label distribution. This imbalance
leads conventionally trained models to favor common samples, which in turn
degrades retrieval performance for rare ones. Rainfall retrieval exemplifies
this issue, with performance particularly compromised for heavy rain. This
study proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.
Following a divide-and-conquer strategy, imbalance in the rain distribution is
decomposed into two components: zero inflation, defined by the predominance of
non-rain samples; and long tail, defined by the disproportionate abundance of
light-rain samples relative to heavy-rain samples. A hurdle model is adopted to
handle the zero inflation, while IMDL is proposed to address the long tail by
transforming the learning object into an unbiased ideal inverse model.
Comprehensive evaluation via statistical metrics and case studies investigating
rainy weather in eastern China confirms Hurdle-IMDL's superiority over
conventional, cost-sensitive, generative, and multi-task learning methods. Its
key advancements include effective mitigation of systematic underestimation and
a marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a
generalizable approach for addressing imbalance in distributions of
environmental variables, enabling enhanced retrieval of rare yet high-impact
events.

</details>


### [12] [Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach](https://arxiv.org/abs/2510.20629)
*Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu*

Main category: cs.LG

TL;DR: 提出了一种公平感知生存建模方法FASM，用于在生存分析中同时减轻组内和跨组风险排序的算法偏见，特别是在医疗保健领域。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在医疗保健中的应用可能放大临床数据中的结构性不平等和社会偏见，特别是在生存分析中，删失和时间动态增加了公平模型开发的复杂性。现有方法往往忽视跨组排名差异，可能导致高风险黑人患者被排在低风险白人患者之后，强化生物本质主义并损害公平护理。

Method: 提出了公平感知生存建模方法FASM，专门设计用于减轻关于组内和跨组风险排序的算法偏见。以乳腺癌预后为代表案例，在SEER乳腺癌数据上应用FASM。

Result: FASM显著提高了公平性，同时保持了与无公平意识的生存模型相当的判别性能。时间分层评估显示FASM在10年时间范围内保持稳定的公平性，在随访中期观察到最大的改进。

Conclusion: 该方法能够开发既注重准确性又注重公平性的生存模型，将公平性作为临床护理的核心原则推进。

Abstract: As machine learning models become increasingly integrated into healthcare,
structural inequities and social biases embedded in clinical data can be
perpetuated or even amplified by data-driven models. In survival analysis,
censoring and time dynamics can further add complexity to fair model
development. Additionally, algorithmic fairness approaches often overlook
disparities in cross-group rankings, e.g., high-risk Black patients may be
ranked below lower-risk White patients who do not experience the event of
mortality. Such misranking can reinforce biological essentialism and undermine
equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed
to mitigate algorithmic bias regarding both intra-group and cross-group risk
rankings over time. Using breast cancer prognosis as a representative case and
applying FASM to SEER breast cancer data, we show that FASM substantially
improves fairness while preserving discrimination performance comparable to
fairness-unaware survival models. Time-stratified evaluations show that FASM
maintains stable fairness over a 10-year horizon, with the greatest
improvements observed during the mid-term of follow-up. Our approach enables
the development of survival models that prioritize both accuracy and equity in
clinical decision-making, advancing fairness as a core principle in clinical
care.

</details>


### [13] [xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion](https://arxiv.org/abs/2510.20651)
*Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: xTime是一个用于时间序列极端事件预测的新框架，通过知识蒸馏和专家混合机制，显著提高了极端事件的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列中的极端事件（如洪水、热浪、医疗紧急情况）具有重要实际意义，但现有模型因数据不平衡和忽略中间事件信息而难以准确预测这些事件。

Method: 使用知识蒸馏从低稀有度事件模型中转移信息，并引入专家混合机制动态选择和融合不同稀有度级别的专家模型输出。

Result: 在多个数据集上的实验表明，xTime在极端事件上的预测准确性从3%提升到78%。

Conclusion: xTime框架通过知识蒸馏和专家混合机制有效解决了极端事件预测中的数据不平衡问题，显著提升了预测性能。

Abstract: Extreme events frequently occur in real-world time series and often carry
significant practical implications. In domains such as climate and healthcare,
these events, such as floods, heatwaves, or acute medical episodes, can lead to
serious consequences. Accurate forecasting of such events is therefore of
substantial importance. Most existing time series forecasting models are
optimized for overall performance within the prediction window, but often
struggle to accurately predict extreme events, such as high temperatures or
heart rate spikes. The main challenges are data imbalance and the neglect of
valuable information contained in intermediate events that precede extreme
events. In this paper, we propose xTime, a novel framework for extreme event
forecasting in time series. xTime leverages knowledge distillation to transfer
information from models trained on lower-rarity events, thereby improving
prediction performance on rarer ones. In addition, we introduce a mixture of
experts (MoE) mechanism that dynamically selects and fuses outputs from expert
models across different rarity levels, which further improves the forecasting
performance for extreme events. Experiments on multiple datasets show that
xTime achieves consistent improvements, with forecasting accuracy on extreme
events improving from 3% to 78%.

</details>


### [14] [Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool](https://arxiv.org/abs/2510.20714)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 通过约束评分优化模型改进约翰霍普金斯跌倒风险评估工具，结合临床知识和电子健康记录数据，显著提升跌倒风险预测性能，为医院跌倒预防提供数据驱动方法。


<details>
  <summary>Details</summary>
Motivation: 现有JHFRAT跌倒风险评估工具需要与更多临床意义指标对齐，通过数据驱动方法改进预测准确性，为医院跌倒预防提供更可靠依据。

Method: 使用约束评分优化模型，结合JHFRAT评估数据和电子健康记录变量，对54,209例住院患者进行回顾性分析，比较不同模型的预测性能。

Result: 约束评分优化模型显著优于当前JHFRAT（AUC-ROC从0.86提升至0.91），与XGBoost模型性能接近（AUC-ROC=0.94），但对风险标签变化更具鲁棒性。

Conclusion: 这种基于证据的方法为医疗系统提供了使用数据驱动优化技术系统增强住院患者跌倒预防方案和患者安全的坚实基础，有助于改善风险评估和资源分配。

Abstract: In this study we aim to better align fall risk prediction from the Johns
Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically
meaningful measures via a data-driven modelling approach. We conducted a
retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins
Health System hospitals between March 2022 and October 2023. A total of 20,208
admissions were included as high fall risk encounters, and 13,941 were included
as low fall risk encounters. To incorporate clinical knowledge and maintain
interpretability, we employed constrained score optimization (CSO) models on
JHFRAT assessment data and additional electronic health record (EHR) variables.
The model demonstrated significant improvements in predictive performance over
the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained
score optimization models performed similarly with and without the EHR
variables. Although the benchmark black-box model (XGBoost), improves upon the
performance metrics of the knowledge-based constrained logistic regression
(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk
labelling. This evidence-based approach provides a robust foundation for health
systems to systematically enhance inpatient fall prevention protocols and
patient safety using data-driven optimization techniques, contributing to
improved risk assessment and resource allocation in healthcare settings.

</details>


### [15] [Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series](https://arxiv.org/abs/2510.20718)
*Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder*

Main category: cs.LG

TL;DR: 提出两种基于时间序列预测的半导体制造异常预测方法：使用N-BEATS的单变量方法和使用图神经网络(GNN)的多变量方法，GNN在性能和效率上均优于N-BEATS。


<details>
  <summary>Details</summary>
Motivation: 半导体制造过程复杂且精度要求高，存在高维传感器数据、类别不平衡和变量间复杂依赖关系等挑战，需要从异常检测向异常预测发展以实现实时过程校正和主动故障预防。

Method: 构建两阶段异常预测框架：(1)在无异常数据集上训练预测模型；(2)对新数据进行预测并与训练信号预测比较，超出阈值的偏差标记为异常。使用N-BEATS(单变量)和GNN(多变量)两种预测模型。

Result: 两种模型在20个时间点内表现出强预测性能，在50个时间点内保持稳定的异常预测。GNN在性能上持续优于N-BEATS，且所需可训练参数和计算成本显著更低。

Conclusion: GNN是制造环境中在线异常预测的有前景解决方案，能够有效处理变量间复杂依赖关系，在性能和效率上均优于单变量方法。

Abstract: Semiconductor manufacturing is an extremely complex and precision-driven
process, characterized by thousands of interdependent parameters collected
across diverse tools and process steps. Multi-variate time-series analysis has
emerged as a critical field for real-time monitoring and fault detection in
such environments. However, anomaly prediction in semiconductor fabrication
presents several critical challenges, including high dimensionality of sensor
data and severe class imbalance due to the rarity of true faults. Furthermore,
the complex interdependencies between variables complicate both anomaly
prediction and root-cause-analysis. This paper proposes two novel approaches to
advance the field from anomaly detection to anomaly prediction, an essential
step toward enabling real-time process correction and proactive fault
prevention. The proposed anomaly prediction framework contains two main stages:
(a) training a forecasting model on a dataset assumed to contain no anomalies,
and (b) performing forecast on unseen time series data. The forecast is
compared with the forecast of the trained signal. Deviations beyond a
predefined threshold are flagged as anomalies. The two approaches differ in the
forecasting model employed. The first assumes independence between variables by
utilizing the N-BEATS model for univariate time series forecasting. The second
lifts this assumption by utilizing a Graph Neural Network (GNN) to capture
inter-variable relationships. Both models demonstrate strong forecasting
performance up to a horizon of 20 time points and maintain stable anomaly
prediction up to 50 time points. The GNN consistently outperforms the N-BEATS
model while requiring significantly fewer trainable parameters and lower
computational cost. These results position the GNN as promising solution for
online anomaly forecasting to be deployed in manufacturing environments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [An Expert-grounded benchmark of General Purpose LLMs in LCA](https://arxiv.org/abs/2510.19886)
*Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard*

Main category: cs.CL

TL;DR: 本研究首次通过专家基准测试评估了11个通用大语言模型在生命周期评估(LCA)中的表现，发现37%的响应包含不准确信息，幻觉率高达40%，但某些模型在解释质量和格式遵循方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和大语言模型在生命周期评估中的应用日益增多，但缺乏对其可靠性、鲁棒性和可用性的系统性证据，需要建立标准化的评估框架。

Method: 评估了11个通用大语言模型在22个LCA相关任务上的表现，由17位经验丰富的从业者根据科学准确性、解释质量、鲁棒性、可验证性和指令遵循等标准进行评审，共收集168份专家评审。

Result: 专家判定37%的响应包含不准确或误导性信息；准确性和解释质量评分普遍中等或良好；幻觉率差异显著，某些模型幻觉引用率高达40%；开源模型与闭源模型在准确性和解释质量等标准上表现相当。

Conclusion: 研究强调在LCA中天真应用LLM的风险，特别是将其视为自由形式的神谕时，但也显示出在解释质量和减轻简单任务劳动强度方面的益处，无基础机制地使用通用LLM存在风险。

Abstract: Purpose: Artificial intelligence (AI), and in particular large language
models (LLMs), are increasingly being explored as tools to support life cycle
assessment (LCA). While demonstrations exist across environmental and social
domains, systematic evidence on their reliability, robustness, and usability
remains limited. This study provides the first expert-grounded benchmark of
LLMs in LCA, addressing the absence of standardized evaluation frameworks in a
field where no clear ground truth or consensus protocols exist.
  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial
and open-source families, across 22 LCA-related tasks. Seventeen experienced
practitioners reviewed model outputs against criteria directly relevant to LCA
practice, including scientific accuracy, explanation quality, robustness,
verifiability, and adherence to instructions. We collected 168 expert reviews.
  Results: Experts judged 37% of responses to contain inaccurate or misleading
information. Ratings of accuracy and quality of explanation were generally
rated average or good on many models even smaller models, and format adherence
was generally rated favourably. Hallucination rates varied significantly, with
some models producing hallucinated citations at rates of up to 40%. There was
no clear-cut distinction between ratings on open-weight versus closed-weight
LLMs, with open-weight models outperforming or competing on par with
closed-weight models on criteria such as accuracy and quality of explanation.
  Conclusion: These findings highlight the risks of applying LLMs na\"ively in
LCA, such as when LLMs are treated as free-form oracles, while also showing
benefits especially around quality of explanation and alleviating labour
intensiveness of simple tasks. The use of general-purpose LLMs without
grounding mechanisms presents ...

</details>


### [17] [Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models](https://arxiv.org/abs/2510.20033)
*David Dukić*

Main category: cs.CL

TL;DR: 该博士论文通过改进预训练神经语言模型的迁移学习方法，提升了序列标注任务的性能。主要贡献包括：引入多任务模型整合额外信号、修改自回归大语言模型架构实现双向信息流、以及使用生成式监督上下文微调框架。


<details>
  <summary>Details</summary>
Motivation: 现有预训练语言模型在序列标注任务中的迁移学习效果有待提升，特别是在领域迁移、模型架构适应性和生成式方法应用方面存在改进空间。

Method: 1) 多任务模型整合领域无关文本处理系统的额外信号；2) 修改自回归大语言模型架构实现层间双向信息流；3) 生成式监督上下文微调框架结合响应导向适应策略。

Result: 提出的模型、方法和框架表明，预训练神经语言模型通过针对性迁移学习范式，在序列标注任务上能达到最佳性能。

Conclusion: 通过多任务学习、架构修改和生成式微调等针对性迁移学习方法，可以有效提升预训练语言模型在序列标注任务中的表现。

Abstract: This doctoral thesis improves the transfer learning for sequence labeling
tasks by adapting pre-trained neural language models. The proposed improvements
in transfer learning involve introducing a multi-task model that incorporates
an additional signal, a method based on architectural modifications in
autoregressive large language models, and a sequence labeling framework for
autoregressive large language models utilizing supervised in-context
fine-tuning combined with response-oriented adaptation strategies. The first
improvement is given in the context of domain transfer for the event trigger
detection task. The domain transfer of the event trigger detection task can be
improved by incorporating an additional signal obtained from a
domain-independent text processing system into a multi-task model. The second
improvement involves modifying the model's architecture. For that purpose, a
method is proposed to enable bidirectional information flow across layers of
autoregressive large language models. The third improvement utilizes
autoregressive large language models as text generators through a generative
supervised in-context fine-tuning framework. The proposed model, method, and
framework demonstrate that pre-trained neural language models achieve their
best performance on sequence labeling tasks when adapted through targeted
transfer learning paradigms.

</details>


### [18] [ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering](https://arxiv.org/abs/2510.20036)
*Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth*

Main category: cs.CL

TL;DR: ToolScope通过合并冗余工具和检索相关工具，提升LLM在大型工具集上的选择准确率，在三个基准测试中实现8.38%至38.6%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界工具集常包含冗余工具，工具名称和描述重叠导致选择歧义，且LLM受限于输入上下文长度，无法有效处理大型工具集。

Method: ToolScope包含两个组件：ToolScopeMerger通过自动校正自动审计和修复工具合并以减少冗余；ToolScopeRetriever对工具进行排序和选择，仅保留最相关工具以压缩工具集。

Result: 在三个最先进LLM和三个开源工具使用基准测试中，工具选择准确率提升8.38%至38.6%。

Conclusion: ToolScope能有效增强LLM工具使用能力，通过减少冗余和压缩工具集来解决工具选择歧义和上下文限制问题。

Abstract: Large language model (LLM) agents rely on external tools to solve complex
tasks, but real-world toolsets often contain redundant tools with overlapping
names and descriptions, introducing ambiguity and reducing selection accuracy.
LLMs also face strict input context limits, preventing efficient consideration
of large toolsets. To address these challenges, we propose ToolScope, which
includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and
fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and
select only the most relevant tools for each query, compressing toolsets to fit
within context limits without sacrificing accuracy. Evaluations on three
state-of-the-art LLMs and three open-source tool-use benchmarks show gains of
8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's
effectiveness in enhancing LLM tool use.

</details>
