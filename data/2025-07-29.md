<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 9]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [FM-LC: A Hierarchical Framework for Urban Flood Mapping by Land Cover Identification Models](https://arxiv.org/abs/2507.19818)
*Xin Hong,Longchao Da,Hua Wei*

Main category: cs.CV

TL;DR: FM-LC框架通过多阶段方法改进干旱地区城市洪水映射，显著提升精度。


<details>
  <summary>Details</summary>
Motivation: 干旱地区城市洪水对基础设施和社区构成严重风险，需高精度洪水映射以改进应急响应和韧性规划。

Method: FM-LC采用三阶段方法：多类U-Net初始分割、轻量级专家模型修正误分类、贝叶斯平滑优化边界。

Result: 在迪拜2024年风暴事件中验证，F1分数平均提升29%，洪水边界更清晰。

Conclusion: FM-LC框架在干旱地区洪水映射中优于传统方法，具有实际应用潜力。

Abstract: Urban flooding in arid regions poses severe risks to infrastructure and
communities. Accurate, fine-scale mapping of flood extents and recovery
trajectories is therefore essential for improving emergency response and
resilience planning. However, arid environments often exhibit limited spectral
contrast between water and adjacent surfaces, rapid hydrological dynamics, and
highly heterogeneous urban land covers, which challenge traditional
flood-mapping approaches. High-resolution, daily PlanetScope imagery provides
the temporal and spatial detail needed. In this work, we introduce FM-LC, a
hierarchical framework for Flood Mapping by Land Cover identification, for this
challenging task. Through a three-stage process, it first uses an initial
multi-class U-Net to segment imagery into water, vegetation, built area, and
bare ground classes. We identify that this method has confusion between
spectrally similar categories (e.g., water vs. vegetation). Second, by early
checking, the class with the major misclassified area is flagged, and a
lightweight binary expert segmentation model is trained to distinguish the
flagged class from the rest. Third, a Bayesian smoothing step refines
boundaries and removes spurious noise by leveraging nearby pixel information.
We validate the framework on the April 2024 Dubai storm event, using pre- and
post-rainfall PlanetScope composites. Experimental results demonstrate average
F1-score improvements of up to 29% across all land-cover classes and notably
sharper flood delineations, significantly outperforming conventional
single-stage U-Net baselines.

</details>


### [2] [UniCT Depth: Event-Image Fusion Based Monocular Depth Estimation with Convolution-Compensated ViT Dual SA Block](https://arxiv.org/abs/2507.19948)
*Luoxi Jing,Dianxi Shi,Zhe Liu,Songchang Jin,Chunping Qiu,Ziteng Qiao,Yuxian Li,Jianqiang Xia*

Main category: cs.CV

TL;DR: UniCT Depth是一种结合CNN和Transformer的事件-图像融合方法，用于单目深度估计，通过局部和全局特征建模提升性能。


<details>
  <summary>Details</summary>
Motivation: 图像方法在复杂场景中表现不佳，事件相机数据稀疏，现有融合方法在遮挡和深度差异方面效果有限。

Method: 提出CcViT-DA块（结合CMSA和MFSA）和DCC块，统一CNN和Transformer以优化特征建模和模态融合。

Result: 实验表明，UniCT Depth在关键指标上优于现有方法。

Conclusion: UniCT Depth通过有效融合事件和图像数据，显著提升了深度估计性能。

Abstract: Depth estimation plays a crucial role in 3D scene understanding and is
extensively used in a wide range of vision tasks. Image-based methods struggle
in challenging scenarios, while event cameras offer high dynamic range and
temporal resolution but face difficulties with sparse data. Combining event and
image data provides significant advantages, yet effective integration remains
challenging. Existing CNN-based fusion methods struggle with occlusions and
depth disparities due to limited receptive fields, while Transformer-based
fusion methods often lack deep modality interaction. To address these issues,
we propose UniCT Depth, an event-image fusion method that unifies CNNs and
Transformers to model local and global features. We propose the
Convolution-compensated ViT Dual SA (CcViT-DA) Block, designed for the encoder,
which integrates Context Modeling Self-Attention (CMSA) to capture spatial
dependencies and Modal Fusion Self-Attention (MFSA) for effective cross-modal
fusion. Furthermore, we design the tailored Detail Compensation Convolution
(DCC) Block to improve texture details and enhances edge representations.
Experiments show that UniCT Depth outperforms existing image, event, and
fusion-based monocular depth estimation methods across key metrics.

</details>


### [3] [Player-Centric Multimodal Prompt Generation for Large Language Model Based Identity-Aware Basketball Video Captioning](https://arxiv.org/abs/2507.20163)
*Zeyu Xi,Haoying Sun,Yaofei Wu,Junchi Yan,Haoran Zhang,Lifang Wu,Liang Wang,Changwen Chen*

Main category: cs.CV

TL;DR: 论文提出了一种基于玩家身份的多模态提示生成网络（LLM-IAVC），用于体育视频字幕生成，通过提取玩家相关信息和视频内容，结合大型语言模型生成身份感知的描述。


<details>
  <summary>Details</summary>
Motivation: 现有体育视频字幕方法常忽略玩家身份，导致描述不准确。本文旨在通过视觉角度识别玩家身份，提升描述质量。

Method: 设计了身份相关信息提取模块（IRIEM）和视觉上下文学习模块（VCLM），结合玩家识别网络（PIN）和双向语义交互模块（BSIM），生成多模态提示输入大型语言模型（LLM）。

Result: 在NBA-Identity和VC-NBA-2022数据集上表现优异，验证了模型的有效性。

Conclusion: LLM-IAVC通过多模态信息融合，显著提升了体育视频字幕的身份感知能力。

Abstract: Existing sports video captioning methods often focus on the action yet
overlook player identities, limiting their applicability. Although some methods
integrate extra information to generate identity-aware descriptions, the player
identities are sometimes incorrect because the extra information is independent
of the video content. This paper proposes a player-centric multimodal prompt
generation network for identity-aware sports video captioning (LLM-IAVC), which
focuses on recognizing player identities from a visual perspective.
Specifically, an identity-related information extraction module (IRIEM) is
designed to extract player-related multimodal embeddings. IRIEM includes a
player identification network (PIN) for extracting visual features and player
names, and a bidirectional semantic interaction module (BSIM) to link player
features with video content for mutual enhancement. Additionally, a visual
context learning module (VCLM) is designed to capture the key video context
information. Finally, by integrating the outputs of the above modules as the
multimodal prompt for the large language model (LLM), it facilitates the
generation of descriptions with player identities. To support this work, we
construct a new benchmark called NBA-Identity, a large identity-aware
basketball video captioning dataset with 9,726 videos covering 9 major event
types. The experimental results on NBA-Identity and VC-NBA-2022 demonstrate
that our proposed model achieves advanced performance. Code and dataset are
publicly available at https://github.com/Zeyu1226-mt/LLM-IAVC.

</details>


### [4] [LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks](https://arxiv.org/abs/2507.20174)
*Fei Kong,Jinhao Duan,Kaidi Xu,Zhenhua Guo,Xiaofeng Zhu,Xiaoshuang Shi*

Main category: cs.CV

TL;DR: 论文提出了一种空间评估流程和基准测试，用于评估视觉语言模型（VLMs）的空间理解能力，发现现有模型表现远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 现实应用（如自动驾驶和人形机器人操作）需要精确的空间感知，但VLMs的空间关系识别能力尚未充分探索。

Method: 构建合成数据集，将空间理解分为绝对空间理解和3D空间理解，并对多种VLMs进行实验。

Result: 人类在所有任务中表现近乎完美，而VLMs仅在两个最简单任务中达到人类水平，其他任务表现显著较差，部分任务得分接近零。

Conclusion: 现有VLMs的空间理解能力仍有显著提升空间，合成数据集为低成本测试提供了可能。

Abstract: Real-world applications, such as autonomous driving and humanoid robot
manipulation, require precise spatial perception. However, it remains
underexplored how Vision-Language Models (VLMs) recognize spatial relationships
and perceive spatial movement. In this work, we introduce a spatial evaluation
pipeline and construct a corresponding benchmark. Specifically, we categorize
spatial understanding into two main types: absolute spatial understanding,
which involves querying the absolute spatial position (e.g., left, right) of an
object within an image, and 3D spatial understanding, which includes movement
and rotation. Notably, our dataset is entirely synthetic, enabling the
generation of test samples at a low cost while also preventing dataset
contamination. We conduct experiments on multiple state-of-the-art VLMs and
observe that there is significant room for improvement in their spatial
understanding abilities. Explicitly, in our experiments, humans achieve
near-perfect performance on all tasks, whereas current VLMs attain human-level
performance only on the two simplest tasks. For the remaining tasks, the
performance of VLMs is distinctly lower than that of humans. In fact, the
best-performing Vision-Language Models even achieve near-zero scores on
multiple tasks. The dataset and code are available on
https://github.com/kong13661/LRR-Bench.

</details>


### [5] [Towards Universal Modal Tracking with Online Dense Temporal Token Learning](https://arxiv.org/abs/2507.20177)
*Yaozong Zheng,Bineng Zhong,Qihua Liang,Shengping Zhang,Guorong Li,Xianxian Li,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出了一种通用的视频级模态感知跟踪模型（Modaltracker），支持多种跟踪任务，通过视频级采样、关联和模态扩展实现高效多任务推理。


<details>
  <summary>Details</summary>
Motivation: 解决多模态跟踪任务中模型独立训练和性能提升的问题，提出统一架构和参数共享方案。

Method: 采用视频级采样和关联机制，结合门控注意力学习跨模态表示，并通过一次性训练实现多任务推理。

Result: 在可见和多模态基准测试中达到SOTA性能。

Conclusion: Modaltracker通过统一架构和参数共享，显著提升了多模态跟踪任务的效率和性能。

Abstract: We propose a universal video-level modality-awareness tracking model with
online dense temporal token learning (called {\modaltracker}). It is designed
to support various tracking tasks, including RGB, RGB+Thermal, RGB+Depth, and
RGB+Event, utilizing the same model architecture and parameters. Specifically,
our model is designed with three core goals: \textbf{Video-level Sampling}. We
expand the model's inputs to a video sequence level, aiming to see a richer
video context from an near-global perspective. \textbf{Video-level
Association}. Furthermore, we introduce two simple yet effective online dense
temporal token association mechanisms to propagate the appearance and motion
trajectory information of target via a video stream manner. \textbf{Modality
Scalable}. We propose two novel gated perceivers that adaptively learn
cross-modal representations via a gated attention mechanism, and subsequently
compress them into the same set of model parameters via a one-shot training
manner for multi-task inference. This new solution brings the following
benefits: (i) The purified token sequences can serve as temporal prompts for
the inference in the next video frames, whereby previous information is
leveraged to guide future inference. (ii) Unlike multi-modal trackers that
require independent training, our one-shot training scheme not only alleviates
the training burden, but also improves model representation. Extensive
experiments on visible and multi-modal benchmarks show that our {\modaltracker}
achieves a new \textit{SOTA} performance. The code will be available at
https://github.com/GXNU-ZhongLab/ODTrack.

</details>


### [6] [T$^\text{3}$SVFND: Towards an Evolving Fake News Detector for Emergencies with Test-time Training on Short Video Platforms](https://arxiv.org/abs/2507.20286)
*Liyuan Zhang,Zeyun Cheng,Yan Yang,Yong Liu,Jinke Ma*

Main category: cs.CV

TL;DR: 提出了一种基于测试时训练（TTT）的假新闻视频检测框架T$^3$SVFND，通过自监督辅助任务增强模型对紧急新闻的检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法因不同事件间的分布偏移而泛化能力不足，尤其在紧急新闻中表现显著下降。

Method: 设计了一个基于掩码语言建模（MLM）的自监督辅助任务，结合多模态（音频和视频）上下文信息预测掩码词，并在测试时训练阶段通过辅助任务适应测试数据分布。

Result: 在公开基准测试中表现优异，特别是在紧急新闻检测方面。

Conclusion: T$^3$SVFND框架有效提升了假新闻视频检测的鲁棒性，尤其在紧急新闻场景中表现突出。

Abstract: The existing methods for fake news videos detection may not be generalized,
because there is a distribution shift between short video news of different
events, and the performance of such techniques greatly drops if news records
are coming from emergencies. We propose a new fake news videos detection
framework (T$^3$SVFND) using Test-Time Training (TTT) to alleviate this
limitation, enhancing the robustness of fake news videos detection.
Specifically, we design a self-supervised auxiliary task based on Mask Language
Modeling (MLM) that masks a certain percentage of words in text and predicts
these masked words by combining contextual information from different
modalities (audio and video). In the test-time training phase, the model adapts
to the distribution of test data through auxiliary tasks. Extensive experiments
on the public benchmark demonstrate the effectiveness of the proposed model,
especially for the detection of emergency news.

</details>


### [7] [DAMS:Dual-Branch Adaptive Multiscale Spatiotemporal Framework for Video Anomaly Detection](https://arxiv.org/abs/2507.20629)
*Dezhi An,Wenqiang Liu,Kefan Wang,Zening Chen,Jun Lu,Shengcai Zhang*

Main category: cs.CV

TL;DR: 提出了一种双路径架构（DAMS），结合多尺度时空特征和跨模态语义对齐，用于视频异常检测。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测面临多尺度时间依赖性、视觉-语义异质性和标记数据稀缺的挑战。

Method: DAMS框架包括主路径（AMTPN+CBAM）和并行路径（CLIP驱动的跨模态语义对齐），通过特征解耦与融合实现高效建模。

Result: 在UCF-Crime和XD-Violence基准测试中验证了DAMS的有效性。

Conclusion: DAMS通过双路径互补和信息融合，实现了对异常事件的全面表征与识别。

Abstract: The goal of video anomaly detection is tantamount to performing
spatio-temporal localization of abnormal events in the video. The multiscale
temporal dependencies, visual-semantic heterogeneity, and the scarcity of
labeled data exhibited by video anomalies collectively present a challenging
research problem in computer vision. This study offers a dual-path architecture
called the Dual-Branch Adaptive Multiscale Spatiotemporal Framework (DAMS),
which is based on multilevel feature decoupling and fusion, enabling efficient
anomaly detection modeling by integrating hierarchical feature learning and
complementary information. The main processing path of this framework
integrates the Adaptive Multiscale Time Pyramid Network (AMTPN) with the
Convolutional Block Attention Mechanism (CBAM). AMTPN enables multigrained
representation and dynamically weighted reconstruction of temporal features
through a three-level cascade structure (time pyramid pooling, adaptive feature
fusion, and temporal context enhancement). CBAM maximizes the entropy
distribution of feature channels and spatial dimensions through dual attention
mapping. Simultaneously, the parallel path driven by CLIP introduces a
contrastive language-visual pre-training paradigm. Cross-modal semantic
alignment and a multiscale instance selection mechanism provide high-order
semantic guidance for spatio-temporal features. This creates a complete
inference chain from the underlying spatio-temporal features to high-level
semantic concepts. The orthogonal complementarity of the two paths and the
information fusion mechanism jointly construct a comprehensive representation
and identification capability for anomalous events. Extensive experimental
results on the UCF-Crime and XD-Violence benchmarks establish the effectiveness
of the DAMS framework.

</details>


### [8] [Learning to See Inside Opaque Liquid Containers using Speckle Vibrometry](https://arxiv.org/abs/2507.20757)
*Matan Kichler,Shai Bagon,Mark Sheinin*

Main category: cs.CV

TL;DR: 该论文提出了一种通过检测表面微小振动来推断不透明容器内隐藏液体水平的新方法，扩展了计算机视觉的能力。


<details>
  <summary>Details</summary>
Motivation: 传统视觉系统只能从物体可见表面提取信息，无法判断容器内液体水平。本文旨在解决这一问题。

Method: 提出了一种基于散斑的振动传感系统，结合Transformer模型分析振动数据，分类容器类型和液体水平。

Result: 模型对振动源具有不变性，能泛化到未见过的容器实例和液体水平，成功恢复了多种日常容器的液体水平。

Conclusion: 该方法为远程、非接触式检测容器内液体水平提供了创新解决方案。

Abstract: Computer vision seeks to infer a wide range of information about objects and
events. However, vision systems based on conventional imaging are limited to
extracting information only from the visible surfaces of scene objects. For
instance, a vision system can detect and identify a Coke can in the scene, but
it cannot determine whether the can is full or empty. In this paper, we aim to
expand the scope of computer vision to include the novel task of inferring the
hidden liquid levels of opaque containers by sensing the tiny vibrations on
their surfaces. Our method provides a first-of-a-kind way to inspect the fill
level of multiple sealed containers remotely, at once, without needing physical
manipulation and manual weighing. First, we propose a novel speckle-based
vibration sensing system for simultaneously capturing scene vibrations on a 2D
grid of points. We use our system to efficiently and remotely capture a dataset
of vibration responses for a variety of everyday liquid containers. Then, we
develop a transformer-based approach for analyzing the captured vibrations and
classifying the container type and its hidden liquid level at the time of
measurement. Our architecture is invariant to the vibration source, yielding
correct liquid level estimates for controlled and ambient scene sound sources.
Moreover, our model generalizes to unseen container instances within known
classes (e.g., training on five Coke cans of a six-pack, testing on a sixth)
and fluid levels. We demonstrate our method by recovering liquid levels from
various everyday containers.

</details>


### [9] [Event-Based De-Snowing for Autonomous Driving](https://arxiv.org/abs/2507.20901)
*Manasi Muglikar,Nico Messikommer,Marco Cannici,Davide Scaramuzza*

Main category: cs.CV

TL;DR: 提出了一种基于事件相机的去雪方法，利用雪花的时空特征，通过注意力模块恢复背景信息，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统图像和视频去雪方法存在幻觉伪影和对高帧率的依赖问题，事件相机因其低延迟特性成为理想解决方案。

Method: 设计基于注意力的模块，利用事件数据中雪花的条纹特征，恢复被遮挡的背景点强度。

Result: 在PSNR上优于现有方法3 dB，且能提升深度估计和光流任务的性能20%。

Conclusion: 该方法为恶劣天气下的视觉系统提供了更可靠的解决方案，推动了全天候应用的发展。

Abstract: Adverse weather conditions, particularly heavy snowfall, pose significant
challenges to both human drivers and autonomous vehicles. Traditional
image-based de-snowing methods often introduce hallucination artifacts as they
rely solely on spatial information, while video-based approaches require high
frame rates and suffer from alignment artifacts at lower frame rates. Camera
parameters, such as exposure time, also influence the appearance of snowflakes,
making the problem difficult to solve and heavily dependent on network
generalization. In this paper, we propose to address the challenge of desnowing
by using event cameras, which offer compressed visual information with
submillisecond latency, making them ideal for de-snowing images, even in the
presence of ego-motion. Our method leverages the fact that snowflake occlusions
appear with a very distinctive streak signature in the spatio-temporal
representation of event data. We design an attention-based module that focuses
on events along these streaks to determine when a background point was occluded
and use this information to recover its original intensity. We benchmark our
method on DSEC-Snow, a new dataset created using a green-screen technique that
overlays pre-recorded snowfall data onto the existing DSEC driving dataset,
resulting in precise ground truth and synchronized image and event streams. Our
approach outperforms state-of-the-art de-snowing methods by 3 dB in PSNR for
image reconstruction. Moreover, we show that off-the-shelf computer vision
algorithms can be applied to our reconstructions for tasks such as depth
estimation and optical flow, achieving a $20\%$ performance improvement over
other de-snowing methods. Our work represents a crucial step towards enhancing
the reliability and safety of vision systems in challenging winter conditions,
paving the way for more robust, all-weather-capable applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [Clinical-Grade Blood Pressure Prediction in ICU Settings: An Ensemble Framework with Uncertainty Quantification and Cross-Institutional Validation](https://arxiv.org/abs/2507.19530)
*Md Basit Azam,Sarangthem Ibotombi Singh*

Main category: cs.LG

TL;DR: 该研究提出了一种基于电子健康记录（EHR）的血压预测框架，解决了现有机器学习方法在外部验证、不确定性量化和数据泄漏预防方面的不足。


<details>
  <summary>Details</summary>
Motivation: ICU中血压监测至关重要，但现有方法缺乏外部验证、不确定性量化和数据泄漏预防。

Method: 采用集成框架（Gradient Boosting、Random Forest、XGBoost），结合74个生理特征，通过分位数回归量化不确定性，并在MIMIC-III和eICU数据库间进行外部验证。

Result: 内部验证性能达标（SBP: R²=0.86, RMSE=6.03 mmHg; DBP: R²=0.49, RMSE=7.13 mmHg），外部验证性能下降30%。不确定性量化生成有效预测区间。

Conclusion: 该框架为跨机构AI辅助血压监测提供了实用方案，并公开了源代码。

Abstract: Blood pressure (BP) monitoring is critical in in tensive care units (ICUs)
where hemodynamic instability can
  rapidly progress to cardiovascular collapse. Current machine
  learning (ML) approaches suffer from three limitations: lack of
  external validation, absence of uncertainty quantification, and
  inadequate data leakage prevention. This study presents the
  first comprehensive framework with novel algorithmic leakage
  prevention, uncertainty quantification, and cross-institutional
  validation for electronic health records (EHRs) based BP pre dictions. Our
methodology implemented systematic data leakage
  prevention, uncertainty quantification through quantile regres sion, and
external validation between the MIMIC-III and eICU
  databases. An ensemble framework combines Gradient Boosting,
  Random Forest, and XGBoost with 74 features across five
  physiological domains. Internal validation achieved a clinically
  acceptable performance (for SBP: R^2 = 0.86, RMSE = 6.03
  mmHg; DBP: R^2 = 0.49, RMSE = 7.13 mmHg), meeting AAMI
  standards. External validation showed 30% degradation with
  critical limitations in patients with hypotensive. Uncertainty
  quantification generated valid prediction intervals (80.3% SBP
  and 79.9% DBP coverage), enabling risk-stratified protocols
  with narrow intervals (< 15 mmHg) for standard monitoring
  and wide intervals (> 30 mmHg) for manual verification. This
  framework provides realistic deployment expectations for cross institutional
AI-assisted BP monitoring in critical care settings.
  The source code is publicly available at https://github.com/
  mdbasit897/clinical-bp-prediction-ehr.

</details>


### [11] [GNSP: Gradient Null Space Projection for Preserving Cross-Modal Alignment in VLMs Continual Learning](https://arxiv.org/abs/2507.19839)
*Tiantian Peng,Yuyang Liu,Shuo Yang,Qiuhe Hong,YongHong Tian*

Main category: cs.LG

TL;DR: 提出了Gradient Null Space Projection (GNSP)方法，用于解决CLIP在持续学习中的灾难性遗忘问题，同时保持其零样本能力。


<details>
  <summary>Details</summary>
Motivation: CLIP在持续学习任务中会出现灾难性遗忘和嵌入对齐退化的问题，影响其零样本泛化能力。

Method: 采用GNSP方法，将任务特定梯度投影到先前知识的零空间，避免干扰；结合知识蒸馏和模态对齐损失，保持多模态嵌入空间结构。

Result: 在MTIL基准测试中取得SOTA性能，同时保持了CLIP的模态间隙和跨模态检索性能。

Conclusion: GNSP方法有效解决了CLIP的持续学习问题，同时保持了其多模态嵌入空间的鲁棒性。

Abstract: Contrastive Language-Image Pretraining has demonstrated remarkable zero-shot
generalization by aligning visual and textual modalities in a shared embedding
space. However, when continuously fine-tuned on diverse tasks, CLIP suffers
from catastrophic forgetting and degradation of its embedding alignment,
undermining its zero-shot capabilities. In this work, we propose Gradient Null
Space Projection (GNSP), an efficient continual learning method that projects
task-specific gradients onto the null space of previously learned knowledge.
This orthogonal projection mathematically prevents interference with previous
tasks without relying on rehearsal or architectural modification. Furthermore,
to preserve the inherent generalization property of CLIP, we introduce
knowledge distillation and combine it with a modality alignment preservation
loss inspired by CLIP pre-training to stabilize the structure of the multimodal
embedding space during fine-tuning. On the MTIL benchmark consisting of 11
tasks, our method achieved SOTA performance on both the Average and Last key
metrics. More importantly, experiments show that our method successfully
maintains the original modality gap and cross-modal retrieval performance of
CLIP, confirming its effectiveness in maintaining a robust visual-language
space throughout the continual learning process.

</details>


### [12] [Improving Group Fairness in Tensor Completion via Imbalance Mitigating Entity Augmentation](https://arxiv.org/abs/2507.20542)
*Dawon Ahn,Jun-Gi Jang,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: STAFF方法通过增强稀疏张量中的实体来改善组公平性，同时降低整体张量补全误差。


<details>
  <summary>Details</summary>
Motivation: 解决现有张量分解方法在组公平性上的性能下降问题。

Method: 提出STAFF方法，通过增强稀疏张量中的实体来平衡不同组的补全误差差距。

Result: 在多种数据集和模型下，STAFF在补全误差和组公平性之间取得了最佳平衡，MSE和MADE分别降低了36%和59%。

Conclusion: STAFF是一种有效的张量分解方法，显著提升了组公平性和性能。

Abstract: Group fairness is important to consider in tensor decomposition to prevent
discrimination based on social grounds such as gender or age. Although few
works have studied group fairness in tensor decomposition, they suffer from
performance degradation. To address this, we propose STAFF(Sparse Tensor
Augmentation For Fairness) to improve group fairness by minimizing the gap in
completion errors of different groups while reducing the overall tensor
completion error. Our main idea is to augment a tensor with augmented entities
including sufficient observed entries to mitigate imbalance and group bias in
the sparse tensor. We evaluate \method on tensor completion with various
datasets under conventional and deep learning-based tensor models. STAFF
consistently shows the best trade-off between completion error and group
fairness; at most, it yields 36% lower MSE and 59% lower MADE than the
second-best baseline.

</details>


### [13] [Reminiscence Attack on Residuals: Exploiting Approximate Machine Unlearning for Privacy](https://arxiv.org/abs/2507.20573)
*Yaxin Xiao,Qingqing Ye,Li Hu,Huadi Zheng,Haibo Hu,Zi Liang,Haoyang Li,Yijie Jiao*

Main category: cs.LG

TL;DR: 论文揭示了近似遗忘算法在保护未学习数据隐私方面的不足，并提出了一种新的攻击方法（ReA）和双阶段遗忘框架以解决隐私风险。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示近似遗忘算法未能充分保护未学习数据的隐私，并提出解决方案。

Method: 提出Reminiscence Attack（ReA）和双阶段近似遗忘框架，包括消除深层未学习数据痕迹和强制收敛稳定性。

Result: ReA攻击在推断类级和样本级成员隐私时分别比现有攻击高1.90倍和1.12倍。双阶段框架将自适应隐私攻击准确率降至接近随机猜测，计算成本仅为完全重新训练的2-12%。

Conclusion: 双阶段近似遗忘框架在保持高效遗忘的同时显著降低隐私风险，适用于分类和生成任务。

Abstract: Machine unlearning enables the removal of specific data from ML models to
uphold the right to be forgotten. While approximate unlearning algorithms offer
efficient alternatives to full retraining, this work reveals that they fail to
adequately protect the privacy of unlearned data. In particular, these
algorithms introduce implicit residuals which facilitate privacy attacks
targeting at unlearned data. We observe that these residuals persist regardless
of model architectures, parameters, and unlearning algorithms, exposing a new
attack surface beyond conventional output-based leakage. Based on this insight,
we propose the Reminiscence Attack (ReA), which amplifies the correlation
between residuals and membership privacy through targeted fine-tuning
processes. ReA achieves up to 1.90x and 1.12x higher accuracy than prior
attacks when inferring class-wise and sample-wise membership, respectively. To
mitigate such residual-induced privacy risk, we develop a dual-phase
approximate unlearning framework that first eliminates deep-layer unlearned
data traces and then enforces convergence stability to prevent models from
"pseudo-convergence", where their outputs are similar to retrained models but
still preserve unlearned residuals. Our framework works for both classification
and generation tasks. Experimental evaluations confirm that our approach
maintains high unlearning efficacy, while reducing the adaptive privacy attack
accuracy to nearly random guess, at the computational cost of 2-12% of full
retraining from scratch.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [14] [Integrating Activity Predictions in Knowledge Graphs](https://arxiv.org/abs/2507.19733)
*Alec Scully,Cameron Stockton,Forrest Hare*

Main category: cs.AI

TL;DR: 论文探讨了基于本体结构知识图谱预测未来事件的方法，结合BFO和CCO语义框架，通过马尔可夫链模型预测船只未来状态，并提出了新的概率观点。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用本体结构知识图谱提升对未来事件的预测能力，同时批判现有概率模型的不足。

Method: 利用BFO和CCO语义框架组织数据，构建马尔可夫链模型预测未来状态，并引入“时空实例”概念完善语义结构。

Result: 展示了如何将马尔可夫链概率计算无缝集成回知识图谱，支持进一步分析和决策。

Conclusion: 提出了一种基于过程轮廓的概率新观点，优化了动态现象的建模，并验证了方法的实用性。

Abstract: We argue that ontology-structured knowledge graphs can play a crucial role in
generating predictions about future events. By leveraging the semantic
framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies
(CCO), we demonstrate how data such as the movements of a fishing vessel can be
organized in and retrieved from a knowledge graph. These query results are then
used to create Markov chain models, allowing us to predict future states based
on the vessel's history. To fully support this process, we introduce the term
`spatiotemporal instant' to complete the necessary structural semantics.
Additionally, we critique the prevailing ontological model of probability,
which conflates probability with likelihood and relies on the problematic
concept of modal measurements: measurements of future entities. We propose an
alternative view, where probabilities are treated as being about process
profiles, which better captures the dynamics of real world phenomena. Finally,
we demonstrate how our Markov chain based probability calculations can be
seamlessly integrated back into the knowledge graph, enabling further analysis
and decision-making. Keywords: predictive analytics, ontology, Markov chains,
probability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL.

</details>


### [15] [Beyond Listenership: AI-Predicted Interventions Drive Improvements in Maternal Health Behaviours](https://arxiv.org/abs/2507.20755)
*Arpan Dasgupta,Sarvesh Gharat,Neha Madhiwalla,Aparna Hegde,Milind Tambe,Aparna Taneja*

Main category: cs.AI

TL;DR: AI模型通过优化电话干预时间提升听众参与度，并显著改善母婴健康行为和知识。


<details>
  <summary>Details</summary>
Motivation: 解决现有健康信息自动语音电话项目中听众流失和参与度低的问题，并验证AI干预是否能转化为实际健康行为改善。

Method: 使用AI模型（restless bandit模型）识别最需要干预的受益者，并通过实验验证其对健康行为的影响。

Result: AI干预显著提升了听众参与度，并改善了受益者的健康行为（如补充铁和钙）和健康知识。

Conclusion: AI在母婴健康领域具有推动实质性改善的潜力。

Abstract: Automated voice calls with health information are a proven method for
disseminating maternal and child health information among beneficiaries and are
deployed in several programs around the world. However, these programs often
suffer from beneficiary dropoffs and poor engagement. In previous work, through
real-world trials, we showed that an AI model, specifically a restless bandit
model, could identify beneficiaries who would benefit most from live service
call interventions, preventing dropoffs and boosting engagement. However, one
key question has remained open so far: does such improved listenership via
AI-targeted interventions translate into beneficiaries' improved knowledge and
health behaviors? We present a first study that shows not only listenership
improvements due to AI interventions, but also simultaneously links these
improvements to health behavior changes. Specifically, we demonstrate that
AI-scheduled interventions, which enhance listenership, lead to statistically
significant improvements in beneficiaries' health behaviors such as taking iron
or calcium supplements in the postnatal period, as well as understanding of
critical health topics during pregnancy and infancy. This underscores the
potential of AI to drive meaningful improvements in maternal and child health.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities](https://arxiv.org/abs/2507.19766)
*Dong Du,Shulin Liu,Tao Yang,Shaohua Chen,Yang Li*

Main category: cs.CL

TL;DR: 论文提出了一种针对超长输出的强化学习方法（UloRL），通过分段解码和动态掩码技术，提升了大型语言模型的推理能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习框架在处理超长输出时效率低下，存在长尾序列分布和熵崩溃问题，限制了大型语言模型的推理能力提升。

Method: 将超长输出解码分为短片段，并引入动态掩码技术（MPTs），以优化训练效率和防止熵崩溃。

Result: 实验显示，UloRL在Qwen3-30B-A3B模型上训练速度提升2.06倍，性能在AIME2025和BeyondAIME任务上分别提升至85.1%和61.9%。

Conclusion: UloRL方法显著提升了大型语言模型在超长序列生成中的推理能力，具有广泛的应用潜力。

Abstract: Recent advances in large language models (LLMs) have highlighted the
potential of reinforcement learning with verifiable rewards (RLVR) to enhance
reasoning capabilities through extended output sequences. However, traditional
RL frameworks face inefficiencies when handling ultra-long outputs due to
long-tail sequence distributions and entropy collapse during training. To
address these challenges, we propose an Ultra-Long Output Reinforcement
Learning (UloRL) approach for advancing large language models' reasoning
abilities. Specifically, we divide ultra long output decoding into short
segments, enabling efficient training by mitigating delays caused by long-tail
samples. Additionally, we introduce dynamic masking of well-Mastered Positive
Tokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the
effectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment
rollout achieved 2.06x increase in training speed, while RL training with
128k-token outputs improves the model's performance on AIME2025 from 70.9\% to
85.1\% and on BeyondAIME from 50.7\% to 61.9\%, even surpassing Qwen3-235B-A22B
with remarkable gains. These findings underscore the potential of our methods
to advance the reasoning capabilities of LLMs with ultra-long sequence
generation. We will release our code and model for further use by the
community.

</details>


### [17] [ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning](https://arxiv.org/abs/2507.20564)
*Duc-Tai Dinh,Duc Anh Khoa Dinh*

Main category: cs.CL

TL;DR: ZSE-Cap系统在EVENTA任务中排名第四，采用零样本方法，结合CLIP、SigLIP和DINOv2进行检索，并利用Gemma 3模型生成图像描述。


<details>
  <summary>Details</summary>
Motivation: 研究目的是通过零样本方法（无需微调）在图像检索和描述任务中取得高效表现。

Method: 检索部分集成CLIP、SigLIP和DINOv2的相似度分数；描述部分通过精心设计的提示词引导Gemma 3模型生成图像描述。

Result: 系统最终得分为0.42002，在测试集上排名第四。

Conclusion: 通过集成基础模型和提示工程，展示了零样本方法的有效性。

Abstract: We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system
in Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image
retrieval and captioning. Our zero-shot approach requires no finetuning on the
competition's data. For retrieval, we ensemble similarity scores from CLIP,
SigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt
to guide the Gemma 3 model, enabling it to link high-level events from the
article to the visual content in the image. Our system achieved a final score
of 0.42002, securing a top-4 position on the private test set, demonstrating
the effectiveness of combining foundation models through ensembling and
prompting. Our code is available at https://github.com/ductai05/ZSE-Cap.

</details>


### [18] [Automating Thematic Review of Prevention of Future Deaths Reports: Replicating the ONS Child Suicide Study using Large Language Models](https://arxiv.org/abs/2507.20786)
*Sam Osian,Arpan Dutta,Sahil Bhandari,Iain E. Buchan,Dan W. Joyce*

Main category: cs.CL

TL;DR: 本文评估了一种自动化语言模型工具（PFD Toolkit）在识别和分析儿童自杀相关PFD报告中的效果，发现其比手动方法更高效且可靠。


<details>
  <summary>Details</summary>
Motivation: 传统手动分析PFD报告耗时且效率低，需要一种自动化方法来提高效率和可靠性。

Method: 使用PFD Toolkit处理4,249份PFD报告，通过LLM自动筛选和编码儿童自杀案例。

Result: 工具识别出72例儿童自杀报告（是手动方法的两倍），且与专家评估一致性高（Cohen's κ = 0.82）。

Conclusion: 自动化LLM分析可高效复制手动主题分析，为公共卫生提供可扩展且及时的见解。

Abstract: Prevention of Future Deaths (PFD) reports, issued by coroners in England and
Wales, flag systemic hazards that may lead to further loss of life. Analysis of
these reports has previously been constrained by the manual effort required to
identify and code relevant cases. In 2025, the Office for National Statistics
(ONS) published a national thematic review of child-suicide PFD reports ($\leq$
18 years), identifying 37 cases from January 2015 to November 2023 - a process
based entirely on manual curation and coding. We evaluated whether a fully
automated, open source "text-to-table" language-model pipeline (PFD Toolkit)
could reproduce the ONS's identification and thematic analysis of child-suicide
PFD reports, and assessed gains in efficiency and reliability. All 4,249 PFD
reports published from July 2013 to November 2023 were processed via PFD
Toolkit's large language model pipelines. Automated screening identified cases
where the coroner attributed death to suicide in individuals aged 18 or
younger, and eligible reports were coded for recipient category and 23 concern
sub-themes, replicating the ONS coding frame. PFD Toolkit identified 72
child-suicide PFD reports - almost twice the ONS count. Three blinded
clinicians adjudicated a stratified sample of 144 reports to validate the
child-suicide screening. Against the post-consensus clinical annotations, the
LLM-based workflow showed substantial to almost-perfect agreement (Cohen's
$\kappa$ = 0.82, 95% CI: 0.66-0.98, raw agreement = 91%). The end-to-end script
runtime was 8m 16s, transforming a process that previously took months into one
that can be completed in minutes. This demonstrates that automated LLM analysis
can reliably and efficiently replicate manual thematic reviews of coronial
data, enabling scalable, reproducible, and timely insights for public health
and safety. The PFD Toolkit is openly available for future research.

</details>


### [19] [Memorization in Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.21009)
*Danil Savine,Muni Sreenivas Pydi,Jamal Atif,Olivier Cappé*

Main category: cs.CL

TL;DR: 研究探讨了微调大型语言模型（LLMs）中记忆化的机制及影响因素，重点关注医疗领域的数据隐私问题。通过PHEE数据集，分析了微调过程中不同因素对模型记忆训练数据的影响。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的数据隐私敏感性促使研究微调LLMs时的记忆化问题，以平衡模型性能与隐私风险。

Method: 采用成员推理攻击检测记忆数据，并通过生成任务评估逐字复现。分析了Transformer架构中不同权重矩阵、困惑度与记忆化的关系，以及低秩适应（LoRA）微调中秩增加的影响。

Result: 发现Value和Output矩阵对记忆化贡献更大；低困惑度与高记忆化相关；高LoRA秩增加记忆化但边际效应递减。

Conclusion: 研究结果为微调LLMs时平衡性能与隐私提供了策略指导，有助于开发更负责任的语言模型适应方法。

Abstract: This study investigates the mechanisms and factors influencing memorization
in fine-tuned large language models (LLMs), with a focus on the medical domain
due to its privacy-sensitive nature. We examine how different aspects of the
fine-tuning process affect a model's propensity to memorize training data,
using the PHEE dataset of pharmacovigilance events.
  Our research employs two main approaches: a membership inference attack to
detect memorized data, and a generation task with prompted prefixes to assess
verbatim reproduction. We analyze the impact of adapting different weight
matrices in the transformer architecture, the relationship between perplexity
and memorization, and the effect of increasing the rank in low-rank adaptation
(LoRA) fine-tuning.
  Key findings include: (1) Value and Output matrices contribute more
significantly to memorization compared to Query and Key matrices; (2) Lower
perplexity in the fine-tuned model correlates with increased memorization; (3)
Higher LoRA ranks lead to increased memorization, but with diminishing returns
at higher ranks.
  These results provide insights into the trade-offs between model performance
and privacy risks in fine-tuned LLMs. Our findings have implications for
developing more effective and responsible strategies for adapting large
language models while managing data privacy concerns.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [Bridging Simulation and Usability: A User-Friendly Framework for Scenario Generation in CARLA](https://arxiv.org/abs/2507.19883)
*Ahmed Abouelazm,Mohammad Mahmoud,Conrad Walter,Oleksandr Shchetsura,Erne Hussong,Helen Gremmelmaier,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 论文提出了一种无需编程的交互式场景生成框架，用于自动驾驶系统的验证，通过图形界面降低使用门槛。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的大规模验证在现实世界中成本高且不安全，而现有仿真工具需要编程知识，限制了非技术用户的使用。

Method: 开发了一个基于图形的交互式框架，支持手动和自动生成场景，无需编程知识。

Result: 该框架简化了场景生成过程，提高了仿真验证的效率和可访问性。

Conclusion: 该框架为研究人员、工程师和政策制定者提供了更高效的测试工具，推动了自动驾驶验证的发展。

Abstract: Autonomous driving promises safer roads, reduced congestion, and improved
mobility, yet validating these systems across diverse conditions remains a
major challenge. Real-world testing is expensive, time-consuming, and sometimes
unsafe, making large-scale validation impractical. In contrast, simulation
environments offer a scalable and cost-effective alternative for rigorous
verification and validation. A critical component of the validation process is
scenario generation, which involves designing and configuring traffic scenarios
to evaluate autonomous systems' responses to various events and uncertainties.
However, existing scenario generation tools often require programming
knowledge, limiting accessibility for non-technical users. To address this
limitation, we present an interactive, no-code framework for scenario
generation. Our framework features a graphical interface that enables users to
create, modify, save, load, and execute scenarios without needing coding
expertise or detailed simulation knowledge. Unlike script-based tools such as
Scenic or ScenarioRunner, our approach lowers the barrier to entry and supports
a broader user base. Central to our framework is a graph-based scenario
representation that facilitates structured management, supports both manual and
automated generation, and enables integration with deep learning-based scenario
and behavior generation methods. In automated mode, the framework can randomly
sample parameters such as actor types, behaviors, and environmental conditions,
allowing the generation of diverse and realistic test datasets. By simplifying
the scenario generation process, this framework supports more efficient testing
workflows and increases the accessibility of simulation-based validation for
researchers, engineers, and policymakers.

</details>


### [21] [High-Speed Event Vision-Based Tactile Roller Sensor for Large Surface Measurements](https://arxiv.org/abs/2507.19914)
*Akram Khairi,Hussain Sajwani,Abdallah Mohammad Alkilany,Laith AbuAssi,Mohamad Halwani,Islam Mohamed Zaid,Ahmed Awadalla,Dewald Swart,Abdulla Ayyad,Yahya Zweiri*

Main category: cs.RO

TL;DR: 提出了一种新型触觉传感器，结合神经形态相机和滚动机制，实现快速、连续、高分辨率的3D表面扫描。


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉传感器在大面积扫描时速度慢且受限于相机帧率和运动模糊，需要一种更高效的解决方案。

Method: 采用神经形态相机和滚动机制，结合改进的事件多视图立体方法进行3D重建，并使用贝叶斯融合策略提高精度。

Result: 扫描速度达0.5 m/s，平均绝对误差低于100微米，比现有方法快11倍，精度提高25.2%。

Conclusion: 新方法显著提升了扫描速度和精度，适用于工业表面检测。

Abstract: Inspecting large-scale industrial surfaces like aircraft fuselages for
quality control requires capturing their precise 3D surface geometry at high
resolution. Vision-based tactile sensors (VBTSs) offer high local resolution
but require slow 'press-and-lift' measurements stitched for large areas.
Approaches with sliding or roller/belt VBTS designs provide measurements
continuity. However, they face significant challenges respectively: sliding
struggles with friction/wear and both approaches are speed-limited by
conventional camera frame rates and motion blur, making large-area scanning
time consuming. Thus, a rapid, continuous, high-resolution method is needed. We
introduce a novel tactile sensor integrating a neuromorphic camera in a rolling
mechanism to achieve this. Leveraging its high temporal resolution and
robustness to motion blur, our system uses a modified event-based multi-view
stereo approach for 3D reconstruction. We demonstrate state-of-the-art scanning
speeds up to 0.5 m/s, achieving Mean Absolute Error below 100 microns -- 11
times faster than prior continuous tactile sensing methods. A multi-reference
Bayesian fusion strategy enhances accuracy (reducing MAE by 25.2\% compared to
EMVS) and mitigates curvature errors. We also validate high-speed feature
recognition via Braille reading 2.6 times faster than previous approaches.

</details>


### [22] [A roadmap for AI in robotics](https://arxiv.org/abs/2507.19975)
*Aude Billard,Alin Albu-Schaeffer,Michael Beetz,Wolfram Burgard,Peter Corke,Matei Ciocarlie,Ravinder Dahiya,Danica Kragic,Ken Goldberg,Yukie Nagai,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文评估了AI在机器人领域的成就，并提出了短期和中期的研究路线图，包括数据集更新、算法设计、人机协作等挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用AI技术解决机器人部署中的障碍，并反思哪些AI技术最适合机器人应用。

Method: 评估自1990年代以来AI在机器人领域的进展，并提出研究路线图。

Result: 指出了从数据集到算法设计的具体挑战，并强调了透明度和可解释性的重要性。

Conclusion: 长期挑战包括设计具备终身学习能力的机器人，同时确保安全性和可持续的计算成本。

Abstract: AI technologies, including deep learning, large-language models have gone
from one breakthrough to the other. As a result, we are witnessing growing
excitement in robotics at the prospect of leveraging the potential of AI to
tackle some of the outstanding barriers to the full deployment of robots in our
daily lives. However, action and sensing in the physical world pose greater and
different challenges than analysing data in isolation. As the development and
application of AI in robotic products advances, it is important to reflect on
which technologies, among the vast array of network architectures and learning
models now available in the AI field, are most likely to be successfully
applied to robots; how they can be adapted to specific robot designs, tasks,
environments; which challenges must be overcome. This article offers an
assessment of what AI for robotics has achieved since the 1990s and proposes a
short- and medium-term research roadmap listing challenges and promises. These
range from keeping up-to-date large datasets, representatives of a diversity of
tasks robots may have to perform, and of environments they may encounter, to
designing AI algorithms tailored specifically to robotics problems but generic
enough to apply to a wide range of applications and transfer easily to a
variety of robotic platforms. For robots to collaborate effectively with
humans, they must predict human behavior without relying on bias-based
profiling. Explainability and transparency in AI-driven robot control are not
optional but essential for building trust, preventing misuse, and attributing
responsibility in accidents. We close on what we view as the primary long-term
challenges, that is, to design robots capable of lifelong learning, while
guaranteeing safe deployment and usage, and sustainable computational costs.

</details>


### [23] [A Strawberry Harvesting Tool with Minimal Footprint](https://arxiv.org/abs/2507.20784)
*Mohamed Sorour,Mohamed Heshmat,Khaled Elgeneidy,Pål Johan From*

Main category: cs.RO

TL;DR: 提出了一种新型草莓采摘原型，通过激光切割茎部，减少接触并延长果实保鲜期。


<details>
  <summary>Details</summary>
Motivation: 解决传统采摘方法可能传播植物病害的问题，同时提高采摘效率和果实保鲜。

Method: 使用平滑捕捉器将茎部引导至精确位置，通过高温激光切割茎部，杀菌并防止病害传播。

Result: 成功实现室内采摘，切割时间为2.88秒，循环时间为5.56秒，优化了激光参数。

Conclusion: 该原型高效且卫生，适用于草莓采摘，显著延长果实保鲜期。

Abstract: In this paper, a novel prototype for harvesting table-top grown strawberries
is presented, that is minimalist in its footprint interacting with the fruit.
In our methodology, a smooth trapper manipulates the stem into a precise groove
location at which a distant laser beam is focused. The tool reaches
temperatures as high as 188{\deg} Celsius and as such killing germs and
preventing the spread of local plant diseases. The burnt stem wound preserves
water content and in turn the fruit shelf life. Cycle and cut times achieved
are 5.56 and 2.88 seconds respectively in successful in-door harvesting
demonstration. Extensive experiments are performed to optimize the laser spot
diameter and lateral speed against the cutting time.

</details>


### [24] [A Human-in-the-loop Approach to Robot Action Replanning through LLM Common-Sense Reasoning](https://arxiv.org/abs/2507.20870)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 论文提出了一种结合视觉和自然语言输入的方法，通过大型语言模型（LLM）增强机器人执行计划，以提高非专家用户的编程效率。


<details>
  <summary>Details</summary>
Motivation: 为非专家提供更直观的机器人编程工具，解决仅依赖视觉输入的局限性和单次演示的不足。

Method: 基于单次RGB视频生成初始执行计划，并通过自然语言输入与LLM交互，调整计划以避免潜在错误并适应用户指令。

Result: 实验证明该方法能有效纠正视觉生成的错误，无需额外演示即可调整计划，提升了系统的鲁棒性。

Conclusion: 结合视觉和自然语言的方法为非专家提供了更高效的机器人编程工具，增强了系统的适应性和鲁棒性。

Abstract: To facilitate the wider adoption of robotics, accessible programming tools
are required for non-experts. Observational learning enables intuitive human
skills transfer through hands-on demonstrations, but relying solely on visual
input can be inefficient in terms of scalability and failure mitigation,
especially when based on a single demonstration. This paper presents a
human-in-the-loop method for enhancing the robot execution plan, automatically
generated based on a single RGB video, with natural language input to a Large
Language Model (LLM). By including user-specified goals or critical task
aspects and exploiting the LLM common-sense reasoning, the system adjusts the
vision-based plan to prevent potential failures and adapts it based on the
received instructions. Experiments demonstrated the framework intuitiveness and
effectiveness in correcting vision-derived errors and adapting plans without
requiring additional demonstrations. Moreover, interactive plan refinement and
hallucination corrections promoted system robustness.

</details>
