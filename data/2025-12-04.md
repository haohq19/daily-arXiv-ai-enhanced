<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ViDiC: Video Difference Captioning](https://arxiv.org/abs/2512.03405)
*Jiangtao Wu,Shihao Li,Zhaozhou Bian,Yuanxing Zhang,Jialu Chen,Runzhe Wen,An Ping,Yiwen He,Jiakai Wang,Jiaheng Liu*

Main category: cs.CV

TL;DR: 本文提出视频差异描述任务ViDiC及其数据集ViDiC-1K，用于评估多模态大语言模型描述视频对之间相似性和差异性的能力，发现现有模型在此任务上存在显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有图像差异描述方法无法捕捉动态场景中的运动连续性、事件演变或编辑一致性，视觉语言系统在比较动态场景的组成、空间和时间变化方面的能力尚未充分探索。

Method: 提出ViDiC任务和ViDiC-1K数据集，包含1000个精心策划的视频对，标注了4000多个比较检查项，涵盖7个类别。采用基于LLM-as-a-Judge协议的双检查表框架分别评估相似性和差异性的准确性。

Result: 在19个代表性多模态模型上的实验显示，它们在比较描述和差异感知能力方面存在显著性能差距，表明当前模型在此任务上仍有很大改进空间。

Conclusion: ViDiC-1K可作为具有挑战性的基准测试，为推进多模态智能中的视频理解、编辑感知和比较推理奠定坚实基础。

Abstract: Understanding visual differences between dynamic scenes requires the comparative perception of compositional, spatial, and temporal changes--a capability that remains underexplored in existing vision-language systems. While prior work on Image Difference Captioning (IDC) has enabled models to describe semantic changes between static images, these approaches fail to capture motion continuity, event evolution, or editing consistency over time. We introduce the ViDiC (Video Difference Captioning) task and its corresponding ViDiC-1K dataset, designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to provide fine-grained descriptions of similarities and differences between video pairs. ViDiC-1K comprises 1,000 curated video pairs annotated with over 4,000 comparative checklist items, covering seven categories: subject, style, background, cinematography, motion, location, and playback techniques. To ensure reliable evaluation, we propose a dual-checklist framework that measures the accuracy of similarity and difference separately, based on the LLM-as-a-Judge protocol. Experiments on nineteen representative multimodal models reveal a significant performance gap in their comparative description and difference perception abilities. We hope ViDiC-1K can be a challenging benchmark that lays a solid foundation for advancing video understanding, edit awareness, and comparative reasoning in multimodal intelligence.

</details>


### [2] [FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation](https://arxiv.org/abs/2512.03520)
*Yiyi Cai,Yuhan Wu,Kunhang Li,You Zhou,Bo Zheng,Haiyang Liu*

Main category: cs.CV

TL;DR: FloodDiffusion是一个用于文本驱动流式人体运动生成的新框架，通过改进的扩散强制方法实现实时延迟下的文本对齐无缝运动序列生成


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖分块处理或带扩散头的自回归模型，无法有效处理时间变化的文本提示下的流式运动生成任务，需要一种能保证输出分布建模的新框架

Method: 采用扩散强制框架，但改进了三个关键方面：1) 使用双向注意力而非因果注意力；2) 实现下三角时间调度器而非随机调度；3) 采用连续时间变化的方式引入文本条件

Result: 在HumanML3D基准测试中达到0.057的FID分数，首次证明扩散强制框架在流式运动生成任务上达到最先进性能

Conclusion: 通过改进的扩散强制框架，FloodDiffusion成功实现了文本对齐的实时流式人体运动生成，为时间序列生成任务提供了有效解决方案

Abstract: We present FloodDiffusion, a new framework for text-driven, streaming human motion generation. Given time-varying text prompts, FloodDiffusion generates text-aligned, seamless motion sequences with real-time latency. Unlike existing methods that rely on chunk-by-chunk or auto-regressive model with diffusion head, we adopt a diffusion forcing framework to model this time-series generation task under time-varying control events. We find that a straightforward implementation of vanilla diffusion forcing (as proposed for video models) fails to model real motion distributions. We demonstrate that to guarantee modeling the output distribution, the vanilla diffusion forcing must be tailored to: (i) train with a bi-directional attention instead of casual attention; (ii) implement a lower triangular time scheduler instead of a random one; (iii) utilize a continues time-varying way to introduce text conditioning. With these improvements, we demonstrate in the first time that the diffusion forcing-based framework achieves state-of-the-art performance on the streaming motion generation task, reaching an FID of 0.057 on the HumanML3D benchmark. Models, code, and weights are available. https://shandaai.github.io/FloodDiffusion/

</details>


### [3] [Out-of-the-box: Black-box Causal Attacks on Object Detectors](https://arxiv.org/abs/2512.03730)
*Melane Navaratnarajah,David A. Kelly,Hana Chockler*

Main category: cs.CV

TL;DR: BlackCAtt是一种黑盒对抗攻击方法，通过识别因果像素集来生成可解释、不可感知、可复现的对抗样本，攻击目标检测器使其丢失、修改或产生虚假检测框。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法多为白盒且架构特定，难以理解其成功机制。需要一种黑盒、架构无关的攻击方法，通过可解释的因果像素分析来揭示目标检测器的漏洞，帮助开发者理解和防御攻击。

Method: 提出BlackCAtt算法，将目标检测器视为黑盒，识别最小因果像素集，结合检测器输出的边界框构造对抗攻击。通过因果像素分析实现精确、不可感知的攻击，支持三种攻击类型：检测框丢失、修改和新增虚假检测。

Result: 在COCO测试集上，BlackCAtt相比基线方法：移除检测效果提升2.7倍，修改检测效果提升3.86倍，触发新虚假检测效果提升5.75倍。攻击生成的图像与原始图像差异极小，几乎不可感知。

Conclusion: 因果像素识别是实现精确、不可感知对抗攻击的关键。BlackCAtt作为黑盒、架构无关的攻击工具，不仅能有效攻击多种目标检测器，还能提供可解释的攻击机制，有助于模型安全分析和防御。

Abstract: Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.

</details>


### [4] [Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.03745)
*Jiaze Li,Yan Lu,Bin Liu,Guojun Yin,Mang Ye*

Main category: cs.CV

TL;DR: 提出DMDL框架，通过模型层和优化层的双重去偏学习解决无监督可见光-红外行人重识别中的模态偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段学习管道在单模态学习阶段会引入模态特定线索，这些偏差会传播到跨模态学习阶段，损害身份识别和泛化能力。

Method: 提出双重模态去偏学习框架：1) 模型层使用因果启发的调整干预模块替代基于似然的建模；2) 优化层采用协作无偏训练策略，通过模态特定增强、标签细化和特征对齐中断偏差传播。

Result: 在基准数据集上的大量实验表明，DMDL能够实现模态不变特征学习和更通用的模型。

Conclusion: 提出的双重模态去偏学习框架有效解决了无监督可见光-红外行人重识别中的模态偏差问题，实现了更好的模态不变特征学习。

Abstract: Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.

</details>


### [5] [Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy](https://arxiv.org/abs/2512.03883)
*Jorge Tapias Gomez,Despoina Kanata,Aneesh Rangnekar,Christina Lee,Julio Garcia-Aguilar,Joshua Jesse Smith,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: 提出SSDCA模型，结合两次内窥镜图像，用于直肠癌患者观察等待期间早期检测局部复发


<details>
  <summary>Details</summary>
Motivation: 直肠癌患者经新辅助治疗后临床完全缓解，观察等待策略需要准确方法早期检测局部复发，以防止远处转移

Method: 开发Siamese Swin Transformer with Dual Cross-Attention (SSDCA)模型，结合新辅助治疗后重新分期和随访期间的内窥镜图像，无需空间对齐即可预测治疗反应

Result: SSDCA在62名患者测试集上表现最佳：平衡准确率81.76%，敏感性90.07%，特异性72.86%，对血液、粪便等伪影具有鲁棒性

Conclusion: SSDCA能够有效区分临床完全缓解和局部复发，为直肠癌观察等待策略提供可靠的早期检测工具

Abstract: Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.

</details>


### [6] [Beyond the Ground Truth: Enhanced Supervision for Image Restoration](https://arxiv.org/abs/2512.03932)
*Donghun Ryou,Inju Ha,Sanghyeok Chu,Bohyung Han*

Main category: cs.CV

TL;DR: 提出一个通过频率域混合增强现有ground truth图像的新框架，为真实世界图像恢复提供更高质量监督，并训练轻量级输出细化网络提升恢复质量。


<details>
  <summary>Details</summary>
Motivation: 真实世界图像恢复中，由于数据采集的实际限制，ground truth图像质量有限，限制了模型性能。需要提升现有ground truth图像质量以提供更高质量监督。

Method: 提出新颖框架：1) 使用条件频率掩码生成器学习自适应频率掩码；2) 通过超分辨率生成感知增强的ground truth图像；3) 频率域混合融合原始ground truth和超分辨率变体的频率成分；4) 训练轻量级输出细化网络，可与现有恢复模型无缝集成。

Result: 大量实验表明，该方法能持续提升恢复图像质量。用户研究验证了监督增强和输出细化的有效性。

Conclusion: 提出的框架通过增强现有ground truth图像，为真实世界图像恢复提供了更高质量的监督，同时通过轻量级输出细化网络进一步提升恢复性能，代码已开源。

Abstract: Deep learning-based image restoration has achieved significant success. However, when addressing real-world degradations, model performance is limited by the quality of ground-truth images in datasets due to practical constraints in data acquisition. To address this limitation, we propose a novel framework that enhances existing ground truth images to provide higher-quality supervision for real-world restoration. Our framework generates perceptually enhanced ground truth images using super-resolution by incorporating adaptive frequency masks, which are learned by a conditional frequency mask generator. These masks guide the optimal fusion of frequency components from the original ground truth and its super-resolved variants, yielding enhanced ground truth images. This frequency-domain mixup preserves the semantic consistency of the original content while selectively enriching perceptual details, preventing hallucinated artifacts that could compromise fidelity. The enhanced ground truth images are used to train a lightweight output refinement network that can be seamlessly integrated with existing restoration models. Extensive experiments demonstrate that our approach consistently improves the quality of restored images. We further validate the effectiveness of both supervision enhancement and output refinement through user studies. Code is available at https://github.com/dhryougit/Beyond-the-Ground-Truth.

</details>


### [7] [PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design](https://arxiv.org/abs/2512.04082)
*Jiazhe Wei,Ken Li,Tianyu Lao,Haofan Wang,Liang Wang,Caifeng Shan,Chenyang Si*

Main category: cs.CV

TL;DR: PosterCopilot是一个基于大型多模态模型的图形设计框架，通过三阶段训练策略提升布局几何准确性和审美推理能力，支持分层可控的迭代编辑，实现专业级海报设计。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型多模态模型的图形设计方法存在几何布局不准确、缺乏专业工作流程所需的迭代分层编辑能力等问题，无法满足专业设计需求。

Method: 提出渐进式三阶段训练策略：1) 扰动监督微调；2) 视觉-现实对齐的强化学习；3) 审美反馈强化学习。结合生成模型构建完整工作流，支持分层可控的迭代编辑。

Result: 实验表明PosterCopilot能够生成几何准确、审美优越的布局，为专业迭代设计提供前所未有的可控性。

Conclusion: PosterCopilot通过创新的训练策略和工作流程，解决了现有自动化图形设计方法的局限性，实现了专业级的布局推理和可控编辑能力。

Abstract: Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins](https://arxiv.org/abs/2512.03055)
*Xiaowu Sun,Thabo Mahendiran,Ortal Senouf,Denise Auberson,Bernard De Bruyne,Stephane Fournier,Olivier Muller,Pascal Frossard,Emmanuel Abbe,Dorina Thanou*

Main category: cs.LG

TL;DR: PINS-CAD：基于物理信息的自监督学习框架，通过预训练图神经网络预测冠状动脉压力和血流，无需CFD或标注数据，在临床数据上微调后能有效预测心血管事件


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，冠状动脉疾病（CAD）是最常见形式，需要早期风险预测。传统3D冠状动脉数字孪生分析依赖计算流体动力学（CFD），计算量大难以扩展；数据驱动方法受限于标注数据稀缺且缺乏生理学先验知识。

Method: 提出PINS-CAD框架：1）在20万个合成的冠状动脉数字孪生上预训练图神经网络，基于1D Navier-Stokes方程和压降定律预测压力和血流，无需CFD或标注数据；2）在FAME2多中心研究的635名患者临床数据上进行微调。

Result: 1）预测未来心血管事件的AUC达到0.73，优于临床风险评分和数据驱动基线方法；2）物理信息预训练提高了样本效率并产生生理学有意义的表示；3）能生成空间分辨的压力和血流储备分数曲线，提供可解释的生物标志物。

Conclusion: 通过将物理先验嵌入几何深度学习，PINS-CAD将常规血管造影转化为无需模拟、具有生理感知的框架，为可扩展的预防性心脏病学提供了新途径。

Abstract: Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.

</details>


### [9] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 论文将倾斜风险（tilted risk）应用于流匹配（Flow Matching），通过log-exponential变换改进标准均方误差损失，以更好地捕捉数据流形的几何结构和少数分支。


<details>
  <summary>Details</summary>
Motivation: 标准流匹配中的均方误差损失将所有到达同一时空点的速度目标压缩为单一条件均值，忽略了高阶条件信息（方差、偏度、多模态），这些信息编码了数据流形的精细几何结构和少数分支。

Method: 将标准风险敏感（log-exponential）变换应用于条件流匹配损失，得到倾斜风险损失，该损失是有意义的条件熵流匹配目标的上界。通过梯度的小阶展开得到两个可解释的一阶修正：流匹配残差的协方差预处理和偏好非对称或稀有分支的偏尾项。

Result: 在专门设计用于探测模糊性和尾部的合成数据上，风险敏感损失比标准整流流匹配改善了统计指标，并更忠实地恢复了几何结构。

Conclusion: 倾斜风险损失为流匹配提供了一种有前景的方法，能够更好地捕捉数据流形的几何复杂性，特别是对于稀有事件和非对称分支。

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [10] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: MoDE提出了一种轻量级可扩展架构，通过解耦模态特定更新来缓解梯度冲突，解决统一多模态生成模型中的模态间遗忘问题


<details>
  <summary>Details</summary>
Motivation: 统一多模态生成模型在持续学习新任务时存在灾难性遗忘问题，包括模态内遗忘和模态间遗忘。虽然模态内遗忘已有研究，但模态间遗忘尚未被充分探索。本文识别并验证了这一现象，并从模态间梯度冲突的角度提供了理论解释。

Method: 提出MoDE（Modality-Decoupled Experts）架构：1）通过隔离模态特定更新来缓解梯度冲突；2）利用知识蒸馏防止灾难性遗忘并保留预训练能力；3）与之前保持模态耦合的方法不同，MoDE显式解耦模态以防止干扰。

Result: 在多样化基准测试中，MoDE显著缓解了模态间和模态内遗忘，在统一多模态生成设置中优于先前的持续学习基线方法。

Conclusion: MoDE通过解耦模态特定更新有效解决了统一多模态生成模型中的模态间遗忘问题，为多模态持续学习提供了轻量级可扩展的解决方案。

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [11] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: SPARK框架通过三阶段方法：1)生成器产生多样解，验证器并行和序列评估；2)用验证输出训练生成式过程奖励模型；3)将PRM作为RL奖励信号，在数学推理任务上超越基于ground-truth的方法。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型需要昂贵的步骤级标注或ground truth参考，限制了其应用。需要开发无需参考的RL训练方法，在缺乏可验证答案或ground truth的领域也能有效工作。

Method: 三阶段框架：第一阶段，生成器产生多样解，验证器通过并行缩放（自一致性）和序列缩放（元批判）评估；第二阶段，用验证输出作为合成训练数据微调生成式过程奖励模型；第三阶段，将PRM作为RL奖励信号，加入格式约束防止奖励攻击。

Result: 在ProcessBench上达到67.5 F1，优于参考指导训练的66.4和GPT-4o的61.9；在六个数学推理基准上平均准确率47.4%，优于基于ground-truth的RLVR的43.9%。

Conclusion: SPARK实现了无需参考的RL训练，性能超越基于ground-truth的方法，为缺乏可验证答案或ground truth的领域开辟了新可能性。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [12] [ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics](https://arxiv.org/abs/2512.03290)
*Julian Evan Chrisnanto,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: ASPEN是一种新型PINN架构，通过自适应谱层和可学习傅里叶特征解决传统PINN在刚性、多尺度非线性系统中的频谱偏差问题，成功求解了复杂的Ginzburg-Landau方程。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在处理刚性、多尺度非线性偏微分方程时存在严重缺陷，主要原因是标准多层感知机架构的频谱偏差无法充分表示高频分量，导致在复杂物理系统中失效。

Method: 提出自适应谱物理网络（ASPEN），在网络输入阶段集成自适应谱层和可学习傅里叶特征，使模型能够在训练过程中动态调整自身的谱基，高效学习解所需的精确频率内容。

Result: 在复杂的Ginzburg-Landau方程上，标准PINN完全失效并产生非物理振荡，而ASPEN成功求解，预测解与高分辨率真实解视觉上无法区分，中位物理残差仅为5.10×10^-3，且能正确捕捉自由能快速弛豫和畴壁前沿长期稳定性等物理特性。

Conclusion: 通过引入自适应谱基，ASPEN为传统PINN失效的复杂动力系统提供了鲁棒且物理一致的求解器，为机器学习在挑战性物理领域的应用开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.

</details>


### [13] [VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing](https://arxiv.org/abs/2512.03394)
*Hamed Poursiami,Shay Snyder,Guojing Cong,Thomas Potok,Maryam Parsa*

Main category: cs.LG

TL;DR: VS-Graph：一种基于向量符号架构的图学习框架，通过尖峰扩散机制和关联消息传递，在保持HDC高效性的同时达到接近GNN的表达能力，训练速度提升高达450倍。


<details>
  <summary>Details</summary>
Motivation: 图神经网络(GNNs)在图分类任务中表现优异但计算成本高，限制了其在资源受限设备上的部署。超维计算(HDC)虽然轻量但性能通常不如GNN。需要一种既能保持HDC高效性又能接近GNN表达能力的解决方案。

Method: 提出VS-Graph框架：1) 尖峰扩散机制(Spike Diffusion)用于拓扑驱动的节点识别；2) 关联消息传递(Associative Message Passing)在高维向量空间内实现多跳邻域聚合。无需基于梯度的优化或反向传播。

Result: 在MUTAG和DD等标准基准测试中，比之前的HDC基线提升4-5%准确率，与GNN基线相当或更好，训练速度提升高达450倍。即使在超向量维度降至D=128时仍保持高准确率。

Conclusion: VS-Graph成功缩小了HDC效率与消息传递表达能力之间的差距，为边缘和神经形态硬件上的超高效执行铺平了道路，实现了轻量级图学习框架的突破。

Abstract: Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.

</details>


### [14] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯事件模型BEBMS，在疾病亚型推断任务中显著优于现有方法SuStaIn，并在阿尔茨海默病数据上得到更符合科学共识的结果。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病在不同患者中进展方式存在差异，通常存在少量亚型。现有方法SuStaIn被广泛用于疾病亚型推断，但其鲁棒性尚未得到充分验证。

Method: 开发了基于贝叶斯的事件模型BEBMS，通过合成数据实验（包含不同程度的模型误设）与SuStaIn进行比较，并在真实阿尔茨海默病数据集上应用两种方法。

Result: BEBMS在排序、分期和亚型分配任务上显著优于SuStaIn。在阿尔茨海默病数据上，BEBMS的结果更符合该疾病进展的科学共识。

Conclusion: BEBMS作为一种贝叶斯方法，在疾病亚型推断中比SuStaIn更稳健可靠，为疾病进展建模提供了改进工具。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [15] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: JPM是一个概率框架，用于从横断面数据推断混合神经退行性疾病的联合进展，通过将单病轨迹视为部分排序并构建联合进展先验，相比传统单病EBM提高了排序准确性。


<details>
  <summary>Details</summary>
Motivation: 传统事件模型假设个体只有单一疾病，但神经退行性疾病中混合病理很常见，需要能够处理多种疾病同时进展的模型。

Method: 提出联合进展模型，将单病轨迹视为部分排序，构建联合进展先验，研究了四种变体：Pairwise、Bradley-Terry、Plackett-Luce和Mallows，分析了校准性、分离性和锐度三个属性。

Result: 所有变体都具备校准性，分离性接近完美；锐度因变体而异，可通过输入部分排序的简单特征预测；在合成实验中，JPM比传统SA-EBM基线提高了约21%的排序准确性；在NACC数据中，Mallows变体和基线模型的结果与AD和VaD混合病理进展的先前文献更一致。

Conclusion: JPM为混合神经退行性疾病的进展建模提供了有效框架，能够处理多种病理同时进展的情况，相比传统单病模型显著提高了准确性。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [16] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出了一种针对扩散模型微调式遗忘学习方法的逆向攻击DiMRA，以及一种新的基于记忆的遗忘学习方法DiMUM来增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成合成图像方面表现出色，但存在安全、隐私和版权问题，需要遗忘学习技术来让模型忘记特定训练数据。然而现有的微调式遗忘学习方法存在被逆向攻击的风险。

Method: 1. DiMRA攻击：在不知道遗忘元素的情况下，通过在辅助数据集上优化已遗忘的扩散模型来逆转遗忘过程；2. DiMUM防御：通过记忆替代数据/特征来替换目标遗忘数据/特征，而不是直接遗忘。

Result: DiMRA成功逆转了最先进的微调式遗忘学习方法，揭示了这类技术的脆弱性。DiMUM在保持扩散模型生成性能的同时，显著增强了对DiMRA攻击的鲁棒性。

Conclusion: 现有的微调式扩散模型遗忘学习方法存在被逆向攻击的严重漏洞，需要更鲁棒的解决方案。提出的DiMUM方法通过记忆替代策略有效增强了遗忘学习的鲁棒性。

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [17] [CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion](https://arxiv.org/abs/2512.03610)
*Julius Lenz*

Main category: cs.LG

TL;DR: CoGraM是一种用于联邦学习和分布式学习的神经网络合并方法，通过多阶段、上下文敏感的迭代优化，在层、神经元和权重级别对齐决策，避免有害更新，显著提升合并网络性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习和分布式学习中，无需重新训练即可合并神经网络是关键需求。现有方法如权重平均或Fisher合并经常导致精度损失且在不同种子下不稳定，需要更鲁棒的合并方法。

Method: CoGraM是一种多阶段、上下文敏感、基于损失的迭代优化方法，在层、神经元和权重级别进行操作。它通过损失差异和阈值对齐决策，并通过回滚机制防止有害更新。

Result: CoGraM能够显著改善合并后的网络性能，解决了Fisher等方法的弱点，提供更稳定和准确的神经网络合并方案。

Conclusion: CoGraM为联邦学习和分布式学习中的神经网络合并问题提供了一个有效的解决方案，通过精细的优化策略克服了现有方法的局限性，实现了更好的模型合并效果。

Abstract: Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.

</details>


### [18] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 提出一种基于物理约束哈密顿学习的算法，通过检测结构不可逆性和重建能量景观来区分交通系统的真实恢复与虚假恢复，发现传统指标会遗漏64.8%的结构损伤。


<details>
  <summary>Details</summary>
Motivation: 当前城市交通系统韧性评估方法依赖表面恢复指标，无法检测隐藏的结构损伤，无法区分真实恢复与"虚假恢复"（交通指标正常化但系统动力学永久退化）。

Method: 开发物理约束哈密顿学习算法，结合"结构不可逆性检测"和"能量景观重建"，提取低维状态表示，通过物理约束优化识别准哈密顿结构，通过能量景观比较量化结构变化。

Result: 对伦敦2021年极端降雨的分析显示，虽然表面指标完全恢复，但算法检测到传统监测遗漏的64.8%结构损伤。

Conclusion: 该框架为主动结构风险评估提供工具，使基础设施投资能够基于真实系统健康状况而非误导性的表面指标。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 作者提出一个检测和分析政治文本中解释的框架，使用轻量级因果语言模型提取因果主张的结构化数据，展示该方法在规模研究中的适用性。


<details>
  <summary>Details</summary>
Motivation: 解释是理解政治世界的基本要素，公民经常询问和回答关于事件原因、责任归属和不同行动方案的问题。然而，尽管解释很重要，但在政治科学中，它们仍然是系统分析中发展不足的对象，现有方法分散且通常是针对特定问题的。

Method: 作者引入一个检测和解析政治文本中解释的框架，训练一个轻量级因果语言模型，该模型返回因果主张的结构化数据集，以原因-结果对的形式供下游分析使用。

Result: 该方法展示了如何在规模上研究因果解释，并显示了该方法相对于人工编码的适度标注要求、泛化能力和准确性。

Conclusion: 该研究提供了一个系统分析政治文本中解释的可行框架，通过轻量级因果语言模型实现了大规模因果解释的检测和分析，填补了政治科学中解释系统分析的空白。

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [20] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 该论文提出了INDI-PROP数据集，用于印度新闻媒体中的宣传分析，包含三层注释：意识形态偏见、细粒度叙事框架和说服技巧，并开发了基于GPT-4o-mini的FANTA和TPTC框架进行自动分类。


<details>
  <summary>Details</summary>
Motivation: 叙事是宣传的认知和情感支架，将孤立的说服技巧组织成连贯的故事。现有研究缺乏针对印度新闻媒体的意识形态基础细粒度叙事分类，需要系统分析宣传中的多层次结构。

Method: 1) 创建INDI-PROP数据集：包含1,266篇关于CAA和农民抗议的文章，进行三层注释：意识形态偏见、事件特定细粒度叙事框架、说服技巧；2) 开发FANTA和TPTC框架：基于GPT-4o-mini的多跳提示推理框架，FANTA整合信息提取和上下文框架进行分层推理，TPTC采用两阶段方法系统分解说服线索。

Result: 提出的FANTA和TPTC框架在偏见、叙事和说服技巧分类任务上相比基线方法有显著改进，验证了多层次注释和推理框架的有效性。

Conclusion: 该研究提供了首个意识形态基础的印度宣传分析数据集和有效的多跳推理框架，为细粒度叙事分类和宣传分析建立了新基准，有助于深入理解宣传中的多层次结构。

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [21] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: DZ-TDPO：一个非破坏性对齐框架，通过冲突感知的动态KL约束和可学习的时间注意力偏置解决长对话中的状态惯性问题，在保持零样本泛化能力的同时实现SOTA胜率。


<details>
  <summary>Details</summary>
Motivation: 长对话系统存在"状态惯性"问题，静态约束导致模型无法解决用户意图演变与历史上下文之间的冲突，限制了对话系统的动态适应性。

Method: 提出DZ-TDPO框架，结合冲突感知的动态KL约束和可学习的时间注意力偏置，通过精确的注意力调节而非破坏性权重更新来缓解状态惯性。

Result: 在MSC数据集上达到86.2%胜率（Phi-3.5），Qwen2.5-7B模型实现99.4%胜率且困惑度开销可忽略；发现"容量-稳定性权衡"现象：小模型需付出"对齐税"克服历史惯性，大模型可实现近乎完美的对齐。

Conclusion: DZ-TDPO通过精确的注意力调节有效缓解状态惯性，保持模型通用能力（MMLU），为非破坏性对话对齐提供了有效解决方案。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [22] [A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection](https://arxiv.org/abs/2512.03684)
*Shahid Ansari,Mahendra Kumar Gohil,Yusuke Maeda,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 提出结合软体手指与刚性外骨骼的混合夹爪，配合视觉感知与力控，实现番茄自主采摘，平均周期24.34秒，成功率约80%


<details>
  <summary>Details</summary>
Motivation: 现有番茄采摘系统在复杂环境中面临挑战：需要轻柔抓取以避免损伤，同时处理遮挡和光照变化，并实现高效可靠的采摘循环

Method: 1) 混合夹爪设计：6个软体负泊松比手指+刚性外骨骼+乳胶篮，实现笼式抓取；2) 视觉系统：RGB-D相机+Detectron2分割成熟/未熟番茄，定位果梗和果实中心；3) 力控：基于虚拟功原理建立伺服扭矩-抓取力模型，使用PID控制器+力敏电阻反馈调节抓取力；4) 运动规划：PSO优化5自由度机械臂轨迹

Result: 完整采摘循环（接近、分离、切割、抓取、运输、释放）平均时间24.34秒，总体成功率约80%，抓取力保持在0.20-0.50N的低水平，验证了系统在杂乱环境中的可靠性

Conclusion: 提出的混合夹爪设计与集成视觉-控制管道能有效实现番茄的可靠采摘，在保持低抓取力的同时达到较高成功率，适用于复杂农业环境

Abstract: This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.

</details>


### [23] [Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware](https://arxiv.org/abs/2512.03911)
*Kenneth Stewart,Roxana Leontie,Samantha Chapin,Joe Hays,Sumit Bam Shrestha,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 将强化学习训练的ANN转换为脉冲Sigma-Delta神经网络，部署在Loihi 2神经形态硬件上，实现机器人控制的低延迟、高能效推理


<details>
  <summary>Details</summary>
Motivation: 为机器人控制应用开发能量高效、实时响应的神经形态计算方案，特别是面向太空和地面机器人应用

Method: 1) 在仿真中训练ANN策略；2) 将使用ReLU激活的ANN转换为脉冲Sigma-Delta神经网络；3) 部署到Intel Loihi 2神经形态硬件；4) 在NVIDIA Omniverse Isaac Lab仿真环境中进行闭环控制评估

Result: 成功将ANN策略转换为SDNN并部署在Loihi 2上，实现了低延迟、能量高效的推理，比较了GPU和Loihi 2的执行性能，验证了神经形态平台用于机器人控制的可行性

Conclusion: 建立了将强化学习策略部署到神经形态硬件的端到端流程，为未来太空和地面机器人应用中的能量高效、实时神经形态计算开辟了途径

Abstract: We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.

</details>
