<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 7]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [State-Change Learning for Prediction of Future Events in Endoscopic Videos](https://arxiv.org/abs/2510.12904)
*Saurav Sharma,Chinedu Innocent Nwoye,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出SurgFUTR方法，将手术未来预测重构为状态变化学习，通过师生架构和Action Dynamics模块实现跨手术程序的通用预测。


<details>
  <summary>Details</summary>
Motivation: 当前手术AI研究主要关注理解当前事件而非预测未来，缺乏统一的短期和长期预测方法，且现有方法难以在不同手术情境间泛化。

Method: 采用师生架构，通过Sinkhorn-Knopp聚类将视频片段压缩为状态表示，教师网络学习当前和未来片段，学生网络仅从当前视频预测未来状态，并由Action Dynamics模块指导。

Result: 在四个数据集和三个手术程序上的实验显示一致改进，跨程序迁移验证了方法的泛化能力。

Conclusion: SurgFUTR通过状态变化学习框架有效解决了手术未来预测的挑战，在多个任务上表现出色且具有良好的跨程序泛化能力。

Abstract: Surgical future prediction, driven by real-time AI analysis of surgical
video, is critical for operating room safety and efficiency. It provides
actionable insights into upcoming events, their timing, and risks-enabling
better resource allocation, timely instrument readiness, and early warnings for
complications (e.g., bleeding, bile duct injury). Despite this need, current
surgical AI research focuses on understanding what is happening rather than
predicting future events. Existing methods target specific tasks in isolation,
lacking unified approaches that span both short-term (action triplets, events)
and long-term horizons (remaining surgery duration, phase transitions). These
methods rely on coarse-grained supervision while fine-grained surgical action
triplets and steps remain underexplored. Furthermore, methods based only on
future feature prediction struggle to generalize across different surgical
contexts and procedures. We address these limits by reframing surgical future
prediction as state-change learning. Rather than forecasting raw observations,
our approach classifies state transitions between current and future timesteps.
We introduce SurgFUTR, implementing this through a teacher-student
architecture. Video clips are compressed into state representations via
Sinkhorn-Knopp clustering; the teacher network learns from both current and
future clips, while the student network predicts future states from current
videos alone, guided by our Action Dynamics (ActDyn) module. We establish
SFPBench with five prediction tasks spanning short-term (triplets, events) and
long-term (remaining surgery duration, phase and step transitions) horizons.
Experiments across four datasets and three procedures show consistent
improvements. Cross-procedure transfer validates generalizability.

</details>


### [2] [SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models](https://arxiv.org/abs/2510.13042)
*Zhengxu Tang,Zizheng Wang,Luning Wang,Zitao Shuai,Chenhao Zhang,Siyu Qian,Yirui Wu,Bohao Wang,Haosong Rao,Zhenyu Yang,Chenwei Wu*

Main category: cs.CV

TL;DR: SeqBench是一个用于评估文本到视频生成中顺序叙事连贯性的基准测试，包含320个提示的数据集和基于动态时序图的自动评估指标，揭示了当前T2V模型在多动作序列中的关键局限性。


<details>
  <summary>Details</summary>
Motivation: 现有T2V生成模型在创建视觉吸引力视频方面取得进展，但在生成需要逻辑递进的多事件连贯顺序叙事方面存在困难，且现有基准主要关注视觉质量指标，缺乏对扩展序列中叙事连贯性的评估。

Method: 提出了SeqBench基准，包括精心设计的320个提示数据集，涵盖各种叙事复杂性，以及基于动态时序图的自动评估指标，能够高效捕捉长距离依赖和时间顺序关系。

Result: 基于DTG的指标与人类标注显示出强相关性。系统评估揭示了当前T2V模型的关键局限：在多动作序列中无法维持一致的对象状态、多对象场景中产生物理上不合理的结果、难以保持顺序动作之间的现实时间顺序关系。

Conclusion: SeqBench为评估T2V生成中的叙事连贯性提供了首个系统框架，并为改进未来模型的顺序推理能力提供了具体见解。

Abstract: Text-to-video (T2V) generation models have made significant progress in
creating visually appealing videos. However, they struggle with generating
coherent sequential narratives that require logical progression through
multiple events. Existing T2V benchmarks primarily focus on visual quality
metrics but fail to evaluate narrative coherence over extended sequences. To
bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating
sequential narrative coherence in T2V generation. SeqBench includes a carefully
designed dataset of 320 prompts spanning various narrative complexities, with
2,560 human-annotated videos generated from 8 state-of-the-art T2V models.
Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic
evaluation metric, which can efficiently capture long-range dependencies and
temporal ordering while maintaining computational efficiency. Our DTG-based
metric demonstrates a strong correlation with human annotations. Through
systematic evaluation using SeqBench, we reveal critical limitations in current
T2V models: failure to maintain consistent object states across multi-action
sequences, physically implausible results in multi-object scenarios, and
difficulties in preserving realistic timing and ordering relationships between
sequential actions. SeqBench provides the first systematic framework for
evaluating narrative coherence in T2V generation and offers concrete insights
for improving sequential reasoning capabilities in future models. Please refer
to https://videobench.github.io/SeqBench.github.io/ for more details.

</details>


### [3] [What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](https://arxiv.org/abs/2510.13232)
*Inha Kang,Youngsun Lim,Seonho Lee,Jiho Choi,Junsuk Choe,Hyunjung Shim*

Main category: cs.CV

TL;DR: 提出了CoVAND数据集和NegToMe模块来解决视觉语言模型在否定理解上的缺陷，显著提升了描述性目标检测任务中的否定理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉语言模型存在否定理解的严重缺陷，特别是在描述性目标检测任务中表现出肯定性偏见，这限制了模型在真实世界检测应用中的实用性。

Method: 1) 开发CoVAND数据集，使用链式思维和VQA流程生成高质量的实例接地否定数据；2) 提出NegToMe文本标记合并模块，通过将否定词与属性词组合成连贯的语义短语来解决标记化过程中的否定线索丢失问题；3) 结合参数高效的LoRA微调方法。

Result: 在挑战性否定基准测试中显著提升性能，将NMS-AP在OVDEval上提升了高达+10.8分，降低了误报率，并在最先进的视觉语言模型上展现出泛化能力。

Conclusion: 这项工作在解决真实世界检测应用中的否定理解问题上迈出了关键一步，为视觉语言模型的否定理解能力提供了有效解决方案。

Abstract: State-of-the-art vision-language models (VLMs) suffer from a critical failure
in understanding negation, often referred to as affirmative bias. This
limitation is particularly severe in described object detection (DOD) tasks. To
address this, we propose two primary contributions: (1) a new dataset pipeline
and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a
dataset constructed with a systematic chain-of-thought (CoT) and VQA-based
pipeline to generate high-quality, instance-grounded negation data. Second, we
propose NegToMe, a novel text token merging module that directly tackles the
architectural cause of affirmative bias. NegToMe fundamentally addresses the
structural loss of negation cues in tokenization, grouping them with attributes
into coherent semantic phrases. It maintains correct polarity at the input
level, enabling robust negation understanding even with limited data. For
instance, to prevent a model from treating the fragmented tokens "not" and
"girl" as simply "girl", NegToMe binds them into a single token whose meaning
is correctly distinguished from that of "girl" alone. This module is integrated
with a parameter-efficient and strategic LoRA fine-tuning approach. Our method
significantly improves performance on challenging negation benchmarks with a
lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval
and demonstrating generalization to SoTA VLMs. This work marks a crucial step
forward in addressing negation understanding for real-world detection
applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Local Timescale Gates for Timescale-Robust Continual Spiking Neural Networks](https://arxiv.org/abs/2510.12843)
*Ansh Tiwari,Ayush Chauhan*

Main category: cs.LG

TL;DR: 提出LT-Gate脉冲神经元模型，通过双时间尺度动态和自适应门控机制解决SNN在持续学习中的稳定性-可塑性困境，在时序分类任务中显著提升准确率和记忆保持能力。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络在神经形态硬件上具有能效优势，但在需要快速适应和长期记忆的持续学习任务中存在困难，特别是稳定性-可塑性困境。

Method: LT-Gate模型让每个脉冲神经元并行跟踪快速和慢速时间尺度信息，通过学习门控机制局部调整其影响，并引入方差跟踪正则化来稳定发放活动。

Result: 在挑战性时序分类基准测试中达到约51%的最终准确率，优于Hebbian持续学习基线的约46%和先前SNN方法，且无需外部重放或昂贵正交化。

Conclusion: 多时间尺度门控可显著增强SNN的持续学习能力，缩小脉冲网络与传统深度网络在终身学习任务上的差距，并完全兼容神经形态硬件。

Abstract: Spiking neural networks (SNNs) promise energy-efficient artificial
intelligence on neuromorphic hardware but struggle with tasks requiring both
fast adaptation and long-term memory, especially in continual learning. We
propose Local Timescale Gating (LT-Gate), a neuron model that combines dual
time-constant dynamics with an adaptive gating mechanism. Each spiking neuron
tracks information on a fast and a slow timescale in parallel, and a learned
gate locally adjusts their influence. This design enables individual neurons to
preserve slow contextual information while responding to fast signals,
addressing the stability-plasticity dilemma. We further introduce a
variance-tracking regularization that stabilizes firing activity, inspired by
biological homeostasis. Empirically, LT-Gate yields significantly improved
accuracy and retention in sequential learning tasks: on a challenging temporal
classification benchmark it achieves about 51 percent final accuracy, compared
to about 46 percent for a recent Hebbian continual-learning baseline and lower
for prior SNN methods. Unlike approaches that require external replay or
expensive orthogonalizations, LT-Gate operates with local updates and is fully
compatible with neuromorphic hardware. In particular, it leverages features of
Intel's Loihi chip (multiple synaptic traces with different decay rates) for
on-chip learning. Our results demonstrate that multi-timescale gating can
substantially enhance continual learning in SNNs, narrowing the gap between
spiking and conventional deep networks on lifelong-learning tasks.

</details>


### [5] [Learning at the Speed of Physics: Equilibrium Propagation on Oscillator Ising Machines](https://arxiv.org/abs/2510.12934)
*Alex Gower*

Main category: cs.LG

TL;DR: 该论文展示了在振荡器伊辛机(OIMs)上实现平衡传播(EP)的方法，将优化和采样统一到单一能量景观中，在MNIST和Fashion-MNIST数据集上达到竞争性准确率，同时保持对硬件约束的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 利用物理系统自然执行能量下降的特性来加速机器学习，特别是将能量基模型(EBMs)的优化直接映射到物理硬件动力学上，避免传统处理器的瓶颈。

Method: 在振荡器伊辛机(OIMs)上实现平衡传播(EP)，利用GHz频率动力学模拟能量基模型优化和梯度下降，内在噪声对应朗之万动力学，支持采样和优化。

Result: 在MNIST上达到97.2±0.1%准确率，在Fashion-MNIST上达到88.0±0.1%准确率，在参数量化和相位噪声等现实硬件约束下保持鲁棒性。

Conclusion: OIMs为神经形态学习提供了快速、节能的硬件平台，表明能量基模型可以在直接执行其优化的物理硬件上实现实际应用。

Abstract: Physical systems that naturally perform energy descent offer a direct route
to accelerating machine learning. Oscillator Ising Machines (OIMs) exemplify
this idea: their GHz-frequency dynamics mirror both the optimization of
energy-based models (EBMs) and gradient descent on loss landscapes, while
intrinsic noise corresponds to Langevin dynamics - supporting sampling as well
as optimization. Equilibrium Propagation (EP) unifies these processes into
descent on a single total energy landscape, enabling local learning rules
without global backpropagation. We show that EP on OIMs achieves competitive
accuracy ($\sim 97.2 \pm 0.1 \%$ on MNIST, $\sim 88.0 \pm 0.1 \%$ on
Fashion-MNIST), while maintaining robustness under realistic hardware
constraints such as parameter quantization and phase noise. These results
establish OIMs as a fast, energy-efficient substrate for neuromorphic learning,
and suggest that EBMs - often bottlenecked by conventional processors - may
find practical realization on physical hardware whose dynamics directly perform
their optimization.

</details>


### [6] [Information Shapes Koopman Representation](https://arxiv.org/abs/2510.13025)
*Xiaoyuan Cheng,Wenxuan Yuan,Yiming Yang,Yuanzhao Zhang,Sibo Cheng,Yi He,Zhuo Sun*

Main category: cs.LG

TL;DR: 该论文提出了一种基于信息论的Koopman学习方法，通过平衡表示简洁性和表达能力来解决深度架构中Koopman算子学习的挑战。


<details>
  <summary>Details</summary>
Motivation: Koopman算子的无限维特性使得寻找合适的有限维子空间具有挑战性，特别是在深度架构中。作者认为这些困难源于次优的表示学习，其中潜在变量未能平衡表达能力和简洁性。

Method: 提出信息论拉格朗日公式，明确平衡简洁性（通过潜在互信息）和表达能力（通过冯·诺依曼熵）之间的权衡。基于此公式开发新算法，促进稳定且可解释的Koopman表示。

Result: 在多种动力系统上验证了该方法，相比现有Koopman学习方法表现出改进的性能，并可视化学习到的流形，观察结果与理论预测一致。

Conclusion: 通过信息论视角重新思考Koopman学习，提出了一种平衡简洁性和表达能力的方法，能够产生稳定且可解释的Koopman表示，在多个动力系统上优于现有方法。

Abstract: The Koopman operator provides a powerful framework for modeling dynamical
systems and has attracted growing interest from the machine learning community.
However, its infinite-dimensional nature makes identifying suitable
finite-dimensional subspaces challenging, especially for deep architectures. We
argue that these difficulties come from suboptimal representation learning,
where latent variables fail to balance expressivity and simplicity. This
tension is closely related to the information bottleneck (IB) dilemma:
constructing compressed representations that are both compact and predictive.
Rethinking Koopman learning through this lens, we demonstrate that latent
mutual information promotes simplicity, yet an overemphasis on simplicity may
cause latent space to collapse onto a few dominant modes. In contrast,
expressiveness is sustained by the von Neumann entropy, which prevents such
collapse and encourages mode diversity. This insight leads us to propose an
information-theoretic Lagrangian formulation that explicitly balances this
tradeoff. Furthermore, we propose a new algorithm based on the Lagrangian
formulation that encourages both simplicity and expressiveness, leading to a
stable and interpretable Koopman representation. Beyond quantitative
evaluations, we further visualize the learned manifolds under our
representations, observing empirical results consistent with our theoretical
predictions. Finally, we validate our approach across a diverse range of
dynamical systems, demonstrating improved performance over existing Koopman
learning methods. The implementation is publicly available at
https://github.com/Wenxuan52/InformationKoopman.

</details>


### [7] [Bridging Idealized and Operational Models: An Explainable AI Framework for Earth System Emulators](https://arxiv.org/abs/2510.13030)
*Pouria Behnoudfar,Charlotte Moser,Marc Bocquet,Sibo Cheng,Nan Chen*

Main category: cs.LG

TL;DR: 开发了一个可解释的AI框架，通过结合高分辨率业务模型和理想化模型的优势，构建地球系统模拟器，显著改善了CMIP6模拟中厄尔尼诺时空模式的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有高分辨率业务模型存在持续偏差，特别是在模拟极端事件和统计分布方面，而理想化模型虽然能精确校准特定特征，但不同模型之间存在学科壁垒。

Method: 利用重构的潜在数据同化技术，将不同复杂度的模型层次连接起来，特别适合利用理想化模型的稀疏输出，构建桥接模型。

Result: 桥接模型继承了业务模型的高分辨率和全面变量，同时通过理想化模型的针对性改进实现了全局精度提升，显著纠正了CMIP6模拟中厄尔尼诺时空模式的偏差。

Conclusion: 该框架不仅提供了超越黑盒校正的物理解释，还强调了推动理想化模型发展和促进建模社区间交流的重要性，为有效的物理辅助数字孪生和不确定性量化提供了计算高效的基础。

Abstract: Computer models are indispensable tools for understanding the Earth system.
While high-resolution operational models have achieved many successes, they
exhibit persistent biases, particularly in simulating extreme events and
statistical distributions. In contrast, coarse-grained idealized models isolate
fundamental processes and can be precisely calibrated to excel in
characterizing specific dynamical and statistical features. However, different
models remain siloed by disciplinary boundaries. By leveraging the
complementary strengths of models of varying complexity, we develop an
explainable AI framework for Earth system emulators. It bridges the model
hierarchy through a reconfigured latent data assimilation technique, uniquely
suited to exploit the sparse output from the idealized models. The resulting
bridging model inherits the high resolution and comprehensive variables of
operational models while achieving global accuracy enhancements through
targeted improvements from idealized models. Crucially, the mechanism of AI
provides a clear rationale for these advancements, moving beyond black-box
correction to physically insightful understanding in a computationally
efficient framework that enables effective physics-assisted digital twins and
uncertainty quantification. We demonstrate its power by significantly
correcting biases in CMIP6 simulations of El Ni\~no spatiotemporal patterns,
leveraging statistically accurate idealized models. This work also highlights
the importance of pushing idealized model development and advancing
communication between modeling communities.

</details>


### [8] [Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training](https://arxiv.org/abs/2510.13361)
*Yisen Wang,Yichuan Mo,Hongjun Wang,Junyi Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 提出Generalist框架，通过将泛化目标分解为多个子任务，每个基础学习器专门优化特定目标，然后参数插值形成全局学习器，缓解对抗训练中的自然精度下降和跨攻击鲁棒性不足问题。


<details>
  <summary>Details</summary>
Motivation: 对抗训练存在两大局限：自然精度显著下降，以及在不同范数约束攻击下的鲁棒性迁移能力差。现有方法通常只解决其中一个问题，且局限于单一网络。

Method: 将整体泛化目标分解为多个子任务，每个基础学习器专门优化特定目标。训练后期通过参数插值形成全局学习器，并周期性地将全局参数重新分配给基础学习器以防止优化轨迹偏离共享目标。

Result: 理论分析和大量实验表明，Generalist实现了更低的泛化误差，显著缓解了权衡问题，相比基线方法表现更优。

Conclusion: Generalist为开发完全鲁棒的分类器提供了有前景的方向，通过专业化分工和知识融合有效解决了对抗训练的关键局限。

Abstract: Despite the rapid progress of neural networks, they remain highly vulnerable
to adversarial examples, for which adversarial training (AT) is currently the
most effective defense. While AT has been extensively studied, its practical
applications expose two major limitations: natural accuracy tends to degrade
significantly compared with standard training, and robustness does not transfer
well across attacks crafted under different norm constraints. Unlike prior
works that attempt to address only one issue within a single network, we
propose to partition the overall generalization goal into multiple sub-tasks,
each assigned to a dedicated base learner. By specializing in its designated
objective, each base learner quickly becomes an expert in its field. In the
later stages of training, we interpolate their parameters to form a
knowledgeable global learner, while periodically redistributing the global
parameters back to the base learners to prevent their optimization trajectories
from drifting too far from the shared target. We term this framework Generalist
and introduce three variants tailored to different application scenarios. Both
theoretical analysis and extensive experiments demonstrate that Generalist
achieves lower generalization error and significantly alleviates the trade-off
problems compared with baseline methods. Our results suggest that Generalist
provides a promising step toward developing fully robust classifiers in the
future.

</details>


### [9] [Prediction Markets with Intermittent Contributions](https://arxiv.org/abs/2510.13385)
*Michael Vitali,Pierre Pinson*

Main category: cs.LG

TL;DR: 提出了一种基于预测市场的协作框架，通过考虑历史表现、适应时变条件并允许自由进出的方式，解决数据所有权和竞争利益限制下的预测协作问题。


<details>
  <summary>Details</summary>
Motivation: 尽管数据可用性和准确预测需求都在增长，但数据所有权和竞争利益限制了利益相关者之间的协作。需要一种能克服这些限制的协作机制。

Method: 采用预测市场框架，使用稳健回归模型学习最优预测组合并处理缺失提交，引入考虑样本内外表现的收益分配机制。

Result: 模拟和真实数据的案例研究表明，所提出的市场设计具有有效性和适应性。

Conclusion: 该预测市场设计能够有效促进独立代理人在数据所有权和竞争利益约束下的预测协作，同时满足重要的经济特性。

Abstract: Although both data availability and the demand for accurate forecasts are
increasing, collaboration between stakeholders is often constrained by data
ownership and competitive interests. In contrast to recent proposals within
cooperative game-theoretical frameworks, we place ourselves in a more general
framework, based on prediction markets. There, independent agents trade
forecasts of uncertain future events in exchange for rewards. We introduce and
analyse a prediction market that (i) accounts for the historical performance of
the agents, (ii) adapts to time-varying conditions, while (iii) permitting
agents to enter and exit the market at will. The proposed design employs robust
regression models to learn the optimal forecasts' combination whilst handling
missing submissions. Moreover, we introduce a pay-off allocation mechanism that
considers both in-sample and out-of-sample performance while satisfying several
desirable economic properties. Case-studies using simulated and real-world data
allow demonstrating the effectiveness and adaptability of the proposed market
design.

</details>


### [10] [DOLFIN: Balancing Stability and Plasticity in Federated Continual Learning](https://arxiv.org/abs/2510.13567)
*Omayma Moussadek,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: 提出DOLFIN方法，结合Vision Transformers和低秩适配器，在联邦持续学习中实现高效稳定的新任务学习，同时最小化通信开销和防止遗忘。


<details>
  <summary>Details</summary>
Motivation: 当前联邦持续学习方法在平衡性能、隐私保护和通信效率方面面临挑战，需要一种更有效的解决方案。

Method: 使用低秩适配器(LoRA)减少通信开销，结合DualGradient Projection Memory(DualGPM)防止遗忘，在联邦环境中实现分布式在线学习。

Result: 在CIFAR-100、ImageNet-R、ImageNet-A和CUB-200数据集上，DOLFIN在两种Dirichlet异构设置下始终优于六个强基线方法，在最终平均准确率上表现更优，同时保持相同的内存占用。

Conclusion: 正交低秩适配器为联邦环境中的隐私保护持续学习提供了有效且可扩展的解决方案。

Abstract: Federated continual learning (FCL) enables models to learn new tasks across
multiple distributed clients, protecting privacy and without forgetting
previously acquired knowledge. However, current methods face challenges
balancing performance, privacy preservation, and communication efficiency. We
introduce a Distributed Online LoRA for Federated INcremental learning method
DOLFIN, a novel approach combining Vision Transformers with low-rank adapters
designed to efficiently and stably learn new tasks in federated environments.
Our method leverages LoRA for minimal communication overhead and incorporates
DualGradient Projection Memory (DualGPM) to prevent forgetting. Evaluated on
CIFAR-100, ImageNet-R, ImageNet-A, and CUB-200 under two Dirichlet
heterogeneity settings, DOLFIN consistently surpasses six strong baselines in
final average accuracy while matching their memory footprint. Orthogonal
low-rank adapters offer an effective and scalable solution for
privacy-preserving continual learning in federated settings.

</details>


### [11] [Time Series Foundation Models: Benchmarking Challenges and Requirements](https://arxiv.org/abs/2510.13654)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Oliver Müller*

Main category: cs.LG

TL;DR: 本文分析了时间序列基础模型(TSFMs)评估中存在的多重挑战，包括基准数据集代表性不足、缺乏时空评估、信息泄露风险以及外部冲击导致的模式记忆问题，呼吁开发更稳健的评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着时间序列基础模型的出现，需要确保评估的完整性，避免重蹈大语言模型和传统时间序列基准测试中已观察到的陷阱。

Method: 通过调查现有TSFM评估方法，识别出数据分区混乱、基准数据集代表性不足、信息泄露风险等问题。

Result: 研究发现现有评估存在广泛的数据分区混淆，导致性能估计膨胀和全局知识向局部时间序列的错误转移。

Conclusion: 呼吁研究社区设计新的原则性方法，如基于真正样本外未来数据的评估，以保障TSFM评估的完整性。

Abstract: Time Series Foundation Models (TSFMs) represent a new paradigm for time
series forecasting, offering zero-shot forecasting capabilities without the
need for domain-specific pre-training or fine-tuning. However, as with Large
Language Models (LLMs), evaluating TSFMs is tricky, as with ever more extensive
training sets, it becomes more and more challenging to ensure the integrity of
benchmarking data. Our investigation of existing TSFM evaluation highlights
multiple challenges, ranging from the representativeness of the benchmark
datasets, over the lack of spatiotemporal evaluation, to risks of information
leakage due to overlapping and obscure datasets, and the memorization of global
patterns caused by external shocks like economic crises or pandemics. Our
findings reveal widespread confusion regarding data partitions, risking
inflated performance estimates and incorrect transfer of global knowledge to
local time series. We argue for the development of robust evaluation
methodologies to prevent pitfalls already observed in LLM and classical time
series benchmarking, and call upon the research community to design new,
principled approaches, such as evaluations on truly out-of-sample future data,
to safeguard the integrity of TSFM assessment.

</details>


### [12] [Rebalancing with Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced Classification](https://arxiv.org/abs/2510.13656)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 提出了一种基于分布校准的类别不平衡分类方法RCS，通过利用多数类和中间类的高斯混合成分加权参数来估计少数类的分布参数，有效缓解过泛化问题。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡问题导致分类器偏向多数类，现有方法仅使用多数类分布来近似少数类统计会产生过泛化问题。

Method: 使用编码器-解码器网络保持不平衡数据结构，通过分布校准策略从编码器提取的特征向量生成合成样本，利用邻近区域数据点分布来校准参数。

Result: 在多种图像、文本和表格数据集上的实验表明，该方法相比多个基线和最先进技术实现了更优的分类性能。

Conclusion: RCS方法通过分布校准有效解决了类别不平衡问题，在多个领域数据集上表现出色。

Abstract: The class imbalance problem refers to the insufficiency of data in certain
classes, which causes a classifier to be biased toward the majority class.
Distribution calibration is a technique that seeks to estimate a more accurate
class distribution based on an observed or estimated one. To address this
issue, we propose a distribution calibration-based method-Rebalancing with
Calibrated Sub-classes (RCS): An Enhanced Approach for Robust Imbalanced
Classification, which estimates the distribution parameters of the minority
classes using weighted parameters derived from a mixture of Gaussian components
from both the majority and intermediate classes. An encoder-decoder network is
trained to preserve the structure of the imbalanced data and prevent
disentanglement. After training, feature vectors extracted from the encoder are
used to generate synthetic samples through our distribution calibration
strategy. This approach effectively mitigates the overgeneralization problem
that arises when only the distribution of the majority class is used to
approximate the minority class statistics. Instead, our method calibrates the
parameters by leveraging the distribution of data points in neighboring
regions. Experimental results demonstrate that the proposed method achieves
superior classification performance compared to several baseline and
state-of-the-art techniques across a diverse range of image, text, and tabular
datasets.

</details>


### [13] [Progressive multi-fidelity learning for physical system predictions](https://arxiv.org/abs/2510.13762)
*Paolo Conti,Mengwu Guo,Attilio Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: 提出了一种渐进式多保真度代理模型，能够顺序整合不同类型的数据，通过定制编码器和神经网络进行多保真度回归，利用双重连接系统确保性能不退化。


<details>
  <summary>Details</summary>
Motivation: 高保真度数据获取成本高且耗时，而低保真度数据更容易获得但精度较低。实际应用中数据可能类型不同、来源模态各异且非同时可用，这给建模带来挑战。

Method: 使用渐进式多保真度代理模型，通过定制编码器顺序整合不同类型数据，采用神经网络进行多保真度回归。输入信息通过两种连接方式从低到高保真度流动：编码输入间的拼接连接和最终输出间的加法连接。

Result: 在数值基准和真实案例研究中证明该方法能可靠整合多模态数据并提供准确预测，在时间和参数变化泛化时保持性能。

Conclusion: 该方法能有效利用多保真度信息，防止新数据集成时性能退化，并基于可用输入自动调整预测，为多模态数据集成提供了可靠解决方案。

Abstract: Highly accurate datasets from numerical or physical experiments are often
expensive and time-consuming to acquire, posing a significant challenge for
applications that require precise evaluations, potentially across multiple
scenarios and in real-time. Even building sufficiently accurate surrogate
models can be extremely challenging with limited high-fidelity data.
Conversely, less expensive, low-fidelity data can be computed more easily and
encompass a broader range of scenarios. By leveraging multi-fidelity
information, prediction capabilities of surrogates can be improved. However, in
practical situations, data may be different in types, come from sources of
different modalities, and not be concurrently available, further complicating
the modeling process. To address these challenges, we introduce a progressive
multi-fidelity surrogate model. This model can sequentially incorporate diverse
data types using tailored encoders. Multi-fidelity regression from the encoded
inputs to the target quantities of interest is then performed using neural
networks. Input information progressively flows from lower to higher fidelity
levels through two sets of connections: concatenations among all the encoded
inputs, and additive connections among the final outputs. This dual connection
system enables the model to exploit correlations among different datasets while
ensuring that each level makes an additive correction to the previous level
without altering it. This approach prevents performance degradation as new
input data are integrated into the model and automatically adapts predictions
based on the available inputs. We demonstrate the effectiveness of the approach
on numerical benchmarks and a real-world case study, showing that it reliably
integrates multi-modal data and provides accurate predictions, maintaining
performance when generalizing across time and parameter variations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [14] [Toward Reasoning-Centric Time-Series Analysis](https://arxiv.org/abs/2510.13029)
*Xinlei Wang,Mingtian Tan,Jing Qiu,Junhua Zhao,Jinjin Gu*

Main category: cs.AI

TL;DR: 本文主张将时间序列分析重新构想为推理任务，利用LLMs的深层推理潜力而非数值回归能力，强调因果结构和可解释性，使分析更贴近人类理解。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分析依赖静态基准测试，但现实世界中政策变化、人类行为适应和意外事件频发，需要超越表面趋势分析实际驱动因素。现有LLM方法多使用数值回归能力而忽视其深层推理潜力。

Method: 将时间序列分析重新定义为推理任务，利用LLMs的多模态输入整合能力，优先考虑因果结构和可解释性分析。

Result: 该方法使时间序列分析更贴近人类对齐的理解，在复杂现实环境中提供透明和上下文感知的洞察。

Conclusion: 需要重新思考LLMs在时间序列分析中的角色，将其作为推理工具而非单纯回归模型，强调因果解释和透明性，以应对现实世界的复杂性。

Abstract: Traditional time series analysis has long relied on pattern recognition,
trained on static and well-established benchmarks. However, in real-world
settings -- where policies shift, human behavior adapts, and unexpected events
unfold -- effective analysis must go beyond surface-level trends to uncover the
actual forces driving them. The recent rise of Large Language Models (LLMs)
presents new opportunities for rethinking time series analysis by integrating
multimodal inputs. However, as the use of LLMs becomes popular, we must remain
cautious, asking why we use LLMs and how to exploit them effectively. Most
existing LLM-based methods still employ their numerical regression ability and
ignore their deeper reasoning potential. This paper argues for rethinking time
series with LLMs as a reasoning task that prioritizes causal structure and
explainability. This shift brings time series analysis closer to human-aligned
understanding, enabling transparent and context-aware insights in complex
real-world environments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [A\textsuperscript{2}FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning](https://arxiv.org/abs/2510.12838)
*Qianben Chen,Jingyi Cao,Jiayu Zhang,Tianrui Qin,Xiaowan Li,King Zhu,Dingfeng Shi,He Zhu,Minghao Liu,Xiaobo Liang,Ge Zhang,Jian Yang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: A²FM是一个统一框架，通过任务感知路由和模式对齐，结合推理、工具调用和即时处理三种模式，在保持准确性的同时显著提升成本效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型分为推理型和代理型，各自有不同优势但存在效率问题。推理型模型擅长内部思维链但无法调用外部工具，代理型模型能与环境交互但推理能力较弱，两者在简单查询上都会过度思考或过度调用工具。

Method: 采用路由-对齐原则：先学习任务感知路由，然后在共享骨干网络下对齐模式特定轨迹。引入即时模式处理简单查询，避免不必要的推理或工具调用。提出自适应策略优化(APO)，强制跨模式自适应采样并应用成本正则化奖励。

Result: 在32B规模上，A²FM在BrowseComp、AIME25和HLE基准上分别达到13.4%、70.4%和16.7%，创下可比模型的新SOTA，在代理、推理和通用基准上与前沿LLM竞争。自适应执行每个正确答案成本仅0.00487美元，相比推理模式降低成本45.2%，相比代理模式降低成本33.5%。

Conclusion: A²FM通过统一框架有效解决了推理型和代理型LLM的分裂问题，在保持高准确性的同时显著提升了成本效率，为构建更高效的多功能语言模型提供了新思路。

Abstract: Large language models split into two families: reasoning-centric LLMs, which
strengthen internal chain-of-thought reasoning but cannot invoke external
tools, and agentic LLMs, which learn to interact with environments and leverage
tools but often lag in deep reasoning. This divide arises from fundamentally
different training objectives, leading to mismatched strengths and inefficiency
on simple queries, where both families tend to overthink or over-call tools. In
this work, we present Adaptive Agent Foundation Model (A\textsuperscript{2}FM),
a unified framework that follows a route-then-align principle: the model first
learns task-aware routing and then aligns mode-specific trajectories under a
shared backbone. To address the inefficiency gap, we introduce a third
mode-instant-that handles simple queries directly, preventing unnecessary
reasoning or tool calls while complementing the agentic and reasoning modes. To
jointly enhance accuracy and efficiency, we propose Adaptive Policy
Optimization (APO), which enforces adaptive sampling across modes and applies a
cost-regularized reward. On the 32B scale, A\textsuperscript{2}FM achieves
13.4\% on BrowseComp, 70.4\% on AIME25, and 16.7\% on HLE, setting new SOTA
among comparable models and performing competitively with frontier LLMs across
agentic, reasoning, and general benchmarks. Notably, the adaptive execution
achieves a cost of pass of only \$0.00487 per correct answer-cutting cost by
45.2\% relative to reasoning and 33.5\% relative to agentic, thus delivering
substantially higher cost efficiency while maintaining comparable accuracy.

</details>


### [16] [OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting during Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2510.13003)
*Yifeng Xiong,Xiaohui Xie*

Main category: cs.CL

TL;DR: OPLoRA通过双面正交投影防止LoRA微调中的灾难性遗忘，约束更新位于前k个奇异子空间的正交补空间中，保留预训练知识。


<details>
  <summary>Details</summary>
Motivation: LoRA在微调大语言模型时存在灾难性遗忘问题，学习更新会干扰编码预训练知识的主导奇异方向。

Method: 通过SVD分解冻结权重，使用投影矩阵P_L = I - U_k U_k^T和P_R = I - V_k V_k^T约束LoRA更新完全位于前k个奇异子空间的正交补空间中。

Result: 实验证明OPLoRA显著减少遗忘，同时在常识推理、数学和代码生成任务上保持竞争力。

Conclusion: 正交投影是参数高效微调中知识保留的有效机制，为知识保留提供数学保证。

Abstract: Low-Rank Adaptation (LoRA) enables efficient fine-tuning of large language
models but suffers from catastrophic forgetting when learned updates interfere
with the dominant singular directions that encode essential pre-trained
knowledge. We propose Orthogonal Projection LoRA (OPLoRA), a theoretically
grounded approach that prevents this interference through double-sided
orthogonal projections. By decomposing frozen weights via SVD, OPLoRA
constrains LoRA updates to lie entirely within the orthogonal complement of the
top-$k$ singular subspace using projections $P_L = I - U_k U_k^\top$ and $P_R =
I - V_k V_k^\top$. We prove that this construction exactly preserves the
top-$k$ singular triples, providing mathematical guarantees for knowledge
retention. To quantify subspace interference, we introduce $\rho_k$, a metric
measuring update alignment with dominant directions. Extensive experiments
across commonsense reasoning, mathematics, and code generation demonstrate that
OPLoRA significantly reduces forgetting while maintaining competitive
task-specific performance on LLaMA-2 7B and Qwen2.5 7B, establishing orthogonal
projection as an effective mechanism for knowledge preservation in
parameter-efficient fine-tuning.

</details>


### [17] [GatePro: Parameter-Free Expert Selection Optimization for Mixture-of-Experts Models](https://arxiv.org/abs/2510.13079)
*Chen Zheng,Yuhang Cai,Deyi Liu,Jin Ma,Yiyuan Ma,Yuan Yang,Jing Liu,Yutao Zeng,Xun Zhou,Siyuan Qiao*

Main category: cs.CL

TL;DR: GatePro是一种无需参数的方法，通过识别最相似的专家对并引入局部竞争机制，直接提升MoE架构中专家选择的多样性，避免功能冗余。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型使用MoE架构进行高效扩展，但面临功能相似专家同时被选择的问题，导致计算冗余和有效模型容量受限。现有平衡损失方法改善了token分布，但未能解决根本的专家多样性问题。

Method: GatePro识别最相似的专家对，引入局部竞争机制，防止冗余专家同时激活，同时保持自然的专家专业化。该方法无需额外可学习参数，可在任何训练阶段热插拔部署。

Result: 综合评估表明GatePro在不同模型规模和基准测试中均有效。分析显示GatePro能够实现增强的专家多样性，专家发展出更独特和互补的能力，避免功能冗余。

Conclusion: GatePro为改进MoE有效性提供了一种实用的解决方案，通过直接促进专家选择多样性来解决功能冗余问题，且无需额外参数即可在任何训练阶段部署。

Abstract: Modern large language models leverage Mixture-of-Experts (MoE) architectures
for efficient scaling, but face a critical challenge: functionally similar
experts are often selected simultaneously, creating redundant computation and
limiting effective model capacity. Existing auxiliary balance loss methods
improve token distribution but fail to address the underlying expert diversity
problem. We introduce GatePro, a novel parameter-free method that directly
promotes expert selection diversity. GatePro identifies the most similar expert
pairs and introduces localized competition mechanisms, preventing redundant
expert co-activation while maintaining natural expert specialization. Our
comprehensive evaluation demonstrates GatePro's effectiveness across model
scales and benchmarks. Analysis demonstrates GatePro's ability to achieve
enhanced expert diversity, where experts develop more distinct and
complementary capabilities, avoiding functional redundancy. This approach can
be deployed hot-swappable during any training phase without additional
learnable parameters, offering a practical solution for improving MoE
effectiveness.

</details>


### [18] [Multi-Label Clinical Text Eligibility Classification and Summarization System](https://arxiv.org/abs/2510.13115)
*Surya Tejaswi Yerramsetty,Almas Fathimah*

Main category: cs.CL

TL;DR: 提出一个结合NLP和LLM的系统，用于自动化多标签临床文本资格分类和摘要生成，旨在提高临床试验资格评估的效率。


<details>
  <summary>Details</summary>
Motivation: 临床试验对医学进步至关重要，但需要包含适当和多样化的参与者。传统方法效率低下，需要自动化系统来改进临床试验资格评估过程。

Method: 结合词嵌入(Word2Vec)、命名实体识别、计数向量化和TF-IDF等特征提取方法，使用随机森林和SVM进行多标签分类，评估TextRank、Luhn和GPT-3等摘要技术。

Result: 通过ROUGE分数评估证明了所提方法的有效性，系统在自动化临床试验资格评估方面显示出潜力。

Conclusion: 该系统通过数据驱动方法展示了自动化临床试验资格评估的可行性，有望提高医学研究效率。

Abstract: Clinical trials are central to medical progress because they help improve
understanding of human health and the healthcare system. They play a key role
in discovering new ways to detect, prevent, or treat diseases, and it is
essential that clinical trials include participants with appropriate and
diverse medical backgrounds. In this paper, we propose a system that leverages
Natural Language Processing (NLP) and Large Language Models (LLMs) to automate
multi-label clinical text eligibility classification and summarization. The
system combines feature extraction methods such as word embeddings (Word2Vec)
and named entity recognition to identify relevant medical concepts, along with
traditional vectorization techniques such as count vectorization and TF-IDF
(Term Frequency-Inverse Document Frequency). We further explore weighted TF-IDF
word embeddings that integrate both count-based and embedding-based strengths
to capture term importance effectively. Multi-label classification using Random
Forest and SVM models is applied to categorize documents based on eligibility
criteria. Summarization techniques including TextRank, Luhn, and GPT-3 are
evaluated to concisely summarize eligibility requirements. Evaluation with
ROUGE scores demonstrates the effectiveness of the proposed methods. This
system shows potential for automating clinical trial eligibility assessment
using data-driven approaches, thereby improving research efficiency.

</details>


### [19] [ConsintBench: Evaluating Language Models on Real-World Consumer Intent Understanding](https://arxiv.org/abs/2510.13499)
*Xiaozhe Li,TianYi Lyu,Siyi Yang,Yuxi Gong,Yizhao Yang,Jinxuan Huang,Ligao Zhang,Zhuoyi Huang,Qingwen Liu*

Main category: cs.CL

TL;DR: 该论文提出了首个动态实时评估基准\bench，专门用于评估大语言模型在消费者领域的人类意图理解能力，解决了现有基准缺乏的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的公共讨论具有交织冲突的观点、不同关切、目标和情感倾向等特点，现有基准无法有效评估LLM在这种复杂环境下的意图理解能力。

Method: 构建了\bench基准，支持实时更新，通过自动化筛选流程防止数据污染，是目前同类基准中规模最大、多样性最丰富的。

Result: 成功开发了首个专门用于意图理解的大规模动态评估基准，填补了该领域的研究空白。

Conclusion: \bench基准为评估LLM在真实世界复杂讨论中的意图理解能力提供了有效工具，有助于推动相关研究发展。

Abstract: Understanding human intent is a complex, high-level task for large language
models (LLMs), requiring analytical reasoning, contextual interpretation,
dynamic information aggregation, and decision-making under uncertainty.
Real-world public discussions, such as consumer product discussions, are rarely
linear or involve a single user. Instead, they are characterized by interwoven
and often conflicting perspectives, divergent concerns, goals, emotional
tendencies, as well as implicit assumptions and background knowledge about
usage scenarios. To accurately understand such explicit public intent, an LLM
must go beyond parsing individual sentences; it must integrate multi-source
signals, reason over inconsistencies, and adapt to evolving discourse, similar
to how experts in fields like politics, economics, or finance approach complex,
uncertain environments. Despite the importance of this capability, no
large-scale benchmark currently exists for evaluating LLMs on real-world human
intent understanding, primarily due to the challenges of collecting real-world
public discussion data and constructing a robust evaluation pipeline. To bridge
this gap, we introduce \bench, the first dynamic, live evaluation benchmark
specifically designed for intent understanding, particularly in the consumer
domain. \bench is the largest and most diverse benchmark of its kind,
supporting real-time updates while preventing data contamination through an
automated curation pipeline.

</details>


### [20] [MemoTime: Memory-Augmented Temporal Knowledge Graph Enhanced Large Language Model Reasoning](https://arxiv.org/abs/2510.13614)
*Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: MemoTime是一个基于记忆增强时序知识图谱的框架，通过结构化基础、递归推理和持续经验学习来增强LLM的时序推理能力，解决了多跳推理中的时序忠实性、多实体时序同步等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于时序知识图谱的LLM推理方法在保持多跳推理的时序忠实性、实现多实体时序同步、适应多样化时序操作符以及重用先前推理经验等方面存在困难，需要新的解决方案。

Method: 提出MemoTime框架，将复杂时序问题分解为时间树层次结构，实现操作符感知推理，采用动态证据检索层选择操作符特定的检索策略，并建立自演进经验记忆存储已验证的推理轨迹。

Result: 在多个时序QA基准测试中，MemoTime实现了整体最先进的结果，比强基线性能提升高达24.0%，并使小型模型能够达到与GPT-4-Turbo相当的推理性能。

Conclusion: MemoTime通过结构化时序推理和持续经验学习，有效提升了LLM的时序理解能力，为复杂时序推理问题提供了可行的解决方案。

Abstract: Large Language Models (LLMs) have achieved impressive reasoning abilities,
but struggle with temporal understanding, especially when questions involve
multiple entities, compound operators, and evolving event sequences. Temporal
Knowledge Graphs (TKGs), which capture vast amounts of temporal facts in a
structured format, offer a reliable source for temporal reasoning. However,
existing TKG-based LLM reasoning methods still struggle with four major
challenges: maintaining temporal faithfulness in multi-hop reasoning, achieving
multi-entity temporal synchronization, adapting retrieval to diverse temporal
operators, and reusing prior reasoning experience for stability and efficiency.
To address these issues, we propose MemoTime, a memory-augmented temporal
knowledge graph framework that enhances LLM reasoning through structured
grounding, recursive reasoning, and continual experience learning. MemoTime
decomposes complex temporal questions into a hierarchical Tree of Time,
enabling operator-aware reasoning that enforces monotonic timestamps and
co-constrains multiple entities under unified temporal bounds. A dynamic
evidence retrieval layer adaptively selects operator-specific retrieval
strategies, while a self-evolving experience memory stores verified reasoning
traces, toolkit decisions, and sub-question embeddings for cross-type reuse.
Comprehensive experiments on multiple temporal QA benchmarks show that MemoTime
achieves overall state-of-the-art results, outperforming the strong baseline by
up to 24.0%. Furthermore, MemoTime enables smaller models (e.g., Qwen3-4B) to
achieve reasoning performance comparable to that of GPT-4-Turbo.

</details>


### [21] [NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching](https://arxiv.org/abs/2510.13721)
*Run Luo,Xiaobo Xia,Lu Wang,Longze Chen,Renke Shan,Jing Luo,Min Yang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: NExT-OMNI是一个开源的全模态基础模型，通过离散流范式实现统一建模，支持任意模态间的理解和生成，在多轮多模态交互和跨模态检索方面优于现有统一模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型受自回归架构限制，无法平衡理解和生成能力，且混合和解耦策略的设计冗余，限制了在更广泛场景中的应用。

Method: 利用度量诱导概率路径和动力学最优速度的离散流范式，通过简洁统一表示而非任务解耦设计，实现任意模态间的理解和生成。

Result: 在大规模交错文本、图像、视频和音频数据上训练，在多模态生成和理解基准上表现优异，在多轮多模态交互和跨模态检索方面优于先前统一模型。

Conclusion: NExT-OMNI作为下一代多模态基础模型具有架构优势，通过开源代码和模型检查点推动进一步研究。

Abstract: Next-generation multimodal foundation models capable of any-to-any
cross-modal generation and multi-turn interaction will serve as core components
of artificial general intelligence systems, playing a pivotal role in
human-machine interaction. However, most existing multimodal models remain
constrained by autoregressive architectures, whose inherent limitations prevent
a balanced integration of understanding and generation capabilities. Although
hybrid and decoupling strategies have been explored to address these tasks
within unified frameworks separately, their redundant, non-integrated designs
limit their applicability to broader scenarios, such as cross-modal
retrieval.In this work, we introduce NExT-OMNI, an open-source omnimodal
foundation model that achieves unified modeling through discrete flow
paradigms. By leveraging metric-induced probability paths and kinetic optimal
velocities, NExT-OMNI natively supports any-to-any understanding and generation
with enhanced response efficiency, while enabling broader application scenarios
through concise unified representations rather than task-decoupled designs.
Trained on large-scale interleaved text, image, video, and audio data,
NExT-OMNI delivers competitive performance on multimodal generation and
understanding benchmarks, while outperforming prior unified models in
multi-turn multimodal interaction and cross-modal retrieval, highlighting its
architectural advantages as a next-generation multimodal foundation model. To
advance further research, we release training details, data protocols, and
open-source both the code and model checkpoints.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [22] [UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles](https://arxiv.org/abs/2510.12992)
*Neel P. Bhatt,Po-han Li,Kushagra Gupta,Rohan Siva,Daniel Milan,Alexander T. Hogue,Sandeep P. Chinchali,David Fridovich-Keil,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: UNCAP是一个基于视觉语言模型的规划方法，让联网自动驾驶车辆通过轻量级自然语言消息进行通信，同时明确考虑感知不确定性，提高了协同规划的扩展性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖传输高带宽原始传感器数据流，要么忽略共享数据中的感知和规划不确定性，导致系统既不可扩展也不安全。

Method: 采用两阶段通信协议：首先识别最相关的车辆子集进行信息交换，然后选定的车辆传输定量表达感知不确定性的消息，通过选择性融合最大化互信息的消息来整合最相关信号。

Result: 实验显示通信带宽减少63%，驾驶安全评分提高31%，决策不确定性降低61%，近碰撞事件中的碰撞距离裕度增加四倍。

Conclusion: UNCAP通过自然语言通信和不确定性指导，显著提高了多车协同规划的效率和安全性。

Abstract: Safe large-scale coordination of multiple cooperative connected autonomous
vehicles (CAVs) hinges on communication that is both efficient and
interpretable. Existing approaches either rely on transmitting high-bandwidth
raw sensor data streams or neglect perception and planning uncertainties
inherent in shared data, resulting in systems that are neither scalable nor
safe. To address these limitations, we propose Uncertainty-Guided Natural
Language Cooperative Autonomous Planning (UNCAP), a vision-language model-based
planning approach that enables CAVs to communicate via lightweight natural
language messages while explicitly accounting for perception uncertainty in
decision-making. UNCAP features a two-stage communication protocol: (i) an ego
CAV first identifies the subset of vehicles most relevant for information
exchange, and (ii) the selected CAVs then transmit messages that quantitatively
express their perception uncertainty. By selectively fusing messages that
maximize mutual information, this strategy allows the ego vehicle to integrate
only the most relevant signals into its decision-making, improving both the
scalability and reliability of cooperative planning. Experiments across diverse
driving scenarios show a 63% reduction in communication bandwidth with a 31%
increase in driving safety score, a 61% reduction in decision uncertainty, and
a four-fold increase in collision distance margin during near-miss events.
Project website: https://uncap-project.github.io/

</details>
