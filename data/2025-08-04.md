<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于事件相机的低光图像增强方法，通过解耦增强流程为可见性恢复和结构细化两阶段，结合动态对齐和对比损失，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用事件相机和帧相机的模态优势，限制了性能提升。

Method: 1. 可见性恢复网络通过傅里叶空间的振幅-相位纠缠设计；2. 动态对齐融合策略解决模态间空间不匹配问题；3. 空间频率插值生成负样本，开发对比损失。

Result: 实验表明，该方法优于现有最先进模型。

Conclusion: 通过解耦增强流程和动态对齐策略，有效提升了低光图像增强的性能。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [2] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt结合前向和后向预测，利用大语言模型提升视频长期动作预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法因单向性限制性能，难以捕捉场景中的语义子动作。

Method: BiAnt结合前向和后向预测，利用大语言模型。

Result: 在Ego4D数据集上，BiAnt在编辑距离上优于基线方法。

Conclusion: BiAnt通过双向预测有效提升了长期动作预测的性能。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [3] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 提出了一种基于双曲时空变换器（HyPCV-Former）的视频异常检测方法，利用双曲空间更好地捕捉事件的层次结构和时空连续性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在RGB或深度域中使用欧几里得表示，难以捕捉事件的层次结构和时空连续性。

Method: 通过点云提取器提取空间特征，并将其嵌入洛伦兹双曲空间，引入双曲多头自注意力机制（HMHA）建模时间动态。

Result: 在TIMo和DAD数据集上分别实现了7%和5.6%的性能提升。

Conclusion: HyPCV-Former在双曲空间中直接进行特征变换和异常评分，显著提升了异常检测性能。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: DevFT是一种资源高效的联邦微调方法，通过分阶段构建LLM，显著提升性能并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决联邦微调在边缘设备上资源消耗大的问题，同时保护数据隐私。

Method: 分阶段微调，逐步增加参数容量，并通过知识转移优化初始化参数。采用去冲突引导的层分组和基于差异的层融合构建子模型。

Result: 在多个基准测试中表现优异，收敛速度提升4.59倍，通信开销减少10.67倍，平均性能提升9.07%。

Conclusion: DevFT是一种高效且兼容现有方法的联邦微调方案。

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [5] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 提出了一种基于多保真度分层采样和自适应机器学习元模型的方法，用于高效估计小失效概率，显著节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂非线性有限元模型中计算小失效概率时仍需要大量模型评估，计算成本高。

Method: 采用分层采样生成高保真数据集训练深度学习元模型，作为低保真模型，结合多保真度蒙特卡洛框架估计失效概率。

Result: 应用于高层钢结构建筑的风激励分析，准确估计非线性响应的超越概率曲线，计算效率显著提升。

Conclusion: 该方法在保证精度的同时大幅降低计算成本，适用于复杂系统的罕见事件分析。

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: AI在工业环境中的应用面临挑战，需要结合对象中心流程挖掘（OCPM）实现流程智能（PI），以支持生成式、预测式和规范式AI。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在端到端操作流程中的应用困难，提出需要结合流程智能（PI）和OCPM来解决。

Method: 提出对象中心流程挖掘（OCPM）作为连接数据和流程的桥梁，支持多种AI形式。

Result: OCPM是实现流程智能（PI）的关键，能够支持生成式、预测式和规范式AI在组织环境中的应用。

Conclusion: AI需要流程智能（PI）和OCPM的结合，以优化操作流程并实现AI在工业环境中的成功应用。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [7] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
*Noboru Myers,Obin Kwon,Sankalp Yamsani,Joohyung Kim*

Main category: cs.RO

TL;DR: CHILD是一种紧凑可重构的遥操作系统，支持人形机器人的关节级控制，适用于全身控制和移动操作。


<details>
  <summary>Details</summary>
Motivation: 现有研究很少支持人形机器人的全身关节级遥操作，限制了任务的多样性。

Method: CHILD系统设计为可穿戴设备，支持直接关节映射和自适应力反馈，防止不安全动作。

Result: 在多种机器人系统上验证了移动操作和全身控制的能力。

Conclusion: CHILD系统开源设计，提升了可访问性和可重复性。

Abstract: Recent advances in teleoperation have demonstrated robots performing complex
manipulation tasks. However, existing works rarely support whole-body
joint-level teleoperation for humanoid robots, limiting the diversity of tasks
that can be accomplished. This work presents Controller for Humanoid Imitation
and Live Demonstration (CHILD), a compact reconfigurable teleoperation system
that enables joint level control over humanoid robots. CHILD fits within a
standard baby carrier, allowing the operator control over all four limbs, and
supports both direct joint mapping for full-body control and loco-manipulation.
Adaptive force feedback is incorporated to enhance operator experience and
prevent unsafe joint movements. We validate the capabilities of this system by
conducting loco-manipulation and full-body control examples on a humanoid robot
and multiple dual-arm systems. Lastly, we open-source the design of the
hardware promoting accessibility and reproducibility. Additional details and
open-source information are available at our project website:
https://uiuckimlab.github.io/CHILD-pages.

</details>


### [8] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
*Samratul Fuady,Danesh Tarapore,Mohammad D. Soorati*

Main category: cs.RO

TL;DR: 提出了一种名为SubCDM的子集集体决策方法，通过动态构建子集减少资源消耗，同时保持决策准确性。


<details>
  <summary>Details</summary>
Motivation: 现有集体决策方法需要所有机器人参与，资源消耗大且无法分配机器人执行其他任务。

Method: 动态构建子集，仅依赖局部信息，自适应确定子集大小以应对共识难度。

Result: 仿真实验表明，SubCDM在减少机器人使用量的同时保持了与全群决策相当的准确性。

Conclusion: SubCDM是一种资源高效的集体决策方法，适用于群体机器人系统。

Abstract: Collective decision-making is a key function of autonomous robot swarms,
enabling them to reach a consensus on actions based on environmental features.
Existing strategies require the participation of all robots in the
decision-making process, which is resource-intensive and prevents the swarm
from allocating the robots to any other tasks. We propose Subset-Based
Collective Decision-Making (SubCDM), which enables decisions using only a swarm
subset. The construction of the subset is dynamic and decentralized, relying
solely on local information. Our method allows the swarm to adaptively
determine the size of the subset for accurate decision-making, depending on the
difficulty of reaching a consensus. Simulation results using one hundred robots
show that our approach achieves accuracy comparable to using the entire swarm
while reducing the number of robots required to perform collective
decision-making, making it a resource-efficient solution for collective
decision-making in swarm robotics.

</details>
