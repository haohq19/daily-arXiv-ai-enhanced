<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 6]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]
- [eess.SP](#eess.SP) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Context-Aware Zero-Shot Anomaly Detection in Surveillance Using Contrastive and Predictive Spatiotemporal Modeling](https://arxiv.org/abs/2508.18463)
*Md. Rashid Shahriar Khan,Md. Abrar Hasan,Mohammod Tareq Aziz Justice*

Main category: cs.CV

TL;DR: 提出了一种新颖的上下文感知零样本异常检测框架，结合TimeSformer、DPC和CLIP模型来检测监控视频中的异常事件，无需在训练时接触异常样本。


<details>
  <summary>Details</summary>
Motivation: 监控视频中的异常检测具有挑战性，因为异常事件不可预测且高度依赖上下文。传统方法需要异常样本进行训练，而零样本方法可以检测未见过的异常行为。

Method: 采用混合架构：TimeSformer作为视觉骨干提取时空特征，DPC预测未来表示检测时间偏差，CLIP通过文本提示实现概念级异常检测。使用InfoNCE和CPC损失联合训练，并引入上下文门控机制增强决策。

Result: 该框架能够整合预测建模和视觉语言理解，在复杂环境中泛化到未见过的行为，弥合了时间推理和语义上下文之间的差距。

Conclusion: 提出的上下文感知零样本异常检测方法有效解决了监控视频中异常检测的挑战，代码已开源供研究使用。

Abstract: Detecting anomalies in surveillance footage is inherently challenging due to
their unpredictable and context-dependent nature. This work introduces a novel
context-aware zero-shot anomaly detection framework that identifies abnormal
events without exposure to anomaly examples during training. The proposed
hybrid architecture combines TimeSformer, DPC, and CLIP to model spatiotemporal
dynamics and semantic context. TimeSformer serves as the vision backbone to
extract rich spatial-temporal features, while DPC forecasts future
representations to identify temporal deviations. Furthermore, a CLIP-based
semantic stream enables concept-level anomaly detection through
context-specific text prompts. These components are jointly trained using
InfoNCE and CPC losses, aligning visual inputs with their temporal and semantic
representations. A context-gating mechanism further enhances decision-making by
modulating predictions with scene-aware cues or global video features. By
integrating predictive modeling with vision-language understanding, the system
can generalize to previously unseen behaviors in complex environments. This
framework bridges the gap between temporal reasoning and semantic context in
zero-shot anomaly detection for surveillance. The code for this research has
been made available at
https://github.com/NK-II/Context-Aware-ZeroShot-Anomaly-Detection-in-Surveillance.

</details>


### [2] [Class-wise Flooding Regularization for Imbalanced Image Classification](https://arxiv.org/abs/2508.18723)
*Hiroaki Aizawa,Yuta Naito,Kohei Fukuda*

Main category: cs.CV

TL;DR: 类别测洗正则化方法，通过根据类别频率设置不同的测洗水平，在不平衡数据集上提升少数类的识别性能和整体泛化能力


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在不平衡数据集上训练时对多数类偏见的问题，提高少数类的识别性能

Method: 提出类别测洗正则化，根据类别频率设置不同的测洗水平，压制多数类过拟合同时充分学习少数类

Result: 在不平衡图像分类任务上，方法在少数类分类性能和整体泛化能力方面都超过传统测洗正则化方法

Conclusion: 类别测洗正则化是一种有效的方法，能够在不平衡数据集上同时提高少数类识别性能和整体泛化性能

Abstract: The purpose of training neural networks is to achieve high generalization
performance on unseen inputs. However, when trained on imbalanced datasets, a
model's prediction tends to favor majority classes over minority classes,
leading to significant degradation in the recognition performance of minority
classes. To address this issue, we propose class-wise flooding regularization,
an extension of flooding regularization applied at the class level. Flooding is
a regularization technique that mitigates overfitting by preventing the
training loss from falling below a predefined threshold, known as the flooding
level, thereby discouraging memorization. Our proposed method assigns a
class-specific flooding level based on class frequencies. By doing so, it
suppresses overfitting in majority classes while allowing sufficient learning
for minority classes. We validate our approach on imbalanced image
classification. Compared to conventional flooding regularizations, our method
improves the classification performance of minority classes and achieves better
overall generalization.

</details>


### [3] [VibES: Induced Vibration for Persistent Event-Based Sensing](https://arxiv.org/abs/2508.19094)
*Vincenzo Polizzi,Stephen Yang,Quentin Clark,Jonathan Kelly,Igor Gilitschenski,David B. Lindell*

Main category: cs.CV

TL;DR: 通过采用简单的旋转不平衡质量产生周期性震动，解决事件相机在静态场景中无法产生事件的问题，结合运动补偿管道获得清洁的事件数据。


<details>
  <summary>Details</summary>
Motivation: 事件相机在固定照明和静态/低运动场景中无法产生事件，影响计算机视觉任务的执行。现有方案需要复杂硬件或额外光学组件，因此需要一种轻量级的解决方案。

Method: 使用旋转不平衡质量产生周期性震动激发事件，结合运动补偿管道去除注入运动，产生清洁的经运动校正的事件数据。

Result: 在实际采集的数据集上评估，方法可靠地恢复运动参数，在图像重建和边缘检测任务上都超越了无运动激发的事件感知方式。

Conclusion: 该轻量级方法通过人工震动激发和运动补偿，有效解决了事件相机在静态场景中的问题，为下游感知任务提供了更好的事件数据。

Abstract: Event cameras are a bio-inspired class of sensors that asynchronously measure
per-pixel intensity changes. Under fixed illumination conditions in static or
low-motion scenes, rigidly mounted event cameras are unable to generate any
events, becoming unsuitable for most computer vision tasks. To address this
limitation, recent work has investigated motion-induced event stimulation that
often requires complex hardware or additional optical components. In contrast,
we introduce a lightweight approach to sustain persistent event generation by
employing a simple rotating unbalanced mass to induce periodic vibrational
motion. This is combined with a motion-compensation pipeline that removes the
injected motion and yields clean, motion-corrected events for downstream
perception tasks. We demonstrate our approach with a hardware prototype and
evaluate it on real-world captured datasets. Our method reliably recovers
motion parameters and improves both image reconstruction and edge detection
over event-based sensing without motion induction.

</details>


### [4] [Design, Implementation and Evaluation of a Real-Time Remote Photoplethysmography (rPPG) Acquisition System for Non-Invasive Vital Sign Monitoring](https://arxiv.org/abs/2508.18787)
*Constantino Álvarez Casado,Sasan Sharifipour,Manuel Lage Cañellas,Nhi Nguyen,Le Nguyen,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 本文提出了一种针对低功耗设备优化的实时远程光电容积脉搏波(rPPG)系统，能够从面部视频流中提取心率、呼吸频率和血氧饱和度等生理信号，采用多线程架构和混合编程模型确保30fps的连续可靠运行。


<details>
  <summary>Details</summary>
Motivation: 随着智能环境和低功耗计算设备的日益集成，以及大众市场传感器技术的发展，远程非接触式生理监测正在进步。但在资源受限平台上实时部署这些系统面临着可扩展性、互操作性和性能方面的重大挑战。

Method: 基于Face2PPG流水线处理视频帧进行rPPG信号提取和分析，采用多线程架构管理视频捕获、实时处理、网络通信和GUI更新。使用函数式响应式编程(FRP)和Actor模型的混合编程模型，实现事件驱动处理和高效任务并行化。

Result: 系统在实时约束下进行评估，展示了鲁棒性同时最小化计算开销，能够以30fps连续可靠运行，并通过自适应反馈指导最佳信号捕获条件。

Conclusion: 这项工作解决了实时生物信号监测中的关键挑战，为现代医疗保健和人机交互应用中的性能优化提供了实用解决方案。

Abstract: The growing integration of smart environments and low-power computing
devices, coupled with mass-market sensor technologies, is driving advancements
in remote and non-contact physiological monitoring. However, deploying these
systems in real-time on resource-constrained platforms introduces significant
challenges related to scalability, interoperability, and performance. This
paper presents a real-time remote photoplethysmography (rPPG) system optimized
for low-power devices, designed to extract physiological signals, such as heart
rate (HR), respiratory rate (RR), and oxygen saturation (SpO2), from facial
video streams. The system is built on the Face2PPG pipeline, which processes
video frames sequentially for rPPG signal extraction and analysis, while
leveraging a multithreaded architecture to manage video capture, real-time
processing, network communication, and graphical user interface (GUI) updates
concurrently. This design ensures continuous, reliable operation at 30 frames
per second (fps), with adaptive feedback through a collaborative user interface
to guide optimal signal capture conditions. The network interface includes both
an HTTP server for continuous video streaming and a RESTful API for on-demand
vital sign retrieval. To ensure accurate performance despite the limitations of
low-power devices, we use a hybrid programming model combining Functional
Reactive Programming (FRP) and the Actor Model, allowing event-driven
processing and efficient task parallelization. The system is evaluated under
real-time constraints, demonstrating robustness while minimizing computational
overhead. Our work addresses key challenges in real-time biosignal monitoring,
offering practical solutions for optimizing performance in modern healthcare
and human-computer interaction applications.

</details>


### [5] [Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025](https://arxiv.org/abs/2508.18904)
*Thien-Phuc Tran,Minh-Quang Nguyen,Minh-Triet Tran,Tam V. Nguyen,Trong-Le Do,Duy-Nam Ly,Viet-Tham Huynh,Khanh-Duy Le,Mai-Khiem Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: EVENTA Grand Challenge 2025推出了首个大规模事件级多模态理解基准，通过事件增强图像检索和字幕生成任务，解决了传统方法忽视上下文和语义维度的问题。


<details>
  <summary>Details</summary>
Motivation: 传统图像字幕和检索任务主要关注人物、物体和场景的表面识别，往往忽略了定义真实世界事件的上下文和语义维度。

Method: 基于OpenEvents V1数据集，构建了两个赛道：事件增强图像检索与字幕生成、基于事件的图像检索，通过公开和私有测试阶段进行评估。

Result: 来自6个国家的45个团队参与，前三名团队在ACM Multimedia 2025上展示解决方案，建立了上下文感知、叙事驱动的多媒体AI基础。

Conclusion: EVENTA为新闻、媒体分析、文化存档和可访问性等应用领域奠定了技术基础，推动了事件级多模态理解的发展。

Abstract: The Event-Enriched Image Analysis (EVENTA) Grand Challenge, hosted at ACM
Multimedia 2025, introduces the first large-scale benchmark for event-level
multimodal understanding. Traditional captioning and retrieval tasks largely
focus on surface-level recognition of people, objects, and scenes, often
overlooking the contextual and semantic dimensions that define real-world
events. EVENTA addresses this gap by integrating contextual, temporal, and
semantic information to capture the who, when, where, what, and why behind an
image. Built upon the OpenEvents V1 dataset, the challenge features two tracks:
Event-Enriched Image Retrieval and Captioning, and Event-Based Image Retrieval.
A total of 45 teams from six countries participated, with evaluation conducted
through Public and Private Test phases to ensure fairness and reproducibility.
The top three teams were invited to present their solutions at ACM Multimedia
2025. EVENTA establishes a foundation for context-aware, narrative-driven
multimedia AI, with applications in journalism, media analysis, cultural
archiving, and accessibility. Further details about the challenge are available
at the official homepage: https://ltnghia.github.io/eventa/eventa-2025.

</details>


### [6] [ProPy: Building Interactive Prompt Pyramids upon CLIP for Partially Relevant Video Retrieval](https://arxiv.org/abs/2508.19024)
*Yi Pan,Yujia Zhang,Michael Kampffmeyer,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: ProPy是一个基于CLIP的模型，通过提示金字塔结构和祖先-后代交互机制，在部分相关视频检索任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的PRVR方法主要处理单模态特征，而强大的预训练视觉-语言模型如CLIP在该领域尚未得到充分探索。

Method: 提出ProPy模型，采用提示金字塔结构组织多粒度事件提示，并构建祖先-后代交互机制实现事件间的动态语义交互。

Result: 在三个公开数据集上达到SOTA性能，显著超越先前模型。

Conclusion: ProPy通过系统性的CLIP架构适配，有效解决了部分相关视频检索问题，证明了预训练视觉-语言模型在该任务中的潜力。

Abstract: Partially Relevant Video Retrieval (PRVR) is a practical yet challenging task
that involves retrieving videos based on queries relevant to only specific
segments. While existing works follow the paradigm of developing models to
process unimodal features, powerful pretrained vision-language models like CLIP
remain underexplored in this field. To bridge this gap, we propose ProPy, a
model with systematic architectural adaption of CLIP specifically designed for
PRVR. Drawing insights from the semantic relevance of multi-granularity events,
ProPy introduces two key innovations: (1) A Prompt Pyramid structure that
organizes event prompts to capture semantics at multiple granularity levels,
and (2) An Ancestor-Descendant Interaction Mechanism built on the pyramid that
enables dynamic semantic interaction among events. With these designs, ProPy
achieves SOTA performance on three public datasets, outperforming previous
models by significant margins. Code is available at
https://github.com/BUAAPY/ProPy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [Data-driven models for production forecasting and decision supporting in petroleum reservoirs](https://arxiv.org/abs/2508.18289)
*Mateus A. Fernandes,Michael M. Furlanetti,Eduardo Gildin,Marcio A. Sampaio*

Main category: cs.LG

TL;DR: 基于机器学习的数据驱动方法，不依赖地质模型和流体性质，通过生产注入数据预测油气田产量


<details>
  <summary>Details</summary>
Motivation: 解决油气蔽层工程中生产预测的主要挑战，预光岩石-流体系统行为变化，减少对地质模型和流体性质信息的依赖

Method: 采用监督学习方法（回归和神经网络），通过生产注入变量相关性分析和数据处理，处理概念漏淀问题，先用组合模型验证后应用于巴西盖盐层实际案例

Result: 开发出可靠的预测器，能够快速响应、处理实际困难（如井射和处理设备限制），重现蔽层动态

Conclusion: 该方法可用于支持蔽层管理，预阻坏行为、优化生产注入参数、分析概率事件影响，最大化油气采取率，为油气田管理提供了高效数据驱动解决方案

Abstract: Forecasting production reliably and anticipating changes in the behavior of
rock-fluid systems are the main challenges in petroleum reservoir engineering.
This project proposes to deal with this problem through a data-driven approach
and using machine learning methods. The objective is to develop a methodology
to forecast production parameters based on simple data as produced and injected
volumes and, eventually, gauges located in wells, without depending on
information from geological models, fluid properties or details of well
completions and flow systems. Initially, we performed relevance analyses of the
production and injection variables, as well as conditioning the data to suit
the problem. As reservoir conditions change over time, concept drift is a
priority concern and require special attention to those observation windows and
the periodicity of retraining, which are also objects of study. For the
production forecasts, we study supervised learning methods, such as those based
on regressions and Neural Networks, to define the most suitable for our
application in terms of performance and complexity. In a first step, we
evaluate the methodology using synthetic data generated from the UNISIM III
compositional simulation model. Next, we applied it to cases of real plays in
the Brazilian pre-salt. The expected result is the design of a reliable
predictor for reproducing reservoir dynamics, with rapid response, capability
of dealing with practical difficulties such as restrictions in wells and
processing units, and that can be used in actions to support reservoir
management, including the anticipation of deleterious behaviors, optimization
of production and injection parameters and the analysis of the effects of
probabilistic events, aiming to maximize oil recovery.

</details>


### [8] [MOCHA: Discovering Multi-Order Dynamic Causality in Temporal Point Processes](https://arxiv.org/abs/2508.18873)
*Yunyang Cao,Juekai Lin,Wenhao Li,Bo Jin*

Main category: cs.LG

TL;DR: MOCHA是一个新颖的框架，用于在时序点过程中发现多阶动态因果关系，通过建模时变有向无环图和端到端可微分框架，实现了准确的事件预测和可解释的因果结构发现。


<details>
  <summary>Details</summary>
Motivation: 现有的时序点过程因果发现方法通常依赖静态或一阶因果结构，忽略了因果关系的多阶性和时变特性，无法充分建模真实世界事件序列中的复杂因果依赖。

Method: 提出MOCHA框架，将多阶影响建模为潜在时变图上的多跳因果路径；使用时变有向无环图（DAG）和可学习结构权重，施加无环性和稀疏性约束；设计端到端可微分框架，联合建模因果发现和时序点过程动态。

Result: 在真实世界数据集上的大量实验表明，MOCHA不仅在事件预测方面达到了最先进的性能，而且揭示了有意义且可解释的因果结构。

Conclusion: MOCHA框架成功解决了时序点过程中多阶动态因果关系的发现问题，为复杂事件序列的建模提供了有效的解决方案，同时保持了良好的可解释性。

Abstract: Discovering complex causal dependencies in temporal point processes (TPPs) is
critical for modeling real-world event sequences. Existing methods typically
rely on static or first-order causal structures, overlooking the multi-order
and time-varying nature of causal relationships. In this paper, we propose
MOCHA, a novel framework for discovering multi-order dynamic causality in TPPs.
MOCHA characterizes multi-order influences as multi-hop causal paths over a
latent time-evolving graph. To model such dynamics, we introduce a time-varying
directed acyclic graph (DAG) with learnable structural weights, where
acyclicity and sparsity constraints are enforced to ensure structural validity.
We design an end-to-end differentiable framework that jointly models causal
discovery and TPP dynamics, enabling accurate event prediction and revealing
interpretable structures. Extensive experiments on real-world datasets
demonstrate that MOCHA not only achieves state-of-the-art performance in event
prediction, but also reveals meaningful and interpretable causal structures.

</details>


### [9] [HAEPO: History-Aggregated Exploratory Policy Optimization](https://arxiv.org/abs/2508.18884)
*Gaurish Trivedi,Alakh Sharma,Kartikey Singh Bhandari,Dhruv Kumar,Pratik Narang,Jagat Sesh Challa*

Main category: cs.LG

TL;DR: HAEPO是一种新的探索性策略优化方法，通过历史聚合和累积对数似然来增强长时域任务的探索能力，在收敛速度、探索广度和奖励对齐方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法如DPO和GRPO在长时域任务中往往限制探索，需要一种能够更好利用完整轨迹历史并促进广泛探索的新方法。

Method: HAEPO将轨迹压缩为累积对数似然，使用Plackett-Luce softmax获得与回报成正比的归一化权重，并加入熵正则化和软KL惩罚来稳定训练。

Result: 实验显示HAEPO收敛快、探索彻底、与真实奖励对齐紧密，在多样化任务中表现优于或等同于PPO、GRPO和DPO。

Conclusion: HAEPO提供了一个稳定且可解释的框架，通过显式利用完整轨迹历史来平衡探索和稳定性。

Abstract: Exploration is essential in modern learning, from reinforcement learning
environments with small neural policies to large language models (LLMs).
Existing work, such as DPO, leverages full sequence log-likelihoods to capture
an entire trajectory of the model's decisions, while methods like GRPO
aggregate per-token ratios into a trajectory-level update. However, both often
limit exploration on long-horizon tasks. We introduce History-Aggregated
Exploratory Policy Optimization (HAEPO), a history-aware exploratory loss to
combat these shortcomings. HAEPO compresses each trajectory into the sum of its
logarithmic probabilities (a cumulative logarithmic likelihood), and applies a
Plackett-Luce softmax across trajectories to obtain normalized weights
proportional to their returns, thus encouraging broader exploration. We add
entropy regularization to stabilize the aggressive updates to prevent premature
collapse and a soft KL penalty relative to a frozen copy of the previous
(reference) policy. Empirically, HAEPO converges fast, explores thoroughly,
aligns closely with true rewards, and demonstrates robust learning behavior
better or at par with PPO, GRPO, and DPO across diverse tasks. Thus, HAEPO
provides a stable and interpretable framework by explicitly leveraging
full-trajectory history while balancing exploration and stability.

</details>


### [10] [Working My Way Back to You: Resource-Centric Next-Activity Prediction](https://arxiv.org/abs/2508.19016)
*Kelly Kurowski,Xixi Lu,Hajo A Reijers*

Main category: cs.LG

TL;DR: 这篇论文研究了从资源角度出发的下一活动预测方法，通过比较四种预测模型和三种编码策略，发现LightGBM和Transformer模型在2-gram活动迁移编码下表现最佳，而随机森林在结2-gram迁移和活动重复特征的编码下表现最好。


<details>
  <summary>Details</summary>
Motivation: 当前预测过程监控研究主要从控制流角度出发，本文采用资源中心视角来研究下一活动预测，这种方法能够帮助改善工作组织、平衡工作负荷和预测容量。

Method: 在四个实际数据集上评估四种预测模型（LightGBM、Transformer、随机森林等）和三种编码策略，包括2-gram活动迁移编码以及结合2-gram迁移和活动重复特征的编码方法。

Result: 结2-gram迁移和活动重复特征的编码方法获得了最高的平均准确率。LightGBM和Transformer模型在2-gram活动迁移编码下表现最好，而随机森林在结合编码下表现最优。

Conclusion: 资源中心的下一活动预测方法为更智能的资源分配、战略性劳务规划和个性化员工支持提供了可能，为预测过程监控领域开启了新的研究方向。

Abstract: Predictive Process Monitoring (PPM) aims to train models that forecast
upcoming events in process executions. These predictions support early
bottleneck detection, improved scheduling, proactive interventions, and timely
communication with stakeholders. While existing research adopts a control-flow
perspective, we investigate next-activity prediction from a resource-centric
viewpoint, which offers additional benefits such as improved work organization,
workload balancing, and capacity forecasting. Although resource information has
been shown to enhance tasks such as process performance analysis, its role in
next-activity prediction remains unexplored. In this study, we evaluate four
prediction models and three encoding strategies across four real-life datasets.
Compared to the baseline, our results show that LightGBM and Transformer models
perform best with an encoding based on 2-gram activity transitions, while
Random Forest benefits most from an encoding that combines 2-gram transitions
and activity repetition features. This combined encoding also achieves the
highest average accuracy. This resource-centric approach could enable smarter
resource allocation, strategic workforce planning, and personalized employee
support by analyzing individual behavior rather than case-level progression.
The findings underscore the potential of resource-centric next-activity
prediction, opening up new venues for research on PPM.

</details>


### [11] [Breaking the Black Box: Inherently Interpretable Physics-Informed Machine Learning for Imbalanced Seismic Data](https://arxiv.org/abs/2508.19031)
*Vemula Sreenath,Filippo Gatti,Pierre Jehel*

Main category: cs.LG

TL;DR: 通过透明的线性机器学习架构和HazBinLoss函数，解决了地震地面运动模型的黑盒问题和数据不平衡问题，在保持可解释性的同时达到了传统模型的性能水平。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习地震地面运动模型存在两大问题：1)黑盒模型难以解释和信任，限制在重要决策中的应用；2)数据平衡问题，近断层大震级记录少于远场小震级记录。

Method: 设计了透明的ML架构，每个输入变量（震级、距离等）独立处理并线性相加得到输出，使每个变量的贡献可解释。使用HazBinLoss函数，在训练中给过少的关键近场大震记录赋予更高权重，以避免对最具破坏性场景的预测不足。

Result: 该模型能够捐描已知的地震学原理，与现有的地震地面运动模型达到相当的性能水平，同时保持了模型的透明性和可解释性。

Conclusion: 该框架为风险评估和灾害规划研究提供了更广泛采用机器学习方法的可能性，解决了黑盒模型和数据不平衡这两个关键问题。

Abstract: Ground motion models (GMMs) predict how strongly the ground will shake during
an earthquake. They are essential for structural analysis, seismic design, and
seismic risk assessment studies. Traditional machine learning (ML) approaches
are popular to develop GMMs, due to large earthquake databases worldwide.
However, they operate as "black boxes," which are hard to interpret and trust,
limiting their use in high-stake decisions. Additionally, these databases
suffer from significant data imbalances: fewer large, critically damaging
records near the fault compared to abundant, less severely damaging distant
records. These two limitations are addressed in this work by developing a
transparent ML architecture using the HazBinLoss function. Each input (e.g.,
magnitude, distance, their interaction term, etc.) is processed separately and
added linearly to obtain the output, resulting in exact contribution of each
term. The HazBinLoss function assigns higher weights to critical near-field
large magnitude records and lower weights to less-critical far-field smaller
magnitude records, during training to prevent underprediction of the most
damaging scenarios. Our model captures known seismological principles and
achieves comparable performance with established GMMs while maintaining
transparency. This framework enables broader adoption of ML-based approaches
for risk assessment studies and disaster planning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [12] [Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models](https://arxiv.org/abs/2508.18651)
*Chenxu Yang,Qingyi Si,Zheng Lin*

Main category: cs.CL

TL;DR: 提出Collaborative Decoding (CoDe)方法，通过动态整合有无外部知识的输出概率，打破忠实性和表达性之间的权衡，提升大语言模型的知识整合能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在整合外部知识时难以同时保持忠实性和表达性，要么缺乏知识支持而损害忠实性，要么过于冗长而牺牲表达性。

Method: 提出协作解码(CoDe)框架，基于分布差异和模型置信度动态整合有无外部知识的输出概率，并引入知识感知重排序机制防止过度依赖参数知识。

Result: 实验表明CoDe框架在多种大语言模型和评估指标上都能显著提升忠实性而不损害表达性，验证了其有效性和泛化能力。

Conclusion: CoDe是一种即插即用的有效方法，成功解决了大语言模型在知识整合中忠实性与表达性的权衡问题，具有很好的通用性。

Abstract: Grounding responses in external knowledge represents an effective strategy
for mitigating hallucinations in Large Language Models (LLMs). However, current
LLMs struggle to seamlessly integrate knowledge while simultaneously
maintaining faithfulness (or fidelity) and expressiveness, capabilities that
humans naturally possess. This limitation results in outputs that either lack
support from external knowledge, thereby compromising faithfulness, or appear
overly verbose and unnatural, thus sacrificing expressiveness. In this work, to
break the trade-off between faithfulness and expressiveness, we propose
Collaborative Decoding (CoDe), a novel approach that dynamically integrates
output probabilities generated with and without external knowledge. This
integration is guided by distribution divergence and model confidence, enabling
the selective activation of relevant and reliable expressions from the model's
internal parameters. Furthermore, we introduce a knowledge-aware reranking
mechanism that prevents over-reliance on prior parametric knowledge while
ensuring proper utilization of provided external information. Through
comprehensive experiments, our plug-and-play CoDe framework demonstrates
superior performance in enhancing faithfulness without compromising
expressiveness across diverse LLMs and evaluation metrics, validating both its
effectiveness and generalizability.

</details>


### [13] [Chronological Passage Assembling in RAG framework for Temporal Question Answering](https://arxiv.org/abs/2508.18748)
*Byeongjeong Kim,Jeonghyun Park,Joonho Yang,Hwanhee Lee*

Main category: cs.CL

TL;DR: ChronoRAG是一个专门针对叙事文本的新型RAG框架，通过重构连贯段落和保持时间顺序来提升长上下文问答性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理叙事文本时效果有限，因为叙事理解需要更广泛的上下文和段落间的时序关系，而不仅仅是孤立片段

Method: 提出ChronoRAG框架，专注于两个关键方面：将分散文档信息重构为连贯结构化段落；通过显式捕获和维护检索段落的时间顺序来保持叙事流

Result: 在NarrativeQA数据集上的实验显示，ChronoRAG在需要事实识别和复杂时序关系理解的任务中取得了显著改进

Conclusion: 时序顺序推理对于解决叙事问答至关重要，ChronoRAG有效解决了叙事文本特有的挑战

Abstract: Long-context question answering over narrative tasks is challenging because
correct answers often hinge on reconstructing a coherent timeline of events
while preserving contextual flow in a limited context window.
Retrieval-augmented generation (RAG) indexing methods aim to address this
challenge by selectively retrieving only necessary document segments. However,
narrative texts possess unique characteristics that limit the effectiveness of
these existing approaches. Specifically, understanding narrative texts requires
more than isolated segments, as the broader context and sequential
relationships between segments are crucial for comprehension. To address these
limitations, we propose ChronoRAG, a novel RAG framework specialized for
narrative texts. This approach focuses on two essential aspects: refining
dispersed document information into coherent and structured passages, and
preserving narrative flow by explicitly capturing and maintaining the temporal
order among retrieved passages. We empirically demonstrate the effectiveness of
ChronoRAG through experiments on the NarrativeQA dataset, showing substantial
improvements in tasks requiring both factual identification and comprehension
of complex sequential relationships, underscoring that reasoning over temporal
order is crucial in resolving narrative QA.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](https://arxiv.org/abs/2508.18397)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 本文通过大规模比较研究，针对自动驾驶离线强化学习中的数据不平衡问题，提出了六种关键性加权策略，显著提升了安全性能，其中基于模型不确定性的方法将碰撞率从16.0%降至5.5%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶离线强化学习面临极端数据不平衡问题，普通场景远多于罕见"长尾"事件，导致标准均匀数据采样产生脆弱且不安全的策略。

Method: 研究了六种关键性加权方案，分为三类：启发式、不确定性和行为基础方法，在两个时间尺度（单时间步和完整场景）评估，训练了七个目标条件保守Q学习智能体。

Result: 所有数据筛选方法均显著优于基线，基于模型不确定性的方法实现最大安全改进，碰撞率降低近三倍（从16.0%降至5.5%）。时间步级加权擅长反应性安全，场景级加权改善长期规划。

Conclusion: 智能非均匀采样是构建安全可靠自动驾驶系统的关键组件，为离线强化学习中的数据筛选提供了全面框架。

Abstract: Offline Reinforcement Learning (RL) presents a promising paradigm for
training autonomous vehicle (AV) planning policies from large-scale, real-world
driving logs. However, the extreme data imbalance in these logs, where mundane
scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe
policies when using standard uniform data sampling. In this work, we address
this challenge through a systematic, large-scale comparative study of data
curation strategies designed to focus the learning process on information-rich
samples. We investigate six distinct criticality weighting schemes which are
categorized into three families: heuristic-based, uncertainty-based, and
behavior-based. These are evaluated at two temporal scales, the individual
timestep and the complete scenario. We train seven goal-conditioned
Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based
architecture and evaluate them in the high-fidelity Waymax simulator. Our
results demonstrate that all data curation methods significantly outperform the
baseline. Notably, data-driven curation using model uncertainty as a signal
achieves the most significant safety improvements, reducing the collision rate
by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear
trade-off where timestep-level weighting excels at reactive safety while
scenario-level weighting improves long-horizon planning. Our work provides a
comprehensive framework for data curation in Offline RL and underscores that
intelligent, non-uniform sampling is a critical component for building safe and
reliable autonomous agents.

</details>


### [15] [Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models](https://arxiv.org/abs/2508.18460)
*Tianze Liu,Md Abu Bakr Siddique,Hongyu An*

Main category: cs.RO

TL;DR: 本文提出通过模拟动物联想学习机制来增强神经形态机器人的自主能力，解决传统AI方法在功耗和适应性方面的限制，特别是在行星探索等SWaP受限应用中。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的AI方法依赖大数据集和神经网络，存在高功耗和有限适应性的问题，特别是在资源受限的太空探索等应用中。动物通过联想学习能够有效适应环境，这为开发更高效的自主机器人系统提供了灵感。

Method: 通过模拟啮齿类动物的联想学习机制，利用空间细胞（位置细胞和网格细胞）的神经模型，在开放场地迷宫环境中实现神经形态机器人的在线联想学习，使其能够在动态环境中自主导航和优化性能。

Result: 该方法使神经形态机器人能够在实时场景中进行空间任务的在线联想学习，通过环境交互来自主适应和优化行为，降低了功耗需求并提高了适应性。

Conclusion: 通过仿生学方法模拟动物联想学习机制，成功实现了神经形态机器人在空间认知任务中的自主学习能力，为生物空间认知与机器人技术的融合提供了有效途径，推动了自主系统的发展。

Abstract: Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable
prowess across various cognitive tasks using extensive training data. However,
the reliance on large datasets and neural networks presents challenges such as
highpower consumption and limited adaptability, particularly in
SWaP-constrained applications like planetary exploration. To address these
issues, we propose enhancing the autonomous capabilities of intelligent robots
by emulating the associative learning observed in animals. Associative learning
enables animals to adapt to their environment by memorizing concurrent events.
By replicating this mechanism, neuromorphic robots can navigate dynamic
environments autonomously, learning from interactions to optimize performance.
This paper explores the emulation of associative learning in rodents using
neuromorphic robots within open-field maze environments, leveraging insights
from spatial cells such as place and grid cells. By integrating these models,
we aim to enable online associative learning for spatial tasks in real-time
scenarios, bridging the gap between biological spatial cognition and robotics
for advancements in autonomous systems.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [16] [EMind: A Foundation Model for Multi-task Electromagnetic Signals Understanding](https://arxiv.org/abs/2508.18785)
*Luqing Luo,Wenjin Gui,Yunfei Liu,Ziyue Zhang,Yunxi Zhang,Fengxiang Wang,Zonghao Guo,Zizhi Ma,Xinzhu Liu,Hanxiang He,Jinhai Li,Xin Qiu,Wupeng Xie,Yangang Sun*

Main category: eess.SP

TL;DR: EMind是一个电磁信号基础模型，通过大规模预训练和物理特性利用，解决了电磁信号处理中的异构性、噪声和跨任务泛化问题。


<details>
  <summary>Details</summary>
Motivation: 电磁信号与文本图像差异大，存在高异构性、强背景噪声和复杂时频结构，现有通用模型无法直接使用，且缺乏跨任务泛化和高质量数据集。

Method: 构建首个统一标准化电磁信号数据集，开发长度自适应多信号打包方法和硬件感知训练策略，利用电磁信号物理特性进行表示学习。

Result: EMind在多个下游任务中表现出强大性能和广泛泛化能力，实现了从任务特定模型到统一电磁智能框架的转变。

Conclusion: 该工作为电磁信号处理提供了首个基础模型，通过统一框架有效解决了该领域的核心挑战，推动了电磁智能的发展。

Abstract: Deep understanding of electromagnetic signals is fundamental to dynamic
spectrum management, intelligent transportation, autonomous driving and
unmanned vehicle perception. The field faces challenges because electromagnetic
signals differ greatly from text and images, showing high heterogeneity, strong
background noise and complex joint time frequency structure, which prevents
existing general models from direct use. Electromagnetic communication and
sensing tasks are diverse, current methods lack cross task generalization and
transfer efficiency, and the scarcity of large high quality datasets blocks the
creation of a truly general multitask learning framework. To overcome these
issue, we introduce EMind, an electromagnetic signals foundation model that
bridges large scale pretraining and the unique nature of this modality. We
build the first unified and largest standardized electromagnetic signal dataset
covering multiple signal types and tasks. By exploiting the physical properties
of electromagnetic signals, we devise a length adaptive multi-signal packing
method and a hardware-aware training strategy that enable efficient use and
representation learning from heterogeneous multi-source signals. Experiments
show that EMind achieves strong performance and broad generalization across
many downstream tasks, moving decisively from task specific models to a unified
framework for electromagnetic intelligence. The code is available at:
https://github.com/GabrielleTse/EMind.

</details>
