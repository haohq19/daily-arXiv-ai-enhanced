<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: MonoVQD是一种新型框架，通过改进DETR架构，解决了单目3D检测中的关键问题，包括稳定性、梯度消失和查询质量优化，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D检测中，DETR架构的直接应用存在局限性，无法达到最优性能。MonoVQD旨在通过创新方法解决这些问题。

Method: 1. 提出Mask Separated Self-Attention机制，将去噪过程集成到DETR中；2. 引入Variational Query Denoising技术解决梯度消失问题；3. 采用自蒸馏策略优化查询质量。

Result: 在KITTI单目基准测试中表现优异，且其核心组件在多视图3D检测（nuScenes数据集）中也显著提升性能。

Conclusion: MonoVQD通过创新方法显著提升了单目3D检测的性能，并展示了强大的泛化能力。

Abstract: Precisely localizing 3D objects from a single image constitutes a central
challenge in monocular 3D detection. While DETR-like architectures offer a
powerful paradigm, their direct application in this domain encounters inherent
limitations, preventing optimal performance. Our work addresses these
challenges by introducing MonoVQD, a novel framework designed to fundamentally
advance DETR-based monocular 3D detection. We propose three main contributions.
First, we propose the Mask Separated Self-Attention mechanism that enables the
integration of the denoising process into a DETR architecture. This improves
the stability of Hungarian matching to achieve a consistent optimization
objective. Second, we present the Variational Query Denoising technique to
address the gradient vanishing problem of conventional denoising methods, which
severely restricts the efficiency of the denoising process. This explicitly
introduces stochastic properties to mitigate this fundamental limitation and
unlock substantial performance gains. Finally, we introduce a sophisticated
self-distillation strategy, leveraging insights from later decoder layers to
synergistically improve query quality in earlier layers, thereby amplifying the
iterative refinement process. Rigorous experimentation demonstrates that
MonoVQD achieves superior performance on the challenging KITTI monocular
benchmark. Highlighting its broad applicability, MonoVQD's core components
seamlessly integrate into other architectures, delivering significant
performance gains even in multi-view 3D detection scenarios on the nuScenes
dataset and underscoring its robust generalization capabilities.

</details>


### [2] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSIC的图像压缩方法，通过多解码选项保护用户隐私，同时保留图像压缩功能，并利用CLTG和UAEO模块优化性能。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言预训练模型对语义理解的提升，公开图片易被搜索引擎等工具利用，因此需要保护用户隐私。

Method: 提出PSIC方法，支持多解码选项；设计CLTG模块生成偏置信息，UAEO优化函数利用目标模型的软标签；采用自适应多目标优化策略。

Result: 实验证明PSIC能有效保护隐私并保持图像质量，且可无缝集成到现有LIC模型中。

Conclusion: PSIC是一种灵活、高效的隐私保护图像压缩方案，适用于多种下游任务。

Abstract: The improved semantic understanding of vision-language pretrained (VLP)
models has made it increasingly difficult to protect publicly posted images
from being exploited by search engines and other similar tools. In this
context, this paper seeks to protect users' privacy by implementing defenses at
the image compression stage to prevent exploitation. Specifically, we propose a
flexible coding method, termed Privacy-Shielded Image Compression (PSIC), that
can produce bitstreams with multiple decoding options. By default, the
bitstream is decoded to preserve satisfactory perceptual quality while
preventing interpretation by VLP models. Our method also retains the original
image compression functionality. With a customizable input condition, the
proposed scheme can reconstruct the image that preserves its full semantic
information. A Conditional Latent Trigger Generation (CLTG) module is proposed
to produce bias information based on customizable conditions to guide the
decoding process into different reconstructed versions, and an
Uncertainty-Aware Encryption-Oriented (UAEO) optimization function is designed
to leverage the soft labels inferred from the target VLP model's uncertainty on
the training data. This paper further incorporates an adaptive multi-objective
optimization strategy to obtain improved encrypting performance and perceptual
quality simultaneously within a unified training process. The proposed scheme
is plug-and-play and can be seamlessly integrated into most existing Learned
Image Compression (LIC) models. Extensive experiments across multiple
downstream tasks have demonstrated the effectiveness of our design.

</details>


### [3] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

Main category: cs.CV

TL;DR: ViMAT是一种无需标记或固定工作环境的AI驱动系统，用于实时监控工业装配任务，通过多视角视频流和推理模块实现高效监控。


<details>
  <summary>Details</summary>
Motivation: 工业装配任务的视觉监控对防止设备损坏和保障工人安全至关重要，但现有商业解决方案通常需要固定工作环境或视觉标记。

Method: ViMAT结合感知模块（从多视角视频流提取视觉信息）和推理模块（基于观察的装配状态和任务知识推断最可能的动作）。

Result: 在LEGO组件更换和液压模具重组任务中，ViMAT在部分和不确定视觉观察的挑战性场景中表现出色。

Conclusion: ViMAT在无需标记或固定环境的条件下，有效实现了工业装配任务的实时视觉监控。

Abstract: Visual monitoring of industrial assembly tasks is critical for preventing
equipment damage due to procedural errors and ensuring worker safety. Although
commercial solutions exist, they typically require rigid workspace setups or
the application of visual markers to simplify the problem. We introduce ViMAT,
a novel AI-driven system for real-time visual monitoring of assembly tasks that
operates without these constraints. ViMAT combines a perception module that
extracts visual observations from multi-view video streams with a reasoning
module that infers the most likely action being performed based on the observed
assembly state and prior task knowledge. We validate ViMAT on two assembly
tasks, involving the replacement of LEGO components and the reconfiguration of
hydraulic press molds, demonstrating its effectiveness through quantitative and
qualitative analysis in challenging real-world scenarios characterized by
partial and uncertain visual observations. Project page:
https://tev-fbk.github.io/ViMAT

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Optimization of bi-directional gated loop cell based on multi-head attention mechanism for SSD health state classification model](https://arxiv.org/abs/2506.14830)
*Zhizhao Wen,Ruoxin Zhang,Chao Wang*

Main category: cs.LG

TL;DR: 提出了一种结合BiGRU和多头注意力机制的混合模型（BiGRU-MHA），用于SSD健康状态预测，显著提高了分类准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: SSD健康状态预测对数据可靠性至关重要，传统模型存在泛化能力不足的问题。

Method: 利用BiGRU网络的双向时序建模能力捕捉SSD退化特征，并通过多头注意力机制动态分配特征权重。

Result: 训练集和测试集分类准确率分别为92.70%和92.44%，AUC为0.94，泛化能力优异。

Conclusion: 该模型为SSD健康预测提供了新技术方案，可显著降低数据丢失风险并优化维护成本。

Abstract: Aiming at the critical role of SSD health state prediction in data
reliability assurance, this study proposes a hybrid BiGRU-MHA model that
incorporates a multi-head attention mechanism to enhance the accuracy and
stability of storage device health classification. The model innovatively
integrates temporal feature extraction and key information focusing
capabilities. Specifically, it leverages the bidirectional timing modeling
advantages of the BiGRU network to capture both forward and backward
dependencies of SSD degradation features. Simultaneously, the multi-head
attention mechanism dynamically assigns feature weights, improving the model's
sensitivity to critical health indicators. Experimental results show that the
proposed model achieves classification accuracies of 92.70% on the training set
and 92.44% on the test set, with a minimal performance gap of only 0.26%,
demonstrating excellent generalization ability. Further analysis using the
receiver operating characteristic (ROC) curve shows an area under the curve
(AUC) of 0.94 on the test set, confirming the model's robust binary
classification performance. This work not only presents a new technical
approach for SSD health prediction but also addresses the generalization
bottleneck of traditional models, offering a verifiable method with practical
value for preventive maintenance of industrial-grade storage systems. The
results show the model can significantly reduce data loss risks by providing
early failure warnings and help optimize maintenance costs, supporting
intelligent decision-making in building reliable storage systems for cloud
computing data centers and edge storage environments.

</details>


### [5] [Event-Driven Online Vertical Federated Learning](https://arxiv.org/abs/2506.14911)
*Ganyu Wang,Boyu Wang,Bin Gu,Charles Ling*

Main category: cs.LG

TL;DR: 论文提出了一种事件驱动的在线垂直联邦学习（VFL）框架，解决了数据异步和非平稳环境下的挑战，并通过动态局部遗憾（DLR）优化了性能。


<details>
  <summary>Details</summary>
Motivation: 在线学习在VFL中更具适应性，但数据异步性和非平稳性带来了挑战，现有研究未充分解决。

Method: 提出事件驱动的在线VFL框架，仅激活部分客户端，引入动态局部遗憾（DLR）处理非凸和非平稳问题。

Result: 实验表明，该框架在非平稳数据下更稳定，显著降低了通信和计算成本。

Conclusion: 该框架为在线VFL提供了高效解决方案，适用于现实场景。

Abstract: Online learning is more adaptable to real-world scenarios in Vertical
Federated Learning (VFL) compared to offline learning. However, integrating
online learning into VFL presents challenges due to the unique nature of VFL,
where clients possess non-intersecting feature sets for the same sample. In
real-world scenarios, the clients may not receive data streaming for the
disjoint features for the same entity synchronously. Instead, the data are
typically generated by an \emph{event} relevant to only a subset of clients. We
are the first to identify these challenges in online VFL, which have been
overlooked by previous research. To address these challenges, we proposed an
event-driven online VFL framework. In this framework, only a subset of clients
were activated during each event, while the remaining clients passively
collaborated in the learning process. Furthermore, we incorporated
\emph{dynamic local regret (DLR)} into VFL to address the challenges posed by
online learning problems with non-convex models within a non-stationary
environment. We conducted a comprehensive regret analysis of our proposed
framework, specifically examining the DLR under non-convex conditions with
event-driven online VFL. Extensive experiments demonstrated that our proposed
framework was more stable than the existing online VFL framework under
non-stationary data conditions while also significantly reducing communication
and computation costs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [6] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 本文介绍了一个手动标注的老年患者出院摘要中不良事件（AE）提取的语料库，填补了临床NLP资源中老年人群的不足。数据集包含14种临床显著AE及上下文属性，支持不连续和重叠实体标注。实验显示，BERT等模型在粗粒度任务表现优异（F1=0.943），但在细粒度任务（F1=0.675）和罕见事件上表现较差。数据集通过DataLoch提供，可作为AE提取方法的基准。


<details>
  <summary>Details</summary>
Motivation: 老年患者在临床NLP资源中代表性不足，现有研究对不连续和重叠实体的处理有限，因此需要构建一个专门针对老年患者的AE标注数据集。

Method: 构建了一个包含14种AE及其上下文属性的手动标注数据集，支持不连续和重叠实体。使用FlairNLP评估了多种模型（如BERT）在三种标注粒度上的表现。

Result: BERT在粗粒度任务上表现优异（F1=0.943），但在细粒度任务（F1=0.675）和罕见事件上表现较差，表明复杂临床语言和罕见事件的检测仍具挑战性。

Conclusion: 尽管粗粒度任务表现良好，细粒度AE提取和罕见事件检测仍需改进。该数据集为未来研究提供了基准，支持跨数据集泛化。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE)
extraction from discharge summaries of elderly patients, a population often
underrepresented in clinical NLP resources. The dataset includes 14 clinically
significant AEs-such as falls, delirium, and intracranial haemorrhage, along
with contextual attributes like negation, diagnosis type, and in-hospital
occurrence. Uniquely, the annotation schema supports both discontinuous and
overlapping entities, addressing challenges rarely tackled in prior work. We
evaluate multiple models using FlairNLP across three annotation granularities:
fine-grained, coarse-grained, and coarse-grained with negation. While
transformer-based models (e.g., BERT-cased) achieve strong performance on
document-level coarse-grained extraction (F1 = 0.943), performance drops
notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly
for rare events and complex attributes. These results demonstrate that despite
high-level scores, significant challenges remain in detecting underrepresented
AEs and capturing nuanced clinical language. Developed within a Trusted
Research Environment (TRE), the dataset is available upon request via DataLoch
and serves as a robust benchmark for evaluating AE extraction methods and
supporting future cross-dataset generalisation.

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

Main category: cs.CL

TL;DR: 该研究利用NLP技术从执法和法医叙述中识别社会隔离和孤独感，开发了高质量分类器，并分析了自杀案例中的相关因素。


<details>
  <summary>Details</summary>
Motivation: 社会隔离和孤独感近年增加，与自杀率密切相关，但未被美国国家暴力死亡报告系统记录，因此需要新方法识别。

Method: 使用主题建模生成词典，并结合监督学习分类器，分析2002至2020年30万例自杀案例。

Result: 开发出高质量分类器（F1平均0.86，准确率0.82），识别出1,198例慢性社会隔离案例，男性、同性恋或离婚者风险更高。

Conclusion: 该方法可改进美国社会隔离和孤独感的监测与预防。

Abstract: Social isolation and loneliness, which have been increasing in recent years
strongly contribute toward suicide rates. Although social isolation and
loneliness are not currently recorded within the US National Violent Death
Reporting System's (NVDRS) structured variables, natural language processing
(NLP) techniques can be used to identify these constructs in law enforcement
and coroner medical examiner narratives. Using topic modeling to generate
lexicon development and supervised learning classifiers, we developed
high-quality classifiers (average F1: .86, accuracy: .82). Evaluating over
300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic
social isolation. Decedents had higher odds of chronic social isolation
classification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =
3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).
We found significant predictors for other social isolation topics of recent or
impending divorce, child custody loss, eviction or recent move, and break-up.
Our methods can improve surveillance and prevention of social isolation and
loneliness in the United States.

</details>


### [8] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

Main category: cs.CL

TL;DR: GenRecal是一种通用的视觉语言模型（VLM）蒸馏框架，通过特征对齐和适应实现异构VLM间的知识迁移，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构VLM架构多样性导致的蒸馏困难，使其在资源受限设备上高效部署。

Method: 提出Generation after Recalibration (GenRecal)框架，包含Recalibrator模块，对齐异构VLM的特征表示。

Result: 在多个基准测试中显著提升性能，超越开源和闭源VLM。

Conclusion: GenRecal为异构VLM知识蒸馏提供了一种高效通用解决方案。

Abstract: Recent advancements in vision-language models (VLMs) have leveraged large
language models (LLMs) to achieve performance on par with closed-source systems
like GPT-4V. However, deploying these models in real-world scenarios,
particularly on resource-constrained devices, remains challenging due to their
substantial computational demands. This has spurred interest in distilling
knowledge from large VLMs into smaller, more efficient counterparts. A key
challenge arises here from the diversity of VLM architectures, which are built
on different LLMs and employ varying token types-differing in vocabulary size,
token splits, and token index ordering. To address this challenge of limitation
to a specific VLM type, we present Generation after Recalibration (GenRecal), a
novel, general-purpose distillation framework for VLMs. GenRecal incorporates a
Recalibrator that aligns and adapts feature representations between
heterogeneous VLMs, enabling effective knowledge transfer across different
types of VLMs. Through extensive experiments on multiple challenging
benchmarks, we demonstrate that GenRecal significantly improves baseline
performances, eventually outperforming large-scale open- and closed-source
VLMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [Human Locomotion Implicit Modeling Based Real-Time Gait Phase Estimation](https://arxiv.org/abs/2506.15150)
*Yuanlong Ji,Xingbang Yang,Ruoqi Zhao,Qihan Ye,Quan Zheng,Yubo Fan*

Main category: cs.RO

TL;DR: 提出了一种基于隐式建模的步态相位估计神经网络，结合时间卷积和Transformer层，通过通道掩码重建预训练策略提升模型泛化能力，实验表明其在稳定和地形变化条件下均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于IMU信号的步态相位估计方法在高精度和鲁棒性方面的不足，特别是在地形变化时的性能问题。

Method: 开发了一种结合时间卷积和Transformer层的神经网络，采用通道掩码重建预训练策略，将步态相位状态向量和IMU信号作为联合观测。

Result: 在稳定地形下步态相位RMSE为2.729±1.071%，相位率MAE为0.037±0.016%；地形变化时RMSE为3.215±1.303%，MAE为0.050±0.023%。硬件验证表明算法能可靠识别步态周期和关键事件。

Conclusion: 该方法为更智能和自适应的外骨骼系统提供了基础，提升了人机交互的安全性和效率。

Abstract: Gait phase estimation based on inertial measurement unit (IMU) signals
facilitates precise adaptation of exoskeletons to individual gait variations.
However, challenges remain in achieving high accuracy and robustness,
particularly during periods of terrain changes. To address this, we develop a
gait phase estimation neural network based on implicit modeling of human
locomotion, which combines temporal convolution for feature extraction with
transformer layers for multi-channel information fusion. A channel-wise masked
reconstruction pre-training strategy is proposed, which first treats gait phase
state vectors and IMU signals as joint observations of human locomotion, thus
enhancing model generalization. Experimental results demonstrate that the
proposed method outperforms existing baseline approaches, achieving a gait
phase RMSE of $2.729 \pm 1.071%$ and phase rate MAE of $0.037 \pm 0.016%$ under
stable terrain conditions with a look-back window of 2 seconds, and a phase
RMSE of $3.215 \pm 1.303%$ and rate MAE of $0.050 \pm 0.023%$ under terrain
transitions. Hardware validation on a hip exoskeleton further confirms that the
algorithm can reliably identify gait cycles and key events, adapting to various
continuous motion scenarios. This research paves the way for more intelligent
and adaptive exoskeleton systems, enabling safer and more efficient human-robot
interaction across diverse real-world environments.

</details>
