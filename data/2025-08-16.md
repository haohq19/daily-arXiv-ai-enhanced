<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SynSpill: Improved Industrial Spill Detection With Synthetic Data](https://arxiv.org/abs/2508.10171)
*Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas*

Main category: cs.CV

TL;DR: 论文提出了一种基于合成数据的框架，用于提升大规模视觉语言模型（VLMs）在工业泄漏检测等安全关键领域的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、数据敏感性和事件罕见性，真实数据稀缺，传统微调方法不适用。

Method: 通过高质量合成数据生成管道，结合参数高效微调（PEFT）方法，优化VLMs和目标检测器（如YOLO和DETR）。

Result: 合成数据显著提升了模型性能，使VLMs和检测器在未见泄漏场景中表现接近。

Conclusion: 高保真合成数据是解决安全关键领域数据稀缺问题的有效途径，结合轻量级适配，为工业环境提供了一种经济高效的解决方案。

Abstract: Large-scale Vision-Language Models (VLMs) have transformed general-purpose
visual recognition through strong zero-shot capabilities. However, their
performance degrades significantly in niche, safety-critical domains such as
industrial spill detection, where hazardous events are rare, sensitive, and
difficult to annotate. This scarcity -- driven by privacy concerns, data
sensitivity, and the infrequency of real incidents -- renders conventional
fine-tuning of detectors infeasible for most industrial settings.
  We address this challenge by introducing a scalable framework centered on a
high-quality synthetic data generation pipeline. We demonstrate that this
synthetic corpus enables effective Parameter-Efficient Fine-Tuning (PEFT) of
VLMs and substantially boosts the performance of state-of-the-art object
detectors such as YOLO and DETR. Notably, in the absence of synthetic data
(SynSpill dataset), VLMs still generalize better to unseen spill scenarios than
these detectors. When SynSpill is used, both VLMs and detectors achieve marked
improvements, with their performance becoming comparable.
  Our results underscore that high-fidelity synthetic data is a powerful means
to bridge the domain gap in safety-critical applications. The combination of
synthetic generation and lightweight adaptation offers a cost-effective,
scalable pathway for deploying vision systems in industrial environments where
real data is scarce/impractical to obtain.
  Project Page: https://synspill.vercel.app

</details>


### [2] [STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images](https://arxiv.org/abs/2508.10473)
*Liangrui Pan,xiaoyu Li,Guang Zhu,Guanting Li,Ruixin Wang,Jiadi Luo,Yaning Yang,Liang qingchun,Shaoliang Peng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为STAMP的多模式注意力感知多实例学习框架，用于通过深度学习模型诊断肺腺癌中的空气传播扩散（STAS），并在多中心数据集上取得了优于临床水平的诊断结果。


<details>
  <summary>Details</summary>
Motivation: STAS是肺腺癌中的一种新型侵袭模式，与肿瘤复发和生存率下降相关，但其诊断因病理特征复杂且易被忽视而具有挑战性，亟需深度学习辅助。

Method: 研究收集了多中心病理图像数据集，并开发了STAMP框架，结合双分支架构、Transformer编码和多模式注意力聚合模块，动态选择STAS相关区域并抑制噪声。

Result: STAMP在三个数据集上的AUC分别为0.8058、0.8017和0.7928，优于临床水平。

Conclusion: STAMP框架在STAS诊断中表现出色，为临床提供了一种高效、准确的辅助工具。

Abstract: Spread through air spaces (STAS) constitutes a novel invasive pattern in lung
adenocarcinoma (LUAD), associated with tumor recurrence and diminished survival
rates. However, large-scale STAS diagnosis in LUAD remains a labor-intensive
endeavor, compounded by the propensity for oversight and misdiagnosis due to
its distinctive pathological characteristics and morphological features.
Consequently, there is a pressing clinical imperative to leverage deep learning
models for STAS diagnosis. This study initially assembled histopathological
images from STAS patients at the Second Xiangya Hospital and the Third Xiangya
Hospital of Central South University, alongside the TCGA-LUAD cohort. Three
senior pathologists conducted cross-verification annotations to construct the
STAS-SXY, STAS-TXY, and STAS-TCGA datasets. We then propose a multi-pattern
attention-aware multiple instance learning framework, named STAMP, to analyze
and diagnose the presence of STAS across multi-center histopathology images.
Specifically, the dual-branch architecture guides the model to learn
STAS-associated pathological features from distinct semantic spaces.
Transformer-based instance encoding and a multi-pattern attention aggregation
modules dynamically selects regions closely associated with STAS pathology,
suppressing irrelevant noise and enhancing the discriminative power of global
representations. Moreover, a similarity regularization constraint prevents
feature redundancy across branches, thereby improving overall diagnostic
accuracy. Extensive experiments demonstrated that STAMP achieved competitive
diagnostic results on STAS-SXY, STAS-TXY and STAS-TCGA, with AUCs of 0.8058,
0.8017, and 0.7928, respectively, surpassing the clinical level.

</details>


### [3] [GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images](https://arxiv.org/abs/2508.10542)
*Mengyu Ren,Yutong Li,Hua Li,Runmin Cong,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了一种基于Mamba架构的图增强上下文和区域感知网络（GCRPNet），用于解决光学遥感图像中显著目标检测的挑战，如目标尺度变化大和低对比度问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于ViT和CNN的方法难以有效整合全局和局部特征，限制了性能。GCRPNet旨在通过捕捉长距离依赖和增强区域特征表示来克服这些限制。

Method: 采用视觉状态空间（VSS）编码器提取多尺度特征，设计了差异相似性引导的层次图注意力模块（DS-HGAM）和LEVSS块解码器，结合自适应扫描策略和多粒度协作注意力增强模块（MCAEM）。

Result: 实验结果表明，GCRPNet在显著目标检测任务中达到了最先进的性能。

Conclusion: GCRPNet通过创新的模块设计，有效整合了全局和局部特征，显著提升了检测性能。

Abstract: Salient object detection (SOD) in optical remote sensing images (ORSIs) faces
numerous challenges, including significant variations in target scales and low
contrast between targets and the background. Existing methods based on vision
transformers (ViTs) and convolutional neural networks (CNNs) architectures aim
to leverage both global and local features, but the difficulty in effectively
integrating these heterogeneous features limits their overall performance. To
overcome these limitations, we propose a graph-enhanced contextual and regional
perception network (GCRPNet), which builds upon the Mamba architecture to
simultaneously capture long-range dependencies and enhance regional feature
representation. Specifically, we employ the visual state space (VSS) encoder to
extract multi-scale features. To further achieve deep guidance and enhancement
of these features, we first design a difference-similarity guided hierarchical
graph attention module (DS-HGAM). This module strengthens cross-layer
interaction capabilities between features of different scales while enhancing
the model's structural perception,allowing it to distinguish between foreground
and background more effectively. Then, we design the LEVSS block as the decoder
of GCRPNet. This module integrates our proposed adaptive scanning strategy and
multi-granularity collaborative attention enhancement module (MCAEM). It
performs adaptive patch scanning on feature maps processed via multi-scale
convolutions, thereby capturing rich local region information and enhancing
Mamba's local modeling capability. Extensive experimental results demonstrate
that the proposed model achieves state-of-the-art performance, validating its
effectiveness and superiority.

</details>


### [4] [EvTurb: Event Camera Guided Turbulence Removal](https://arxiv.org/abs/2508.10582)
*Yixing Liu,Minggui Teng,Yifei Xia,Peiqi Duan,Boxin Shi*

Main category: cs.CV

TL;DR: EvTurb提出了一种基于事件流的湍流去除框架，通过两步事件引导网络解耦模糊和倾斜效应，并在真实数据集TurbEvent上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 大气湍流导致图像质量下降，现有方法难以处理其高度不适定问题。

Method: EvTurb利用高速事件流，通过事件积分和方差图两步网络解耦模糊和倾斜效应。

Result: 实验表明EvTurb在性能和计算效率上优于现有方法。

Conclusion: EvTurb为湍流去除提供了高效且有效的解决方案。

Abstract: Atmospheric turbulence degrades image quality by introducing blur and
geometric tilt distortions, posing significant challenges to downstream
computer vision tasks. Existing single-image and multi-frame methods struggle
with the highly ill-posed nature of this problem due to the compositional
complexity of turbulence-induced distortions. To address this, we propose
EvTurb, an event guided turbulence removal framework that leverages high-speed
event streams to decouple blur and tilt effects. EvTurb decouples blur and tilt
effects by modeling event-based turbulence formation, specifically through a
novel two-step event-guided network: event integrals are first employed to
reduce blur in the coarse outputs. This is followed by employing a variance
map, derived from raw event streams, to eliminate the tilt distortion for the
refined outputs. Additionally, we present TurbEvent, the first real-captured
dataset featuring diverse turbulence scenarios. Experimental results
demonstrate that EvTurb surpasses state-of-the-art methods while maintaining
computational efficiency.

</details>


### [5] [Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios](https://arxiv.org/abs/2508.10704)
*Zhanwen Liu,Yujing Sun,Yang Wang,Nan Yang,Shengbo Eben Li,Xiangmo Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种结合事件相机和RGB相机的方法（MCFNet），通过运动线索融合网络解决复杂交通环境中动态范围限制导致的细节丢失问题，显著提升了目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在复杂交通环境（如夜间驾驶、隧道）中动态范围有限，导致全局对比度降低和高频细节丢失，影响目标检测性能。

Method: 提出MCFNet网络，包括事件校正模块（ECM）进行时间对齐，事件动态上采样模块（EDUM）提升空间分辨率，以及跨模态融合模块（CMM）实现自适应特征融合。

Result: 在DSEC-Det和PKU-DAVIS-SOD数据集上，MCFNet显著优于现有方法，mAP50提升7.4%，mAP提升1.7%。

Conclusion: MCFNet通过多模态融合和自适应对齐机制，有效解决了复杂光照条件下的目标检测问题，性能显著提升。

Abstract: The dynamic range limitation of conventional RGB cameras reduces global
contrast and causes loss of high-frequency details such as textures and edges
in complex traffic environments (e.g., nighttime driving, tunnels), hindering
discriminative feature extraction and degrading frame-based object detection.
To address this, we integrate a bio-inspired event camera with an RGB camera to
provide high dynamic range information and propose a motion cue fusion network
(MCFNet), which achieves optimal spatiotemporal alignment and adaptive
cross-modal feature fusion under challenging lighting. Specifically, an event
correction module (ECM) temporally aligns asynchronous event streams with image
frames via optical-flow-based warping, jointly optimized with the detection
network to learn task-aware event representations. The event dynamic upsampling
module (EDUM) enhances spatial resolution of event frames to match image
structures, ensuring precise spatiotemporal alignment. The cross-modal mamba
fusion module (CMM) uses adaptive feature fusion with a novel interlaced
scanning mechanism, effectively integrating complementary information for
robust detection. Experiments conducted on the DSEC-Det and PKU-DAVIS-SOD
datasets demonstrate that MCFNet significantly outperforms existing methods in
various poor lighting and fast moving traffic scenarios. Notably, on the
DSEC-Det dataset, MCFNet achieves a remarkable improvement, surpassing the best
existing methods by 7.4% in mAP50 and 1.7% in mAP metrics, respectively. The
code is available at https://github.com/Charm11492/MCFNet.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study](https://arxiv.org/abs/2508.10233)
*Li Sun,Shuheng Chen,Junyi Fan,Yong Si,Minoo Ahmadi,Elham Pishgar,Kamiar Alaei,Maryam Pishgar*

Main category: cs.LG

TL;DR: 研究开发了一种可解释的机器学习模型，用于早期预测肝硬化重症患者的急性肾损伤（AKI），LightGBM表现最佳。


<details>
  <summary>Details</summary>
Motivation: 肝硬化患者AKI发生率高且预后差，现有预测工具准确性不足且难以与ICU工作流程结合。

Method: 回顾性分析MIMIC-IV数据库，提取48小时内实验室和生理数据，使用多种算法训练并评估。

Result: LightGBM表现最佳（AUROC 0.808），关键预测因子包括部分凝血活酶时间延长、pH值低等。

Conclusion: 该模型能准确预测AKI风险，高阴性预测值支持低风险患者安全降级，需进一步外部验证。

Abstract: Background: Cirrhosis is a progressive liver disease with high mortality and
frequent complications, notably acute kidney injury (AKI), which occurs in up
to 50% of hospitalized patients and worsens outcomes. AKI stems from complex
hemodynamic, inflammatory, and metabolic changes, making early detection
essential. Many predictive tools lack accuracy, interpretability, and alignment
with intensive care unit (ICU) workflows. This study developed an interpretable
machine learning model for early AKI prediction in critically ill patients with
cirrhosis.
  Methods: We conducted a retrospective analysis of the MIMIC-IV v2.2 database,
identifying 1240 adult ICU patients with cirrhosis and excluding those with ICU
stays under 48 hours or missing key data. Laboratory and physiological
variables from the first 48 hours were extracted. The pipeline included
preprocessing, missingness filtering, LASSO feature selection, and SMOTE class
balancing. Six algorithms-LightGBM, CatBoost, XGBoost, logistic regression,
naive Bayes, and neural networks-were trained and evaluated using AUROC,
accuracy, F1-score, sensitivity, specificity, and predictive values.
  Results: LightGBM achieved the best performance (AUROC 0.808, 95% CI
0.741-0.856; accuracy 0.704; NPV 0.911). Key predictors included prolonged
partial thromboplastin time, absence of outside-facility 20G placement, low pH,
and altered pO2, consistent with known cirrhosis-AKI mechanisms and suggesting
actionable targets.
  Conclusion: The LightGBM-based model enables accurate early AKI risk
stratification in ICU patients with cirrhosis using routine clinical variables.
Its high negative predictive value supports safe de-escalation for low-risk
patients, and interpretability fosters clinician trust and targeted prevention.
External validation and integration into electronic health record systems are
warranted.

</details>


### [7] [GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation](https://arxiv.org/abs/2508.10471)
*Xinrui Li,Qilin Fan,Tianfu Wang,Kaiwen Wei,Ke Yu,Xu Zhang*

Main category: cs.LG

TL;DR: GraphFedMIG是一个新的联邦图学习框架，通过生成对抗网络和互信息引导机制解决非独立同分布数据中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 联邦图学习（FGL）中，非独立同分布数据分布和类别不平衡会严重损害模型性能，尤其是少数类别的识别能力。

Method: 提出GraphFedMIG框架，采用分层生成对抗网络，客户端训练本地生成器合成特征表示，并通过互信息引导机制优化生成器参数。

Result: 在四个真实数据集上的实验表明，GraphFedMIG优于其他基线方法。

Conclusion: GraphFedMIG有效解决了FGL中的类别不平衡问题，提升了模型对少数类别的识别能力。

Abstract: Federated graph learning (FGL) enables multiple clients to collaboratively
train powerful graph neural networks without sharing their private,
decentralized graph data. Inherited from generic federated learning, FGL is
critically challenged by statistical heterogeneity, where non-IID data
distributions across clients can severely impair model performance. A
particularly destructive form of this is class imbalance, which causes the
global model to become biased towards majority classes and fail at identifying
rare but critical events. This issue is exacerbated in FGL, as nodes from a
minority class are often surrounded by biased neighborhood information,
hindering the learning of expressive embeddings. To grapple with this
challenge, we propose GraphFedMIG, a novel FGL framework that reframes the
problem as a federated generative data augmentation task. GraphFedMIG employs a
hierarchical generative adversarial network where each client trains a local
generator to synthesize high-fidelity feature representations. To provide
tailored supervision, clients are grouped into clusters, each sharing a
dedicated discriminator. Crucially, the framework designs a mutual
information-guided mechanism to steer the evolution of these client generators.
By calculating each client's unique informational value, this mechanism
corrects the local generator parameters, ensuring that subsequent rounds of
mutual information-guided generation are focused on producing high-value,
minority-class features. We conduct extensive experiments on four real-world
datasets, and the results demonstrate the superiority of the proposed
GraphFedMIG compared with other baselines.

</details>


### [8] [REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations](https://arxiv.org/abs/2508.10701)
*Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang*

Main category: cs.LG

TL;DR: REFN利用强化学习训练大型语言模型（LLM）自动生成网络过滤器，以应对1天或N天漏洞，解决了现有防御措施的扩展性、兼容性和部署问题。


<details>
  <summary>Details</summary>
Motivation: 现有防御措施（如主机补丁和网络过滤）因扩展性、兼容性和部署问题不足，无法有效应对大规模部署设备和延迟修补的威胁。

Method: REFN通过强化学习驱动在线网络奖励（而非人工反馈）训练LLM，结合边缘安全网关统一部署和在线验证，解决了LLM在漏洞修复中的知识、语言转换和幻觉问题。

Result: 在22类1天或N天漏洞测试中，REFN表现出高效（修补时间3.65小时）、高准确率（比替代方案高21.1%）和强扩展性（支持10K设备）。

Conclusion: REFN是训练LLM快速预防大规模漏洞利用的初步成果，展示了其潜力。

Abstract: The exploitation of 1 day or n day vulnerabilities poses severe threats to
networked devices due to massive deployment scales and delayed patching
(average Mean Time To Patch exceeds 60 days). Existing defenses, including host
based patching and network based filtering, are inadequate due to limited
scalability across diverse devices, compatibility issues especially with
embedded or legacy systems, and error prone deployment process (manual patch
validation). To address these issues, we introduce REFN (Reinforcement Learning
From Network), a novel framework that trains Large Language Models (LLMs) to
autonomously generate network filters to prevent 1 day or n day exploitations.
REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven
by online network rewards instead of traditional Human Feedback (RLHF). REFN
guarantees compatibility via unified deployment on edge security gateways
(Amazon Eero). REFN provides robustness via online validation using real
network traffic. Crucially, REFN addresses three core challenges in training
LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability
fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging
current LLMs language to network gaps through an RL From VNF Pipeline that
translates language context (vulnerability description) into network
enforcement, 3) addressing the LLM hallucination and non determinism via the
Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22
families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1
percent higher accuracy than alternatives), efficiency (Mean Time To Patch of
3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an
initial step toward training LLMs to rapidly prevent massive scale 1 day or n
day exploitations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence](https://arxiv.org/abs/2508.10241)
*Mark Zilberman*

Main category: cs.AI

TL;DR: 论文提出了一种基于事件熵势的概念，用于增强AI中的不确定性量化、决策和可解释性，并探讨了其在多个AI应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 通过引入事件熵势的概念，量化离散事件对系统未来熵的影响，以提升AI系统的不确定性建模能力。

Method: 将物理学中的熵势概念调整到AI领域，提出事件中心化的度量方法，并形式化定义，强调条件期望以考虑反事实场景。

Result: 在策略评估、内在奖励设计、可解释AI和异常检测等应用中展示了熵势框架的潜力。

Conclusion: 熵势框架为AI中的不确定性管理提供了一种理论扎实、可解释且多功能的方法，融合了热力学、信息论和机器学习的原理。

Abstract: This work demonstrates how the concept of the entropic potential of events --
a parameter quantifying the influence of discrete events on the expected future
entropy of a system -- can enhance uncertainty quantification, decision-making,
and interpretability in artificial intelligence (AI). Building on its original
formulation in physics, the framework is adapted for AI by introducing an
event-centric measure that captures how actions, observations, or other
discrete occurrences impact uncertainty at future time horizons. Both the
original and AI-adjusted definitions of entropic potential are formalized, with
the latter emphasizing conditional expectations to account for counterfactual
scenarios. Applications are explored in policy evaluation, intrinsic reward
design, explainable AI, and anomaly detection, highlighting the metric's
potential to unify and strengthen uncertainty modeling in intelligent systems.
Conceptual examples illustrate its use in reinforcement learning, Bayesian
inference, and anomaly detection, while practical considerations for
computation in complex AI models are discussed. The entropic potential
framework offers a theoretically grounded, interpretable, and versatile
approach to managing uncertainty in AI, bridging principles from
thermodynamics, information theory, and machine learning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [10] [XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs](https://arxiv.org/abs/2508.09999)
*Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang*

Main category: cs.CL

TL;DR: 论文提出XFacta数据集，用于评估基于多模态大语言模型（MLLM）的虚假信息检测方法，并分析了现有方法的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有数据集过时或人工合成，无法反映真实虚假信息模式，且缺乏对MLLM模型设计的系统分析。

Method: 引入XFacta数据集，评估多种MLLM检测策略，并提出半自动检测框架以保持数据集的时效性。

Result: 提供了对MLLM虚假信息检测的深入分析，并发布了代码和数据。

Conclusion: XFacta和半自动框架为多模态虚假信息检测领域提供了有价值的实践和见解。

Abstract: The rapid spread of multimodal misinformation on social media calls for more
effective and robust detection methods. Recent advances leveraging multimodal
large language models (MLLMs) have shown the potential in addressing this
challenge. However, it remains unclear exactly where the bottleneck of existing
approaches lies (evidence retrieval v.s. reasoning), hindering the further
advances in this field. On the dataset side, existing benchmarks either contain
outdated events, leading to evaluation bias due to discrepancies with
contemporary social media scenarios as MLLMs can simply memorize these events,
or artificially synthetic, failing to reflect real-world misinformation
patterns. Additionally, it lacks comprehensive analyses of MLLM-based model
design strategies. To address these issues, we introduce XFacta, a
contemporary, real-world dataset that is better suited for evaluating
MLLM-based detectors. We systematically evaluate various MLLM-based
misinformation detection strategies, assessing models across different
architectures and scales, as well as benchmarking against existing detection
methods. Building on these analyses, we further enable a semi-automatic
detection-in-the-loop framework that continuously updates XFacta with new
content to maintain its contemporary relevance. Our analysis provides valuable
insights and practices for advancing the field of multimodal misinformation
detection. The code and data have been released.

</details>


### [11] [An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs](https://arxiv.org/abs/2508.10010)
*Ayana Hussain,Patrick Zhao,Nicholas Vincent*

Main category: cs.CL

TL;DR: 论文研究了LLM生成的越狱攻击对医疗错误信息的产生及其检测效果，发现LLM可用于检测错误信息。


<details>
  <summary>Details</summary>
Motivation: LLM既能生成有害错误信息，也能用于检测和防止其传播，研究旨在探索其双重作用。

Method: 分析了109种针对三种目标LLM的越狱攻击，比较攻击提示与真实健康查询，并对比生成的错误信息与Reddit上的健康错误信息。

Result: LLM能有效检测来自其他LLM和人类的错误信息，支持其在健康信息生态中的积极作用。

Conclusion: 通过精心设计，LLM可促进更健康的信息生态系统。

Abstract: Large Language Models (LLMs) are a double-edged sword capable of generating
harmful misinformation -- inadvertently, or when prompted by "jailbreak"
attacks that attempt to produce malicious outputs. LLMs could, with additional
research, be used to detect and prevent the spread of misinformation. In this
paper, we investigate the efficacy and characteristics of LLM-produced
jailbreak attacks that cause other models to produce harmful medical
misinformation. We also study how misinformation generated by jailbroken LLMs
compares to typical misinformation found on social media, and how effectively
it can be detected using standard machine learning approaches. Specifically, we
closely examine 109 distinct attacks against three target LLMs and compare the
attack prompts to in-the-wild health-related LLM queries. We also examine the
resulting jailbreak responses, comparing the generated misinformation to
health-related misinformation on Reddit. Our findings add more evidence that
LLMs can be effectively used to detect misinformation from both other LLMs and
from people, and support a body of work suggesting that with careful design,
LLMs can contribute to a healthier overall information ecosystem.

</details>


### [12] [LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients](https://arxiv.org/abs/2508.10021)
*Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko*

Main category: cs.CL

TL;DR: 提出LATTE框架，通过对比学习将原始事件嵌入与冻结LLM的语义嵌入对齐，显著降低推理成本和输入大小。


<details>
  <summary>Details</summary>
Motivation: 直接使用LLM处理长事件序列计算成本高且不实用，需高效方法学习客户历史通信的嵌入表示。

Method: LATTE框架利用对比学习，将行为特征总结为短提示，通过LLM嵌入并作为监督信号。

Result: 在真实金融数据集上优于现有技术，同时适用于延迟敏感环境。

Conclusion: LATTE是一种高效且实用的方法，适用于金融应用中的事件序列表示学习。

Abstract: Learning clients embeddings from sequences of their historic communications
is central to financial applications. While large language models (LLMs) offer
general world knowledge, their direct use on long event sequences is
computationally expensive and impractical in real-world pipelines. In this
paper, we propose LATTE, a contrastive learning framework that aligns raw event
embeddings with semantic embeddings from frozen LLMs. Behavioral features are
summarized into short prompts, embedded by the LLM, and used as supervision via
contrastive loss. The proposed approach significantly reduces inference cost
and input size compared to conventional processing of complete sequence by LLM.
We experimentally show that our method outperforms state-of-the-art techniques
for learning event sequence representations on real-world financial datasets
while remaining deployable in latency-sensitive environments.

</details>


### [13] [Detecting and explaining postpartum depression in real-time with generative artificial intelligence](https://arxiv.org/abs/2508.10025)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.CL

TL;DR: 该论文提出了一种结合自然语言处理、机器学习和大型语言模型的智能产后抑郁症筛查系统，旨在实现实时、非侵入性的免费语音分析，并解决黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 产后抑郁症（PPD）严重影响母亲的身心健康，快速检测PPD及其相关风险因素对及时干预至关重要。

Method: 结合自然语言处理、机器学习和大型语言模型，利用可解释的树基算法和特征重要性进行预测。

Result: 在所有评估指标上达到90%的PPD检测准确率，优于现有解决方案。

Conclusion: 该解决方案有助于快速检测PPD及其风险因素，为及时干预提供了技术支持。

Abstract: Among the many challenges mothers undergo after childbirth, postpartum
depression (PPD) is a severe condition that significantly impacts their mental
and physical well-being. Consequently, the rapid detection of ppd and their
associated risk factors is critical for in-time assessment and intervention
through specialized prevention procedures. Accordingly, this work addresses the
need to help practitioners make decisions with the latest technological
advancements to enable real-time screening and treatment recommendations.
Mainly, our work contributes to an intelligent PPD screening system that
combines Natural Language Processing, Machine Learning (ML), and Large Language
Models (LLMs) towards an affordable, real-time, and non-invasive free speech
analysis. Moreover, it addresses the black box problem since the predictions
are described to the end users thanks to the combination of LLMs with
interpretable ml models (i.e., tree-based algorithms) using feature importance
and natural language. The results obtained are 90 % on ppd detection for all
evaluation metrics, outperforming the competing solutions in the literature.
Ultimately, our solution contributes to the rapid detection of PPD and their
associated risk factors, critical for in-time and proper assessment and
intervention.

</details>


### [14] [Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models](https://arxiv.org/abs/2508.10192)
*Igor Halperin*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The proliferation of Large Language Models (LLMs) is challenged by
hallucinations, critical failure modes where models generate non-factual,
nonsensical or unfaithful text. This paper introduces Semantic Divergence
Metrics (SDM), a novel lightweight framework for detecting Faithfulness
Hallucinations -- events of severe deviations of LLMs responses from input
contexts. We focus on a specific implementation of these LLM errors,
{confabulations, defined as responses that are arbitrary and semantically
misaligned with the user's query. Existing methods like Semantic Entropy test
for arbitrariness by measuring the diversity of answers to a single, fixed
prompt. Our SDM framework improves upon this by being more prompt-aware: we
test for a deeper form of arbitrariness by measuring response consistency not
only across multiple answers but also across multiple, semantically-equivalent
paraphrases of the original prompt. Methodologically, our approach uses joint
clustering on sentence embeddings to create a shared topic space for prompts
and answers. A heatmap of topic co-occurances between prompts and responses can
be viewed as a quantified two-dimensional visualization of the user-machine
dialogue. We then compute a suite of information-theoretic metrics to measure
the semantic divergence between prompts and responses. Our practical score,
$\mathcal{S}_H$, combines the Jensen-Shannon divergence and Wasserstein
distance to quantify this divergence, with a high score indicating a
Faithfulness hallucination. Furthermore, we identify the KL divergence
KL(Answer $||$ Prompt) as a powerful indicator of \textbf{Semantic
Exploration}, a key signal for distinguishing different generative behaviors.
These metrics are further combined into the Semantic Box, a diagnostic
framework for classifying LLM response types, including the dangerous,
confident confabulation.

</details>
