<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 14]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs](https://arxiv.org/abs/2601.20911)
*Haochen Zhang,Animesh Sinha,Felix Juefei-Xu,Haoyu Ma,Kunpeng Li,Zhipeng Fan,Meng Dong,Xiaoliang Dai,Tingbo Hou,Peizhao Zhang,Zecheng He*

Main category: cs.CV

TL;DR: 该论文针对对话式图像生成中的非马尔可夫挑战，提出数据构造、训练框架和优化方法，显著提升多轮一致性和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在对话式图像生成中大多采用马尔可夫方法，仅依赖最近图像而忽略长期历史，无法处理用户回溯早期状态、撤销更改或引用多轮前实体的复杂交互需求。

Method: 提出三部分方法：(1)非马尔可夫多轮数据构造策略，包括回滚式编辑和基于名称的多轮个性化；(2)历史条件训练和推理框架，采用令牌级缓存防止多轮身份漂移；(3)高保真图像重建和可编辑个性化优化，包括重建式DiT解令牌器和多阶段微调课程。

Result: 实验表明，针对非马尔可夫交互的显式训练显著提升了多轮一致性和指令遵循能力，同时保持了强大的单轮编辑和个性化性能。

Conclusion: 该工作形式化并解决了对话式图像生成中的非马尔可夫挑战，通过系统性方法实现了更自然、一致的多轮交互，为复杂对话式图像生成任务提供了有效解决方案。

Abstract: Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.

</details>


### [2] [LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220)
*Alvi Md Ishmam,Najibul Haque Sarker,Zaber Ibn Abdul Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: LAMP：针对多图像多模态大语言模型的黑盒通用对抗扰动攻击方法，通过注意力约束和跨图像传染机制实现高效攻击


<details>
  <summary>Details</summary>
Motivation: 多图像MLLMs在视觉语言任务中表现出色，但其安全漏洞尚未被充分研究。现有对抗攻击主要针对单图像场景且多为白盒攻击，在实际应用中不实用，需要开发针对多图像MLLMs的黑盒攻击方法

Method: LAMP采用黑盒方法学习通用对抗扰动，包含三个核心组件：1)基于注意力的约束防止模型有效聚合多图像信息；2)跨图像传染约束使扰动token影响干净token，无需修改所有输入；3)索引注意力抑制损失实现位置不变的鲁棒攻击

Result: 实验结果表明，LAMP在多个视觉语言任务和模型上超越了现有最佳基线方法，实现了最高的攻击成功率

Conclusion: LAMP成功揭示了多图像MLLMs的安全漏洞，为黑盒场景下的对抗攻击提供了有效解决方案，其跨图像传染机制和位置不变攻击策略具有创新性

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.

</details>


### [3] [Hypersolid: Emergent Vision Representations via Short-Range Repulsion](https://arxiv.org/abs/2601.21255)
*Esteban Rodríguez-Betancourt,Edgar Casasola-Murillo*

Main category: cs.CV

TL;DR: Hypersolid是一种自监督学习方法，将表示学习重新解释为离散打包问题，使用短程硬球排斥防止局部碰撞，从而避免表示崩溃


<details>
  <summary>Details</summary>
Motivation: 自监督学习中防止表示崩溃是一个持续挑战，现有方法通常依赖全局正则化，如最大化距离、去相关维度或强制特定分布。本文提出从不同角度解决这个问题

Method: 将表示学习重新解释为离散打包问题，保持信息简化为保持单射性。Hypersolid方法使用短程硬球排斥来防止局部碰撞，形成高分离几何机制

Result: 该方法能够保持增强多样性，在细粒度和低分辨率分类任务上表现出色

Conclusion: 通过将表示学习视为离散打包问题并使用局部排斥约束，Hypersolid提供了一种避免表示崩溃的有效方法，特别适用于需要保持细微差异的任务

Abstract: A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.

</details>


### [4] [Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21345)
*Ruiqi Liu,Boyu Diao,Zijia An,Runjie Shao,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: SGDS通过语义引导的动态稀疏化，在激活空间中塑造类特定稀疏子空间，解决CIL中参数正交约束损害可塑性的问题，实现知识转移与干扰预防的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的CIL方法通常冻结预训练模型并使用轻量适配器，通过参数正交约束防止任务间干扰，但这种方法会损害模型的可塑性。需要一种既能防止干扰又不限制参数空间的方法。

Method: 提出语义引导的动态稀疏化(SGDS)，通过定向稀疏化控制激活空间子空间的方向和秩。鼓励相似类共享紧凑的激活子空间以促进知识转移，同时为不相似类分配不重叠的激活子空间以防止干扰。

Result: 在多个基准数据集上的广泛实验表明，SGDS取得了最先进的性能表现。

Conclusion: SGDS通过在激活空间中塑造类特定稀疏子空间，有效缓解了干扰问题，同时避免了参数空间的刚性约束，为CIL提供了一种更灵活有效的解决方案。

Abstract: Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [TwinWeaver: An LLM-Based Foundation Model Framework for Pan-Cancer Digital Twins](https://arxiv.org/abs/2601.20906)
*Nikita Makarov,Maria Bordukova,Lena Voith von Voithenberg,Estrella Pivel-Villanueva,Sabrina Mielke,Jonathan Wickes,Hanchen Wang,Mingyu Derek Ma,Keunwoo Choi,Kyunghyun Cho,Stephen Ra,Raul Rodriguez-Esteban,Fabian Schmich,Michael Menden*

Main category: cs.LG

TL;DR: TwinWeaver框架将患者纵向病史序列化为文本，使大语言模型能统一预测临床事件，在93,054名癌症患者数据上构建的GDT模型显著优于传统时间序列方法。


<details>
  <summary>Details</summary>
Motivation: 精准肿瘤学需要预测临床事件和轨迹，但建模稀疏、多模态的临床时间序列仍然是一个关键挑战。

Method: 提出TwinWeaver开源框架，将纵向患者病史序列化为文本，使大语言模型能进行统一事件预测和预测，并在93,054名20种癌症类型患者数据上构建Genie Digital Twin (GDT)模型。

Result: GDT显著降低预测误差（中位MASE 0.87 vs 基线0.97），改善风险分层（平均C-index 0.703 vs 基线0.662），在分布外临床试验中表现优异（中位MASE 0.75-0.88，平均C-index 0.672 vs 基线0.648）。

Conclusion: TwinWeaver为纵向临床建模提供了可扩展和透明的基础，支持可解释的临床推理扩展，在精准肿瘤学预测任务中表现出色。

Abstract: Precision oncology requires forecasting clinical events and trajectories, yet modeling sparse, multi-modal clinical time series remains a critical challenge. We introduce TwinWeaver, an open-source framework that serializes longitudinal patient histories into text, enabling unified event prediction as well as forecasting with large language models, and use it to build Genie Digital Twin (GDT) on 93,054 patients across 20 cancer types. In benchmarks, GDT significantly reduces forecasting error, achieving a median Mean Absolute Scaled Error (MASE) of 0.87 compared to 0.97 for the strongest time-series baseline (p<0.001). Furthermore, GDT improves risk stratification, achieving an average concordance index (C-index) of 0.703 across survival, progression, and therapy switching tasks, surpassing the best baseline of 0.662. GDT also generalizes to out-of-distribution clinical trials, matching trained baselines at zero-shot and surpassing them with fine-tuning, achieving a median MASE of 0.75-0.88 and outperforming the strongest baseline in event prediction with an average C-index of 0.672 versus 0.648. Finally, TwinWeaver enables an interpretable clinical reasoning extension, providing a scalable and transparent foundation for longitudinal clinical modeling.

</details>


### [6] [Pre-trained Encoders for Global Child Development: Transfer Learning Enables Deployment in Data-Scarce Settings](https://arxiv.org/abs/2601.20987)
*Md Muhtasim Munif Fahim,Md Rezaul Karim*

Main category: cs.LG

TL;DR: 开发首个全球儿童发育预训练编码器，使用UNICEF 44国35.7万儿童数据训练，仅需50个样本即可实现0.65 AUC，显著优于冷启动方法，为资源受限环境下的儿童发育监测提供可行ML方案。


<details>
  <summary>Details</summary>
Motivation: 每年大量儿童经历可预防的发育迟缓，但机器学习在新国家的部署面临数据瓶颈：可靠模型需要数千样本，而新项目开始时通常少于100个样本。

Method: 使用UNICEF调查数据，在44个国家357,709名儿童上训练首个全球儿童发育预训练编码器，采用迁移学习框架，应用迁移学习边界理论解释预训练多样性的作用。

Result: 仅需50个训练样本，预训练编码器平均AUC达0.65（95% CI: 0.56-0.72），比冷启动梯度提升的0.61高8-12%；500个样本时AUC达0.73；零样本部署到未见国家AUC最高达0.84。

Conclusion: 预训练编码器可以改变资源受限环境下监测可持续发展目标4.2.1（儿童发育）的机器学习可行性，预训练多样性支持少样本泛化。

Abstract: A large number of children experience preventable developmental delays each year, yet the deployment of machine learning in new countries has been stymied by a data bottleneck: reliable models require thousands of samples, while new programs begin with fewer than 100. We introduce the first pre-trained encoder for global child development, trained on 357,709 children across 44 countries using UNICEF survey data. With only 50 training samples, the pre-trained encoder achieves an average AUC of 0.65 (95% CI: 0.56-0.72), outperforming cold-start gradient boosting at 0.61 by 8-12% across regions. At N=500, the encoder achieves an AUC of 0.73. Zero-shot deployment to unseen countries achieves AUCs up to 0.84. We apply a transfer learning bound to explain why pre-training diversity enables few-shot generalization. These results establish that pre-trained encoders can transform the feasibility of ML for SDG 4.2.1 monitoring in resource-constrained settings.

</details>


### [7] [SIGMA-PPG: Statistical-prior Informed Generative Masking Architecture for PPG Foundation Model](https://arxiv.org/abs/2601.21031)
*Zongheng Guo,Tao Chen,Yang Jiao,Yi Pan,Xiao Hu,Manuela Ferrario*

Main category: cs.LG

TL;DR: SIGMA-PPG：一种基于统计先验的生成式掩码架构，通过强化学习驱动的教师模型和语义一致性约束，解决了PPG信号内在冗余和噪声问题，在12个下游任务中超越5个SOTA基线。


<details>
  <summary>Details</summary>
Motivation: 当前PPG信号基础模型面临信号内在冗余和噪声的挑战。标准掩码建模容易产生平凡解，而对比学习方法缺乏形态学精度。需要一种能有效处理PPG信号特性并提高下游任务性能的方法。

Method: 提出SIGMA-PPG（统计先验引导的生成式掩码架构），包含：1）先验引导的对抗掩码机制，使用强化学习驱动的教师模型利用统计先验创建具有挑战性的学习路径；2）通过向量量化的语义一致性约束，确保生理相同的波形映射到共享索引，提高码本语义密度并消除冗余特征结构。

Result: 在超过120,000小时数据上预训练后，SIGMA-PPG在12个多样化下游任务中平均性能优于5个最先进的基线方法。

Conclusion: SIGMA-PPG通过结合统计先验引导的对抗掩码和语义一致性约束，有效解决了PPG信号建模中的冗余和噪声问题，为PPG基础模型提供了新的解决方案。

Abstract: Current foundation model for photoplethysmography (PPG) signals is challenged by the intrinsic redundancy and noise of the signal. Standard masked modeling often yields trivial solutions while contrastive methods lack morphological precision. To address these limitations, we propose a Statistical-prior Informed Generative Masking Architecture (SIGMA-PPG), a generative foundation model featuring a Prior-Guided Adversarial Masking mechanism, where a reinforcement learning-driven teacher leverages statistical priors to create challenging learning paths that prevent overfitting to noise. We also incorporate a semantic consistency constraint via vector quantization to ensure that physiologically identical waveforms (even those altered by recording artifacts or minor perturbations) map to shared indices. This enhances codebook semantic density and eliminates redundant feature structures. Pre-trained on over 120,000 hours of data, SIGMA-PPG achieves superior average performance compared to five state-of-the-art baselines across 12 diverse downstream tasks. The code is available at https://github.com/ZonghengGuo/SigmaPPG.

</details>


### [8] [Smooth Dynamic Cutoffs for Machine Learning Interatomic Potentials](https://arxiv.org/abs/2601.21147)
*Kevin Han,Haolin Cong,Bowen Deng,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 提出动态截断半径方法，通过控制每个原子的邻居数量来优化机器学习原子间势能模型，显著减少内存消耗和推理时间，同时保持模拟稳定性。


<details>
  <summary>Details</summary>
Motivation: 机器学习原子间势能模型在分子动力学模拟中应用广泛，但面临推理时间和内存消耗两大瓶颈。传统固定截断半径方法限制了模型的实际应用规模，需要新的优化方案。

Method: 挑战传统固定截断半径的假设，首次引入动态截断半径公式，通过控制每个原子的目标邻居数量来诱导原子图的稀疏性，在保持模拟稳定性的同时减少计算资源需求。

Result: 在MACE、Nequip、Orbv3和TensorNet四种先进模型上实现动态截断，平均减少2.26倍内存消耗和2.04倍推理时间，在材料和分子数据集上精度损失最小。

Conclusion: 动态截断半径方法有效解决了MLIPs的计算瓶颈，实现了更高效的大规模分子动力学模拟，所有模型实现和训练代码将开源。

Abstract: Machine learning interatomic potentials (MLIPs) have proven to be wildly useful for molecular dynamics simulations, powering countless drug and materials discovery applications. However, MLIPs face two primary bottlenecks preventing them from reaching realistic simulation scales: inference time and memory consumption. In this work, we address both issues by challenging the long-held belief that the cutoff radius for the MLIP must be held to a fixed, constant value. For the first time, we introduce a dynamic cutoff formulation that still leads to stable, long timescale molecular dynamics simulation. In introducing the dynamic cutoff, we are able to induce sparsity onto the underlying atom graph by targeting a specific number of neighbors per atom, significantly reducing both memory consumption and inference time. We show the effectiveness of a dynamic cutoff by implementing it onto 4 state of the art MLIPs: MACE, Nequip, Orbv3, and TensorNet, leading to 2.26x less memory consumption and 2.04x faster inference time, depending on the model and atomic system. We also perform an extensive error analysis and find that the dynamic cutoff models exhibit minimal accuracy dropoff compared to their fixed cutoff counterparts on both materials and molecular datasets. All model implementations and training code will be fully open sourced.

</details>


### [9] [The Powers of Precision: Structure-Informed Detection in Complex Systems -- From Customer Churn to Seizure Onset](https://arxiv.org/abs/2601.21170)
*Augusto Santos,Teresa Santos,Catarina Rodrigues,José M. F. Moura*

Main category: cs.LG

TL;DR: 提出一种基于协方差矩阵幂次变换的机器学习方法，用于复杂系统中涌现现象的早期检测，通过优化特征表示来揭示潜在的因果结构。


<details>
  <summary>Details</summary>
Motivation: 复杂系统中的涌现现象（如癫痫发作、客户流失、疫情爆发）通常源于隐藏的因果相互作用。核心挑战在于：在数据生成过程未知且部分可观测的情况下，揭示和利用系统的潜在因果结构。

Method: 方法包含两个模块：1）从单参数估计器族（经验协方差或精度矩阵的幂次）中学习最优特征表示，以调整到底层结构；2）监督学习模块对学习到的表示进行分类。证明了该族的结构一致性。

Result: 在癫痫发作检测和客户流失预测任务中取得了有竞争力的结果。最优协方差幂次显示出良好的可识别性，同时捕获了结构特征，实现了预测性能与可解释统计结构的统一。

Conclusion: 该方法不仅能有效预测涌现现象，还能提供可解释的统计结构，在预测性能和可解释性之间取得了平衡，为复杂系统中关键事件的早期检测提供了新途径。

Abstract: Emergent phenomena -- onset of epileptic seizures, sudden customer churn, or pandemic outbreaks -- often arise from hidden causal interactions in complex systems. We propose a machine learning method for their early detection that addresses a core challenge: unveiling and harnessing a system's latent causal structure despite the data-generating process being unknown and partially observed. The method learns an optimal feature representation from a one-parameter family of estimators -- powers of the empirical covariance or precision matrix -- offering a principled way to tune in to the underlying structure driving the emergence of critical events. A supervised learning module then classifies the learned representation. We prove structural consistency of the family and demonstrate the empirical soundness of our approach on seizure detection and churn prediction, attaining competitive results in both. Beyond prediction, and toward explainability, we ascertain that the optimal covariance power exhibits evidence of good identifiability while capturing structural signatures, thus reconciling predictive performance with interpretable statistical structure.

</details>


### [10] [Physics-Guided Tiny-Mamba Transformer for Reliability-Aware Early Fault Warning](https://arxiv.org/abs/2601.21293)
*Changyu Li,Dingcheng Huang,Kexuan Yao,Xiaoya Ni,Lijuan Shen,Fei Luo*

Main category: cs.LG

TL;DR: PG-TMT：一种用于旋转机械可靠性预测的物理引导微型Mamba Transformer，通过三分支编码器、物理对齐的注意力谱分析和极值理论校准的决策规则，实现跨域、不平衡条件下的早期故障预警。


<details>
  <summary>Details</summary>
Motivation: 旋转机械的可靠性预测需要在非平稳工况、跨域（速度/负载/传感器）偏移和严重类别不平衡条件下，提供准确且误报率可控的早期预警信号。

Method: 提出物理引导的微型Mamba Transformer（PG-TMT），包含三个分支：深度可分离卷积主干捕捉微瞬变、Tiny-Mamba状态空间分支建模近线性长程动态、轻量级局部Transformer编码跨通道共振。通过解析的时频映射将注意力谱与经典轴承故障阶次带对齐，并使用极值理论建模健康分数超限，结合双阈值滞环抑制误报。

Result: 在CWRU、Paderborn、XJTU-SY和工业试点数据集上，PG-TMT在无泄漏流式协议下，取得了更高的精确率-召回率AUC（主要针对不平衡问题）、竞争性或更好的ROC AUC、更短的检测平均时间（在相同误报强度下），并展现出强大的跨域迁移能力。

Conclusion: 通过将物理对齐的表征与极值理论校准的决策规则相结合，PG-TMT为以可靠性为中心的预测和健康管理提供了可校准、可解释且可部署的早期预警解决方案。

Abstract: Reliability-centered prognostics for rotating machinery requires early warning signals that remain accurate under nonstationary operating conditions, domain shifts across speed/load/sensors, and severe class imbalance, while keeping the false-alarm rate small and predictable. We propose the Physics-Guided Tiny-Mamba Transformer (PG-TMT), a compact tri-branch encoder tailored for online condition monitoring. A depthwise-separable convolutional stem captures micro-transients, a Tiny-Mamba state-space branch models near-linear long-range dynamics, and a lightweight local Transformer encodes cross-channel resonances. We derive an analytic temporal-to-spectral mapping that ties the model's attention spectrum to classical bearing fault-order bands, yielding a band-alignment score that quantifies physical plausibility and provides physics-grounded explanations. To ensure decision reliability, healthy-score exceedances are modeled with extreme-value theory (EVT), which yields an on-threshold achieving a target false-alarm intensity (events/hour); a dual-threshold hysteresis with a minimum hold time further suppresses chatter. Under a leakage-free streaming protocol with right-censoring of missed detections on CWRU, Paderborn, XJTU-SY, and an industrial pilot, PG-TMT attains higher precision-recall AUC (primary under imbalance), competitive or better ROC AUC, and shorter mean time-to-detect at matched false-alarm intensity, together with strong cross-domain transfer. By coupling physics-aligned representations with EVT-calibrated decision rules, PG-TMT delivers calibrated, interpretable, and deployment-ready early warnings for reliability-centric prognostics and health management.

</details>


### [11] [Few-Shot Learning for Dynamic Operations of Automated Electric Taxi Fleets under Evolving Charging Infrastructure: A Meta-Deep Reinforcement Learning Approach](https://arxiv.org/abs/2601.21312)
*Xiaozhuang Li,Xindi Tang,Fang He*

Main category: cs.LG

TL;DR: 提出GAT-PEARL框架，结合图注意力网络和概率嵌入强化学习，解决动态充电网络下自动驾驶电动出租车车队管理问题，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车和充电基础设施快速发展，自动驾驶电动出租车车队在动态不确定充电环境下面临管理挑战。现有研究大多假设静态充电网络，这与现实运营存在显著差距。

Method: 提出GAT-PEARL元强化学习框架：1) 使用图注意力网络提取稳健的空间表示并建模复杂时空关系；2) 采用概率嵌入的actor-critic强化学习，实现无需重新训练即可快速适应充电网络布局变化。

Result: 基于中国成都真实数据的广泛仿真表明，GAT-PEARL显著优于传统强化学习方法，对未见过的基础设施布局表现出优越的泛化能力，在动态环境中实现更高的整体运营效率。

Conclusion: GAT-PEARL框架有效解决了动态充电网络下自动驾驶电动出租车车队管理问题，通过元强化学习方法实现了对基础设施布局变化的快速适应，为实际运营提供了更贴近现实的解决方案。

Abstract: With the rapid expansion of electric vehicles (EVs) and charging infrastructure, the effective management of Autonomous Electric Taxi (AET) fleets faces a critical challenge in environments with dynamic and uncertain charging availability. While most existing research assumes a static charging network, this simplification creates a significant gap between theoretical models and real-world operations. To bridge this gap, we propose GAT-PEARL, a novel meta-reinforcement learning framework that learns an adaptive operational policy. Our approach integrates a graph attention network (GAT) to effectively extract robust spatial representations under infrastructure layouts and model the complex spatiotemporal relationships of the urban environment, and employs probabilistic embeddings for actor-critic reinforcement learning (PEARL) to enable rapid, inference-based adaptation to changes in charging network layouts without retraining. Through extensive simulations on real-world data in Chengdu, China, we demonstrate that GAT-PEARL significantly outperforms conventional reinforcement learning baselines, showing superior generalization to unseen infrastructure layouts and achieving higher overall operational efficiency in dynamic settings.

</details>


### [12] [Graph-Free Root Cause Analysis](https://arxiv.org/abs/2601.21359)
*Luan Pham*

Main category: cs.LG

TL;DR: PRISM是一个无需依赖图的根因分析框架，通过考虑故障传播延迟，在735个真实故障案例中实现68%的Top-1准确率，比最佳基线提升258%


<details>
  <summary>Details</summary>
Motivation: 现有无依赖图的RCA方法通常假设根因具有最高异常分数，但当故障传播时，根因的小延迟可能在下游累积成更大异常，导致该假设失效

Method: 提出PRISM框架，针对一类基于组件的系统，在无依赖图情况下进行根因分析，并具有理论保证

Result: 在9个真实数据集上的735个故障中，PRISM达到68%的Top-1准确率，比最佳基线提升258%，每个诊断仅需8ms

Conclusion: PRISM是一个简单高效的RCA框架，无需依赖图即可处理故障传播问题，在真实场景中表现优异

Abstract: Failures in complex systems demand rapid Root Cause Analysis (RCA) to prevent cascading damage. Existing RCA methods that operate without dependency graph typically assume that the root cause having the highest anomaly score. This assumption fails when faults propagate, as a small delay at the root cause can accumulate into a much larger anomaly downstream. In this paper, we propose PRISM, a simple and efficient framework for RCA when the dependency graph is absent. We formulate a class of component-based systems under which PRISM performs RCA with theoretical guarantees. On 735 failures across 9 real-world datasets, PRISM achieves 68% Top-1 accuracy, a 258% improvement over the best baseline, while requiring only 8ms per diagnosis.

</details>


### [13] [SAGE: Sequence-level Adaptive Gradient Evolution for Generative Recommendation](https://arxiv.org/abs/2601.21452)
*Yu Xie,Xing Kai Ren,Ying Qi,Hu Yao*

Main category: cs.LG

TL;DR: SAGE提出序列级自适应梯度演化框架，解决OneRec中对称保守主义问题，实现无需单独词汇表的LLM推荐系统优化


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐系统如OneRec依赖单独词汇表，导致维护成本高、扩展性差；同时其GBPO优化策略存在对称保守主义问题，抑制冷启动项目更新动量，无法防止高噪声环境中的多样性崩溃

Method: 提出SAGE统一优化框架：1)序列级信号解耦：结合几何平均重要性比率和解耦多目标优势，消除令牌级方差；2)非对称自适应动态：构建动态梯度流形，对高潜力冷启动项目应用"提升因子"实现超线性更新，使用"熵感知惩罚"打破信息茧房

Result: 理论分析和实证结果表明，SAGE有效释放冷启动流量并维持推荐多样性，同时保持GBPO的数值稳定性

Conclusion: SAGE框架成功解决了LLM推荐系统中的词汇表依赖和对称保守主义问题，实现了高效、可扩展的列表式生成推荐优化

Abstract: While works such as OneRec have validated the scaling laws of Large Language Models (LLMs) in recommender systems, they rely on a cumbersome separate vocabulary. This dependency prevents the model architecture from reusing native LLM vocabularies, resulting in high maintenance costs and poor scalability. In response, we aim to efficiently reuse open-source LLM architectures without constructing a separate tokenization vocabulary. Furthermore, we identify that the optimization strategy of OneRec Gradient Bounded Policy Optimization (GBPO),suffers from a "Symmetric Conservatism" problem: its static gradient boundaries structurally suppress the update momentum required for cold-start items and fail to prevent diversity collapse in high-noise environments.To address this issue, we propose SAGE (Sequence-level Adaptive Gradient Evolution), a unified optimization framework tailored for list-wise generative recommendation. SAGE introduces two key innovations:(1) Sequence-level Signal Decoupling: By combining a geometric mean importance ratio with decoupled multi-objective advantages, we eliminate token-level variance and resolve the "Reward Collapse" problem. (2) Asymmetric Adaptive Dynamics: We construct a dynamic gradient manifold that applies a "Boost Factor" to high-potential cold start items to achieve super-linear updates and employs an "Entropy Aware Penalty" to break information cocoons. Theoretical analysis and empirical results demonstrate that SAGE effectively unblocks cold-start traffic and sustains recommendation diversity, all while retaining the numerical stability of GBPO.

</details>


### [14] [Visual-Guided Key-Token Regularization for Multimodal Large Language Model Unlearning](https://arxiv.org/abs/2601.22020)
*Chengyi Cai,Zesheng Ye,Peike Li,Bo Han,Jianzhong Qi,Feng Liu*

Main category: cs.LG

TL;DR: 提出ViKeR方法，通过视觉引导的关键令牌正则化来改进多模态大语言模型的遗忘学习，重点关注答案中关键令牌的重要性


<details>
  <summary>Details</summary>
Motivation: 现有MLLM遗忘学习方法主要沿用LLM方法，将所有答案令牌同等对待，忽视了它们在遗忘过程中的重要性差异，且仅关注语言模态而忽略了视觉线索

Method: 提出视觉引导的关键令牌正则化(ViKeR)：利用无关视觉输入预测理想的遗忘后令牌级分布，用这些分布正则化遗忘过程；通过信息熵定义关键令牌，并通过令牌级梯度重加权放大关键令牌的更新

Result: 在MLLMU和CLEAR基准测试中，该方法能有效执行遗忘学习，同时减轻遗忘效应并保持回答连贯性

Conclusion: ViKeR方法通过视觉引导的关键令牌正则化，解决了现有MLLM遗忘学习方法忽视令牌重要性和视觉线索的问题，实现了更有效的隐私保护遗忘学习

Abstract: Unlearning in Multimodal Large Language Models (MLLMs) prevents the model from revealing private information when queried about target images. Existing MLLM unlearning methods largely adopt approaches developed for LLMs. They treat all answer tokens uniformly, disregarding their varying importance in the unlearning process. Moreover, these methods focus exclusively on the language modality, disregarding visual cues that indicate key tokens in answers. In this paper, after formulating the problem of unlearning in multimodal question answering for MLLMs, we propose Visual-Guided Key-Token Regularization (ViKeR). We leverage irrelevant visual inputs to predict ideal post-unlearning token-level distributions and use these distributions to regularize the unlearning process, thereby prioritizing key tokens. Further, we define key tokens in unlearning via information entropy and discuss ViKeR's effectiveness through token-level gradient reweighting, which amplifies updates on key tokens. Experiments on MLLMU and CLEAR benchmarks demonstrate that our method effectively performs unlearning while mitigating forgetting and maintaining response coherence.

</details>


### [15] [Expected Return Causes Outcome-Level Mode Collapse in Reinforcement Learning and How to Fix It with Inverse Probability Scaling](https://arxiv.org/abs/2601.21669)
*Abhijeet Sinha,Sundari Elango,Dianbo Liu*

Main category: cs.LG

TL;DR: 论文指出强化学习中的模式崩溃是期望回报目标的结构性问题，而非探索不足。提出逆概率缩放修正，开发IPS-GRPO方法，在推理和分子生成任务中有效减少模式崩溃。


<details>
  <summary>Details</summary>
Motivation: 许多强化学习问题存在多个质量相当的终端解，但标准期望回报最大化训练的政策总是崩溃到少数结果上。传统解释归因于探索不足或正则化弱，但作者认为这是期望回报目标本身的结构性问题。

Method: 识别期望回报目标中的概率乘数是问题根源，提出逆概率缩放修正，消除结果频率放大效应。实例化为IPS-GRPO方法，作为Group Relative Policy Optimization的即插即用修改，无需辅助模型或架构变更。

Result: 在理想学习动态下，IPS-GRPO能产生奖励比例分布的终端分布，防止多模态设置中的崩溃。在不同推理和分子生成任务中，IPS-GRPO持续减少结果级模式崩溃，同时匹配或超越基线性能。

Conclusion: 修正目标函数而非添加探索启发式方法是可靠多模态政策优化的关键。逆概率缩放从根本上改变学习动态，防止模式崩溃，为多模态强化学习提供了理论保证。

Abstract: Many reinforcement learning (RL) problems admit multiple terminal solutions of comparable quality, where the goal is not to identify a single optimum but to represent a diverse set of high-quality outcomes. Nevertheless, policies trained by standard expected return maximization routinely collapse onto a small subset of outcomes, a phenomenon commonly attributed to insufficient exploration or weak regularization. We show that this explanation is incomplete: outcome level mode collapse is a structural consequence of the expected-return objective itself. Under idealized learning dynamics, the log-probability ratio between any two outcomes evolves linearly in their reward difference, implying exponential ratio divergence and inevitable collapse independent of the exploration strategy, entropy regularization, or optimization algorithm. We identify the source of this pathology as the probability multiplier inside the expectation and propose a minimal correction: inverse probability scaling, which removes outcome-frequency amplification from the learning signal, fundamentally changes the learning dynamics, and provably yields reward-proportional terminal distributions, preventing collapse in multimodal settings. We instantiate this principle in Group Relative Policy Optimization (GRPO) as a drop-in modification, IPS-GRPO, requiring no auxiliary models or architectural changes. Across different reasoning and molecular generation tasks, IPS-GRPO consistently reduces outcome-level mode collapse while matching or exceeding baseline performance, suggesting that correcting the objective rather than adding exploration heuristics is key to reliable multimodal policy optimization.

</details>


### [16] [Knowledge Vector Weakening: Efficient Training-free Unlearning for Large Vision-Language Models](https://arxiv.org/abs/2601.21794)
*Yejin Kim,Dongjun Hwang,Sungmin Cha,Junsuk Choe*

Main category: cs.LG

TL;DR: KVW是一种无需训练的知识向量弱化方法，通过直接干预模型激活的知识向量来实现大视觉语言模型的高效遗忘，避免梯度计算带来的计算开销。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型存在隐私泄露和有害内容生成等严重问题，机器遗忘是移除特定数据影响的解决方案，但现有基于梯度优化的方法计算成本过高。

Method: KVW（知识向量弱化）是一种无需训练的遗忘方法，识别模型在遗忘集上输出生成时激活的知识向量，并逐步削弱这些向量的贡献，防止模型利用不良知识。

Result: 在MLLMU和CLEAR基准测试中，KVW实现了稳定的遗忘-保留权衡，同时在计算效率上显著优于基于梯度和LoRA的遗忘方法。

Conclusion: KVW为大规模LVLMs提供了一种高效、无需训练的遗忘解决方案，解决了现有梯度方法计算成本高的问题，在保持模型性能的同时实现特定知识的移除。

Abstract: Large Vision-Language Models (LVLMs) are widely adopted for their strong multimodal capabilities, yet they raise serious concerns such as privacy leakage and harmful content generation. Machine unlearning has emerged as a promising solution for removing the influence of specific data from trained models. However, existing approaches largely rely on gradient-based optimization, incurring substantial computational costs for large-scale LVLMs. To address this limitation, we propose Knowledge Vector Weakening (KVW), a training-free unlearning method that directly intervenes in the full model without gradient computation. KVW identifies knowledge vectors that are activated during the model's output generation on the forget set and progressively weakens their contributions, thereby preventing the model from exploiting undesirable knowledge. Experiments on the MLLMU and CLEAR benchmarks demonstrate that KVW achieves a stable forget-retain trade-off while significantly improving computational efficiency over gradient-based and LoRA-based unlearning methods.

</details>


### [17] [Dependence of Equilibrium Propagation Training Success on Network Architecture](https://arxiv.org/abs/2601.21945)
*Qingshan Wang,Clara C. Wanjura,Florian Marquardt*

Main category: cs.LG

TL;DR: 研究探索了平衡传播训练方法在局部连接晶格架构上的性能，发现稀疏局部连接网络能达到与密集网络相当的性能，为实际实现提供了指导。


<details>
  <summary>Details</summary>
Motivation: 人工智能快速发展导致能耗不可持续增长，推动了神经形态计算和基于物理的训练方法研究。现有理论研究多关注全连接或密集层状网络，但这些架构在实际实验中难以实现（如连接性限制）。因此需要研究更现实的架构选择。

Method: 采用广泛使用的基于物理的训练方法——平衡传播，研究局部连接晶格架构。训练XY模型，探索架构对各种基准任务的影响，跟踪训练过程中空间分布响应和耦合的演化。

Result: 稀疏网络（仅局部连接）能够达到与密集网络相当的性能表现。研究结果为在现实环境中进一步扩展基于平衡传播的架构提供了指导。

Conclusion: 局部连接晶格架构在实际实现中具有可行性，稀疏网络性能不亚于密集网络，这为构建更节能、更易实现的神经形态计算系统提供了重要参考。

Abstract: The rapid rise of artificial intelligence has led to an unsustainable growth in energy consumption. This has motivated progress in neuromorphic computing and physics-based training of learning machines as alternatives to digital neural networks. Many theoretical studies focus on simple architectures like all-to-all or densely connected layered networks. However, these may be challenging to realize experimentally, e.g. due to connectivity constraints. In this work, we investigate the performance of the widespread physics-based training method of equilibrium propagation for more realistic architectural choices, specifically, locally connected lattices. We train an XY model and explore the influence of architecture on various benchmark tasks, tracking the evolution of spatially distributed responses and couplings during training. Our results show that sparse networks with only local connections can achieve performance comparable to dense networks. Our findings provide guidelines for further scaling up architectures based on equilibrium propagation in realistic settings.

</details>


### [18] [Bridging Graph Structure and Knowledge-Guided Editing for Interpretable Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2601.21978)
*Shiqi Fan,Quanming Yao,Hongyi Nie,Wentao Ma,Zhen Wang,Wen Hua*

Main category: cs.LG

TL;DR: IGETR是一个结合GNN结构化时序建模和LLM上下文理解的混合推理框架，用于时序知识图谱推理，在标准基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的时序知识图谱推理方法过于关注上下文关系而忽视结构关系，难以从动态图中提取相关子图，导致对结构信息理解不足，产生非结构化且易出现幻觉的推理，特别是在时序不一致的情况下。

Method: 提出IGETR三阶段流水线：1) 使用时序GNN识别结构和时序一致的候选路径，确保推理基于可靠图证据；2) LLM引导的路径编辑，利用外部知识修正逻辑和语义不一致；3) 整合精炼的推理路径生成准确且可解释的预测。

Result: 在标准TKG基准测试中，IGETR达到最先进性能，在挑战性的ICEWS数据集上，Hits@1相对提升5.6%，Hits@3相对提升8.1%。消融研究和额外分析确认了各组件有效性。

Conclusion: IGETR成功结合了GNN的结构化时序建模能力和LLM的上下文理解，解决了现有方法在时序知识图谱推理中的结构信息提取不足和幻觉问题，实现了更准确可靠的预测。

Abstract: Temporal knowledge graph reasoning (TKGR) aims to predict future events by inferring missing entities with dynamic knowledge structures. Existing LLM-based reasoning methods prioritize contextual over structural relations, struggling to extract relevant subgraphs from dynamic graphs. This limits structural information understanding, leading to unstructured, hallucination-prone inferences especially with temporal inconsistencies. To address this problem, we propose IGETR (Integration of Graph and Editing-enhanced Temporal Reasoning), a hybrid reasoning framework that combines the structured temporal modeling capabilities of Graph Neural Networks (GNNs) with the contextual understanding of LLMs. IGETR operates through a three-stage pipeline. The first stage aims to ground the reasoning process in the actual data by identifying structurally and temporally coherent candidate paths through a temporal GNN, ensuring that inference starts from reliable graph-based evidence. The second stage introduces LLM-guided path editing to address logical and semantic inconsistencies, leveraging external knowledge to refine and enhance the initial paths. The final stage focuses on integrating the refined reasoning paths to produce predictions that are both accurate and interpretable. Experiments on standard TKG benchmarks show that IGETR achieves state-of-the-art performance, outperforming strong baselines with relative improvements of up to 5.6% on Hits@1 and 8.1% on Hits@3 on the challenging ICEWS datasets. Additionally, we execute ablation studies and additional analyses confirm the effectiveness of each component.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [The Epistemic Planning Domain Definition Language: Official Guideline](https://arxiv.org/abs/2601.20969)
*Alessandro Burigana,Francesco Fabiano*

Main category: cs.AI

TL;DR: 提出了EPDDL（认知规划领域定义语言），这是一个类似PDDL的统一表示语言，用于捕获完整的动态认知逻辑语义，解决现有认知规划器在基准测试和语言表示上的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于动态认知逻辑（DEL）的认知规划器通常针对不同的DEL片段，使用不同的临时语言表示基准测试，甚至没有统一语言。这种碎片化阻碍了比较、重用和系统化的基准开发。

Method: 1. 开发了抽象事件模型作为认知动作的新表示方法；2. 基于抽象事件模型和DEL形式化定义了EPDDL的语法和语义；3. 识别了适用于当前规划器的有用片段，并展示如何在EPDDL中表示它们。

Result: 提出了EPDDL语言，能够统一表示完整的DEL语义，通过代表性基准测试示例展示了EPDDL如何促进互操作性、可重复评估和认知规划的未来发展。

Conclusion: EPDDL为认知规划提供了一个统一的PDDL-like表示语言，解决了现有系统的碎片化问题，促进了认知规划领域的标准化、比较和未来发展。

Abstract: Epistemic planning extends (multi-agent) automated planning by making agents' knowledge and beliefs first-class aspects of the planning formalism. One of the most well-known frameworks for epistemic planning is Dynamic Epistemic Logic (DEL), which offers an rich and natural semantics for modelling problems in this setting. The high expressive power provided by DEL make DEL-based epistemic planning a challenging problem to tackle both theoretically, and in practical implementations. As a result, existing epistemic planners often target different DEL fragments, and typically rely on ad hoc languages to represent benchmarks, and sometimes no language at all. This fragmentation hampers comparison, reuse, and systematic benchmark development. We address these issues by introducing the Epistemic Planning Domain Definition Language (EPDDL). EPDDL provides a unique PDDL-like representation that captures the entire DEL semantics, enabling uniform specification of epistemic planning tasks. Our contributions are threefold: 1. A formal development of abstract event models, a novel representation for epistemic actions used to define the semantics of our language; 2. A formal specification of EPDDL's syntax and semantics grounded in DEL with abstract event models; 3. A demonstration of EPDDL's practical applicability: we identify useful fragments amenable to current planners and show how they can be represented in EPDDL. Through examples of representative benchmarks, we illustrate how EPDDL facilitates interoperability, reproducible evaluation, and future advances in epistemic planning.

</details>


### [20] [QUARK: Robust Retrieval under Non-Faithful Queries via Query-Anchored Aggregation](https://arxiv.org/abs/2601.21049)
*Rita Qiuran Lyu,Michelle Manqiao Wang,Lei Shi*

Main category: cs.AI

TL;DR: QUARK框架通过建模查询不确定性，使用恢复假设和查询锚定聚合来提高非忠实查询下的检索鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的用户查询往往是非忠实的（噪声、不完整或扭曲），导致检索器在关键语义缺失时失败。这被形式化为召回噪声下的检索问题。

Method: 提出QUARK框架：1) 通过恢复假设（即给定观察查询下潜在意图的多个合理解释）显式建模查询不确定性；2) 引入查询锚定聚合来鲁棒地结合这些信号。原始查询作为语义锚点，恢复假设提供受控的辅助证据。

Result: 在受控模拟和BEIR基准测试（FIQA、SciFact、NFCorpus）中，QUARK在稀疏和密集检索器上都提高了Recall、MRR和nDCG。消融实验显示QUARK对恢复假设数量具有鲁棒性，且锚定聚合优于非锚定的最大/平均/中位数池化。

Conclusion: 通过恢复假设建模查询不确定性，结合原则性的锚定聚合，对于非忠实查询下的鲁棒检索至关重要。QUARK无需训练即可提高召回和排序质量，同时保持鲁棒性。

Abstract: User queries in real-world retrieval are often non-faithful (noisy, incomplete, or distorted), causing retrievers to fail when key semantics are missing. We formalize this as retrieval under recall noise, where the observed query is drawn from a noisy recall process of a latent target item. To address this, we propose QUARK, a simple yet effective training-free framework for robust retrieval under non-faithful queries. QUARK explicitly models query uncertainty through recovery hypotheses, i.e., multiple plausible interpretations of the latent intent given the observed query, and introduces query-anchored aggregation to combine their signals robustly. The original query serves as a semantic anchor, while recovery hypotheses provide controlled auxiliary evidence, preventing semantic drift and hypothesis hijacking. This design enables QUARK to improve recall and ranking quality without sacrificing robustness, even when some hypotheses are noisy or uninformative. Across controlled simulations and BEIR benchmarks (FIQA, SciFact, NFCorpus) with both sparse and dense retrievers, QUARK improves Recall, MRR, and nDCG over the base retriever. Ablations show QUARK is robust to the number of recovery hypotheses and that anchored aggregation outperforms unanchored max/mean/median pooling. These results demonstrate that modeling query uncertainty through recovery hypotheses, coupled with principled anchored aggregation, is essential for robust retrieval under non-faithful queries.

</details>


### [21] [EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21340)
*Lang Cao,Qingyu Chen,Yue Guo*

Main category: cs.AI

TL;DR: EHR-RAG：针对长时序电子健康记录的检索增强框架，通过事件-时间感知混合检索、自适应迭代检索和双路径证据推理，提升临床预测准确性


<details>
  <summary>Details</summary>
Motivation: 电子健康记录包含丰富的纵向临床证据，但长时序EHR常超出LLM上下文限制，现有方法通过截断或简单检索会丢失临床相关事件和时间依赖性，需要专门针对结构化EHR数据的检索增强框架

Method: 提出EHR-RAG框架，包含三个核心组件：1）事件-时间感知混合EHR检索，保留临床结构和时间动态；2）自适应迭代检索，逐步细化查询以扩展证据覆盖；3）双路径证据检索与推理，联合检索和推理事实与反事实证据

Result: 在四个长时序EHR预测任务上的实验表明，EHR-RAG始终优于最强的LLM基线方法，平均Macro-F1提升10.76%

Conclusion: 检索增强的LLM在结构化EHR数据的临床预测实践中具有显著潜力，EHR-RAG框架通过专门设计的组件有效解决了长时序EHR处理的挑战

Abstract: Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.

</details>


### [22] [Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget](https://arxiv.org/abs/2601.21608)
*Saisubramaniam Gopalakrishnan,Harikrishnan P M,Dagnachew Birru*

Main category: cs.AI

TL;DR: 该研究将企业级智能文档处理系统的验证问题形式化为基于搜索的软件测试问题，旨在在有限预算下最大化发现不同类型的故障模式，并通过多种搜索策略的对比分析展示了策略间的互补性。


<details>
  <summary>Details</summary>
Motivation: 企业级智能文档处理系统在金融、保险和医疗等高风险领域应用广泛，早期系统验证需要在有限预算下发现多样化的故障机制，而不仅仅是识别单一最坏情况文档。现有方法往往依赖单一测试策略，可能无法全面覆盖各种故障类型。

Method: 将问题形式化为基于搜索的软件测试问题，在文档配置的组合空间中操作，通过实例化结构性风险特征来诱导现实故障条件。评估了包括进化算法、群体智能、质量多样性、学习型和量子算法在内的多种搜索策略，在相同预算约束下进行基准测试，并通过配置级排他性、胜率和跨时间重叠分析等方法评估策略效果。

Result: 不同求解器在可比预算下能持续发现其他特定替代方法未发现的故障模式。跨时间分析显示，所有评估预算中都存在求解器特定的持久性发现，没有任何单一策略表现出绝对优势。虽然所有求解器的联合最终能覆盖观察到的故障空间，但依赖任何单一方法都会系统性地延迟重要风险的发现。

Conclusion: 研究结果证明了求解器之间的内在互补性，为基于组合策略的SBST方法提供了理论依据，建议采用组合式测试策略进行稳健的工业IDP验证，以提高故障发现的全面性和效率。

Abstract: Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.

</details>


### [23] [Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling](https://arxiv.org/abs/2601.21760)
*Ruian Tie,Wenbo Xiong,Zhengyu Shi,Xinyu Su,Chenyu jiang,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: 提出ZSSD零样本统计降尺度框架，无需配对训练数据，通过物理一致性气候先验和统一坐标引导解决现有方法物理不一致和梯度消失问题


<details>
  <summary>Details</summary>
Motivation: 传统监督式气候降尺度方法因缺乏配对训练数据和与再分析数据的领域差距而难以泛化到全球气候模型，现有零样本方法存在物理不一致性和大尺度因子下的梯度消失问题

Method: 提出ZSSD零样本统计降尺度框架，包含：1）从再分析数据学习物理一致性气候先验，结合地球物理边界和时序信息确保物理有效性；2）统一坐标引导策略解决DPS中的梯度消失问题并确保与大尺度场的一致性

Result: ZSSD在99%分位数误差上显著优于现有零样本基线，能成功重建复杂天气事件（如热带气旋），并在异质GCMs中表现良好

Conclusion: ZSSD为零样本气候降尺度提供了有效解决方案，通过物理一致性先验和统一坐标引导解决了现有方法的局限性，在多个GCMs中展现出优越性能

Abstract: Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without paired data during training. ZSSD leverages a Physics-Consistent Climate Prior learned from reanalysis data, conditioned on geophysical boundaries and temporal information to enforce physical validity. Furthermore, to enable robust inference across varying GCMs, we introduce Unified Coordinate Guidance. This strategy addresses the vanishing gradient problem in vanilla DPS and ensures consistency with large-scale fields. Results show that ZSSD significantly outperforms existing zero-shot baselines in 99th percentile errors and successfully reconstructs complex weather events, such as tropical cyclones, across heterogeneous GCMs.

</details>


### [24] [From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning](https://arxiv.org/abs/2601.21909)
*Shaojie Wang,Liang Zhang*

Main category: cs.AI

TL;DR: 提出Chain-of-Meta-Thought (CoMT)框架，模仿人类认知的两阶段过程：先学习抽象推理模式，再通过置信度校准强化学习优化任务适应，相比传统方法显著提升泛化能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练方法将完整推理轨迹作为基本单元进行优化，这与人类实际解决问题的方式存在根本差异。人类认知自然地将问题解决分解为两个阶段：首先获取跨问题泛化的抽象策略（元知识），然后将其适应到具体实例。现有方法的问题中心化处理将抽象策略与问题特定执行纠缠在一起，导致泛化能力不足。

Method: 提出认知启发的两阶段框架：1) Chain-of-Meta-Thought (CoMT)：专注于抽象推理模式的监督学习，不涉及具体执行，获取可泛化的策略；2) Confidence-Calibrated Reinforcement Learning (CCRL)：通过中间步骤的置信度感知奖励优化任务适应，防止过度自信的错误级联，提高执行可靠性。

Result: 在4个模型和8个基准测试上的实验显示，相比标准方法，在分布内提升2.19%，分布外提升4.63%，同时减少65-70%的训练时间和50%的token消耗，表明与人类认知原则对齐不仅能获得更好的泛化能力，还能显著提高训练效率。

Conclusion: 通过模仿人类认知的两阶段过程，将后训练与人类认知原则对齐，能够同时实现更好的泛化性能和更高的训练效率，为LLM后训练方法提供了新的认知启发方向。

Abstract: Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\% and 4.63\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.

</details>


### [25] [Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities](https://arxiv.org/abs/2601.21937)
*Shuangshuang Ying,Zheyu Wang,Yunjian Peng,Jin Chen,Yuhao Wu,Hongbin Lin,Dingyu He,Siyi Liu,Gengchen Yu,YinZhu Piao,Yuchen Wu,Xin Gui,Zhongyuan Peng,Xin Li,Xeron Du,Libo Qin,YiXin Cao,Ge Zhang*

Main category: cs.AI

TL;DR: DeR2是一个用于评估大语言模型在科学新信息上推理能力的受控深度研究沙箱，通过四种证据访问机制分离检索损失与推理损失，揭示了模型在文档基础推理中的显著性能差异和脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在多个问题：端到端RAG管道中推理与检索/工具链选择混淆；信号受到参数记忆和开放网络波动的污染；无法确定大语言模型是否真正能在新颖科学信息上进行推理。

Method: 设计了DeR2沙箱，通过四种证据访问机制（仅指令、概念、仅相关文档、完整集）分离证据访问与推理；采用两阶段验证防止参数泄漏；使用2023-2025年理论论文构建冻结文档库，包含专家标注的概念和验证的推理链。

Result: 实验显示不同基础模型表现差异显著：有些模型表现出模式切换脆弱性（完整集表现比仅指令更差）；有些模型存在结构性概念误用（能正确命名概念但无法将其作为程序执行）；整体存在显著的改进空间。

Conclusion: DeR2提供了一个受控环境来评估文档基础推理能力，揭示了当前大语言模型在处理新颖科学信息时的实质性限制，为未来模型开发和评估提供了重要基准。

Abstract: Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.

</details>


### [26] [VERSA: Verified Event Data Format for Reliable Soccer Analytics](https://arxiv.org/abs/2601.21981)
*Geonhee Jo,Mingu Kang,Kangmin Lee,Minho Lee,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: VERSA是一个用于足球事件数据的系统验证框架，通过状态转移模型检测和纠正逻辑不一致性，显著提高数据质量和下游分析可靠性。


<details>
  <summary>Details</summary>
Motivation: 事件流数据在体育分析中至关重要，但现有数据存在逻辑不一致问题（如事件顺序错误、事件缺失），这限制了分析模型的可靠性。特别是在足球领域，数据质量问题会影响球员贡献评估和战术模式识别等精细分析。

Method: 提出VERSA框架，基于状态转移模型定义有效事件序列，能够自动检测和纠正事件流数据中的异常模式。该框架通过系统验证确保足球事件数据的完整性。

Result: 在K League 1（2024赛季）的Bepro数据中，发现18.81%的事件存在逻辑不一致。VERSA显著提高了跨数据提供商的一致性，确保异构数据源的稳定统一表示。经VERSA精炼的数据显著提升了VAEP（评估球员贡献的下游任务）的鲁棒性和性能。

Conclusion: VERSA验证框架能有效提高事件流数据的可靠性，从而增强数据驱动分析的准确性。该研究强调了数据质量验证在体育分析中的重要性，为其他领域的事件数据分析提供了参考。

Abstract: Event stream data is a critical resource for fine-grained analysis across various domains, including financial transactions, system operations, and sports. In sports, it is actively used for fine-grained analyses such as quantifying player contributions and identifying tactical patterns. However, the reliability of these models is fundamentally limited by inherent data quality issues that cause logical inconsistencies (e.g., incorrect event ordering or missing events). To this end, this study proposes VERSA (Verified Event Data Format for Reliable Soccer Analytics), a systematic verification framework that ensures the integrity of event stream data within the soccer domain. VERSA is based on a state-transition model that defines valid event sequences, thereby enabling the automatic detection and correction of anomalous patterns within the event stream data. Notably, our examination of event data from the K League 1 (2024 season), provided by Bepro, detected that 18.81% of all recorded events exhibited logical inconsistencies. Addressing such integrity issues, our experiments demonstrate that VERSA significantly enhances cross-provider consistency, ensuring stable and unified data representation across heterogeneous sources. Furthermore, we demonstrate that data refined by VERSA significantly improves the robustness and performance of a downstream task called VAEP, which evaluates player contributions. These results highlight that the verification process is highly effective in increasing the reliability of data-driven analysis.

</details>


### [27] [Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems](https://arxiv.org/abs/2601.21993)
*Dhiogo de Sá,Carlos Schmiedel,Carlos Pereira Lopes*

Main category: cs.AI

TL;DR: 提出Liquid Interfaces协调范式，将接口视为运行时通过意图表达和语义协商产生的短暂关系事件，而非持久技术制品，以支持自适应、概率性和上下文相关的智能体系统。


<details>
  <summary>Details</summary>
Motivation: 当前软件架构难以支持具有自适应、概率性和上下文相关推理能力的自主智能体，系统集成仍主要依赖静态接口和确定性契约，需要新的协调范式来解决这一矛盾。

Method: 提出Liquid Interfaces协调范式，形式化该模型并设计Liquid Interface Protocol (LIP)，该协议管理意图驱动的交互、协商执行以及在语义不确定性下的短暂性执行，同时讨论了治理影响并描述了参考架构。

Result: 开发了Liquid Interface Protocol (LIP)作为协调协议，建立了参考架构来展示实际可行性，为基于智能体的自适应协调系统提供了原则性基础。

Conclusion: Liquid Interfaces为基于智能体的自适应协调系统提供了新的原则性基础，通过将接口视为短暂关系事件而非持久技术制品，能够更好地支持自适应、概率性和上下文相关的智能体推理。

Abstract: Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [28] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 提出一种新的预训练方法，通过强化学习在预训练阶段提升语言模型的事实性、安全性和生成质量，避免后期难以纠正的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要通过昂贵的微调和对齐来解决安全性和事实性问题，但这种方法无法纠正预训练阶段学习到的错误模式。在预训练阶段就解决这些问题至关重要，因为预训练塑造了模型的核心行为，可以防止不安全或幻觉输出被深度嵌入。

Method: 提出新的预训练方法：流式处理文档，使用强化学习（RL）在每一步改进接下来K个生成的token。使用一个经过后训练的强模型来评估候选生成（包括模型rollout、原始后缀和重写后缀）的质量、安全性和事实性。训练早期依赖原始和重写的后缀，随着模型改进，RL奖励高质量的rollout。

Result: 相比标准预训练，该方法在事实性方面获得36.2%的相对改进，在安全性方面获得18.5%的相对改进，在整体生成质量方面获得高达86.3%的胜率改进。

Conclusion: 该方法能够从基础开始构建更高质量、更安全、更事实的模型，通过在预训练阶段直接解决核心问题，避免了后期难以纠正的错误模式。

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [29] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: OVD是一种基于轨迹匹配的在线知识蒸馏框架，用离散语言评分替代token级概率匹配，显著降低内存消耗并提升学生模型探索能力。


<details>
  <summary>Details</summary>
Motivation: 现有token级在线蒸馏方法需要token级对齐，限制了学生模型的探索能力，无法有效利用环境反馈，且在强化学习中存在严重内存瓶颈。

Method: 提出在线语言蒸馏(OVD)框架，用教师模型的离散语言评分(0-9)进行轨迹匹配，替代token级概率匹配，避免token级对齐要求。

Result: 在Web问答和数学推理任务上显著优于现有方法，Web Q&A任务平均EM提升+12.9%，数学基准提升+25.7%，训练效率更高。

Conclusion: OVD通过轨迹匹配和语言评分有效解决了token级蒸馏的限制，实现了内存高效且性能优越的知识蒸馏。

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [30] [InspecSafe-V1: A Multimodal Benchmark for Safety Assessment in Industrial Inspection Scenarios](https://arxiv.org/abs/2601.21173)
*Zeyi Liu,Shuang Liu,Jihai Min,Zhaoheng Zhang,Jun Cen,Pengyu Han,Songqiao Hu,Zihan Meng,Xiao He,Donghua Zhou*

Main category: cs.RO

TL;DR: InspecSafe-V1是首个用于工业巡检安全评估的多模态基准数据集，包含真实巡检机器人采集的5,013个实例，覆盖5种工业场景，提供7种同步感知模态和像素级分割标注。


<details>
  <summary>Details</summary>
Motivation: 工业智能化和无人巡检快速发展，但现有公共数据集存在模拟数据、单模态感知、缺乏细粒度标注等问题，限制了工业基础模型的鲁棒场景理解和多模态安全推理能力。

Method: 从真实工业环境中41台轮式和轨道式巡检机器人的日常操作中收集数据，覆盖2,239个有效巡检点，构建包含5,013个巡检实例的数据集。提供像素级分割标注、语义场景描述和安全等级标签，并包含7种同步感知模态。

Result: 发布了InspecSafe-V1数据集，覆盖隧道、电力设施、烧结设备、石油化工、煤炭输送栈桥等5种代表性工业场景，包含可见光图像、红外视频、音频、深度点云、雷达点云、气体测量、温湿度等7种同步模态。

Conclusion: InspecSafe-V1填补了工业巡检安全评估领域多模态基准数据集的空白，支持多模态异常识别、跨模态融合和综合安全评估，为工业基础模型的发展提供了重要资源。

Abstract: With the rapid development of industrial intelligence and unmanned inspection, reliable perception and safety assessment for AI systems in complex and dynamic industrial sites has become a key bottleneck for deploying predictive maintenance and autonomous inspection. Most public datasets remain limited by simulated data sources, single-modality sensing, or the absence of fine-grained object-level annotations, which prevents robust scene understanding and multimodal safety reasoning for industrial foundation models. To address these limitations, InspecSafe-V1 is released as the first multimodal benchmark dataset for industrial inspection safety assessment that is collected from routine operations of real inspection robots in real-world environments. InspecSafe-V1 covers five representative industrial scenarios, including tunnels, power facilities, sintering equipment, oil and gas petrochemical plants, and coal conveyor trestles. The dataset is constructed from 41 wheeled and rail-mounted inspection robots operating at 2,239 valid inspection sites, yielding 5,013 inspection instances. For each instance, pixel-level segmentation annotations are provided for key objects in visible-spectrum images. In addition, a semantic scene description and a corresponding safety level label are provided according to practical inspection tasks. Seven synchronized sensing modalities are further included, including infrared video, audio, depth point clouds, radar point clouds, gas measurements, temperature, and humidity, to support multimodal anomaly recognition, cross-modal fusion, and comprehensive safety assessment in industrial environments.

</details>


### [31] [HPTune: Hierarchical Proactive Tuning for Collision-Free Model Predictive Control](https://arxiv.org/abs/2601.21346)
*Wei Zuo,Chengyang Li,Yikun Wang,Bingyang Cheng,Zeyi Ren,Shuai Wang,Derrick Wing Kwan Ng,Yik-Chung Wu*

Main category: cs.RO

TL;DR: 提出分层主动调参框架HPTune，通过评估已执行和未执行动作来提升MPC运动规划器的参数调优效率，结合快速层和慢速层调参，并与多普勒激光雷达集成增强运动预测。


<details>
  <summary>Details</summary>
Motivation: 现有MPC参数调优方法通常只评估已执行动作，导致参数更新效率低下，因为失败事件（如障碍物接近或碰撞）稀疏。需要扩展评估范围以提高调优效率。

Method: 提出分层主动调参框架HPTune：1）快速层调参使用预测接近速度和预测接近距离的风险指标；2）慢速层调参利用闭环反向传播的扩展评估损失；3）集成多普勒激光雷达提供障碍物速度和位置测量以增强运动预测。

Result: 在高保真模拟器上的大量实验表明，HPTune实现了高效的MPC调参，在复杂环境中优于各种基线方案。HPTune能够通过制定安全、敏捷的避撞策略实现情境定制的运动规划。

Conclusion: HPTune框架通过扩展评估范围到未执行动作，结合分层调参和多普勒激光雷达集成，显著提升了MPC运动规划器的参数调优效率和适应性，实现了更安全、更敏捷的避撞策略。

Abstract: Parameter tuning is a powerful approach to enhance adaptability in model predictive control (MPC) motion planners. However, existing methods typically operate in a myopic fashion that only evaluates executed actions, leading to inefficient parameter updates due to the sparsity of failure events (e.g., obstacle nearness or collision). To cope with this issue, we propose to extend evaluation from executed to non-executed actions, yielding a hierarchical proactive tuning (HPTune) framework that combines both a fast-level tuning and a slow-level tuning. The fast one adopts risk indicators of predictive closing speed and predictive proximity distance, and the slow one leverages an extended evaluation loss for closed-loop backpropagation. Additionally, we integrate HPTune with the Doppler LiDAR that provides obstacle velocities apart from position-only measurements for enhanced motion predictions, thus facilitating the implementation of HPTune. Extensive experiments on high-fidelity simulator demonstrate that HPTune achieves efficient MPC tuning and outperforms various baseline schemes in complex environments. It is found that HPTune enables situation-tailored motion planning by formulating a safe, agile collision avoidance strategy.

</details>


### [32] [Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning](https://arxiv.org/abs/2601.21548)
*Irene Ambrosini,Ingo Blakowski,Dmitrii Zendrikov,Cristiano Capone,Luna Gava,Giacomo Indiveri,Chiara De Luca,Chiara Bartolozzi*

Main category: cs.RO

TL;DR: 使用脉冲神经网络在神经形态处理器上实现空气曲棍球实时学习，通过硬件-算法协同设计实现快速强化学习


<details>
  <summary>Details</summary>
Motivation: 空气曲棍球需要在高速度下做出瞬间决策，传统方法难以应对。研究旨在将神经科学启发的硬件与真实世界机器人控制结合，展示脑启发方法能够处理快速交互任务并支持持续学习

Method: 采用混合信号模拟/数字神经形态处理器上的脉冲神经网络，通过硬件-算法协同设计。使用固定随机连接捕捉任务时间结构，在读出层采用局部e-prop学习规则，利用事件驱动活动进行快速高效学习。通过计算机和神经形态芯片的实时循环设置进行强化学习训练

Result: 系统在极少试验次数内成功实现冰球交互，展示了实时学习能力。神经形态芯片能够支持脉冲神经网络的实用训练，为机器人自主系统提供解决方案

Conclusion: 这项工作成功将神经科学启发的硬件与真实世界机器人控制连接起来，证明脑启发方法能够处理快速交互任务，同时支持智能机器的持续在线学习，为机器人自主系统开辟了新途径

Abstract: Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.

</details>


### [33] [From Instruction to Event: Sound-Triggered Mobile Manipulation](https://arxiv.org/abs/2601.21667)
*Hao Ju,Shaofei Huang,Hongyu Li,Zihan Ding,Si Liu,Meng Wang,Zhedong Zheng*

Main category: cs.RO

TL;DR: 提出声音触发的移动操作任务，让机器人主动感知声音物体而非依赖预设指令，开发Habitat-Echo数据平台和分层基线模型，实验证明能有效处理动态声学事件


<details>
  <summary>Details</summary>
Motivation: 当前移动操作研究主要遵循指令驱动范式，机器人依赖预设文本命令执行任务，这限制了其自主性和对动态环境事件的响应能力

Method: 1) 引入声音触发的移动操作任务；2) 开发Habitat-Echo数据平台，集成声学渲染与物理交互；3) 提出包含高层任务规划器和低层策略模型的分层基线

Result: 实验表明基线模型使机器人能主动检测和响应听觉事件，无需逐案例指令。在挑战性的双声源场景中，机器人成功从重叠声学干扰中分离主要声源执行首次交互，随后操作次要物体

Conclusion: 声音触发移动操作增强了机器人自主性，Habitat-Echo平台和分层基线模型为处理动态声学事件提供了有效解决方案，验证了方法的鲁棒性

Abstract: Current mobile manipulation research predominantly follows an instruction-driven paradigm, where agents rely on predefined textual commands to execute tasks. However, this setting confines agents to a passive role, limiting their autonomy and ability to react to dynamic environmental events. To address these limitations, we introduce sound-triggered mobile manipulation, where agents must actively perceive and interact with sound-emitting objects without explicit action instructions. To support these tasks, we develop Habitat-Echo, a data platform that integrates acoustic rendering with physical interaction. We further propose a baseline comprising a high-level task planner and low-level policy models to complete these tasks. Extensive experiments show that the proposed baseline empowers agents to actively detect and respond to auditory events, eliminating the need for case-by-case instructions. Notably, in the challenging dual-source scenario, the agent successfully isolates the primary source from overlapping acoustic interference to execute the first interaction, and subsequently proceeds to manipulate the secondary object, verifying the robustness of the baseline.

</details>


### [34] [mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning](https://arxiv.org/abs/2601.22074)
*Kevin Zakka,Qiayuan Liao,Brent Yi,Louis Le Lay,Koushil Sreenath,Pieter Abbeel*

Main category: cs.RO

TL;DR: mjlab是一个轻量级开源机器人学习框架，结合GPU加速仿真、可组合环境和最小化设置摩擦，提供单命令安装和原生MuJoCo数据结构访问。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习框架通常设置复杂、依赖众多，需要更轻量、易用且高性能的解决方案。mjlab旨在提供最小化设置摩擦的GPU加速仿真环境，降低机器人学习研究门槛。

Method: 采用Isaac Lab引入的manager-based API，用户可组合模块化构建块（观测、奖励、事件），结合MuJoCo Warp实现GPU加速物理仿真，提供单命令安装和最小依赖。

Result: 开发出轻量级开源框架mjlab，提供速度跟踪、运动模仿和操作任务的参考实现，支持直接访问原生MuJoCo数据结构，安装简单且依赖少。

Conclusion: mjlab成功创建了一个易用、高性能的机器人学习框架，通过GPU加速和模块化设计降低了研究门槛，为机器人学习社区提供了实用的工具。

Abstract: We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.

</details>
