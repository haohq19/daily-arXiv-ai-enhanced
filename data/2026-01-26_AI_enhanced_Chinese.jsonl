{"id": "2601.16406", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16406", "abs": "https://arxiv.org/abs/2601.16406", "authors": ["Vitaly Bulgakov", "Alexander Turchin"], "title": "Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction", "comment": "28 pages, 12 figures, provisional patent", "summary": "Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.", "AI": {"tldr": "LPCORP\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u589e\u5f3a\u9884\u6d4b\u548c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u7ed3\u679c\u4fee\u6b63\u6765\u89e3\u51b3\u7f55\u89c1\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7cbe\u5ea6\u5e76\u964d\u4f4e\u76f8\u5173\u6210\u672c\u3002", "motivation": "\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u53ef\u9760\u6027\u5de5\u7a0b\u7b49\u5173\u952e\u9886\u57df\uff0c\u7f55\u89c1\u4e8b\u4ef6\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6781\u7aef\u7c7b\u522b\u4e0d\u5e73\u8861\u5bfc\u81f4\u4f20\u7edf\u6a21\u578b\u504f\u5411\u591a\u6570\u7c7b\u9884\u6d4b\uff0c\u9650\u5236\u4e86\u53ec\u56de\u7387\u3001\u6821\u51c6\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u63d0\u51faLPCORP\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u63a8\u7406\u6a21\u578b\u4ece\u53d9\u8ff0\u8f93\u5165\u751f\u6210\u589e\u5f3a\u9884\u6d4b\uff1b2) \u8f7b\u91cf\u7ea7\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\u8bc4\u4f30\u5e76\u9009\u62e9\u6027\u4fee\u6b63\u8fd9\u4e9b\u8f93\u51fa\uff0c\u4ee5\u51cf\u8f7b\u6d41\u884c\u5ea6\u9a71\u52a8\u7684\u504f\u5dee\u3002", "result": "\u5728\u533b\u7597\u548c\u6d88\u8d39\u8005\u670d\u52a1\u9886\u57df\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5c06\u9ad8\u5ea6\u4e0d\u5e73\u8861\u8bbe\u7f6e\u8f6c\u5316\u4e3a\u5e73\u8861\u8bbe\u7f6e\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u6837\u672c\u6570\u91cf\u4e14\u65e0\u9700\u91cd\u91c7\u6837\u7b56\u7565\uff0c\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662f\u7cbe\u5ea6\u65b9\u9762\u3002\u6210\u672c\u964d\u4f4e\u5206\u6790\u663e\u793a\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u51cf\u5c1150%\u4ee5\u4e0a\u8d39\u7528\u3002", "conclusion": "LPCORP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7f55\u89c1\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u63a8\u7406\u589e\u5f3a\u548c\u9009\u62e9\u6027\u4fee\u6b63\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u663e\u8457\u7684\u6210\u672c\u8282\u7ea6\u6f5c\u529b\u3002"}}
{"id": "2601.16333", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16333", "abs": "https://arxiv.org/abs/2601.16333", "authors": ["Aditya K Surikuchi", "Raquel Fern\u00e1ndez", "Sandro Pezzelle"], "title": "Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments", "comment": null, "summary": "Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u8bc6\u522b\u8db3\u7403\u89c6\u9891\u91cd\u8981\u5b50\u4e8b\u4ef6\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u4e3b\u8981\u4f9d\u8d56\u5355\u4e00\u6a21\u6001\u4e14\u65e0\u6cd5\u6709\u6548\u6574\u5408\u591a\u6e90\u4fe1\u606f\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u6d89\u53ca\u65f6\u5e8f\u591a\u6a21\u6001\u4e8b\u4ef6\u7684\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6a21\u578b\u8bc6\u522b\u89c6\u9891\u4e2d\u91cd\u8981\u5b50\u4e8b\u4ef6\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u8be5\u80fd\u529b\u662f\u53d9\u8ff0\u6216\u603b\u7ed3\u591a\u6a21\u6001\u4e8b\u4ef6\u7684\u57fa\u672c\u524d\u63d0\uff0c\u7279\u522b\u662f\u5728\u8db3\u7403\u6bd4\u8d5b\u573a\u666f\u4e2d\u3002", "method": "\u6784\u5efa\u65b0\u6570\u636e\u96c6\uff1a\u5229\u7528\u8db3\u7403\u6bd4\u8d5b\u7cbe\u5f69\u96c6\u9526\u4e2d\u9690\u542b\u7684\u4eba\u7c7b\u91cd\u8981\u6027\u504f\u597d\uff0c\u65e0\u9700\u989d\u5916\u6807\u6ce8\u6210\u672c\u3002\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u591a\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5206\u6790\u6a21\u578b\u8868\u73b0\u5e76\u8d85\u8d8a\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "result": "\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u5206\u6790\u663e\u793a\u6a21\u578b\u503e\u5411\u4e8e\u4f9d\u8d56\u5355\u4e00\u4e3b\u5bfc\u6a21\u6001\uff0c\u65e0\u6cd5\u6709\u6548\u5408\u6210\u6765\u81ea\u591a\u4e2a\u6765\u6e90\u7684\u5fc5\u8981\u4fe1\u606f\u3002", "conclusion": "\u9700\u8981\u6a21\u5757\u5316\u67b6\u6784\u6765\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u4e2d\u7684\u6837\u672c\u7ea7\u5f02\u8d28\u6027\uff0c\u4ee5\u53ca\u4e92\u8865\u7684\u8bad\u7ec3\u7a0b\u5e8f\u6765\u6700\u5927\u5316\u8de8\u6a21\u6001\u534f\u540c\u6548\u5e94\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u8bc6\u522b\u91cd\u8981\u4e8b\u4ef6\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.16411", "categories": ["cs.LG", "math.CA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.16411", "abs": "https://arxiv.org/abs/2601.16411", "authors": ["A. Iosevich", "A. Vagharshakyan", "E. Wyman"], "title": "A Refinement of Vapnik--Chervonenkis' Theorem", "comment": null, "summary": "Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.\n  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\\varepsilon\\sqrt{n})^{-1}$ in the leading exponential term when $\\varepsilon\\sqrt{n}$ is large.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4f7f\u7528\u5177\u6709\u663e\u5f0fBerry-Esseen\u8bef\u5dee\u63a7\u5236\u7684\u6b63\u6001\u8fd1\u4f3c\u4ee3\u66ffHoeffding\u4e0d\u7b49\u5f0f\uff0c\u6539\u8fdb\u4e86\u7ecf\u5178\u7684Vapnik-Chervonenkis\u5b9a\u7406\uff0c\u5728\u03b5\u221an\u8f83\u5927\u65f6\u83b7\u5f97\u4e86\u66f4\u7cbe\u786e\u7684\u5747\u5300\u6536\u655b\u901f\u7387\u4f30\u8ba1\u3002", "motivation": "\u7ecf\u5178VC\u5b9a\u7406\u4f7f\u7528Hoeffding\u4e0d\u7b49\u5f0f\u4f5c\u4e3a\u6700\u540e\u4e00\u6b65\uff0c\u4f5c\u8005\u5e0c\u671b\u6539\u8fdb\u8fd9\u4e00\u65b9\u6cd5\u4ee5\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u6536\u655b\u901f\u7387\u4f30\u8ba1\uff0c\u7279\u522b\u662f\u5728\u4e2d\u7b49\u504f\u5dee\u8303\u56f4\u5185\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u7ecf\u5178VC\u5b9a\u7406\u7684\u6982\u7387\u90e8\u5206\uff0c\u4f7f\u7528\u5177\u6709\u663e\u5f0fBerry-Esseen\u8bef\u5dee\u63a7\u5236\u7684\u6b63\u6001\u8fd1\u4f3c\u4ee3\u66ffHoeffding\u4e0d\u7b49\u5f0f\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u7cbe\u7ec6\u7684\u6536\u655b\u901f\u7387\u4f30\u8ba1\u3002", "result": "\u5f97\u5230\u4e86VC\u4f30\u8ba1\u7684\u4e2d\u7b49\u504f\u5dee\u9510\u5316\u7248\u672c\uff0c\u5f53\u03b5\u221an\u8f83\u5927\u65f6\uff0c\u5728\u4e3b\u8981\u6307\u6570\u9879\u4e2d\u83b7\u5f97\u4e86\u989d\u5916\u7684(\u03b5\u221an)^{-1}\u9636\u56e0\u5b50\uff0c\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u5747\u5300\u6536\u655b\u901f\u7387\u4f30\u8ba1\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u66f4\u7cbe\u786e\u7684\u6b63\u6001\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e86\u7ecf\u5178VC\u5b9a\u7406\u7684\u6536\u655b\u901f\u7387\u4f30\u8ba1\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2601.16309", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.16309", "abs": "https://arxiv.org/abs/2601.16309", "authors": ["Dikshya Mohanty", "Taisiia Sabadyn", "Jelwin Rodrigues", "Chenlu Wang", "Abhishek Kalugade", "Ritwik Banerjee"], "title": "A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War", "comment": null, "summary": "We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.", "AI": {"tldr": "DNIPRO\u662f\u4e00\u4e2a\u5305\u542b24.6\u4e07\u7bc7\u65b0\u95fb\u6587\u7ae0\u7684\u591a\u8bed\u8a00\u8bed\u6599\u5e93\uff0c\u8bb0\u5f55\u4e862022\u5e742\u6708\u81f32024\u5e748\u6708\u7684\u4fc4\u4e4c\u6218\u4e89\uff0c\u6db5\u76d611\u5bb6\u5a92\u4f53\u30015\u4e2a\u56fd\u5bb6\uff08\u4fc4\u3001\u4e4c\u3001\u7f8e\u3001\u82f1\u3001\u4e2d\uff09\u548c3\u79cd\u8bed\u8a00\uff08\u82f1\u3001\u4fc4\u3001\u4e2d\u6587\uff09\uff0c\u7528\u4e8e\u7814\u7a76\u6218\u65f6\u4e89\u8bae\u6027\u8bdd\u8bed\u7684\u8de8\u56fd\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u8d44\u6e90\u7f3a\u4e4f\u5bf9\u4fc4\u4e4c\u6218\u4e89\u7684\u591a\u8bed\u8a00\u3001\u8de8\u56fd\u5a92\u4f53\u8986\u76d6\u7684\u7cfb\u7edf\u6027\u8bb0\u5f55\uff0c\u9700\u8981\u5305\u542b\u7ade\u4e89\u6027\u5730\u7f18\u653f\u6cbb\u89c6\u89d2\u7684\u8bed\u6599\u5e93\u6765\u7814\u7a76\u53d9\u4e8b\u5206\u6b67\u3001\u5a92\u4f53\u6846\u67b6\u548c\u4fe1\u606f\u6218\u3002", "method": "\u6784\u5efa\u5305\u542b24.6\u4e07\u7bc7\u65b0\u95fb\u6587\u7ae0\u7684\u7eb5\u5411\u8bed\u6599\u5e93\uff0c\u6db5\u76d611\u5bb6\u5a92\u4f53\u673a\u6784\uff0c\u8de8\u8d8a5\u4e2a\u56fd\u5bb6\u30013\u79cd\u8bed\u8a00\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684\u5143\u6570\u636e\u548c\u591a\u79cd\u6ce8\u91ca\u7c7b\u578b\uff0c\u5e76\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u4eba\u5de5\u8bc4\u4f30\u3002", "result": "\u521b\u5efa\u4e86DNIPRO\u8bed\u6599\u5e93\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7acb\u573a\u68c0\u6d4b\u3001\u60c5\u611f\u5206\u6790\u3001\u4e3b\u9898\u6846\u67b6\u548c\u77db\u76fe\u5206\u6790\u7b49\u7528\u4f8b\u5b9e\u9a8c\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u63ed\u793a\u4e86\u5a92\u4f53\u5982\u4f55\u6784\u5efa\u7ade\u4e89\u6027\u73b0\u5b9e\uff0c\u62a5\u9053\u5448\u73b0\u53cd\u6620\u5730\u7f18\u653f\u6cbb\u5229\u76ca\u7684\u6781\u5316\u89e3\u91ca\u3002", "conclusion": "DNIPRO\u4e3a\u7406\u89e3\u51b2\u7a81\u6027\u53d9\u4e8b\u5982\u4f55\u5728\u5168\u7403\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u4e2d\u51fa\u73b0\u548c\u6f14\u53d8\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\uff0c\u4e0d\u4ec5\u652f\u6301\u8ba1\u7b97\u65b0\u95fb\u5b66\u7814\u7a76\uff0c\u8fd8\u80fd\u4fc3\u8fdb\u5bf9\u6218\u65f6\u8bdd\u8bed\u7684\u7cfb\u7edf\u6027\u8de8\u56fd\u5206\u6790\u3002"}}
{"id": "2601.16909", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16909", "abs": "https://arxiv.org/abs/2601.16909", "authors": ["Lei You", "Lele Cao", "Iryna Gurevych"], "title": "Preventing the Collapse of Peer Review Requires Verification-First AI", "comment": null, "summary": "This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20AI\u8f85\u52a9\u540c\u884c\u8bc4\u5ba1\u5e94\u91c7\u7528\"\u9a8c\u8bc1\u4f18\u5148\"\u800c\u975e\"\u6a21\u4eff\u8bc4\u5ba1\"\u8303\u5f0f\uff0c\u63d0\u51fa\"\u771f\u76f8\u8026\u5408\"\u4f5c\u4e3a\u8bc4\u5ba1\u5de5\u5177\u7684\u6b63\u786e\u76ee\u6807\uff0c\u5e76\u5206\u6790\u5bfc\u81f4\u8bc4\u5ba1\u7cfb\u7edf\u8f6c\u5411\u4ee3\u7406\u6307\u6807\u4e3b\u5bfc\u7684\u4e24\u79cd\u529b\u91cf", "motivation": "\u5f53\u524dAI\u8f85\u52a9\u8bc4\u5ba1\u7cfb\u7edf\u503e\u5411\u4e8e\u6a21\u4eff\u4eba\u7c7b\u8bc4\u5ba1\u8fc7\u7a0b\uff0c\u8fd9\u53ef\u80fd\u52a0\u5267\u79d1\u5b66\u8bc4\u4f30\u4e2d\u7684\u4ee3\u7406\u6307\u6807\u4e3b\u5bfc\u95ee\u9898\u3002\u8bba\u6587\u65e8\u5728\u91cd\u65b0\u601d\u8003AI\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u89d2\u8272\uff0c\u9632\u6b62\u8bc4\u5ba1\u7cfb\u7edf\u4ece\u8ffd\u6c42\u79d1\u5b66\u771f\u76f8\u8f6c\u5411\u4f18\u5316\u4ee3\u7406\u6307\u6807", "method": "\u63d0\u51fa\"\u771f\u76f8\u8026\u5408\"\u4f5c\u4e3a\u8bc4\u5ba1\u5de5\u5177\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u538b\u529b\u548c\u4fe1\u53f7\u6536\u7f29\u4e24\u79cd\u529b\u91cf\uff0c\u5efa\u7acb\u5305\u542b\u9ad8\u4fdd\u771f\u68c0\u67e5\u548c\u9891\u7e41\u4ee3\u7406\u5224\u65ad\u7684\u6700\u5c0f\u6a21\u578b\uff0c\u63a8\u5bfc\u8026\u5408\u5b9a\u5f8b\u548c\u6fc0\u52b1\u5d29\u6e83\u6761\u4ef6", "result": "\u5728\u6700\u5c0f\u6a21\u578b\u4e2d\u63a8\u5bfc\u51fa\u660e\u786e\u7684\u8026\u5408\u5b9a\u5f8b\uff0c\u8bc6\u522b\u51fa\u6fc0\u52b1\u5d29\u6e83\u6761\u4ef6\uff1a\u5373\u4f7f\u5f53\u524d\u51b3\u7b56\u770b\u8d77\u6765\u53ef\u9760\uff0c\u7406\u6027\u52aa\u529b\u4e5f\u4f1a\u4ece\u8ffd\u6c42\u771f\u76f8\u8f6c\u5411\u4f18\u5316\u4ee3\u7406\u6307\u6807", "conclusion": "AI\u5e94\u4f5c\u4e3a\u5bf9\u6297\u6027\u5ba1\u8ba1\u5de5\u5177\uff0c\u751f\u6210\u53ef\u5ba1\u8ba1\u7684\u9a8c\u8bc1\u5de5\u4ef6\u5e76\u6269\u5c55\u6709\u6548\u9a8c\u8bc1\u5e26\u5bbd\uff0c\u800c\u4e0d\u662f\u4f5c\u4e3a\u5206\u6570\u9884\u6d4b\u5668\u653e\u5927\u58f0\u660e\u81a8\u80c0\u3002\u5de5\u5177\u6784\u5efa\u8005\u548c\u7a0b\u5e8f\u4e3b\u5e2d\u5e94\u91c7\u53d6\u76f8\u5e94\u884c\u52a8"}}
{"id": "2601.16531", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16531", "abs": "https://arxiv.org/abs/2601.16531", "authors": ["Tao Lin"], "title": "A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics", "comment": null, "summary": "We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.\n  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent \"hot-to-cold advantage flip\" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.\n  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.", "AI": {"tldr": "\u9ad8\u9891\u952e\u78b0\u649e\u4e0d\u662fEngram\u5f0f\u6761\u4ef6\u8bb0\u5fc6\u7684\u4e3b\u8981\u74f6\u9888\u3002\u901a\u8fc7\u78b0\u649e\u81ea\u7531\u8bbe\u8ba1\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5355\u7eaf\u63d0\u9ad8\u67e5\u627e\u7cbe\u5ea6\u5e76\u4e0d\u80fd\u6539\u5584\u8bad\u7ec3\u6548\u679c\uff0c\u78b0\u649e\u566a\u58f0\u53cd\u800c\u63d0\u4f9b\u6709\u76ca\u7684\u6b63\u5219\u5316\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u9ad8\u9891\u952e\u78b0\u649e\u662f\u5426\u662fEngram\u5f0f\u6761\u4ef6\u8bb0\u5fc6\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u63a2\u7a76\u5355\u7eaf\u6d88\u9664\u78b0\u649e\u662f\u5426\u771f\u7684\u80fd\u6539\u5584\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5f15\u5165Engram-Nine\u78b0\u649e\u81ea\u7531\u70ed\u5c42\u6269\u5c55\uff0c\u4f7f\u7528\u6700\u5c0f\u5b8c\u7f8e\u54c8\u5e0c\u51fd\u6570\u6620\u5c04\u6700\u9ad8\u9891n-gram\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u591a\u5934\u54c8\u5e0c\u67e5\u627e\u4f5c\u4e3a\u51b7\u5c42\u3002\u5728\u4e25\u683c\u7b49\u53c2\u6570\u8bbe\u7f6e\u4e0b\uff0c\u901a\u8fc7\u8def\u7531\u5206\u5c42\u8bc4\u4f30\u5206\u89e3\u6bcf\u4e2atoken\u7684\u635f\u5931\u4e3a\u70ed/\u51b7\u5c42\u8d21\u732e\u3002", "result": "\u78b0\u649e\u81ea\u7531\u8bbe\u8ba1\u5e76\u672a\u6301\u7eed\u6539\u5584\u9a8c\u8bc1\u635f\u5931\u3002\u53d1\u73b0\u8bad\u7ec3\u4e2d\u5b58\u5728\u4e00\u81f4\u7684\"\u70ed\u5230\u51b7\u4f18\u52bf\u7ffb\u8f6c\"\u73b0\u8c61\uff1a\u70ed\u4f4d\u7f6e\u521d\u59cb\u635f\u5931\u8f83\u4f4e\uff0c\u4f46\u51b7\u4f4d\u7f6e\u6700\u7ec8\u8d85\u8d8a\u3002\u78b0\u649e\u81ea\u7531\u914d\u7f6e\u6bd4\u78b0\u649e\u57fa\u7ebf\u66f4\u65e9\u7ffb\u8f6c\uff0c\u8868\u660e\u78b0\u649e\u8d77\u5230\u9690\u5f0f\u6b63\u5219\u5316\u4f5c\u7528\u3002\u8fd8\u53d1\u73b0\u95e8\u63a7\u5931\u914d\u95ee\u9898\u3002", "conclusion": "\u5355\u7eaf\u63d0\u9ad8\u67e5\u627e\u7cbe\u5ea6\u4e0d\u80fd\u4fdd\u8bc1\u66f4\u597d\u7684\u8bad\u7ec3\u7ed3\u679c\u3002\u4e3b\u8981\u9650\u5236\u53ef\u80fd\u5728\u4e8e\u95e8\u63a7\u4fe1\u7528\u5206\u914d\u800c\u975e\u7d22\u5f15\u7cbe\u5ea6\uff0c\u78b0\u649e\u5f15\u8d77\u7684\u566a\u58f0\u53ef\u80fd\u63d0\u4f9b\u6709\u76ca\u7684\u6b63\u5219\u5316\uff0c\u4e0d\u5e94\u7b80\u5355\u6d88\u9664\u3002"}}
{"id": "2601.16632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16632", "abs": "https://arxiv.org/abs/2601.16632", "authors": ["Haonan Yang", "Jianchao Tang", "Zhuo Li"], "title": "Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting", "comment": null, "summary": "Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.", "AI": {"tldr": "DPAD\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u8f85\u52a9\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u539f\u578b\u81ea\u9002\u5e94\u89e3\u8026\u673a\u5236\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u6a21\u5f0f\u89e3\u8026\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u4fee\u6539\u67b6\u6784\u6216\u5f15\u5165\u589e\u5f3a\u7b56\u7565\u6765\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u52a8\u6001\u89e3\u8026\u548c\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u4e2d\u590d\u6742\u4ea4\u7ec7\u7684\u65f6\u5e8f\u6a21\u5f0f\uff0c\u5bfc\u81f4\u5b66\u4e60\u5230\u9759\u6001\u3001\u5e73\u5747\u5316\u7684\u8868\u793a\uff0c\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u53cc\u539f\u578b\u81ea\u9002\u5e94\u89e3\u8026\u6846\u67b6(DPAD)\uff1a1)\u6784\u5efa\u52a8\u6001\u53cc\u539f\u578b\u5e93(DDP)\uff0c\u5305\u542b\u5177\u6709\u5f3a\u65f6\u5e8f\u5148\u9a8c\u7684\u5e38\u89c1\u6a21\u5f0f\u5e93\u548c\u52a8\u6001\u8bb0\u5fc6\u5173\u952e\u4f46\u7f55\u89c1\u4e8b\u4ef6\u7684\u7f55\u89c1\u6a21\u5f0f\u5e93\uff1b2)\u8bbe\u8ba1\u53cc\u8def\u5f84\u4e0a\u4e0b\u6587\u611f\u77e5\u8def\u7531(DPC)\u673a\u5236\uff0c\u4eceDDP\u4e2d\u9009\u62e9\u6027\u68c0\u7d22\u4e0a\u4e0b\u6587\u7279\u5b9a\u6a21\u5f0f\u8868\u793a\u6765\u589e\u5f3a\u8f93\u51fa\uff1b3)\u5f15\u5165\u89e3\u8026\u5f15\u5bfc\u635f\u5931(DGLoss)\u786e\u4fdd\u6bcf\u4e2a\u539f\u578b\u5e93\u4e13\u6ce8\u4e8e\u5176\u6307\u5b9a\u89d2\u8272\u540c\u65f6\u4fdd\u6301\u5168\u9762\u8986\u76d6\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cDPAD\u5728\u5404\u79cd\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u80fd\u591f\u4e00\u81f4\u5730\u63d0\u5347\u6700\u5148\u8fdb\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "conclusion": "DPAD\u6846\u67b6\u901a\u8fc7\u6a21\u5f0f\u89e3\u8026\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u9002\u5e94\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u52a8\u6001\u5904\u7406\u590d\u6742\u65f6\u5e8f\u6a21\u5f0f\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u6a21\u578b\u65e0\u5173\u7684\u589e\u5f3a\u65b9\u6848\u3002"}}
{"id": "2601.16512", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16512", "abs": "https://arxiv.org/abs/2601.16512", "authors": ["Hoang-Quoc Nguyen-Son", "Minh-Son Dao", "Koji Zettsu"], "title": "SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine", "comment": "EACL 2026 camera ready (Main Track)", "summary": "With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.", "AI": {"tldr": "SearchLLM\uff1a\u4e00\u79cd\u5229\u7528\u641c\u7d22\u5f15\u64ce\u68c0\u6d4bLLM\u6539\u5199\u6587\u672c\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u627e\u6f5c\u5728\u539f\u6587\u6765\u6e90\u5e76\u5206\u6790\u76f8\u4f3c\u6027\u6765\u8bc6\u522bLLM\u6539\u5199\u5185\u5bb9\uff0c\u53ef\u589e\u5f3a\u73b0\u6709\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u7528\u6237\u5e38\u4f7f\u7528LLM\u6539\u5199\u6587\u672c\u4ee5\u63d0\u5347\u8d28\u91cf\uff0c\u4f46\u8fd9\u53ef\u80fd\u5bfc\u81f4\u539f\u610f\u4e22\u5931\u6216\u626d\u66f2\u3002\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u8bc6\u522bLLM\u751f\u6210\u7684\u7c7b\u4eba\u6587\u672c\uff0c\u7279\u522b\u662f\u5f53\u6539\u5199\u5185\u5bb9\u4e0e\u539f\u6587\u9ad8\u5ea6\u76f8\u4f3c\u65f6\u3002", "method": "\u63d0\u51faSearchLLM\u65b9\u6cd5\uff0c\u5229\u7528\u641c\u7d22\u5f15\u64ce\u67e5\u627e\u6f5c\u5728\u539f\u6587\u6765\u6e90\uff0c\u901a\u8fc7\u5206\u6790\u8f93\u5165\u6587\u672c\u4e0e\u5019\u9009\u6765\u6e90\u518d\u751f\u7248\u672c\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6765\u8bc6\u522bLLM\u6539\u5199\u5185\u5bb9\u3002\u8be5\u65b9\u6cd5\u8bbe\u8ba1\u4e3a\u4ee3\u7406\u5c42\uff0c\u53ef\u4e0e\u73b0\u6709\u68c0\u6d4b\u5668\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSearchLLM\u80fd\u6301\u7eed\u63d0\u5347\u6700\u65b0\u68c0\u6d4b\u5668\u5728\u8bc6\u522b\u9ad8\u5ea6\u6a21\u4eff\u539f\u6587\u7684LLM\u6539\u5199\u6587\u672c\u65b9\u9762\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5e2e\u52a9\u68c0\u6d4b\u5668\u9632\u6b62\u6539\u5199\u653b\u51fb\u3002", "conclusion": "SearchLLM\u4e3a\u68c0\u6d4bLLM\u6539\u5199\u6587\u672c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u641c\u7d22\u5f15\u64ce\u8f85\u52a9\u589e\u5f3a\u4e86\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u8bc6\u522b\u9ad8\u8d28\u91cf\u6539\u5199\u5185\u5bb9\u7684\u95ee\u9898\u3002"}}
{"id": "2601.16905", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16905", "abs": "https://arxiv.org/abs/2601.16905", "authors": ["Andy Zhu", "Rongzhe Wei", "Yupu Gu", "Pan Li"], "title": "GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints", "comment": null, "summary": "Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.", "AI": {"tldr": "GRIP\u6846\u67b6\u901a\u8fc7\u51e0\u4f55\u7ea6\u675f\u4fdd\u62a4MoE\u6a21\u578b\u7684\u8def\u7531\u7a33\u5b9a\u6027\uff0c\u9632\u6b62\u4f20\u7edf\u9057\u5fd8\u65b9\u6cd5\u5229\u7528\u8def\u7531\u6f0f\u6d1e\u8fdb\u884c\u8868\u9762\u9057\u5fd8\uff0c\u771f\u6b63\u4ece\u4e13\u5bb6\u53c2\u6570\u4e2d\u64e6\u9664\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u7528\u4e8eMoE\u67b6\u6784\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f1a\u5229\u7528\u8def\u7531\u5668\u7684\u8106\u5f31\u6027\u8fdb\u884c\u8868\u9762\u9057\u5fd8\uff08\u901a\u8fc7\u64cd\u7eb5\u8def\u7531\u5668\u5c06\u67e5\u8be2\u4ece\u77e5\u8bc6\u4e13\u5bb6\u5904\u91cd\u5b9a\u5411\uff09\uff0c\u800c\u4e0d\u662f\u771f\u6b63\u64e6\u9664\u77e5\u8bc6\uff0c\u5bfc\u81f4\u6a21\u578b\u6548\u7528\u635f\u5931\u548c\u8868\u9762\u9057\u5fd8\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u8def\u7531\u4e0d\u53d8\u6027\u4fdd\u62a4\uff08GRIP\uff09\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u901a\u8fc7\u5c06\u8def\u7531\u5668\u68af\u5ea6\u66f4\u65b0\u6295\u5f71\u5230\u4e13\u5bb6\u7279\u5b9a\u7684\u96f6\u7a7a\u95f4\u6765\u5b9e\u73b0\u51e0\u4f55\u7ea6\u675f\u3002\u8fd9\u89e3\u8026\u4e86\u8def\u7531\u7a33\u5b9a\u6027\u4e0e\u53c2\u6570\u521a\u6027\uff1a\u79bb\u6563\u4e13\u5bb6\u9009\u62e9\u4fdd\u6301\u7a33\u5b9a\u4ee5\u4fdd\u7559\u77e5\u8bc6\uff0c\u800c\u8fde\u7eed\u8def\u7531\u5668\u53c2\u6570\u5728\u96f6\u7a7a\u95f4\u5185\u4fdd\u6301\u53ef\u5851\u6027\uff0c\u5141\u8bb8\u6a21\u578b\u8fdb\u884c\u5fc5\u8981\u7684\u5185\u90e8\u91cd\u6784\u4ee5\u6ee1\u8db3\u9057\u5fd8\u76ee\u6807\u3002", "result": "\u5927\u89c4\u6a21MoE\u6a21\u578b\u5b9e\u9a8c\u8868\u660e\uff0cGRIP\u9002\u914d\u5668\u6d88\u9664\u4e86\u4e13\u5bb6\u9009\u62e9\u504f\u79fb\uff08\u5b9e\u73b0\u8d85\u8fc795%\u7684\u8def\u7531\u7a33\u5b9a\u6027\uff09\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u6240\u6709\u6d4b\u8bd5\u9057\u5fd8\u65b9\u6cd5\u7684\u6548\u7528\u3002\u901a\u8fc7\u9632\u6b62\u73b0\u6709\u7b97\u6cd5\u5229\u7528MoE\u6a21\u578b\u7684\u8def\u7531\u6f0f\u6d1e\uff0cGRIP\u5c06\u73b0\u6709\u9057\u5fd8\u7814\u7a76\u4ece\u5bc6\u96c6\u67b6\u6784\u9002\u914d\u5230MoE\u3002", "conclusion": "GRIP\u4f5c\u4e3a\u4e00\u4e2a\u7b97\u6cd5\u65e0\u5173\u7684\u9002\u914d\u5668\u6846\u67b6\uff0c\u901a\u8fc7\u51e0\u4f55\u7ea6\u675f\u4fdd\u62a4\u8def\u7531\u7a33\u5b9a\u6027\uff0c\u5f3a\u5236\u9057\u5fd8\u4f18\u5316\u76f4\u63a5\u4ece\u4e13\u5bb6\u53c2\u6570\u4e2d\u64e6\u9664\u77e5\u8bc6\uff0c\u800c\u4e0d\u662f\u5229\u7528\u8868\u9762\u8def\u7531\u5668\u64cd\u7eb5\u7684\u6377\u5f84\uff0c\u4ece\u800c\u6709\u6548\u89e3\u51b3MoE\u67b6\u6784\u7684\u673a\u5668\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2601.16724", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16724", "abs": "https://arxiv.org/abs/2601.16724", "authors": ["Kevin Fan", "Eric Yun"], "title": "Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach", "comment": null, "summary": "As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u5bf9ESL\u5b66\u4e60\u8005\u7684\u7b97\u6cd5\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u5339\u914d\u4f5c\u6587\u5bf9\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9ad8\u719f\u7ec3\u5ea6ESL\u4f5c\u6587\u7684\u8bc4\u5206\u5dee\u8ddd\u3002", "motivation": "\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u6559\u80b2\u573a\u666f\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u56de\u5f52\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u6bcd\u8bed\u8005\u8bed\u6599\u8bad\u7ec3\uff0c\u5bb9\u6613\u5b66\u4e60\u5230L2\u8bed\u8a00\u8868\u9762\u7279\u5f81\u4e0e\u4f5c\u6587\u8d28\u91cf\u4e4b\u95f4\u7684\u865a\u5047\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u5bf9ESL\u5b66\u4e60\u8005\u7684\u7b97\u6cd5\u504f\u89c1\u3002", "method": "\u63d0\u51fa\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u4e09\u5143\u7ec4\u6784\u5efa\u7b56\u7565\uff1a\u5339\u914d\u4f5c\u6587\u5bf9\u5bf9\u6bd4\u5b66\u4e60\u3002\u6784\u5efa\u4e8617,161\u5bf9\u5339\u914d\u4f5c\u6587\u5bf9\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u4e09\u5143\u7ec4\u8fb9\u754c\u635f\u5931\u5fae\u8c03DeBERTa-v3\u6a21\u578b\uff0c\u5bf9\u9f50ESL\u548c\u6bcd\u8bed\u5199\u4f5c\u7684\u6f5c\u5728\u8868\u793a\u3002", "result": "\u5c06\u9ad8\u719f\u7ec3\u5ea6ESL\u4f5c\u6587\u7684\u8bc4\u5206\u5dee\u8ddd\u51cf\u5c11\u4e8639.9%\uff08\u4ece10.3%\u964d\u81f36.2%\uff09\uff0c\u540c\u65f6\u4fdd\u63010.76\u7684\u4e8c\u6b21\u52a0\u6743Kappa\u503c\u3002\u540e\u9a8c\u8bed\u8a00\u5206\u6790\u8868\u660e\u6a21\u578b\u6210\u529f\u89e3\u8026\u4e86\u53e5\u5b50\u590d\u6742\u6027\u548c\u8bed\u6cd5\u9519\u8bef\uff0c\u907f\u514d\u4e86\u5bf9\u6709\u6548L2\u53e5\u6cd5\u7ed3\u6784\u7684\u60e9\u7f5a\u3002", "conclusion": "\u5339\u914d\u4f5c\u6587\u5bf9\u5bf9\u6bd4\u5b66\u4e60\u662f\u51cf\u5c11\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u4e2d\u7b97\u6cd5\u504f\u89c1\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6574\u4f53\u8bc4\u5206\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u6539\u5584\u5bf9ESL\u5b66\u4e60\u8005\u7684\u516c\u5e73\u6027\u3002"}}
