<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Optical Flow-Guided 6DoF Object Pose Tracking with an Event Camera](https://arxiv.org/abs/2512.21053)
*Zibin Liu,Banglei Guan,Yang Shang,Shunkun Liang,Zhenbao Yu,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出了一种基于事件相机的光流引导6DoF物体姿态跟踪方法，通过2D-3D混合特征提取和光流引导的角点-边缘关联，实现高精度姿态跟踪


<details>
  <summary>Details</summary>
Motivation: 传统相机在物体姿态跟踪中面临运动模糊、传感器噪声、部分遮挡和光照变化等挑战，而事件相机具有高动态范围和低延迟的优势，有望解决这些问题

Method: 1. 采用2D-3D混合特征提取策略从事件和物体模型中检测角点和边缘；2. 通过最大化时空窗口内事件关联概率搜索角点光流；3. 光流引导建立角点与边缘的关联；4. 通过最小化角点与边缘距离迭代优化6DoF物体姿态

Result: 在模拟和真实事件数据上的实验结果表明，该方法在准确性和鲁棒性方面优于当前最先进的事件基方法

Conclusion: 提出的光流引导6DoF物体姿态跟踪方法有效利用了事件相机的优势，在挑战性条件下实现了更准确和鲁棒的姿态跟踪

Abstract: Object pose tracking is one of the pivotal technologies in multimedia, attracting ever-growing attention in recent years. Existing methods employing traditional cameras encounter numerous challenges such as motion blur, sensor noise, partial occlusion, and changing lighting conditions. The emerging bio-inspired sensors, particularly event cameras, possess advantages such as high dynamic range and low latency, which hold the potential to address the aforementioned challenges. In this work, we present an optical flow-guided 6DoF object pose tracking method with an event camera. A 2D-3D hybrid feature extraction strategy is firstly utilized to detect corners and edges from events and object models, which characterizes object motion precisely. Then, we search for the optical flow of corners by maximizing the event-associated probability within a spatio-temporal window, and establish the correlation between corners and edges guided by optical flow. Furthermore, by minimizing the distances between corners and edges, the 6DoF object pose is iteratively optimized to achieve continuous pose tracking. Experimental results of both simulated and real events demonstrate that our methods outperform event-based state-of-the-art methods in terms of both accuracy and robustness.

</details>


### [2] [Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval](https://arxiv.org/abs/2512.21221)
*Dao Sy Duy Minh,Huynh Trung Kiet,Nguyen Lam Phu Quy,Phu-Hoa Pham,Tran Chi Nguyen*

Main category: cs.CV

TL;DR: 提出基于事件实体提取的轻量级两阶段图像检索方法，结合BM25过滤和BEiT-3重排序，在OpenEvents v1基准上取得0.559的mAP，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界的图像-文本检索面临模糊查询、语境依赖、语言多样性和可扩展性等挑战，需要更有效的解决方案来处理复杂场景。

Method: 采用两阶段检索流程：第一阶段使用基于事件实体的BM25进行高效候选过滤，第二阶段使用BEiT-3模型进行深度多模态语义理解和结果重排序。

Result: 在OpenEvents v1基准测试中达到0.559的平均精度均值(mAP)，显著超越先前基线方法，证明了方法的有效性。

Conclusion: 结合事件引导的过滤和长文本视觉语言建模，能够在复杂现实场景中实现准确高效的图像检索，为实际应用提供了有效解决方案。

Abstract: Retrieving images from natural language descriptions is a core task at the intersection of computer vision and natural language processing, with wide-ranging applications in search engines, media archiving, and digital content management. However, real-world image-text retrieval remains challenging due to vague or context-dependent queries, linguistic variability, and the need for scalable solutions. In this work, we propose a lightweight two-stage retrieval pipeline that leverages event-centric entity extraction to incorporate temporal and contextual signals from real-world captions. The first stage performs efficient candidate filtering using BM25 based on salient entities, while the second stage applies BEiT-3 models to capture deep multimodal semantics and rerank the results. Evaluated on the OpenEvents v1 benchmark, our method achieves a mean average precision of 0.559, substantially outperforming prior baselines. These results highlight the effectiveness of combining event-guided filtering with long-text vision-language modeling for accurate and efficient retrieval in complex, real-world scenarios. Our code is available at https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval

</details>


### [3] [Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential](https://arxiv.org/abs/2512.21284)
*Shihao Zou,Jingjing Li,Wei Ji,Jincai Huang,Kai Wang,Guo Dan,Weixin Si,Yi Pan*

Main category: cs.CV

TL;DR: 提出首个基于脉冲神经网络的实时手术场景分割框架SpikeSurgSeg，在保持与ANN模型相当精度的同时，实现8-20倍推理加速


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型（特别是大模型）虽然分割精度高，但计算需求大、功耗高，难以在资源受限的手术环境中实时部署。脉冲神经网络（SNN）作为高效计算范式具有潜力，但面临手术标注数据稀缺和手术视频表示稀疏的挑战。

Method: 提出SpikeSurgSeg框架：1）采用手术场景掩码自编码预训练策略，通过分层管状掩码实现鲁棒的时空表示学习；2）在预训练骨干网络基础上，采用轻量级脉冲驱动分割头，在保持SNN低延迟特性的同时产生时间一致的预测。

Result: 在EndoVis18和内部SurgBleed数据集上的实验表明，SpikeSurgSeg达到与SOTA ANN模型相当的mIoU，同时推理延迟降低至少8倍，相对于大多数基础模型基线实现20倍以上加速。

Conclusion: SpikeSurgSeg是首个针对手术场景分割的脉冲驱动视频Transformer框架，在非GPU平台上具有实时潜力，为时间关键的手术场景分割提供了高效解决方案。

Abstract: Modern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning models, particularly large-scale foundation models, achieve remarkable segmentation accuracy, their substantial computational demands and power consumption hinder real-time deployment in resource-constrained surgical environments. To address this limitation, we explore the emerging SNN as a promising paradigm for highly efficient surgical intelligence. However, their performance is still constrained by the scarcity of labeled surgical data and the inherently sparse nature of surgical video representations. To this end, we propose \textit{SpikeSurgSeg}, the first spike-driven video Transformer framework tailored for surgical scene segmentation with real-time potential on non-GPU platforms. To address the limited availability of surgical annotations, we introduce a surgical-scene masked autoencoding pretraining strategy for SNNs that enables robust spatiotemporal representation learning via layer-wise tube masking. Building on this pretrained backbone, we further adopt a lightweight spike-driven segmentation head that produces temporally consistent predictions while preserving the low-latency characteristics of SNNs. Extensive experiments on EndoVis18 and our in-house SurgBleed dataset demonstrate that SpikeSurgSeg achieves mIoU comparable to SOTA ANN-based models while reducing inference latency by at least $8\times$. Notably, it delivers over $20\times$ acceleration relative to most foundation-model baselines, underscoring its potential for time-critical surgical scene segmentation.

</details>


### [4] [Streaming Video Instruction Tuning](https://arxiv.org/abs/2512.21334)
*Jiaer Xia,Peixian Chen,Mengdan Zhang,Xing Sun,Kaiyang Zhou*

Main category: cs.CV

TL;DR: Streamo是一个实时流式视频LLM，作为通用交互助手，能够执行实时叙述、动作理解、事件字幕、时间事件定位和时间敏感问答等多种流式视频任务。


<details>
  <summary>Details</summary>
Motivation: 现有在线视频模型主要局限于问答或字幕生成等狭窄任务，缺乏能够处理多样化流式视频任务的通用交互助手，需要弥合离线视频感知模型与实时多模态助手之间的差距。

Method: 构建了Streamo-Instruct-465K大规模指令跟随数据集，涵盖多样化时间上下文和多任务监督；通过简化的端到端管道在指令跟随数据集上进行训练，实现异构流式任务的统一训练。

Result: Streamo表现出强大的时间推理能力、响应式交互能力以及在各种流式基准测试中的广泛泛化能力，在多个流式视频任务上取得优异表现。

Conclusion: Streamo弥合了离线视频感知模型与实时多模态助手之间的差距，朝着连续视频流中统一智能视频理解迈出了一步。

Abstract: We present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams](https://arxiv.org/abs/2512.20631)
*Aayam Bansal,Ishaan Gangwani*

Main category: cs.LG

TL;DR: 无需训练的变压器情感模型时间漂移分析，在真实社交媒体数据上验证，发现事件驱动期间模型性能显著下降，提出四种新漂移指标优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 研究变压器情感模型在真实世界事件期间的时间稳定性问题，现有方法需要重新训练或大量计算资源，需要开发无需训练的高效漂移检测方法。

Method: 使用三种变压器架构，在12,279条真实社交媒体帖子上进行系统评估，引入四种新的漂移指标，采用统计验证方法（Bootstrap置信区间），与基于嵌入的基线方法比较。

Result: 事件驱动期间模型不稳定，准确率下降最高达23.4%，置信度最大下降13.0%（95% CI: [9.1%, 16.5%]），新指标优于基线方法且计算效率高，适合生产部署。

Conclusion: 无需训练的方法能立即部署于实时情感监控系统，为变压器模型在动态内容期间的行为提供新见解，具有实际应用价值。

Abstract: We present a comprehensive zero-training temporal drift analysis of transformer-based sentiment models validated on authentic social media data from major real-world events. Through systematic evaluation across three transformer architectures and rigorous statistical validation on 12,279 authentic social media posts, we demonstrate significant model instability with accuracy drops reaching 23.4% during event-driven periods. Our analysis reveals maximum confidence drops of 13.0% (Bootstrap 95% CI: [9.1%, 16.5%]) with strong correlation to actual performance degradation. We introduce four novel drift metrics that outperform embedding-based baselines while maintaining computational efficiency suitable for production deployment. Statistical validation across multiple events confirms robust detection capabilities with practical significance exceeding industry monitoring thresholds. This zero-training methodology enables immediate deployment for real-time sentiment monitoring systems and provides new insights into transformer model behavior during dynamic content periods.

</details>


### [6] [TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform](https://arxiv.org/abs/2512.20761)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Henrik Albers,Oliver Müller*

Main category: cs.LG

TL;DR: TS-Arena平台通过实时数据流预注册机制，解决时间序列基础模型评估中的信息泄露问题，确保在真实未知未来环境中进行有效模型比较。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在评估中存在信息泄露危机，包括训练集与测试集重叠以及全局模式非法迁移到测试数据，导致基准测试失效。

Method: 提出TS-Arena平台，采用预注册机制处理实时数据流，确保评估目标在推理时物理上不存在，强制执行严格的全局时间分割，建立移动时间边界。

Result: 在能源领域初步应用，建立了可持续的基础设施，能够在真实世界约束下比较基础模型，原型平台已在Hugging Face上提供。

Conclusion: TS-Arena通过将真正未知的未来作为测试环境，恢复了预测的操作完整性，防止历史数据污染，为模型泛化能力提供了真实评估。

Abstract: While Time Series Foundation Models (TSFMs) offer transformative capabilities for forecasting, they simultaneously risk triggering a fundamental evaluation crisis. This crisis is driven by information leakage due to overlapping training and test sets across different models, as well as the illegitimate transfer of global patterns to test data. While the ability to learn shared temporal dynamics represents a primary strength of these models, their evaluation on historical archives often permits the exploitation of observed global shocks, which violates the independence required for valid benchmarking. We introduce TS-Arena, a platform that restores the operational integrity of forecasting by treating the genuinely unknown future as the definitive test environment. By implementing a pre-registration mechanism on live data streams, the platform ensures that evaluation targets remain physically non-existent during inference, thereby enforcing a strict global temporal split. This methodology establishes a moving temporal frontier that prevents historical contamination and provides an authentic assessment of model generalization. Initially applied within the energy sector, TS-Arena provides a sustainable infrastructure for comparing foundation models under real-world constraints. A prototype of the platform is available at https://huggingface.co/spaces/DAG-UPB/TS-Arena.

</details>


### [7] [STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting](https://arxiv.org/abs/2512.21118)
*Shi Quan Foo,Chi-Ho Wong,Zhihan Gao,Dit-Yan Yeung,Ka-Hing Wong,Wai-Kin Wong*

Main category: cs.LG

TL;DR: STLDM是一种基于扩散模型的降水临近预报方法，通过变分自编码器和条件网络学习潜在表示，将任务分解为确定性预报和增强两个阶段，在多个雷达数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 降水临近预报对预防极端天气灾害至关重要，但现有方法面临挑战：确定性模型预测模糊，生成模型精度不足。需要一种能平衡准确性和清晰度的新方法。

Method: STLDM是一种端到端的扩散模型，结合变分自编码器和条件网络学习潜在表示。将任务分解为：1）条件网络处理确定性预报阶段；2）潜在扩散模型执行增强阶段。

Result: 在多个雷达数据集上的实验结果表明，STLDM相比现有最先进方法取得了更优的性能，同时提高了推理效率。

Conclusion: STLDM通过两阶段架构有效解决了降水临近预报中确定性模型模糊和生成模型精度不足的问题，实现了高性能和高效率的预测。

Abstract: Precipitation nowcasting is a critical spatio-temporal prediction task for society to prevent severe damage owing to extreme weather events. Despite the advances in this field, the complex and stochastic nature of this task still poses challenges to existing approaches. Specifically, deterministic models tend to produce blurry predictions while generative models often struggle with poor accuracy. In this paper, we present a simple yet effective model architecture termed STLDM, a diffusion-based model that learns the latent representation from end to end alongside both the Variational Autoencoder and the conditioning network. STLDM decomposes this task into two stages: a deterministic forecasting stage handled by the conditioning network, and an enhancement stage performed by the latent diffusion model. Experimental results on multiple radar datasets demonstrate that STLDM achieves superior performance compared to the state of the art, while also improving inference efficiency. The code is available in https://github.com/sqfoo/stldm_official.

</details>


### [8] [BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft](https://arxiv.org/abs/2512.21165)
*Qizhi Wang*

Main category: cs.LG

TL;DR: BALLAST使用上下文多臂老虎机替代静态超时启发式方法，通过安全探索减少长尾延迟下的Raft选举不可用时间


<details>
  <summary>Details</summary>
Motivation: 随机选举超时在长尾延迟、抖动和分区恢复场景下变得脆弱，重复的分裂投票会增加不可用时间

Method: 使用线性上下文多臂老虎机（LinUCB变体）从离散的超时"臂"中选择，并通过安全探索限制不稳定期间的风险

Result: 在具有长尾延迟、丢包、突发相关、节点异构和分区恢复的仿真环境中，BALLAST显著减少了恢复时间和不可写时间

Conclusion: BALLAST在挑战性WAN环境下优于标准随机超时和常见启发式方法，同时在稳定LAN/WAN设置中保持竞争力

Abstract: Randomized election timeouts are a simple and effective liveness heuristic for Raft, but they become brittle under long-tail latency, jitter, and partition recovery, where repeated split votes can inflate unavailability. This paper presents BALLAST, a lightweight online adaptation mechanism that replaces static timeout heuristics with contextual bandits. BALLAST selects from a discrete set of timeout "arms" using efficient linear contextual bandits (LinUCB variants), and augments learning with safe exploration to cap risk during unstable periods. We evaluate BALLAST on a reproducible discrete-event simulation with long-tail delay, loss, correlated bursts, node heterogeneity, and partition/recovery turbulence. Across challenging WAN regimes, BALLAST substantially reduces recovery time and unwritable time compared to standard randomized timeouts and common heuristics, while remaining competitive on stable LAN/WAN settings.

</details>


### [9] [Learning to Solve PDEs on Neural Shape Representations](https://arxiv.org/abs/2512.21311)
*Lilian Welschinger,Yilin Liu,Zican Wang,Niloy Mitra*

Main category: cs.LG

TL;DR: 提出一种新颖的无网格方法，直接在神经表面表示上求解偏微分方程，无需显式网格提取或逐实例优化。


<details>
  <summary>Details</summary>
Motivation: 现代3D资产越来越多地以神经表示形式存在，但现有的PDE求解器主要针对多边形/三角形网格，导致在神经域中直接求解表面PDE缺乏合适方法，阻碍端到端工作流程。

Method: 提出一种基于局部更新算子的无网格公式，该算子以神经（局部）形状属性为条件，能够直接在与神经数据相同的位置求解表面PDE。算子与主流神经表面表示自然集成，只需在单个代表性形状上训练一次。

Result: 在解析基准（球体上的热方程和泊松求解）和不同表示的真实神经资产上，该方法略微优于CPM，同时与FEM保持合理接近，实现了首个端到端管道，可在神经和经典表面表示上求解表面PDE。

Conclusion: 该方法提供了一种新颖的解决方案，能够在神经表面表示上直接求解PDE，无需显式网格化或逐实例优化，同时保持可微性，支持跨形状和拓扑变化的泛化能力。

Abstract: Solving partial differential equations (PDEs) on shapes underpins many shape analysis and engineering tasks; yet, prevailing PDE solvers operate on polygonal/triangle meshes while modern 3D assets increasingly live as neural representations. This mismatch leaves no suitable method to solve surface PDEs directly within the neural domain, forcing explicit mesh extraction or per-instance residual training, preventing end-to-end workflows. We present a novel, mesh-free formulation that learns a local update operator conditioned on neural (local) shape attributes, enabling surface PDEs to be solved directly where the (neural) data lives. The operator integrates naturally with prevalent neural surface representations, is trained once on a single representative shape, and generalizes across shape and topology variations, enabling accurate, fast inference without explicit meshing or per-instance optimization while preserving differentiability. Across analytic benchmarks (heat equation and Poisson solve on sphere) and real neural assets across different representations, our method slightly outperforms CPM while remaining reasonably close to FEM, and, to our knowledge, delivers the first end-to-end pipeline that solves surface PDEs on both neural and classical surface representations. Code will be released on acceptance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines](https://arxiv.org/abs/2512.20985)
*Salman Jan,Hassan Ali Razzaqi,Ali Akarma,Mohammad Riyaz Belgaum*

Main category: cs.AI

TL;DR: 提出结合LangChain多智能体系统与许可区块链的架构，确保AI自主决策的可信监控、策略执行与不可篡改审计


<details>
  <summary>Details</summary>
Motivation: AI智能体在医疗、智慧城市、数字取证和供应链等领域的自主决策应用日益增长，但存在信任、监管和信息完整性问题，需要确保自主决策系统的可靠性和可审计性

Method: 设计统一架构模型，将LangChain多智能体系统与许可区块链结合，将感知-概念化-行动循环与区块链治理层关联，验证输入、评估建议行动并记录执行结果。具体实现基于Hyperledger Fabric，集成MCP动作执行器和LangChain智能体

Result: 实验涵盖智能库存管理、交通信号控制和医疗监控，结果显示区块链安全验证能有效防止未授权操作，提供全决策过程可追溯性，并在合理范围内保持操作延迟

Conclusion: 该框架为实施高影响力AI智能体应用提供了通用系统，既能保持自主性又能确保责任性，实现自主且负责任的AI应用

Abstract: The application of agentic AI systems in autonomous decision-making is growing in the areas of healthcare, smart cities, digital forensics, and supply chain management. Even though these systems are flexible and offer real-time reasoning, they also raise concerns of trust and oversight, and integrity of the information and activities upon which they are founded. The paper suggests a single architecture model comprising of LangChain-based multi-agent system with a permissioned blockchain to guarantee constant monitoring, policy enforcement, and immutable auditability of agentic action. The framework relates the perception conceptualization-action cycle to a blockchain layer of governance that verifies the inputs, evaluates recommended actions, and documents the outcomes of the execution. A Hyperledger Fabric-based system, action executors MCP-integrated, and LangChain agent are introduced and experiments of smart inventory management, traffic-signal control, and healthcare monitoring are done. The results suggest that blockchain-security verification is efficient in preventing unauthorized practices, offers traceability throughout the whole decision-making process, and maintains operational latency within reasonable ranges. The suggested framework provides a universal system of implementing high-impact agentic AI applications that are autonomous yet responsible.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks](https://arxiv.org/abs/2512.21329)
*Xinhe Wang,Jin Huang,Xingjian Zhang,Tianhao Wang,Jiaqi W. Ma*

Main category: cs.CL

TL;DR: 该论文挑战了当前对AI在ARC类推理基准测试中表现不佳的主流解释，认为性能差距主要源于视觉感知缺陷而非推理能力不足，并通过分离感知与推理的两阶段实验验证了这一假设。


<details>
  <summary>Details</summary>
Motivation: 当前AI在ARC等推理基准测试中表现不佳通常被归因于机器推理能力的缺陷，但作者认为这种解释可能存在问题。他们假设性能差距主要源于视觉感知限制而非推理能力不足，需要验证这一假设。

Method: 引入两阶段实验流程：1）感知阶段：将每个图像独立转换为自然语言描述；2）推理阶段：模型基于这些描述进行归纳和应用规则。这种方法防止了跨图像归纳信号的泄漏，并隔离了感知瓶颈。在Mini-ARC、ACRE和Bongard-LOGO三个数据集上进行实验，比较两阶段流程与标准端到端评估。

Result: 实验表明感知能力是观察到的性能差距的主导因素。对VLM输出的推理轨迹进行人工检查发现，约80%的模型失败源于感知错误。这些结果表明ARC类基准测试混淆了感知和推理挑战，观察到的性能差距可能夸大了机器推理的缺陷。

Conclusion: ARC类基准测试将感知和推理挑战混为一谈，当前对AI推理能力缺陷的评估可能被夸大。需要开发能够分离感知与推理的评估协议，以更准确地评估机器智能的进展。

Abstract: Reasoning benchmarks such as the Abstraction and Reasoning Corpus (ARC) and ARC-AGI are widely used to assess progress in artificial intelligence and are often interpreted as probes of core, so-called ``fluid'' reasoning abilities. Despite their apparent simplicity for humans, these tasks remain challenging for frontier vision-language models (VLMs), a gap commonly attributed to deficiencies in machine reasoning. We challenge this interpretation and hypothesize that the gap arises primarily from limitations in visual perception rather than from shortcomings in inductive reasoning.
  To verify this hypothesis, we introduce a two-stage experimental pipeline that explicitly separates perception and reasoning. In the perception stage, each image is independently converted into a natural-language description, while in the reasoning stage a model induces and applies rules using these descriptions. This design prevents leakage of cross-image inductive signals and isolates reasoning from perception bottlenecks. Across three ARC-style datasets, Mini-ARC, ACRE, and Bongard-LOGO, we show that the perception capability is the dominant factor underlying the observed performance gap by comparing the two-stage pipeline with against standard end-to-end one-stage evaluation. Manual inspection of reasoning traces in the VLM outputs further reveals that approximately 80 percent of model failures stem from perception errors. Together, these results demonstrate that ARC-style benchmarks conflate perceptual and reasoning challenges and that observed performance gaps may overstate deficiencies in machine reasoning. Our findings underscore the need for evaluation protocols that disentangle perception from reasoning when assessing progress in machine intelligence.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [12] [Tracing Energy Flow: Learning Tactile-based Grasping Force Control to Prevent Slippage in Dynamic Object Interaction](https://arxiv.org/abs/2512.21043)
*Cheng-Yu Kuo,Hirofumi Shin,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出一种基于物理能量抽象的方法，让机器人手通过触觉学习抓握力控制，无需外部传感或物体先验知识，几分钟内就能学会减少滑动。


<details>
  <summary>Details</summary>
Motivation: 在动态物体交互中调节抓握力以减少滑动是机器人操作的基本挑战，特别是当物体被多个滚动接触操纵、具有未知属性（如质量或表面条件）且外部传感不可靠时。人类即使没有视觉线索也能通过触觉快速调节抓握力，受此启发，希望让机器人手能够快速探索物体并在运动和有限传感下学习触觉驱动的抓握力控制。

Method: 提出物理信息能量抽象，将物体建模为虚拟能量容器。手指施加功率与物体保留能量之间的不一致性提供了推断滑动感知稳定性的物理基础信号。基于此抽象，采用基于模型的学习和规划，从触觉传感高效建模能量动力学，并执行实时抓握力优化。

Result: 在仿真和硬件实验中，该方法能够在几分钟内从零开始学习抓握力控制，有效减少滑动，并在各种运动-物体对中延长抓握持续时间，且不依赖外部传感或物体先验知识。

Conclusion: 该方法通过物理信息能量抽象和基于模型的学习，使机器人能够仅凭触觉快速学习抓握力控制，解决了动态物体交互中的滑动问题，为机器人操作提供了新的解决方案。

Abstract: Regulating grasping force to reduce slippage during dynamic object interaction remains a fundamental challenge in robotic manipulation, especially when objects are manipulated by multiple rolling contacts, have unknown properties (such as mass or surface conditions), and when external sensing is unreliable. In contrast, humans can quickly regulate grasping force by touch, even without visual cues. Inspired by this ability, we aim to enable robotic hands to rapidly explore objects and learn tactile-driven grasping force control under motion and limited sensing. We propose a physics-informed energy abstraction that models the object as a virtual energy container. The inconsistency between the fingers' applied power and the object's retained energy provides a physically grounded signal for inferring slip-aware stability. Building on this abstraction, we employ model-based learning and planning to efficiently model energy dynamics from tactile sensing and perform real-time grasping force optimization. Experiments in both simulation and hardware demonstrate that our method can learn grasping force control from scratch within minutes, effectively reduce slippage, and extend grasp duration across diverse motion-object pairs, all without relying on external sensing or prior object knowledge.

</details>
