{"id": "2506.13780", "categories": ["cs.CV", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.13780", "abs": "https://arxiv.org/abs/2506.13780", "authors": ["Sedat Porikli", "Vedat Porikli"], "title": "Hidden Bias in the Machine: Stereotypes in Text-to-Image Models", "comment": "Equal contribution by both authors, Published at CVPR 2025 Workshop on Experimental Model Auditing via Controllable Synthesis (EMACS) and Workshop on Demographic Diversity in Computer Vision (DemoDiv)", "summary": "Text-to-Image (T2I) models have transformed visual content creation, producing highly realistic images from natural language prompts. However, concerns persist around their potential to replicate and magnify existing societal biases. To investigate these issues, we curated a diverse set of prompts spanning thematic categories such as occupations, traits, actions, ideologies, emotions, family roles, place descriptions, spirituality, and life events. For each of the 160 unique topics, we crafted multiple prompt variations to reflect a wide range of meanings and perspectives. Using Stable Diffusion 1.5 (UNet-based) and Flux-1 (DiT-based) models with original checkpoints, we generated over 16,000 images under consistent settings. Additionally, we collected 8,000 comparison images from Google Image Search. All outputs were filtered to exclude abstract, distorted, or nonsensical results. Our analysis reveals significant disparities in the representation of gender, race, age, somatotype, and other human-centric factors across generated images. These disparities often mirror and reinforce harmful stereotypes embedded in societal narratives. We discuss the implications of these findings and emphasize the need for more inclusive datasets and development practices to foster fairness in generative visual systems.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6a21\u578b\u5982\u4f55\u653e\u5927\u793e\u4f1a\u504f\u89c1\uff0c\u901a\u8fc7\u751f\u6210\u548c\u5206\u679016,000\u591a\u5f20\u56fe\u50cf\uff0c\u53d1\u73b0\u5176\u5728\u6027\u522b\u3001\u79cd\u65cf\u7b49\u65b9\u9762\u7684\u663e\u8457\u5dee\u5f02\u3002", "motivation": "T2I\u6a21\u578b\u5728\u89c6\u89c9\u5185\u5bb9\u521b\u4f5c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u53ef\u80fd\u590d\u5236\u548c\u653e\u5927\u793e\u4f1a\u504f\u89c1\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5176\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u4f7f\u7528Stable Diffusion 1.5\u548cFlux-1\u6a21\u578b\u751f\u621016,000\u591a\u5f20\u56fe\u50cf\uff0c\u5e76\u7ed3\u5408Google Image Search\u76848,000\u5f20\u5bf9\u6bd4\u56fe\u50cf\uff0c\u5206\u6790\u5176\u504f\u89c1\u8868\u73b0\u3002", "result": "\u751f\u6210\u56fe\u50cf\u4e2d\u6027\u522b\u3001\u79cd\u65cf\u3001\u5e74\u9f84\u7b49\u4eba\u7c7b\u7279\u5f81\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u53cd\u6620\u4e86\u793e\u4f1a\u4e2d\u7684\u6709\u5bb3\u523b\u677f\u5370\u8c61\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u66f4\u5305\u5bb9\u7684\u6570\u636e\u96c6\u548c\u5f00\u53d1\u5b9e\u8df5\uff0c\u4ee5\u4fc3\u8fdb\u751f\u6210\u89c6\u89c9\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u3002"}}
{"id": "2506.13910", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13910", "abs": "https://arxiv.org/abs/2506.13910", "authors": ["Aritra Dutta", "Pushpita Boral", "G Suseela"], "title": "Intelligent Image Sensing for Crime Analysis: A ML Approach towards Enhanced Violence Detection and Investigation", "comment": null, "summary": "The increasing global crime rate, coupled with substantial human and property losses, highlights the limitations of traditional surveillance methods in promptly detecting diverse and unexpected acts of violence. Addressing this pressing need for automatic violence detection, we leverage Machine Learning to detect and categorize violent events in video streams. This paper introduces a comprehensive framework for violence detection and classification, employing Supervised Learning for both binary and multi-class violence classification. The detection model relies on 3D Convolutional Neural Networks, while the classification model utilizes the separable convolutional 3D model for feature extraction and bidirectional LSTM for temporal processing. Training is conducted on a diverse customized datasets with frame-level annotations, incorporating videos from surveillance cameras, human recordings, hockey fight, sohas and wvd dataset across various platforms. Additionally, a camera module integrated with raspberry pi is used to capture live video feed, which is sent to the ML model for processing. Thus, demonstrating improved performance in terms of computational resource efficiency and accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u66b4\u529b\u68c0\u6d4b\u4e0e\u5206\u7c7b\u6846\u67b6\uff0c\u5229\u75283D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u53cc\u5411LSTM\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u8d44\u6e90\u6548\u7387\u548c\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5168\u7403\u72af\u7f6a\u7387\u4e0a\u5347\u53ca\u4f20\u7edf\u76d1\u63a7\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4fc3\u4f7f\u5f00\u53d1\u81ea\u52a8\u66b4\u529b\u68c0\u6d4b\u7cfb\u7edf\u4ee5\u5e94\u5bf9\u591a\u6837\u5316\u548c\u7a81\u53d1\u6027\u66b4\u529b\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u4e8c\u5143\u548c\u591a\u7c7b\u66b4\u529b\u5206\u7c7b\uff0c\u7ed3\u54083D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u68c0\u6d4b\uff0c\u4f7f\u7528\u53ef\u5206\u79bb\u5377\u79ef3D\u6a21\u578b\u548c\u53cc\u5411LSTM\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u4e0e\u65f6\u95f4\u5e8f\u5217\u5904\u7406\u3002", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u7ed3\u5408\u5b9e\u65f6\u89c6\u9891\u6d41\u5904\u7406\uff0c\u5c55\u793a\u4e86\u8ba1\u7b97\u8d44\u6e90\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u81ea\u52a8\u66b4\u529b\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u76d1\u63a7\u573a\u666f\u3002"}}
{"id": "2506.13925", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.13925", "abs": "https://arxiv.org/abs/2506.13925", "authors": ["Numair Nadeem", "Saeed Anwar", "Muhammad Hamza Asad", "Abdul Bais"], "title": "HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment", "comment": null, "summary": "Semi-supervised semantic segmentation remains challenging under severe label scarcity and domain variability. Vision-only methods often struggle to generalize, resulting in pixel misclassification between similar classes, poor generalization and boundary localization. Vision-Language Models offer robust, domain-invariant semantics but lack the spatial grounding required for dense prediction. We introduce HierVL, a unified framework that bridges this gap by integrating abstract text embeddings into a mask-transformer architecture tailored for semi-supervised segmentation. HierVL features three novel components: a Hierarchical Semantic Query Generator that filters and projects abstract class embeddings into multi-scale queries to suppress irrelevant classes and handle intra-class variability; a Cross-Modal Spatial Alignment Module that aligns semantic queries with pixel features for sharper boundaries under sparse supervision; and a Dual-Query Transformer Decoder that fuses semantic and instance-level queries to prevent instance collapse. We also introduce targeted regularization losses that maintain vision-language alignment throughout training to reinforce semantic grounding. HierVL establishes a new state-of-the-art by achieving a +4.4% mean improvement of the intersection over the union on COCO (with 232 labeled images), +3.1% on Pascal VOC (with 92 labels), +5.9% on ADE20 (with 158 labels) and +1.8% on Cityscapes (with 100 labels), demonstrating better performance under 1% supervision on four benchmark datasets. Our results show that language-guided segmentation closes the label efficiency gap and unlocks new levels of fine-grained, instance-aware generalization.", "AI": {"tldr": "HierVL\u662f\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u534a\u76d1\u7763\u8bed\u4e49\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u67e5\u8be2\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6807\u7b7e\u7a00\u7f3a\u548c\u9886\u57df\u53d8\u5316\u4e0b\u89c6\u89c9\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faHierVL\u6846\u67b6\uff0c\u5305\u62ec\u5206\u5c42\u8bed\u4e49\u67e5\u8be2\u751f\u6210\u5668\u3001\u8de8\u6a21\u6001\u7a7a\u95f4\u5bf9\u9f50\u6a21\u5757\u548c\u53cc\u67e5\u8be2Transformer\u89e3\u7801\u5668\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u5982COCO\uff08+4.4% mIoU\uff09\u3001Pascal VOC\uff08+3.1% mIoU\uff09\u7b49\u3002", "conclusion": "\u8bed\u8a00\u5f15\u5bfc\u7684\u5206\u5272\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6807\u7b7e\u6548\u7387\u548c\u7ec6\u7c92\u5ea6\u5b9e\u4f8b\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2506.14039", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.14039", "abs": "https://arxiv.org/abs/2506.14039", "authors": ["Ioannis Mandralis", "Richard M. Murray", "Morteza Gharib"], "title": "Quadrotor Morpho-Transition: Learning vs Model-Based Control Strategies", "comment": null, "summary": "Quadrotor Morpho-Transition, or the act of transitioning from air to ground through mid-air transformation, involves complex aerodynamic interactions and a need to operate near actuator saturation, complicating controller design. In recent work, morpho-transition has been studied from a model-based control perspective, but these approaches remain limited due to unmodeled dynamics and the requirement for planning through contacts. Here, we train an end-to-end Reinforcement Learning (RL) controller to learn a morpho-transition policy and demonstrate successful transfer to hardware. We find that the RL control policy achieves agile landing, but only transfers to hardware if motor dynamics and observation delays are taken into account. On the other hand, a baseline MPC controller transfers out-of-the-box without knowledge of the actuator dynamics and delays, at the cost of reduced recovery from disturbances in the event of unknown actuator failures. Our work opens the way for more robust control of agile in-flight quadrotor maneuvers that require mid-air transformation.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u56db\u65cb\u7ffc\u98de\u884c\u5668\u5728\u7a7a\u4e2d\u53d8\u5f62\uff08Morpho-Transition\uff09\u65f6\u7684\u63a7\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u63a7\u5236\u5668\uff0c\u5e76\u6210\u529f\u5728\u786c\u4ef6\u4e0a\u5b9e\u73b0\u3002", "motivation": "\u56db\u65cb\u7ffc\u98de\u884c\u5668\u5728\u7a7a\u4e2d\u53d8\u5f62\u65f6\u6d89\u53ca\u590d\u6742\u7684\u6c14\u52a8\u76f8\u4e92\u4f5c\u7528\u548c\u63a5\u8fd1\u6267\u884c\u5668\u9971\u548c\u7684\u64cd\u4f5c\uff0c\u4f20\u7edf\u6a21\u578b\u63a7\u5236\u65b9\u6cd5\u56e0\u672a\u5efa\u6a21\u52a8\u6001\u548c\u63a5\u89e6\u89c4\u5212\u9650\u5236\u800c\u6548\u679c\u6709\u9650\u3002", "method": "\u91c7\u7528\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u63a7\u5236\u5668\uff0c\u5e76\u8003\u8651\u7535\u673a\u52a8\u6001\u548c\u89c2\u6d4b\u5ef6\u8fdf\u4ee5\u5b9e\u73b0\u786c\u4ef6\u8fc1\u79fb\u3002", "result": "RL\u63a7\u5236\u5668\u5b9e\u73b0\u4e86\u654f\u6377\u7740\u9646\uff0c\u4f46\u9700\u8003\u8651\u7535\u673a\u52a8\u6001\u548c\u5ef6\u8fdf\u624d\u80fd\u8fc1\u79fb\u5230\u786c\u4ef6\uff1b\u57fa\u7ebfMPC\u63a7\u5236\u5668\u65e0\u9700\u989d\u5916\u4fe1\u606f\u5373\u53ef\u8fc1\u79fb\uff0c\u4f46\u5bf9\u672a\u77e5\u6267\u884c\u5668\u6545\u969c\u7684\u6062\u590d\u80fd\u529b\u8f83\u5f31\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9700\u8981\u7a7a\u4e2d\u53d8\u5f62\u7684\u654f\u6377\u56db\u65cb\u7ffc\u98de\u884c\u5668\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.14123", "categories": ["cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14123", "abs": "https://arxiv.org/abs/2506.14123", "authors": ["Jonathan Hayase", "Alisa Liu", "Noah A. Smith", "Sewoong Oh"], "title": "Sampling from Your Language Model One Byte at a Time", "comment": "23 pages, 8 figures", "summary": "Tokenization is used almost universally by modern language models, enabling efficient text representation using multi-byte or multi-character tokens. However, prior work has shown that tokenization can introduce distortion into the model's generations. For example, users are often advised not to end their prompts with a space because it prevents the model from including the space as part of the next token. This Prompt Boundary Problem (PBP) also arises in languages such as Chinese and in code generation, where tokens often do not line up with syntactic boundaries. Additionally mismatching tokenizers often hinder model composition and interoperability. For example, it is not possible to directly ensemble models with different tokenizers due to their mismatching vocabularies. To address these issues, we present an inference-time method to convert any autoregressive LM with a BPE tokenizer into a character-level or byte-level LM, without changing its generative distribution at the text level. Our method efficient solves the PBP and is also able to unify the vocabularies of language models with different tokenizers, allowing one to ensemble LMs with different tokenizers at inference time as well as transfer the post-training from one model to another using proxy-tuning. We demonstrate in experiments that the ensemble and proxy-tuned models outperform their constituents on downstream evals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u7406\u65f6\u65b9\u6cd5\uff0c\u5c06\u4efb\u4f55\u4f7f\u7528BPE\u5206\u8bcd\u5668\u7684\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u8f6c\u6362\u4e3a\u5b57\u7b26\u7ea7\u6216\u5b57\u8282\u7ea7\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u5206\u8bcd\u5668\u5e26\u6765\u7684Prompt Boundary Problem\uff08PBP\uff09\u548c\u6a21\u578b\u517c\u5bb9\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u666e\u904d\u4f7f\u7528\u5206\u8bcd\u5668\uff0c\u4f46\u5206\u8bcd\u5668\u53ef\u80fd\u5bfc\u81f4\u751f\u6210\u6587\u672c\u7684\u5931\u771f\uff08\u5982PBP\u95ee\u9898\uff09\u548c\u6a21\u578b\u95f4\u7684\u4e0d\u517c\u5bb9\u6027\uff08\u5982\u4e0d\u540c\u5206\u8bcd\u5668\u65e0\u6cd5\u76f4\u63a5\u96c6\u6210\uff09\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u63a8\u7406\u65f6\u65b9\u6cd5\uff0c\u5c06BPE\u5206\u8bcd\u5668\u7684\u81ea\u56de\u5f52\u6a21\u578b\u8f6c\u6362\u4e3a\u5b57\u7b26\u7ea7\u6216\u5b57\u8282\u7ea7\u6a21\u578b\uff0c\u4fdd\u6301\u6587\u672c\u751f\u6210\u5206\u5e03\u4e0d\u53d8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u8be5\u65b9\u6cd5\u96c6\u6210\u7684\u6a21\u578b\u548c\u4ee3\u7406\u8c03\u4f18\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u539f\u59cb\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86PBP\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0d\u540c\u5206\u8bcd\u5668\u6a21\u578b\u7684\u517c\u5bb9\u6027\u548c\u96c6\u6210\u80fd\u529b\u3002"}}
{"id": "2506.14231", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.14231", "abs": "https://arxiv.org/abs/2506.14231", "authors": ["Omri Haller", "Yair Meidan", "Dudu Mimran", "Yuval Elovici", "Asaf Shabtai"], "title": "ImpReSS: Implicit Recommender System for Support Conversations", "comment": null, "summary": "Following recent advancements in large language models (LLMs), LLM-based chatbots have transformed customer support by automating interactions and providing consistent, scalable service. While LLM-based conversational recommender systems (CRSs) have attracted attention for their ability to enhance the quality of recommendations, limited research has addressed the implicit integration of recommendations within customer support interactions. In this work, we introduce ImpReSS, an implicit recommender system designed for customer support conversations. ImpReSS operates alongside existing support chatbots, where users report issues and chatbots provide solutions. Based on a customer support conversation, ImpReSS identifies opportunities to recommend relevant solution product categories (SPCs) that help resolve the issue or prevent its recurrence -- thereby also supporting business growth. Unlike traditional CRSs, ImpReSS functions entirely implicitly and does not rely on any assumption of a user's purchasing intent. Our empirical evaluation of ImpReSS's ability to recommend relevant SPCs that can help address issues raised in support conversations shows promising results, including an MRR@1 (and recall@3) of 0.72 (0.89) for general problem solving, 0.82 (0.83) for information security support, and 0.85 (0.67) for cybersecurity troubleshooting. To support future research, our data and code will be shared upon request.", "AI": {"tldr": "ImpReSS\u662f\u4e00\u4e2a\u9690\u5f0f\u63a8\u8350\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u5ba2\u6237\u652f\u6301\u5bf9\u8bdd\u4e2d\u63a8\u8350\u76f8\u5173\u89e3\u51b3\u65b9\u6848\u4ea7\u54c1\u7c7b\u522b\uff08SPCs\uff09\uff0c\u65e0\u9700\u7528\u6237\u660e\u786e\u8d2d\u4e70\u610f\u56fe\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u63a2\u8ba8\u5728\u5ba2\u6237\u652f\u6301\u4ea4\u4e92\u4e2d\u9690\u5f0f\u96c6\u6210\u63a8\u8350\u529f\u80fd\uff0cImpReSS\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "ImpReSS\u4e0e\u73b0\u6709\u652f\u6301\u804a\u5929\u673a\u5668\u4eba\u534f\u540c\u5de5\u4f5c\uff0c\u5206\u6790\u5bf9\u8bdd\u5185\u5bb9\u5e76\u8bc6\u522b\u63a8\u8350SPCs\u7684\u673a\u4f1a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cImpReSS\u5728\u63a8\u8350\u76f8\u5173SPCs\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0cMRR@1\u548crecall@3\u6307\u6807\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u5747\u8f83\u9ad8\u3002", "conclusion": "ImpReSS\u4e3a\u9690\u5f0f\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4e1a\u52a1\u589e\u957f\u5e76\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.14213", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14213", "abs": "https://arxiv.org/abs/2506.14213", "authors": ["Jongho Kim", "Dohyeon Lee", "Minsoo Kim", "Seung-won Hwang"], "title": "Chaining Event Spans for Temporal Relation Grounding", "comment": "In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1689-1700", "summary": "Accurately understanding temporal relations between events is a critical building block of diverse tasks, such as temporal reading comprehension (TRC) and relation extraction (TRE). For example in TRC, we need to understand the temporal semantic differences between the following two questions that are lexically near-identical: \"What finished right before the decision?\" or \"What finished right after the decision?\". To discern the two questions, existing solutions have relied on answer overlaps as a proxy label to contrast similar and dissimilar questions. However, we claim that answer overlap can lead to unreliable results, due to spurious overlaps of two dissimilar questions with coincidentally identical answers. To address the issue, we propose a novel approach that elicits proper reasoning behaviors through a module for predicting time spans of events. We introduce the Timeline Reasoning Network (TRN) operating in a two-step inductive reasoning process: In the first step model initially answers each question with semantic and syntactic information. The next step chains multiple questions on the same event to predict a timeline, which is then used to ground the answers. Results on the TORQUE and TB-dense, TRC and TRE tasks respectively, demonstrate that TRN outperforms previous methods by effectively resolving the spurious overlaps using the predicted timeline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u7ebf\u63a8\u7406\u7f51\u7edc\uff08TRN\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u4e8b\u4ef6\u7684\u65f6\u95f4\u8de8\u5ea6\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u56e0\u7b54\u6848\u91cd\u53e0\u5bfc\u81f4\u7684\u4e0d\u53ef\u9760\u95ee\u9898\u3002", "motivation": "\u51c6\u786e\u7406\u89e3\u4e8b\u4ef6\u95f4\u7684\u65f6\u95f4\u5173\u7cfb\u662f\u591a\u9879\u4efb\u52a1\uff08\u5982\u65f6\u95f4\u9605\u8bfb\u7406\u89e3TRC\u548c\u65f6\u95f4\u5173\u7cfb\u63d0\u53d6TRE\uff09\u7684\u5173\u952e\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7b54\u6848\u91cd\u53e0\u4f5c\u4e3a\u6807\u7b7e\uff0c\u4f46\u53ef\u80fd\u56e0\u5076\u7136\u76f8\u540c\u7684\u7b54\u6848\u5bfc\u81f4\u4e0d\u53ef\u9760\u7ed3\u679c\u3002", "method": "\u63d0\u51faTRN\uff0c\u91c7\u7528\u4e24\u6b65\u5f52\u7eb3\u63a8\u7406\uff1a\u9996\u5148\u751f\u6210\u6bcf\u4e2a\u95ee\u9898\u7684\u521d\u6b65\u7b54\u6848\uff0c\u7136\u540e\u901a\u8fc7\u94fe\u63a5\u591a\u4e2a\u95ee\u9898\u9884\u6d4b\u65f6\u95f4\u7ebf\uff0c\u5e76\u57fa\u4e8e\u65f6\u95f4\u7ebf\u4fee\u6b63\u7b54\u6848\u3002", "result": "\u5728TORQUE\u548cTB-dense\u7b49\u4efb\u52a1\u4e0a\uff0cTRN\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7b54\u6848\u91cd\u53e0\u95ee\u9898\u3002", "conclusion": "TRN\u901a\u8fc7\u65f6\u95f4\u7ebf\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5173\u7cfb\u7406\u89e3\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u76f8\u5173\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.14235", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14235", "abs": "https://arxiv.org/abs/2506.14235", "authors": ["Yimin Deng", "Yuxia Wu", "Yejing Wang", "Guoshuai Zhao", "Li Zhu", "Qidong Liu", "Derong Xu", "Zichuan Fu", "Xian Wu", "Yefeng Zheng", "Xiangyu Zhao", "Xueming Qian"], "title": "A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs", "comment": "ACL25 findings", "summary": "Temporal knowledge graph reasoning aims to predict future events with knowledge of existing facts and plays a key role in various downstream tasks. Previous methods focused on either graph structure learning or semantic reasoning, failing to integrate dual reasoning perspectives to handle different prediction scenarios. Moreover, they lack the capability to capture the inherent differences between historical and non-historical events, which limits their generalization across different temporal contexts. To this end, we propose a Multi-Expert Structural-Semantic Hybrid (MESH) framework that employs three kinds of expert modules to integrate both structural and semantic information, guiding the reasoning process for different events. Extensive experiments on three datasets demonstrate the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4e13\u5bb6\u7ed3\u6784-\u8bed\u4e49\u6df7\u5408\u6846\u67b6\uff08MESH\uff09\uff0c\u7528\u4e8e\u6574\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u4ee5\u5904\u7406\u4e0d\u540c\u9884\u6d4b\u573a\u666f\u4e0b\u7684\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6574\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u63a8\u7406\u7684\u53cc\u91cd\u89c6\u89d2\uff0c\u4e14\u65e0\u6cd5\u533a\u5206\u5386\u53f2\u4e0e\u975e\u5386\u53f2\u4e8b\u4ef6\u7684\u5dee\u5f02\uff0c\u9650\u5236\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u4e13\u5bb6\u6a21\u5757\uff0c\u7ed3\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u6307\u5bfc\u4e0d\u540c\u4e8b\u4ef6\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "MESH\u6846\u67b6\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u6027\u80fd\u3002"}}
{"id": "2506.14285", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14285", "abs": "https://arxiv.org/abs/2506.14285", "authors": ["Seongbo Jang", "Minjin Jeon", "Jaehoon Lee", "Seonghyeon Lee", "Dongha Lee", "Hwanjo Yu"], "title": "From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents", "comment": "Work in progress", "summary": "While research on dialogue response generation has primarily focused on generating coherent responses conditioning on textual context, the critical question of when to respond grounded on the temporal context remains underexplored. To bridge this gap, we propose a novel task called timely dialogue response generation and introduce the TimelyChat benchmark, which evaluates the capabilities of language models to predict appropriate time intervals and generate time-conditioned responses. Additionally, we construct a large-scale training dataset by leveraging unlabeled event knowledge from a temporal commonsense knowledge graph and employing a large language model (LLM) to synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent designed to proactively predict time intervals and generate timely responses that align with those intervals. Experimental results show that Timer outperforms prompting-based LLMs and other fine-tuned baselines in both turn-level and dialogue-level evaluations. We publicly release our data, model, and code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u9879\u65b0\u4efb\u52a1\u2014\u2014\u53ca\u65f6\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\uff0c\u5e76\u5f15\u5165\u4e86TimelyChat\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u65f6\u95f4\u95f4\u9694\u548c\u751f\u6210\u65f6\u95f4\u6761\u4ef6\u54cd\u5e94\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u57fa\u4e8e\u6587\u672c\u4e0a\u4e0b\u6587\u7684\u8fde\u8d2f\u54cd\u5e94\uff0c\u800c\u5ffd\u7565\u4e86\u57fa\u4e8e\u65f6\u95f4\u4e0a\u4e0b\u6587\u7684\u54cd\u5e94\u65f6\u673a\u95ee\u9898\u3002", "method": "\u5229\u7528\u65f6\u95f4\u5e38\u8bc6\u77e5\u8bc6\u56fe\u8c31\u7684\u65e0\u6807\u7b7e\u4e8b\u4ef6\u77e5\u8bc6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5408\u621055K\u4e8b\u4ef6\u9a71\u52a8\u5bf9\u8bdd\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u540d\u4e3aTimer\u7684\u5bf9\u8bdd\u4ee3\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTimer\u5728\u8f6e\u6b21\u548c\u5bf9\u8bdd\u7ea7\u522b\u7684\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u57fa\u4e8e\u63d0\u793a\u7684LLM\u548c\u5176\u4ed6\u5fae\u8c03\u57fa\u7ebf\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\u4e2d\u65f6\u95f4\u4e0a\u4e0b\u6587\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u3001\u6a21\u578b\u548c\u4ee3\u7801\u3002"}}
{"id": "2506.14539", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.14539", "abs": "https://arxiv.org/abs/2506.14539", "authors": ["Daewon Kang", "YeongHwan Shin", "Doyeon Kim", "Kyu-Hwan Jung", "Meong Hi Son"], "title": "Doppelg\u00e4nger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack", "comment": null, "summary": "Since the advent of large language models, prompt engineering now enables the rapid, low-effort creation of diverse autonomous agents that are already in widespread use. Yet this convenience raises urgent concerns about the safety, robustness, and behavioral consistency of the underlying prompts, along with the pressing challenge of preventing those prompts from being exposed to user's attempts. In this paper, we propose the ''Doppelg\u00e4nger method'' to demonstrate the risk of an agent being hijacked, thereby exposing system instructions and internal information. Next, we define the ''Prompt Alignment Collapse under Adversarial Transfer (PACAT)'' level to evaluate the vulnerability to this adversarial transfer attack. We also propose a ''Caution for Adversarial Transfer (CAT)'' prompt to counter the Doppelg\u00e4nger method. The experimental results demonstrate that the Doppelg\u00e4nger method can compromise the agent's consistency and expose its internal information. In contrast, CAT prompts enable effective defense against this adversarial attack.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cDoppelg\u00e4nger\u201d\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4ee3\u7406\u88ab\u52ab\u6301\u7684\u98ce\u9669\uff0c\u5e76\u5b9a\u4e49\u4e86\u201cPACAT\u201d\u7ea7\u522b\u8bc4\u4f30\u5176\u8106\u5f31\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u201cCAT\u201d\u63d0\u793a\u4f5c\u4e3a\u9632\u5fa1\u624b\u6bb5\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u63d0\u793a\u5de5\u7a0b\u7684\u4fbf\u6377\u6027\u5f15\u53d1\u4e86\u5b89\u5168\u6027\u548c\u4e00\u81f4\u6027\u7684\u62c5\u5fe7\uff0c\u9700\u8981\u9632\u6b62\u63d0\u793a\u88ab\u7528\u6237\u66b4\u9732\u6216\u52ab\u6301\u3002", "method": "\u63d0\u51fa\u201cDoppelg\u00e4nger\u201d\u65b9\u6cd5\u5c55\u793a\u4ee3\u7406\u52ab\u6301\u98ce\u9669\uff0c\u5b9a\u4e49\u201cPACAT\u201d\u7ea7\u522b\u8bc4\u4f30\u8106\u5f31\u6027\uff0c\u5e76\u8bbe\u8ba1\u201cCAT\u201d\u63d0\u793a\u4f5c\u4e3a\u9632\u5fa1\u63aa\u65bd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u201cDoppelg\u00e4nger\u201d\u65b9\u6cd5\u80fd\u7834\u574f\u4ee3\u7406\u4e00\u81f4\u6027\u5e76\u66b4\u9732\u5185\u90e8\u4fe1\u606f\uff0c\u800c\u201cCAT\u201d\u63d0\u793a\u80fd\u6709\u6548\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u63d0\u793a\u5de5\u7a0b\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.14629", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14629", "abs": "https://arxiv.org/abs/2506.14629", "authors": ["Md. Adnanul Islam", "Md. Faiyaz Abdullah Sayeedi", "Md. Asaduzzaman Shuvo", "Muhammad Ziaur Rahman", "Shahanur Rahman Bappy", "Raiyan Rahman", "Swakkhar Shatabda"], "title": "VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning", "comment": null, "summary": "Mosquito-borne diseases pose a major global health risk, requiring early detection and proactive control of breeding sites to prevent outbreaks. In this paper, we present VisText-Mosquito, a multimodal dataset that integrates visual and textual data to support automated detection, segmentation, and reasoning for mosquito breeding site analysis. The dataset includes 1,828 annotated images for object detection, 142 images for water surface segmentation, and natural language reasoning texts linked to each image. The YOLOv9s model achieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object detection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and mAP@50 of 0.79795. For reasoning generation, our fine-tuned BLIP model achieves a final loss of 0.0028, with a BLEU score of 54.7, BERTScore of 0.91, and ROUGE-L of 0.87. This dataset and model framework emphasize the theme \"Prevention is Better than Cure\", showcasing how AI-based detection can proactively address mosquito-borne disease risks. The dataset and implementation code are publicly available at GitHub: https://github.com/adnanul-islam-jisun/VisText-Mosquito", "AI": {"tldr": "VisText-Mosquito\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\uff0c\u7528\u4e8e\u868a\u866b\u6ecb\u751f\u5730\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\u3001\u5206\u5272\u548c\u63a8\u7406\u5206\u6790\u3002", "motivation": "\u868a\u5a92\u75be\u75c5\u662f\u5168\u7403\u91cd\u5927\u5065\u5eb7\u5a01\u80c1\uff0c\u9700\u65e9\u671f\u68c0\u6d4b\u548c\u4e3b\u52a8\u63a7\u5236\u6ecb\u751f\u5730\u4ee5\u9884\u9632\u75ab\u60c5\u3002", "method": "\u6570\u636e\u96c6\u5305\u542b1,828\u5f20\u6807\u6ce8\u56fe\u50cf\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\uff0c142\u5f20\u7528\u4e8e\u6c34\u9762\u5206\u5272\uff0c\u4ee5\u53ca\u6bcf\u5f20\u56fe\u50cf\u5173\u8054\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6587\u672c\u3002\u4f7f\u7528YOLOv9s\u548cYOLOv11n-Seg\u6a21\u578b\u8fdb\u884c\u68c0\u6d4b\u548c\u5206\u5272\uff0cBLIP\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u751f\u6210\u3002", "result": "YOLOv9s\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u8fbe\u5230\u6700\u9ad8\u7cbe\u5ea60.92926\uff0cmAP@50\u4e3a0.92891\uff1bYOLOv11n-Seg\u5206\u5272\u7cbe\u5ea6\u4e3a0.91587\uff0cmAP@50\u4e3a0.79795\u3002BLIP\u6a21\u578b\u7684\u63a8\u7406\u751f\u6210\u8868\u73b0\u4f18\u5f02\uff08BLEU 54.7\uff0cBERTScore 0.91\uff0cROUGE-L 0.87\uff09\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u6a21\u578b\u6846\u67b6\u5f3a\u8c03\u201c\u9884\u9632\u80dc\u4e8e\u6cbb\u7597\u201d\uff0c\u5c55\u793a\u4e86AI\u5982\u4f55\u4e3b\u52a8\u5e94\u5bf9\u868a\u5a92\u75be\u75c5\u98ce\u9669\u3002\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.14472", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14472", "abs": "https://arxiv.org/abs/2506.14472", "authors": ["Fabien Bernier", "Maxime Cordy", "Yves Le Traon"], "title": "Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks", "comment": "ECML PKDD 2025", "summary": "Accurate electrical consumption forecasting is crucial for efficient energy management and resource allocation. While traditional time series forecasting relies on historical patterns and temporal dependencies, incorporating external factors -- such as weather indicators -- has shown significant potential for improving prediction accuracy in complex real-world applications. However, the inclusion of these additional features often degrades the performance of global predictive models trained on entire populations, despite improving individual household-level models. To address this challenge, we found that a hypernetwork architecture can effectively leverage external factors to enhance the accuracy of global electrical consumption forecasting models, by specifically adjusting the model weights to each consumer.\n  We collected a comprehensive dataset spanning two years, comprising consumption data from over 6000 luxembourgish households and corresponding external factors such as weather indicators, holidays, and major local events. By comparing various forecasting models, we demonstrate that a hypernetwork approach outperforms existing methods when associated to external factors, reducing forecasting errors and achieving the best accuracy while maintaining the benefits of a global model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8d85\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u56e0\u7d20\uff08\u5982\u5929\u6c14\u6307\u6807\uff09\u6765\u63d0\u5347\u5168\u7403\u7535\u529b\u6d88\u8017\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5386\u53f2\u6a21\u5f0f\u548c\u65f6\u5e8f\u4f9d\u8d56\u6027\uff0c\u4f46\u7ed3\u5408\u5916\u90e8\u56e0\u7d20\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u590d\u6742\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u989d\u5916\u7279\u5f81\u5f80\u5f80\u4f1a\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u8d85\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u6d88\u8d39\u8005\u8c03\u6574\u6a21\u578b\u6743\u91cd\uff0c\u6709\u6548\u5229\u7528\u5916\u90e8\u56e0\u7d20\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8d85\u7f51\u7edc\u65b9\u6cd5\u5728\u7ed3\u5408\u5916\u90e8\u56e0\u7d20\u65f6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u9884\u6d4b\u8bef\u5dee\u5e76\u4fdd\u6301\u4e86\u5168\u5c40\u6a21\u578b\u7684\u4f18\u52bf\u3002", "conclusion": "\u8d85\u7f51\u7edc\u67b6\u6784\u80fd\u591f\u6709\u6548\u63d0\u5347\u5168\u7403\u7535\u529b\u6d88\u8017\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5229\u7528\u5916\u90e8\u56e0\u7d20\u3002"}}
