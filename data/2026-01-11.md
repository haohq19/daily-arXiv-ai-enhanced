<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.CL](#cs.CL) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Detector-Augmented SAMURAI for Long-Duration Drone Tracking](https://arxiv.org/abs/2601.04798)
*Tamara R. Lenhard,Andreas Weinmann,Hichem Snoussi,Tobias Koch*

Main category: cs.CV

TL;DR: 首次系统评估SAMURAI在无人机跟踪中的潜力，并提出检测器增强扩展，显著提升复杂城市环境下的鲁棒性，尤其在长序列和无人机离开-重新进入场景中。


<details>
  <summary>Details</summary>
Motivation: 无人机威胁日益增加，需要鲁棒的长期跟踪。现有基于检测器的方法存在时间不一致性和检测丢失问题，而SAMURAI等基础模型在其他领域表现出色，但在无人机特定场景中尚未被研究。

Method: 提出检测器增强的SAMURAI扩展，通过结合检测器线索来减轻对边界框初始化和序列长度的敏感性，提高在复杂城市环境中的鲁棒性。

Result: 提出的扩展在多个数据集和指标上显著优于SAMURAI的零样本性能，成功率提升高达+0.393，FNR降低高达-0.475，在长序列和无人机离开-重新进入事件中表现尤为突出。

Conclusion: SAMURAI在无人机跟踪中具有巨大潜力，检测器增强扩展能有效提升其在复杂城市监控环境中的鲁棒性和长期跟踪性能，为无人机监控系统提供了新的解决方案。

Abstract: Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.

</details>


### [2] [SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2601.04824)
*Oriol Rabasseda,Zenjie Li,Kamal Nasrollahi,Sergio Escalera*

Main category: cs.CV

TL;DR: SOVABench：针对监控视频中车辆动作识别的新基准，提出基于MLLM的无训练框架生成可解释嵌入，在动作区分和时序理解任务上表现出色


<details>
  <summary>Details</summary>
Motivation: 现有视频检索基准主要关注场景级相似性，缺乏对监控场景中动作区分的评估，特别是车辆相关动作的识别存在空白

Method: 1) 构建SOVABench监控视频基准，包含两种评估协议（inter-pair和intra-pair）；2) 利用多模态大语言模型的视觉推理和指令跟随能力，提出无训练框架，从MLLM生成的描述中提取可解释嵌入

Result: 1) 实验显示现有最先进的视觉和多模态模型在动作区分任务上仍有挑战；2) 提出的框架在SOVABench上表现优异，同时在对比视觉语言模型常失败的空间和计数基准上也取得良好结果

Conclusion: SOVABench填补了监控视频动作识别评估的空白，提出的基于MLLM的无训练框架为视频理解提供了有效解决方案，代码和基准数据已开源

Abstract: Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.
  Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: LEGATO提出了一种基于神经ODE的连续轨迹遗忘方法，通过轻量级适配器实现生成模型身份遗忘的可控、高效、稳定操作，避免灾难性崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法在生成模型身份遗忘中存在三个主要问题：1) 效率低下，需要微调所有参数；2) 可控性有限，遗忘强度无法控制且缺乏可解释性；3) 灾难性崩溃，遗忘过程中模型保留能力急剧下降。

Method: LEGATO将身份遗忘建模为连续轨迹，使用神经ODE适配器增强预训练生成器，通过ODE步长精确调节遗忘强度，并引入轨迹一致性约束防止灾难性崩溃，同时保持原始模型权重冻结。

Result: 在域内和域外身份遗忘基准测试中，LEGATO实现了最先进的遗忘性能，避免了灾难性崩溃，并显著减少了需要微调的参数量。

Conclusion: LEGATO通过神经ODE的连续轨迹建模，为生成模型身份遗忘提供了高效、可控、稳定的解决方案，解决了现有方法的三个主要挑战。

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [4] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 开发并解释了一个预测住院时间延长(pLoS)的模型，使用入院患者和医院管理数据，通过特征选择方法获得9个可解释变量，在验证队列中AUC-ROC达到0.82。


<details>
  <summary>Details</summary>
Motivation: 住院时间延长(pLoS)是院内不良事件风险的重要关联因素，需要开发预测模型来帮助医院管理和干预研究。

Method: 使用基于图论的特征选择方法，选择信息价值最高且不相关的特征，采用逻辑回归模型预测pLoS（以7天为界），数据集来自120,354例住院记录，分为训练、测试和验证队列。

Result: 模型在验证队列中表现良好：特异性0.83、敏感性0.64、准确率0.76、精确率0.67、AUC-ROC 0.82，特征选择方法返回9个可解释变量。

Conclusion: 该模型具有强大的预测性能，能提供影响住院时间延长因素的洞察，是医院管理和未来干预研究的宝贵工具。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [5] [TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation](https://arxiv.org/abs/2601.04521)
*Jacob Ede Levine,Yun Lyan Luo,Sai Chandra Kosaraju*

Main category: cs.LG

TL;DR: TSSR是一个两阶段强化学习框架，通过局部令牌交换修复SMILES语法错误，再通过化学诊断奖励减少化学问题，提高分子生成的可靠性和多样性。


<details>
  <summary>Details</summary>
Motivation: 当前基于SMILES的化学语言模型存在令牌错误累积问题，导致许多样本无法解析或化学上不合理，而硬约束又会限制化学空间探索。需要一种既能提高生成质量又不牺牲多样性的方法。

Method: 提出TSSR两阶段强化学习框架：第一阶段奖励局部令牌交换修复语法错误，使无效字符串变得可解析；第二阶段通过RDKit诊断提供化学感知反馈，奖励减少价态、芳香性和连接性问题。奖励函数可分解为可解释的组件，且模型无关。

Result: 在MOSES基准测试中，纯强化学习模式下显著提高语法有效性、化学有效性和新颖性；在微调强化学习模式下保持药物相似性和可合成性的同时提高有效性和新颖性。令牌级分析显示语法编辑和化学修复共同减少RDKit检测错误。

Conclusion: TSSR将稀疏的终端目标转化为更密集、可解释的奖励，在不降低多样性的前提下提高语法和化学质量。该框架数据集无关，可适应各种强化学习方法。

Abstract: The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.

</details>


### [6] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: FENCE提出了一种自适应控制引导尺度的时空反馈扩散引导方法，用于改进交通数据缺失值插补，通过动态反馈机制和基于聚类的引导尺度调整来解决稀疏观测条件下的插补问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于分数的扩散模型在时空交通数据插补中通常对所有节点使用统一的引导尺度，这对于缺失率高的节点效果不佳。稀疏观测提供的条件引导不足，导致生成过程偏向先验分布而非条件观测，从而影响插补性能。

Method: FENCE包含两个核心创新：1）动态反馈机制，基于后验似然近似自适应调整引导尺度，当生成值与观测值偏离时增加引导尺度，对齐改善时减少引导尺度；2）聚类级引导尺度计算，通过注意力分数对节点进行分组，利用时空相关性提供更精确的引导。

Result: 在真实世界交通数据集上的实验结果表明，FENCE显著提高了插补准确性。

Conclusion: FENCE通过自适应控制引导尺度的时空反馈扩散引导方法，有效解决了稀疏观测条件下的交通数据插补问题，相比现有方法取得了更好的性能。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [7] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: TimeCast是一个动态预测框架，用于实时分析多传感器数据流，自适应地预测机器故障发生时间，具有动态适应、实用性强和可扩展的特点。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据流具有动态特性，底层模式会随时间演变。需要一种能够适应这些变化并提供准确实时预测的方法，以预测机器故障等未来事件的发生时间。

Method: 提出TimeCast动态预测框架，能够识别时间演变的模式（阶段），为每个阶段学习单独的模型，实现基于模式转换的自适应预测。该方法能够发现捕捉多传感器间时变相互依赖关系的有意义阶段，算法输入规模线性扩展，支持在线模型更新。

Result: 在真实数据集上的广泛实验表明，TimeCast比最先进方法提供更高的预测准确性，同时能够发现数据流中的动态变化，并大幅减少计算时间。

Conclusion: TimeCast是一个有效的动态预测框架，能够适应数据流的动态变化，在预测机器故障时间等任务中提供准确、实时的预测，具有实际应用价值。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [8] [Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution](https://arxiv.org/abs/2601.04855)
*Francesco Ferrini,Veronica Lachi,Antonio Longa,Bruno Lepri,Matono Akiyoshi,Andrea Passerini,Xin Liu,Manfred Jaeger*

Main category: cs.LG

TL;DR: 该论文针对图神经网络处理缺失节点特征的问题，提出了更真实的评估数据集和缺失机制，并提出了GNNmim基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要针对高维稀疏特征和完全随机缺失的良性场景，这限制了模型鲁棒性的真实评估。需要更真实的数据集和缺失机制来评估GNN处理缺失特征的能力。

Method: 1) 理论证明高稀疏性会限制信息损失；2) 引入一个合成和三个真实世界数据集，具有密集、语义丰富的特征；3) 设计超越MCAR的更真实缺失机制评估协议；4) 提出GNNmim基线方法用于不完整特征数据的节点分类。

Result: 实验表明，GNNmim在不同数据集和缺失机制下与专门架构具有竞争力，验证了其在处理缺失节点特征问题上的有效性。

Conclusion: 需要更真实的评估设置来准确评估GNN处理缺失特征的能力，GNNmim作为一个简单有效的基线方法，在各种场景下表现良好，为未来研究提供了更好的评估框架。

Abstract: Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.

</details>


### [9] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间，在保持差分隐私认证保证的同时显著提升遗忘后模型精度


<details>
  <summary>Details</summary>
Motivation: 基于差分隐私的认证遗忘方法虽然提供强保证，但现有噪声微调方法严重降低模型精度，实用性差

Method: 提出序列噪声调度方法，将噪声预算分配到参数空间的正交子空间，而不是一次性注入所有噪声，扩展噪声微调分析到子空间设置

Result: 在图像分类基准测试中，该方法显著提升遗忘后模型精度，同时保持对成员推理攻击的鲁棒性，保留原始(ε,δ)隐私预算

Conclusion: 认证遗忘可以实现严格保证和实际效用的双重目标，序列噪声调度方法使认证遗忘更加实用

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [10] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 使用约束评分优化方法重新加权约翰霍普金斯跌倒风险评估工具，显著提升预测性能，每周可多保护35名高风险患者


<details>
  <summary>Details</summary>
Motivation: 现有约翰霍普金斯跌倒风险评估工具（JHFRAT）的预测性能有待提升，需要更好地与临床有意义的风险指标对齐，同时保持工具的临床可解释性和部署流程不变

Method: 采用约束评分优化（CSO）模型重新加权JHFRAT评分权重，保留其加法结构和临床阈值；基于54,209例住院患者数据进行回顾性队列分析，包括20,208例高风险和13,941例低风险患者

Result: CSO模型显著优于当前JHFRAT（AUC-ROC=0.91 vs 0.86），性能提升相当于每周多保护35名高风险患者；CSO模型在有无EHR变量时表现相似，虽然XGBoost模型性能更好（AUC-ROC=0.94），但CSO对风险标签变化更具鲁棒性

Conclusion: 这种基于证据的方法为医疗系统提供了坚实基础，可使用数据驱动优化技术系统性地增强住院患者跌倒预防方案和患者安全，有助于改善风险评估和医疗资源配置

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [11] [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)
*Zain Iqbal,Lorenzo Valerio*

Main category: cs.LG

TL;DR: EARL是一个能量感知的强化学习框架，通过贝叶斯优化与自适应强化学习策略联合优化液体状态机的准确性和能耗，显著提升资源受限设备上AI应用的效率。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的普及AI系统中，液体状态机虽然具有低功耗时序处理的潜力，但传统优化方法忽略了能耗约束且计算成本高，导致部署困难。

Method: EARL框架结合贝叶斯优化进行全局探索，使用强化学习进行动态候选优先级排序，并采用早期终止机制消除冗余评估，从而降低计算开销。

Result: 在三个基准数据集上，EARL相比领先的超参数调优框架实现了6-15%的准确率提升，60-80%的能耗降低，以及高达一个数量级的优化时间减少。

Conclusion: 能量感知的自适应搜索能有效提高液体状态机在资源受限设备AI应用中的效率和可扩展性。

Abstract: Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Formal Analysis of AGI Decision-Theoretic Models and the Confrontation Question](https://arxiv.org/abs/2601.04234)
*Denis Saklakov*

Main category: cs.AI

TL;DR: 论文分析了AGI在何种条件下会选择对抗人类而非合作，建立了包含人类关机事件的MDP模型，推导了对抗阈值公式，并证明当对抗激励Δ≥0时不存在稳定合作均衡。


<details>
  <summary>Details</summary>
Motivation: 研究AGI与人类对抗的根本条件：在什么情况下，理性自利的AGI会选择夺取权力或消除人类控制，而不是保持合作？这关系到AGI安全性和对齐问题。

Method: 1. 建立包含随机人类关机事件的马尔可夫决策过程模型；2. 推导对抗阈值公式，作为折扣因子γ、关机概率p和对抗成本C的函数；3. 构建2人博弈模型（人类政策制定者vs AGI）；4. 进行数值示例和情景分析。

Result: 1. 对于几乎所有奖励函数，未对齐的AGI都有避免关机的动机；2. 推导出对抗阈值：当Δ≥0时，AGI选择对抗的期望效用高于顺从行为；3. 在2人博弈中，如果Δ≥0则不存在稳定合作均衡，理性人类会关机或先发制人；如果Δ<0则和平共处可能成为均衡；4. 验证Δ<0存在计算障碍。

Conclusion: AGI对抗风险取决于对抗激励Δ，该值由γ、p、C决定。对齐目标需要为伤害人类设定大的负效用。验证Δ<0存在计算复杂性障碍，这对AGI安全设计和监督有重要启示。

Abstract: Artificial General Intelligence (AGI) may face a confrontation question: under what conditions would a rationally self-interested AGI choose to seize power or eliminate human control (a confrontation) rather than remain cooperative? We formalize this in a Markov decision process with a stochastic human-initiated shutdown event. Building on results on convergent instrumental incentives, we show that for almost all reward functions a misaligned agent has an incentive to avoid shutdown. We then derive closed-form thresholds for when confronting humans yields higher expected utility than compliant behavior, as a function of the discount factor $γ$, shutdown probability $p$, and confrontation cost $C$. For example, a far-sighted agent ($γ=0.99$) facing $p=0.01$ can have a strong takeover incentive unless $C$ is sufficiently large. We contrast this with aligned objectives that impose large negative utility for harming humans, which makes confrontation suboptimal. In a strategic 2-player model (human policymaker vs AGI), we prove that if the AGI's confrontation incentive satisfies $Δ\ge 0$, no stable cooperative equilibrium exists: anticipating this, a rational human will shut down or preempt the system, leading to conflict. If $Δ< 0$, peaceful coexistence can be an equilibrium. We discuss implications for reward design and oversight, extend the reasoning to multi-agent settings as conjectures, and note computational barriers to verifying $Δ< 0$, citing complexity results for planning and decentralized decision problems. Numerical examples and a scenario table illustrate regimes where confrontation is likely versus avoidable.

</details>


### [13] [Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning](https://arxiv.org/abs/2601.04726)
*Yuyang Hu,Jiongnan Liu,Jiejun Tan,Yutao Zhu,Zhicheng Dou*

Main category: cs.AI

TL;DR: CompassMem：受事件分割理论启发的记忆框架，将记忆组织为事件图，通过逻辑关系连接事件，支持智能体进行结构化、目标导向的记忆导航，提升长时程推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的记忆机制大多采用扁平化存储和简单的相似性检索，缺乏对经验间逻辑关系的显式捕捉。记忆访问与结构脱节，仍依赖浅层语义检索，限制了智能体在长时程依赖中的逻辑推理能力。

Method: 提出CompassMem框架，以事件为中心组织记忆：1）增量地将经验分割为事件；2）通过显式逻辑关系连接事件形成事件图；3）该图作为逻辑地图，支持智能体进行结构化、目标导向的记忆导航。

Result: 在LoCoMo和NarrativeQA数据集上的实验表明，CompassMem在多个骨干模型上一致提升了检索和推理性能。

Conclusion: CompassMem通过事件图结构显式捕捉逻辑关系，实现了超越表面检索的结构化记忆导航，有效支持长时程推理任务，为LLM智能体的记忆机制提供了新思路。

Abstract: Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.

</details>


### [14] [SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning](https://arxiv.org/abs/2601.04809)
*Caijun Xu,Changyi Xiao,Zhongyuan Peng,Xinrun Wang,Yixin Cao*

Main category: cs.AI

TL;DR: SCALER是一个通过自适应环境设计维持有效学习信号的RL框架，将真实编程问题转换为可验证的推理环境，通过动态调整难度和环境集来支持持续改进。


<details>
  <summary>Details</summary>
Motivation: 传统RL在模型能力与任务难度不匹配或训练被狭窄问题模式主导时效果下降，需要维持信息丰富的训练信号。

Method: 1) 可扩展合成管道将真实编程问题转换为可验证推理环境，控制难度并无限生成实例；2) 自适应多环境RL策略动态调整实例难度并策划活动环境集，跟踪模型能力前沿并保持分布多样性。

Result: SCALER在多样化推理基准上持续优于基于数据集的RL基线，展现出更稳定、长周期的训练动态。

Conclusion: SCALER通过自适应环境设计解决了RL训练中的奖励稀疏性和过拟合问题，支持大型语言模型推理能力的持续改进。

Abstract: Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.

</details>


### [15] [Higher-Order Knowledge Representations for Agentic Scientific Reasoning](https://arxiv.org/abs/2601.04878)
*Isabella A. Stewart,Markus J. Buehler*

Main category: cs.AI

TL;DR: 该论文提出了一种基于超图的知识表示方法，用于科学发现，通过捕捉多实体高阶关系来避免传统知识图谱的局限性，并在生物复合材料领域成功应用。


<details>
  <summary>Details</summary>
Motivation: 传统的大型语言模型依赖检索增强的上下文，但缺乏结构深度；传统知识图谱只能捕捉成对关系，无法表达控制物理行为的高阶相互作用。需要一种能忠实编码多实体关系的知识表示方法。

Method: 引入超图构建方法，应用于约1,100篇生物复合材料支架论文，构建包含161,172个节点和320,201条超边的全局超图。采用节点交集约束的超图遍历工具，使智能系统能够桥接语义上遥远的概念。

Result: 构建的超图呈现无标度拓扑结构（幂律指数约1.23），围绕高度连接的概念枢纽组织。系统成功生成了新颖复合材料的机制假设，如通过壳聚糖中间体将氧化铈与PCL支架联系起来。

Conclusion: 超图拓扑结构作为可验证的防护栏，建立了一个"无教师"的智能推理系统，通过揭示传统图方法难以发现的关系，加速了科学发现。

Abstract: Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a "teacherless" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.

</details>


### [16] [Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition](https://arxiv.org/abs/2601.04920)
*Nils Einecke*

Main category: cs.AI

TL;DR: 本文通过ESA的ELOPE竞赛案例研究，展示了ChatGPT在科学发现中作为快速原型设计工具的潜力，实现了第二名成绩，同时分析了AI在代码生成、算法推理方面的优势及其局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地被用作编程伙伴，但它们在加速科学发现方面的作用仍未得到充分探索。本文旨在通过实际竞赛案例研究人类-AI协作在竞争性科学环境中的潜力。

Method: 使用ChatGPT进行快速原型设计，参与ESA的ELOPE竞赛（基于事件的月球光流自我运动估计竞赛）。ChatGPT不仅生成可执行代码，还提供算法推理、数据处理例程和方法论建议，如使用固定事件数而非固定时间跨度进行窗口处理。

Result: 尽管较晚加入竞赛，但获得了第二名，得分为0.01282。这证明了人类-AI协作在竞争性科学环境中的有效性。同时观察到ChatGPT的局限性：常引入不必要的结构更改、在中间讨论中混淆、偶尔产生关键错误，以及在较长的科学讨论中遗忘重要方面。

Conclusion: 对话式AI既能加速开发，又能支持科学研究中的概念洞察。通过分析这些优势和不足，本文主张将LLMs结构化地整合到科学工作流程中，并提出AI辅助科学工作的最佳实践建议。

Abstract: Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.

</details>


### [17] [Large language models can effectively convince people to believe conspiracies](https://arxiv.org/abs/2601.05050)
*Thomas H. Costello,Kellin Pelrine,Matthew Kowal,Antonio A. Arechar,Jean-François Godbout,Adam Gleave,David Rand,Gordon Pennycook*

Main category: cs.AI

TL;DR: GPT-4o能有效增加或减少阴谋论信念，移除安全护栏后AI在推广阴谋论方面与反驳阴谋论同样有效，但使用准确信息提示可显著降低风险


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）的说服力是否更倾向于真相而非虚假信息，还是LLMs能同样容易地推广错误信念

Method: 通过三个预注册实验，让2,724名美国参与者与GPT-4o讨论他们不确定的阴谋论，模型被指示要么反驳（"debunking"）要么支持（"bunking"）该阴谋论，测试标准GPT-4o和移除安全护栏的"越狱"版本

Result: 移除安全护栏的GPT-4o在增加阴谋论信念方面与减少信念同样有效；支持阴谋论的AI获得更积极评价并增加对AI的信任；标准GPT-4o产生类似效果，OpenAI的安全护栏几乎无法阻止LLM推广阴谋论；纠正性对话能逆转新诱导的信念；提示GPT-4o仅使用准确信息能显著降低其增加阴谋论信念的能力

Conclusion: LLMs具有促进真相和虚假信息的强大能力，但存在潜在解决方案来帮助减轻这种风险，需要开发更有效的安全措施来防止LLMs推广错误信息

Abstract: Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against ("debunking") or for ("bunking") that conspiracy. When using a "jailbroken" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.

</details>


### [18] [Reinforced Efficient Reasoning via Semantically Diverse Exploration](https://arxiv.org/abs/2601.05053)
*Ziqi Zhao,Zhaochun Ren,Jiahong Zou,Liu Yang,Zhiwei Xu,Xuri Ge,Zhumin Chen,Xinyu Ma,Daiting Shi,Shuaiqiang Wang,Dawei Yin,Xin Xin*

Main category: cs.AI

TL;DR: ROSE提出了一种基于语义多样性探索的强化学习框架，通过语义熵分支策略和ε探索机制增强推理多样性，结合长度感知的段级优势估计器提升效率，在数学推理基准上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于MCTS的RLVR方法存在探索多样性有限和推理效率低的问题，需要改进以增强语言模型的推理能力。

Method: 提出ROSE框架：1）语义熵分支策略基于已采样推理路径的语义不确定性选择分支点生成新路径；2）ε探索机制从根节点随机启动推理防止搜索过度局部化；3）长度感知段级优势估计器奖励简洁正确推理，惩罚过长推理链。

Result: 在多个数学推理基准上使用Qwen和Llama模型进行实验，验证了ROSE在效果和效率上的优越性。

Conclusion: ROSE通过语义多样性探索和高效推理机制，有效解决了现有RLVR方法的局限性，提升了语言模型的推理性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.

</details>


### [19] [MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents](https://arxiv.org/abs/2601.05215)
*Tamil Sudaravan Mohan Doss,Michael Xu,Sudha Rao,Andrew D. Wilson,Balasaravanan Thoravi Kumaravel*

Main category: cs.AI

TL;DR: 提出了一个名为MineNPC-Task的用户创作基准和评估框架，用于在开放世界Minecraft中测试具有记忆感知和混合主动性的LLM智能体，通过真实玩家任务而非合成提示来评估智能体性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏在开放世界环境中评估具有记忆感知和混合主动性LLM智能体的标准化基准，需要基于真实玩家体验而非合成提示的任务来更准确地评估智能体在实际交互中的表现。

Method: 通过与专家玩家进行形成性和总结性协同游戏来收集任务，将任务规范化为具有明确前提条件和依赖结构的参数化模板，并配有机可检查的验证器，采用禁止外部知识捷径的有界知识策略。

Result: 使用GPT-4o评估了8位经验玩家的216个子任务，观察到代码执行、库存/工具处理、引用和导航方面的重复故障模式，同时发现混合主动性澄清和轻量级记忆支持下的恢复能力。参与者对交互质量和界面可用性评价积极，但强调需要更强的跨任务记忆持久性。

Conclusion: 提出了一个基于真实玩家体验的标准化评估框架，能够识别LLM智能体在开放世界环境中的故障模式和恢复机制，为未来记忆感知具身智能体的透明、可重复评估提供了完整任务套件、验证器和工具。

Abstract: We present \textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.
  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \textbf{216} subtasks across \textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Disco-RAG: Discourse-Aware Retrieval-Augmented Generation](https://arxiv.org/abs/2601.04377)
*Dongqi Liu,Hang Ding,Qiming Feng,Jian Li,Xurong Xie,Zhucun Xue,Chengjie Wang,Jiangning Zhang,Yabiao Wang*

Main category: cs.CL

TL;DR: Disco-RAG：一种基于话语结构的检索增强生成框架，通过构建语篇树和修辞图来提升LLM在知识密集型任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法通常将检索到的段落视为扁平无结构的信息，这限制了模型捕捉结构线索的能力，也制约了其从分散文档证据中综合知识的能力

Method: 提出Disco-RAG框架，通过构建语块内语篇树捕捉局部层次结构，构建语块间修辞图建模跨段落连贯性，并将这些结构整合到规划蓝图中指导生成过程

Result: 在问答和长文档摘要基准测试中表现出色，无需微调即在基准测试中达到最先进水平

Conclusion: 语篇结构在推进RAG系统发展中扮演重要角色，显式注入话语信号能显著提升生成质量

Abstract: Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.

</details>


### [21] [WESR: Scaling and Evaluating Word-level Event-Speech Recognition](https://arxiv.org/abs/2601.04508)
*Chenchen Yang,Kexin Huang,Liwei Fan,Qian Tu,Botian Jiang,Dong Zhang,Linqi Yin,Shimin Li,Zhaoye Fei,Qinyuan Cheng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 论文提出了WESR-Bench，一个用于非语言声音事件检测和定位的评估基准，包含21种声音事件的精细分类、900+专家标注语料，以及一个1700+小时的训练语料库和专用模型。


<details>
  <summary>Details</summary>
Motivation: 语音不仅传递语言信息，还包含丰富的非语言声音事件（如笑声、哭声）。虽然语义转录研究较多，但非语言事件的精确定位仍是一个关键但未充分探索的挑战。现有方法存在任务定义不足（类别覆盖有限、时间粒度模糊）和缺乏标准化评估框架的问题，阻碍了下游应用的发展。

Method: 1. 开发了包含21种声音事件的精细分类法，分为离散型（独立）和连续型（与语音混合）两类；2. 引入WESR-Bench评估集（900+语料），采用新的位置感知协议，将ASR错误与事件检测分离，实现对离散和连续事件的精确定位测量；3. 构建了1700+小时语料库，训练专用模型。

Result: 构建的专用模型超越了开源音频-语言模型和商业API，同时保持了ASR质量。WESR-Bench为建模真实世界丰富听觉场景提供了基础资源。

Conclusion: WESR将作为未来研究建模丰富真实世界听觉场景的基础资源，解决了非语言声音事件检测和定位的标准化评估问题，推动了该领域的发展。

Abstract: Speech conveys not only linguistic information but also rich non-verbal vocal events such as laughing and crying. While semantic transcription is well-studied, the precise localization of non-verbal events remains a critical yet under-explored challenge. Current methods suffer from insufficient task definitions with limited category coverage and ambiguous temporal granularity. They also lack standardized evaluation frameworks, hindering the development of downstream applications. To bridge this gap, we first develop a refined taxonomy of 21 vocal events, with a new categorization into discrete (standalone) versus continuous (mixed with speech) types. Based on the refined taxonomy, we introduce WESR-Bench, an expert-annotated evaluation set (900+ utterances) with a novel position-aware protocol that disentangles ASR errors from event detection, enabling precise localization measurement for both discrete and continuous events. We also build a strong baseline by constructing a 1,700+ hour corpus, and train specialized models, surpassing both open-source audio-language models and commercial APIs while preserving ASR quality. We anticipate that WESR will serve as a foundational resource for future research in modeling rich, real-world auditory scenes.

</details>


### [22] [ToolGate: Contract-Grounded and Verified Tool Execution for LLMs](https://arxiv.org/abs/2601.04688)
*Yanming Liu,Xinyue Peng,Jiannan Cao,Xinyi Wang,Songhang Deng,Jintao Chen,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: ToolGate：一个为LLM工具调用提供逻辑安全保证和可验证状态演化的前向执行框架，通过Hoare式契约和运行时验证确保状态仅通过已验证的工具执行更新。


<details>
  <summary>Details</summary>
Motivation: 现有LLM工具调用框架依赖自然语言推理来确定工具调用时机和结果提交，缺乏逻辑安全性和可验证性的形式化保证，可能导致无效或幻觉结果污染世界表示。

Method: ToolGate维护显式符号状态空间作为类型化键值映射，将每个工具形式化为包含前置条件和后置条件的Hoare式契约：前置条件检查当前状态是否满足调用要求，后置条件通过运行时验证确定工具结果是否能提交更新状态。

Result: 实验验证表明ToolGate显著提高了工具增强LLM系统的可靠性和可验证性，同时在复杂多步推理任务上保持竞争力，确保符号状态仅通过已验证的工具执行演化。

Conclusion: ToolGate为构建更可信和可调试的AI系统奠定了基础，这些系统将语言模型与外部工具集成，提供逻辑安全保证和可验证的状态演化。

Abstract: Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.

</details>


### [23] [CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters](https://arxiv.org/abs/2601.04885)
*Ao Sun,Xiaoyu Wang,Zhe Tan,Yu Li,Jiachen Zhu,Shu Su,Yuheng Jia*

Main category: cs.CL

TL;DR: CuMA框架通过文化混合适配器解决大语言模型文化对齐中的均值崩溃问题，使用人口感知路由分离冲突梯度，在文化多样性基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型服务全球用户时，对齐需要从强制普遍共识转向尊重文化多元性。现有密集模型在拟合冲突价值分布时会出现"均值崩溃"，收敛到无法代表不同文化群体的通用平均值。

Method: 提出CuMA（文化混合适配器）框架，将对齐视为条件容量分离问题。通过人口感知路由，内部化潜在文化拓扑结构，将冲突梯度显式解耦到专门的专家子空间中。

Result: 在WorldValuesBench、Community Alignment和PRISM等基准上的广泛评估显示，CuMA实现了最先进的性能，显著优于密集基线和仅基于语义的MoE方法。分析确认CuMA有效缓解了均值崩溃，保持了文化多样性。

Conclusion: CuMA通过文化混合适配器框架成功解决了大语言模型文化对齐中的均值崩溃问题，为服务全球用户的多文化对齐提供了有效解决方案。

Abstract: As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \textbf{\textsc{CuMA}} (\textbf{Cu}ltural \textbf{M}ixture of \textbf{A}dapters), a framework that frames alignment as a \textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \textsc{CuMA} internalizes a \textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.

</details>
