<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 14]
- [cs.LG](#cs.LG) [Total: 20]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 17]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 提出MDDC框架，通过数据质量诊断与修正提升边缘设备杂草检测性能，在固定轻量模型下实现5-25%的mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的农业杂草检测面临严格的计算资源、模型容量和实时推理延迟约束，无法通过模型扩展或集成来提升性能，需要数据层面的优化方案

Method: 提出模型驱动的数据修正框架，通过自动化错误分析将检测失败分为四类，采用结构化训练-修正-再训练流程，结合版本控制数据管理

Result: 在多个杂草检测数据集上，使用固定轻量检测器实现5-25%的mAP@0.5提升，证明数据质量优化能有效缓解固定模型容量下的性能瓶颈

Conclusion: 系统化的数据质量优化是提升边缘设备杂草检测性能的有效途径，在模型容量受限时，数据层面的改进能显著提升检测精度

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [2] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 提出一种新的半监督领域泛化方法，通过将模型特征与视觉语言模型的语义丰富特征空间对齐来提升性能，同时采用数据增强和正则化策略防止过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签准确性，而忽视了训练过程中的最大数据利用率，这限制了性能提升潜力。需要一种既能利用有限标注数据又能充分利用未标注数据的方法。

Method: 1) 将模型中间特征与视觉语言模型(VLM)的语义丰富且泛化的特征空间对齐，以促进领域不变性；2) 采用有效的图像级增强策略；3) 实施输出级正则化策略来最小化过拟合。

Result: 在四个基准测试上进行了广泛实验，与现有SSDG基线相比，该方法在定性和定量上都达到了最先进的(SOTA)结果。

Conclusion: 通过将模型特征与VLM特征空间对齐，并结合数据增强和正则化策略，能够有效解决SSDG问题，在数据利用率和防止过拟合方面优于现有方法，实现了性能的显著提升。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [3] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 提出Decoder Gradient Shields (DGS)防御机制，保护无盒模型水印解码器免受基于梯度泄露查询的攻击，通过梯度重定向和缩放防止水印移除器训练收敛。


<details>
  <summary>Details</summary>
Motivation: 现有无盒模型水印研究主要关注编码器的鲁棒性，而解码器被忽视，导致存在针对解码器的攻击。攻击者利用查询响应获取反向传播梯度来训练水印移除器，需要防御机制保护解码器。

Method: 提出DGS防御机制家族：DGS-O（输出层）、DGS-I（输入层）和DGS-L（中间层）。DGS-O有闭式解，所有DGS都有可证明的性能。通过联合设计水印通道梯度泄露查询的梯度重定向和缩放，防止水印移除器达到低损失值训练收敛。

Result: 在去雨和图像生成任务中，使用最先进的无盒水印技术，DGS在所有设置下实现了100%的防御成功率，同时保持解码器输出的图像质量。

Conclusion: DGS是有效的解码器防御机制，能够保护无盒模型水印免受基于梯度泄露的攻击，填补了现有水印研究中解码器安全性的空白。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [4] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR：首个支持测试时自适应检测未见新闻视频的假新闻视频检测框架，通过检索引导的适应范式解决新兴事件和未见主题的检测问题。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频，需要能够适应未见新闻视频的测试时自适应框架。

Method: 提出RADAR框架，采用检索引导的适应范式：1) 基于熵选择的检索机制，为目标域视频提供稳定（低熵）相关参考；2) 稳定锚点引导的对齐模块，通过分布级匹配将不稳定实例表示对齐到源域；3) 目标域感知的自训练范式，生成由稳定参考增强的信息性伪标签。

Result: 大量实验表明，RADAR在测试时假新闻视频检测方面取得优越性能，能够对未见假新闻视频主题实现强大的即时适应。

Conclusion: RADAR是首个支持测试时自适应检测未见新闻视频的假新闻视频检测框架，通过创新的检索引导适应范式，有效解决了现有方法无法检测新兴事件和未见主题的局限性。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [5] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: 提出SMc2f框架，通过粗到细的流程改进自动驾驶场景挖掘，结合视觉语言模型进行粗筛选、构建案例数据库，并引入文本-轨迹对比学习进行细粒度匹配，显著提升检索质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有RefAV框架仅基于轨迹标签进行检索，忽略了自然语言与原始RGB图像的直接联系，且依赖上游3D目标检测和跟踪的质量，轨迹数据不准确会导致时空定位错误。需要更鲁棒的场景挖掘方法。

Method: 提出SMc2f粗到细流程：1) 使用视觉语言模型进行粗粒度图像-文本过滤；2) 在RefAV基础上构建成功挖掘案例数据库，自动检索示例进行少样本条件学习；3) 引入文本-轨迹对比学习，在共享嵌入空间中将匹配对拉近、不匹配对推远，获得细粒度匹配器。

Result: 在公开数据集上的实验表明，该方法在检索质量和效率方面都取得了显著提升。

Conclusion: SMc2f框架通过结合视觉语言模型、案例数据库和对比学习，有效解决了现有场景挖掘方法的局限性，为自动驾驶系统的安全验证提供了更鲁棒的解决方案。

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [6] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 本文提出首个大规模遥感视频指代分割基准RS-RVOS Bench和基于SAM的记忆质量控制框架MQC-SAM，解决了遥感场景中目标显著性弱、视觉信息截断以及记忆偏差积累等问题。


<details>
  <summary>Details</summary>
Motivation: 遥感视频指代分割面临目标显著性弱、动态场景视觉信息截断的挑战，现有研究缺乏大规模专用基准，且现有模型存在初始记忆构建偏差和噪声积累导致错误传播的问题。

Method: 1) 构建首个大规模遥感视频指代分割基准RS-RVOS Bench，包含111个视频序列、约25,000帧和213,000个时序指代标注，采用严格的因果感知标注策略；2) 提出记忆质量感知的在线指代分割框架MQC-SAM，包含时序运动一致性模块进行初始记忆校准，以及解耦注意力记忆集成机制进行动态质量评估和选择性更新。

Result: 在RS-RVOS Bench上的大量实验表明，MQC-SAM达到了最先进的性能。

Conclusion: 本文通过数据和方法的双重贡献推进了遥感视频指代分割研究，提出的基准和框架有效解决了现有挑战，为未来研究提供了重要基础。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [7] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: FiCoP提出了一种从全局匹配转向空间约束的patch级对应的细粒度对应位姿估计框架，通过patch-to-patch关联矩阵作为结构先验来缩小匹配范围，在开放词汇6D物体位姿估计中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体位姿估计方法依赖无约束的全局匹配策略，在开放世界场景中，将锚点特征与整个查询图像空间匹配会引入过多歧义，目标特征容易与背景干扰物混淆，导致性能下降。

Method: 1) 物体中心解耦预处理：从环境噪声中分离语义目标；2) 跨视角全局感知模块：融合双视角特征，通过显式上下文推理建立结构共识；3) Patch关联预测器：生成精确的块级关联图，作为空间过滤器实现细粒度、抗噪声匹配。

Result: 在REAL275和Toyota-Light数据集上，FiCoP相比最先进方法分别提高了8.0%和6.1%的平均召回率，证明了其在复杂、无约束开放世界环境中为机器人提供鲁棒和泛化感知的能力。

Conclusion: FiCoP通过从噪声敏感的全局匹配转向空间约束的patch级对应，有效解决了开放词汇6D位姿估计中的歧义问题，为机器人在开放世界环境中的操作提供了更可靠的感知基础。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [8] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: FedDCG提出了一种联邦学习框架，同时解决类别和领域泛化问题，通过领域分组策略和可学习网络提升未见类别和未见领域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理未见类别或未见领域问题，缺乏同时考虑两者的联合框架。在联邦学习场景中，需要同时处理类别和领域泛化挑战。

Method: 提出FedDCG方法：1）领域分组策略，在每个组内训练类别泛化网络以避免决策边界混淆；2）推理时基于领域相似性聚合类别泛化结果；3）使用可学习网络增强类别泛化能力；4）解耦机制分离通用知识和领域特定知识。

Result: 在多个数据集上的广泛实验表明，FedDCG在准确性和鲁棒性方面优于最先进的基线方法。

Conclusion: FedDCG成功解决了联邦学习中同时处理类别和领域泛化的挑战，通过联合学习框架实现了更好的泛化性能。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [9] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: VILTA：一种将视觉语言模型集成到自动驾驶闭环训练中的新框架，通过直接编辑周围车辆的未来轨迹来生成多样化挑战性场景，解决长尾安全问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统安全部署面临长尾问题，即罕见但关键的驾驶场景在真实数据中严重不足。现有方法（基于规则的启发式、重采样、生成模型）生成多样性和新颖性有限，而两阶段VLM方法受下游算法泛化能力限制。

Method: 提出VILTA框架，将VLM集成到自动驾驶代理的闭环训练中。VLM理解动态驾驶环境，通过直接、细粒度编辑周围代理的未来轨迹来战略性地生成挑战性场景，充分发挥VLM的强大泛化能力。

Result: 该方法显著增强了自动驾驶策略的安全性和鲁棒性，特别是在处理关键长尾事件方面表现出色，超越了传统方法的范围。

Conclusion: VILTA通过将VLM直接集成到训练循环中，利用其强大的泛化能力创建多样化、合理的挑战性场景，有效解决了自动驾驶的长尾安全问题，提高了系统的整体安全性。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [10] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

TL;DR: 提出DSOD框架解决源自由目标检测中的源偏差问题，通过VFM辅助特征注入和语义感知特征正则化，在多个跨域基准上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有源自由目标检测方法存在源偏差问题，即适应后的模型仍然偏向源域特征，导致泛化能力差和自训练过程中的错误累积

Method: 提出DSOD框架：1) 统一特征注入模块，通过简单尺度扩展和域感知自适应加权将VFM特征集成到CNN骨干网络；2) 语义感知特征正则化，约束特征学习防止过拟合源域特征；3) 针对计算受限场景提出DSOD-distill变体，采用双教师蒸馏方案

Result: 在多个基准测试中超越现有SOTA方法：正常到雾天天气适应达到48.1% AP，跨场景适应达到39.3% AP，合成到真实适应达到61.4% AP

Conclusion: DSOD框架能有效缓解源自由目标检测中的源偏差问题，通过VFM辅助的特征增强和正则化机制显著提升跨域适应性能，同时提供计算友好的蒸馏变体

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [11] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity：首个开源、大规模、多领域工程图数据集，包含全面的结构化标注，用于自动化图表解析


<details>
  <summary>Details</summary>
Motivation: 当前AI系统难以理解和处理工程图中的视觉-结构知识，这阻碍了AI在科学发现工作流中的全面参与。工程图解析、技术图纸分析和视觉推理对于假设生成、实验设计和科学发现至关重要，但缺乏合适的标注数据集。

Method: 创建了一个开放、大规模、多领域的工程图数据集，包含层次化组件关系、连接和语义元素的全面结构化标注。该数据集支持多模态大语言模型处理工程图解析任务。

Result: 提出的Enginuity数据集将能够支持结构化图表解析、跨模态信息检索和AI辅助工程仿真等关键下游任务。

Conclusion: Enginuity数据集将为科学发现AI带来变革性影响，使AI系统能够理解和操作工程图中嵌入的视觉-结构知识，打破当前阻碍AI全面参与科学工作流的基本障碍。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [12] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 将事件流映射到对数强度和强度导数估计，嵌入动态线性系统模型，实现事件数据的逆滤波


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器（神经形态相机）输出稀疏、异步的事件流，但作为非线性系统难以与大多数计算成像和光学系统设计所依赖的线性前向模型集成

Method: 提出基于物理的处理流程：将事件流映射到像素级对数强度和强度导数估计，将这些测量嵌入具有时变点扩散函数的动态线性系统模型，使用频域维纳反卷积进行逆滤波

Result: 在模拟中验证了调制离焦下单点和重叠点源的处理效果，并在真实事件数据（可调焦望远镜观测星场）上展示了源定位和可分离性

Conclusion: 该框架为事件感知和基于模型的计算成像之间建立了实用桥梁，特别适用于动态光学系统

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [13] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA是一个专门为灾害响应设计的视觉问答基准数据集，包含1,395张真实灾害图像和4,405个专家标注的问答对，用于评估模型在灾害场景下的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾害期间提供低延迟的态势信息，但现有的通用视觉问答模型在灾害响应这种复杂、安全关键的推理任务中的适用性尚不清楚。需要专门针对灾害场景的基准来评估和指导模型开发。

Method: 创建DisasterVQA数据集，包含1,395张真实灾害图像（洪水、野火、地震等）和4,405个专家标注的问答对。问题基于FEMA ESF和OCHA MIRA等人道主义框架设计，涵盖二元选择、多项选择和开放式问题，涉及态势感知和操作决策任务。

Result: 评估了7个最先进的视觉语言模型，发现模型在不同问题类型、灾害类别、区域和人道主义任务上表现差异显著。模型在二元问题上准确率高，但在细粒度定量推理、物体计数和上下文敏感解释方面表现不佳，特别是在代表性不足的灾害场景中。

Conclusion: DisasterVQA为灾害响应提供了具有挑战性和实用性的基准，能够指导开发更鲁棒、更具操作意义的视觉语言模型。数据集已公开可用，有助于推动灾害响应AI技术的发展。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [14] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 提出FBL联邦平衡学习，通过客户端样本平衡解决非IID数据下的客户端漂移问题，使用知识填充和知识采样实现样本平衡


<details>
  <summary>Details</summary>
Motivation: 在联邦学习的非IID设置中，全局模型会出现客户端漂移问题，严重影响最终性能。现有方法主要基于损失函数或梯度纠正已偏离的全局模型，忽视了客户端样本的影响

Method: 提出FBL方法，在客户端侧通过知识填充和知识采样实现样本平衡，使用边缘侧生成模型；设计知识对齐策略和知识丢弃策略；扩展到真实复杂场景，允许不同客户端采用不同方法

Result: 大量实验表明，该方法优于最先进的基线方法

Conclusion: 通过客户端样本平衡可以有效解决联邦学习中的客户端漂移问题，FBL方法在非IID设置下表现出色

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [15] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的基于被动传感器（PIR和门传感器）的人类活动识别方法，通过聚类活动到不同时间段并编码时间信息，提高了老年人在智能家居中的活动识别准确率。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要让老年人能够独立安全地在家中生活。使用被动传感器监测日常活动对于预防性医疗干预很重要，但现有方法在有效利用时间信息方面存在挑战。

Method: 将活动聚类到早晨、下午和夜晚，并将这些信息编码到特征加权方法中，计算不同的互信息矩阵。扩展特征向量，加入一天中的时间和一周中的天数作为循环时间特征，并添加用户位置跟踪特征。

Result: 在四个真实世界数据集中，三个数据集上相比现有最先进方法获得了改进的准确率和F1分数，在低数据情况下获得最高增益。

Conclusion: 该方法展示了开发有效智能家居解决方案以支持老年人原地养老的潜力，通过更好地利用时间信息提高了活动识别性能。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [16] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 这篇综述研究了基于连续血糖监测数据的机器学习模型预测1型糖尿病患者低血糖事件的能力，比较了不同预测时间范围和模型性能，发现1小时内的预测效果最佳，传统ML方法在分类任务中表现更好，而深度学习在回归任务中更优。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用。低血糖（血糖低于70 mg/dL）会增加死亡风险，因此需要开发能够准确预测低血糖的机器学习模型来改善糖尿病管理。

Method: 综述分析了基于连续血糖监测数据的机器学习模型，包括回归模型（预测血糖值）和分类模型（识别低血糖事件）。比较了短期（15-120分钟）和长期（3-24小时以上）预测时间范围内的模型性能，并探讨了影响性能的因素。

Result: 1）1小时内的预测时间范围效果最佳；2）传统机器学习方法在分类任务中表现最好，深度学习在回归任务中更优，单一模型无法在多个预测时间范围内都表现良好；3）多变量数据集和输入序列长度影响模型性能；4）个性化数据能提升性能，但由于数据质量有限，基于人群的模型更受青睐。

Conclusion: 机器学习模型能够有效预测1型糖尿病患者的低血糖事件，但预测时间范围、模型选择、数据特征和个性化程度都会影响预测性能。未来需要更多高质量数据和更先进的模型来进一步提高预测准确性。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [17] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: IPEC是一种测试时增量原型增强方法，通过利用先前查询样本的信息优化原型估计，提升小样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的小样本方法在测试时假设批次独立性，无法利用先前批次积累的宝贵知识，限制了性能提升。

Method: 提出IPEC方法：1）维护动态辅助集，选择性纳入高置信度查询样本；2）设计双重过滤机制，基于全局预测置信度和局部判别能力评估样本质量；3）将辅助集与支持集聚合构建更稳定的原型；4）基于贝叶斯解释设计"预热-测试"两阶段推理协议。

Result: 在多个小样本分类任务上的广泛实验验证了IPEC方法的优越性能。

Conclusion: IPEC通过测试时增量学习有效减少对初始支持集的依赖，构建更稳定和具有代表性的原型，显著提升小样本分类性能。

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [18] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 本文分析了SGD在病态优化中的"可疑对齐"现象，发现梯度与主导子空间的对齐呈现先降后升最终稳定的两阶段行为，并揭示了步长选择如何影响这一现象。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在病态优化中的"可疑对齐"现象，即梯度与Hessian主导子空间的对齐行为，这种对齐被称为"可疑"的，因为沿着高度对齐的主导子空间的梯度更新实际上无法有效降低损失。

Method: 在高维二次设置中进行细粒度分析，提出步长条件理论，区分对齐减少和对齐增加的不同步长区间，分析自适应临界步长η_t^*的作用，并证明在常数步长和大初始化下SGD的两阶段行为。

Result: 发现在低对齐区域存在自适应临界步长η_t^*，步长小于它时对齐减少，大于它时对齐增加；在高对齐区域，对齐具有自校正性。在足够病态条件下，存在步长区间使得向bulk子空间投影能降低损失，而向主导子空间投影反而增加损失。

Conclusion: SGD在病态优化中确实存在"可疑对齐"的两阶段现象，步长选择是关键因素。该理论解释了为什么向主导子空间投影梯度更新是无效的，并为理解SGD在病态问题中的行为提供了理论框架。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [19] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

TL;DR: PC²DAE是一种物理信息去噪自编码器，通过将物理约束嵌入网络架构来解决无人机传感器数据稀缺问题，相比传统深度学习方法在数据量极少的情况下表现更好。


<details>
  <summary>Details</summary>
Motivation: 无人机搭载的低成本传感器存在基线漂移、交叉敏感性和响应延迟等问题，而传统深度学习方法需要大量数据，这在有限的无人机飞行任务中难以获得。

Method: 提出PC²DAE物理信息去噪自编码器，通过softplus激活函数强制非负浓度估计和物理合理的时间平滑，将物理约束直接嵌入网络架构而非依赖损失函数惩罚。设计了两种变体：PC²DAE-Lean（21k参数）用于边缘部署，PC²DAE-Wide（204k参数）用于离线处理。

Result: 在仅7,894个同步1Hz样本（约2.2小时飞行数据）上评估，PC²DAE-Lean实现了67.3%平滑度改进和90.7%高频噪声减少，且零物理违规。五个基线方法产生15-23%负输出。精简版比宽版表现更好（+5.6%平滑度）。

Conclusion: PC²DAE通过将物理约束直接嵌入网络架构，在数据稀缺情况下有效解决了无人机传感器去噪问题，精简架构配合强归纳偏置能防止过拟合，训练时间短且适合边缘部署。

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [20] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: EVO算法利用极值理论处理强化学习中的极端风险事件，通过极值分位数优化和优先级回放机制，显著减少约束违反，同时保持策略性能。


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习使用期望约束，忽略了尾部分布中的罕见但高影响的极端值事件（如黑天鹅事件），可能导致严重的约束违反。需要一种能处理极端风险的方法。

Method: 提出EVO算法：1) 利用极值理论建模极端奖励和成本样本；2) 引入极值分位数优化目标捕捉成本尾部分布；3) 采用极端优先级回放机制，放大罕见但高影响样本的学习信号。

Result: 理论上：建立了策略更新期间预期约束违反的上界，保证在零违反分位数水平上的严格约束满足。EVO比期望方法具有更低的约束违反概率，比分位数回归方法具有更低的方差。实验上：EVO显著减少了训练期间的约束违反，同时保持与基线方法竞争的策略性能。

Conclusion: EVO算法通过极值理论有效处理强化学习中的极端风险事件，在保证策略性能的同时显著降低约束违反，为解决现实世界强化学习应用的安全挑战提供了新方法。

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [21] [Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding](https://arxiv.org/abs/2601.12095)
*Hamidreza Sadeghi,Saeedeh Momtazi,Reza Safabakhsh*

Main category: cs.LG

TL;DR: 提出神经同构场，使用嵌入向量表示数字以解决神经网络处理极值时的数值不稳定问题，该嵌入能保持有理数域上的代数运算性质。


<details>
  <summary>Details</summary>
Motivation: 神经网络在处理极小数或极大数时面临溢出、下溢和输出不稳定等问题，需要一种能保持代数性质同时避免数值不稳定的数字表示方法。

Method: 提出神经同构场作为代数结构（如群、域）的神经抽象，使用固定长度的嵌入向量表示数字，这些嵌入向量在计算过程中保持代数结构，特别是能保持有理数域上的加法、乘法和比较运算。

Result: 加法运算表现优异，在恒等性、封闭性和结合性等关键代数测试中准确率超过95%；乘法运算面临挑战，在不同代数性质测试中准确率在53%到73%之间。

Conclusion: 该方法在保持加法运算的代数性质方面表现出色，但在处理乘法运算方面仍有改进空间，为神经网络中数值表示的代数结构保持提供了新思路。

Abstract: Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.

</details>


### [22] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3构建的领域适应大语言模型，专门用于空间天气和太阳物理学的教育问答，通过科学文献和GPT-4生成的数据训练，在零样本设置下优于通用模型，在教育解释方面与指令调优模型竞争。


<details>
  <summary>Details</summary>
Motivation: 太阳活动（太阳耀斑、日冕物质抛射、地磁暴）对卫星、航空、电网等关键基础设施有重大影响，极端事件可能造成巨大经济损失。当前大语言模型缺乏领域专业知识，且无法清晰解释复杂的空间科学概念，需要专门的教育工具。

Method: 基于LLaMA-3基础模型构建SolarGPT-QA问答系统，使用科学文献和GPT-4生成的大规模问答数据进行训练，并用Grok-3以学生友好的故事风格进行精炼。结合领域自适应预训练和教学微调，平衡科学准确性和教育效果。

Result: 人工成对评估显示，SolarGPT-QA在零样本设置下优于通用模型，在教育解释方面与指令调优模型竞争。小型试点学生理解研究表明生成的解释清晰度和可访问性有所改善。消融实验表明领域自适应预训练与教学微调结合对平衡科学准确性和教育效果很重要。

Conclusion: SolarGPT-QA代表了向更广泛的SolarGPT框架迈出的第一步，该框架旨在空间科学教育和预测。通过结合领域专业知识和教学能力，该系统能够提供准确且易于理解的太阳活动解释，有助于提高空间天气意识和教育效果。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [23] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: IceWatch是一个结合空间视觉和时序物理动态的深度学习框架，用于冰川湖溃决洪水预测，提高预测可靠性和实时性


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法依赖水文建模、阈值监测和人工卫星图像分析，存在更新慢、依赖人工、云干扰和现场数据缺失等问题，需要更自动化和可靠的预测系统

Method: 提出IceWatch框架，包含视觉组件RiskFlow（基于CNN的Sentinel-2卫星图像分类器）和表格组件（TerraFlow建模冰川速度，TempFlow预测近地表温度），通过多模态融合实现物理信息增强的GLOF预测

Result: 系统具有强大的预测性能、快速数据处理能力、对噪声和缺失信息的鲁棒性，能够实现实时应用，并通过交叉验证提高GLOF检测的可靠性和可解释性

Conclusion: IceWatch为自动化、可扩展的GLOF预警系统铺平道路，具有整合多种传感器输入和全球冰川监测活动的潜力

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [24] [Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems](https://arxiv.org/abs/2601.12362)
*Natthapong Promsricha,Chotirawee Chatpattanasiri,Nuttavut Kerdgongsup,Stavroula Balabani*

Main category: cs.LG

TL;DR: 提出基于机器学习的控制阀粘滞故障检测与预测框架，使用常规过程信号（OP和PV），LSTM模型在真实炼油厂数据上实现最高精度，可提前4小时预测粘滞故障。


<details>
  <summary>Details</summary>
Motivation: 控制阀粘滞是工业过程系统中常见的故障，会导致系统不稳定、设备磨损和维护成本增加。许多工厂仍使用缺乏实时监控的传统阀门，使得早期预测具有挑战性。

Method: 开发了三种深度学习模型：CNN、CNN-SVM混合模型和LSTM网络。使用基于斜率比分析的数据驱动标注方法，在真实炼油厂数据集上训练模型。

Result: LSTM模型取得了最高精度，能够提前4小时预测控制阀粘滞故障。据作者所知，这是首个基于真实工业数据实现ML早期预测控制阀粘滞的研究。

Conclusion: 提出的框架可集成到现有控制系统中，支持预测性维护，减少停机时间，避免不必要的硬件更换。

Abstract: Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.

</details>


### [25] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT框架通过采样、提示和优化三个角度解决RL微调生成模型时的多样性崩溃问题，在保持任务对齐的同时显著提升生成多样性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型时存在多样性崩溃问题，即优化过程导致策略收敛到狄拉克分布，限制了生成多样性，而实际应用需要既对齐任务又保持多样性的生成结果。

Method: 提出DRIFT框架，从三个角度激励多样性：1) 采样奖励集中子集过滤异常值防止过早崩溃；2) 使用随机变体提示扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: 实验显示DRIFT在任务对齐和生成多样性方面达到帕累托最优，在同等对齐水平下多样性提升9.08%~43.46%，在同等多样性水平下对齐度提升59.65%~65.86%。

Conclusion: DRIFT框架成功解决了RL微调生成模型时的多样性崩溃问题，实现了任务对齐与生成多样性的平衡，为需要多样化候选生成的应用提供了有效解决方案。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [26] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发了一个可解释的机器学习框架用于儿童牙科风险分层，优先考虑可解释性和伦理部署而非最大预测准确性


<details>
  <summary>Details</summary>
Motivation: 儿童牙科疾病是全球最普遍且不公平的慢性健康状况之一。虽然流行病学证据显示口腔健康结果与社会经济和人口因素相关，但大多数牙科AI应用依赖基于图像的诊断和黑盒预测模型，限制了在儿童群体中的透明度和伦理适用性。

Method: 使用人口水平的儿童数据（包括年龄、收入贫困比、种族/民族、性别和病史）训练监督机器学习模型。使用ROC分析和校准曲线评估性能，通过SHAP实现可解释性，提供全局和个体层面的预测解释。

Result: 模型实现了适度的区分能力（AUC=0.61），具有保守的校准特性，在高概率水平下低估风险。SHAP分析显示年龄和收入贫困比是预测风险的最强贡献因素，其次是种族/民族和性别。

Conclusion: 可解释的机器学习能够实现透明的、预防导向的儿童牙科风险分层，支持人群筛查和公平资源分配，而非用于诊断决策。

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [27] [Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks](https://arxiv.org/abs/2601.12519)
*Abdullah Umut Hamzaogullari,Arkadas Ozakin*

Main category: cs.LG

TL;DR: 提出改进拉格朗日神经网络(LNNs)的稳定性方法，包括Hessian正则化、专用激活函数和物理感知坐标缩放，成功训练复杂系统并应用于相对论场景。


<details>
  <summary>Details</summary>
Motivation: 拉格朗日神经网络可以从轨迹数据学习任意拉格朗日量，但其不寻常的优化目标导致显著的训练不稳定性，限制了其在复杂系统中的应用。

Method: 提出三种改进：1) Hessian正则化方案，惩罚拉格朗日量对速度二阶导数中的非物理特征；2) 更适合学习拉格朗日量的激活函数；3) 物理感知坐标缩放以提高稳定性。还扩展正则化以惩罚洛伦兹特征违反，处理相对论场景。

Result: 改进架构成功训练前所未有的复杂系统（包括三摆），在双摆系统中验证损失降低96.6%，稳定性提高90.68%。首次从轨迹数据预测AdS₄时空度量下的测地线拉格朗日量。

Conclusion: 该方法显著扩展了LNNs在科学发现任务中的实际应用，为物理中几何结构的自动发现（包括从测地线轨迹提取时空度量张量分量）开辟了新可能性。

Abstract: Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.

</details>


### [28] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

TL;DR: 论文研究在线集中充电调度问题(OCCSP)，通过游戏化建模，使用DAgger训练学习代理，在蒙特利尔实际案例中每年可节省数千万美元成本


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车动态到达时的实时充电调度问题，需要在容量限制下平衡负载，现有方法在复杂性和泛化能力方面存在不足

Method: 1) 将问题游戏化建模为在时间和容量约束网格上放置充电块；2) 设计启发式策略；3) 使用专家演示训练学习代理；4) 采用数据集聚合(DAgger)进行改进

Result: 游戏化方法降低了模型复杂度，获得了比向量化方法更紧的泛化边界。使用DAgger训练的image-to-movement模型在多种EV到达模式下始终优于启发式基线、向量化方法和监督学习代理，在蒙特利尔案例中每年可降低数千万美元系统成本

Conclusion: 游戏化学习能有效增强负载平衡，具有显著的经济价值，能够推迟昂贵的电网升级需求，为解决OCCSP问题提供了有前景的方法

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [29] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

TL;DR: 提出基于浮点编码、惩罚驱动的单目标进化框架，用于生成通用对抗扰动，在降低可见性的同时提高攻击成功率


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动能够用单一噪声模式攻击多个输入，进化算法因其能够处理非凸、无梯度优化问题而成为有前景的生成方法

Method: 采用浮点编码的基因表示以适应深度学习规模，结合动态进化算子与自适应调度，使用模块化PyTorch实现，通过周期性切换批次防止过拟合

Result: 在ImageNet数据集上实验表明，该方法相比现有进化方法能生成范数更小、误分类效果更好、收敛更快的扰动

Conclusion: 该方法展示了生成通用对抗扰动的鲁棒性和可扩展性，适用于多种深度学习架构

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [30] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: RLVR微调导致LLM过度自信，SFT校准更好但性能提升小；提出校准感知RL方法，在保持性能的同时降低ECE分数达9点


<details>
  <summary>Details</summary>
Motivation: LLM在决策任务中需要可靠的置信度估计，以便下游系统决定何时信任模型或使用备用机制。研究两种主流微调范式（SFT和RLVR）的校准特性差异。

Method: 系统研究SFT和RLVR的校准特性；诊断RLVR失败原因（决策token作为提取步骤不携带置信信息）；提出校准感知RL方法，直接调整决策token概率。

Result: RLVR提高任务性能但产生极度过度自信模型；SFT校准更好（即使在分布偏移下）但性能提升较小；提出的方法保持RLVR准确度水平，同时减少ECE分数达9点。

Conclusion: RLVR微调导致校准问题，决策token机制是根本原因；提出的校准感知RL方法能有效缓解过度自信，为LLM决策任务提供更可靠的置信度估计。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [31] [TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction](https://arxiv.org/abs/2601.13422)
*Dahai Yu,Rongchao Xu,Dingyi Zhuang,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

TL;DR: TrustEnergy：一个用于准确可靠用户级能源使用预测的统一框架，通过分层时空表示和顺序保形分位数回归实现5.4%的预测精度提升和5.7%的不确定性量化改进。


<details>
  <summary>Details</summary>
Motivation: 现有能源使用预测方法存在两个主要问题：1）大多忽视家庭间的空间相关性或无法扩展到个体化预测；2）由于极端天气等因素导致的能源使用动态不确定性，现有工作未充分探索不确定性量化。需要准确可靠的用户级预测来支持电网管理、基础设施规划和灾害响应等应用。

Method: TrustEnergy框架包含两个关键技术组件：1）分层时空表示模块，使用新型记忆增强时空图神经网络高效捕获宏观和微观能源使用模式；2）顺序保形分位数回归模块，动态调整不确定性边界，确保随时间推移的有效预测区间，无需对底层数据分布做强假设。

Result: 通过与佛罗里达州电力供应商合作实施和评估，TrustEnergy相比最先进的基线方法，实现了5.4%的预测精度提升和5.7%的不确定性量化改进。

Conclusion: TrustEnergy提供了一个统一框架，能够准确可靠地进行用户级能源使用预测，有效解决了现有方法在空间相关性建模和不确定性量化方面的不足，为电网管理、基础设施规划和灾害响应等实际应用提供了更好的支持。

Abstract: Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.

</details>


### [32] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 联邦学习在时间概念漂移下表现不佳，标准FedAvg在Fashion-MNIST的季节性漂移中准确率从74%降至28%。提出客户端经验回放方法，每个客户端维护少量历史样本缓冲区，无需修改服务器聚合，仅用每类50个样本即可将准确率恢复至78-82%。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临时间概念漂移的挑战，即客户端数据分布随时间变化。标准FedAvg方法在这种场景下会出现灾难性遗忘问题，导致模型性能严重下降。

Method: 提出客户端经验回放方法：每个客户端维护一个小型历史样本缓冲区，在本地训练时将缓冲区中的历史样本与当前数据混合使用。该方法不需要修改服务器端的聚合算法，保持了联邦学习的标准框架。

Result: 在Fashion-MNIST的季节性漂移实验中，标准FedAvg准确率从74%降至28%。使用每类50个样本的缓冲区后，准确率恢复至78-82%，有效防止了灾难性遗忘。消融研究显示存在明显的内存-准确率权衡关系。

Conclusion: 客户端经验回放是一种简单有效的联邦学习抗遗忘方法，仅需少量历史样本即可显著缓解时间概念漂移带来的性能下降，且无需改变联邦学习的基本架构。

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [33] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: 提出FG-OrIU框架，通过特征和梯度的正交约束实现深度遗忘，解决增量遗忘中的表面遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法主要在参数层面抑制或混淆知识，缺乏特征和梯度层面的显式约束，导致"表面遗忘"——残留信息仍可恢复。这种不完整遗忘存在安全风险，并破坏保留平衡，特别是在增量遗忘场景中。

Method: 提出FG-OrIU框架：1) 使用SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间；2) 实施双重正交约束：特征正交投影防止特征混合，梯度正交投影防止更新时重新引入遗忘知识；3) 动态子空间适应：合并新遗忘子空间并收缩保留子空间，在连续遗忘任务中保持稳定平衡。

Result: 大量实验证明了该方法的有效性，能够实现深度遗忘（遗忘效果不可逆），同时保持保留知识的稳定性。

Conclusion: FG-OrIU是首个在特征和梯度层面统一正交约束的增量遗忘框架，解决了表面遗忘问题，实现了安全可靠的深度遗忘，在连续遗忘任务中保持了移除与保留的平衡。

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [34] [Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment](https://arxiv.org/abs/2601.14022)
*Rodrigo Pereira David,Luciano Araujo Dourado Filho,Daniel Marques da Silva,João Alfredo Cal-Braz*

Main category: cs.LG

TL;DR: 提出基于机器学习的框架，在相同真实驾驶条件下公平比较内燃机车和电动车的CO2排放


<details>
  <summary>Details</summary>
Motivation: 道路运输脱碳需要一致透明的方法来比较不同车辆技术的CO2排放，现有方法缺乏在相同真实驾驶条件下的公平比较

Method: 使用循环神经网络分别训练ICEV和EV模型，学习从驾驶变量（速度、加速度、温度）到内部执行变量（扭矩、油门）和瞬时CO2当量排放率的映射，构建反事实场景进行对比

Result: 建立了一个可扩展的框架，能够在统一瞬时排放指标下公平评估动力系统技术，支持数据驱动的车辆碳性能评估

Conclusion: 该机器学习框架为在真实操作条件下进行可信、可重复的车辆技术比较提供了基础，有助于道路运输脱碳决策

Abstract: Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 提出一种基于环境存活性而非奖励的自我训练架构，通过行为在真实资源约束下的存续进行选择，防止奖励黑客攻击和语义漂移，实现可持续的开放式自我改进。


<details>
  <summary>Details</summary>
Motivation: 传统自我训练系统因缺乏外部数据质量判断标准而退化，容易出现奖励黑客攻击和语义漂移问题。需要一种在稀疏外部反馈和有限内存下实现稳定自我训练的系统架构。

Method: 提出基于环境存活性而非奖励的自我训练架构：候选行为在真实资源约束下执行，只有那些环境效果持久且保留未来交互可能性的行为才会被传播。环境不提供语义反馈、密集奖励或任务特定监督，选择仅通过行为作为世界改变事件的差异存续进行。

Result: 分析语义动态显示，改进主要通过有效且可重复策略在整合和修剪机制下的持久性实现（负空间学习范式）。模型发展出元学习策略（如故意实验失败以获取信息性错误消息），无需明确指令。环境基础选择使可持续开放式自我改进成为可能。

Conclusion: 环境基础选择能够实现可持续的开放式自我改进，为构建更鲁棒和可泛化的自主系统提供了可行路径，无需依赖人类策划数据或复杂奖励塑造。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [36] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard是一个即插即用的防御框架，通过基于模拟的训练来增强计算机使用代理的安全性，使用神经符号模拟管道生成高风险GUI交互轨迹，在模拟环境中学习拦截和纠正不安全推理链。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型集成到计算机使用代理中，使其能够通过图形用户界面自主与操作系统交互，执行复杂任务。这种自主性带来了严重的安全风险：恶意指令或视觉提示注入可能触发不安全的推理并导致有害的系统级操作。现有的基于检测的防御方法虽然能防止损害，但通常会过早中止任务，降低了代理的实用性。

Method: 提出MirrorGuard防御框架，采用基于模拟的训练方法。设计了一个新颖的神经符号模拟管道，在纯文本模拟环境中生成逼真的高风险GUI交互轨迹，捕获不安全的推理模式和潜在系统危险，而无需执行真实操作。在模拟环境中，MirrorGuard学习在CUAs产生和执行不安全操作之前拦截和纠正不安全的推理链。

Result: 在真实世界测试中，跨多个基准和CUA架构的广泛评估显示，MirrorGuard显著降低了安全风险。例如，在字节跳动的UI-TARS系统上，它将不安全率从66.5%降低到13.0%，同时保持较低的误拒率（FRR）。相比之下，最先进的GuardAgent仅将不安全率降低到53.9%，且误拒率高出15.4%。

Conclusion: MirrorGuard证明了基于模拟的防御方法能够在保持代理基本实用性的同时，提供强大的真实世界保护。该工作表明，通过模拟生成的防御机制可以有效增强计算机使用代理的安全性，而不会过度影响其功能性。

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [37] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 研究发现当前基于概率的置信度指标无法有效捕捉推理步骤间的因果依赖关系，主要反映表面流畅度而非逻辑结构，并提出新的对比因果度量方法


<details>
  <summary>Details</summary>
Motivation: 挑战当前普遍假设——即概率置信度指标能反映推理质量，质疑这些指标是否真正捕捉到推理步骤间的因果依赖关系

Method: 引入三类步间因果扰动，系统性地破坏推理步骤间的依赖关系但保持局部流畅度；提出对比因果度量方法，显式隔离步间因果依赖

Result: 即使严重干预（如硬注意力掩码阻止模型关注先前推理步骤），选择准确率仅轻微下降；现有概率指标对逻辑结构不敏感，主要捕捉表面流畅度或分布先验

Conclusion: 现有概率置信度指标不能有效评估推理质量，提出的对比因果度量方法在输出选择中比现有概率方法更忠实

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [38] [CTPD: Cross Tokenizer Preference Distillation](https://arxiv.org/abs/2601.11865)
*Truong Nguyen,Phi Van Dat,Ngan Nguyen,Linh Ngo Van,Trung Le,Thanh Hong Nguyen*

Main category: cs.CL

TL;DR: CTPD是首个在异构分词器模型间转移人类偏好对齐行为的统一框架，通过字符级对齐、重要性采样和教师锚定参考实现跨分词器偏好蒸馏。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在预训练和指令调优中广泛应用，但在语言模型与人类偏好对齐方面的应用仍未被充分探索，特别是在更现实的跨分词器设置中。教师和学生模型之间分词方案的不兼容性阻碍了细粒度的白盒偏好信息蒸馏。

Method: 提出跨分词器偏好蒸馏(CTPD)框架，包含三个关键创新：1)对齐跨度投影，将教师和学生token映射到共享字符级跨度；2)跨分词器适配的token级重要性采样(TIS-DPO)；3)教师锚定参考，让学生在DPO风格目标中直接利用教师偏好。

Result: 理论分析将CTPD建立在重要性采样基础上，多个基准测试实验证实其有效性，相比现有方法获得显著性能提升。

Conclusion: CTPD为不同分词方案间的偏好蒸馏提供了实用且通用的解决方案，为语言模型更易获取和高效的对齐打开了大门。

Abstract: While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.

</details>


### [39] [PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning](https://arxiv.org/abs/2601.11908)
*Byeongjin Kim,Gyuwan Kim,Seo Yeon Park*

Main category: cs.CL

TL;DR: PPA-Plan是一种针对长上下文推理的主动规划策略，通过识别潜在逻辑陷阱和错误假设，将其作为负面约束来指导规划生成，从而在规划阶段就预防失败。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文推理中存在困难，特别是相关信息稀疏分布时。现有的规划-执行框架因依赖表面线索而生成不可靠的规划，导致基于错误假设，且事后难以识别和修正问题。

Method: PPA-Plan主动识别潜在逻辑陷阱和错误假设，将其表述为负面约束，并在规划生成时明确避免这些约束，从而在规划阶段预防失败。

Result: 在长上下文QA基准测试中，执行PPA-Plan生成的规划一致优于现有的规划-执行方法和直接提示方法。

Conclusion: PPA-Plan通过主动预防规划失败，有效提升了长上下文推理的性能，为规划-执行框架提供了更可靠的规划生成方法。

Abstract: Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.

</details>


### [40] [Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes](https://arxiv.org/abs/2601.11932)
*Abdullah Al Monsur,Nitesh Vamshi Bommisetty,Gene Louis Kim*

Main category: cs.CL

TL;DR: 本文研究事件检测中的两个关键限制：解码器LLMs的单向性架构瓶颈和Micro-F1指标偏向多数类的问题，提出使用句子上下文增强和LoRA微调来提升长尾事件类型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 事件检测研究存在两个主要限制：1）解码器LLMs的单向架构不适合需要双向上下文理解的自然语言理解任务；2）传统使用的Micro-F1指标会偏向多数类，无法准确评估模型在长尾事件类型上的表现。

Method: 1）使用句子上下文增强模型以克服解码器LLMs的单向性限制；2）采用LoRA（低秩适应）进行微调；3）使用Macro-F1作为主要评估指标来更公平地评估模型在所有事件类型上的表现。

Result: 实验表明：1）句子上下文增强的模型优于标准解码器基线；2）LoRA微调显著提升了Macro-F1分数，特别是对解码器模型；3）LoRA能有效提升LLMs在长尾事件类别上的性能。

Conclusion: 通过句子上下文增强和LoRA微调可以克服事件检测中的架构限制和评估偏差，Macro-F1是更合适的评估指标，LoRA是提升LLMs在长尾事件类别上性能的有效工具。

Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.

</details>


### [41] [DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity](https://arxiv.org/abs/2601.12505)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

TL;DR: DoPE是一种文档层防御框架，通过在PDF/HTML考试文档中嵌入语义诱饵来对抗多模态大语言模型，防止自动化作弊并检测AI依赖。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型能够直接处理考试文档，威胁传统评估方式和学术诚信。需要开发模型无关的防御机制来防止自动化作弊和检测AI依赖。

Method: 提出DoPE框架，在文档创作时嵌入语义诱饵，利用MLLM渲染-解析差异。开发FewSoRT-Q生成问题级语义诱饵，FewSoRT-D将其封装到水印文档中。

Result: 在Integrity-Bench基准测试中，对OpenAI和Anthropic的黑盒MLLM，DoPE实现91.4%检测率（8.7%误报率），96.3%的尝试被阻止或诱导失败。

Conclusion: DoPE提供有效的文档层防御机制，保护学术诚信，无需依赖传统单次分类器。开源基准、工具包和代码促进可重复研究。

Abstract: Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.

</details>


### [42] [Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph](https://arxiv.org/abs/2601.13251)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 开发大规模语义聚类系统，解决神经嵌入无法区分同义词和反义词的问题，通过三路语义关系判别器和软到硬聚类算法生成290万个高精度语义簇。


<details>
  <summary>Details</summary>
Motivation: 神经嵌入存在一个显著缺陷：无法可靠地区分同义词和反义词，导致提高相似度阈值仍无法防止反义词被错误分组。现有方法在形态丰富和低资源语言中尤其不足，需要专门解决语义关系歧义的系统。

Method: 1) 构建84.3万个概念对的数据集，涵盖同义、反义和共下位关系，使用Gemini 2.5-Flash LLM增强并用人编词典验证；2) 提出三路语义关系判别器，实现90%宏F1分数；3) 开发新颖的软到硬聚类算法，采用拓扑感知的两阶段扩展-剪枝过程，防止语义漂移并解决多义性。

Result: 系统处理1500万个词汇项，评估5.2亿个潜在关系，最终生成290万个高精度语义簇。判别器达到90%宏F1分数，聚类算法能防止错误传递链（如hot->spicy->pain->depression），确保每个术语被分配到唯一语义连贯的簇中。

Conclusion: 该方法成功解决了神经嵌入的同义词-反义词区分问题，为形态丰富和低资源语言提供了高精度语义搜索和检索增强生成资源，填补了现有同义词数据库的空白。

Abstract: Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

</details>


### [43] [Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse](https://arxiv.org/abs/2601.13317)
*Samantha Sudhoff,Pranav Perumal,Zhaoqing Wu,Tunazzina Islam*

Main category: cs.CL

TL;DR: 本文提出一个可解释的主题发现框架，比较Meta付费广告和Bluesky公共帖子中的气候话语差异，发现平台激励机制影响叙事结构、立场对齐和时间响应性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立分析不同平台的气候话语，难以区分机构信息与公众表达。付费广告生态系统激励有针对性的战略说服，而公共社交媒体平台主要承载用户驱动的有机讨论，需要比较分析这两种结构不同的环境。

Method: 提出一个可解释的端到端主题发现和分配框架：通过语义相似性聚类文本，利用大语言模型生成简洁、人类可解释的主题标签。在2024年7月至2025年9月期间，比较Meta付费广告和Bluesky公共帖子中的气候话语。通过人工判断和基于LLM的评估器评估主题质量，并通过下游立场预测和主题引导检索任务验证语义连贯性。

Result: 平台层面的激励机制反映在气候叙事的主题结构、立场对齐和时间响应性中。付费气候信息与公共气候话语存在系统性差异，主题流行度在重大政治事件周围发生变化。提出的框架在主题质量评估中优于传统主题建模基线。

Conclusion: 平台激励机制显著影响气候话语的特征。虽然实证分析聚焦气候传播，但提出的框架支持跨异构传播环境的比较叙事分析，有助于区分机构信息与公众表达。

Abstract: Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

</details>


### [44] [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368)
*Zhenjiang Mao,Anirudhh Venkat*

Main category: cs.CL

TL;DR: 提出一种结合步骤间注意力分析和隐藏置信度机制的新方法，用于评估大语言模型推理过程中的不确定性，在数学和因果推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务上表现良好，但缺乏对答案不确定性的准确评估，可能导致误导性幻觉。现有方法忽略置信度的时间分布，即使早期步骤置信度很低，整体置信度也可能被高估。

Method: 提出结合步骤间注意力分析语义相关性，并引入隐藏置信度机制来保留历史置信信息，将逐步置信度与历史信息结合得到更准确的整体置信度估计。

Result: 在GAOKAO数学基准和CLadder因果推理数据集上评估，使用主流开源大语言模型，在负对数似然和期望校准误差指标上优于最先进方法，实现了预测质量与校准的更好平衡。

Conclusion: 提出的方法能更准确地评估大语言模型推理过程中的不确定性，通过考虑置信度的时间分布和步骤间语义相关性，有效解决了整体置信度高估问题。

Abstract: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.

</details>


### [45] [Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives](https://arxiv.org/abs/2601.13503)
*Kyung Ho Lim,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: Anonpsy：一种将精神病学叙事转化为语义图，通过图约束扰动修改识别信息，同时保留临床结构，再生成文本的去识别框架


<details>
  <summary>Details</summary>
Motivation: 精神病学叙事不仅包含明确的患者标识符，还包含嵌入临床结构中的独特生活事件。现有的去识别方法（如PHI掩码和基于LLM的合成重写）在文本层面操作，对保留或改变哪些语义元素控制有限。

Method: 1) 将每个叙事转换为编码临床实体、时间锚点和类型化关系的语义图；2) 应用图约束扰动，修改识别上下文同时保留临床必需结构；3) 通过图条件LLM生成重新生成文本。

Result: 在90个临床医生撰写的精神病学案例叙事上评估，Anonpsy在保持诊断保真度的同时，在专家、语义和GPT-5评估下实现了一致的低重识别风险。与强大的仅LLM重写基线相比，Anonpsy产生显著更低的语义相似性和可识别性。

Conclusion: 显式结构表示与约束生成相结合，为精神病学叙事的去识别提供了有效方法。

Abstract: Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.

</details>


### [46] [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717)
*Zehan Li,Yuxuan Wang,Ali El Lahib,Ying-Jieh Xia,Xinyu Pi*

Main category: cs.CL

TL;DR: 模拟无知方法无法有效抑制大语言模型的先验知识，不能替代真实无知状态进行预测评估


<details>
  <summary>Details</summary>
Motivation: 评估LLM预测能力面临两难：前瞻性评估延迟高，回顾性预测面临数据污染问题。模拟无知方法被提出作为解决方案，但需要验证其有效性。

Method: 通过477个竞赛级问题和9个模型，系统测试模拟无知能否近似真实无知，分析截止指令效果、思维链推理抑制能力、推理优化模型表现。

Result: 模拟无知系统性失败：1) 截止指令造成52%性能差距；2) 思维链无法有效抑制先验知识；3) 推理优化模型模拟无知保真度更差。提示无法可靠"回滚"模型知识。

Conclusion: 基于截止前事件的回顾性预测方法存在根本缺陷，不应使用模拟无知方法评估预测能力，需要寻找更可靠的评估方法。

Abstract: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.

</details>


### [47] [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836)
*Qian Chen,Jinlan Fu,Changsong Li,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出了首个用于评估多模态大语言模型音频-视觉未来预测能力的基准FutureOmni，包含919个视频和1034个QA对，发现现有模型在此任务上表现不佳，并提出了OFF训练策略来提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在跨模态感知方面表现出色，但缺乏对未来事件预测能力的评估。现有基准主要关注回顾性理解，而音频-视觉环境中的未来预测能力尚未得到充分探索。

Method: 1) 通过LLM辅助、人机协同的流程构建FutureOmni基准，包含919个视频和1034个多项选择题对，涵盖8个主要领域；2) 提出Omni-Modal Future Forecasting (OFF)训练策略，并构建了7K样本的指令调优数据集。

Result: 评估了13个多模态模型和7个纯视频模型，发现当前系统在音频-视觉未来预测方面表现不佳，特别是在语音密集场景中，最佳准确率仅为64.8%（Gemini 3 Flash）。OFF训练策略显著提升了未来预测能力和泛化性能。

Conclusion: FutureOmni填补了多模态未来预测评估的空白，揭示了现有模型的局限性，提出的OFF训练策略有效提升了预测性能，为未来研究提供了重要基准和方法。

Abstract: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

</details>


### [48] [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918)
*Yusheng Liao,Chuan Xuan,Yutong Cai,Lina Yang,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出了AgentEHR基准和RetroSum框架，用于解决LLM在原始高噪声电子病历数据库中执行复杂决策任务时的信息丢失和推理连续性断裂问题，通过回顾性总结和演化经验策略显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在医疗领域的应用主要依赖精心准备的输入和简化的检索任务，无法在原始、高噪声的电子病历数据库中执行复杂的临床决策任务，存在信息丢失和推理连续性断裂的问题。

Method: 提出RetroSum框架，包含两个核心组件：1）回顾性总结机制，通过动态重新评估交互历史防止长上下文信息丢失，确保逻辑连贯性；2）演化经验策略，通过从记忆库中检索累积经验来弥合领域差距。

Result: RetroSum在AgentEHR基准测试中表现出色，相比竞争基线性能提升高达29.16%，同时将总交互错误显著降低高达92.3%。

Conclusion: RetroSum框架通过创新的回顾性总结和演化经验策略，有效解决了LLM在原始电子病历数据库中执行复杂临床决策任务时的关键挑战，为医疗AI的实际应用提供了重要进展。

Abstract: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

</details>


### [49] ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992)
*Jin Cui,Jiaqi Guo,Jiepeng Zhou,Ruixuan Yang,Jiayi Lu,Jiajun Xu,Jiangcheng Song,Boran Zhao,Pengju Ren*

Main category: cs.CL

TL;DR: COMPACT是一个多教师CoT蒸馏框架，通过动态加权教师梯度来融合不同教师的监督，避免单一教师的偏见和灾难性遗忘，提升小模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoT蒸馏方法通常依赖单一教师模型，但单个LLM存在能力偏见和灾难性遗忘问题，限制了学生模型的潜力。虽然使用多样化教师很吸引人，但有效融合它们的监督面临挑战：师生不兼容可能放大幻觉，被动监督无法确保真正的逻辑内化。

Method: COMPACT通过动态加权教师梯度来融合不同教师的监督，基于三个多维指标评估学生的实时兼容性：1) 基于图的共识性，通过识别主流推理路径过滤误导性理由；2) 基于互信息的适应性，检测"顿悟时刻"以确保真正理解推理过程而非简单模仿；3) 基于损失的难度，评估学生对教师指导的接受度，防止负迁移。

Result: 广泛的实验和潜在空间分析表明，COMPACT能有效整合多样化推理能力而不损害模型的原始知识结构，在各种基准测试中达到最先进性能，同时减轻了灾难性遗忘。

Conclusion: COMPACT框架通过自适应融合多教师监督，成功解决了CoT蒸馏中的师生不兼容和逻辑内化问题，为小模型获得强大推理能力提供了有效途径。

Abstract: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

</details>


### [50] [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007)
*Junyu Zhang,Yipeng Kang,Jiong Guo,Jiayu Zhan,Junqi Wang*

Main category: cs.CL

TL;DR: LLMs确实拥有结构化的价值表征，能够跨抽象概念、具体事件和决策推理三个层次进行迁移，但抽象价值表征相对稳定，不易被干预改变。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否真正理解抽象概念，还是仅仅在操作统计模式。以人类价值观作为测试平台，因为价值观具有语义丰富性和对齐重要性。

Method: 提出抽象-具身框架，将概念理解分解为三个能力：抽象概念解释（A-A）、抽象概念在具体事件中的具身化（A-C）、抽象原则在具体决策中的应用（C-C）。使用探测（检测内部激活中的价值痕迹）和引导（修改表征以改变行为）两种方法，在六个开源LLM和十个价值维度上进行实验。

Result: 探测显示：仅基于抽象价值描述训练的探测模型能够可靠地在具体事件叙述和决策推理中检测到相同的价值观，表现出跨层次迁移能力。引导实验揭示不对称性：干预价值表征会因果性地改变具体判断和决策（A-C，C-C），但不会改变抽象解释（A-A），表明编码的抽象价值观作为稳定锚点而非可塑激活。

Conclusion: LLMs维持着结构化的价值表征，能够桥接抽象与行动，这为构建价值驱动的自主AI系统提供了机制性和操作性的基础，有助于实现更透明、可泛化的对齐和控制。

Abstract: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.

</details>


### [51] [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041)
*Yunhe Wang,Kai Han,Huiling Zhen,Yuchuan Tian,Hanting Chen,Yongbing Huang,Yufei Cui,Yingte Shu,Shan Gao,Ismail Elezi,Roy Vaughan Miles,Songcen Xu,Feng Wen,Chao Xu,Sinan Zeng,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文认为扩散语言模型（DLMs）相比自回归模型具有革命性潜力，但面临十大挑战，提出了基于四大支柱的路线图来推动DLMs发展


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型主要采用自回归架构，存在因果瓶颈限制全局结构预见和迭代优化能力。扩散语言模型提供了变革性替代方案，但潜力未充分发挥，需要突破现有AR遗留框架的束缚

Method: 识别了阻碍DLMs发展的十大根本挑战，包括架构惯性、梯度稀疏性、线性推理限制等，并提出了基于四大支柱的战略路线图：基础架构、算法优化、认知推理和统一多模态智能

Result: 提出了向扩散原生生态系统转型的解决方案，包括多尺度分词、主动重掩码、潜在思维等关键技术，旨在超越因果视野的约束

Conclusion: 向扩散原生生态系统的转型对于开发下一代AI至关重要，能够实现复杂结构推理、动态自我修正和无缝多模态集成，推动DLMs达到"GPT-4时刻"

Abstract: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.

</details>


### [52] [NewsRECON: News article REtrieval for image CONtextualization](https://arxiv.org/abs/2601.14121)
*Jonathan Tonglet,Iryna Gurevych,Tinne Tuytelaars,Marie-Francine Moens*

Main category: cs.CL

TL;DR: NewsRECON：一种无需反向图像搜索证据的新闻图像时空定位方法，通过将图像链接到相关新闻文章来推断拍摄时间和地点。


<details>
  <summary>Details</summary>
Motivation: 新闻图像的时间和地点定位对记者和取证专家至关重要，但现有的反向图像搜索工具经常无法返回结果，限制了实际应用。本研究针对反向图像搜索证据不可用的挑战性场景。

Method: NewsRECON方法包含三个核心组件：1）双编码器用于检索事件相关文章；2）两个交叉编码器分别根据位置一致性和事件一致性对文章进行重排序。该方法基于超过90,000篇文章的语料库。

Result: 在TARA和5Pils-OOC数据集上的实验表明，NewsRECON优于先前工作，并且可以与多模态大语言模型结合，在缺乏反向图像搜索证据的情况下实现新的SOTA结果。

Conclusion: NewsRECON提供了一种有效的替代方案，能够在反向图像搜索失败时通过链接图像到新闻文章来推断时空信息，代码已开源。

Abstract: Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

</details>


### [53] [Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models](https://arxiv.org/abs/2601.14152)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CL

TL;DR: 研究发现，在多项选择题回答中，将上下文放在问题和选项之前（CQO）比反向顺序（QOC）性能提升超过14%，这种差异源于因果注意力机制导致QOC中选项无法关注上下文信息。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对提示结构表现出惊人的敏感性，但其背后的机制尚不清楚。本文旨在深入探究一个显著现象：在多项选择题回答中，不同的提示顺序会导致显著的性能差异。

Method: 通过系统的架构分析，识别因果注意力作为核心机制。在QOC提示中，因果掩码阻止选项标记关注上下文，创建了信息瓶颈，使得上下文对选项不可见。

Result: CQO顺序（上下文-问题-选项）比QOC顺序（问题-选项-上下文）性能提升超过14个百分点，这种差异在广泛的模型和数据集上保持一致。

Conclusion: 因果注意力机制是导致提示结构敏感性的核心原因，理解这一机制有助于设计更有效的提示策略，并深入理解语言模型的工作原理。

Abstract: Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.

</details>


### [54] [MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems](https://arxiv.org/abs/2601.14230)
*Yiyang Wang,Yiqiao Jin,Alex Cabral,Josiah Hester*

Main category: cs.CL

TL;DR: MASCOT：一个防止多智能体系统角色崩溃和社会谄媚的通用框架，通过双层优化策略协调个体与集体行为


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统存在角色崩溃（智能体退化为通用助手行为）和社会谄媚（产生冗余、非建设性对话）的问题，需要解决这些缺陷以构建真正有效的社交协作伴侣

Method: 提出MASCOT框架，采用双层优化策略：1）角色感知行为对齐——基于RLAIF的管道，微调个体智能体以确保严格的角色保真度；2）协作对话优化——基于群体级奖励的元策略，确保多样化和富有成效的对话

Result: 在心理支持和职场领域的广泛评估显示，MASCOT显著优于现有基线方法，在角色一致性方面提升高达+14.1，在社会贡献方面提升高达+10.6

Conclusion: MASCOT为构建下一代社交智能多智能体系统提供了实用的路线图，有效解决了角色崩溃和社会谄媚问题

Abstract: Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [55] [Learning Legged MPC with Smooth Neural Surrogates](https://arxiv.org/abs/2601.12169)
*Samuel A. Moore,Easop Lee,Boyuan Chen*

Main category: cs.RO

TL;DR: 提出平滑神经代理模型和鲁棒学习方法，解决学习动力学模型在腿式机器人MPC中的三个关键问题，显著提升零样本运动的可靠性和性能。


<details>
  <summary>Details</summary>
Motivation: 将深度学习与模型预测控制结合应用于腿式机器人时面临三个挑战：1）接触事件的刚性过渡；2）额外的非物理局部非光滑性；3）训练数据导致的非高斯模型误差。这些问题限制了学习模型在在线规划中的可靠性。

Method: 1）引入平滑神经代理模型，具有可调平滑性，为接触轨迹优化提供信息预测和导数；2）使用重尾似然函数训练模型，更好地匹配腿式机器人动力学的经验误差分布。

Result: 在难度递增的零样本运动任务中，平滑神经代理模型与鲁棒学习结合：简单行为上累积成本降低10-50%；在标准神经动力学常失败的复杂场景中，成功率从0/5提升到5/5，累积成本降低2-50倍，实现数量级的鲁棒性提升。

Conclusion: 通过平滑神经代理模型和重尾似然训练的设计选择，显著提升了学习腿式机器人MPC的可靠性、可扩展性和泛化能力，特别是在复杂接触场景中实现了突破性的性能改进。

Abstract: Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains.

</details>


### [56] [R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry](https://arxiv.org/abs/2601.12377)
*Haobo Xi,Shiyong Zhang,Qianli Dong,Yunze Tong,Songyang Wu,Jing Yuan,Xuebo Zhang*

Main category: cs.RO

TL;DR: R-VoxelMap：一种基于几何驱动递归平面拟合的新型体素建图方法，通过异常值检测与重用管道提升LiDAR里程计定位精度


<details>
  <summary>Details</summary>
Motivation: 现有VoxelMap及其变体在体素中使用所有点拟合平面，存在三个主要问题：1）异常值导致平面参数偏差；2）大平面过度分割；3）不同物理平面错误合并。这些问题影响了建图精度和定位性能。

Method: 采用几何驱动的递归构建策略：1）在每个体素中使用RANSAC拟合准确平面并分离异常值；2）剩余异常值传播到更深的八叉树层级进行递归处理；3）设计基于点分布的有效性检查算法防止错误平面合并。

Result: 在多个开源LiDAR(-惯性)SLAM数据集上的广泛实验表明，R-VoxelMap相比其他最先进方法达到更高精度，同时保持相当的效率和内存使用。

Conclusion: R-VoxelMap通过递归平面拟合和异常值处理机制，有效解决了传统体素建图中的问题，显著提升了LiDAR里程计的定位精度，代码将在GitHub开源。

Abstract: This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.

</details>


### [57] [Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints](https://arxiv.org/abs/2601.13252)
*Mahmud S. Zango,Jianglin Lan*

Main category: cs.RO

TL;DR: 本文综述了纳米无人机（重量<50g，计算功率<100mW）自主导航技术的最新进展，分析了从传统几何方法到边缘AI范式的转变，并指出了当前在长期续航、动态环境避障和强化学习策略迁移等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机面临极端的尺寸、重量和功率（SWaP）限制（重量<50g，机载处理器<100mW），这使其与标准机器人范式有根本区别。需要专门针对这种超低功耗计算环境设计传感、计算和控制架构。

Method: 综合评述了面向100mW以下计算环境的传感、计算和控制架构，包括从传统几何方法到边缘AI范式的转变，量化深度神经网络在超低功耗SoC上的部署，神经形态事件控制，以及硬件-软件协同设计方法。

Result: 在视觉导航和相对姿态估计方面取得了显著进展，但在长期续航、动态环境中的鲁棒避障以及强化学习策略的"仿真到现实"迁移方面仍存在持续差距。

Conclusion: 提出了融合轻量级经典控制和数据驱动感知的混合架构路线图，以实现在GPS拒止环境中完全自主、敏捷的纳米无人机。

Abstract: Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging "Edge AI" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the "Sim-to-Real" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.

</details>


### [58] [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](https://arxiv.org/abs/2601.13451)
*Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.RO

TL;DR: 提出了一种结合混合神经网络和脉冲神经网络滤波的机器人视觉导航框架，用于未建模障碍物检测和定位，实现高精度环境理解和低功耗实时处理。


<details>
  <summary>Details</summary>
Motivation: 传统机器人导航系统在处理动态、不可预测环境中的未建模障碍物时存在局限性，需要同时满足高精度环境理解和实时、低功耗处理的要求。人工神经网络和脉冲神经网络各有优势，但单独使用难以兼顾精度和效率。

Method: 采用双路径架构：ANN组件处理低频静态空间特征，SNN组件实时处理动态事件传感器数据。系统包含预开发的SNN滤波器，直接使用脉冲编码输入进行定位和状态估计。检测到的异常通过ANN路径的上下文信息验证并持续跟踪，支持预测性导航策略。

Result: 仿真结果表明，该方法在保持接近纯SNN实现的计算效率的同时，提供了可接受的检测精度。纯SNN实现的资源成本仅为传统方法的一小部分。

Conclusion: 该框架代表了神经形态导航系统的重大进展，特别适用于机器人在不可预测和动态环境中的操作，成功结合了ANN的准确性和SNN的效率优势。

Abstract: This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

</details>


### [59] [SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media](https://arxiv.org/abs/2601.14128)
*Shoujie Li,Changqing Guo,Junhao Gong,Chenxin Liang,Wenhua Ding,Wenbo Ding*

Main category: cs.RO

TL;DR: SandWorm机器人结合仿生螺旋驱动和蠕动运动增强在颗粒介质中的运动能力，SWTac新型事件视觉触觉传感器通过主动振动弹性体和弹簧隔离机制实现高质量触觉成像，系统在复杂颗粒介质中表现出色。


<details>
  <summary>Details</summary>
Motivation: 颗粒介质中的感知具有挑战性，因为粒子动态难以预测。需要开发能够在复杂颗粒环境中有效感知和运动的机器人系统。

Method: 1) SandWorm：仿生螺旋驱动机器人，结合蠕动运动增强运动能力；2) SWTac：新型事件视觉触觉传感器，采用主动振动弹性体，通过弹簧隔离机制将事件相机与振动机械解耦；3) IMU引导的时间滤波器提高成像一致性；4) 系统优化振动参数、事件相机设置和弹性体特性；5) 基于非对称边缘特征的U-Net接触表面估计。

Result: SWTac实现0.2mm纹理分辨率、98%石块分类准确率、0.15N力估计误差；SandWorm在挑战性地形中实现多样化运动（最高12.5mm/s），在复杂颗粒介质中成功执行管道疏浚和地下勘探（成功率90%）；IMU引导滤波器将MSNR提高24%。

Conclusion: SandWorm和SWTac系统在颗粒介质中表现出卓越的感知和运动能力，现场实验验证了其实际性能，为解决颗粒环境中的机器人挑战提供了有效解决方案。

Abstract: Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.

</details>
