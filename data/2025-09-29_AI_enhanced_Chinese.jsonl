{"id": "2509.21322", "categories": ["cs.LG", "math.PR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.21322", "abs": "https://arxiv.org/abs/2509.21322", "authors": ["Anna Kalenkova", "Lu Xia", "Dirk Neumann"], "title": "Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail", "comment": null, "summary": "This paper proposes a novel method for analyzing food retail processes with a\nfocus on reducing food waste. The approach integrates object-centric process\nmining (OCPM) with stochastic process discovery and analysis. First, a\nstochastic process in the form of a continuous-time Markov chain is discovered\nfrom grocery store sales data. This model is then extended with supply\nactivities. Finally, a what-if analysis is conducted to evaluate how the\nquantity of products in the store evolves over time. This enables the\nidentification of an optimal balance between customer purchasing behavior and\nsupply strategies, helping to prevent both food waste due to oversupply and\nproduct shortages.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5bf9\u8c61\u4e2d\u5fc3\u6d41\u7a0b\u6316\u6398\u4e0e\u968f\u673a\u8fc7\u7a0b\u53d1\u73b0\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u98df\u54c1\u96f6\u552e\u6d41\u7a0b\u4ee5\u51cf\u5c11\u98df\u7269\u6d6a\u8d39\u3002", "motivation": "\u89e3\u51b3\u98df\u54c1\u96f6\u552e\u4e2d\u7684\u98df\u7269\u6d6a\u8d39\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u4f9b\u5e94\u7b56\u7565\u4e0e\u987e\u5ba2\u8d2d\u4e70\u884c\u4e3a\u4e4b\u95f4\u7684\u5e73\u8861\u6765\u9632\u6b62\u8fc7\u5ea6\u4f9b\u5e94\u5bfc\u81f4\u7684\u6d6a\u8d39\u548c\u4ea7\u54c1\u77ed\u7f3a\u3002", "method": "\u9996\u5148\u4ece\u6742\u8d27\u5e97\u9500\u552e\u6570\u636e\u4e2d\u53d1\u73b0\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u5f62\u5f0f\u7684\u968f\u673a\u8fc7\u7a0b\u6a21\u578b\uff0c\u7136\u540e\u6269\u5c55\u4f9b\u5e94\u6d3b\u52a8\uff0c\u6700\u540e\u8fdb\u884c\u5047\u8bbe\u5206\u6790\u8bc4\u4f30\u4ea7\u54c1\u6570\u91cf\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "result": "\u80fd\u591f\u8bc6\u522b\u987e\u5ba2\u8d2d\u4e70\u884c\u4e3a\u4e0e\u4f9b\u5e94\u7b56\u7565\u4e4b\u95f4\u7684\u6700\u4f18\u5e73\u8861\u70b9\uff0c\u6709\u6548\u9632\u6b62\u56e0\u8fc7\u5ea6\u4f9b\u5e94\u5bfc\u81f4\u7684\u98df\u7269\u6d6a\u8d39\u548c\u4ea7\u54c1\u77ed\u7f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u98df\u54c1\u96f6\u552e\u6d41\u7a0b\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u98df\u7269\u6d6a\u8d39\u5e76\u4f18\u5316\u5e93\u5b58\u7ba1\u7406\u3002"}}
{"id": "2509.21886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.21886", "abs": "https://arxiv.org/abs/2509.21886", "authors": ["Ziyang Zheng", "Jiaying Zhu", "Jingyi Zhou", "Qiang Xu"], "title": "TRACE: Learning to Compute on Graphs", "comment": null, "summary": "Learning to compute, the ability to model the functional behavior of a\ncomputational graph, is a fundamental challenge for graph representation\nlearning. Yet, the dominant paradigm is architecturally mismatched for this\ntask. This flawed assumption, central to mainstream message passing neural\nnetworks (MPNNs) and their conventional Transformer-based counterparts,\nprevents models from capturing the position-aware, hierarchical nature of\ncomputation. To resolve this, we introduce \\textbf{TRACE}, a new paradigm built\non an architecturally sound backbone and a principled learning objective.\nFirst, TRACE employs a Hierarchical Transformer that mirrors the step-by-step\nflow of computation, providing a faithful architectural backbone that replaces\nthe flawed permutation-invariant aggregation. Second, we introduce\n\\textbf{function shift learning}, a novel objective that decouples the learning\nproblem. Instead of predicting the complex global function directly, our model\nis trained to predict only the \\textit{function shift}, the discrepancy between\nthe true global function and a simple local approximation that assumes input\nindependence. We validate this paradigm on electronic circuits, one of the most\ncomplex and economically critical classes of computational graphs. Across a\ncomprehensive suite of benchmarks, TRACE substantially outperforms all prior\narchitectures. These results demonstrate that our architecturally-aligned\nbackbone and decoupled learning objective form a more robust paradigm for the\nfundamental challenge of learning to compute on graphs.", "AI": {"tldr": "TRACE\u662f\u4e00\u79cd\u65b0\u7684\u56fe\u8868\u793a\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u5c42\u6b21\u5316Transformer\u67b6\u6784\u548c\u51fd\u6570\u504f\u79fb\u5b66\u4e60\u76ee\u6807\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u8ba1\u7b97\u56fe\u5efa\u6a21\u4e2d\u7684\u67b6\u6784\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\u548cTransformer\u5728\u56fe\u8ba1\u7b97\u5efa\u6a21\u4e2d\u5b58\u5728\u67b6\u6784\u4e0d\u5339\u914d\uff0c\u65e0\u6cd5\u6355\u6349\u8ba1\u7b97\u7684\u4f4d\u7f6e\u611f\u77e5\u548c\u5c42\u6b21\u5316\u7279\u6027\u3002", "method": "\u4f7f\u7528\u5c42\u6b21\u5316Transformer\u6a21\u62df\u9010\u6b65\u8ba1\u7b97\u6d41\u7a0b\uff0c\u5f15\u5165\u51fd\u6570\u504f\u79fb\u5b66\u4e60\u76ee\u6807\uff0c\u5c06\u590d\u6742\u5168\u5c40\u51fd\u6570\u9884\u6d4b\u5206\u89e3\u4e3a\u9884\u6d4b\u771f\u5b9e\u51fd\u6570\u4e0e\u5c40\u90e8\u8fd1\u4f3c\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u5728\u7535\u5b50\u7535\u8def\u7b49\u590d\u6742\u8ba1\u7b97\u56fe\u4e0a\uff0cTRACE\u5728\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6240\u6709\u73b0\u6709\u67b6\u6784\u3002", "conclusion": "\u67b6\u6784\u5bf9\u9f50\u7684\u9aa8\u5e72\u7f51\u7edc\u548c\u89e3\u8026\u5b66\u4e60\u76ee\u6807\u4e3a\u56fe\u8ba1\u7b97\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u8303\u5f0f\u3002"}}
{"id": "2509.21902", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.21902", "abs": "https://arxiv.org/abs/2509.21902", "authors": ["Ruiqi Chen", "Yi Mei", "Fangfang Zhang", "Mengjie Zhang"], "title": "DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling", "comment": null, "summary": "Dynamic job shop scheduling, a fundamental combinatorial optimisation problem\nin various industrial sectors, poses substantial challenges for effective\nscheduling due to frequent disruptions caused by the arrival of new jobs.\nState-of-the-art methods employ machine learning to learn scheduling policies\noffline, enabling rapid responses to dynamic events. However, these offline\npolicies are often imperfect, necessitating the use of planning techniques such\nas Monte Carlo Tree Search (MCTS) to improve performance at online decision\ntime. The unpredictability of new job arrivals complicates online planning, as\ndecisions based on incomplete problem information are vulnerable to\ndisturbances. To address this issue, we propose the Dynamic Robust MCTS\n(DyRo-MCTS) approach, which integrates action robustness estimation into MCTS.\nDyRo-MCTS guides the production environment toward states that not only yield\ngood scheduling outcomes but are also easily adaptable to future job arrivals.\nExtensive experiments show that DyRo-MCTS significantly improves the\nperformance of offline-learned policies with negligible additional online\nplanning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across\nvarious scheduling scenarios. Further analysis reveals that its ability to make\nrobust scheduling decisions leads to long-term, sustainable performance gains\nunder disturbances.", "AI": {"tldr": "\u63d0\u51faDyRo-MCTS\u65b9\u6cd5\uff0c\u5c06\u52a8\u4f5c\u9c81\u68d2\u6027\u4f30\u8ba1\u96c6\u6210\u5230MCTS\u4e2d\uff0c\u7528\u4e8e\u52a8\u6001\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5feb\u901f\u5728\u7ebf\u89c4\u5212\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u79bb\u7ebf\u5b66\u4e60\u7b56\u7565\u7684\u6027\u80fd\u3002", "motivation": "\u52a8\u6001\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u9762\u4e34\u65b0\u4f5c\u4e1a\u9891\u7e41\u5230\u8fbe\u7684\u5e72\u6270\uff0c\u73b0\u6709\u79bb\u7ebf\u5b66\u4e60\u7b56\u7565\u5b58\u5728\u4e0d\u5b8c\u7f8e\u6027\uff0c\u800c\u5728\u7ebf\u89c4\u5212\u7531\u4e8e\u95ee\u9898\u4fe1\u606f\u4e0d\u5b8c\u6574\u5bb9\u6613\u53d7\u5230\u6270\u52a8\u5f71\u54cd\u3002", "method": "DyRo-MCTS\u65b9\u6cd5\u5728MCTS\u4e2d\u96c6\u6210\u52a8\u4f5c\u9c81\u68d2\u6027\u4f30\u8ba1\uff0c\u5f15\u5bfc\u751f\u4ea7\u73af\u5883\u8d70\u5411\u65e2\u80fd\u4ea7\u751f\u826f\u597d\u8c03\u5ea6\u7ed3\u679c\u53c8\u6613\u4e8e\u9002\u5e94\u672a\u6765\u4f5c\u4e1a\u5230\u8fbe\u7684\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDyRo-MCTS\u663e\u8457\u63d0\u5347\u79bb\u7ebf\u5b66\u4e60\u7b56\u7565\u6027\u80fd\uff0c\u5728\u7ebf\u89c4\u5212\u65f6\u95f4\u589e\u52a0\u53ef\u5ffd\u7565\uff0c\u5728\u5404\u79cd\u8c03\u5ea6\u573a\u666f\u4e0b\u6301\u7eed\u4f18\u4e8e\u666e\u901aMCTS\u3002", "conclusion": "DyRo-MCTS\u901a\u8fc7\u505a\u51fa\u9c81\u68d2\u8c03\u5ea6\u51b3\u7b56\uff0c\u5728\u6270\u52a8\u4e0b\u5b9e\u73b0\u957f\u671f\u53ef\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.22296", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.22296", "abs": "https://arxiv.org/abs/2509.22296", "authors": ["Joseph Hunt", "Koyo Fujii", "Aly Magassouba", "Praminda Caleb-Solly"], "title": "Beyond Detection -- Orchestrating Human-Robot-Robot Assistance via an Internet of Robotic Things Paradigm", "comment": "ICSR 2025, 8 pages, 3 figures", "summary": "Hospital patient falls remain a critical and costly challenge worldwide.\nWhile conventional fall prevention systems typically rely on post-fall\ndetection or reactive alerts, they also often suffer from high false positive\nrates and fail to address the underlying patient needs that lead to bed-exit\nattempts. This paper presents a novel system architecture that leverages the\nInternet of Robotic Things (IoRT) to orchestrate human-robot-robot interaction\nfor proactive and personalized patient assistance. The system integrates a\nprivacy-preserving thermal sensing model capable of real-time bed-exit\nprediction, with two coordinated robotic agents that respond dynamically based\non predicted intent and patient input. This orchestrated response could not\nonly reduce fall risk but also attend to the patient's underlying motivations\nfor movement, such as thirst, discomfort, or the need for assistance, before a\nhazardous situation arises. Our contributions with this pilot study are\nthree-fold: (1) a modular IoRT-based framework enabling distributed sensing,\nprediction, and multi-robot coordination; (2) a demonstration of low-resolution\nthermal sensing for accurate, privacy-preserving preemptive bed-exit detection;\nand (3) results from a user study and systematic error analysis that inform the\ndesign of situationally aware, multi-agent interactions in hospital settings.\nThe findings highlight how interactive and connected robotic systems can move\nbeyond passive monitoring to deliver timely, meaningful assistance, empowering\nsafer, more responsive care environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7269\u8054\u7f51\u673a\u5668\u4eba\u6280\u672f\u7684\u4e3b\u52a8\u5f0f\u60a3\u8005\u9632\u8dcc\u5012\u7cfb\u7edf\uff0c\u901a\u8fc7\u70ed\u611f\u6d4b\u9884\u6d4b\u60a3\u8005\u79bb\u5e8a\u610f\u56fe\uff0c\u534f\u8c03\u591a\u4e2a\u673a\u5668\u4eba\u63d0\u4f9b\u4e2a\u6027\u5316\u534f\u52a9", "motivation": "\u4f20\u7edf\u8dcc\u5012\u9884\u9632\u7cfb\u7edf\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\u4e14\u65e0\u6cd5\u89e3\u51b3\u60a3\u8005\u79bb\u5e8a\u7684\u6839\u672c\u9700\u6c42\uff0c\u9700\u8981\u4ece\u88ab\u52a8\u68c0\u6d4b\u8f6c\u5411\u4e3b\u52a8\u9884\u9632", "method": "\u91c7\u7528\u9690\u79c1\u4fdd\u62a4\u7684\u70ed\u611f\u6d4b\u6a21\u578b\u5b9e\u65f6\u9884\u6d4b\u79bb\u5e8a\u610f\u56fe\uff0c\u7ed3\u5408\u4e24\u4e2a\u534f\u8c03\u7684\u673a\u5668\u4eba\u4ee3\u7406\u6839\u636e\u9884\u6d4b\u610f\u56fe\u548c\u60a3\u8005\u8f93\u5165\u52a8\u6001\u54cd\u5e94", "result": "\u7cfb\u7edf\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u79bb\u5e8a\u884c\u4e3a\uff0c\u901a\u8fc7\u591a\u673a\u5668\u4eba\u534f\u8c03\u63d0\u4f9b\u53ca\u65f6\u6709\u610f\u4e49\u7684\u534f\u52a9\uff0c\u521b\u9020\u66f4\u5b89\u5168\u3001\u54cd\u5e94\u66f4\u5feb\u7684\u62a4\u7406\u73af\u5883", "conclusion": "\u4ea4\u4e92\u5f0f\u8fde\u63a5\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u53ef\u4ee5\u8d85\u8d8a\u88ab\u52a8\u76d1\u6d4b\uff0c\u63d0\u4f9b\u53ca\u65f6\u6709\u6548\u7684\u534f\u52a9\uff0c\u4e3a\u533b\u9662\u73af\u5883\u5e26\u6765\u66f4\u5b89\u5168\u7684\u62a4\u7406\u65b9\u6848"}}
{"id": "2509.21946", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.21946", "abs": "https://arxiv.org/abs/2509.21946", "authors": ["Kasidit Sermsri", "Teerapong Panboonyuen"], "title": "Debiasing Large Language Models in Thai Political Stance Detection via Counterfactual Calibration", "comment": "9 pages", "summary": "Political stance detection in low-resource and culturally complex settings\nposes a critical challenge for large language models (LLMs). In the Thai\npolitical landscape - marked by indirect language, polarized figures, and\nentangled sentiment and stance - LLMs often display systematic biases such as\nsentiment leakage and favoritism toward entities. These biases undermine\nfairness and reliability. We present ThaiFACTUAL, a lightweight, model-agnostic\ncalibration framework that mitigates political bias without requiring\nfine-tuning. ThaiFACTUAL uses counterfactual data augmentation and\nrationale-based supervision to disentangle sentiment from stance and reduce\nbias. We also release the first high-quality Thai political stance dataset,\nannotated with stance, sentiment, rationales, and bias markers across diverse\nentities and events. Experimental results show that ThaiFACTUAL significantly\nreduces spurious correlations, enhances zero-shot generalization, and improves\nfairness across multiple LLMs. This work highlights the importance of\nculturally grounded debiasing techniques for underrepresented languages.", "AI": {"tldr": "\u63d0\u51faThaiFACTUAL\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u548c\u57fa\u4e8e\u7406\u7531\u7684\u76d1\u7763\u6765\u51cf\u8f7b\u6cf0\u8bed\u653f\u6cbb\u7acb\u573a\u68c0\u6d4b\u4e2d\u7684\u504f\u89c1\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u63d0\u9ad8\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u5728\u8d44\u6e90\u532e\u4e4f\u548c\u6587\u5316\u590d\u6742\u7684\u6cf0\u8bed\u653f\u6cbb\u73af\u5883\u4e2d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff08\u5982\u60c5\u611f\u6cc4\u6f0f\u548c\u5b9e\u4f53\u504f\u8892\uff09\uff0c\u5f71\u54cd\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u548c\u57fa\u4e8e\u7406\u7531\u7684\u76d1\u7763\u6765\u89e3\u8026\u60c5\u611f\u4e0e\u7acb\u573a\uff0c\u5e76\u51cf\u5c11\u504f\u89c1\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u9996\u4e2a\u9ad8\u8d28\u91cf\u7684\u6cf0\u8bed\u653f\u6cbb\u7acb\u573a\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eThaiFACTUAL\u663e\u8457\u51cf\u5c11\u4e86\u865a\u5047\u76f8\u5173\u6027\uff0c\u589e\u5f3a\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u9488\u5bf9\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u7684\u6587\u5316\u57fa\u7840\u53bb\u504f\u89c1\u6280\u672f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.22613", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.22613", "abs": "https://arxiv.org/abs/2509.22613", "authors": ["Siwei Wang", "Yifei Shen", "Haoran Sun", "Shi Feng", "Shang-Hua Teng", "Li Dong", "Yaru Hao", "Wei Chen"], "title": "Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective", "comment": null, "summary": "Recent reinforcement learning (RL) methods have substantially enhanced the\nplanning capabilities of Large Language Models (LLMs), yet the theoretical\nbasis for their effectiveness remains elusive. In this work, we investigate\nRL's benefits and limitations through a tractable graph-based abstraction,\nfocusing on policy gradient (PG) and Q-learning methods. Our theoretical\nanalyses reveal that supervised fine-tuning (SFT) may introduce\nco-occurrence-based spurious solutions, whereas RL achieves correct planning\nprimarily through exploration, underscoring exploration's role in enabling\nbetter generalization. However, we also show that PG suffers from diversity\ncollapse, where output diversity decreases during training and persists even\nafter perfect accuracy is attained. By contrast, Q-learning provides two key\nadvantages: off-policy learning and diversity preservation at convergence. We\nfurther demonstrate that careful reward design is necessary to prevent reward\nhacking in Q-learning. Finally, applying our framework to the real-world\nplanning benchmark Blocksworld, we confirm that these behaviors manifest in\npractice.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56fe\u62bd\u8c61\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u5bf9LLM\u89c4\u5212\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u76d1\u7763\u5fae\u8c03\u4f1a\u4ea7\u751f\u4f2a\u89e3\uff0c\u800cRL\u901a\u8fc7\u63a2\u7d22\u5b9e\u73b0\u6b63\u786e\u89c4\u5212\uff0c\u4f46PG\u5b58\u5728\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0cQ\u5b66\u4e60\u5219\u80fd\u4fdd\u6301\u591a\u6837\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u5176\u6709\u6548\u6027\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790RL\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u5206\u6790\u7b56\u7565\u68af\u5ea6\u548cQ\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5728Blocksworld\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9645\u9a8c\u8bc1\u3002", "result": "\u76d1\u7763\u5fae\u8c03\u4f1a\u4ea7\u751f\u57fa\u4e8e\u5171\u73b0\u7684\u4f2a\u89e3\uff1b\u7b56\u7565\u68af\u5ea6\u5b58\u5728\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff1bQ\u5b66\u4e60\u80fd\u4fdd\u6301\u8f93\u51fa\u591a\u6837\u6027\u4f46\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u9632\u6b62\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u3002", "conclusion": "\u63a2\u7d22\u662fRL\u5b9e\u73b0\u66f4\u597d\u6cdb\u5316\u7684\u5173\u952e\uff0cQ\u5b66\u4e60\u5728\u4fdd\u6301\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8e\u7b56\u7565\u68af\u5ea6\uff0c\u4f46\u9700\u8981\u8c28\u614e\u7684\u5956\u52b1\u8bbe\u8ba1\u3002"}}
{"id": "2509.21695", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.21695", "abs": "https://arxiv.org/abs/2509.21695", "authors": ["Saurabh Kataria", "Davood Fattahi", "Minxiao Wang", "Ran Xiao", "Matthew Clark", "Timothy Ruchti", "Mark Mai", "Xiao Hu"], "title": "Wav2Arrest 2.0: Long-Horizon Cardiac Arrest Prediction with Time-to-Event Modeling, Identity-Invariance, and Pseudo-Lab Alignment", "comment": "Submitted to BPSC", "summary": "High-frequency physiological waveform modality offers deep, real-time\ninsights into patient status. Recently, physiological foundation models based\non Photoplethysmography (PPG), such as PPG-GPT, have been shown to predict\ncritical events, including Cardiac Arrest (CA). However, their powerful\nrepresentation still needs to be leveraged suitably, especially when the\ndownstream data/label is scarce. We offer three orthogonal improvements to\nimprove PPG-only CA systems by using minimal auxiliary information. First, we\npropose to use time-to-event modeling, either through simple regression to the\nevent onset time or by pursuing fine-grained discrete survival modeling.\nSecond, we encourage the model to learn CA-focused features by making them\npatient-identity invariant. This is achieved by first training the\nlargest-scale de-identified biometric identification model, referred to as the\np-vector, and subsequently using it adversarially to deconfound cues, such as\nperson identity, that may cause overfitting through memorization. Third, we\npropose regression on the pseudo-lab values generated by pre-trained auxiliary\nestimator networks. This is crucial since true blood lab measurements, such as\nlactate, sodium, troponin, and potassium, are collected sparingly. Via\nzero-shot prediction, the auxiliary networks can enrich cardiac arrest waveform\nlabels and generate pseudo-continuous estimates as targets. Our proposals can\nindependently improve the 24-hour time-averaged AUC from the 0.74 to the\n0.78-0.80 range. We primarily improve over longer time horizons with minimal\ndegradation near the event, thus pushing the Early Warning System research.\nFinally, we pursue multi-task formulation and diagnose it with a high gradient\nconflict rate among competing losses, which we alleviate via the PCGrad\noptimization technique.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u6b63\u4ea4\u6539\u8fdb\u65b9\u6cd5\u6765\u63d0\u5347\u4ec5\u4f7f\u7528PPG\u4fe1\u53f7\u7684\u5fc3\u810f\u9aa4\u505c\u9884\u6d4b\u7cfb\u7edf\uff1a\u65f6\u95f4\u5230\u4e8b\u4ef6\u5efa\u6a21\u3001\u60a3\u8005\u8eab\u4efd\u4e0d\u53d8\u6027\u7279\u5f81\u5b66\u4e60\u3001\u4ee5\u53ca\u57fa\u4e8e\u9884\u8bad\u7ec3\u8f85\u52a9\u7f51\u7edc\u7684\u4f2a\u6807\u7b7e\u56de\u5f52\u3002\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u5c0624\u5c0f\u65f6\u65f6\u95f4\u5e73\u5747AUC\u4ece0.74\u63d0\u5347\u81f30.78-0.80\u8303\u56f4\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u7406\u57fa\u7840\u6a21\u578b\u5982PPG-GPT\u867d\u7136\u80fd\u591f\u9884\u6d4b\u5fc3\u810f\u9aa4\u505c\u7b49\u5173\u952e\u4e8b\u4ef6\uff0c\u4f46\u5176\u5f3a\u5927\u8868\u793a\u80fd\u529b\u5728\u4e0b\u6e38\u6570\u636e/\u6807\u7b7e\u7a00\u7f3a\u65f6\u672a\u80fd\u5145\u5206\u5229\u7528\u3002\u9700\u8981\u5f00\u53d1\u5728\u6700\u5c0f\u8f85\u52a9\u4fe1\u606f\u4e0b\u6539\u8fdbPPG-only\u5fc3\u810f\u9aa4\u505c\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002", "method": "1. \u65f6\u95f4\u5230\u4e8b\u4ef6\u5efa\u6a21\uff1a\u901a\u8fc7\u7b80\u5355\u56de\u5f52\u5230\u4e8b\u4ef6\u53d1\u751f\u65f6\u95f4\u6216\u7cbe\u7ec6\u79bb\u6563\u751f\u5b58\u5efa\u6a21\n2. \u60a3\u8005\u8eab\u4efd\u4e0d\u53d8\u6027\u7279\u5f81\u5b66\u4e60\uff1a\u8bad\u7ec3\u5927\u89c4\u6a21\u53bb\u8bc6\u522b\u751f\u7269\u7279\u5f81\u8bc6\u522b\u6a21\u578b(p-vector)\uff0c\u5e76\u5bf9\u5176\u4f7f\u7528\u5bf9\u6297\u6027\u8bad\u7ec3\u6765\u6d88\u9664\u53ef\u80fd\u5bfc\u81f4\u8fc7\u62df\u5408\u7684\u60a3\u8005\u8eab\u4efd\u7ebf\u7d22\n3. \u4f2a\u6807\u7b7e\u56de\u5f52\uff1a\u4f7f\u7528\u9884\u8bad\u7ec3\u8f85\u52a9\u7f51\u7edc\u8fdb\u884c\u96f6\u6837\u672c\u9884\u6d4b\uff0c\u751f\u6210\u4f2a\u8fde\u7eed\u4f30\u8ba1\u4f5c\u4e3a\u76ee\u6807\uff0c\u4e30\u5bcc\u5fc3\u810f\u9aa4\u505c\u6ce2\u5f62\u6807\u7b7e", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u5c0624\u5c0f\u65f6\u65f6\u95f4\u5e73\u5747AUC\u4ece0.74\u72ec\u7acb\u63d0\u5347\u81f30.78-0.80\u8303\u56f4\u3002\u4e3b\u8981\u6539\u8fdb\u4f53\u73b0\u5728\u8f83\u957f\u7684\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u5728\u4e8b\u4ef6\u9644\u8fd1\u4ec5\u6709\u6700\u5c0f\u7a0b\u5ea6\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u4ece\u800c\u63a8\u52a8\u4e86\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u7684\u7814\u7a76\u3002", "conclusion": "\u901a\u8fc7\u65f6\u95f4\u5230\u4e8b\u4ef6\u5efa\u6a21\u3001\u60a3\u8005\u8eab\u4efd\u4e0d\u53d8\u6027\u5b66\u4e60\u548c\u4f2a\u6807\u7b7e\u56de\u5f52\u8fd9\u4e09\u79cd\u6b63\u4ea4\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ec5\u4f7f\u7528PPG\u4fe1\u53f7\u7684\u5fc3\u810f\u9aa4\u505c\u9884\u6d4b\u6027\u80fd\u3002\u540c\u65f6\u4f7f\u7528PCGrad\u4f18\u5316\u6280\u672f\u7f13\u89e3\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7ade\u4e89\u635f\u5931\u95f4\u7684\u9ad8\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\u3002"}}
{"id": "2509.21853", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.21853", "abs": "https://arxiv.org/abs/2509.21853", "authors": ["Kaixuan Zhang", "Zhipeng Xiong", "Minxian Li", "Mingwu Ren", "Jiankang Deng", "Xiatian Zhu"], "title": "Dynamic Novel View Synthesis in High Dynamic Range", "comment": null, "summary": "High Dynamic Range Novel View Synthesis (HDR NVS) seeks to learn an HDR 3D\nmodel from Low Dynamic Range (LDR) training images captured under conventional\nimaging conditions. Current methods primarily focus on static scenes,\nimplicitly assuming all scene elements remain stationary and non-living.\nHowever, real-world scenarios frequently feature dynamic elements, such as\nmoving objects, varying lighting conditions, and other temporal events, thereby\npresenting a significantly more challenging scenario. To address this gap, we\npropose a more realistic problem named HDR Dynamic Novel View Synthesis (HDR\nDNVS), where the additional dimension ``Dynamic'' emphasizes the necessity of\njointly modeling temporal radiance variations alongside sophisticated 3D\ntranslation between LDR and HDR. To tackle this complex, intertwined challenge,\nwe introduce HDR-4DGS, a Gaussian Splatting-based architecture featured with an\ninnovative dynamic tone-mapping module that explicitly connects HDR and LDR\ndomains, maintaining temporal radiance coherence by dynamically adapting\ntone-mapping functions according to the evolving radiance distributions across\nthe temporal dimension. As a result, HDR-4DGS achieves both temporal radiance\nconsistency and spatially accurate color translation, enabling photorealistic\nHDR renderings from arbitrary viewpoints and time instances. Extensive\nexperiments demonstrate that HDR-4DGS surpasses existing state-of-the-art\nmethods in both quantitative performance and visual fidelity. Source code will\nbe released.", "AI": {"tldr": "\u63d0\u51fa\u4e86HDR\u52a8\u6001\u65b0\u89c6\u89d2\u5408\u6210\uff08HDR DNVS\uff09\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86HDR-4DGS\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8272\u8c03\u6620\u5c04\u6a21\u5757\u5728LDR\u548cHDR\u57df\u4e4b\u95f4\u5efa\u7acb\u8fde\u63a5\uff0c\u5b9e\u73b0\u52a8\u6001\u573a\u666f\u7684\u9ad8\u8d28\u91cfHDR\u6e32\u67d3\u3002", "motivation": "\u73b0\u6709HDR\u65b0\u89c6\u89d2\u5408\u6210\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u573a\u666f\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u573a\u666f\u5e38\u5305\u542b\u52a8\u6001\u5143\u7d20\uff08\u79fb\u52a8\u7269\u4f53\u3001\u53d8\u5316\u5149\u7167\u7b49\uff09\uff0c\u9700\u8981\u540c\u65f6\u5efa\u6a21\u65f6\u95f4\u8f90\u5c04\u53d8\u5316\u548c3D\u8f6c\u6362\u3002", "method": "\u57fa\u4e8e\u9ad8\u65af\u6cfc\u6e85\u7684HDR-4DGS\u67b6\u6784\uff0c\u5305\u542b\u521b\u65b0\u7684\u52a8\u6001\u8272\u8c03\u6620\u5c04\u6a21\u5757\uff0c\u6839\u636e\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u8f90\u5c04\u5206\u5e03\u7684\u53d8\u5316\u52a8\u6001\u8c03\u6574\u8272\u8c03\u6620\u5c04\u51fd\u6570\u3002", "result": "HDR-4DGS\u5728\u5b9a\u91cf\u6027\u80fd\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u65f6\u95f4\u8f90\u5c04\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u51c6\u786e\u7684\u989c\u8272\u8f6c\u6362\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u4efb\u610f\u89c6\u89d2\u548c\u65f6\u95f4\u5b9e\u4f8b\u751f\u6210\u903c\u771f\u7684HDR\u6e32\u67d3\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u573a\u666fHDR\u65b0\u89c6\u89d2\u5408\u6210\u7684\u6311\u6218\u3002"}}
{"id": "2509.22237", "categories": ["cs.CL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22237", "abs": "https://arxiv.org/abs/2509.22237", "authors": ["Haorui Chen", "Chengze Li", "Jia Li"], "title": "FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has given rise to a\nnovel software development paradigm known as \"vibe coding,\" where users\ninteract with coding agents through high-level natural language. However,\nexisting evaluation benchmarks for code generation inadequately assess an\nagent's vibe coding capabilities. Existing benchmarks are misaligned, as they\neither require code-level specifications or focus narrowly on issue-solving,\nneglecting the critical scenario of feature implementation within the vibe\ncoding paradiam. To address this gap, we propose FeatBench, a novel benchmark\nfor vibe coding that focuses on feature implementation. Our benchmark is\ndistinguished by several key features: 1. Pure Natural Language Prompts. Task\ninputs consist solely of abstract natural language descriptions, devoid of any\ncode or structural hints. 2. A Rigorous & Evolving Data Collection Process.\nFeatBench is built on a multi-level filtering pipeline to ensure quality and a\nfully automated pipeline to evolve the benchmark, mitigating data\ncontamination. 3. Comprehensive Test Cases. Each task includes Fail-to-Pass\n(F2P) and Pass-to-Pass (P2P) tests to verify correctness and prevent\nregressions. 4. Diverse Application Domains. The benchmark includes\nrepositories from diverse domains to ensure it reflects real-world scenarios.\nWe evaluate two state-of-the-art agent frameworks with four leading LLMs on\nFeatBench. Our evaluation reveals that feature implementation within the vibe\ncoding paradigm is a significant challenge, with the highest success rate of\nonly 29.94%. Our analysis also reveals a tendency for \"aggressive\nimplementation,\" a strategy that paradoxically leads to both critical failures\nand superior software design. We release FeatBench, our automated collection\npipeline, and all experimental results to facilitate further community\nresearch.", "AI": {"tldr": "\u63d0\u51fa\u4e86FeatBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\"\u6c1b\u56f4\u7f16\u7a0b\"\u8303\u5f0f\u4e0b\u7684\u529f\u80fd\u5b9e\u73b0\u80fd\u529b\uff0c\u901a\u8fc7\u7eaf\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u548c\u5168\u9762\u6d4b\u8bd5\u7528\u4f8b\u6765\u5f25\u8865\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e0e\"\u6c1b\u56f4\u7f16\u7a0b\"\u8303\u5f0f\u4e0d\u5339\u914d\uff0c\u5b83\u4eec\u8981\u4e48\u9700\u8981\u4ee3\u7801\u7ea7\u89c4\u8303\uff0c\u8981\u4e48\u53ea\u5173\u6ce8\u95ee\u9898\u89e3\u51b3\uff0c\u800c\u5ffd\u7565\u4e86\u529f\u80fd\u5b9e\u73b0\u8fd9\u4e00\u5173\u952e\u573a\u666f\u3002", "method": "\u6784\u5efaFeatBench\u57fa\u51c6\uff0c\u5177\u6709\u7eaf\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u3001\u4e25\u683c\u7684\u6570\u636e\u6536\u96c6\u6d41\u7a0b\u3001\u5168\u9762\u7684\u6d4b\u8bd5\u7528\u4f8b\uff08F2P\u548cP2P\u6d4b\u8bd5\uff09\u4ee5\u53ca\u591a\u6837\u5316\u7684\u5e94\u7528\u9886\u57df\u3002", "result": "\u5728FeatBench\u4e0a\u8bc4\u4f30\u4e24\u4e2a\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u6846\u67b6\u548c\u56db\u4e2a\u9886\u5148\u7684LLM\uff0c\u6700\u9ad8\u6210\u529f\u7387\u4ec5\u4e3a29.94%\uff0c\u53d1\u73b0\u5b58\u5728\"\u6fc0\u8fdb\u5b9e\u73b0\"\u503e\u5411\u3002", "conclusion": "\u6c1b\u56f4\u7f16\u7a0b\u8303\u5f0f\u4e0b\u7684\u529f\u80fd\u5b9e\u73b0\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0cFeatBench\u4e3a\u793e\u533a\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3001\u81ea\u52a8\u5316\u6536\u96c6\u6d41\u7a0b\u548c\u5b9e\u9a8c\u7ed3\u679c\u3002"}}
{"id": "2509.22150", "categories": ["cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.22150", "abs": "https://arxiv.org/abs/2509.22150", "authors": ["Zhiqiang Tian", "Weigang Li", "Junwei Hu", "Chunhua Deng"], "title": "Joint graph entropy knowledge distillation for point cloud classification and robustness against corruptions", "comment": null, "summary": "Classification tasks in 3D point clouds often assume that class events\n\\replaced{are }{follow }independent and identically distributed (IID), although\nthis assumption destroys the correlation between classes. This \\replaced{study\n}{paper }proposes a classification strategy, \\textbf{J}oint \\textbf{G}raph\n\\textbf{E}ntropy \\textbf{K}nowledge \\textbf{D}istillation (JGEKD), suitable for\nnon-independent and identically distributed 3D point cloud data,\n\\replaced{which }{the strategy } achieves knowledge transfer of class\ncorrelations through knowledge distillation by constructing a loss function\nbased on joint graph entropy. First\\deleted{ly}, we employ joint graphs to\ncapture add{the }hidden relationships between classes\\replaced{ and}{,}\nimplement knowledge distillation to train our model by calculating the entropy\nof add{add }graph.\\replaced{ Subsequently}{ Then}, to handle 3D point clouds\n\\deleted{that is }invariant to spatial transformations, we construct\n\\replaced{S}{s}iamese structures and develop two frameworks, self-knowledge\ndistillation and teacher-knowledge distillation, to facilitate information\ntransfer between different transformation forms of the same data. \\replaced{In\naddition}{ Additionally}, we use the above framework to achieve knowledge\ntransfer between point clouds and their corrupted forms, and increase the\nrobustness against corruption of model. Extensive experiments on ScanObject,\nModelNet40, ScanntV2\\_cls and ModelNet-C demonstrate that the proposed strategy\ncan achieve competitive results.", "AI": {"tldr": "\u63d0\u51faJGEKD\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u56fe\u71b5\u77e5\u8bc6\u84b8\u998f\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\u76843D\u70b9\u4e91\u5206\u7c7b\u95ee\u9898\uff0c\u6355\u83b7\u7c7b\u522b\u95f4\u76f8\u5173\u6027\u5e76\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf3D\u70b9\u4e91\u5206\u7c7b\u5047\u8bbe\u7c7b\u522b\u72ec\u7acb\u540c\u5206\u5e03\uff0c\u8fd9\u7834\u574f\u4e86\u7c7b\u522b\u95f4\u7684\u76f8\u5173\u6027\u3002\u73b0\u5b9e\u4e2d\u7684\u70b9\u4e91\u6570\u636e\u5f80\u5f80\u662f\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7684\uff0c\u9700\u8981\u8003\u8651\u7c7b\u522b\u95f4\u7684\u5173\u8054\u6027\u3002", "method": "\u4f7f\u7528\u8054\u5408\u56fe\u6355\u83b7\u7c7b\u522b\u95f4\u9690\u85cf\u5173\u7cfb\uff0c\u57fa\u4e8e\u8054\u5408\u56fe\u71b5\u6784\u5efa\u635f\u5931\u51fd\u6570\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u3002\u6784\u5efa\u5b6a\u751f\u7ed3\u6784\u5904\u7406\u7a7a\u95f4\u53d8\u6362\u4e0d\u53d8\u6027\uff0c\u5f00\u53d1\u81ea\u77e5\u8bc6\u84b8\u998f\u548c\u6559\u5e08\u77e5\u8bc6\u84b8\u998f\u4e24\u79cd\u6846\u67b6\u3002", "result": "\u5728ScanObject\u3001ModelNet40\u3001ScanntV2_cls\u548cModelNet-C\u7b49\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "JGEKD\u7b56\u7565\u901a\u8fc7\u8054\u5408\u56fe\u71b5\u77e5\u8bc6\u84b8\u998f\u6709\u6548\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\u76843D\u70b9\u4e91\u5206\u7c7b\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7c7b\u522b\u76f8\u5173\u6027\u7684\u77e5\u8bc6\u8f6c\u79fb\uff0c\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u6570\u636e\u635f\u574f\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.22225", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22225", "abs": "https://arxiv.org/abs/2509.22225", "authors": ["Jiayu Ding", "Xinpeng Liu", "Zhiyi Pan", "Shiqiang Long", "Ge Li"], "title": "Polysemous Language Gaussian Splatting via Matching-based Mask Lifting", "comment": null, "summary": "Lifting 2D open-vocabulary understanding into 3D Gaussian Splatting (3DGS)\nscenes is a critical challenge. However, mainstream methods suffer from three\nkey flaws: (i) their reliance on costly per-scene retraining prevents\nplug-and-play application; (ii) their restrictive monosemous design fails to\nrepresent complex, multi-concept semantics; and (iii) their vulnerability to\ncross-view semantic inconsistencies corrupts the final semantic representation.\nTo overcome these limitations, we introduce MUSplat, a training-free framework\nthat abandons feature optimization entirely. Leveraging a pre-trained 2D\nsegmentation model, our pipeline generates and lifts multi-granularity 2D masks\ninto 3D, where we estimate a foreground probability for each Gaussian point to\nform initial object groups. We then optimize the ambiguous boundaries of these\ninitial groups using semantic entropy and geometric opacity. Subsequently, by\ninterpreting the object's appearance across its most representative viewpoints,\na Vision-Language Model (VLM) distills robust textual features that reconciles\nvisual inconsistencies, enabling open-vocabulary querying via semantic\nmatching. By eliminating the costly per-scene training process, MUSplat reduces\nscene adaptation time from hours to mere minutes. On benchmark tasks for\nopen-vocabulary 3D object selection and semantic segmentation, MUSplat\noutperforms established training-based frameworks while simultaneously\naddressing their monosemous limitations.", "AI": {"tldr": "MUSplat\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u901a\u8fc7\u5c062D\u591a\u7c92\u5ea6\u63a9\u7801\u63d0\u5347\u52303D\u9ad8\u65af\u6cfc\u6e85\u573a\u666f\uff0c\u5b9e\u73b0\u5f00\u653e\u8bcd\u6c47\u76843D\u8bed\u4e49\u7406\u89e3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9010\u573a\u666f\u8bad\u7ec3\u3001\u5355\u8bed\u4e49\u8868\u793a\u548c\u8de8\u89c6\u56fe\u8bed\u4e49\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u7f3a\u9677\uff1a(i)\u4f9d\u8d56\u6602\u8d35\u7684\u9010\u573a\u666f\u91cd\u65b0\u8bad\u7ec3\uff0c\u65e0\u6cd5\u5373\u63d2\u5373\u7528\uff1b(ii)\u9650\u5236\u6027\u7684\u5355\u8bed\u4e49\u8bbe\u8ba1\u65e0\u6cd5\u8868\u793a\u590d\u6742\u7684\u591a\u6982\u5ff5\u8bed\u4e49\uff1b(iii)\u6613\u53d7\u8de8\u89c6\u56fe\u8bed\u4e49\u4e0d\u4e00\u81f4\u5f71\u54cd\uff0c\u7834\u574f\u6700\u7ec8\u8bed\u4e49\u8868\u793a\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u76842D\u5206\u5272\u6a21\u578b\u751f\u6210\u591a\u7c92\u5ea62D\u63a9\u7801\u5e76\u63d0\u5347\u52303D\uff0c\u4f30\u8ba1\u6bcf\u4e2a\u9ad8\u65af\u70b9\u7684\u524d\u666f\u6982\u7387\u5f62\u6210\u521d\u59cb\u5bf9\u8c61\u7ec4\uff0c\u901a\u8fc7\u8bed\u4e49\u71b5\u548c\u51e0\u4f55\u4e0d\u900f\u660e\u5ea6\u4f18\u5316\u6a21\u7cca\u8fb9\u754c\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u6700\u5177\u4ee3\u8868\u6027\u7684\u89c6\u89d2\u89e3\u91ca\u5bf9\u8c61\u5916\u89c2\uff0c\u63d0\u53d6\u9c81\u68d2\u7684\u6587\u672c\u7279\u5f81\u3002", "result": "MUSplat\u5c06\u573a\u666f\u9002\u5e94\u65f6\u95f4\u4ece\u6570\u5c0f\u65f6\u51cf\u5c11\u5230\u51e0\u5206\u949f\uff0c\u5728\u5f00\u653e\u8bcd\u6c473D\u5bf9\u8c61\u9009\u62e9\u548c\u8bed\u4e49\u5206\u5272\u57fa\u51c6\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5df2\u5efa\u7acb\u7684\u57fa\u4e8e\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u5b83\u4eec\u7684\u5355\u8bed\u4e49\u9650\u5236\u3002", "conclusion": "\u901a\u8fc7\u5b8c\u5168\u653e\u5f03\u7279\u5f81\u4f18\u5316\uff0cMUSplat\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bad\u7ec3\u514d\u8d39\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u591a\u6982\u5ff5\u8bed\u4e49\uff0c\u5e76\u5728\u5f00\u653e\u8bcd\u6c47\u67e5\u8be2\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684\u8bed\u4e49\u5339\u914d\u3002"}}
{"id": "2509.22115", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22115", "abs": "https://arxiv.org/abs/2509.22115", "authors": ["Chao Wang", "Tao Yang", "Hongtao Tian", "Yunsheng Shi", "Qiyao Ma", "Xiaotao Liu", "Ting Yao", "Wenbo Ding"], "title": "Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization", "comment": "18 pages, 5 figures, Under review as a conference paper at ICLR 2026", "summary": "Critic-free methods like GRPO reduce memory demands by estimating advantages\nfrom multiple rollouts but tend to converge slowly, as critical learning\nsignals are diluted by an abundance of uninformative samples and tokens. To\ntackle this challenge, we propose the \\textbf{Dynamic Dual-Level Down-Sampling\n(D$^3$S)} framework that prioritizes the most informative samples and tokens\nacross groups to improve the efficient of policy optimization. D$^3$S operates\nalong two levels: (1) the sample-level, which selects a subset of rollouts to\nmaximize advantage variance ($\\text{Var}(A)$). We theoretically proven that\nthis selection is positively correlated with the upper bound of the policy\ngradient norms, yielding higher policy gradients. (2) the token-level, which\nprioritizes tokens with a high product of advantage magnitude and policy\nentropy ($|A_{i,t}|\\times H_{i,t}$), focusing updates on tokens where the\npolicy is both uncertain and impactful. Moreover, to prevent overfitting to\nhigh-signal data, D$^3$S employs a dynamic down-sampling schedule inspired by\ncurriculum learning. This schedule starts with aggressive down-sampling to\naccelerate early learning and gradually relaxes to promote robust\ngeneralization. Extensive experiments on Qwen2.5 and Llama3.1 demonstrate that\nintegrating D$^3$S into advanced RL algorithms achieves state-of-the-art\nperformance and generalization while requiring \\textit{fewer} samples and\ntokens across diverse reasoning benchmarks. Our code is added in the\nsupplementary materials and will be made publicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86D\u00b3S\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u53cc\u7ea7\u4e0b\u91c7\u6837\u7b56\u7565\u4f18\u5316\u65e0\u8bc4\u8bba\u8005RL\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u5728\u6837\u672c\u7ea7\u9009\u62e9\u4f18\u52bf\u65b9\u5dee\u6700\u5927\u7684rollouts\uff0c\u5728token\u7ea7\u9009\u62e9\u4f18\u52bf\u5e45\u5ea6\u4e0e\u7b56\u7565\u71b5\u4e58\u79ef\u9ad8\u7684tokens\uff0c\u663e\u8457\u63d0\u5347\u6536\u655b\u901f\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u65e0\u8bc4\u8bba\u8005\u65b9\u6cd5\u5982GRPO\u56e0\u4f7f\u7528\u5927\u91cf\u65e0\u4fe1\u606f\u6837\u672c\u548ctoken\u5bfc\u81f4\u6536\u655b\u7f13\u6162\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5148\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u6837\u672c\u548ctoken\u6765\u63d0\u9ad8\u7b56\u7565\u4f18\u5316\u7684\u6548\u7387\u3002", "method": "D\u00b3S\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u5c42\u7ea7\uff1a\u6837\u672c\u7ea7\u9009\u62e9\u4f18\u52bf\u65b9\u5dee\u6700\u5927\u7684rollouts\u5b50\u96c6\uff0ctoken\u7ea7\u9009\u62e9\u4f18\u52bf\u5e45\u5ea6\u4e0e\u7b56\u7565\u71b5\u4e58\u79ef\u9ad8\u7684tokens\u3002\u91c7\u7528\u52a8\u6001\u4e0b\u91c7\u6837\u8c03\u5ea6\uff0c\u4ece\u6fc0\u8fdb\u4e0b\u91c7\u6837\u9010\u6b65\u8fc7\u6e21\u5230\u5bbd\u677e\u91c7\u6837\u3002", "result": "\u5728Qwen2.5\u548cLlama3.1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cD\u00b3S\u96c6\u6210\u5230\u5148\u8fdbRL\u7b97\u6cd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u6837\u672c\u548ctokens\u3002", "conclusion": "D\u00b3S\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u53cc\u7ea7\u4e0b\u91c7\u6837\u6709\u6548\u63d0\u5347\u4e86\u65e0\u8bc4\u8bba\u8005RL\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.22161", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22161", "abs": "https://arxiv.org/abs/2509.22161", "authors": ["Takashi Morita"], "title": "Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization", "comment": null, "summary": "Vector quantization, which discretizes a continuous vector space into a\nfinite set of representative vectors (a codebook), has been widely adopted in\nmodern machine learning. Despite its effectiveness, vector quantization poses a\nfundamental challenge: the non-differentiable quantization step blocks gradient\nbackpropagation. Smoothed vector quantization addresses this issue by relaxing\nthe hard assignment of a codebook vector into a weighted combination of\ncodebook entries, represented as the matrix product of a simplex vector and the\ncodebook. Effective smoothing requires two properties: (1) smoothed quantizers\nshould remain close to a onehot vector, ensuring tight approximation, and (2)\nall codebook entries should be utilized, preventing code collapse. Existing\nmethods typically address these desiderata separately. By contrast, the present\nstudy introduces a simple and intuitive regularization that promotes both\nsimultaneously by minimizing the distance between each simplex vertex and its\n$K$-nearest smoothed quantizers. Experiments on representative benchmarks,\nincluding discrete image autoencoding and contrastive speech representation\nlearning, demonstrate that the proposed method achieves more reliable codebook\nutilization and improves performance compared to prior approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5411\u91cf\u91cf\u5316\u5e73\u6ed1\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6bcf\u4e2a\u7801\u672c\u5411\u91cf\u4e0e\u5176K\u4e2a\u6700\u8fd1\u90bb\u5e73\u6ed1\u91cf\u5316\u5668\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u540c\u65f6\u5b9e\u73b0\u7d27\u81f4\u8fd1\u4f3c\u548c\u7801\u672c\u5229\u7528\u3002", "motivation": "\u5411\u91cf\u91cf\u5316\u5728\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u975e\u53ef\u5fae\u7684\u91cf\u5316\u6b65\u9aa4\u963b\u788d\u4e86\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u3002\u73b0\u6709\u5e73\u6ed1\u65b9\u6cd5\u901a\u5e38\u5206\u522b\u5904\u7406\u7d27\u81f4\u8fd1\u4f3c\u548c\u7801\u672c\u5229\u7528\u4e24\u4e2a\u9700\u6c42\u3002", "method": "\u5f15\u5165\u7b80\u5355\u76f4\u89c2\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6bcf\u4e2a\u7801\u672c\u5411\u91cf\u4e0e\u5176K\u4e2a\u6700\u8fd1\u90bb\u5e73\u6ed1\u91cf\u5316\u5668\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u540c\u65f6\u4fc3\u8fdb\u7d27\u81f4\u8fd1\u4f3c\u548c\u7801\u672c\u5229\u7528\u3002", "result": "\u5728\u79bb\u6563\u56fe\u50cf\u81ea\u7f16\u7801\u548c\u5bf9\u6bd4\u8bed\u97f3\u8868\u793a\u5b66\u4e60\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u7684\u7801\u672c\u5229\u7528\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u80fd\u540c\u65f6\u6ee1\u8db3\u5411\u91cf\u91cf\u5316\u5e73\u6ed1\u7684\u4e24\u4e2a\u5173\u952e\u9700\u6c42\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2509.22331", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22331", "abs": "https://arxiv.org/abs/2509.22331", "authors": ["Xiao Wang", "Shujuan Wu", "Xiaoxia Cheng", "Changwei Bi", "Jin Tang", "Bin Luo"], "title": "Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph Learning", "comment": "The First Work that Exploits Multi-modal Knowledge Graph for\n  Pedestrian Attribute Recognition", "summary": "Current Pedestrian Attribute Recognition (PAR) algorithms typically focus on\nmapping visual features to semantic labels or attempt to enhance learning by\nfusing visual and attribute information. However, these methods fail to fully\nexploit attribute knowledge and contextual information for more accurate\nrecognition. Although recent works have started to consider using attribute\ntext as additional input to enhance the association between visual and semantic\ninformation, these methods are still in their infancy. To address the above\nchallenges, this paper proposes the construction of a multi-modal knowledge\ngraph, which is utilized to mine the relationships between local visual\nfeatures and text, as well as the relationships between attributes and\nextensive visual context samples. Specifically, we propose an effective\nmulti-modal knowledge graph construction method that fully considers the\nrelationships among attributes and the relationships between attributes and\nvision tokens. To effectively model these relationships, this paper introduces\na knowledge graph-guided cross-modal hypergraph learning framework to enhance\nthe standard pedestrian attribute recognition framework. Comprehensive\nexperiments on multiple PAR benchmark datasets have thoroughly demonstrated the\neffectiveness of our proposed knowledge graph for the PAR task, establishing a\nstrong foundation for knowledge-guided pedestrian attribute recognition. The\nsource code of this paper will be released on\nhttps://github.com/Event-AHU/OpenPAR", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u884c\u4eba\u5c5e\u6027\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u89c6\u89c9\u7279\u5f81\u4e0e\u6587\u672c\u5c5e\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u56fe\u8c31\uff0c\u63d0\u5347\u5c5e\u6027\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u884c\u4eba\u5c5e\u6027\u8bc6\u522b\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u5c5e\u6027\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u867d\u7136\u8fd1\u671f\u5de5\u4f5c\u5f00\u59cb\u4f7f\u7528\u5c5e\u6027\u6587\u672c\u4f5c\u4e3a\u989d\u5916\u8f93\u5165\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u5904\u4e8e\u521d\u7ea7\u9636\u6bb5\u3002", "method": "\u6784\u5efa\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\uff0c\u6316\u6398\u5c40\u90e8\u89c6\u89c9\u7279\u5f81\u4e0e\u6587\u672c\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u5c5e\u6027\u4e0e\u5e7f\u6cdb\u89c6\u89c9\u4e0a\u4e0b\u6587\u6837\u672c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u63d0\u51fa\u77e5\u8bc6\u56fe\u8c31\u5f15\u5bfc\u7684\u8de8\u6a21\u6001\u8d85\u56fe\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5728\u591a\u4e2aPAR\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u5145\u5206\u8bc1\u660e\u4e86\u6240\u63d0\u77e5\u8bc6\u56fe\u8c31\u5bf9PAR\u4efb\u52a1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e3a\u77e5\u8bc6\u5f15\u5bfc\u7684\u884c\u4eba\u5c5e\u6027\u8bc6\u522b\u5efa\u7acb\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u63d0\u51fa\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u5c5e\u6027\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2509.22246", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22246", "abs": "https://arxiv.org/abs/2509.22246", "authors": ["Xiaoyang Liu", "Tao Zhu", "Zineng Dong", "Yuntian Liu", "Qingfeng Guo", "Zhaoxuan Liu", "Yu Chen", "Tao Luo"], "title": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity", "comment": null, "summary": "Statement autoformalization, the automated translation of statements from\nnatural language into formal languages, has seen significant advancements, yet\nthe development of automated evaluation metrics remains limited. Existing\nmetrics for formal statement similarity often fail to balance semantic and\nstructural information. String-based approaches capture syntactic structure but\nignore semantic meaning, whereas proof-based methods validate semantic\nequivalence but disregard structural nuances and, critically, provide no graded\nsimilarity score in the event of proof failure. To address these issues, we\nintroduce ASSESS (A Semantic and Structural Evaluation Framework for Statement\nSimilarity), which comprehensively integrates semantic and structural\ninformation to provide a continuous similarity score. Our framework first\ntransforms formal statements into Operator Trees to capture their syntactic\nstructure and then computes a similarity score using our novel TransTED\n(Transformation Tree Edit Distance) Similarity metric, which enhances\ntraditional Tree Edit Distance by incorporating semantic awareness through\ntransformations. For rigorous validation, we present EPLA (Evaluating\nProvability and Likeness for Autoformalization), a new benchmark of 524\nexpert-annotated formal statement pairs derived from miniF2F and ProofNet, with\nlabels for both semantic provability and structural likeness. Experiments on\nEPLA demonstrate that TransTED Similarity outperforms existing methods,\nachieving state-of-the-art accuracy and the highest Kappa coefficient. The\nbenchmark, and implementation code will be made public soon.", "AI": {"tldr": "\u63d0\u51fa\u4e86ASSESS\u6846\u67b6\uff0c\u901a\u8fc7TransTED\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u7ed3\u5408\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\u6765\u8bc4\u4f30\u5f62\u5f0f\u5316\u8bed\u53e5\u76f8\u4f3c\u5ea6\uff0c\u5e76\u5728EPLA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u4f18\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u5316\u8bed\u53e5\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u65b9\u6cd5\u65e0\u6cd5\u5e73\u8861\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff0c\u5b57\u7b26\u4e32\u65b9\u6cd5\u5ffd\u7565\u8bed\u4e49\uff0c\u8bc1\u660e\u65b9\u6cd5\u7f3a\u4e4f\u5206\u7ea7\u76f8\u4f3c\u5ea6\u8bc4\u5206\u3002", "method": "\u5c06\u5f62\u5f0f\u5316\u8bed\u53e5\u8f6c\u6362\u4e3a\u64cd\u4f5c\u7b26\u6811\u6355\u83b7\u8bed\u6cd5\u7ed3\u6784\uff0c\u4f7f\u7528TransTED\u76f8\u4f3c\u5ea6\u5ea6\u91cf\uff08\u589e\u5f3a\u7684\u6811\u7f16\u8f91\u8ddd\u79bb\uff0c\u5305\u542b\u8bed\u4e49\u8f6c\u6362\uff09\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u3002", "result": "\u5728EPLA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTransTED\u76f8\u4f3c\u5ea6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u51c6\u786e\u7387\u548c\u6700\u9ad8\u7684Kappa\u7cfb\u6570\u3002", "conclusion": "ASSESS\u6846\u67b6\u6709\u6548\u6574\u5408\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff0c\u4e3a\u5f62\u5f0f\u5316\u8bed\u53e5\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u8fde\u7eed\u8bc4\u5206\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.22263", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.22263", "abs": "https://arxiv.org/abs/2509.22263", "authors": ["Nakyeong Yang", "Dong-Kyum Kim", "Jea Kwon", "Minsung Kim", "Kyomin Jung", "Meeyoung Cha"], "title": "Erase or Hide? Suppressing Spurious Unlearning Neurons for Robust Unlearning", "comment": "15 pages", "summary": "Large language models trained on web-scale data can memorize private or\nsensitive knowledge, raising significant privacy risks. Although some\nunlearning methods mitigate these risks, they remain vulnerable to \"relearning\"\nduring subsequent training, allowing a substantial portion of forgotten\nknowledge to resurface. In this paper, we show that widely used unlearning\nmethods cause shallow alignment: instead of faithfully erasing target\nknowledge, they generate spurious unlearning neurons that amplify negative\ninfluence to hide it. To overcome this limitation, we introduce Ssiuu, a new\nclass of unlearning methods that employs attribution-guided regularization to\nprevent spurious negative influence and faithfully remove target knowledge.\nExperimental results confirm that our method reliably erases target knowledge\nand outperforms strong baselines across two practical retraining scenarios: (1)\nadversarial injection of private data, and (2) benign attack using an\ninstruction-following benchmark. Our findings highlight the necessity of robust\nand faithful unlearning methods for safe deployment of language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSsiuu\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f52\u56e0\u5f15\u5bfc\u7684\u6b63\u5219\u5316\u9632\u6b62\u865a\u5047\u8d1f\u5f71\u54cd\uff0c\u5b9e\u73b0\u5fe0\u5b9e\u7684\u76ee\u6807\u77e5\u8bc6\u9057\u5fd8\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u5b58\u5728\u7684\u6d45\u5c42\u5bf9\u9f50\u548c\u91cd\u65b0\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u65b9\u6cd5\u5b58\u5728\"\u6d45\u5c42\u5bf9\u9f50\"\u95ee\u9898\uff0c\u4ec5\u901a\u8fc7\u4ea7\u751f\u865a\u5047\u9057\u5fd8\u795e\u7ecf\u5143\u6765\u9690\u85cf\u76ee\u6807\u77e5\u8bc6\u800c\u975e\u771f\u6b63\u5220\u9664\uff0c\u5bfc\u81f4\u5728\u540e\u7eed\u8bad\u7ec3\u4e2d\u5bb9\u6613\u91cd\u65b0\u5b66\u4e60\u88ab\u9057\u5fd8\u7684\u77e5\u8bc6\uff0c\u5b58\u5728\u9690\u79c1\u98ce\u9669\u3002", "method": "\u5f15\u5165Ssiuu\u9057\u5fd8\u65b9\u6cd5\uff0c\u91c7\u7528\u5f52\u56e0\u5f15\u5bfc\u7684\u6b63\u5219\u5316\u6280\u672f\uff0c\u9632\u6b62\u4ea7\u751f\u865a\u5047\u7684\u8d1f\u5f71\u54cd\uff0c\u786e\u4fdd\u76ee\u6807\u77e5\u8bc6\u88ab\u5fe0\u5b9e\u79fb\u9664\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u53ef\u9760\u5730\u64e6\u9664\u76ee\u6807\u77e5\u8bc6\uff0c\u5728\u4e24\u79cd\u5b9e\u9645\u91cd\u8bad\u7ec3\u573a\u666f\uff08\u654c\u5bf9\u6570\u636e\u6ce8\u5165\u548c\u826f\u6027\u653b\u51fb\uff09\u4e2d\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5f00\u53d1\u9c81\u68d2\u4e14\u5fe0\u5b9e\u7684\u9057\u5fd8\u65b9\u6cd5\u5bf9\u4e8e\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.22267", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.22267", "abs": "https://arxiv.org/abs/2509.22267", "authors": ["Jo\u00e3o Paulo Vieira", "Victor Afonso Bauler", "Rodrigo Kobashikawa Rosa", "Danilo Silva"], "title": "Towards a more realistic evaluation of machine learning models for bearing fault diagnosis", "comment": "Submitted to Mechanical Systems and Signal Processing", "summary": "Reliable detection of bearing faults is essential for maintaining the safety\nand operational efficiency of rotating machinery. While recent advances in\nmachine learning (ML), particularly deep learning, have shown strong\nperformance in controlled settings, many studies fail to generalize to\nreal-world applications due to methodological flaws, most notably data leakage.\nThis paper investigates the issue of data leakage in vibration-based bearing\nfault diagnosis and its impact on model evaluation. We demonstrate that common\ndataset partitioning strategies, such as segment-wise and condition-wise\nsplits, introduce spurious correlations that inflate performance metrics. To\naddress this, we propose a rigorous, leakage-free evaluation methodology\ncentered on bearing-wise data partitioning, ensuring no overlap between the\nphysical components used for training and testing. Additionally, we reformulate\nthe classification task as a multi-label problem, enabling the detection of\nco-occurring fault types and the use of prevalence-independent metrics such as\nMacro AUROC. Beyond preventing leakage, we also examine the effect of dataset\ndiversity on generalization, showing that the number of unique training\nbearings is a decisive factor for achieving robust performance. We evaluate our\nmethodology on three widely adopted datasets: CWRU, Paderborn University (PU),\nand University of Ottawa (UORED-VAFCLS). This study highlights the importance\nof leakage-aware evaluation protocols and provides practical guidelines for\ndataset partitioning, model selection, and validation, fostering the\ndevelopment of more trustworthy ML systems for industrial fault diagnosis\napplications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8f74\u627f\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u6570\u636e\u6cc4\u9732\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f74\u627f\u5212\u5206\u7684\u65e0\u6cc4\u6f0f\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u91cd\u65b0\u5b9a\u4e49\u4e86\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u8f74\u627f\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u5728\u53d7\u63a7\u73af\u5883\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u6cc4\u9732\u7b49\u65b9\u200b\u200b\u6cd5\u8bba\u7f3a\u9677\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8f74\u627f\u5212\u5206\u7684\u6570\u636e\u5206\u5272\u7b56\u7565\uff0c\u786e\u4fdd\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u4f7f\u7528\u4e0d\u540c\u7684\u7269\u7406\u8f74\u627f\u7ec4\u4ef6\uff1b\u5c06\u5206\u7c7b\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u6807\u7b7e\u95ee\u9898\uff1b\u4f7f\u7528Macro AUROC\u7b49\u4e0e\u6d41\u884c\u5ea6\u65e0\u5173\u7684\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728CWRU\u3001Paderborn University\u548cUniversity of Ottawa\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8f74\u627f\u5212\u5206\u7b56\u7565\u80fd\u6709\u6548\u9632\u6b62\u6570\u636e\u6cc4\u9732\uff0c\u8bad\u7ec3\u8f74\u627f\u6570\u91cf\u5bf9\u6a21\u578b\u6cdb\u5316\u6027\u80fd\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u6cc4\u6f0f\u611f\u77e5\u8bc4\u4f30\u534f\u8bae\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u6570\u636e\u96c6\u5212\u5206\u3001\u6a21\u578b\u9009\u62e9\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u5de5\u4e1a\u6545\u969c\u8bca\u65adML\u7cfb\u7edf\u3002"}}
{"id": "2509.22576", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.22576", "abs": "https://arxiv.org/abs/2509.22576", "authors": ["Xu Wujiang", "Wentian Zhao", "Zhenting Wang", "Li Yu-Jhe", "Jin Can", "Jin Mingyu", "Mei Kai", "Wan Kun", "Metaxas Dimitris"], "title": "EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning", "comment": null, "summary": "Training LLM agents in multi-turn environments with sparse rewards, where\ncompleting a single task requires 30+ turns of interaction within an episode,\npresents a fundamental challenge for reinforcement learning. We identify a\ncritical failure mode unique to this setting: the exploration-exploitation\ncascade failure. This cascade begins with early-stage policy premature\nconvergence, where sparse feedback causes agents to commit to flawed,\nlow-entropy strategies. Subsequently, agents enter late-stage policy collapse,\nwhere conventional entropy regularization becomes counterproductive, promoting\nchaotic exploration that destabilizes training. We propose Entropy-regularized\nPolicy Optimization (EPO), a general framework that breaks this failure cycle\nthrough three synergistic mechanisms: (1) adopting entropy regularization in\nmulti-turn settings to enhance exploration, (2) an entropy smoothing\nregularizer that bounds policy entropy within historical averages to prevent\nabrupt fluctuations, and (3) adaptive phase-based weighting that balances\nexploration and exploitation across training. Our analysis justifies that EPO\nguarantees monotonically decreasing entropy variance while maintaining\nconvergence. EPO achieves up to 152% performance improvement on ScienceWorld\nand up to 19.8% on ALFWorld. Our work demonstrates that multi-turn\nsparse-reward settings require fundamentally different entropy control than\ntraditional RL, with broad implications for LLM agent training.", "AI": {"tldr": "\u63d0\u51fa\u4e86EPO\u6846\u67b6\u6765\u89e3\u51b3\u591a\u8f6e\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2dLLM\u667a\u80fd\u4f53\u7684\u63a2\u7d22-\u5229\u7528\u7ea7\u8054\u5931\u8d25\u95ee\u9898\uff0c\u901a\u8fc7\u71b5\u6b63\u5219\u5316\u3001\u71b5\u5e73\u6ed1\u548c\u81ea\u9002\u5e94\u6743\u91cd\u673a\u5236\uff0c\u5728ScienceWorld\u548cALFWorld\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86152%\u548c19.8%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u591a\u8f6e\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\uff0c\u667a\u80fd\u4f53\u9762\u4e34\u63a2\u7d22-\u5229\u7528\u7ea7\u8054\u5931\u8d25\uff1a\u65e9\u671f\u7b56\u7565\u8fc7\u65e9\u6536\u655b\u5230\u4f4e\u71b5\u7b56\u7565\uff0c\u540e\u671f\u71b5\u6b63\u5219\u5316\u53cd\u800c\u5bfc\u81f4\u7b56\u7565\u5d29\u6e83\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002", "method": "EPO\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u673a\u5236\uff1a(1)\u591a\u8f6e\u73af\u5883\u4e2d\u7684\u71b5\u6b63\u5219\u5316\u589e\u5f3a\u63a2\u7d22\uff1b(2)\u71b5\u5e73\u6ed1\u6b63\u5219\u5316\u5668\u9650\u5236\u7b56\u7565\u71b5\u5728\u5386\u53f2\u5e73\u5747\u503c\u8303\u56f4\u5185\uff1b(3)\u81ea\u9002\u5e94\u9636\u6bb5\u6743\u91cd\u5e73\u8861\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "EPO\u5728ScienceWorld\u4e0a\u5b9e\u73b0\u6700\u9ad8152%\u6027\u80fd\u63d0\u5347\uff0c\u5728ALFWorld\u4e0a\u5b9e\u73b019.8%\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u80fd\u6709\u6548\u89e3\u51b3\u591a\u8f6e\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u7684\u8bad\u7ec3\u95ee\u9898\u3002", "conclusion": "\u591a\u8f6e\u7a00\u758f\u5956\u52b1\u73af\u5883\u9700\u8981\u4e0e\u4f20\u7edfRL\u4e0d\u540c\u7684\u71b5\u63a7\u5236\u65b9\u6cd5\uff0cEPO\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u71b5\u7ba1\u7406\u673a\u5236\u6210\u529f\u89e3\u51b3\u4e86\u63a2\u7d22-\u5229\u7528\u7ea7\u8054\u5931\u8d25\u95ee\u9898\u3002"}}
{"id": "2509.22481", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22481", "abs": "https://arxiv.org/abs/2509.22481", "authors": ["Xiangmo Zhao", "Nan Yang", "Yang Wang", "Zhanwen Liu"], "title": "PSTTS: A Plug-and-Play Token Selector for Efficient Event-based Spatio-temporal Representation Learning", "comment": null, "summary": "Mainstream event-based spatio-temporal representation learning methods\ntypically process event streams by converting them into sequences of event\nframes, achieving remarkable performance. However, they neglect the high\nspatial sparsity and inter-frame motion redundancy inherent in event frame\nsequences, leading to significant computational overhead. Existing token\nsparsification methods for RGB videos rely on unreliable intermediate token\nrepresentations and neglect the influence of event noise, making them\nineffective for direct application to event data. In this paper, we propose\nProgressive Spatio-Temporal Token Selection (PSTTS), a Plug-and-Play module for\nevent data without introducing any additional parameters. PSTTS exploits the\nspatio-temporal distribution characteristics embedded in raw event data to\neffectively identify and discard spatio-temporal redundant tokens, achieving an\noptimal trade-off between accuracy and efficiency. Specifically, PSTTS consists\nof two stages, Spatial Token Purification and Temporal Token Selection. Spatial\nToken Purification discards noise and non-event regions by assessing the\nspatio-temporal consistency of events within each event frame to prevent\ninterference with subsequent temporal redundancy evaluation. Temporal Token\nSelection evaluates the motion pattern similarity between adjacent event\nframes, precisely identifying and removing redundant temporal information. We\napply PSTTS to four representative backbones UniformerV2, VideoSwin, EVMamba,\nand ExACT on the HARDVS, DailyDVS-200, and SeACT datasets. Experimental results\ndemonstrate that PSTTS achieves significant efficiency improvements.\nSpecifically, PSTTS reduces FLOPs by 29-43.6% and increases FPS by 21.6-41.3%\non the DailyDVS-200 dataset, while maintaining task accuracy. Our code will be\navailable.", "AI": {"tldr": "\u63d0\u51faPSTTS\u6a21\u5757\uff0c\u5229\u7528\u4e8b\u4ef6\u6570\u636e\u7684\u65f6\u7a7a\u5206\u5e03\u7279\u6027\u8bc6\u522b\u548c\u4e22\u5f03\u5197\u4f59token\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387", "motivation": "\u73b0\u6709\u4e8b\u4ef6\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5c06\u4e8b\u4ef6\u6d41\u8f6c\u6362\u4e3a\u4e8b\u4ef6\u5e27\u5e8f\u5217\uff0c\u4f46\u5ffd\u7565\u4e86\u4e8b\u4ef6\u5e27\u5e8f\u5217\u7684\u9ad8\u7a7a\u95f4\u7a00\u758f\u6027\u548c\u5e27\u95f4\u8fd0\u52a8\u5197\u4f59\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u3002\u73b0\u6709\u7684RGB\u89c6\u9891token\u7a00\u758f\u5316\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684\u4e2d\u95f4token\u8868\u793a\u4e14\u5ffd\u7565\u4e8b\u4ef6\u566a\u58f0\u5f71\u54cd", "method": "PSTTS\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u7a7a\u95f4token\u51c0\u5316\uff08\u901a\u8fc7\u8bc4\u4f30\u4e8b\u4ef6\u5e27\u5185\u4e8b\u4ef6\u7684\u65f6\u7a7a\u4e00\u81f4\u6027\u6765\u4e22\u5f03\u566a\u58f0\u548c\u975e\u4e8b\u4ef6\u533a\u57df\uff09\u548c\u65f6\u95f4token\u9009\u62e9\uff08\u8bc4\u4f30\u76f8\u90bb\u4e8b\u4ef6\u5e27\u95f4\u8fd0\u52a8\u6a21\u5f0f\u76f8\u4f3c\u6027\u6765\u8bc6\u522b\u548c\u79fb\u9664\u5197\u4f59\u65f6\u95f4\u4fe1\u606f\uff09", "result": "\u5728HARDVS\u3001DailyDVS-200\u548cSeACT\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cPSTTS\u663e\u8457\u63d0\u5347\u6548\u7387\uff1a\u5728DailyDVS-200\u6570\u636e\u96c6\u4e0a\u51cf\u5c11FLOPs 29-43.6%\uff0c\u63d0\u5347FPS 21.6-41.3%\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u7cbe\u5ea6", "conclusion": "PSTTS\u662f\u4e00\u4e2a\u65e0\u9700\u989d\u5916\u53c2\u6570\u7684\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u4e8b\u4ef6\u6570\u636e\u4e2d\u7684\u65f6\u7a7a\u5197\u4f59token\uff0c\u5b9e\u73b0\u7cbe\u5ea6\u548c\u6548\u7387\u7684\u6700\u4f73\u5e73\u8861"}}
{"id": "2509.22352", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22352", "abs": "https://arxiv.org/abs/2509.22352", "authors": ["Marie Brockschmidt", "Maresa Schr\u00f6der", "Stefan Feuerriegel"], "title": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis", "comment": null, "summary": "Survival analysis is a cornerstone of clinical research by modeling\ntime-to-event outcomes such as metastasis, disease relapse, or patient death.\nUnlike standard tabular data, survival data often come with incomplete event\ninformation due to dropout, or loss to follow-up. This poses unique challenges\nfor synthetic data generation, where it is crucial for clinical research to\nfaithfully reproduce both the event-time distribution and the censoring\nmechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model\nspecifically designed for generating synthetic data in survival analysis.\nSurvDiff is tailored to capture the data-generating mechanism by jointly\ngenerating mixed-type covariates, event times, and right-censoring, guided by a\nsurvival-tailored loss function. The loss encodes the time-to-event structure\nand directly optimizes for downstream survival tasks, which ensures that\nSurvDiff (i) reproduces realistic event-time distributions and (ii) preserves\nthe censoring mechanism. Across multiple datasets, we show that \\survdiff\nconsistently outperforms state-of-the-art generative baselines in both\ndistributional fidelity and downstream evaluation metrics across multiple\nmedical datasets. To the best of our knowledge, SurvDiff is the first diffusion\nmodel explicitly designed for generating synthetic survival data.", "AI": {"tldr": "SurvDiff\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u751f\u5b58\u5206\u6790\u8bbe\u8ba1\u7684\u7aef\u5230\u7aef\u6269\u6563\u6a21\u578b\uff0c\u80fd\u591f\u8054\u5408\u751f\u6210\u6df7\u5408\u7c7b\u578b\u534f\u53d8\u91cf\u3001\u4e8b\u4ef6\u65f6\u95f4\u548c\u53f3\u5220\u5931\u6570\u636e\uff0c\u901a\u8fc7\u751f\u5b58\u5bfc\u5411\u7684\u635f\u5931\u51fd\u6570\u786e\u4fdd\u751f\u6210\u6570\u636e\u7684\u5206\u5e03\u4fdd\u771f\u5ea6\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u751f\u5b58\u5206\u6790\u6570\u636e\u5e38\u56e0\u5931\u8bbf\u7b49\u539f\u56e0\u5b58\u5728\u4e0d\u5b8c\u6574\u7684\u4e8b\u4ef6\u4fe1\u606f\uff0c\u8fd9\u7ed9\u5408\u6210\u6570\u636e\u751f\u6210\u5e26\u6765\u72ec\u7279\u6311\u6218\u3002\u9700\u8981\u540c\u65f6\u5fe0\u5b9e\u91cd\u73b0\u4e8b\u4ef6\u65f6\u95f4\u5206\u5e03\u548c\u5220\u5931\u673a\u5236\uff0c\u4ee5\u652f\u6301\u4e34\u5e8a\u7814\u7a76\u3002", "method": "\u63d0\u51faSurvDiff\u6269\u6563\u6a21\u578b\uff0c\u4f7f\u7528\u751f\u5b58\u5bfc\u5411\u7684\u635f\u5931\u51fd\u6570\u8054\u5408\u751f\u6210\u6df7\u5408\u7c7b\u578b\u534f\u53d8\u91cf\u3001\u4e8b\u4ef6\u65f6\u95f4\u548c\u53f3\u5220\u5931\u6570\u636e\uff0c\u76f4\u63a5\u4f18\u5316\u4e0b\u6e38\u751f\u5b58\u4efb\u52a1\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cSurvDiff\u5728\u5206\u5e03\u4fdd\u771f\u5ea6\u548c\u4e0b\u6e38\u8bc4\u4f30\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u751f\u6210\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "SurvDiff\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u751f\u6210\u751f\u5b58\u5206\u6790\u5408\u6210\u6570\u636e\u8bbe\u8ba1\u7684\u6269\u6563\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u91cd\u73b0\u4e8b\u4ef6\u65f6\u95f4\u5206\u5e03\u5e76\u4fdd\u6301\u5220\u5931\u673a\u5236\u3002"}}
{"id": "2509.22358", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22358", "abs": "https://arxiv.org/abs/2509.22358", "authors": ["Maria Lomeli", "Matthijs Douze", "Gergely Szilvasy", "Loic Cabannes", "Jade Copet", "Sainbayar Sukhbaatar", "Jason Weston", "Gabriel Synnaeve", "Pierre-Emmanuel Mazar\u00e9", "Herv\u00e9 J\u00e9gou"], "title": "Stochastic activations", "comment": null, "summary": "We introduce stochastic activations. This novel strategy randomly selects\nbetween several non-linear functions in the feed-forward layer of a large\nlanguage model. In particular, we choose between SILU or RELU depending on a\nBernoulli draw. This strategy circumvents the optimization problem associated\nwith RELU, namely, the constant shape for negative inputs that prevents the\ngradient flow. We leverage this strategy in two ways:\n  (1) We use stochastic activations during pre-training and fine-tune the model\nwith RELU, which is used at inference time to provide sparse latent vectors.\nThis reduces the inference FLOPs and translates into a significant speedup in\nthe CPU. Interestingly, this leads to much better results than training from\nscratch with the RELU activation function.\n  (2) We evaluate stochastic activations for generation. This strategy performs\nreasonably well: it is only slightly inferior to the best deterministic\nnon-linearity, namely SILU combined with temperature scaling. This offers an\nalternative to existing strategies by providing a controlled way to increase\nthe diversity of the generated text.", "AI": {"tldr": "\u63d0\u51fa\u968f\u673a\u6fc0\u6d3b\u7b56\u7565\uff0c\u5728LLM\u524d\u9988\u5c42\u4e2d\u968f\u673a\u9009\u62e9SILU\u6216RELU\u6fc0\u6d3b\u51fd\u6570\uff0c\u89e3\u51b3\u4e86RELU\u7684\u68af\u5ea6\u6d41\u95ee\u9898\uff0c\u53ef\u7528\u4e8e\u9884\u8bad\u7ec3\u548c\u751f\u6210\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3RELU\u6fc0\u6d3b\u51fd\u6570\u5728\u8d1f\u8f93\u5165\u533a\u57df\u68af\u5ea6\u4e3a\u96f6\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5229\u7528RELU\u7684\u7a00\u758f\u6027\u4f18\u52bf\u6765\u51cf\u5c11\u63a8\u7406\u8ba1\u7b97\u91cf\u3002", "method": "\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u4f2f\u52aa\u5229\u5206\u5e03\u968f\u673a\u9009\u62e9SILU\u6216RELU\u6fc0\u6d3b\u51fd\u6570\uff0c\u63a8\u7406\u65f6\u56fa\u5b9a\u4f7f\u7528RELU\u4ee5\u83b7\u5f97\u7a00\u758f\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u76f8\u6bd4\u4ece\u5934\u8bad\u7ec3RELU\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u663e\u8457\u51cf\u5c11FLOPs\u5e76\u52a0\u901fCPU\u63a8\u7406\uff1b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u6700\u4f73\u786e\u5b9a\u6027\u975e\u7ebf\u6027\u51fd\u6570\u3002", "conclusion": "\u968f\u673a\u6fc0\u6d3b\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86RELU\u7684\u4f18\u5316\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u63a7\u5236\u751f\u6210\u591a\u6837\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2509.22544", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22544", "abs": "https://arxiv.org/abs/2509.22544", "authors": ["Mohammad Mahdi Hemmatyar", "Mahdi Jafari", "Mohammad Amin Yousefi", "Mohammad Reza Nemati", "Mobin Azadani", "Hamid Reza Rastad", "Amirmohammad Akbari"], "title": "HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection", "comment": null, "summary": "Video anomaly detection (VAD) is crucial for intelligent surveillance, but a\nsignificant challenge lies in identifying complex anomalies, which are events\ndefined by intricate relationships and temporal dependencies among multiple\nentities rather than by isolated actions. While self-supervised learning (SSL)\nmethods effectively model low-level spatiotemporal patterns, they often\nstruggle to grasp the semantic meaning of these interactions. Conversely, large\nlanguage models (LLMs) offer powerful contextual reasoning but are\ncomputationally expensive for frame-by-frame analysis and lack fine-grained\nspatial localization. We introduce HyCoVAD, Hybrid Complex Video Anomaly\nDetection, a hybrid SSL-LLM model that combines a multi-task SSL temporal\nanalyzer with LLM validator. The SSL module is built upon an nnFormer backbone\nwhich is a transformer-based model for image segmentation. It is trained with\nmultiple proxy tasks, learns from video frames to identify those suspected of\nanomaly. The selected frames are then forwarded to the LLM, which enriches the\nanalysis with semantic context by applying structured, rule-based reasoning to\nvalidate the presence of anomalies. Experiments on the challenging ComplexVAD\ndataset show that HyCoVAD achieves a 72.5% frame-level AUC, outperforming\nexisting baselines by 12.5% while reducing LLM computation. We release our\ninteraction anomaly taxonomy, adaptive thresholding protocol, and code to\nfacilitate future research in complex VAD scenarios.", "AI": {"tldr": "HyCoVAD\u662f\u4e00\u4e2a\u6df7\u5408SSL-LLM\u6a21\u578b\uff0c\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u68c0\u6d4b\u590d\u6742\u89c6\u9891\u5f02\u5e38\uff0c\u5728ComplexVAD\u6570\u636e\u96c6\u4e0a\u8fbe\u523072.5%\u7684\u5e27\u7ea7AUC\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u534712.5%", "motivation": "\u4f20\u7edf\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u7406\u89e3\u590d\u6742\u5f02\u5e38\u4e2d\u7684\u8bed\u4e49\u4ea4\u4e92\u5173\u7cfb\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u5b9a\u4f4d", "method": "\u4f7f\u7528\u57fa\u4e8ennFormer\u7684\u591a\u4efb\u52a1SSL\u65f6\u5e8f\u5206\u6790\u5668\u8bc6\u522b\u53ef\u7591\u5f02\u5e38\u5e27\uff0c\u7136\u540e\u901a\u8fc7LLM\u9a8c\u8bc1\u5668\u5e94\u7528\u7ed3\u6784\u5316\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u6765\u9a8c\u8bc1\u5f02\u5e38\u5b58\u5728", "result": "\u5728ComplexVAD\u6570\u636e\u96c6\u4e0a\u8fbe\u523072.5%\u7684\u5e27\u7ea7AUC\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u534712.5%\uff0c\u540c\u65f6\u51cf\u5c11\u4e86LLM\u8ba1\u7b97\u91cf", "conclusion": "HyCoVAD\u6210\u529f\u7ed3\u5408\u4e86SSL\u548cLLM\u7684\u4f18\u52bf\uff0c\u4e3a\u590d\u6742\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53d1\u5e03\u4e86\u4ea4\u4e92\u5f02\u5e38\u5206\u7c7b\u6cd5\u3001\u81ea\u9002\u5e94\u9608\u503c\u534f\u8bae\u548c\u4ee3\u7801"}}
{"id": "2509.22381", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.22381", "abs": "https://arxiv.org/abs/2509.22381", "authors": ["Haibo Wang", "Lutfu S. Sua", "Jun Huang", "Figen Balo", "Burak Dolar"], "title": "Enhancing Credit Risk Prediction: A Meta-Learning Framework Integrating Baseline Models, LASSO, and ECOC for Superior Accuracy", "comment": "36 pages", "summary": "Effective credit risk management is fundamental to financial decision-making,\nnecessitating robust models for default probability prediction and financial\nentity classification. Traditional machine learning approaches face significant\nchallenges when confronted with high-dimensional data, limited\ninterpretability, rare event detection, and multi-class imbalance problems in\nrisk assessment. This research proposes a comprehensive meta-learning framework\nthat synthesizes multiple complementary models: supervised learning algorithms,\nincluding XGBoost, Random Forest, Support Vector Machine, and Decision Tree;\nunsupervised methods such as K-Nearest Neighbors; deep learning architectures\nlike Multilayer Perceptron; alongside LASSO regularization for feature\nselection and dimensionality reduction; and Error-Correcting Output Codes as a\nmeta-classifier for handling imbalanced multi-class problems. We implement\nPermutation Feature Importance analysis for each prediction class across all\nconstituent models to enhance model transparency. Our framework aims to\noptimize predictive performance while providing a more holistic approach to\ncredit risk assessment. This research contributes to the development of more\naccurate and reliable computational models for strategic financial decision\nsupport by addressing three fundamental challenges in credit risk modeling. The\nempirical validation of our approach involves an analysis of the Corporate\nCredit Ratings dataset with credit ratings for 2,029 publicly listed US\ncompanies. Results demonstrate that our meta-learning framework significantly\nenhances the accuracy of financial entity classification regarding credit\nrating migrations (upgrades and downgrades) and default probability estimation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7efc\u5408\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u4e2d\u7684\u9ad8\u7ef4\u6570\u636e\u3001\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u7f55\u89c1\u4e8b\u4ef6\u68c0\u6d4b\u548c\u591a\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u4e2d\u9762\u4e34\u9ad8\u7ef4\u6570\u636e\u3001\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u7f55\u89c1\u4e8b\u4ef6\u68c0\u6d4b\u548c\u591a\u7c7b\u522b\u4e0d\u5e73\u8861\u7b49\u6311\u6218\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u548c\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\uff08XGBoost\u3001\u968f\u673a\u68ee\u6797\u3001SVM\u3001\u51b3\u7b56\u6811\uff09\u3001\u65e0\u76d1\u7763\u65b9\u6cd5\uff08KNN\uff09\u3001\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08\u591a\u5c42\u611f\u77e5\u673a\uff09\u3001LASSO\u6b63\u5219\u5316\u7279\u5f81\u9009\u62e9\uff0c\u4ee5\u53ca\u7ea0\u9519\u8f93\u51fa\u7801\u4f5c\u4e3a\u5143\u5206\u7c7b\u5668\u5904\u7406\u4e0d\u5e73\u8861\u591a\u7c7b\u522b\u95ee\u9898\u3002", "result": "\u5728\u5305\u542b2,029\u5bb6\u7f8e\u56fd\u4e0a\u5e02\u516c\u53f8\u4fe1\u7528\u8bc4\u7ea7\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u7528\u8bc4\u7ea7\u8fc1\u79fb\uff08\u5347\u7ea7\u548c\u964d\u7ea7\uff09\u548c\u8fdd\u7ea6\u6982\u7387\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u5143\u5b66\u4e60\u6846\u67b6\u4e3a\u4fe1\u7528\u98ce\u9669\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u53ef\u9760\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u652f\u6301\u6218\u7565\u91d1\u878d\u51b3\u7b56\u3002"}}
{"id": "2509.22522", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22522", "abs": "https://arxiv.org/abs/2509.22522", "authors": ["Guillem Capellera", "Luis Ferraz", "Antonio Rubio", "Alexandre Alahi", "Antonio Agudo"], "title": "JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation", "comment": null, "summary": "Generative models often treat continuous data and discrete events as separate\nprocesses, creating a gap in modeling complex systems where they interact\nsynchronously. To bridge this gap, we introduce JointDiff, a novel diffusion\nframework designed to unify these two processes by simultaneously generating\ncontinuous spatio-temporal data and synchronous discrete events. We demonstrate\nits efficacy in the sports domain by simultaneously modeling multi-agent\ntrajectories and key possession events. This joint modeling is validated with\nnon-controllable generation and two novel controllable generation scenarios:\nweak-possessor-guidance, which offers flexible semantic control over game\ndynamics through a simple list of intended ball possessors, and text-guidance,\nwhich enables fine-grained, language-driven generation. To enable the\nconditioning with these guidance signals, we introduce CrossGuid, an effective\nconditioning operation for multi-agent domains. We also share a new unified\nsports benchmark enhanced with textual descriptions for soccer and football\ndatasets. JointDiff achieves state-of-the-art performance, demonstrating that\njoint modeling is crucial for building realistic and controllable generative\nmodels for interactive systems.", "AI": {"tldr": "JointDiff\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6269\u6563\u6846\u67b6\uff0c\u7edf\u4e00\u751f\u6210\u8fde\u7eed\u65f6\u7a7a\u6570\u636e\u548c\u540c\u6b65\u79bb\u6563\u4e8b\u4ef6\uff0c\u5728\u4f53\u80b2\u9886\u57df\u9a8c\u8bc1\u4e86\u540c\u65f6\u5efa\u6a21\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u548c\u5173\u952e\u63a7\u7403\u4e8b\u4ef6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u901a\u5e38\u5c06\u8fde\u7eed\u6570\u636e\u548c\u79bb\u6563\u4e8b\u4ef6\u89c6\u4e3a\u72ec\u7acb\u8fc7\u7a0b\uff0c\u8fd9\u9650\u5236\u4e86\u5efa\u6a21\u590d\u6742\u7cfb\u7edf\u4e2d\u4e24\u8005\u540c\u6b65\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faJointDiff\u6269\u6563\u6846\u67b6\uff0c\u5f15\u5165CrossGuid\u6761\u4ef6\u64cd\u4f5c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u9886\u57df\u7684\u6709\u6548\u6761\u4ef6\u63a7\u5236\uff0c\u652f\u6301\u5f31\u63a7\u7403\u8005\u5f15\u5bfc\u548c\u6587\u672c\u5f15\u5bfc\u4e24\u79cd\u53ef\u63a7\u751f\u6210\u573a\u666f\u3002", "result": "\u5728\u8db3\u7403\u548c\u7f8e\u5f0f\u8db3\u7403\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8054\u5408\u5efa\u6a21\u5bf9\u4e8e\u6784\u5efa\u771f\u5b9e\u53ef\u63a7\u7684\u4ea4\u4e92\u7cfb\u7edf\u751f\u6210\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8054\u5408\u5efa\u6a21\u8fde\u7eed\u548c\u79bb\u6563\u8fc7\u7a0b\u5bf9\u4e8e\u6784\u5efa\u771f\u5b9e\u4e14\u53ef\u63a7\u7684\u4ea4\u4e92\u7cfb\u7edf\u751f\u6210\u6a21\u578b\u662f\u5fc5\u8981\u7684\uff0cJointDiff\u6846\u67b6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.22574", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.22574", "abs": "https://arxiv.org/abs/2509.22574", "authors": ["Marek Pecha", "Michael Skotnica", "Jana Ru\u0161ajov\u00e1", "Bohdan Rieznikov", "V\u00edt Wandrol", "Mark\u00e9ta R\u00f6snerov\u00e1", "Jarom\u00edr Knejzl\u00edk"], "title": "Machine learning approaches to seismic event classification in the Ostrava region", "comment": "10 pages, 5 figures", "summary": "The northeastern region of the Czech Republic is among the most seismically\nactive areas in the country. The most frequent seismic events are\nmining-induced since there used to be strong mining activity in the past.\nHowever, natural tectonic events may also occur. In addition, seismic stations\noften record explosions in quarries in the region. Despite the cessation of\nmining activities, mine-induced seismic events still occur. Therefore, a rapid\ndifferentiation between tectonic and anthropogenic events is still important.\n  The region is currently monitored by the OKC seismic station in\nOstrava-Kr\\'{a}sn\\'{e} Pole built in 1983 which is a part of the Czech Regional\nSeismic Network. The station has been providing digital continuous waveform\ndata at 100 Hz since 2007. In the years 1992--2002, the region was co-monitored\nby the Seismic Polygon Fren\\v{s}t\\'{a}t (SPF) which consisted of five seismic\nstations using a triggered STA/LTA system.\n  In this study, we apply and compare machine learning methods to the SPF\ndataset, which contains labeled records of tectonic and mining-induced events.\nFor binary classification, a Long Short-Term Memory recurrent neural network\nand XGBoost achieved an F1-score of 0.94 -- 0.95, demonstrating the potential\nof modern machine learning techniques for rapid event characterization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u533a\u5206\u6377\u514b\u4e1c\u5317\u90e8\u7684\u5730\u9707\u4e8b\u4ef6\u7c7b\u578b\uff08\u6784\u9020\u5730\u9707\u4e0e\u91c7\u77ff\u8bf1\u53d1\u5730\u9707\uff09\uff0c\u5728SPF\u6570\u636e\u96c6\u4e0aLSTM\u548cXGBoost\u6a21\u578b\u53d6\u5f97\u4e860.94-0.95\u7684F1\u5206\u6570\u3002", "motivation": "\u6377\u514b\u4e1c\u5317\u90e8\u662f\u5730\u9707\u6d3b\u8dc3\u533a\uff0c\u65e2\u6709\u91c7\u77ff\u8bf1\u53d1\u5730\u9707\u4e5f\u6709\u6784\u9020\u5730\u9707\uff0c\u5c3d\u7ba1\u91c7\u77ff\u6d3b\u52a8\u5df2\u505c\u6b62\uff0c\u4f46\u91c7\u77ff\u8bf1\u53d1\u5730\u9707\u4ecd\u4f1a\u53d1\u751f\uff0c\u56e0\u6b64\u9700\u8981\u5feb\u901f\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u7684\u5730\u9707\u4e8b\u4ef6\u3002", "method": "\u5e94\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u957f\u77ed\u671f\u8bb0\u5fc6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548cXGBoost\uff09\u5bf9SPF\u6570\u636e\u96c6\u4e2d\u7684\u6784\u9020\u5730\u9707\u548c\u91c7\u77ff\u8bf1\u53d1\u5730\u9707\u8bb0\u5f55\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\u3002", "result": "LSTM\u548cXGBoost\u6a21\u578b\u5728\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e860.94-0.95\u7684F1\u5206\u6570\uff0c\u8868\u660e\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u5feb\u901f\u4e8b\u4ef6\u7279\u5f81\u8bc6\u522b\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u533a\u5206\u6784\u9020\u5730\u9707\u548c\u91c7\u77ff\u8bf1\u53d1\u5730\u9707\uff0c\u4e3a\u5feb\u901f\u4e8b\u4ef6\u8868\u5f81\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2509.22611", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22611", "abs": "https://arxiv.org/abs/2509.22611", "authors": ["Junkang Wu", "Kexin Huang", "Jiancan Wu", "An Zhang", "Xiang Wang", "Xiangnan He"], "title": "Quantile Advantage Estimation for Entropy-Safe Reasoning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) strengthens LLM\nreasoning, but training often oscillates between {entropy collapse} and\n{entropy explosion}. We trace both hazards to the mean baseline used in\nvalue-free RL (e.g., GRPO and DAPO), which improperly penalizes\nnegative-advantage samples under reward outliers. We propose {Quantile\nAdvantage Estimation} (QAE), replacing the mean with a group-wise K-quantile\nbaseline. QAE induces a response-level, two-regime gate: on hard queries (p <=\n1 - K) it reinforces rare successes, while on easy queries (p > 1 - K) it\ntargets remaining failures. Under first-order softmax updates, we prove\n{two-sided entropy safety}, giving lower and upper bounds on one-step entropy\nchange that curb explosion and prevent collapse. Empirically, this minimal\nmodification stabilizes entropy, sparsifies credit assignment (with tuned K,\nroughly 80% of responses receive zero advantage), and yields sustained pass@1\ngains on Qwen3-8B/14B-Base across AIME 2024/2025 and AMC 2023. These results\nidentify {baseline design} -- rather than token-level heuristics -- as the\nprimary mechanism for scaling RLVR.", "AI": {"tldr": "\u63d0\u51fa\u4e86Quantile Advantage Estimation (QAE)\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u5206\u4f4d\u6570\u57fa\u7ebf\u66ff\u4ee3\u5747\u503c\u57fa\u7ebf\u6765\u89e3\u51b3RLVR\u8bad\u7ec3\u4e2d\u7684\u71b5\u5d29\u6e83\u548c\u71b5\u7206\u70b8\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53cc\u9762\u71b5\u5b89\u5168\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u7a33\u5b9a\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1(RLVR)\u867d\u7136\u80fd\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u5728\u71b5\u5d29\u6e83\u548c\u71b5\u7206\u70b8\u4e4b\u95f4\u632f\u8361\u3002\u7814\u7a76\u53d1\u73b0\u8fd9\u4e24\u79cd\u98ce\u9669\u90fd\u6e90\u4e8e\u65e0\u4ef7\u503cRL\u4e2d\u4f7f\u7528\u7684\u5747\u503c\u57fa\u7ebf\u5728\u5956\u52b1\u5f02\u5e38\u503c\u4e0b\u5bf9\u8d1f\u4f18\u52bf\u6837\u672c\u7684\u4e0d\u5f53\u60e9\u7f5a\u3002", "method": "\u63d0\u51fa\u5206\u4f4d\u6570\u4f18\u52bf\u4f30\u8ba1(QAE)\uff0c\u7528\u5206\u7ec4K\u5206\u4f4d\u6570\u57fa\u7ebf\u66ff\u4ee3\u5747\u503c\u57fa\u7ebf\u3002QAE\u5728\u56f0\u96be\u67e5\u8be2(p <= 1-K)\u65f6\u5f3a\u5316\u7f55\u89c1\u6210\u529f\uff0c\u5728\u7b80\u5355\u67e5\u8be2(p > 1-K)\u65f6\u9488\u5bf9\u5269\u4f59\u5931\u8d25\u3002\u5728\u4e00\u9636softmax\u66f4\u65b0\u4e0b\u8bc1\u660e\u4e86\u4e24\u9762\u71b5\u5b89\u5168\u6027\u3002", "result": "\u8fd9\u4e00\u6700\u5c0f\u4fee\u6539\u7a33\u5b9a\u4e86\u71b5\uff0c\u7a00\u758f\u5316\u4e86\u4fe1\u7528\u5206\u914d(\u8c03\u4f18K\u540e\u7ea680%\u54cd\u5e94\u83b7\u5f97\u96f6\u4f18\u52bf)\uff0c\u5e76\u5728Qwen3-8B/14B-Base\u6a21\u578b\u4e0a\u5bf9AIME 2024/2025\u548cAMC 2023\u5b9e\u73b0\u4e86\u6301\u7eed\u7684pass@1\u589e\u76ca\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\u57fa\u7ebf\u8bbe\u8ba1\u2014\u2014\u800c\u975etoken\u7ea7\u542f\u53d1\u5f0f\u65b9\u6cd5\u2014\u2014\u662f\u6269\u5c55RLVR\u7684\u4e3b\u8981\u673a\u5236\u3002"}}
