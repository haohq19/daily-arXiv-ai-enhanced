<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 13]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CL](#cs.CL) [Total: 7]
- [cs.RO](#cs.RO) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [In-process 3D Deviation Mapping and Defect Monitoring (3D-DM2) in High Production-rate Robotic Additive Manufacturing](https://arxiv.org/abs/2511.05604)
*Subash Gautam,Alejandro Vargas-Uscategui,Peter King,Hans Lohr,Alireza Bab-Hadiashar,Ivan Cole,Ehsan Asadi*

Main category: cs.CV

TL;DR: 开发实时监测系统，在高速机器人增材制造过程中检测和跟踪形状偏差，实现及时干预以保证零件质量


<details>
  <summary>Details</summary>
Motivation: 高速机器人增材制造（如冷喷涂）虽然沉积速率高，但当前开环系统存在过程不稳定性，难以保持形状精度，需要实时检测偏差以防止误差传播

Method: 提出实时监测系统，采集和重建生长中的零件，与近净形参考模型直接比较，检测制造过程中的形状偏差，并对每个偏差区域进行分割和跟踪

Result: 实现了形状不一致性的早期识别，为及时干预和补偿提供了基础

Conclusion: 该监测系统能够实现一致的零件质量，减少后处理需求

Abstract: Additive manufacturing (AM) is an emerging digital manufacturing technology to produce complex and freeform objects through a layer-wise deposition. High deposition rate robotic AM (HDRRAM) processes, such as cold spray additive manufacturing (CSAM), offer significantly increased build speeds by delivering large volumes of material per unit time. However, maintaining shape accuracy remains a critical challenge, particularly due to process instabilities in current open-loop systems. Detecting these deviations as they occur is essential to prevent error propagation, ensure part quality, and minimize post-processing requirements. This study presents a real-time monitoring system to acquire and reconstruct the growing part and directly compares it with a near-net reference model to detect the shape deviation during the manufacturing process. The early identification of shape inconsistencies, followed by segmenting and tracking each deviation region, paves the way for timely intervention and compensation to achieve consistent part quality.

</details>


### [2] [CGCE: Classifier-Guided Concept Erasure in Generative Models](https://arxiv.org/abs/2511.05865)
*Viet Nguyen,Vishal M. Patel*

Main category: cs.CV

TL;DR: CGCE是一个高效的即插即用框架，通过轻量级分类器检测和优化包含不良概念的文本嵌入，实现多概念擦除，在保持生成质量的同时提供强大的安全防护。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法容易受到对抗攻击，且鲁棒擦除往往会降低模型对安全概念的生成质量，需要在安全性和性能之间做出困难权衡。

Method: 使用在文本嵌入上操作的轻量级分类器，首先检测然后优化包含不良概念的提示词，仅修改推理时的不安全嵌入，不改变原始模型权重。

Result: CGCE在广泛的红队攻击中实现了最先进的鲁棒性，同时保持了高生成效用，在安全性和性能之间取得了优越的平衡。

Conclusion: CGCE是一个实用有效的安全生成AI解决方案，成功应用于各种现代T2I和T2V模型，展示了其多功能性。

Abstract: Recent advancements in large-scale generative models have enabled the creation of high-quality images and videos, but have also raised significant safety concerns regarding the generation of unsafe content. To mitigate this, concept erasure methods have been developed to remove undesirable concepts from pre-trained models. However, existing methods remain vulnerable to adversarial attacks that can regenerate the erased content. Moreover, achieving robust erasure often degrades the model's generative quality for safe, unrelated concepts, creating a difficult trade-off between safety and performance. To address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE), an efficient plug-and-play framework that provides robust concept erasure for diverse generative models without altering their original weights. CGCE uses a lightweight classifier operating on text embeddings to first detect and then refine prompts containing undesired concepts. This approach is highly scalable, allowing for multi-concept erasure by aggregating guidance from several classifiers. By modifying only unsafe embeddings at inference time, our method prevents harmful content generation while preserving the model's original quality on benign prompts. Extensive experiments show that CGCE achieves state-of-the-art robustness against a wide range of red-teaming attacks. Our approach also maintains high generative utility, demonstrating a superior balance between safety and performance. We showcase the versatility of CGCE through its successful application to various modern T2I and T2V models, establishing it as a practical and effective solution for safe generative AI.

</details>


### [3] [Towards Frequency-Adaptive Learning for SAR Despeckling](https://arxiv.org/abs/2511.05890)
*Ziqing Ma,Chang Yang,Zhichang Guo,Yao Li*

Main category: cs.CV

TL;DR: 提出SAR-FAH模型，通过频率自适应异构去斑方法，针对SAR图像不同频率子带设计专门子网络，有效抑制斑点噪声并保持边缘纹理。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法使用单一网络处理整个SAR图像，忽略了不同空间物理特征对应的斑点统计特性差异，导致伪影、边缘模糊和纹理失真问题。

Method: 使用小波分解将图像分离为不同频率子带；为低频部分设计基于神经ODE的动态系统去噪；为高频子带设计增强型U-Net结合可变形卷积进行噪声抑制和特征增强。

Result: 在合成和真实SAR图像上的广泛实验验证了该模型在噪声去除和结构保持方面的优越性能。

Conclusion: SAR-FAH模型通过频率自适应异构设计，有效解决了SAR图像去斑中的伪影和纹理失真问题，实现了更好的噪声抑制和结构保持效果。

Abstract: Synthetic Aperture Radar (SAR) images are inherently corrupted by speckle noise, limiting their utility in high-precision applications. While deep learning methods have shown promise in SAR despeckling, most methods employ a single unified network to process the entire image, failing to account for the distinct speckle statistics associated with different spatial physical characteristics. It often leads to artifacts, blurred edges, and texture distortion. To address these issues, we propose SAR-FAH, a frequency-adaptive heterogeneous despeckling model based on a divide-and-conquer architecture. First, wavelet decomposition is used to separate the image into frequency sub-bands carrying different intrinsic characteristics. Inspired by their differing noise characteristics, we design specialized sub-networks for different frequency components. The tailored approach leverages statistical variations across frequencies, improving edge and texture preservation while suppressing noise. Specifically, for the low-frequency part, denoising is formulated as a continuous dynamic system via neural ordinary differential equations, ensuring structural fidelity and sufficient smoothness that prevents artifacts. For high-frequency sub-bands rich in edges and textures, we introduce an enhanced U-Net with deformable convolutions for noise suppression and enhanced features. Extensive experiments on synthetic and real SAR images validate the superior performance of the proposed model in noise removal and structural preservation.

</details>


### [4] [DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational AutoEncoder for Robust Radiology Reporting with Missing Modalities](https://arxiv.org/abs/2511.05968)
*Nagur Shareef Shaik,Teja Krishna Cherukuri,Adnan Masood,Dong Hye Ye*

Main category: cs.CV

TL;DR: 提出DiA-gnostic VLVAE框架，通过解耦对齐实现稳健的放射学报告生成，解决临床数据中模态缺失和特征纠缠问题


<details>
  <summary>Details</summary>
Motivation: 当前自动化方法依赖资源密集型大语言模型或静态知识图谱，难以应对真实临床数据中的模态缺失和特征纠缠问题，导致次优融合和临床不忠实的幻觉发现

Method: 使用基于专家混合的视觉语言变分自编码器解耦共享和模态特定特征，通过约束优化目标强制潜在表示的正交性和对齐，最后使用紧凑的LLaMA-X解码器生成报告

Result: 在IU X-Ray和MIMIC-CXR数据集上分别达到0.266和0.134的BLEU@4分数，显著优于最先进模型

Conclusion: DiA框架通过解耦对齐有效解决了临床数据中的模态缺失和特征纠缠问题，实现了稳健且高效的放射学报告生成

Abstract: The integration of medical images with clinical context is essential for generating accurate and clinically interpretable radiology reports. However, current automated methods often rely on resource-heavy Large Language Models (LLMs) or static knowledge graphs and struggle with two fundamental challenges in real-world clinical data: (1) missing modalities, such as incomplete clinical context , and (2) feature entanglement, where mixed modality-specific and shared information leads to suboptimal fusion and clinically unfaithful hallucinated findings. To address these challenges, we propose the DiA-gnostic VLVAE, which achieves robust radiology reporting through Disentangled Alignment. Our framework is designed to be resilient to missing modalities by disentangling shared and modality-specific features using a Mixture-of-Experts (MoE) based Vision-Language Variational Autoencoder (VLVAE). A constrained optimization objective enforces orthogonality and alignment between these latent representations to prevent suboptimal fusion. A compact LLaMA-X decoder then uses these disentangled representations to generate reports efficiently. On the IU X-Ray and MIMIC-CXR datasets, DiA has achieved competetive BLEU@4 scores of 0.266 and 0.134, respectively. Experimental results show that the proposed method significantly outperforms state-of-the-art models.

</details>


### [5] [MALeR: Improving Compositional Fidelity in Layout-Guided Generation](https://arxiv.org/abs/2511.06002)
*Shivank Saxena,Dhruv Srivastava,Makarand Tapaswi*

Main category: cs.CV

TL;DR: MALeR是一个解决文本到图像生成中多主体组合场景布局控制问题的方法，能够防止主体出现在布局外、避免属性泄露，并生成分布内图像。


<details>
  <summary>Details</summary>
Motivation: 现有的布局引导方法在多主体组合场景中面临挑战：主体出现在布局外、生成图像超出分布范围包含不自然伪影、属性在主体间泄露导致视觉输出错误。

Method: 提出MALeR方法，给定文本提示和对应布局，防止主体出现在给定布局外并保持分布内生成；提出掩码属性感知绑定机制防止属性泄露。

Result: 定性和定量评估表明，MALeR在组合准确性、生成一致性和属性绑定方面优于先前工作，特别擅长生成具有多个主体和每个主体多个属性的场景图像。

Conclusion: MALeR有效解决了多主体组合场景生成中的关键挑战，在布局控制、属性绑定和图像质量方面表现出色。

Abstract: Recent advances in text-to-image models have enabled a new era of creative and controllable image generation. However, generating compositional scenes with multiple subjects and attributes remains a significant challenge. To enhance user control over subject placement, several layout-guided methods have been proposed. However, these methods face numerous challenges, particularly in compositional scenes. Unintended subjects often appear outside the layouts, generated images can be out-of-distribution and contain unnatural artifacts, or attributes bleed across subjects, leading to incorrect visual outputs. In this work, we propose MALeR, a method that addresses each of these challenges. Given a text prompt and corresponding layouts, our method prevents subjects from appearing outside the given layouts while being in-distribution. Additionally, we propose a masked, attribute-aware binding mechanism that prevents attribute leakage, enabling accurate rendering of subjects with multiple attributes, even in complex compositional scenes. Qualitative and quantitative evaluation demonstrates that our method achieves superior performance in compositional accuracy, generation consistency, and attribute binding compared to previous work. MALeR is particularly adept at generating images of scenes with multiple subjects and multiple attributes per subject.

</details>


### [6] [Temporal-Guided Visual Foundation Models for Event-Based Vision](https://arxiv.org/abs/2511.06238)
*Ruihao Xia,Junhong Cai,Luziwei Leng,Liuyi Wang,Chengju Liu,Ran Cheng,Yang Tang,Pan Zhou*

Main category: cs.CV

TL;DR: 提出TGVFM框架，将视觉基础模型与时间上下文融合块结合，用于事件相机视觉任务，在语义分割、深度估计和目标检测上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机在挑战性环境中具有独特优势，但处理异步事件流仍具挑战。现有方法依赖专门架构或资源密集型训练，而基于图像的视觉基础模型在事件视觉中的潜力尚未充分探索。

Method: TGVFM框架包含时间上下文融合块，具有三个关键组件：长程时间注意力建模全局时间依赖、双时空注意力进行多尺度帧关联、深度特征引导机制融合语义-时间特征。通过重新训练事件到视频模型并利用基于transformer的视觉基础模型。

Result: 在语义分割、深度估计和目标检测任务上分别比现有方法提升16%、21%和16%，达到SOTA性能。

Conclusion: 这项工作通过时间推理解锁了基于图像的视觉基础模型在事件视觉中的跨模态潜力。

Abstract: Event cameras offer unique advantages for vision tasks in challenging environments, yet processing asynchronous event streams remains an open challenge. While existing methods rely on specialized architectures or resource-intensive training, the potential of leveraging modern Visual Foundation Models (VFMs) pretrained on image data remains under-explored for event-based vision. To address this, we propose Temporal-Guided VFM (TGVFM), a novel framework that integrates VFMs with our temporal context fusion block seamlessly to bridge this gap. Our temporal block introduces three key components: (1) Long-Range Temporal Attention to model global temporal dependencies, (2) Dual Spatiotemporal Attention for multi-scale frame correlation, and (3) Deep Feature Guidance Mechanism to fuse semantic-temporal features. By retraining event-to-video models on real-world data and leveraging transformer-based VFMs, TGVFM preserves spatiotemporal dynamics while harnessing pretrained representations. Experiments demonstrate SoTA performance across semantic segmentation, depth estimation, and object detection, with improvements of 16%, 21%, and 16% over existing methods, respectively. Overall, this work unlocks the cross-modality potential of image-based VFMs for event-based vision with temporal reasoning. Code is available at https://github.com/XiaRho/TGVFM.

</details>


### [7] [Enhancing Multimodal Misinformation Detection by Replaying the Whole Story from Image Modality Perspective](https://arxiv.org/abs/2511.06284)
*Bing Wang,Ximing Li,Yanjun Wang,Changchun Li,Lin Yuanbo Wu,Buyu Wang,Shengsheng Wang*

Main category: cs.CV

TL;DR: 提出RETSIMD方法，通过文本分割和文本到图像生成来增强多模态虚假信息检测，利用图神经网络融合特征


<details>
  <summary>Details</summary>
Motivation: 观察到在多模态虚假信息检测中，文本模态通常比图像模态信息更丰富，因为文本描述完整事件而图像只呈现部分场景

Method: 将文本分割成多个片段，用预训练的文本到图像生成器生成对应图像序列，结合文本-图像和图像-标签互信息辅助目标，使用图神经网络融合图像特征

Result: 广泛的实证结果验证了RETSIMD的有效性

Conclusion: 提出的RETSIMD方法在多模态虚假信息检测任务中表现有效，通过文本分割和图像生成增强了检测能力

Abstract: Multimodal Misinformation Detection (MMD) refers to the task of detecting social media posts involving misinformation, where the post often contains text and image modalities. However, by observing the MMD posts, we hold that the text modality may be much more informative than the image modality because the text generally describes the whole event/story of the current post but the image often presents partial scenes only. Our preliminary empirical results indicate that the image modality exactly contributes less to MMD. Upon this idea, we propose a new MMD method named RETSIMD. Specifically, we suppose that each text can be divided into several segments, and each text segment describes a partial scene that can be presented by an image. Accordingly, we split the text into a sequence of segments, and feed these segments into a pre-trained text-to-image generator to augment a sequence of images. We further incorporate two auxiliary objectives concerning text-image and image-label mutual information, and further post-train the generator over an auxiliary text-to-image generation benchmark dataset. Additionally, we propose a graph structure by defining three heuristic relationships between images, and use a graph neural network to generate the fused features. Extensive empirical results validate the effectiveness of RETSIMD.

</details>


### [8] [NOAH: Benchmarking Narrative Prior driven Hallucination and Omission in Video Large Language Models](https://arxiv.org/abs/2511.06475)
*Kyuho Lee,Euntae Kim,Jinwoo Choi,Buru Chang*

Main category: cs.CV

TL;DR: NOAH是一个评估视频大语言模型中叙事先验引起幻觉和遗漏错误的大规模基准，通过插入外来视频片段构建复合视频，系统分析模型因追求叙事连贯性而忽视视觉证据的问题。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型在追求叙事连贯性时，会引入叙事先验偏差，导致产生幻觉（引入不存在事件）和遗漏（抑制与上下文不符的事实事件）两种错误，需要系统评估这些问题。

Method: 构建NOAH基准，通过将其他来源的视频片段插入目标视频中，控制语义相似度和插入位置，创建包含60K+评估样本的标注任务（一个描述任务和三个QA任务）。

Result: 实验发现：(i)大多数视频大语言模型存在叙事先验驱动的幻觉和遗漏；(ii)错误模式因架构、事件相似度和插入位置而异；(iii)帧数较少时叙事先验依赖更强，错误更严重。

Conclusion: NOAH是首个标准化评估视频大语言模型中叙事先验引起幻觉和遗漏的基准，为开发更可靠可信的模型奠定了基础。

Abstract: Video large language models (Video LLMs) have recently achieved strong performance on tasks such as captioning, summarization, and question answering. Many models and training methods explicitly encourage continuity across events to enhance narrative coherence. While this improves fluency, it also introduces an inductive bias that prioritizes storyline consistency over strict grounding in visual evidence. We identify this bias, which we call narrative prior, as a key driver of two errors: hallucinations, where non-existent events are introduced or existing ones are misinterpreted, and omissions, where factual events are suppressed because they are misaligned with surrounding context. To systematically evaluate narrative prior-induced errors, we introduce NOAH, a large-scale benchmark that constructs composite videos by inserting clips from other sources into target videos. By varying semantic similarity and insertion position, our benchmark enables controlled and scalable analysis of narrative priors. We design one captioning task with tailored metrics and three QA tasks - Existence, Temporal, and Narrative - yielding more than 60K evaluation samples. Extensive experiments yield three key findings: (i) most Video LLMs exhibit hallucinations and omissions driven by narrative priors, (ii) the patterns of these errors vary across architectures and depend on event similarity and insertion position, and (iii) reliance on narrative priors intensifies under sampling with fewer frames, amplifying errors when event continuity is weak. We establish NOAH as the first standardized evaluation of narrative prior-induced hallucination and omission in Video LLMs, providing a foundation for developing more reliable and trustworthy models. Our benchmark and code are available at https://anonymous550520.github.io/.

</details>


### [9] [SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection](https://arxiv.org/abs/2511.06702)
*Yifan Wang,Yian Zhao,Fanqi Pu,Xiaochen Yang,Yang Tang,Xi Chen,Wenming Yang*

Main category: cs.CV

TL;DR: 提出SPAN方法解决单目3D检测中解耦预测忽略几何约束的问题，通过空间点对齐和3D-2D投影对齐确保几何一致性，并采用分层任务学习策略保证训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测器采用解耦预测范式分别估计几何中心、深度、尺寸和旋转角度，但忽略了不同属性间的几何协作约束，导致缺乏几何一致性先验，性能次优。

Method: SPAN包含两个关键组件：空间点对齐在预测和真实3D边界框之间施加全局空间约束；3D-2D投影对齐确保投影的3D框与2D检测框紧密对齐。采用分层任务学习策略逐步引入对齐约束。

Result: 该方法可轻松集成到任何现有单目3D检测器中，并能带来显著的性能提升。

Conclusion: SPAN通过引入几何一致性约束解决了单目3D检测中解耦预测的局限性，提高了检测精度和几何一致性。

Abstract: Existing monocular 3D detectors typically tame the pronounced nonlinear regression of 3D bounding box through decoupled prediction paradigm, which employs multiple branches to estimate geometric center, depth, dimensions, and rotation angle separately. Although this decoupling strategy simplifies the learning process, it inherently ignores the geometric collaborative constraints between different attributes, resulting in the lack of geometric consistency prior, thereby leading to suboptimal performance. To address this issue, we propose novel Spatial-Projection Alignment (SPAN) with two pivotal components: (i). Spatial Point Alignment enforces an explicit global spatial constraint between the predicted and ground-truth 3D bounding boxes, thereby rectifying spatial drift caused by decoupled attribute regression. (ii). 3D-2D Projection Alignment ensures that the projected 3D box is aligned tightly within its corresponding 2D detection bounding box on the image plane, mitigating projection misalignment overlooked in previous works. To ensure training stability, we further introduce a Hierarchical Task Learning strategy that progressively incorporates spatial-projection alignment as 3D attribute predictions refine, preventing early stage error propagation across attributes. Extensive experiments demonstrate that the proposed method can be easily integrated into any established monocular 3D detector and delivers significant performance improvements.

</details>


### [10] [VAEVQ: Enhancing Discrete Visual Tokenization through Variational Modeling](https://arxiv.org/abs/2511.06863)
*Sicheng Yang,Xing Hu,Qiang Wu,Dawei Yang*

Main category: cs.CV

TL;DR: VAEVQ通过变分潜在量化、表示一致性策略和分布一致性正则化解决了传统VQ方法在潜在空间平滑性、表示对齐和域一致性方面的问题，显著提升了重建和生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统向量量化(VQ)方法存在潜在空间不平滑、量化前后表示对齐弱、连续与离散域一致性差等问题，导致码字学习不稳定和码本利用率低，影响重建和生成任务性能。

Method: 提出VAEVQ框架，包含三个核心组件：1) 变分潜在量化(VLQ)，用VAE替代AE进行量化；2) 表示一致性策略(RCS)，自适应调节量化前后特征对齐强度；3) 分布一致性正则化(DCR)，对齐码本分布与连续潜在分布。

Result: 在两个基准数据集上的大量实验表明，VAEVQ优于现有最先进方法。

Conclusion: VAEVQ通过改进量化机制和增强表示一致性，有效解决了传统VQ方法的局限性，在重建和生成任务中取得了更好的性能。

Abstract: Vector quantization (VQ) transforms continuous image features into discrete representations, providing compressed, tokenized inputs for generative models. However, VQ-based frameworks suffer from several issues, such as non-smooth latent spaces, weak alignment between representations before and after quantization, and poor coherence between the continuous and discrete domains. These issues lead to unstable codeword learning and underutilized codebooks, ultimately degrading the performance of both reconstruction and downstream generation tasks. To this end, we propose VAEVQ, which comprises three key components: (1) Variational Latent Quantization (VLQ), replacing the AE with a VAE for quantization to leverage its structured and smooth latent space, thereby facilitating more effective codeword activation; (2) Representation Coherence Strategy (RCS), adaptively modulating the alignment strength between pre- and post-quantization features to enhance consistency and prevent overfitting to noise; and (3) Distribution Consistency Regularization (DCR), aligning the entire codebook distribution with the continuous latent distribution to improve utilization. Extensive experiments on two benchmark datasets demonstrate that VAEVQ outperforms state-of-the-art methods.

</details>


### [11] [VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models](https://arxiv.org/abs/2511.07299)
*Ying Cheng,Yu-Ho Lin,Min-Hung Chen,Fu-En Yang,Shang-Hong Lai*

Main category: cs.CV

TL;DR: VADER是一个基于大语言模型的视频异常理解框架，通过整合关键帧对象关系特征和视觉线索来增强异常理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注异常检测和定位，忽视了对象间更深层次的因果关系和交互，这些对于理解异常行为至关重要。

Method: VADER首先应用异常评分器分配每帧异常分数，然后使用上下文感知采样策略捕获异常事件的因果上下文。通过关系特征提取器和对比关系编码器联合建模动态对象交互，生成紧凑的关系表示，最后与LLM集成生成详细描述。

Result: 在多个真实世界VAU基准测试中，VADER在异常描述、解释和因果推理任务上取得了强劲结果。

Conclusion: VADER推动了可解释视频异常分析的前沿，能够生成基于因果关系的详细描述并支持稳健的异常相关问答。

Abstract: Video anomaly understanding (VAU) aims to provide detailed interpretation and semantic comprehension of anomalous events within videos, addressing limitations of traditional methods that focus solely on detecting and localizing anomalies. However, existing approaches often neglect the deeper causal relationships and interactions between objects, which are critical for understanding anomalous behaviors. In this paper, we propose VADER, an LLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe object Relation features with visual cues to enhance anomaly comprehension from video. Specifically, VADER first applies an Anomaly Scorer to assign per-frame anomaly scores, followed by a Context-AwarE Sampling (CAES) strategy to capture the causal context of each anomalous event. A Relation Feature Extractor and a COntrastive Relation Encoder (CORE) jointly model dynamic object interactions, producing compact relational representations for downstream reasoning. These visual and relational cues are integrated with LLMs to generate detailed, causally grounded descriptions and support robust anomaly-related question answering. Experiments on multiple real-world VAU benchmarks demonstrate that VADER achieves strong results across anomaly description, explanation, and causal reasoning tasks, advancing the frontier of explainable video anomaly analysis.

</details>


### [12] [YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting](https://arxiv.org/abs/2511.07321)
*Botao Ye,Boqi Chen,Haofei Xu,Daniel Barath,Marc Pollefeys*

Main category: cs.CV

TL;DR: YoNoSplat是一个前馈模型，能够从任意数量的无结构图像中重建高质量的3D高斯溅射表示，支持有姿态和无姿态、有标定和无标定的输入，具有高效和多功能的特点。


<details>
  <summary>Details</summary>
Motivation: 解决从无结构图像集合中进行快速灵活的3D场景重建的挑战，特别是在处理无姿态和无标定输入时的困难。

Method: 使用前馈模型预测局部高斯和相机姿态，通过混合训练策略解决3D高斯和相机参数联合学习的困难，采用成对相机距离归一化方案解决尺度模糊问题，并嵌入相机内参到网络中。

Result: 在NVIDIA GH200 GPU上，从100个视图（280x518分辨率）重建场景仅需2.69秒，在标准基准测试中在无姿态和有姿态设置下均达到最先进性能。

Conclusion: YoNoSplat提供了一个高效、灵活且性能优越的3D场景重建解决方案，特别适用于处理无结构图像集合。

Abstract: Fast and flexible 3D scene reconstruction from unstructured image collections remains a significant challenge. We present YoNoSplat, a feedforward model that reconstructs high-quality 3D Gaussian Splatting representations from an arbitrary number of images. Our model is highly versatile, operating effectively with both posed and unposed, calibrated and uncalibrated inputs. YoNoSplat predicts local Gaussians and camera poses for each view, which are aggregated into a global representation using either predicted or provided poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and camera parameters, we introduce a novel mixing training strategy. This approach mitigates the entanglement between the two tasks by initially using ground-truth poses to aggregate local Gaussians and gradually transitioning to a mix of predicted and ground-truth poses, which prevents both training instability and exposure bias. We further resolve the scale ambiguity problem by a novel pairwise camera-distance normalization scheme and by embedding camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates exceptional efficiency, reconstructing a scene from 100 views (at 280x518 resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves state-of-the-art performance on standard benchmarks in both pose-free and pose-dependent settings. Our project page is at https://botaoye.github.io/yonosplat/.

</details>


### [13] [Garbage Vulnerable Point Monitoring using IoT and Computer Vision](https://arxiv.org/abs/2511.07325)
*R. Kumar,A. Lall,S. Chaudhari,M. Kale,A. Vattem*

Main category: cs.CV

TL;DR: 提出基于物联网和计算机视觉的智能城市垃圾管理系统，使用目标检测算法监控垃圾易发点的非法倾倒行为，YOLO11m模型在垃圾检测中达到92.39%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 解决城市垃圾易发点的非法倾倒问题，通过技术手段实现高效监控和管理，改善城市环境卫生。

Method: 使用街级摄像头和目标检测算法（包括YOLOv8、YOLOv10、YOLO11m和RT-DETR）进行垃圾检测，数据来自印度特伦甘纳邦Sangareddy地区。

Result: YOLO11m模型表现最佳，垃圾检测准确率达92.39%，mAP@50为0.91，能有效捕获垃圾倾倒的时、日、周模式，实现全天候监控。

Conclusion: 目标检测模型适用于垃圾易发点的监控和追踪，系统能全面监测垃圾倾倒行为，为城市垃圾管理提供有效解决方案。

Abstract: This paper proposes a smart way to manage municipal solid waste by using the Internet of Things (IoT) and computer vision (CV) to monitor illegal waste dumping at garbage vulnerable points (GVPs) in urban areas. The system can quickly detect and monitor dumped waste using a street-level camera and object detection algorithm. Data was collected from the Sangareddy district in Telangana, India. A series of comprehensive experiments was carried out using the proposed dataset to assess the accuracy and overall performance of various object detection models. Specifically, we performed an in-depth evaluation of YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models, YOLO11m achieved the highest accuracy of 92.39\% in waste detection, demonstrating its effectiveness in detecting waste. Additionally, it attains an mAP@50 of 0.91, highlighting its high precision. These findings confirm that the object detection model is well-suited for monitoring and tracking waste dumping events at GVP locations. Furthermore, the system effectively captures waste disposal patterns, including hourly, daily, and weekly dumping trends, ensuring comprehensive daily and nightly monitoring.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [FedSparQ: Adaptive Sparse Quantization with Error Feedback for Robust & Efficient Federated Learning](https://arxiv.org/abs/2511.05591)
*Chaimaa Medjadji,Sadi Alawadi,Feras M. Awaysheh,Guilain Leduc,Sylvain Kubler,Yves Le Traon*

Main category: cs.LG

TL;DR: FedSparQ是一个轻量级联邦学习压缩框架，通过动态稀疏化、半精度量化和误差反馈来减少90%的通信开销，同时保持或提高模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护数据隐私的同时面临显著的通信开销问题，因为需要在受限网络上频繁交换高维模型更新。

Method: 采用自适应阈值动态稀疏化客户端梯度，对保留条目应用半精度量化，并集成误差反馈以防止信息丢失。无需手动调整稀疏率或量化计划，适应同质和异质数据分布，且与模型架构无关。

Result: 在IID和非IID数据下的视觉基准测试中，FedSparQ显著减少通信开销（相比FedAvg减少90%字节传输），同时保持或提高模型精度（相比FedAvg非压缩方案或最先进压缩模型提高6%），并增强收敛鲁棒性（相比其他基线提高50%）。

Conclusion: FedSparQ为带宽受限的联邦学习部署提供了实用、易于部署的解决方案，并为自适应精度和隐私保护协议的未来扩展奠定了基础。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized clients while preserving data privacy by keeping raw data local. However, FL suffers from significant communication overhead due to the frequent exchange of high-dimensional model updates over constrained networks. In this paper, we present FedSparQ, a lightweight compression framework that dynamically sparsifies the gradient of each client through an adaptive threshold, applies half-precision quantization to retained entries and integrates residuals from error feedback to prevent loss of information. FedSparQ requires no manual tuning of sparsity rates or quantization schedules, adapts seamlessly to both homogeneous and heterogeneous data distributions, and is agnostic to model architecture. Through extensive empirical evaluation on vision benchmarks under independent and identically distributed (IID) and non-IID data, we show that FedSparQ substantially reduces communication overhead (reducing by 90% of bytes sent compared to FedAvg) while preserving or improving model accuracy (improving by 6% compared to FedAvg non-compressed solution or to state-of-the-art compression models) and enhancing convergence robustness (by 50%, compared to the other baselines). Our approach provides a practical, easy-to-deploy solution for bandwidth-constrained federated deployments and lays the groundwork for future extensions in adaptive precision and privacy-preserving protocols.

</details>


### [15] [Primal-Only Actor Critic Algorithm for Robust Constrained Average Cost MDPs](https://arxiv.org/abs/2511.05758)
*Anirudh Satheesh,Sooraj Sathish,Swetha Ganesh,Keenan Powell,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 提出了一种用于平均成本鲁棒约束MDP的actor-critic算法，解决了强对偶性缺失和鲁棒贝尔曼算子非收缩的问题，实现了ε-可行性和ε-最优性。


<details>
  <summary>Details</summary>
Motivation: 在鲁棒约束平均成本MDP中，强对偶性的缺失阻碍了标准对偶方法的应用，且平均成本设置下鲁棒贝尔曼算子不是收缩算子，这带来了额外的挑战。

Method: 提出了一种actor-critic算法，通过设计适当的更新规则来处理鲁棒约束和平均成本特性。

Result: 算法实现了ε-可行性和ε-最优性，在有无松弛假设下的样本复杂度分别为Õ(ε⁻⁴)和Õ(ε⁻⁶)，与折扣设置相当。

Conclusion: 该方法成功解决了鲁棒约束平均成本MDP中的关键挑战，为这类问题提供了有效的解决方案。

Abstract: In this work, we study the problem of finding robust and safe policies in Robust Constrained Average-Cost Markov Decision Processes (RCMDPs). A key challenge in this setting is the lack of strong duality, which prevents the direct use of standard primal-dual methods for constrained RL. Additional difficulties arise from the average-cost setting, where the Robust Bellman operator is not a contraction under any norm. To address these challenges, we propose an actor-critic algorithm for Average-Cost RCMDPs. We show that our method achieves both \(ε\)-feasibility and \(ε\)-optimality, and we establish a sample complexities of \(\tilde{O}\left(ε^{-4}\right)\) and \(\tilde{O}\left(ε^{-6}\right)\) with and without slackness assumption, which is comparable to the discounted setting.

</details>


### [16] [Deep Survival Analysis of Longitudinal EHR Data for Joint Prediction of Hospitalization and Death in COPD Patients](https://arxiv.org/abs/2511.05960)
*Enrico Manzini,Thomas Gonzalez Saito,Joan Escudero,Ana Génova,Cristina Caso,Tomas Perez-Porcuna,Alexandre Perera-Lluna*

Main category: cs.LG

TL;DR: 本研究使用纵向电子健康记录数据，比较统计模型、机器学习和深度学习方法预测COPD患者的住院和死亡风险，发现深度学习模型在预测性能上表现最佳。


<details>
  <summary>Details</summary>
Motivation: COPD患者住院风险增加且与生存率下降密切相关，但预测这些事件发生时间具有挑战性，文献中对此关注有限。

Method: 使用西班牙加泰罗尼亚SIDIAP数据库中2013-2017年超过15万患者的数据，将住院建模为首次事件，死亡建模为半竞争性终点事件，比较了Cox比例风险、SurvivalBoost、DeepPseudo、SurvTRACE、Dynamic Deep-Hit和Deep Recurrent Survival Machine等多种模型。

Result: 深度学习模型特别是循环架构模型在一致性指数和时间依赖性AUC方面优于机器学习和线性方法，尤其是对更难预测的住院事件。

Conclusion: 这是首个在COPD患者纵向EHR数据上应用深度生存分析联合预测多个时间到事件结果的研究，突显了深度学习方法捕捉时间模式和改进风险分层的潜力。

Abstract: Patients with chronic obstructive pulmonary disease (COPD) have an increased risk of hospitalizations, strongly associated with decreased survival, yet predicting the timing of these events remains challenging and has received limited attention in the literature. In this study, we performed survival analysis to predict hospitalization and death in COPD patients using longitudinal electronic health records (EHRs), comparing statistical models, machine learning (ML), and deep learning (DL) approaches. We analyzed data from more than 150k patients from the SIDIAP database in Catalonia, Spain, from 2013 to 2017, modeling hospitalization as a first event and death as a semi-competing terminal event. Multiple models were evaluated, including Cox proportional hazards, SurvivalBoost, DeepPseudo, SurvTRACE, Dynamic Deep-Hit, and Deep Recurrent Survival Machine. Results showed that DL models utilizing recurrent architectures outperformed both ML and linear approaches in concordance and time-dependent AUC, especially for hospitalization, which proved to be the harder event to predict. This study is, to our knowledge, the first to apply deep survival analysis on longitudinal EHR data to jointly predict multiple time-to-event outcomes in COPD patients, highlighting the potential of DL approaches to capture temporal patterns and improve risk stratification.

</details>


### [17] [ITPP: Learning Disentangled Event Dynamics in Marked Temporal Point Processes](https://arxiv.org/abs/2511.06032)
*Wang-Tao Zhou,Zhao Kang,Ke Yan,Ling Tian*

Main category: cs.LG

TL;DR: ITPP是一种新颖的通道独立MTPP架构，通过ODE骨干网络和类型感知倒置自注意力机制解耦事件类型信息，显著提升预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MTPP模型使用通道混合策略将不同事件类型信息编码到单一潜在表示中，这种纠缠会模糊类型特定动态，导致性能下降和过拟合风险增加。

Method: 提出通道独立架构ITPP，采用编码器-解码器框架和ODE骨干网络，核心是类型感知倒置自注意力机制，显式建模异构事件类型间的通道间相关性。

Result: 在多个真实世界和合成数据集上的综合实验表明，ITPP在预测准确性和泛化能力方面始终优于最先进的MTPP模型。

Conclusion: ITPP通过解耦事件类型信息并显式建模通道间相关性，提高了MTPP建模的有效性和鲁棒性，同时减少了过拟合。

Abstract: Marked Temporal Point Processes (MTPPs) provide a principled framework for modeling asynchronous event sequences by conditioning on the history of past events. However, most existing MTPP models rely on channel-mixing strategies that encode information from different event types into a single, fixed-size latent representation. This entanglement can obscure type-specific dynamics, leading to performance degradation and increased risk of overfitting. In this work, we introduce ITPP, a novel channel-independent architecture for MTPP modeling that decouples event type information using an encoder-decoder framework with an ODE-based backbone. Central to ITPP is a type-aware inverted self-attention mechanism, designed to explicitly model inter-channel correlations among heterogeneous event types. This architecture enhances effectiveness and robustness while reducing overfitting. Comprehensive experiments on multiple real-world and synthetic datasets demonstrate that ITPP consistently outperforms state-of-the-art MTPP models in both predictive accuracy and generalization.

</details>


### [18] [Event-driven physics-informed operator learning for reliability analysis](https://arxiv.org/abs/2511.06083)
*Shailesh Garg,Souvik Chakraborty*

Main category: cs.LG

TL;DR: NeuroPOL是首个神经科学启发的物理信息算子学习框架，用于可靠性分析。它通过引入可变脉冲神经元和事件驱动的脉冲动力学，显著降低计算负载和能耗，支持在边缘设备和数字孪生中的实时部署。


<details>
  <summary>Details</summary>
Motivation: 传统代理模型方法在不确定性下的工程系统可靠性分析中面临高能耗问题，限制了其在资源受限环境中的可扩展性和部署能力。

Method: 将可变脉冲神经元集成到物理信息算子架构中，用事件驱动的脉冲动力学替代连续激活函数，实现稀疏通信和能量高效的代理建模。

Result: 在五个基准测试中，NeuroPOL实现了与标准物理信息算子相当的可靠性度量，同时引入了显著的通信稀疏性，支持可扩展、分布式和能量高效的部署。

Conclusion: NeuroPOL通过神经科学启发的设计，在保持准确性的同时显著降低了计算和能耗需求，为高维问题的实时可靠性评估提供了可行解决方案。

Abstract: Reliability analysis of engineering systems under uncertainty poses significant computational challenges, particularly for problems involving high-dimensional stochastic inputs, nonlinear system responses, and multiphysics couplings. Traditional surrogate modeling approaches often incur high energy consumption, which severely limits their scalability and deployability in resource-constrained environments. We introduce NeuroPOL, \textit{the first neuroscience-inspired physics-informed operator learning framework} for reliability analysis. NeuroPOL incorporates Variable Spiking Neurons into a physics-informed operator architecture, replacing continuous activations with event-driven spiking dynamics. This innovation promotes sparse communication, significantly reduces computational load, and enables an energy-efficient surrogate model. The proposed framework lowers both computational and power demands, supporting real-time reliability assessment and deployment on edge devices and digital twins. By embedding governing physical laws into operator learning, NeuroPOL builds physics-consistent surrogates capable of accurate uncertainty propagation and efficient failure probability estimation, even for high-dimensional problems. We evaluate NeuroPOL on five canonical benchmarks, the Burgers equation, Nagumo equation, two-dimensional Poisson equation, two-dimensional Darcy equation, and incompressible Navier-Stokes equation with energy coupling. Results show that NeuroPOL achieves reliability measures comparable to standard physics-informed operators, while introducing significant communication sparsity, enabling scalable, distributed, and energy-efficient deployment.

</details>


### [19] [Mixtures of SubExperts for Large Language Continual Learning](https://arxiv.org/abs/2511.06237)
*Haeyong Kang*

Main category: cs.LG

TL;DR: 提出MoSEs方法，通过混合子专家和任务特定路由机制解决LLMs持续学习中的灾难性遗忘和参数线性增长问题。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法在持续学习中面临两难：重用参数导致灾难性遗忘，分配独立参数导致模型线性增长且无法知识迁移。

Method: 在transformer层集成稀疏子专家混合，通过任务特定路由机制隔离保护知识，自适应选择和组合已有参数。

Result: 在TRACE基准测试中显著优于传统方法，在知识保留和可扩展性方面达到SOTA，大幅节省内存和计算资源。

Conclusion: MoSEs框架有效平衡了持续学习中的遗忘控制和参数效率，实现了次线性增长和知识迁移。

Abstract: Adapting Large Language Models (LLMs) to a continuous stream of tasks is a critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT) methods have become a standard for this, they face a fundamental dilemma in continual learning. Reusing a single set of PEFT parameters for new tasks often leads to catastrophic forgetting of prior knowledge. Conversely, allocating distinct parameters for each task prevents forgetting but results in a linear growth of the model's size and fails to facilitate knowledge transfer between related tasks. To overcome these limitations, we propose a novel adaptive PEFT method referred to as \textit{Mixtures of SubExperts (MoSEs)}, a novel continual learning framework designed for minimal forgetting and efficient scalability. MoSEs integrate a sparse Mixture of SubExperts into the transformer layers, governed by a task-specific routing mechanism. This architecture allows the model to isolate and protect knowledge within dedicated SubExperts, thereby minimizing parameter interference and catastrophic forgetting. Crucially, the router can adaptively select and combine previously learned sparse parameters for new tasks, enabling effective knowledge transfer while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that MoSEs significantly outperform conventional continual learning approaches in both knowledge retention and scalability to new tasks, achieving state-of-the-art performance with substantial memory and computational savings.

</details>


### [20] [COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions](https://arxiv.org/abs/2511.06273)
*Boyan Tang,Yilong Zeng,Xuanhao Ren,Peng Xiao,Yuhan Zhao,Raymond Lee,Jianghua Wu*

Main category: cs.LG

TL;DR: 提出COTN模型，结合Transformer架构和Lee振荡器激活函数，通过Max-over-Time池化和lambda门控机制，有效捕捉混沌动态并提升在极端波动期间的预测性能。


<details>
  <summary>Details</summary>
Motivation: 金融市场和电力市场由于内在非线性、快速波动和混沌模式，在极端条件下的准确预测具有挑战性。传统激活函数在高度波动期间容易饱和，需要更有效的模型来应对这些挑战。

Method: COTN结合Transformer架构与新型Lee振荡器激活函数，采用Max-over-Time池化和lambda门控机制。还包含自编码器自回归模块来检测和隔离异常市场模式。

Result: 在电力现货市场和金融市场的广泛实验中，COTN比最先进的深度学习模型Informer性能提升达17%，比传统统计方法GARCH提升达40%。

Conclusion: COTN在应对现实世界市场不确定性和复杂性方面表现出色，为在压力下预测高波动系统提供了强大工具。

Abstract: Accurate prediction of financial and electricity markets, especially under extreme conditions, remains a significant challenge due to their intrinsic nonlinearity, rapid fluctuations, and chaotic patterns. To address these limitations, we propose the Chaotic Oscillatory Transformer Network (COTN). COTN innovatively combines a Transformer architecture with a novel Lee Oscillator activation function, processed through Max-over-Time pooling and a lambda-gating mechanism. This design is specifically tailored to effectively capture chaotic dynamics and improve responsiveness during periods of heightened volatility, where conventional activation functions (e.g., ReLU, GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder Self-Regressive (ASR) module to detect and isolate abnormal market patterns, such as sudden price spikes or crashes, thereby preventing corruption of the core prediction process and enhancing robustness. Extensive experiments across electricity spot markets and financial markets demonstrate the practical applicability and resilience of COTN. Our approach outperforms state-of-the-art deep learning models like Informer by up to 17% and traditional statistical methods like GARCH by as much as 40%. These results underscore COTN's effectiveness in navigating real-world market uncertainty and complexity, offering a powerful tool for forecasting highly volatile systems under duress.

</details>


### [21] [Adaptive Regularization for Large-Scale Sparse Feature Embedding Models](https://arxiv.org/abs/2511.06374)
*Mang Li,Wei Lyu*

Main category: cs.LG

TL;DR: 本文针对CTR和CVR预估模型中的单轮过拟合问题进行了理论分析，提出了自适应正则化方法来解决多轮训练时的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 在搜索、广告和推荐领域，依赖大规模稀疏类别特征的CTR和CVR预估模型在多轮训练时会出现显著的性能下降，但现有研究未能明确这一现象的根本原因。

Method: 首先对大规模稀疏类别特征导致过拟合的原因进行理论分析，然后基于分析提出自适应正则化方法。

Result: 该方法不仅防止了多轮训练时的严重性能下降，还提高了单轮训练时的模型性能，并已在实际生产系统中部署。

Conclusion: 通过理论分析识别了过拟合的根本原因，提出的自适应正则化方法有效解决了单轮过拟合问题，提升了模型性能。

Abstract: The one-epoch overfitting problem has drawn widespread attention, especially in CTR and CVR estimation models in search, advertising, and recommendation domains. These models which rely heavily on large-scale sparse categorical features, often suffer a significant decline in performance when trained for multiple epochs. Although recent studies have proposed heuristic solutions, they have not clearly identified the fundamental cause of this phenomenon. In this work, we provide a theoretical analysis that explains why overfitting occurs in models that use large-scale sparse categorical features. Based on this analysis, we propose an adaptive regularization method to address it. Our approach not only prevents the severe performance degradation observed during multi-epoch training, but also improves model performance within a single epoch. This method has already been deployed in online production systems.

</details>


### [22] [Explainable AI For Early Detection Of Sepsis](https://arxiv.org/abs/2511.06492)
*Atharva Thakur,Shruti Dhumal*

Main category: cs.LG

TL;DR: 提出了一种可解释的AI方法用于脓毒症分析，将机器学习与临床知识相结合，既提供准确的脓毒症发病预测，又让临床医生能够理解和验证模型输出。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命的疾病，需要快速检测和治疗。虽然机器学习模型在预测脓毒症发病方面显示出潜力，但其黑盒性质限制了可解释性和临床信任度。

Method: 开发了一种可解释的AI方法，将机器学习与临床知识相结合，使模型输出能够与既定的医学专业知识对齐。

Result: 该方法不仅能够准确预测脓毒症发病，还使临床医生能够理解、验证模型输出。

Conclusion: 提出的可解释AI方法解决了脓毒症预测中黑盒模型的局限性，增强了临床信任度和实用性。

Abstract: Sepsis is a life-threatening condition that requires rapid detection and treatment to prevent progression to severe sepsis, septic shock, or multi-organ failure. Despite advances in medical technology, it remains a major challenge for clinicians. While recent machine learning models have shown promise in predicting sepsis onset, their black-box nature limits interpretability and clinical trust. In this study, we present an interpretable AI approach for sepsis analysis that integrates machine learning with clinical knowledge. Our method not only delivers accurate predictions of sepsis onset but also enables clinicians to understand, validate, and align model outputs with established medical expertise.

</details>


### [23] [Adaptive Initial Residual Connections for GNNs with Theoretical Guarantees](https://arxiv.org/abs/2511.06598)
*Mohammad Shirzadi,Ali Safarpoor Dehkordi,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 本文研究图神经网络中的自适应残差连接方案，证明其能防止过平滑现象，并在异配图上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度图神经网络中消息传递会导致表达能力下降，现有残差连接方案不够灵活，需要研究自适应残差强度的方法来保持节点嵌入的多样性。

Method: 提出自适应残差方案，不同节点具有不同的残差强度；证明该方法能保持Dirichlet能量远离零；还引入启发式设置残差强度的变体以降低时间复杂度。

Result: 理论证明该方法能防止过平滑；实验表明在异配图上优于标准方法和最先进方法；启发式变体与可学习版本性能相当但更高效。

Conclusion: 自适应残差连接是防止图神经网络过平滑的有效方法，在异配图上表现优异，且启发式设置残差强度可达到相似性能但更高效。

Abstract: Message passing is the core operation in graph neural networks, where each node updates its embeddings by aggregating information from its neighbors. However, in deep architectures, this process often leads to diminished expressiveness. A popular solution is to use residual connections, where the input from the current (or initial) layer is added to aggregated neighbor information to preserve embeddings across layers. Following a recent line of research, we investigate an adaptive residual scheme in which different nodes have varying residual strengths. We prove that this approach prevents oversmoothing; particularly, we show that the Dirichlet energy of the embeddings remains bounded away from zero. This is the first theoretical guarantee not only for the adaptive setting, but also for static residual connections (where residual strengths are shared across nodes) with activation functions. Furthermore, extensive experiments show that this adaptive approach outperforms standard and state-of-the-art message passing mechanisms, especially on heterophilic graphs. To improve the time complexity of our approach, we introduce a variant in which residual strengths are not learned but instead set heuristically, a choice that performs as well as the learnable version.

</details>


### [24] [Non-Rival Data as Rival Products: An Encapsulation-Forging Approach for Data Synthesis](https://arxiv.org/abs/2511.06610)
*Kaidong Wang,Jiale Li,Shao-Bo Lin,Yao Wang*

Main category: cs.LG

TL;DR: EnFo框架通过将原始数据的预测知识封装到特定"密钥"模型中，然后优化合成数据使其过度拟合该模型，从而创建具有不对称效用的竞争性合成数据，解决数据共享与竞争优势保护的困境。


<details>
  <summary>Details</summary>
Motivation: 数据的非竞争性使企业在共享数据创造价值与保护竞争优势之间面临两难，现有数据合成方法通常产生对称效用的数据，无法有效保护数据所有者的竞争优势。

Method: EnFo框架采用两阶段方法：首先将原始数据的预测知识封装到指定的"密钥"模型中，然后通过优化合成数据使其故意过度拟合该密钥模型，从而创建具有不对称效用的竞争性合成数据。

Result: EnFo框架展现出卓越的样本效率，仅需原始数据的一小部分即可达到相同性能，同时提供强大的隐私保护和抗滥用能力。

Conclusion: EnFo为企业提供了一种实用的解决方案，使其能够在战略合作中共享数据，同时不损害核心分析优势。

Abstract: The non-rival nature of data creates a dilemma for firms: sharing data unlocks value but risks eroding competitive advantage. Existing data synthesis methods often exacerbate this problem by creating data with symmetric utility, allowing any party to extract its value. This paper introduces the Encapsulation-Forging (EnFo) framework, a novel approach to generate rival synthetic data with asymmetric utility. EnFo operates in two stages: it first encapsulates predictive knowledge from the original data into a designated ``key'' model, and then forges a synthetic dataset by optimizing the data to intentionally overfit this key model. This process transforms non-rival data into a rival product, ensuring its value is accessible only to the intended model, thereby preventing unauthorized use and preserving the data owner's competitive edge. Our framework demonstrates remarkable sample efficiency, matching the original data's performance with a fraction of its size, while providing robust privacy protection and resistance to misuse. EnFo offers a practical solution for firms to collaborate strategically without compromising their core analytical advantage.

</details>


### [25] [Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions](https://arxiv.org/abs/2511.06662)
*Franklin Lee,Tengfei Ma*

Main category: cs.LG

TL;DR: 提出了首个结合知识图谱和电子健康记录的系统，通过教师-学生模型实现零样本药物相互作用预测，提高临床决策支持能力。


<details>
  <summary>Details</summary>
Motivation: 现有药物相互作用模型要么依赖知识图谱（无法处理未见药物），要么依赖电子健康记录（噪声大、时间依赖性强、站点依赖性），需要一种能结合两者优势的新方法。

Method: 使用融合教师模型学习知识图谱和电子健康记录中的药物关系，然后蒸馏到仅使用电子健康记录的学生模型中，实现零样本推理。系统基于共享药理学机制本体，生成可解释的警报而非不透明的风险评分。

Result: 在多机构数据集上评估，系统保持精度，产生机制特异性预测，减少误报，在可比检测性能下漏报更少真实相互作用。案例研究显示能零样本识别知识图谱中缺失药物的CYP介导和药效学机制。

Conclusion: 该系统支持临床决策支持和药物警戒的实际应用，能够泛化到新药或罕见药物，无需推理时访问知识图谱。

Abstract: Drug-drug interactions (DDIs) remain a major source of preventable harm, and many clinically important mechanisms are still unknown. Existing models either rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on electronic health records (EHRs), which are noisy, temporal, and site-dependent. We introduce, to our knowledge, the first system that conditions KG relation scoring on patient-level EHR context and distills that reasoning into an EHR-only model for zero-shot inference. A fusion "Teacher" learns mechanism-specific relations for drug pairs represented in both sources, while a distilled "Student" generalizes to new or rarely used drugs without KG access at inference. Both operate under a shared ontology (set) of pharmacologic mechanisms (drug relations) to produce interpretable, auditable alerts rather than opaque risk scores. Trained on a multi-institution EHR corpus paired with a curated DrugBank DDI graph, and evaluated using a clinically aligned, decision-focused protocol with leakage-safe negatives that avoid artificially easy pairs, the system maintains precision across multi-institutuion test data, produces mechanism-specific, clinically consistent predictions, reduces false alerts (higher precision) at comparable overall detection performance (F1), and misses fewer true interactions compared to prior methods. Case studies further show zero-shot identification of clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs absent from the KG, supporting real-world use in clinical decision support and pharmacovigilance.

</details>


### [26] [Multi-Modal Continual Learning via Cross-Modality Adapters and Representation Alignment with Knowledge Preservation](https://arxiv.org/abs/2511.06723)
*Evelyn Chee,Wynne Hsu,Mong Li Lee*

Main category: cs.LG

TL;DR: 提出基于预训练模型的多模态持续学习框架，通过跨模态适配器和表示对齐损失来整合多模态信息并防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法主要关注单模态数据，而多模态学习能利用多样化感官输入，但多模态持续学习面临整合新信息和防止遗忘的双重挑战。

Method: 使用预训练模型框架，包含混合专家结构的跨模态适配器、表示对齐损失以及表示关系正则化来保护先前任务知识。

Result: 在多个多模态数据集上的实验表明，该方法在类别增量和域增量学习中均优于基线，获得更高准确率和更低遗忘率。

Conclusion: 该框架能有效处理多模态持续学习问题，在保持先前知识的同时整合新模态信息，性能优于现有方法。

Abstract: Continual learning is essential for adapting models to new tasks while retaining previously acquired knowledge. While existing approaches predominantly focus on uni-modal data, multi-modal learning offers substantial benefits by utilizing diverse sensory inputs, akin to human perception. However, multi-modal continual learning presents additional challenges, as the model must effectively integrate new information from various modalities while preventing catastrophic forgetting. In this work, we propose a pre-trained model-based framework for multi-modal continual learning. Our framework includes a novel cross-modality adapter with a mixture-of-experts structure to facilitate effective integration of multi-modal information across tasks. We also introduce a representation alignment loss that fosters learning of robust multi-modal representations, and regularize relationships between learned representations to preserve knowledge from previous tasks. Experiments on several multi-modal datasets demonstrate that our approach consistently outperforms baselines in both class-incremental and domain-incremental learning, achieving higher accuracy and reduced forgetting.

</details>


### [27] [Contact Wasserstein Geodesics for Non-Conservative Schrodinger Bridges](https://arxiv.org/abs/2511.06856)
*Andrea Testa,Soren Hauberg,Tamim Asfour,Leonel Rozo*

Main category: cs.LG

TL;DR: 提出非保守广义薛定谔桥(NCGSB)，基于接触哈密顿力学，允许能量随时间变化，能建模更丰富的真实世界随机过程。通过参数化Wasserstein流形，将桥问题转化为有限维空间中的可处理测地线计算。


<details>
  <summary>Details</summary>
Motivation: 传统薛定谔桥方法受限于能量守恒假设，限制了桥的形状，无法建模能量变化的现象。需要克服这一限制来捕捉更丰富和真实的中间动态。

Method: 引入NCGSB框架，基于接触哈密顿力学允许能量变化。通过参数化Wasserstein流形，将问题转化为接触Wasserstein测地线(CWG)计算，使用ResNet架构实现非迭代求解器，具有近线性复杂度。

Result: 在流形导航、分子动力学预测和图像生成等任务上验证了框架的有效性，展示了其实际优势和多功能性。

Conclusion: NCGSB提供了一个更通用的随机过程建模框架，能够捕捉能量变化的真实世界现象，计算效率高且支持引导生成。

Abstract: The Schrödinger Bridge provides a principled framework for modeling stochastic processes between distributions; however, existing methods are limited by energy-conservation assumptions, which constrains the bridge's shape preventing it from model varying-energy phenomena. To overcome this, we introduce the non-conservative generalized Schrödinger bridge (NCGSB), a novel, energy-varying reformulation based on contact Hamiltonian mechanics. By allowing energy to change over time, the NCGSB provides a broader class of real-world stochastic processes, capturing richer and more faithful intermediate dynamics. By parameterizing the Wasserstein manifold, we lift the bridge problem to a tractable geodesic computation in a finite-dimensional space. Unlike computationally expensive iterative solutions, our contact Wasserstein geodesic (CWG) is naturally implemented via a ResNet architecture and relies on a non-iterative solver with near-linear complexity. Furthermore, CWG supports guided generation by modulating a task-specific distance metric. We validate our framework on tasks including manifold navigation, molecular dynamics predictions, and image generation, demonstrating its practical benefits and versatility.

</details>


### [28] [RobustA: Robust Anomaly Detection in Multimodal Data](https://arxiv.org/abs/2511.07276)
*Salem AlMarri,Muhammad Irzam Liaqat,Muhammad Zaigham Zaheer,Shah Nawaz,Karthik Nandakumar,Markus Schedl*

Main category: cs.LG

TL;DR: 该论文首次系统研究模态损坏对多模态异常检测的影响，提出了包含音频和视觉损坏的评估数据集RobustA，并提出了一种对损坏模态具有鲁棒性的多模态异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多模态数据经常因环境失真而损坏，现有方法未充分考虑模态损坏对异常检测性能的负面影响。

Method: 学习不同模态的共享表示空间，并在推理时基于估计的损坏程度采用动态加权方案。

Result: 提出的方法对损坏模态表现出显著的鲁棒性，能够有效应对现实世界中可能发生的模态损坏情况。

Conclusion: 这项工作推动了多模态异常检测在现实世界中的应用，解决了模态损坏可能发生的情况，相关数据集和特征将公开提供。

Abstract: In recent years, multimodal anomaly detection methods have demonstrated remarkable performance improvements over video-only models. However, real-world multimodal data is often corrupted due to unforeseen environmental distortions. In this paper, we present the first-of-its-kind work that comprehensively investigates the adverse effects of corrupted modalities on multimodal anomaly detection task. To streamline this work, we propose RobustA, a carefully curated evaluation dataset to systematically observe the impacts of audio and visual corruptions on the overall effectiveness of anomaly detection systems. Furthermore, we propose a multimodal anomaly detection method, which shows notable resilience against corrupted modalities. The proposed method learns a shared representation space for different modalities and employs a dynamic weighting scheme during inference based on the estimated level of corruption. Our work represents a significant step forward in enabling the real-world application of multimodal anomaly detection, addressing situations where the likely events of modality corruptions occur. The proposed evaluation dataset with corrupted modalities and respective extracted features will be made publicly available.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference](https://arxiv.org/abs/2511.06175)
*Kaijie Xu,Fandi Meng,Clark Verbrugge,Simon Lucas*

Main category: cs.AI

TL;DR: CSP4SDG是一个用于社交推理游戏的约束满足概率框架，通过分析游戏事件和对话来推断玩家隐藏身份，在推理准确性和解释性方面优于基于LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 在社交推理游戏中，玩家隐藏身份并故意误导他人，使得角色推断成为核心且具有挑战性的任务。准确的角色识别是玩家和AI表现的关键基础。

Method: 提出CSP4SDG框架，将游戏事件和对话映射到四个语言无关的约束类别：证据、现象、断言和假设。使用硬约束修剪不可能的角色分配，加权软约束对剩余分配进行评分，信息增益加权将每个假设与其在熵减少下的期望值联系起来。

Result: 在三个公共数据集上的实验表明，CSP4SDG在所有推理场景中都优于基于LLM的基线方法，并且当作为辅助"推理工具"提供给LLM时能提升其性能。

Conclusion: 研究表明，基于信息论的原则性概率推理是社交推理游戏中重型神经模型的可扩展替代或补充方案，产生完全可解释的角色后验分布并能实时更新。

Abstract: In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary "reasoning tool." Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.

</details>


### [30] [GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening](https://arxiv.org/abs/2511.06262)
*Siming Zhao,Qi Li*

Main category: cs.AI

TL;DR: GAIA是一个面向B2B谈判和筛选的治理优先框架，通过定义角色、信息门控进展、双重反馈集成和授权边界机制，确保AI委托的安全性、效率和可审计性。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在高风险B2B环境中的部署受到治理限制，包括防止未经授权承诺、确保充分信息收集以及维持有效人类监督。现有研究主要关注自主谈判，忽略了实际需求如分阶段信息收集、明确授权边界和系统反馈集成。

Method: GAIA框架定义三个核心角色（委托人、代理、对方）和可选批评者角色，通过三个机制组织交互：信息门控进展分离筛选与谈判；双重反馈集成结合AI批评与人类修正；授权边界与明确升级路径。

Result: 提出了一个正式的治理框架，包含四个安全不变量的协调机制，通过任务完整性跟踪实现信息门控进展，通过并行学习通道实现双重反馈集成，并建立了结合自动化协议指标与人类判断的混合验证蓝图。

Conclusion: GAIA通过连接理论与实践，提供了一个可复现的规范，用于在采购、房地产和人员配置等流程中实现安全、高效和可问责的AI委托。

Abstract: Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows.

</details>


### [31] [Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems](https://arxiv.org/abs/2511.06301)
*Azanzi Jiomekong,Jean Bikim,Patricia Negoue,Joyce Chin*

Main category: cs.AI

TL;DR: 本文介绍了Secu-Table数据集，这是一个包含1500多个表格和15k+实体的安全领域语义表解释数据集，基于CVE和CWE数据构建，用于评估基于LLM的语义表解释系统。


<details>
  <summary>Details</summary>
Motivation: 在安全领域，用于评估语义表解释系统的表格数据集尚未公开可用，这限制了该领域的研究进展。

Method: 从CVE和CWE数据源提取安全数据构建表格，使用Wikidata和SEPSES CSKG知识图谱进行标注，创建了包含1500多个表格的数据集。

Result: 发布了Secu-Table数据集及相关代码，作为SemTab挑战赛的一部分，并进行了初步评估，使用了Falcon3-7b-instruct、Mistral-7B-Instruct和GPT-4o mini等LLM作为基线。

Conclusion: Secu-Table数据集填补了安全领域语义表解释评估数据的空白，为研究社区提供了重要的资源。

Abstract: Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM.

</details>


### [32] [What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models](https://arxiv.org/abs/2511.06380)
*Chen He,Xun Jiang,Lei Wang,Hao Yang,Chong Peng,Peng Yan,Fumin Shen,Xing Xu*

Main category: cs.AI

TL;DR: 论文提出AEPO方法解决LLMs在复杂领域推理中的"回音反射"问题，通过控制信息流和自适应熵优化来提升反思质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数学推理上表现良好，但在涉及复杂领域知识的任务中，LLMs在反思阶段无法产生新的认知见解，而是机械重复早期推理步骤，形成"回音反射"现象。

Method: 提出自适应熵策略优化(AEPO)框架，包含两个核心组件：反思感知信息过滤(量化认知信息流，防止最终答案受早期错误认知影响)和自适应熵优化(动态平衡不同推理阶段的探索与利用)。

Result: 广泛实验表明AEPO在多样化基准测试中持续优于主流强化学习方法，达到最先进性能。

Conclusion: AEPO有效解决了LLMs在复杂领域推理中的反思质量问题，通过控制信息流和优化探索策略显著提升了模型的认知反思能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as "Echo Reflection". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [33] [Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation](https://arxiv.org/abs/2511.05516)
*Canxiang Yan,Chunxiang Jin,Dawei Huang,Haibing Yu,Han Peng,Hui Zhan,Jie Gao,Jing Peng,Jingdong Chen,Jun Zhou,Kaimeng Ren,Ming Yang,Mingxue Yang,Qiang Xu,Qin Zhao,Ruijie Xiong,Shaoxiong Lin,Xuezhi Wang,Yi Yuan,Yifei Wu,Yongjie Lyu,Zhengyu He,Zhihao Qiu,Zhiqiang Fang,Ziyuan Huang*

Main category: cs.CL

TL;DR: 提出了统一的语音理解、生成和编辑框架，通过统一的连续语音分词器MingTok-Audio整合语义和声学特征，开发了语音语言模型Ming-UniAudio及其编辑版本Ming-UniAudio-Edit，首个仅通过自然语言指令实现通用自由形式语音编辑的模型。


<details>
  <summary>Details</summary>
Motivation: 现有语音模型在理解和生成任务上存在表征冲突，阻碍了基于指令的自由形式语音编辑能力。

Method: 开发统一的连续语音分词器MingTok-Audio整合语义和声学特征，基于此构建语音语言模型Ming-UniAudio，并进一步训练专门的语音编辑模型Ming-UniAudio-Edit。

Result: 在ContextASR基准测试中12个指标中的8个达到新SOTA，中文语音克隆的Seed-TTS-WER达到0.95，建立了首个自由形式语音编辑基准Ming-Freeform-Audio-Edit。

Conclusion: 成功解决了语音理解与生成任务的表征冲突问题，实现了统一的语音理解、生成和编辑能力，为未来研究奠定了基础。

Abstract: Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.

</details>


### [34] [Language Generation: Complexity Barriers and Implications for Learning](https://arxiv.org/abs/2511.05759)
*Marcelo Arenas,Pablo Barceló,Luis Cofré,Alexander Kozachinskiy*

Main category: cs.CL

TL;DR: 论文揭示了语言生成理论可能性与实际可行性之间的巨大差距，即使对于简单的正则和上下文无关语言，成功生成所需的样本数量也可能极其庞大甚至不可计算。


<details>
  <summary>Details</summary>
Motivation: 虽然Kleinberg和Mullainathan证明了语言生成在理论上是可能的，但这种理论保证并未说明其实际可行性。本研究旨在探讨语言生成在实际中的效率问题。

Method: 通过分析简单且经过充分研究的语言家族（如正则语言和上下文无关语言），研究这些语言生成所需的样本数量。

Result: 研究发现，即使是简单的语言家族，成功生成所需的样本数量也可能极其庞大，在某些情况下甚至无法用任何可计算函数来界定。

Conclusion: 理论可能性与高效可学习性之间存在显著差距，解释现代语言模型的经验成功需要更精细的视角，考虑自然语言的结构特性如何使有效生成在实践中成为可能。

Abstract: Kleinberg and Mullainathan showed that, in principle, language generation is always possible: with sufficiently many positive examples, a learner can eventually produce sentences indistinguishable from those of a target language. However, the existence of such a guarantee does not speak to its practical feasibility. In this work, we show that even for simple and well-studied language families -- such as regular and context-free languages -- the number of examples required for successful generation can be extraordinarily large, and in some cases not bounded by any computable function. These results reveal a substantial gap between theoretical possibility and efficient learnability. They suggest that explaining the empirical success of modern language models requires a refined perspective -- one that takes into account structural properties of natural language that make effective generation possible in practice.

</details>


### [35] [Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records](https://arxiv.org/abs/2511.06230)
*Juntao Li,Haobin Yuan,Ling Luo,Tengxiao Lv,Yan Jiang,Fan Wang,Ping Zhang,Huiyi Lv,Jian Wang,Yuanyuan Sun,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文介绍了CHIP 2025共享任务2竞赛，该竞赛旨在开发基于中国真实电子病历数据的出院药物推荐系统。构建了包含5,894条住院记录的CDrugRed数据集，最佳团队在最终测试集上获得了0.5102的Jaccard分数和0.6267的F1分数。


<details>
  <summary>Details</summary>
Motivation: 出院药物推荐对于确保治疗连续性、预防再入院和改善慢性代谢疾病患者的长期管理至关重要。该任务旨在开发基于中国真实电子病历数据的自动药物推荐方法。

Method: 构建了CDrugRed数据集，包含5,894条去标识化的住院记录，涉及3,190名中国患者。任务具有多标签推荐、异质临床文本和患者特异性治疗计划等挑战。使用基于大语言模型的集成系统进行药物推荐。

Result: 共有526个团队注册，167个团队提交了Phase A的有效结果，95个团队提交了Phase B的有效结果。最佳团队在最终测试集上获得了0.5102的Jaccard分数和0.6267的F1分数。

Conclusion: 结果显示了基于大语言模型的集成系统在中国电子病历药物推荐中的潜力，同时也凸显了应用大语言模型于药物推荐领域仍面临的挑战。

Abstract: Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.

</details>


### [36] [HLPD: Aligning LLMs to Human Language Preference for Machine-Revised Text Detection](https://arxiv.org/abs/2511.06942)
*Fangqi Dai,Xingjian Jiang,Zizhuang Deng*

Main category: cs.CL

TL;DR: 提出了HLPD方法，通过奖励对齐优化使评分模型更偏好人类写作风格，从而在对抗性多任务环境中更有效检测机器修订文本。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以检测先进LLM输出或经过对抗性多任务机器修订的文本，特别是在黑盒设置下生成模型未知时。

Method: 基于人类写作具有独特风格模式的假设，提出HLPD方法，使用HLPO奖励对齐过程将评分模型的标记分布向人类写作风格偏移。

Result: 在检测GPT系列模型修订文本时，HLPD相比ImBD相对提升15.11% AUROC，比Fast-DetectGPT提升45.56%；在先进LLM生成文本上，HLPD平均AUROC最高，超过ImBD 5.53%，超过Fast-DetectGPT 34.14%。

Conclusion: HLPD通过偏好人类写作风格的方法，在对抗性多任务环境中显著提升了机器修订文本的检测性能。

Abstract: To prevent misinformation and social issues arising from trustworthy-looking content generated by LLMs, it is crucial to develop efficient and reliable methods for identifying the source of texts. Previous approaches have demonstrated exceptional performance in detecting texts fully generated by LLMs. However, these methods struggle when confronting more advanced LLM output or text with adversarial multi-task machine revision, especially in the black-box setting, where the generating model is unknown. To address this challenge, grounded in the hypothesis that human writing possesses distinctive stylistic patterns, we propose Human Language Preference Detection (HLPD). HLPD employs a reward-based alignment process, Human Language Preference Optimization (HLPO), to shift the scoring model's token distribution toward human-like writing, making the model more sensitive to human writing, therefore enhancing the identification of machine-revised text. We test HLPD in an adversarial multi-task evaluation framework that leverages a five-dimensional prompt generator and multiple advanced LLMs to create diverse revision scenarios. When detecting texts revised by GPT-series models, HLPD achieves a 15.11% relative improvement in AUROC over ImBD, surpassing Fast-DetectGPT by 45.56%. When evaluated on texts generated by advanced LLMs, HLPD achieves the highest average AUROC, exceeding ImBD by 5.53% and Fast-DetectGPT by 34.14%. Code will be made available at https://github.com/dfq2021/HLPD.

</details>


### [37] [Evaluating LLMs for Anxiety, Depression, and Stress Detection Evaluating Large Language Models for Anxiety, Depression, and Stress Detection: Insights into Prompting Strategies and Synthetic Data](https://arxiv.org/abs/2511.07044)
*Mihael Arcan,David-Paul Niland*

Main category: cs.CL

TL;DR: 该研究比较了LLM与传统机器学习方法在心理健康检测中的表现，发现基于transformer的模型和合成数据生成能有效提升焦虑、抑郁和压力分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 全球超过五分之一成年人受心理健康问题影响，但文本中症状表达的微妙性和多样性使得检测具有挑战性。

Method: 使用DAIC-WOZ临床访谈数据集，对Llama、GPT等LLM以及BERT、XLNet、Distil-RoBERTa等模型进行微调，应用合成数据生成解决类别不平衡问题。

Result: Distil-RoBERTa在GAD-2任务中获得最高F1分数(0.883)，XLNet在PHQ任务中表现最佳(F1达0.891)，零样本合成方法在压力检测中达到F1 0.884和ROC AUC 0.886。

Conclusion: transformer模型和合成数据结合能有效提升自动化心理健康评估，但需要谨慎校准以避免精度损失。

Abstract: Mental health disorders affect over one-fifth of adults globally, yet detecting such conditions from text remains challenging due to the subtle and varied nature of symptom expression. This study evaluates multiple approaches for mental health detection, comparing Large Language Models (LLMs) such as Llama and GPT with classical machine learning and transformer-based architectures including BERT, XLNet, and Distil-RoBERTa. Using the DAIC-WOZ dataset of clinical interviews, we fine-tuned models for anxiety, depression, and stress classification and applied synthetic data generation to mitigate class imbalance. Results show that Distil-RoBERTa achieved the highest F1 score (0.883) for GAD-2, while XLNet outperformed others on PHQ tasks (F1 up to 0.891). For stress detection, a zero-shot synthetic approach (SD+Zero-Shot-Basic) reached an F1 of 0.884 and ROC AUC of 0.886. Findings demonstrate the effectiveness of transformer-based models and highlight the value of synthetic data in improving recall and generalization. However, careful calibration is required to prevent precision loss. Overall, this work emphasizes the potential of combining advanced language models and data augmentation to enhance automated mental health assessment from text.

</details>


### [38] [Categorical Emotions or Appraisals - Which Emotion Model Explains Argument Convincingness Better?](https://arxiv.org/abs/2511.07162)
*Lynn Greschner,Meike Bauer,Sabine Weber,Roman Klinger*

Main category: cs.CL

TL;DR: 本文评估了评价理论在论证情感分析中的适用性，发现评价信息比分类情感信息更能有效预测论证的说服力。


<details>
  <summary>Details</summary>
Motivation: 论证的说服力不仅取决于逻辑结构和论证者信誉，还取决于接收者的情感反应。现有研究主要关注情感的强度和分类，但忽略了情感的主观性特征。

Method: 基于ContArgA语料库的标注，进行零样本提示实验，评估黄金标注和预测的情感及评价对主观说服力标签评估的重要性。

Result: 分类情感信息确实能改善说服力预测，但评价信息带来的改善更为显著。

Conclusion: 这是首次系统比较情感模型在说服力预测中的表现，证明了评价理论的优势，为计算论证的理论和实践应用提供了见解。

Abstract: The convincingness of an argument does not only depend on its structure (logos), the person who makes the argument (ethos), but also on the emotion that it causes in the recipient (pathos). While the overall intensity and categorical values of emotions in arguments have received considerable attention in the research community, we argue that the emotion an argument evokes in a recipient is subjective. It depends on the recipient's goals, standards, prior knowledge, and stance. Appraisal theories lend themselves as a link between the subjective cognitive assessment of events and emotions. They have been used in event-centric emotion analysis, but their suitability for assessing argument convincingness remains unexplored. In this paper, we evaluate whether appraisal theories are suitable for emotion analysis in arguments by considering subjective cognitive evaluations of the importance and impact of an argument on its receiver. Based on the annotations in the recently published ContArgA corpus, we perform zero-shot prompting experiments to evaluate the importance of gold-annotated and predicted emotions and appraisals for the assessment of the subjective convincingness labels. We find that, while categorical emotion information does improve convincingness prediction, the improvement is more pronounced with appraisals. This work presents the first systematic comparison between emotion models for convincingness prediction, demonstrating the advantage of appraisals, providing insights for theoretical and practical applications in computational argumentation.

</details>


### [39] [Who Is the Story About? Protagonist Entity Recognition in News](https://arxiv.org/abs/2511.07296)
*Jorge Gabín,M. Eduardo Ares,Javier Parapar*

Main category: cs.CL

TL;DR: 提出了主角实体识别（PER）任务，用于识别新闻故事中锚定叙事并推动主要发展的组织实体，相比传统NER更关注叙事重要性。


<details>
  <summary>Details</summary>
Motivation: 传统NER将所有实体提及同等对待，无法识别真正驱动叙事的核心组织，限制了理解事件显著性、影响力或叙事焦度的下游任务。

Method: 比较LLMs预测与专家标注的一致性，使用NER引导提示自动标注大规模新闻数据，评估LLMs在有限上下文和无明确候选指导下的主角识别能力。

Result: 建立了标注者间一致性和人-LLM一致性，证明PER是可行且有意义的任务扩展，引导的LLMs能够大规模近似人类对叙事重要性的判断。

Conclusion: PER是面向叙事中心信息提取的有意义扩展，引导的LLMs能够有效识别新闻故事中的主角实体，为大规模分析提供了可行方案。

Abstract: News articles often reference numerous organizations, but traditional Named Entity Recognition (NER) treats all mentions equally, obscuring which entities genuinely drive the narrative. This limits downstream tasks that rely on understanding event salience, influence, or narrative focus. We introduce Protagonist Entity Recognition (PER), a task that identifies the organizations that anchor a news story and shape its main developments. To validate PER, we compare he predictions of Large Language Models (LLMs) against annotations from four expert annotators over a gold corpus, establishing both inter-annotator consistency and human-LLM agreement. Leveraging these findings, we use state-of-the-art LLMs to automatically label large-scale news collections through NER-guided prompting, generating scalable, high-quality supervision. We then evaluate whether other LLMs, given reduced context and without explicit candidate guidance, can still infer the correct protagonists. Our results demonstrate that PER is a feasible and meaningful extension to narrative-centered information extraction, and that guided LLMs can approximate human judgments of narrative importance at scale.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [40] [Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills](https://arxiv.org/abs/2511.05855)
*Jiayu Zhou,Qiwei Wu,Jian Li,Zhe Chen,Xiaogang Xiong,Renjing Xu*

Main category: cs.RO

TL;DR: 提出了一个结合分层语义分解、强化学习、视觉语言模型和知识蒸馏的框架，用于自主执行长时程、接触丰富的操作任务，无需昂贵的人类演示。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量真实世界数据和专家工程，存在成本和可扩展性挑战。本文旨在克服这些限制，实现无需人类演示的长时程操作策略学习。

Method: 将复杂任务分解为原子技能，在模拟环境中用RL训练每个原始技能的策略，并加入明确的力约束防止物体损坏。使用VLM进行高层任务分解和技能规划，生成多样化专家演示，通过视觉-触觉扩散策略蒸馏为统一策略。

Result: 通过全面消融研究确定了最优演示生成流程，系统比较了技能蒸馏的模仿学习算法。仿真实验和物理部署验证了该方法能实现长时程操作策略学习，且VLM引导的原子技能框架支持多样化任务的可扩展泛化。

Conclusion: 该框架成功实现了无需人类演示的长时程操作策略学习，VLM引导的原子技能分解为多样化任务提供了可扩展的泛化能力。

Abstract: Autonomous execution of long-horizon, contact-rich manipulation tasks traditionally requires extensive real-world data and expert engineering, posing significant cost and scalability challenges. This paper proposes a novel framework integrating hierarchical semantic decomposition, reinforcement learning (RL), visual language models (VLMs), and knowledge distillation to overcome these limitations. Complex tasks are decomposed into atomic skills, with RL-trained policies for each primitive exclusively in simulation. Crucially, our RL formulation incorporates explicit force constraints to prevent object damage during delicate interactions. VLMs perform high-level task decomposition and skill planning, generating diverse expert demonstrations. These are distilled into a unified policy via Visual-Tactile Diffusion Policy for end-to-end execution. We conduct comprehensive ablation studies exploring different VLM-based task planners to identify optimal demonstration generation pipelines, and systematically compare imitation learning algorithms for skill distillation. Extensive simulation experiments and physical deployment validate that our approach achieves policy learning for long-horizon manipulation without costly human demonstrations, while the VLM-guided atomic skill framework enables scalable generalization to diverse tasks.

</details>


### [41] [ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval](https://arxiv.org/abs/2511.06202)
*Shahram Najam Syed,Yatharth Ahuja,Arthur Jakobsson,Jeff Ichnowski*

Main category: cs.RO

TL;DR: ExpReS-VLA通过经验回放和检索机制，在防止灾难性遗忘的同时，专门化预训练的视觉-语言-动作模型，显著提升在特定任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在零样本泛化方面表现优异，但在适应新部署环境时效率不高。在实际应用中，在有限任务集上保持稳定高性能比广泛泛化更重要。

Method: 存储冻结视觉骨干网络的紧凑特征表示而非原始图像-动作对，减少97%内存使用；通过余弦相似度检索相关经验指导适应；优先回放成功轨迹；引入阈值混合对比损失，从成功和失败尝试中学习。

Result: 在LIBERO仿真基准测试中，空间推理任务成功率从82.6%提升至93.1%，长时程任务从61%提升至72.3%；在物理机器人实验中，在5个操作任务上达到98%成功率，而朴素微调方法分别为84.7%和32%。

Conclusion: ExpReS-VLA能够高效适应新环境，仅需31秒和12个演示样本即可完成适应，为真实机器人部署提供了实用解决方案。

Abstract: Vision-Language-Action models such as OpenVLA show impressive zero-shot generalization across robotic manipulation tasks but often fail to adapt efficiently to new deployment environments. In many real-world applications, consistent high performance on a limited set of tasks is more important than broad generalization. We propose ExpReS-VLA, a method for specializing pre-trained VLA models through experience replay and retrieval while preventing catastrophic forgetting. ExpReS-VLA stores compact feature representations from the frozen vision backbone instead of raw image-action pairs, reducing memory usage by approximately 97 percent. During deployment, relevant past experiences are retrieved using cosine similarity and used to guide adaptation, while prioritized experience replay emphasizes successful trajectories. We also introduce Thresholded Hybrid Contrastive Loss, which enables learning from both successful and failed attempts. On the LIBERO simulation benchmark, ExpReS-VLA improves success rates from 82.6 to 93.1 percent on spatial reasoning tasks and from 61 to 72.3 percent on long-horizon tasks. On physical robot experiments with five manipulation tasks, it reaches 98 percent success on both seen and unseen settings, compared to 84.7 and 32 percent for naive fine-tuning. Adaptation takes 31 seconds using 12 demonstrations on a single RTX 5090 GPU, making the approach practical for real robot deployment.

</details>


### [42] [Robust Differentiable Collision Detection for General Objects](https://arxiv.org/abs/2511.06267)
*Jiayi Chen,Wei Zhao,Liangwang Ruan,Baoquan Chen,He Wang*

Main category: cs.RO

TL;DR: 提出了一种鲁棒高效的微分碰撞检测框架，支持凸面和凹面物体，通过距离导向的随机平滑、自适应采样和等效梯度传输实现稳健的梯度计算。


<details>
  <summary>Details</summary>
Motivation: 传统碰撞检测算法如GJK+EPA不可微分，阻碍了梯度流和基于梯度的优化。现有微分方法仅限于凸面物体且对复杂几何缺乏鲁棒性。

Method: 采用距离导向的一阶随机平滑、自适应采样和等效梯度传输技术，构建支持凸面和凹面物体的微分碰撞检测框架。

Result: 在DexGraspNet和Objaverse的复杂网格上实验显示，相比现有基线有显著改进，并成功应用于灵巧抓取合成以提升抓取质量。

Conclusion: 提出的微分碰撞检测框架在复杂几何场景下表现出优越性能，为接触丰富的机器人任务提供了有效的梯度优化支持。

Abstract: Collision detection is a core component of robotics applications such as simulation, control, and planning. Traditional algorithms like GJK+EPA compute witness points (i.e., the closest or deepest-penetration pairs between two objects) but are inherently non-differentiable, preventing gradient flow and limiting gradient-based optimization in contact-rich tasks such as grasping and manipulation. Recent work introduced efficient first-order randomized smoothing to make witness points differentiable; however, their direction-based formulation is restricted to convex objects and lacks robustness for complex geometries. In this work, we propose a robust and efficient differentiable collision detection framework that supports both convex and concave objects across diverse scales and configurations. Our method introduces distance-based first-order randomized smoothing, adaptive sampling, and equivalent gradient transport for robust and informative gradient computation. Experiments on complex meshes from DexGraspNet and Objaverse show significant improvements over existing baselines. Finally, we demonstrate a direct application of our method for dexterous grasp synthesis to refine the grasp quality. The code is available at https://github.com/JYChen18/DiffCollision.

</details>


### [43] [External Photoreflective Tactile Sensing Based on Surface Deformation Measurement](https://arxiv.org/abs/2511.06311)
*Seiichi Yamamoto,Hiroki Ishizuka,Takumi Kawasetsu,Koh Hosoda,Takayuki Kameoka,Kango Yanagida,Takato Horii,Sei Ikeda,Osamu Oshiro*

Main category: cs.RO

TL;DR: 提出一种基于软机器人机械柔顺性的触觉感知方法，使用外部可附加的光反射模块读取硅胶皮肤表面变形来估计接触力，无需嵌入触觉传感器。


<details>
  <summary>Details</summary>
Motivation: 将传感器置于接触界面之外可降低损坏风险、保持柔软性，并简化制造和维护。相比液体填充或线缆嵌入的触觉皮肤，该模块化附加架构增强了耐用性、减少了布线复杂性。

Method: 通过光学传感元件和柔顺皮肤的表征，设计原型触觉传感器。利用外部光学模块读取皮肤应变模式来感知接触力。

Result: 压缩实验验证了该方法，显示出与理论一致的单调力输出关系、低滞后性、高重复性以及对压痕速度的小响应。在软机器人抓手上的集成演示中，模块能可靠检测抓握事件。

Conclusion: 利用表面柔顺性与外部光学模块为软机器人提供力感知提供了一条实用且稳健的途径，同时保持了结构灵活性和可制造性，为机器人应用和安全人机协作铺平了道路。

Abstract: We present a tactile sensing method enabled by the mechanical compliance of soft robots; an externally attachable photoreflective module reads surface deformation of silicone skin to estimate contact force without embedding tactile transducers. Locating the sensor off the contact interface reduces damage risk, preserves softness, and simplifies fabrication and maintenance. We first characterize the optical sensing element and the compliant skin, thendetermine the design of a prototype tactile sensor. Compression experiments validate the approach, exhibiting a monotonic force output relationship consistent with theory, low hysteresis, high repeatability over repeated cycles, and small response indentation speeds. We further demonstrate integration on a soft robotic gripper, where the module reliably detects grasp events. Compared with liquid filled or wireembedded tactile skins, the proposed modular add on architecture enhances durability, reduces wiring complexity, and supports straightforward deployment across diverse robot geometries. Because the sensing principle reads skin strain patterns, it also suggests extensions to other somatosensory cues such as joint angle or actuator state estimation from surface deformation. Overall, leveraging surface compliance with an external optical module provides a practical and robust route to equip soft robots with force perception while preserving structural flexibility and manufacturability, paving the way for robotic applications and safe human robot collaboration.

</details>


### [44] [Unified Humanoid Fall-Safety Policy from a Few Demonstrations](https://arxiv.org/abs/2511.07407)
*Zhengjie Xu,Ye Li,Kwan-yee Lin,Stella X. Yu*

Main category: cs.RO

TL;DR: 提出了一种统一策略，将防跌倒、冲击缓解和快速恢复整合到一个策略中，通过融合稀疏人类演示、强化学习和自适应扩散记忆来实现


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人跌倒时的综合安全问题，超越单纯保持平衡，使整个跌倒-恢复过程安全自主

Method: 融合稀疏人类演示与强化学习，结合自适应扩散记忆学习安全反应，训练统一策略

Result: 在仿真和Unitree G1机器人上验证，实现稳健的仿真到现实迁移，降低冲击力，跨多样干扰实现快速恢复

Conclusion: 该方法指向在真实环境中实现更安全、更具韧性的人形机器人

Abstract: Falling is an inherent risk of humanoid mobility. Maintaining stability is thus a primary safety focus in robot control and learning, yet no existing approach fully averts loss of balance. When instability does occur, prior work addresses only isolated aspects of falling: avoiding falls, choreographing a controlled descent, or standing up afterward. Consequently, humanoid robots lack integrated strategies for impact mitigation and prompt recovery when real falls defy these scripts. We aim to go beyond keeping balance to make the entire fall-and-recovery process safe and autonomous: prevent falls when possible, reduce impact when unavoidable, and stand up when fallen. By fusing sparse human demonstrations with reinforcement learning and an adaptive diffusion-based memory of safe reactions, we learn adaptive whole-body behaviors that unify fall prevention, impact mitigation, and rapid recovery in one policy. Experiments in simulation and on a Unitree G1 demonstrate robust sim-to-real transfer, lower impact forces, and consistently fast recovery across diverse disturbances, pointing towards safer, more resilient humanoids in real environments. Videos are available at https://firm2025.github.io/.

</details>
