<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Optical Flow-Guided 6DoF Object Pose Tracking with an Event Camera](https://arxiv.org/abs/2512.21053)
*Zibin Liu,Banglei Guan,Yang Shang,Shunkun Liang,Zhenbao Yu,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于事件相机的光流引导6自由度物体姿态跟踪方法，通过2D-3D混合特征提取和光流关联优化，在精度和鲁棒性上超越了现有事件相机方法。


<details>
  <summary>Details</summary>
Motivation: 传统相机在物体姿态跟踪中面临运动模糊、传感器噪声、部分遮挡和光照变化等挑战。事件相机具有高动态范围和低延迟的优势，有潜力解决这些问题。

Method: 1. 采用2D-3D混合特征提取策略，从事件和物体模型中检测角点和边缘特征；2. 通过在时空窗口中最大化事件关联概率来搜索角点的光流；3. 利用光流引导建立角点和边缘之间的关联；4. 通过最小化角点和边缘之间的距离，迭代优化6自由度物体姿态。

Result: 在模拟和真实事件数据上的实验结果表明，该方法在精度和鲁棒性方面优于现有的基于事件相机的最先进方法。

Conclusion: 提出的光流引导6自由度物体姿态跟踪方法有效利用了事件相机的优势，能够应对传统相机面临的挑战，在物体姿态跟踪任务中表现出色。

Abstract: Object pose tracking is one of the pivotal technologies in multimedia, attracting ever-growing attention in recent years. Existing methods employing traditional cameras encounter numerous challenges such as motion blur, sensor noise, partial occlusion, and changing lighting conditions. The emerging bio-inspired sensors, particularly event cameras, possess advantages such as high dynamic range and low latency, which hold the potential to address the aforementioned challenges. In this work, we present an optical flow-guided 6DoF object pose tracking method with an event camera. A 2D-3D hybrid feature extraction strategy is firstly utilized to detect corners and edges from events and object models, which characterizes object motion precisely. Then, we search for the optical flow of corners by maximizing the event-associated probability within a spatio-temporal window, and establish the correlation between corners and edges guided by optical flow. Furthermore, by minimizing the distances between corners and edges, the 6DoF object pose is iteratively optimized to achieve continuous pose tracking. Experimental results of both simulated and real events demonstrate that our methods outperform event-based state-of-the-art methods in terms of both accuracy and robustness.

</details>


### [2] [Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval](https://arxiv.org/abs/2512.21221)
*Dao Sy Duy Minh,Huynh Trung Kiet,Nguyen Lam Phu Quy,Phu-Hoa Pham,Tran Chi Nguyen*

Main category: cs.CV

TL;DR: 提出基于事件实体提取的轻量级两阶段图像检索方法，结合BM25实体过滤和BEiT-3深度语义重排序，在OpenEvents v1基准上取得0.559的平均精度


<details>
  <summary>Details</summary>
Motivation: 现实世界图像文本检索面临模糊查询、语境依赖、语言变异性和可扩展性等挑战，需要更有效的解决方案来处理复杂场景

Method: 两阶段检索流水线：第一阶段使用基于事件的实体提取和BM25进行高效候选过滤；第二阶段应用BEiT-3模型进行深度多模态语义建模和结果重排序

Result: 在OpenEvents v1基准测试中达到0.559的平均精度，显著优于现有基线方法

Conclusion: 事件引导的过滤与长文本视觉语言建模相结合，能够在复杂现实场景中实现准确高效的图像检索

Abstract: Retrieving images from natural language descriptions is a core task at the intersection of computer vision and natural language processing, with wide-ranging applications in search engines, media archiving, and digital content management. However, real-world image-text retrieval remains challenging due to vague or context-dependent queries, linguistic variability, and the need for scalable solutions. In this work, we propose a lightweight two-stage retrieval pipeline that leverages event-centric entity extraction to incorporate temporal and contextual signals from real-world captions. The first stage performs efficient candidate filtering using BM25 based on salient entities, while the second stage applies BEiT-3 models to capture deep multimodal semantics and rerank the results. Evaluated on the OpenEvents v1 benchmark, our method achieves a mean average precision of 0.559, substantially outperforming prior baselines. These results highlight the effectiveness of combining event-guided filtering with long-text vision-language modeling for accurate and efficient retrieval in complex, real-world scenarios. Our code is available at https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval

</details>


### [3] [Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential](https://arxiv.org/abs/2512.21284)
*Shihao Zou,Jingjing Li,Wei Ji,Jincai Huang,Kai Wang,Guo Dan,Weixin Si,Yi Pan*

Main category: cs.CV

TL;DR: SpikeSurgSeg：首个基于脉冲神经网络的视频Transformer框架，用于手术场景分割，在非GPU平台上实现实时性能，相比传统ANN模型减少8倍延迟，相比基础模型加速20倍以上。


<details>
  <summary>Details</summary>
Motivation: 当前手术系统依赖智能场景理解来增强术中安全性，但现有深度学习模型（特别是大型基础模型）计算需求大、功耗高，难以在资源受限的手术环境中实时部署。脉冲神经网络（SNN）作为高效计算范式具有潜力，但面临标注数据稀缺和手术视频表示稀疏的挑战。

Method: 提出SpikeSurgSeg框架：1）引入手术场景掩码自编码预训练策略，通过分层管状掩码实现鲁棒的时空表示学习；2）采用轻量级脉冲驱动分割头，在保持SNN低延迟特性的同时产生时间一致的预测。

Result: 在EndoVis18和内部SurgBleed数据集上的实验表明，SpikeSurgSeg达到与最先进ANN模型相当的mIoU，同时推理延迟减少至少8倍，相比大多数基础模型基线加速超过20倍。

Conclusion: SpikeSurgSeg展示了脉冲神经网络在时间关键型手术场景分割中的潜力，能够在资源受限的非GPU平台上实现高效实时性能，为手术智能系统提供了可行的部署方案。

Abstract: Modern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning models, particularly large-scale foundation models, achieve remarkable segmentation accuracy, their substantial computational demands and power consumption hinder real-time deployment in resource-constrained surgical environments. To address this limitation, we explore the emerging SNN as a promising paradigm for highly efficient surgical intelligence. However, their performance is still constrained by the scarcity of labeled surgical data and the inherently sparse nature of surgical video representations. To this end, we propose \textit{SpikeSurgSeg}, the first spike-driven video Transformer framework tailored for surgical scene segmentation with real-time potential on non-GPU platforms. To address the limited availability of surgical annotations, we introduce a surgical-scene masked autoencoding pretraining strategy for SNNs that enables robust spatiotemporal representation learning via layer-wise tube masking. Building on this pretrained backbone, we further adopt a lightweight spike-driven segmentation head that produces temporally consistent predictions while preserving the low-latency characteristics of SNNs. Extensive experiments on EndoVis18 and our in-house SurgBleed dataset demonstrate that SpikeSurgSeg achieves mIoU comparable to SOTA ANN-based models while reducing inference latency by at least $8\times$. Notably, it delivers over $20\times$ acceleration relative to most foundation-model baselines, underscoring its potential for time-critical surgical scene segmentation.

</details>


### [4] [Streaming Video Instruction Tuning](https://arxiv.org/abs/2512.21334)
*Jiaer Xia,Peixian Chen,Mengdan Zhang,Xing Sun,Kaiyang Zhou*

Main category: cs.CV

TL;DR: Streamo是一个实时流式视频LLM，作为通用交互助手，能执行实时叙述、动作理解、事件描述、时间事件定位和时间敏感问答等多种流式视频任务。


<details>
  <summary>Details</summary>
Motivation: 现有在线视频模型主要专注于问答或字幕生成等狭窄任务，缺乏能够处理多种流式视频任务的通用交互助手。需要开发一个能够统一处理异质流式任务的模型，弥合离线视频感知模型与实时多模态助手之间的差距。

Method: 构建了Streamo-Instruct-465K大规模指令跟随数据集，专门针对流式视频理解，涵盖多样化时间上下文和多任务监督。通过简化的端到端管道在指令跟随数据集上进行训练，实现统一训练。

Result: Streamo展现出强大的时间推理能力、响应式交互能力以及在各种流式基准测试中的广泛泛化能力。实验表明该模型在多个流式视频任务上表现优异。

Conclusion: Streamo弥合了离线视频感知模型与实时多模态助手之间的差距，朝着统一、智能的连续视频流理解迈出了一步。

Abstract: We present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams](https://arxiv.org/abs/2512.20631)
*Aayam Bansal,Ishaan Gangwani*

Main category: cs.LG

TL;DR: 提出零训练时间漂移分析方法，验证Transformer情感模型在真实社交媒体数据上的不稳定性，准确率下降可达23.4%，并引入四个新漂移指标


<details>
  <summary>Details</summary>
Motivation: Transformer情感模型在真实世界事件期间可能存在性能漂移，需要无需重新训练的方法来监控模型稳定性，特别是在动态内容时期

Method: 使用零训练方法，系统评估三种Transformer架构，在12,279个真实社交媒体帖子上进行统计验证，引入四个新的漂移指标，并与嵌入基线比较

Result: 发现模型显著不稳定性，事件驱动期间准确率下降达23.4%，最大置信度下降13.0%，新指标优于嵌入基线且计算高效，统计验证显示检测能力超过行业监控阈值

Conclusion: 零训练方法可直接部署于实时情感监控系统，为Transformer模型在动态内容期间的行为提供新见解，具有实际应用价值

Abstract: We present a comprehensive zero-training temporal drift analysis of transformer-based sentiment models validated on authentic social media data from major real-world events. Through systematic evaluation across three transformer architectures and rigorous statistical validation on 12,279 authentic social media posts, we demonstrate significant model instability with accuracy drops reaching 23.4% during event-driven periods. Our analysis reveals maximum confidence drops of 13.0% (Bootstrap 95% CI: [9.1%, 16.5%]) with strong correlation to actual performance degradation. We introduce four novel drift metrics that outperform embedding-based baselines while maintaining computational efficiency suitable for production deployment. Statistical validation across multiple events confirms robust detection capabilities with practical significance exceeding industry monitoring thresholds. This zero-training methodology enables immediate deployment for real-time sentiment monitoring systems and provides new insights into transformer model behavior during dynamic content periods.

</details>


### [6] [TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform](https://arxiv.org/abs/2512.20761)
*Marcel Meyer,Sascha Kaltenpoth,Kevin Zalipski,Henrik Albers,Oliver Müller*

Main category: cs.LG

TL;DR: TS-Arena平台解决时间序列基础模型评估中的信息泄露危机，通过在实时数据流上实施预注册机制，确保评估目标在推理时物理上不存在，实现严格的全局时间分割。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型存在评估危机，主要源于训练集和测试集重叠导致的信息泄露，以及全局模式向测试数据的非法转移。虽然学习共享时间动态是这些模型的主要优势，但在历史档案上的评估往往允许利用观察到的全局冲击，这违反了有效基准测试所需的独立性。

Method: 引入TS-Arena平台，将真正未知的未来作为明确的测试环境。通过在实时数据流上实施预注册机制，确保评估目标在推理时物理上不存在，从而强制执行严格的全局时间分割。该方法建立了一个移动的时间边界，防止历史污染。

Result: TS-Arena最初在能源领域应用，为基础模型在现实约束下的比较提供了可持续的基础设施。平台原型已在Hugging Face上提供。

Conclusion: TS-Arena通过恢复预测的操作完整性，防止历史污染，为模型泛化能力提供真实评估，解决了时间序列基础模型的评估危机。

Abstract: While Time Series Foundation Models (TSFMs) offer transformative capabilities for forecasting, they simultaneously risk triggering a fundamental evaluation crisis. This crisis is driven by information leakage due to overlapping training and test sets across different models, as well as the illegitimate transfer of global patterns to test data. While the ability to learn shared temporal dynamics represents a primary strength of these models, their evaluation on historical archives often permits the exploitation of observed global shocks, which violates the independence required for valid benchmarking. We introduce TS-Arena, a platform that restores the operational integrity of forecasting by treating the genuinely unknown future as the definitive test environment. By implementing a pre-registration mechanism on live data streams, the platform ensures that evaluation targets remain physically non-existent during inference, thereby enforcing a strict global temporal split. This methodology establishes a moving temporal frontier that prevents historical contamination and provides an authentic assessment of model generalization. Initially applied within the energy sector, TS-Arena provides a sustainable infrastructure for comparing foundation models under real-world constraints. A prototype of the platform is available at https://huggingface.co/spaces/DAG-UPB/TS-Arena.

</details>


### [7] [STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting](https://arxiv.org/abs/2512.21118)
*Shi Quan Foo,Chi-Ho Wong,Zhihan Gao,Dit-Yan Yeung,Ka-Hing Wong,Wai-Kin Wong*

Main category: cs.LG

TL;DR: STLDM是一种基于扩散模型的降水临近预报方法，通过变分自编码器和条件网络学习潜在表示，将任务分解为确定性预报和增强两个阶段，在多个雷达数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 降水临近预报对预防极端天气灾害至关重要，但现有方法面临挑战：确定性模型预测模糊，生成模型精度不足。需要一种既能保持准确性又能生成清晰预测的方法。

Method: STLDM采用扩散模型架构，结合变分自编码器和条件网络端到端学习潜在表示。将任务分解为两个阶段：1）条件网络处理确定性预报阶段；2）潜在扩散模型执行增强阶段。

Result: 在多个雷达数据集上的实验结果表明，STLDM相比现有最先进方法取得了更优的性能，同时提高了推理效率。

Conclusion: STLDM通过将降水临近预报分解为确定性预报和增强两个阶段，有效解决了现有方法在准确性和清晰度方面的局限性，为降水临近预报提供了简单而有效的解决方案。

Abstract: Precipitation nowcasting is a critical spatio-temporal prediction task for society to prevent severe damage owing to extreme weather events. Despite the advances in this field, the complex and stochastic nature of this task still poses challenges to existing approaches. Specifically, deterministic models tend to produce blurry predictions while generative models often struggle with poor accuracy. In this paper, we present a simple yet effective model architecture termed STLDM, a diffusion-based model that learns the latent representation from end to end alongside both the Variational Autoencoder and the conditioning network. STLDM decomposes this task into two stages: a deterministic forecasting stage handled by the conditioning network, and an enhancement stage performed by the latent diffusion model. Experimental results on multiple radar datasets demonstrate that STLDM achieves superior performance compared to the state of the art, while also improving inference efficiency. The code is available in https://github.com/sqfoo/stldm_official.

</details>


### [8] [BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft](https://arxiv.org/abs/2512.21165)
*Qizhi Wang*

Main category: cs.LG

TL;DR: BALLAST使用上下文多臂赌博机替代Raft中静态随机超时机制，通过安全探索在长尾延迟和分区恢复等挑战性网络环境下显著提升可用性。


<details>
  <summary>Details</summary>
Motivation: Raft协议中的随机选举超时机制在长尾延迟、抖动和分区恢复等场景下变得脆弱，重复的分裂投票会显著增加不可用时间。

Method: BALLAST采用轻量级在线自适应机制，使用线性上下文多臂赌博机（LinUCB变体）从离散的超时选项中选择，并通过安全探索在系统不稳定期间限制风险。

Result: 在包含长尾延迟、丢包、相关突发、节点异构性和分区/恢复动荡的可重现离散事件模拟中，BALLAST在挑战性WAN环境下显著减少了恢复时间和不可写时间，同时在稳定LAN/WAN设置中保持竞争力。

Conclusion: BALLAST通过上下文多臂赌博机有效解决了Raft协议在复杂网络环境下的选举超时优化问题，显著提升了系统的可用性和恢复性能。

Abstract: Randomized election timeouts are a simple and effective liveness heuristic for Raft, but they become brittle under long-tail latency, jitter, and partition recovery, where repeated split votes can inflate unavailability. This paper presents BALLAST, a lightweight online adaptation mechanism that replaces static timeout heuristics with contextual bandits. BALLAST selects from a discrete set of timeout "arms" using efficient linear contextual bandits (LinUCB variants), and augments learning with safe exploration to cap risk during unstable periods. We evaluate BALLAST on a reproducible discrete-event simulation with long-tail delay, loss, correlated bursts, node heterogeneity, and partition/recovery turbulence. Across challenging WAN regimes, BALLAST substantially reduces recovery time and unwritable time compared to standard randomized timeouts and common heuristics, while remaining competitive on stable LAN/WAN settings.

</details>


### [9] [Learning to Solve PDEs on Neural Shape Representations](https://arxiv.org/abs/2512.21311)
*Lilian Welschinger,Yilin Liu,Zican Wang,Niloy Mitra*

Main category: cs.LG

TL;DR: 提出一种直接在神经表面表示上求解表面偏微分方程（PDE）的网格无关方法，无需显式网格提取或逐实例优化


<details>
  <summary>Details</summary>
Motivation: 现代3D资产越来越多地以神经表示形式存在，但现有的PDE求解器主要针对多边形/三角形网格，导致在神经域中直接求解表面PDE缺乏合适方法，阻碍了端到端工作流程

Method: 提出一种网格无关的公式，学习一个基于神经（局部）形状属性的局部更新算子，该算子自然地与流行的神经表面表示集成，只需在单个代表性形状上训练一次，就能泛化到各种形状和拓扑变化

Result: 在解析基准测试（球体上的热方程和泊松求解）和不同表示的真实神经资产上，该方法略优于CPM，同时与FEM保持合理接近，并提供了第一个在神经和经典表面表示上求解表面PDE的端到端管道

Conclusion: 该方法实现了直接在神经表示上求解表面PDE，无需显式网格化或逐实例优化，同时保持可微性，为神经表面分析提供了新的可能性

Abstract: Solving partial differential equations (PDEs) on shapes underpins many shape analysis and engineering tasks; yet, prevailing PDE solvers operate on polygonal/triangle meshes while modern 3D assets increasingly live as neural representations. This mismatch leaves no suitable method to solve surface PDEs directly within the neural domain, forcing explicit mesh extraction or per-instance residual training, preventing end-to-end workflows. We present a novel, mesh-free formulation that learns a local update operator conditioned on neural (local) shape attributes, enabling surface PDEs to be solved directly where the (neural) data lives. The operator integrates naturally with prevalent neural surface representations, is trained once on a single representative shape, and generalizes across shape and topology variations, enabling accurate, fast inference without explicit meshing or per-instance optimization while preserving differentiability. Across analytic benchmarks (heat equation and Poisson solve on sphere) and real neural assets across different representations, our method slightly outperforms CPM while remaining reasonably close to FEM, and, to our knowledge, delivers the first end-to-end pipeline that solves surface PDEs on both neural and classical surface representations. Code will be released on acceptance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines](https://arxiv.org/abs/2512.20985)
*Salman Jan,Hassan Ali Razzaqi,Ali Akarma,Mohammad Riyaz Belgaum*

Main category: cs.AI

TL;DR: 提出结合LangChain多智能体系统与许可区块链的架构，确保自主AI系统的监控、策略执行和不可篡改审计


<details>
  <summary>Details</summary>
Motivation: 自主AI系统在医疗、智慧城市等领域应用增长，但存在信任、监督和信息完整性问题，需要确保其决策过程的可审计性和安全性

Method: 采用LangChain多智能体系统与Hyperledger Fabric许可区块链结合，将感知-概念化-行动周期与区块链治理层关联，验证输入、评估行动建议并记录执行结果

Result: 区块链安全验证能有效防止未授权操作，提供完整决策过程追溯性，并在合理范围内保持操作延迟，在智能库存管理、交通信号控制和医疗监控实验中验证

Conclusion: 该框架为高影响力自主AI应用提供了通用系统，既保持自主性又确保责任性，实现可信的自主决策

Abstract: The application of agentic AI systems in autonomous decision-making is growing in the areas of healthcare, smart cities, digital forensics, and supply chain management. Even though these systems are flexible and offer real-time reasoning, they also raise concerns of trust and oversight, and integrity of the information and activities upon which they are founded. The paper suggests a single architecture model comprising of LangChain-based multi-agent system with a permissioned blockchain to guarantee constant monitoring, policy enforcement, and immutable auditability of agentic action. The framework relates the perception conceptualization-action cycle to a blockchain layer of governance that verifies the inputs, evaluates recommended actions, and documents the outcomes of the execution. A Hyperledger Fabric-based system, action executors MCP-integrated, and LangChain agent are introduced and experiments of smart inventory management, traffic-signal control, and healthcare monitoring are done. The results suggest that blockchain-security verification is efficient in preventing unauthorized practices, offers traceability throughout the whole decision-making process, and maintains operational latency within reasonable ranges. The suggested framework provides a universal system of implementing high-impact agentic AI applications that are autonomous yet responsible.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks](https://arxiv.org/abs/2512.21329)
*Xinhe Wang,Jin Huang,Xingjian Zhang,Tianhao Wang,Jiaqi W. Ma*

Main category: cs.CL

TL;DR: 论文挑战了当前对AI推理能力评估的普遍解释，认为ARC等基准测试的性能差距主要源于视觉感知限制而非推理能力缺陷，并通过两阶段实验验证了这一假设。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域广泛使用ARC等推理基准来评估人工智能进展，通常将其解释为"流体"推理能力的测试。尽管这些任务对人类来说看似简单，但对前沿视觉语言模型仍具挑战性，这一差距通常被归因于机器推理能力的不足。作者质疑这种解释，认为差距主要来自视觉感知限制而非归纳推理缺陷。

Method: 引入两阶段实验流程：感知阶段将每个图像独立转换为自然语言描述；推理阶段使用这些描述进行规则归纳和应用。这种设计防止跨图像归纳信号的泄漏，将推理与感知瓶颈隔离。在Mini-ARC、ACRE和Bongard-LOGO三个ARC风格数据集上，比较两阶段流程与标准端到端单阶段评估。

Result: 研究表明感知能力是观察到的性能差距的主导因素。对VLM输出推理轨迹的手动检查进一步显示，约80%的模型失败源于感知错误。这些结果表明ARC风格基准混淆了感知和推理挑战，观察到的性能差距可能夸大了机器推理能力的缺陷。

Conclusion: ARC风格基准测试将感知和推理挑战混为一谈，观察到的性能差距可能高估了机器推理能力的不足。研究强调在评估机器智能进展时需要将感知与推理分离的评估协议。

Abstract: Reasoning benchmarks such as the Abstraction and Reasoning Corpus (ARC) and ARC-AGI are widely used to assess progress in artificial intelligence and are often interpreted as probes of core, so-called ``fluid'' reasoning abilities. Despite their apparent simplicity for humans, these tasks remain challenging for frontier vision-language models (VLMs), a gap commonly attributed to deficiencies in machine reasoning. We challenge this interpretation and hypothesize that the gap arises primarily from limitations in visual perception rather than from shortcomings in inductive reasoning.
  To verify this hypothesis, we introduce a two-stage experimental pipeline that explicitly separates perception and reasoning. In the perception stage, each image is independently converted into a natural-language description, while in the reasoning stage a model induces and applies rules using these descriptions. This design prevents leakage of cross-image inductive signals and isolates reasoning from perception bottlenecks. Across three ARC-style datasets, Mini-ARC, ACRE, and Bongard-LOGO, we show that the perception capability is the dominant factor underlying the observed performance gap by comparing the two-stage pipeline with against standard end-to-end one-stage evaluation. Manual inspection of reasoning traces in the VLM outputs further reveals that approximately 80 percent of model failures stem from perception errors. Together, these results demonstrate that ARC-style benchmarks conflate perceptual and reasoning challenges and that observed performance gaps may overstate deficiencies in machine reasoning. Our findings underscore the need for evaluation protocols that disentangle perception from reasoning when assessing progress in machine intelligence.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [12] [Tracing Energy Flow: Learning Tactile-based Grasping Force Control to Prevent Slippage in Dynamic Object Interaction](https://arxiv.org/abs/2512.21043)
*Cheng-Yu Kuo,Hirofumi Shin,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出一种基于物理能量抽象的方法，让机器人手通过触觉快速学习抓握力控制，无需外部传感或物体先验知识


<details>
  <summary>Details</summary>
Motivation: 在动态物体交互中调节抓握力以防止滑动是机器人操作的基本挑战，尤其是在多滚动接触、物体属性未知、外部传感不可靠的情况下。人类仅凭触觉就能快速调节抓握力，受此启发，希望让机器人手也能快速探索物体并学习触觉驱动的抓握力控制

Method: 提出物理信息能量抽象，将物体建模为虚拟能量容器；手指施加功率与物体保留能量之间的不一致性提供了物理基础的滑动感知稳定性信号；基于此抽象，采用基于模型的学习和规划，从触觉传感中高效建模能量动态，并进行实时抓握力优化

Result: 在仿真和硬件实验中，该方法能在几分钟内从零开始学习抓握力控制，有效减少滑动，延长不同运动-物体组合下的抓握持续时间，且不依赖外部传感或物体先验知识

Conclusion: 提出的基于物理能量抽象的方法使机器人能够仅凭触觉快速学习抓握力控制，为在动态、未知环境中的稳健操作提供了有前景的解决方案

Abstract: Regulating grasping force to reduce slippage during dynamic object interaction remains a fundamental challenge in robotic manipulation, especially when objects are manipulated by multiple rolling contacts, have unknown properties (such as mass or surface conditions), and when external sensing is unreliable. In contrast, humans can quickly regulate grasping force by touch, even without visual cues. Inspired by this ability, we aim to enable robotic hands to rapidly explore objects and learn tactile-driven grasping force control under motion and limited sensing. We propose a physics-informed energy abstraction that models the object as a virtual energy container. The inconsistency between the fingers' applied power and the object's retained energy provides a physically grounded signal for inferring slip-aware stability. Building on this abstraction, we employ model-based learning and planning to efficiently model energy dynamics from tactile sensing and perform real-time grasping force optimization. Experiments in both simulation and hardware demonstrate that our method can learn grasping force control from scratch within minutes, effectively reduce slippage, and extend grasp duration across diverse motion-object pairs, all without relying on external sensing or prior object knowledge.

</details>
