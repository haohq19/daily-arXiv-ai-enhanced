{"id": "2507.22962", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22962", "abs": "https://arxiv.org/abs/2507.22962", "authors": ["Boyuan Zheng", "Victor W. Chu"], "title": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations", "comment": "Pre-print v0.8 2025-07-30", "summary": "Climate extremes present escalating risks to agriculture intensifying the\nneed for reliable multi-hazard early warning systems (EWS). The situation is\nevolving due to climate change and hence such systems should have the\nintelligent to continue to learn from recent climate behaviours. However,\ntraditional single-hazard forecasting methods fall short in capturing complex\ninteractions among concurrent climatic events. To address this deficiency, in\nthis paper, we combine sequential deep learning models and advanced Explainable\nArtificial Intelligence (XAI) techniques to introduce a multi-hazard\nforecasting framework for agriculture. In our experiments, we utilize\nmeteorological data from four prominent agricultural regions in the United\nStates (between 2010 and 2023) to validate the predictive accuracy of our\nframework on multiple severe event types, which are extreme cold, floods,\nfrost, hail, heatwaves, and heavy rainfall, with tailored models for each area.\nThe framework uniquely integrates attention mechanisms with TimeSHAP (a\nrecurrent XAI explainer for time series) to provide comprehensive temporal\nexplanations revealing not only which climatic features are influential but\nprecisely when their impacts occur. Our results demonstrate strong predictive\naccuracy, particularly with the BiLSTM architecture, and highlight the system's\ncapacity to inform nuanced, proactive risk management strategies. This research\nsignificantly advances the explainability and applicability of multi-hazard\nEWS, fostering interdisciplinary trust and effective decision-making process\nfor climate risk management in the agricultural industry.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u53ef\u89e3\u91caAI\u7684\u591a\u707e\u5bb3\u9884\u8b66\u6846\u67b6\uff0c\u7528\u4e8e\u519c\u4e1a\u6c14\u5019\u98ce\u9669\u7ba1\u7406\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u5355\u707e\u5bb3\u9884\u8b66\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u590d\u6742\u6c14\u5019\u4e8b\u4ef6\u4ea4\u4e92\uff0c\u9700\u667a\u80fd\u5b66\u4e60\u8fd1\u671f\u6c14\u5019\u884c\u4e3a\u4ee5\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3002", "method": "\u7ed3\u5408\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982BiLSTM\uff09\u4e0e\u53ef\u89e3\u91caAI\u6280\u672f\uff08TimeSHAP\uff09\uff0c\u6784\u5efa\u591a\u707e\u5bb3\u9884\u6d4b\u6846\u67b6\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u533a\u57df\u5b9a\u5236\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6846\u67b6\u9884\u6d4b\u51c6\u786e\u6027\u9ad8\uff0cBiLSTM\u8868\u73b0\u7a81\u51fa\uff0c\u80fd\u63d0\u4f9b\u8be6\u7ec6\u65f6\u95f4\u89e3\u91ca\uff0c\u652f\u6301\u4e3b\u52a8\u98ce\u9669\u7ba1\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u5347\u4e86\u591a\u707e\u5bb3\u9884\u8b66\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4fc3\u8fdb\u519c\u4e1a\u6c14\u5019\u98ce\u9669\u7ba1\u7406\u7684\u8de8\u5b66\u79d1\u4fe1\u4efb\u4e0e\u51b3\u7b56\u3002"}}
{"id": "2507.23000", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23000", "abs": "https://arxiv.org/abs/2507.23000", "authors": ["Shengao Yi", "Xiaojiang Li", "Wei Tu", "Tianhong Zhao"], "title": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation", "comment": null, "summary": "As extreme heat events intensify due to climate change and urbanization,\ncities face increasing challenges in mitigating outdoor heat stress. While\ntraditional physical models such as SOLWEIG and ENVI-met provide detailed\nassessments of human-perceived heat exposure, their computational demands limit\nscalability for city-wide planning. In this study, we propose GSM-UTCI, a\nmultimodal deep learning framework designed to predict daytime average\nUniversal Thermal Climate Index (UTCI) at 1-meter hyperlocal resolution. The\nmodel fuses surface morphology (nDSM), high-resolution land cover data, and\nhourly meteorological conditions using a feature-wise linear modulation (FiLM)\narchitecture that dynamically conditions spatial features on atmospheric\ncontext. Trained on SOLWEIG-derived UTCI maps, GSM-UTCI achieves near-physical\naccuracy, with an R2 of 0.9151 and a mean absolute error (MAE) of 0.41{\\deg}C,\nwhile reducing inference time from hours to under five minutes for an entire\ncity. To demonstrate its planning relevance, we apply GSM-UTCI to simulate\nsystematic landscape transformation scenarios in Philadelphia, replacing bare\nearth, grass, and impervious surfaces with tree canopy. Results show spatially\nheterogeneous but consistently strong cooling effects, with impervious-to-tree\nconversion producing the highest aggregated benefit (-4.18{\\deg}C average\nchange in UTCI across 270.7 km2). Tract-level bivariate analysis further\nreveals strong alignment between thermal reduction potential and land cover\nproportions. These findings underscore the utility of GSM-UTCI as a scalable,\nfine-grained decision support tool for urban climate adaptation, enabling\nscenario-based evaluation of greening strategies across diverse urban\nenvironments.", "AI": {"tldr": "GSM-UTCI\u662f\u4e00\u79cd\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u9ad8\u5206\u8fa8\u7387UTCI\uff0c\u7ed3\u5408\u5730\u8868\u5f62\u6001\u548c\u6c14\u8c61\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u57ce\u5e02\u6c14\u5019\u9002\u5e94\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u968f\u7740\u6781\u7aef\u9ad8\u6e29\u4e8b\u4ef6\u52a0\u5267\uff0c\u57ce\u5e02\u9700\u8981\u9ad8\u6548\u5de5\u5177\u8bc4\u4f30\u548c\u7f13\u89e3\u70ed\u538b\u529b\uff0c\u4f20\u7edf\u7269\u7406\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5927\u89c4\u6a21\u5e94\u7528\u3002", "method": "\u63d0\u51faGSM-UTCI\u6846\u67b6\uff0c\u878d\u5408\u5730\u8868\u5f62\u6001\u3001\u9ad8\u5206\u8fa8\u7387\u571f\u5730\u8986\u76d6\u6570\u636e\u548c\u6c14\u8c61\u6761\u4ef6\uff0c\u91c7\u7528FiLM\u67b6\u6784\u52a8\u6001\u8c03\u6574\u7a7a\u95f4\u7279\u5f81\u3002", "result": "\u6a21\u578b\u5728R2\u548cMAE\u4e0a\u8868\u73b0\u4f18\u5f02\uff080.9151\u548c0.41\u00b0C\uff09\uff0c\u8ba1\u7b97\u65f6\u95f4\u4ece\u5c0f\u65f6\u7ea7\u964d\u81f3\u5206\u949f\u7ea7\uff0c\u5e94\u7528\u4e8e\u8d39\u57ce\u7eff\u5316\u573a\u666f\u663e\u793a\u663e\u8457\u964d\u6e29\u6548\u679c\u3002", "conclusion": "GSM-UTCI\u4e3a\u57ce\u5e02\u6c14\u5019\u9002\u5e94\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7cbe\u7ec6\u5316\u7684\u51b3\u7b56\u5de5\u5177\uff0c\u652f\u6301\u591a\u6837\u5316\u7eff\u5316\u7b56\u7565\u7684\u8bc4\u4f30\u3002"}}
{"id": "2507.23163", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e76\u5b9a\u4e49\u4e86\u2018\u8bba\u8bc1\u8fde\u8d2f\u6027\u2019\u5c5e\u6027\uff0c\u8bc4\u4f30\u5176\u5728\u4eba\u7c7b\u548cLLM\u9884\u6d4b\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u9884\u6d4b\u53ef\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u7528\u6237\u5b9e\u9a8c\u663e\u793a\u7528\u6237\u901a\u5e38\u4e0d\u9075\u5faa\u8fd9\u4e00\u5c5e\u6027\u3002", "motivation": "\u7814\u7a76\u8bba\u8bc1\u7ed3\u6784\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u2018\u8bba\u8bc1\u8fde\u8d2f\u6027\u2019\u4ee5\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u4eba\u7c7b\u548cLLM\u9884\u6d4b\u5b9e\u9a8c\uff0c\u4ee5\u53ca\u7528\u6237\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u8fde\u8d2f\u6027\u7684\u5f71\u54cd\u3002", "result": "\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u9884\u6d4b\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u7528\u6237\u672a\u666e\u904d\u9075\u5faa\u8fde\u8d2f\u6027\u3002", "conclusion": "\u9700\u5728\u57fa\u4e8e\u8bba\u8bc1\u7684\u9884\u6d4b\u4e2d\u5f15\u5165\u673a\u5236\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u610f\u89c1\uff0c\u4ee5\u63d0\u5347\u7fa4\u4f53\u9884\u6d4b\u8d28\u91cf\u3002"}}
{"id": "2507.23035", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.23035", "abs": "https://arxiv.org/abs/2507.23035", "authors": ["Xueying Wu", "Baijun Zhou", "Zhihui Gao", "Yuzhe Fu", "Qilin Zheng", "Yintao He", "Hai Li"], "title": "KLLM: Fast LLM Inference with K-Means Quantization", "comment": null, "summary": "Large language model (LLM) inference poses significant challenges due to its\nintensive memory and computation demands. Weight and activation quantization\n(WAQ) offers a promising solution by reducing both memory footprint and\narithmetic complexity. However, two key challenges remain in the existing WAQ\ndesigns. (1) Traditional WAQ designs rely on uniform integer-based quantization\nfor hardware efficiency, but this often results in significant accuracy\ndegradation at low precision. K-Means-based quantization, a non-uniform\nquantization technique, achieves higher accuracy by matching the Gaussian-like\ndistributions of weights and activations in LLMs. However, its non-uniform\nnature prevents direct execution on low-precision compute units, requiring\ndequantization and floating-point matrix multiplications (MatMuls) during\ninference. (2) Activation outliers further hinder effective low-precision WAQ.\nOffline thresholding methods for outlier detection can lead to significant\nmodel performance degradation, while existing online detection techniques\nintroduce substantial runtime overhead.\n  To address the aforementioned challenges and fully unleash the potential of\nWAQ with K-Means quantization for LLM inference, in this paper, we propose\nKLLM, a hardware-software co-design framework. KLLM features an index-based\ncomputation scheme for efficient execution of MatMuls and nonlinear operations\non K-Means-quantized data, which avoids most of the dequantization and\nfull-precision computations. Moreover, KLLM incorporates a novel outlier\ndetection engine, Orizuru, that efficiently identifies the top-$k$ largest and\nsmallest elements in the activation data stream during online inference.\n  Extensive experiments show that, on average, KLLM achieves speedups of 9.67x,\n7.03x and energy efficiency improvements of 229.50x, 150.21x compared to the\nA100 GPU and Atom, respectively.", "AI": {"tldr": "KLLM\u662f\u4e00\u4e2a\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7K-Means\u91cf\u5316\u548c\u9ad8\u6548\u7684\u5f02\u5e38\u503c\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9762\u4e34\u5185\u5b58\u548c\u8ba1\u7b97\u7684\u9ad8\u9700\u6c42\u6311\u6218\uff0c\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u5b58\u5728\u51c6\u786e\u7387\u4e0b\u964d\u6216\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faKLLM\u6846\u67b6\uff0c\u7ed3\u5408K-Means\u91cf\u5316\u7684\u7d22\u5f15\u8ba1\u7b97\u65b9\u6848\u548c\u5728\u7ebf\u5f02\u5e38\u503c\u68c0\u6d4b\u5f15\u64ceOrizuru\uff0c\u907f\u514d\u89e3\u91cf\u5316\u548c\u5168\u7cbe\u5ea6\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cKLLM\u5728A100 GPU\u548cAtom\u4e0a\u5206\u522b\u5b9e\u73b09.67x\u548c7.03x\u7684\u52a0\u901f\uff0c\u80fd\u6548\u63d0\u5347229.50x\u548c150.21x\u3002", "conclusion": "KLLM\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\u4e86\u91cf\u5316\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548c\u80fd\u6548\u3002"}}
{"id": "2507.23037", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23037", "abs": "https://arxiv.org/abs/2507.23037", "authors": ["Aur\u00e9lie Leribaux", "Rafael Oyamada", "Johannes De Smedt", "Zahra Dasht Bozorgi", "Artem Polyvyanyy", "Jochen De Weerdt"], "title": "Linking Actor Behavior to Process Performance Over Time", "comment": "Accepted for presentation at the 5th Workshop on Change, Drift, and\n  Dynamics of Organizational Processes (ProDy), BPM 2025", "summary": "Understanding how actor behavior influences process outcomes is a critical\naspect of process mining. Traditional approaches often use aggregate and static\nprocess data, overlooking the temporal and causal dynamics that arise from\nindividual actor behavior. This limits the ability to accurately capture the\ncomplexity of real-world processes, where individual actor behavior and\ninteractions between actors significantly shape performance. In this work, we\naddress this gap by integrating actor behavior analysis with Granger causality\nto identify correlating links in time series data. We apply this approach to\nrealworld event logs, constructing time series for actor interactions, i.e.\ncontinuation, interruption, and handovers, and process outcomes. Using Group\nLasso for lag selection, we identify a small but consistently influential set\nof lags that capture the majority of causal influence, revealing that actor\nbehavior has direct and measurable impacts on process performance, particularly\nthroughput time. These findings demonstrate the potential of actor-centric,\ntime series-based methods for uncovering the temporal dependencies that drive\nprocess outcomes, offering a more nuanced understanding of how individual\nbehaviors impact overall process efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u884c\u4e3a\u5206\u6790\u548cGranger\u56e0\u679c\u6027\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u4e2a\u4f53\u884c\u4e3a\u5bf9\u6d41\u7a0b\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u9759\u6001\u548c\u805a\u5408\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u884c\u4e3a\u7684\u65f6\u95f4\u52a8\u6001\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u73b0\u5b9e\u6d41\u7a0b\u7684\u590d\u6742\u6027\u3002", "method": "\u6574\u5408\u884c\u4e3a\u5206\u6790\u548cGranger\u56e0\u679c\u6027\uff0c\u6784\u5efa\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u4f7f\u7528Group Lasso\u8fdb\u884c\u6ede\u540e\u9009\u62e9\u3002", "result": "\u53d1\u73b0\u884c\u4e3a\u5bf9\u6d41\u7a0b\u6027\u80fd\uff08\u5982\u541e\u5410\u65f6\u95f4\uff09\u6709\u76f4\u63a5\u4e14\u53ef\u6d4b\u91cf\u7684\u5f71\u54cd\u3002", "conclusion": "\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u7684\u884c\u4e3a\u5206\u6790\u65b9\u6cd5\u80fd\u66f4\u7ec6\u81f4\u5730\u63ed\u793a\u4e2a\u4f53\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u6574\u4f53\u6d41\u7a0b\u6548\u7387\u3002"}}
{"id": "2507.23273", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23273", "abs": "https://arxiv.org/abs/2507.23273", "authors": ["Jaeseok Park", "Chanoh Park", "Minsu Kim", "Soohwan Kim"], "title": "GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting", "comment": null, "summary": "While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic mapping,\nconventional approaches based on camera sensor, even RGB-D, suffer from\nfundamental limitations such as high computational load, failure in\nenvironments with poor texture or illumination, and short operational ranges.\nLiDAR emerges as a robust alternative, but its integration with 3DGS introduces\nnew challenges, such as the need for exceptional global alignment for\nphotorealistic quality and prolonged optimization times caused by sparse data.\nTo address these challenges, we propose GSFusion, an online\nLiDAR-Inertial-Visual mapping system that ensures high-precision map\nconsistency through a surfel-to-surfel constraint in the global pose-graph\noptimization. To handle sparse data, our system employs a pixel-aware Gaussian\ninitialization strategy for efficient representation and a bounded sigmoid\nconstraint to prevent uncontrolled Gaussian growth. Experiments on public and\nour datasets demonstrate our system outperforms existing 3DGS SLAM systems in\nterms of rendering quality and map-building efficiency.", "AI": {"tldr": "GSFusion\u662f\u4e00\u79cd\u7ed3\u5408LiDAR\u3001\u60ef\u6027\u548c\u89c6\u89c9\u7684\u5728\u7ebf\u6620\u5c04\u7cfb\u7edf\uff0c\u901a\u8fc7\u5168\u5c40\u4f4d\u59ff\u56fe\u4f18\u5316\u548c\u9ad8\u6548\u9ad8\u65af\u521d\u59cb\u5316\u7b56\u7565\uff0c\u89e3\u51b3\u4e863D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u5728\u7a00\u758f\u6570\u636e\u548c\u5168\u5c40\u5bf9\u9f50\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u76f8\u673a\u4f20\u611f\u5668\uff08\u5305\u62ecRGB-D\uff09\u76843DGS\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u8d1f\u8f7d\u9ad8\u3001\u5728\u4f4e\u7eb9\u7406\u6216\u5149\u7167\u73af\u5883\u4e0b\u5931\u6548\u4ee5\u53ca\u64cd\u4f5c\u8303\u56f4\u77ed\u7684\u95ee\u9898\uff0c\u800cLiDAR\u867d\u7136\u9c81\u68d2\uff0c\u4f46\u5176\u4e0e3DGS\u7684\u96c6\u6210\u5e26\u6765\u4e86\u5168\u5c40\u5bf9\u9f50\u548c\u9ad8\u4f18\u5316\u65f6\u95f4\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faGSFusion\u7cfb\u7edf\uff0c\u91c7\u7528\u5168\u5c40\u4f4d\u59ff\u56fe\u4f18\u5316\u4e2d\u7684surfel-to-surfel\u7ea6\u675f\u786e\u4fdd\u5730\u56fe\u4e00\u81f4\u6027\uff0c\u5e76\u4f7f\u7528\u50cf\u7d20\u611f\u77e5\u7684\u9ad8\u65af\u521d\u59cb\u5316\u7b56\u7565\u548c\u8fb9\u754csigmoid\u7ea6\u675f\u5904\u7406\u7a00\u758f\u6570\u636e\u3002", "result": "\u5728\u516c\u5f00\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGSFusion\u5728\u6e32\u67d3\u8d28\u91cf\u548c\u5730\u56fe\u6784\u5efa\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u67093DGS SLAM\u7cfb\u7edf\u3002", "conclusion": "GSFusion\u901a\u8fc7\u521b\u65b0\u7684\u7ea6\u675f\u548c\u521d\u59cb\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e863DGS\u5728LiDAR-\u60ef\u6027-\u89c6\u89c9\u6620\u5c04\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.22919", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22919", "abs": "https://arxiv.org/abs/2507.22919", "authors": ["Qixuan Hu", "Xumou Zhang", "Jinman Kim", "Florence Bourgeois", "Adam G. Dunn"], "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "comment": null, "summary": "Objectives: With accurate estimates of expected safety results, clinical\ntrials could be designed to avoid terminations and limit exposing participants\nto unnecessary risks. We evaluated methods for predicting serious adverse event\n(SAE) results in clinical trials using information only from their\nregistrations prior to the trial. Material and Methods: We analysed 22,107\ntwo-arm parallel interventional clinical trials from ClinicalTrials.gov with\nstructured summary results. Two prediction models were developed: a classifier\npredicting will experimental arm have higher SAE rates (area under the receiver\noperating characteristic curve; AUC) than control arm, and a regression model\nto predict the proportion of SAEs in control arms (root mean squared error;\nRMSE). A transfer learning approach using pretrained language models (e.g.,\nClinicalT5, BioBERT) was used for feature extraction, combined with downstream\nmodel for prediction. To maintain semantic representation in long trial texts\nexceeding localised language model input limits, a sliding window method was\ndeveloped for embedding extraction. Results: The best model\n(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a\nhigher proportion of patients with SAEs. When predicting proportion of\nparticipants experiencing SAE in the control arm, the same model achieved RMSE\nof 18.6%. The sliding window approach consistently outperformed methods without\nit. Across 12 classifiers, the average absolute AUC increase was 2.00%; across\n12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:\nSummary results data available at ClinicalTrials.gov remains underutilised. The\npotential to estimate results of trials before they start is an opportunity to\nimprove trial design and flag discrepancies between expected and reported\nsafety results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u6a21\u578b\u9884\u6d4b\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u7684\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\uff08SAE\uff09\u7ed3\u679c\uff0c\u5229\u7528\u6ce8\u518c\u4fe1\u606f\u63d0\u524d\u9884\u6d4b\uff0c\u4ee5\u4f18\u5316\u8bd5\u9a8c\u8bbe\u8ba1\u3002", "motivation": "\u901a\u8fc7\u51c6\u786e\u9884\u6d4bSAE\u7ed3\u679c\uff0c\u907f\u514d\u8bd5\u9a8c\u7ec8\u6b62\u5e76\u51cf\u5c11\u53c2\u4e0e\u8005\u98ce\u9669\uff0c\u5229\u7528ClinicalTrials.gov\u7684\u6ce8\u518c\u6570\u636e\u4f18\u5316\u8bd5\u9a8c\u8bbe\u8ba1\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08\u5982ClinicalT5\u3001BioBERT\uff09\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u5904\u7406\u957f\u6587\u672c\uff0c\u5f00\u53d1\u5206\u7c7b\u5668\u548c\u56de\u5f52\u6a21\u578b\u9884\u6d4bSAE\u7ed3\u679c\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08ClinicalT5+Transformer+MLP\uff09\u5728\u9884\u6d4bSAE\u6bd4\u4f8b\u65f6AUC\u4e3a77.6%\uff0c\u63a7\u5236\u7ec4SAE\u6bd4\u4f8b\u9884\u6d4bRMSE\u4e3a18.6%\u3002\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u5229\u7528ClinicalTrials.gov\u6570\u636e\u9884\u6d4bSAE\u7ed3\u679c\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u6539\u8fdb\u8bd5\u9a8c\u8bbe\u8ba1\u5e76\u53d1\u73b0\u9884\u671f\u4e0e\u5b9e\u9645\u7ed3\u679c\u7684\u5dee\u5f02\u3002"}}
{"id": "2507.23350", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.23350", "abs": "https://arxiv.org/abs/2507.23350", "authors": ["Mahmoud Ghorab", "Matthias Lorenzen"], "title": "Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications", "comment": "6 pages", "summary": "There is a growing demand for autonomous mobile robots capable of navigating\nunstructured agricultural environments. Tasks such as weed control in meadows\nrequire efficient path planning through an unordered set of coordinates while\nminimizing travel distance and adhering to curvature constraints to prevent\nsoil damage and protect vegetation. This paper presents an integrated\nnavigation framework combining a global path planner based on the Dubins\nTraveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control\n(NMPC) strategy for local path planning and control. The DTSP generates a\nminimum-length, curvature-constrained path that efficiently visits all targets,\nwhile the NMPC leverages this path to compute control signals to accurately\nreach each waypoint. The system's performance was validated through comparative\nsimulation analysis on real-world field datasets, demonstrating that the\ncoupled DTSP-based planner produced smoother and shorter paths, with a\nreduction of about 16% in the provided scenario, compared to decoupled methods.\nBased thereon, the NMPC controller effectively steered the robot to the desired\nwaypoints, while locally optimizing the trajectory and ensuring adherence to\nconstraints. These findings demonstrate the potential of the proposed framework\nfor efficient autonomous navigation in agricultural environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5168\u5c40Dubins\u65c5\u884c\u5546\u95ee\u9898\uff08DTSP\uff09\u8def\u5f84\u89c4\u5212\u4e0e\u5c40\u90e8\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08NMPC\uff09\u7684\u5bfc\u822a\u6846\u67b6\uff0c\u7528\u4e8e\u519c\u4e1a\u73af\u5883\u4e2d\u81ea\u4e3b\u79fb\u52a8\u673a\u5668\u4eba\u7684\u9ad8\u6548\u5bfc\u822a\u3002", "motivation": "\u519c\u4e1a\u73af\u5883\u4e2d\u81ea\u4e3b\u79fb\u52a8\u673a\u5668\u4eba\u5bfc\u822a\u9700\u6c42\u589e\u957f\uff0c\u9700\u9ad8\u6548\u8def\u5f84\u89c4\u5212\u4ee5\u51cf\u5c11\u884c\u9a76\u8ddd\u79bb\u5e76\u6ee1\u8db3\u66f2\u7387\u7ea6\u675f\uff0c\u4fdd\u62a4\u571f\u58e4\u548c\u690d\u88ab\u3002", "method": "\u91c7\u7528DTSP\u751f\u6210\u6700\u77ed\u66f2\u7387\u7ea6\u675f\u8def\u5f84\uff0c\u7ed3\u5408NMPC\u8fdb\u884c\u5c40\u90e8\u8def\u5f84\u89c4\u5212\u4e0e\u63a7\u5236\uff0c\u4f18\u5316\u8f68\u8ff9\u5e76\u6ee1\u8db3\u7ea6\u675f\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u663e\u793a\uff0c\u8026\u5408DTSP\u7684\u89c4\u5212\u5668\u8def\u5f84\u66f4\u5e73\u6ed1\u3001\u66f4\u77ed\uff0c\u6bd4\u89e3\u8026\u65b9\u6cd5\u51cf\u5c11\u7ea616%\u7684\u884c\u9a76\u8ddd\u79bb\uff1bNMPC\u63a7\u5236\u5668\u6709\u6548\u5f15\u5bfc\u673a\u5668\u4eba\u5230\u8fbe\u76ee\u6807\u70b9\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u519c\u4e1a\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u9ad8\u6548\u81ea\u4e3b\u5bfc\u822a\u6f5c\u529b\u3002"}}
{"id": "2507.23185", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.23185", "abs": "https://arxiv.org/abs/2507.23185", "authors": ["Jongwook Si", "Sungyoung Kim"], "title": "Single Image Rain Streak Removal Using Harris Corner Loss and R-CBAM Network", "comment": "21 pages", "summary": "The problem of single-image rain streak removal goes beyond simple noise\nsuppression, requiring the simultaneous preservation of fine structural details\nand overall visual quality. In this study, we propose a novel image restoration\nnetwork that effectively constrains the restoration process by introducing a\nCorner Loss, which prevents the loss of object boundaries and detailed texture\ninformation during restoration. Furthermore, we propose a Residual\nConvolutional Block Attention Module (R-CBAM) Block into the encoder and\ndecoder to dynamically adjust the importance of features in both spatial and\nchannel dimensions, enabling the network to focus more effectively on regions\nheavily affected by rain streaks. Quantitative evaluations conducted on the\nRain100L and Rain100H datasets demonstrate that the proposed method\nsignificantly outperforms previous approaches, achieving a PSNR of 33.29 dB on\nRain100L and 26.16 dB on Rain100H.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Corner Loss\u548cR-CBAM\u6a21\u5757\u7684\u56fe\u50cf\u53bb\u96e8\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53bb\u96e8\u6548\u679c\u3002", "motivation": "\u5355\u56fe\u50cf\u53bb\u96e8\u4efb\u52a1\u9700\u8981\u540c\u65f6\u4fdd\u7559\u7ec6\u8282\u548c\u6574\u4f53\u89c6\u89c9\u8d28\u91cf\uff0c\u73b0\u6709\u65b9\u6cd5\u5bb9\u6613\u4e22\u5931\u8fb9\u754c\u548c\u7eb9\u7406\u4fe1\u606f\u3002", "method": "\u5f15\u5165Corner Loss\u9632\u6b62\u8fb9\u754c\u548c\u7eb9\u7406\u4e22\u5931\uff0c\u5e76\u5728\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e2d\u52a0\u5165R-CBAM\u6a21\u5757\u52a8\u6001\u8c03\u6574\u7279\u5f81\u91cd\u8981\u6027\u3002", "result": "\u5728Rain100L\u548cRain100H\u6570\u636e\u96c6\u4e0aPSNR\u5206\u522b\u8fbe\u523033.29 dB\u548c26.16 dB\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u53bb\u96e8\u6548\u679c\uff0c\u5c24\u5176\u5728\u4fdd\u7559\u7ec6\u8282\u548c\u8fb9\u754c\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2507.23303", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23303", "abs": "https://arxiv.org/abs/2507.23303", "authors": ["Luca Corbucci", "Javier Alejandro Borges Legrottaglie", "Francesco Spinnato", "Anna Monreale", "Riccardo Guidotti"], "title": "An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items", "comment": null, "summary": "Accurately identifying items forgotten during a supermarket visit and\nproviding clear, interpretable explanations for recommending them remains an\nunderexplored problem within the Next Basket Prediction (NBP) domain. Existing\nNBP approaches typically only focus on forecasting future purchases, without\nexplicitly addressing the detection of unintentionally omitted items. This gap\nis partly due to the scarcity of real-world datasets that allow for the\nreliable estimation of forgotten items. Furthermore, most current NBP methods\nrely on black-box models, which lack transparency and limit the ability to\njustify recommendations to end users. In this paper, we formally introduce the\nforgotten item prediction task and propose two novel interpretable-by-design\nalgorithms. These methods are tailored to identify forgotten items while\noffering intuitive, human-understandable explanations. Experiments on a\nreal-world retail dataset show our algorithms outperform state-of-the-art NBP\nbaselines by 10-15% across multiple evaluation metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u53ef\u89e3\u91ca\u7b97\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u8d85\u5e02\u8d2d\u7269\u4e2d\u88ab\u9057\u5fd8\u7684\u5546\u54c1\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709NBP\u65b9\u6cd5\u4ec5\u9884\u6d4b\u672a\u6765\u8d2d\u4e70\uff0c\u672a\u89e3\u51b3\u9057\u6f0f\u5546\u54c1\u7684\u8bc6\u522b\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u900f\u660e\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u53ef\u89e3\u91ca\u7b97\u6cd5\uff0c\u4e13\u95e8\u8bc6\u522b\u9057\u5fd8\u5546\u54c1\u5e76\u63d0\u4f9b\u76f4\u89c2\u89e3\u91ca\u3002", "result": "\u5728\u771f\u5b9e\u96f6\u552e\u6570\u636e\u96c6\u4e0a\uff0c\u7b97\u6cd5\u6bd4\u73b0\u6709NBP\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u63d0\u534710-15%\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86NBP\u9886\u57df\u9057\u5fd8\u5546\u54c1\u9884\u6d4b\u7684\u7a7a\u767d\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22943", "categories": ["cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.22943", "abs": "https://arxiv.org/abs/2507.22943", "authors": ["Shirley V Wang", "Georg Hahn", "Sushama Kattinakere Sreedhara", "Mufaddal Mahesri", "Haritha S. Pillai", "Rajendra Aldis", "Joyce Lii", "Sarah K. Dutcher", "Rhoda Eniafe", "Jamal T. Jones", "Keewan Kim", "Jiwei He", "Hana Lee", "Sengwee Toh", "Rishi J Desai", "Jie Yang"], "title": "A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies", "comment": null, "summary": "Background: One of the ways to enhance analyses conducted with large claims\ndatabases is by validating the measurement characteristics of code-based\nalgorithms used to identify health outcomes or other key study parameters of\ninterest. These metrics can be used in quantitative bias analyses to assess the\nrobustness of results for an inferential study given potential bias from\noutcome misclassification. However, extensive time and resource allocation are\ntypically re-quired to create reference-standard labels through manual chart\nreview of free-text notes from linked electronic health records. Methods: We\ndescribe an expedited process that introduces efficiency in a validation study\nus-ing two distinct mechanisms: 1) use of natural language processing (NLP) to\nreduce time spent by human reviewers to review each chart, and 2) a multi-wave\nadaptive sampling approach with pre-defined criteria to stop the validation\nstudy once performance characteristics are identified with sufficient\nprecision. We illustrate this process in a case study that validates the\nperformance of a claims-based outcome algorithm for intentional self-harm in\npatients with obesity. Results: We empirically demonstrate that the\nNLP-assisted annotation process reduced the time spent on review per chart by\n40% and use of the pre-defined stopping rule with multi-wave samples would have\nprevented review of 77% of patient charts with limited compromise to precision\nin derived measurement characteristics. Conclusion: This approach could\nfacilitate more routine validation of code-based algorithms used to define key\nstudy parameters, ultimately enhancing understanding of the reliability of\nfind-ings derived from database studies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a0\u901f\u9a8c\u8bc1\u4ee3\u7801\u7b97\u6cd5\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u591a\u6ce2\u81ea\u9002\u5e94\u62bd\u6837\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5ba1\u6838\u65f6\u95f4\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u901a\u8fc7\u9a8c\u8bc1\u4ee3\u7801\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u53ef\u4ee5\u589e\u5f3a\u5927\u578b\u7d22\u8d54\u6570\u636e\u5e93\u7684\u5206\u6790\u53ef\u9760\u6027\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u8017\u529b\u3002", "method": "\u4f7f\u7528NLP\u51cf\u5c11\u4eba\u5de5\u5ba1\u6838\u65f6\u95f4\uff0c\u5e76\u7ed3\u5408\u591a\u6ce2\u81ea\u9002\u5e94\u62bd\u6837\u548c\u9884\u5b9a\u4e49\u505c\u6b62\u89c4\u5219\uff0c\u4ee5\u9ad8\u6548\u5b8c\u6210\u9a8c\u8bc1\u3002", "result": "NLP\u8f85\u52a9\u5ba1\u6838\u51cf\u5c1140%\u65f6\u95f4\uff0c\u591a\u6ce2\u62bd\u6837\u907f\u514d77%\u7684\u56fe\u8868\u5ba1\u6838\uff0c\u4e14\u4e0d\u5f71\u54cd\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4fc3\u8fdb\u4ee3\u7801\u7b97\u6cd5\u7684\u5e38\u89c4\u9a8c\u8bc1\uff0c\u63d0\u5347\u6570\u636e\u5e93\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.23082", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23082", "abs": "https://arxiv.org/abs/2507.23082", "authors": ["Diego Garat", "Guillermo Moncecchi", "Dina Wonsever"], "title": "Exploring In-Context Learning for Frame-Semantic Parsing", "comment": null, "summary": "Frame Semantic Parsing (FSP) entails identifying predicates and labeling\ntheir arguments according to Frame Semantics. This paper investigates the use\nof In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP\nwithout model fine-tuning. We propose a method that automatically generates\ntask-specific prompts for the Frame Identification (FI) and Frame Semantic Role\nLabeling (FSRL) subtasks, relying solely on the FrameNet database. These\nprompts, constructed from frame definitions and annotated examples, are used to\nguide six different LLMs. Experiments are conducted on a subset of frames\nrelated to violent events. The method achieves competitive results, with F1\nscores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers\na practical and effective alternative to traditional fine-tuning for\ndomain-specific FSP tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u8fdb\u884c\u6846\u67b6\u8bed\u4e49\u89e3\u6790\uff08FSP\uff09\uff0c\u65e0\u9700\u5fae\u8c03\u6a21\u578b\u3002\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\uff0c\u5728FrameNet\u6570\u636e\u5e93\u7684\u57fa\u7840\u4e0a\uff0c\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u7ed3\u679c\u3002", "motivation": "\u63a2\u7d22\u65e0\u9700\u5fae\u8c03\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5229\u7528ICL\u548cLLMs\u5b8c\u6210FSP\u4efb\u52a1\uff0c\u4ee5\u7b80\u5316\u6d41\u7a0b\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u81ea\u52a8\u751f\u6210\u9488\u5bf9\u6846\u67b6\u8bc6\u522b\uff08FI\uff09\u548c\u6846\u67b6\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\uff08FSRL\uff09\u5b50\u4efb\u52a1\u7684\u63d0\u793a\uff0c\u57fa\u4e8eFrameNet\u6570\u636e\u5e93\u7684\u6846\u67b6\u5b9a\u4e49\u548c\u6807\u6ce8\u793a\u4f8b\u3002", "result": "\u5728\u66b4\u529b\u4e8b\u4ef6\u76f8\u5173\u5e27\u7684\u5b50\u96c6\u4e0a\uff0cFI\u7684F1\u5f97\u5206\u4e3a94.3%\uff0cFSRL\u4e3a77.4%\u3002", "conclusion": "ICL\u4e3a\u9886\u57df\u7279\u5b9a\u7684FSP\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u6709\u6548\u7684\u66ff\u4ee3\u4f20\u7edf\u5fae\u8c03\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.23562", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.23562", "abs": "https://arxiv.org/abs/2507.23562", "authors": ["Sirine Arfa", "Bernhard Vogginger", "Christian Mayr"], "title": "Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform", "comment": "8 pages, 5 figures, 3 tables", "summary": "Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power\nconsumption and low-latency inference on neuromorphic hardware for a wide range\nof robotic tasks. In this work, we present an energy-efficient implementation\nof a reinforcement learning (RL) algorithm using quantized SNNs to solve two\nclassical control tasks. The network is trained using the Q-learning algorithm,\nthen fine-tuned and quantized to low-bit (8-bit) precision for embedded\ndeployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative\nadvantage of SpiNNaker2 over conventional computing platforms, we analyze\ninference latency, dynamic power consumption, and energy cost per inference for\nour SNN models, comparing performance against a GTX 1650 GPU baseline. Our\nresults demonstrate SpiNNaker2's strong potential for scalable, low-energy\nneuromorphic computing, achieving up to 32x reduction in energy consumption.\nInference latency remains on par with GPU-based execution, with improvements\nobserved in certain task settings, reinforcing SpiNNaker2's viability for\nreal-time neuromorphic control and making the neuromorphic approach a\ncompelling direction for efficient deep Q-learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5316\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\uff0c\u5e76\u5728SpiNNaker2\u795e\u7ecf\u5f62\u6001\u82af\u7247\u4e0a\u5b9e\u73b0\u4f4e\u529f\u8017\u90e8\u7f72\u3002\u4e0eGPU\u76f8\u6bd4\uff0cSpiNNaker2\u5728\u80fd\u8017\u4e0a\u964d\u4f4e\u4e8632\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5229\u7528SNN\u548c\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\uff08\u5982SpiNNaker2\uff09\u5b9e\u73b0\u4f4e\u529f\u8017\u3001\u4f4e\u5ef6\u8fdf\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u4ee5\u89e3\u51b3\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u7684\u80fd\u8017\u548c\u5b9e\u65f6\u6027\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528Q-learning\u7b97\u6cd5\u8bad\u7ec3SNN\uff0c\u7136\u540e\u5bf9\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03\u548c8\u4f4d\u91cf\u5316\uff0c\u6700\u7ec8\u5728SpiNNaker2\u82af\u7247\u4e0a\u90e8\u7f72\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cSpiNNaker2\u5728\u80fd\u8017\u4e0a\u6bd4GPU\u964d\u4f4e\u4e8632\u500d\uff0c\u63a8\u7406\u5ef6\u8fdf\u4e0eGPU\u76f8\u5f53\uff0c\u67d0\u4e9b\u4efb\u52a1\u4e2d\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0cSpiNNaker2\u5728\u53ef\u6269\u5c55\u3001\u4f4e\u80fd\u8017\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u9ad8\u6548\u7684\u6df1\u5ea6Q\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.23407", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23407", "abs": "https://arxiv.org/abs/2507.23407", "authors": ["Ante Wang", "Yujie Lin", "Jingyao Liu", "Suhang Wu", "Hao Liu", "Xinyan Xiao", "Jinsong Su"], "title": "Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration", "comment": null, "summary": "Critical thinking is essential for building robust AI systems, preventing\nthem from blindly accepting flawed data or biased reasoning. However, prior\nwork has primarily focused on passive critical thinking, where models simply\nreject problematic queries without taking constructive steps to address user\nrequests. In this work, we introduce proactive critical thinking, a paradigm\nwhere models actively seek missing or clarifying information from users to\nresolve their queries better. To evaluate this capability, we present GSM-MC\nand GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical\nreasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math\nproblems with a key variable deliberately removed, requiring models to identify\nand request the missing information. GSM-MCE further increases the difficulty\nby introducing irrelevant details to test robustness against distractions.\nExperiments on Qwen3 and Llama series models show that, while these models\nexcel in traditional reasoning tasks due to extensive post-training and\ninference-time scaling, they struggle with proactive critical thinking,\nespecially smaller ones. However, we demonstrate that reinforcement learning\n(RL) can significantly improve this ability. Using our enhanced RL algorithm,\nwe achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to\n73.98% on GSM-MC. We hope this work advances models that collaborate more\neffectively with users in problem-solving through proactive critical thinking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u8303\u5f0f\uff0c\u65e8\u5728\u8ba9AI\u6a21\u578b\u4e3b\u52a8\u5bfb\u6c42\u7f3a\u5931\u6216\u6f84\u6e05\u4fe1\u606f\u4ee5\u66f4\u597d\u5730\u89e3\u51b3\u7528\u6237\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u65b0\u57fa\u51c6GSM-MC\u548cGSM-MCE\u8bc4\u4f30\u5176\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f3a\u5316\u5b66\u4e60\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u591a\u91c7\u7528\u88ab\u52a8\u6279\u5224\u6027\u601d\u7ef4\uff0c\u4ec5\u62d2\u7edd\u95ee\u9898\u67e5\u8be2\u800c\u7f3a\u4e4f\u4e3b\u52a8\u89e3\u51b3\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u63a8\u52a8\u6a21\u578b\u901a\u8fc7\u4e3b\u52a8\u5bfb\u6c42\u4fe1\u606f\u6765\u66f4\u6709\u6548\u5730\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u8303\u5f0f\uff0c\u8bbe\u8ba1GSM-MC\u548cGSM-MCE\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4f20\u7edf\u6a21\u578b\u5728\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86Qwen3-1.7B\u6a21\u578b\u7684\u51c6\u786e\u7387\uff08\u4ece0.15%\u63d0\u5347\u81f373.98%\uff09\u3002", "conclusion": "\u901a\u8fc7\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u548c\u5f3a\u5316\u5b66\u4e60\uff0cAI\u6a21\u578b\u80fd\u66f4\u6709\u6548\u5730\u4e0e\u7528\u6237\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.23465", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23465", "abs": "https://arxiv.org/abs/2507.23465", "authors": ["Saeed Almheiri", "Yerulan Kongrat", "Adrian Santosh", "Ruslan Tasmukhanov", "Josemaria Vera", "Muhammad Dehan Al Kautsar", "Fajri Koto"], "title": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in enterprise\nsettings, controlling model behavior based on user roles becomes an essential\nrequirement. Existing safety methods typically assume uniform access and focus\non preventing harmful or toxic outputs, without addressing role-specific access\nconstraints. In this work, we investigate whether LLMs can be fine-tuned to\ngenerate responses that reflect the access privileges associated with different\norganizational roles. We explore three modeling strategies: a BERT-based\nclassifier, an LLM-based classifier, and role-conditioned generation. To\nevaluate these approaches, we construct two complementary datasets. The first\nis adapted from existing instruction-tuning corpora through clustering and role\nlabeling, while the second is synthetically generated to reflect realistic,\nrole-sensitive enterprise scenarios. We assess model performance across varying\norganizational structures and analyze robustness to prompt injection, role\nmismatch, and jailbreak attempts.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b9e\u73b0\u57fa\u4e8e\u7528\u6237\u89d2\u8272\u7684\u884c\u4e3a\u63a7\u5236\uff0c\u63d0\u51fa\u4e09\u79cd\u5efa\u6a21\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u4e24\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\uff0cLLMs\u7684\u884c\u4e3a\u9700\u6839\u636e\u7528\u6237\u89d2\u8272\u8fdb\u884c\u63a7\u5236\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u89e3\u51b3\u89d2\u8272\u7279\u5b9a\u8bbf\u95ee\u9650\u5236\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e09\u79cd\u7b56\u7565\uff1aBERT\u5206\u7c7b\u5668\u3001LLM\u5206\u7c7b\u5668\u548c\u89d2\u8272\u6761\u4ef6\u751f\u6210\uff0c\u5e76\u6784\u5efa\u4e24\u4e2a\u6570\u636e\u96c6\uff08\u57fa\u4e8e\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u548c\u5408\u6210\u6570\u636e\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u7ec4\u7ec7\u7ed3\u6784\u548c\u5bf9\u6297\u653b\u51fb\uff08\u5982\u63d0\u793a\u6ce8\u5165\u3001\u89d2\u8272\u4e0d\u5339\u914d\u548c\u8d8a\u72f1\uff09\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u8868\u660eLLMs\u53ef\u901a\u8fc7\u5fae\u8c03\u5b9e\u73b0\u89d2\u8272\u7279\u5b9a\u7684\u884c\u4e3a\u63a7\u5236\uff0c\u4e3a\u5b9e\u9645\u4f01\u4e1a\u5e94\u7528\u63d0\u4f9b\u53ef\u80fd\u3002"}}
{"id": "2507.23643", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23643", "abs": "https://arxiv.org/abs/2507.23643", "authors": ["Changqing Xu", "Ziqiang Yang", "Yi Liu", "Xinfang Liao", "Guiqi Mo", "Hao Zeng", "Yintang Yang"], "title": "FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks", "comment": null, "summary": "Spiking Neural Networks (SNNs) offer a biologically plausible framework for\nenergy-efficient neuromorphic computing. However, it is a challenge to train\nSNNs due to their non-differentiability, efficiently. Existing gradient\napproximation approaches frequently sacrifice accuracy and face deployment\nlimitations on edge devices due to the substantial computational requirements\nof backpropagation. To address these challenges, we propose a Forward-Forward\n(FF) based gradient approximation-free training framework for Spiking Neural\nNetworks, which treats spiking activations as black-box modules, thereby\neliminating the need for gradient approximation while significantly reducing\ncomputational complexity. Furthermore, we introduce a class-aware complexity\nadaptation mechanism that dynamically optimizes the loss function based on\ninter-class difficulty metrics, enabling efficient allocation of network\nresources across different categories. Experimental results demonstrate that\nour proposed training framework achieves test accuracies of 99.58%, 92.13%, and\n75.64% on the MNIST, Fashion-MNIST, and CIFAR-10 datasets, respectively,\nsurpassing all existing FF-based SNN approaches. Additionally, our proposed\nmethod exhibits significant advantages in terms of memory access and\ncomputational power consumption.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eForward-Forward\uff08FF\uff09\u7684\u65e0\u68af\u5ea6\u8fd1\u4f3c\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u8bad\u7ec3SNN\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u635f\u5931\u51fd\u6570\u63d0\u5347\u6027\u80fd\u3002", "motivation": "SNN\u8bad\u7ec3\u56e0\u975e\u53ef\u5fae\u6027\u548c\u9ad8\u8ba1\u7b97\u9700\u6c42\u800c\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u727a\u7272\u7cbe\u5ea6\u4e14\u96be\u4ee5\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u3002", "method": "\u91c7\u7528FF\u6846\u67b6\uff0c\u5c06\u8109\u51b2\u6fc0\u6d3b\u89c6\u4e3a\u9ed1\u76d2\u6a21\u5757\uff0c\u65e0\u9700\u68af\u5ea6\u8fd1\u4f3c\uff1b\u5f15\u5165\u7c7b\u611f\u77e5\u590d\u6742\u5ea6\u9002\u5e94\u673a\u5236\u52a8\u6001\u4f18\u5316\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728MNIST\u3001Fashion-MNIST\u548cCIFAR-10\u4e0a\u5206\u522b\u8fbe\u523099.58%\u300192.13%\u548c75.64%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709FF\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5185\u5b58\u8bbf\u95ee\u9700\u6c42\uff0c\u4e3aSNN\u7684\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
