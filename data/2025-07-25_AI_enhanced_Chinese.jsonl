{"id": "2507.17842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.17842", "abs": "https://arxiv.org/abs/2507.17842", "authors": ["Yimeng Zhang", "Tian Wang", "Jiri Gesi", "Ziyi Wang", "Yuxuan Lu", "Jiacheng Lin", "Sinong Zhan", "Vianne Gao", "Ruochen Jiao", "Junze Liu", "Kun Qian", "Yuxin Tang", "Ran Xue", "Houyu Zhang", "Qingjun Cui", "Yufan Guo", "Dakuo Wang"], "title": "Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) have recently demonstrated strong potential in\ngenerating 'believable human-like' behavior in web environments. Prior work has\nexplored augmenting training data with LLM-synthesized rationales and applying\nsupervised fine-tuning (SFT) to enhance reasoning ability, which in turn can\nimprove downstream action prediction. However, the performance of such\napproaches remains inherently bounded by the reasoning capabilities of the\nmodel used to generate the rationales. In this paper, we introduce Shop-R1, a\nnovel reinforcement learning (RL) framework aimed at enhancing the reasoning\nability of LLMs for simulation of real human behavior in online shopping\nenvironments Specifically, Shop-R1 decomposes the human behavior simulation\ntask into two stages: rationale generation and action prediction, each guided\nby distinct reward signals. For rationale generation, we leverage internal\nmodel signals (e.g., logit distributions) to guide the reasoning process in a\nself-supervised manner. For action prediction, we propose a hierarchical reward\nstructure with difficulty-aware scaling to prevent reward hacking and enable\nfine-grained reward assignment. This design evaluates both high-level action\ntypes and the correctness of fine-grained sub-action details (attributes and\nvalues), rewarding outputs proportionally to their difficulty. Experimental\nresults show that our method achieves a relative improvement of over 65%\ncompared to the baseline.", "AI": {"tldr": "Shop-R1\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u751f\u6210\u7406\u7531\u548c\u9884\u6d4b\u52a8\u4f5c\uff0c\u63d0\u5347LLMs\u5728\u5728\u7ebf\u8d2d\u7269\u73af\u5883\u4e2d\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u751f\u6210\u7406\u7531\u7684\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0cShop-R1\u65e8\u5728\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLMs\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "Shop-R1\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u7406\u7531\u751f\u6210\u548c\u52a8\u4f5c\u9884\u6d4b\u4e24\u9636\u6bb5\uff0c\u5206\u522b\u4f7f\u7528\u81ea\u76d1\u7763\u548c\u5206\u5c42\u5956\u52b1\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u63d0\u5347\u4e8665%\u4ee5\u4e0a\u3002", "conclusion": "Shop-R1\u6709\u6548\u63d0\u5347\u4e86LLMs\u5728\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.18070", "categories": ["cs.RO", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.18070", "abs": "https://arxiv.org/abs/2507.18070", "authors": ["Behzad Zamani", "Jochen Trumpf", "Chris Manzie"], "title": "Modular Robot and Landmark Localisation Using Relative Bearing Measurements", "comment": "Submitted to RA-L", "summary": "In this paper we propose a modular nonlinear least squares filtering approach\nfor systems composed of independent subsystems. The state and error covariance\nestimate of each subsystem is updated independently, even when a relative\nmeasurement simultaneously depends on the states of multiple subsystems. We\nintegrate the Covariance Intersection (CI) algorithm as part of our solution in\norder to prevent double counting of information when subsystems share estimates\nwith each other. An alternative derivation of the CI algorithm based on least\nsquares estimation makes this integration possible. We particularise the\nproposed approach to the robot-landmark localization problem. In this problem,\nnoisy measurements of the bearing angle to a stationary landmark position\nmeasured relative to the SE(2) pose of a moving robot couple the estimation\nproblems for the robot pose and the landmark position. In a randomized\nsimulation study, we benchmark the proposed modular method against a monolithic\njoint state filter to elucidate their respective trade-offs. In this study we\nalso include variants of the proposed method that achieve a graceful\ndegradation of performance with reduced communication and bandwidth\nrequirements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u7528\u4e8e\u72ec\u7acb\u5b50\u7cfb\u7edf\u7ec4\u6210\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u534f\u65b9\u5dee\u4ea4\u96c6\uff08CI\uff09\u7b97\u6cd5\u907f\u514d\u4fe1\u606f\u91cd\u590d\u8ba1\u7b97\uff0c\u5e76\u5728\u673a\u5668\u4eba-\u5730\u6807\u5b9a\u4f4d\u95ee\u9898\u4e2d\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u7531\u72ec\u7acb\u5b50\u7cfb\u7edf\u7ec4\u6210\u7684\u7cfb\u7edf\u4e2d\u72b6\u6001\u548c\u8bef\u5dee\u534f\u65b9\u5dee\u4f30\u8ba1\u7684\u72ec\u7acb\u66f4\u65b0\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u76f8\u5bf9\u6d4b\u91cf\u540c\u65f6\u4f9d\u8d56\u591a\u4e2a\u5b50\u7cfb\u7edf\u72b6\u6001\u65f6\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u7ed3\u5408\u534f\u65b9\u5dee\u4ea4\u96c6\uff08CI\uff09\u7b97\u6cd5\uff0c\u9632\u6b62\u4fe1\u606f\u91cd\u590d\u8ba1\u7b97\uff0c\u5e76\u5728\u673a\u5668\u4eba-\u5730\u6807\u5b9a\u4f4d\u95ee\u9898\u4e2d\u5177\u4f53\u5e94\u7528\u3002", "result": "\u901a\u8fc7\u968f\u673a\u6a21\u62df\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86\u6a21\u5757\u5316\u65b9\u6cd5\u4e0e\u8054\u5408\u72b6\u6001\u6ee4\u6ce2\u5668\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u6a21\u5757\u5316\u65b9\u6cd5\u5728\u901a\u4fe1\u548c\u5e26\u5bbd\u9700\u6c42\u51cf\u5c11\u65f6\u7684\u6027\u80fd\u4e0b\u964d\u60c5\u51b5\u3002", "conclusion": "\u6a21\u5757\u5316\u65b9\u6cd5\u5728\u72ec\u7acb\u5b50\u7cfb\u7edf\u7cfb\u7edf\u4e2d\u6709\u6548\uff0c\u534f\u65b9\u5dee\u4ea4\u96c6\u7b97\u6cd5\u89e3\u51b3\u4e86\u4fe1\u606f\u5171\u4eab\u95ee\u9898\uff0c\u6027\u80fd\u5728\u51cf\u5c11\u901a\u4fe1\u9700\u6c42\u65f6\u9010\u6e10\u964d\u4f4e\u3002"}}
{"id": "2507.18398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18398", "abs": "https://arxiv.org/abs/2507.18398", "authors": ["Kwong Ho Li", "Wathsala Karunarathne"], "title": "Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation", "comment": "10 pages", "summary": "This paper investigates the application of Reinforcement Learning (RL) to\noptimise call routing in call centres to minimise client waiting time and staff\nidle time. Two methods are compared: a model-based approach using Value\nIteration (VI) under known system dynamics, and a model-free approach using\nProximal Policy Optimisation (PPO) that learns from experience. For the\nmodel-based approach, a theoretical model is used, while a simulation model\ncombining Discrete Event Simulation (DES) with the OpenAI Gym environment is\ndeveloped for model-free learning. Both models frame the problem as a Markov\nDecision Process (MDP) within a Skills-Based Routing (SBR) framework, with\nPoisson client arrivals and exponentially distributed service and abandonment\ntimes. For policy evaluation, random, VI, and PPO policies are evaluated using\nthe simulation model. After 1,000 test episodes, PPO consistently achives the\nhighest rewards, along with the lowest client waiting time and staff idle time,\ndespite requiring longer training time.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6a21\u578b\u7684Value Iteration\uff08VI\uff09\u548c\u65e0\u6a21\u578b\u7684Proximal Policy Optimisation\uff08PPO\uff09\u5728\u547c\u53eb\u4e2d\u5fc3\u8def\u7531\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0cPPO\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u4f18\u5316\u547c\u53eb\u4e2d\u5fc3\u7684\u8def\u7531\u7b56\u7565\u4ee5\u51cf\u5c11\u5ba2\u6237\u7b49\u5f85\u65f6\u95f4\u548c\u5458\u5de5\u7a7a\u95f2\u65f6\u95f4\u3002", "method": "\u4f7f\u7528VI\uff08\u5df2\u77e5\u7cfb\u7edf\u52a8\u6001\uff09\u548cPPO\uff08\u4ece\u7ecf\u9a8c\u5b66\u4e60\uff09\uff0c\u95ee\u9898\u5efa\u6a21\u4e3aMDP\uff0c\u7ed3\u5408DES\u548cOpenAI Gym\u8fdb\u884c\u6a21\u62df\u3002", "result": "PPO\u57281000\u6b21\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u5956\u52b1\u6700\u9ad8\uff0c\u5ba2\u6237\u7b49\u5f85\u65f6\u95f4\u548c\u5458\u5de5\u7a7a\u95f2\u65f6\u95f4\u6700\u4f4e\u3002", "conclusion": "PPO\u5728\u547c\u53eb\u4e2d\u5fc3\u8def\u7531\u4f18\u5316\u4e2d\u4f18\u4e8eVI\uff0c\u5c3d\u7ba1\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\u3002"}}
{"id": "2507.18182", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18182", "abs": "https://arxiv.org/abs/2507.18182", "authors": ["Wonjun Jeong", "Dongseok Kim", "Taegkeun Whangbo"], "title": "SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models", "comment": "34 pages, 1 figure", "summary": "Large Language Models (LLMs) can achieve inflated scores on multiple-choice\ntasks by exploiting inherent biases in option positions or labels, rather than\ndemonstrating genuine understanding. This study introduces SCOPE, an evaluation\nframework designed to measure and mitigate such selection bias in a\ndataset-independent manner. By repeatedly invoking a null prompt that lacks\nsemantic content, SCOPE estimates each model's unique position-bias\ndistribution. It then redistributes the answer slot according to the\ninverse-bias distribution, thereby equalizing the lucky-rate, the probability\nof selecting the correct answer by chance. Furthermore, it prevents\nsemantically similar distractors from being placed adjacent to the answer,\nthereby blocking near-miss guesses based on superficial proximity cues. Across\nmultiple benchmark experiments, SCOPE consistently outperformed existing\ndebiasing methods in terms of stable performance improvements and showed\nclearer confidence distributions over correct options. This framework thus\noffers a new standard for enhancing the fairness and reliability of LLM\nevaluations.", "AI": {"tldr": "SCOPE\u6846\u67b6\u901a\u8fc7\u6d88\u9664\u9009\u9879\u4f4d\u7f6e\u504f\u89c1\u548c\u8bed\u4e49\u90bb\u8fd1\u5e72\u6270\uff0c\u63d0\u5347LLM\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "LLMs\u5728\u591a\u9879\u9009\u62e9\u4efb\u52a1\u4e2d\u53ef\u80fd\u901a\u8fc7\u5229\u7528\u9009\u9879\u4f4d\u7f6e\u6216\u6807\u7b7e\u7684\u504f\u89c1\u800c\u975e\u771f\u5b9e\u7406\u89e3\u6765\u83b7\u5f97\u9ad8\u5206\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6d88\u9664\u8fd9\u79cd\u504f\u89c1\u3002", "method": "SCOPE\u901a\u8fc7\u91cd\u590d\u8c03\u7528\u65e0\u8bed\u4e49\u5185\u5bb9\u7684\u7a7a\u63d0\u793a\u4f30\u8ba1\u6a21\u578b\u7684\u504f\u89c1\u5206\u5e03\uff0c\u5e76\u91cd\u65b0\u5206\u914d\u7b54\u6848\u4f4d\u7f6e\u4ee5\u5e73\u8861\u968f\u673a\u6b63\u786e\u7387\uff0c\u540c\u65f6\u9632\u6b62\u8bed\u4e49\u76f8\u4f3c\u5e72\u6270\u9879\u76f8\u90bb\u3002", "result": "SCOPE\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7a33\u5b9a\u4f18\u4e8e\u73b0\u6709\u53bb\u504f\u65b9\u6cd5\uff0c\u5e76\u663e\u793a\u51fa\u66f4\u6e05\u6670\u7684\u6b63\u786e\u9009\u9879\u7f6e\u4fe1\u5206\u5e03\u3002", "conclusion": "SCOPE\u4e3a\u63d0\u5347LLM\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2507.18417", "categories": ["cs.CL", "cs.LG", "q-fin.ST", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2507.18417", "abs": "https://arxiv.org/abs/2507.18417", "authors": ["Giorgos Iacovides", "Wuyang Zhou", "Danilo Mandic"], "title": "FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs", "comment": null, "summary": "Opinions expressed in online finance-related textual data are having an\nincreasingly profound impact on trading decisions and market movements. This\ntrend highlights the vital role of sentiment analysis as a tool for quantifying\nthe nature and strength of such opinions. With the rapid development of\nGenerative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs)\nhave become the de facto standard for financial sentiment analysis. However,\nthe SFT paradigm can lead to memorization of the training data and often fails\nto generalize to unseen samples. This is a critical limitation in financial\ndomains, where models must adapt to previously unobserved events and the\nnuanced, domain-specific language of finance. To this end, we introduce FinDPO,\nthe first finance-specific LLM framework based on post-training human\npreference alignment via Direct Preference Optimization (DPO). The proposed\nFinDPO achieves state-of-the-art performance on standard sentiment\nclassification benchmarks, outperforming existing supervised fine-tuned models\nby 11% on the average. Uniquely, the FinDPO framework enables the integration\nof a fine-tuned causal LLM into realistic portfolio strategies through a novel\n'logit-to-score' conversion, which transforms discrete sentiment predictions\ninto continuous, rankable sentiment scores (probabilities). In this way,\nsimulations demonstrate that FinDPO is the first sentiment-based approach to\nmaintain substantial positive returns of 67% annually and strong risk-adjusted\nperformance, as indicated by a Sharpe ratio of 2.0, even under realistic\ntransaction costs of 5 basis points (bps).", "AI": {"tldr": "FinDPO\u662f\u4e00\u79cd\u57fa\u4e8eDPO\u7684\u91d1\u878d\u9886\u57df\u4e13\u7528LLM\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u60c5\u611f\u5206\u6790\u6027\u80fd\uff0c\u5e76\u5728\u5b9e\u9645\u6295\u8d44\u7b56\u7565\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u7ebf\u91d1\u878d\u6587\u672c\u60c5\u611f\u5206\u6790\u5bf9\u4ea4\u6613\u51b3\u7b56\u548c\u5e02\u573a\u52a8\u6001\u5f71\u54cd\u65e5\u76ca\u663e\u8457\uff0c\u4f46\u4f20\u7edfSFT\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faFinDPO\u6846\u67b6\uff0c\u901a\u8fc7DPO\u8fdb\u884c\u540e\u8bad\u7ec3\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u5e76\u7ed3\u5408'logit-to-score'\u8f6c\u6362\u751f\u6210\u8fde\u7eed\u60c5\u611f\u8bc4\u5206\u3002", "result": "FinDPO\u5728\u60c5\u611f\u5206\u7c7b\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u534711%\uff0c\u6a21\u62df\u6295\u8d44\u7b56\u7565\u5e74\u56de\u62a5\u7387\u8fbe67%\uff0c\u590f\u666e\u6bd4\u7387\u4e3a2.0\u3002", "conclusion": "FinDPO\u662f\u9996\u4e2a\u5728\u91d1\u878d\u9886\u57df\u5b9e\u73b0\u9ad8\u6027\u80fd\u60c5\u611f\u5206\u6790\u5e76\u6709\u6548\u652f\u6301\u6295\u8d44\u7b56\u7565\u7684\u6846\u67b6\u3002"}}
{"id": "2507.18139", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18139", "abs": "https://arxiv.org/abs/2507.18139", "authors": ["Alberto Marchisio", "Muhammad Shafique"], "title": "Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions", "comment": "To appear at the 31st IEEE International Symposium on On-Line Testing\n  and Robust System Design (IOLTS), Ischia, Italy, July 2025", "summary": "The growing need for intelligent, adaptive, and energy-efficient autonomous\nsystems across fields such as robotics, mobile agents (e.g., UAVs), and\nself-driving vehicles is driving interest in neuromorphic computing. By drawing\ninspiration from biological neural systems, neuromorphic approaches offer\npromising pathways to enhance the perception, decision-making, and\nresponsiveness of autonomous platforms. This paper surveys recent progress in\nneuromorphic algorithms, specialized hardware, and cross-layer optimization\nstrategies, with a focus on their deployment in real-world autonomous\nscenarios. Special attention is given to event-based dynamic vision sensors and\ntheir role in enabling fast, efficient perception. The discussion highlights\nnew methods that improve energy efficiency, robustness, adaptability, and\nreliability through the integration of spiking neural networks into autonomous\nsystem architectures. We integrate perspectives from machine learning,\nrobotics, neuroscience, and neuromorphic engineering to offer a comprehensive\nview of the state of the field. Finally, emerging trends and open challenges\nare explored, particularly in the areas of real-time decision-making, continual\nlearning, and the development of secure, resilient autonomous systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u5728\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u5173\u6ce8\u7b97\u6cd5\u3001\u786c\u4ef6\u548c\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e8b\u4ef6\u52a8\u6001\u89c6\u89c9\u4f20\u611f\u5668\u548c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5bf9\u667a\u80fd\u3001\u81ea\u9002\u5e94\u548c\u8282\u80fd\u81ea\u4e3b\u7cfb\u7edf\u7684\u9700\u6c42\u589e\u957f\uff0c\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u56e0\u5176\u4eff\u751f\u7279\u6027\u5728\u611f\u77e5\u3001\u51b3\u7b56\u548c\u54cd\u5e94\u80fd\u529b\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u6574\u5408\u673a\u5668\u5b66\u4e60\u3001\u673a\u5668\u4eba\u5b66\u3001\u795e\u7ecf\u79d1\u5b66\u548c\u795e\u7ecf\u5f62\u6001\u5de5\u7a0b\u7684\u591a\u5b66\u79d1\u89c6\u89d2\uff0c\u7efc\u8ff0\u4e86\u795e\u7ecf\u5f62\u6001\u7b97\u6cd5\u3001\u786c\u4ef6\u548c\u8de8\u5c42\u4f18\u5316\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u795e\u7ecf\u5f62\u6001\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u80fd\u6e90\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e8b\u4ef6\u52a8\u6001\u89c6\u89c9\u4f20\u611f\u5668\u548c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u4e2d\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u7684\u73b0\u72b6\uff0c\u5e76\u6307\u51fa\u4e86\u5b9e\u65f6\u51b3\u7b56\u3001\u6301\u7eed\u5b66\u4e60\u4ee5\u53ca\u5b89\u5168\u97e7\u6027\u7cfb\u7edf\u5f00\u53d1\u7b49\u672a\u6765\u6311\u6218\u3002"}}
{"id": "2507.18287", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.18287", "abs": "https://arxiv.org/abs/2507.18287", "authors": ["Wenran Zhang", "Huihuan Luo", "Linda Wei", "Ping Nie", "Yiqun Wu", "Dedong Yu"], "title": "Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis", "comment": null, "summary": "Periodontitis and dental caries are common oral diseases affecting billions\nglobally. While observational studies suggest links between these conditions\nand lung cancer, causality remains uncertain. This study used two sample\nMendelian randomization (MR) to explore causal relationships between dental\ntraits (periodontitis, dental caries) and lung cancer subtypes, and to assess\nmediation by pulmonary function. Genetic instruments were derived from the\nlargest available genome wide association studies, including data from 487,823\ndental caries and 506,594 periodontitis cases, as well as lung cancer data from\nthe Transdisciplinary Research of Cancer in Lung consortium. Inverse variance\nweighting was the main analytical method; lung function mediation was assessed\nusing the delta method. The results showed a significant positive causal effect\nof dental caries on overall lung cancer and its subtypes. Specifically, a one\nstandard deviation increase in dental caries incidence was associated with a\n188.0% higher risk of squamous cell lung carcinoma (OR = 2.880, 95% CI =\n1.236--6.713, p = 0.014), partially mediated by declines in forced vital\ncapacity (FVC) and forced expiratory volume in one second (FEV1), accounting\nfor 5.124% and 5.890% of the total effect. No causal effect was found for\nperiodontitis. These findings highlight a causal role of dental caries in lung\ncancer risk and support integrating dental care and pulmonary function\nmonitoring into cancer prevention strategies.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u9f8b\u9f7f\u4e0e\u80ba\u764c\u98ce\u9669\u5b58\u5728\u663e\u8457\u56e0\u679c\u5173\u8054\uff0c\u5c24\u5176\u662f\u9cde\u72b6\u7ec6\u80de\u80ba\u764c\uff0c\u90e8\u5206\u901a\u8fc7\u80ba\u529f\u80fd\u4e0b\u964d\u4ecb\u5bfc\uff1b\u7259\u5468\u708e\u5219\u672a\u53d1\u73b0\u7c7b\u4f3c\u5173\u8054\u3002", "motivation": "\u63a2\u8ba8\u53e3\u8154\u75be\u75c5\uff08\u9f8b\u9f7f\u548c\u7259\u5468\u708e\uff09\u4e0e\u80ba\u764c\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u8bc4\u4f30\u80ba\u529f\u80fd\u7684\u6f5c\u5728\u4e2d\u4ecb\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u53cc\u6837\u672c\u5b5f\u5fb7\u5c14\u968f\u673a\u5316\uff08MR\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u89c4\u6a21\u57fa\u56e0\u7ec4\u5173\u8054\u7814\u7a76\u6570\u636e\uff0c\u4ee5\u9006\u65b9\u5dee\u52a0\u6743\u4e3a\u4e3b\u8981\u5206\u6790\u624b\u6bb5\uff0c\u5e76\u901a\u8fc7delta\u65b9\u6cd5\u8bc4\u4f30\u80ba\u529f\u80fd\u7684\u4e2d\u4ecb\u6548\u5e94\u3002", "result": "\u9f8b\u9f7f\u663e\u8457\u589e\u52a0\u80ba\u764c\u53ca\u5176\u4e9a\u578b\uff08\u5982\u9cde\u72b6\u7ec6\u80de\u80ba\u764c\uff09\u7684\u98ce\u9669\uff08OR=2.880\uff09\uff0c\u90e8\u5206\u7531\u80ba\u529f\u80fd\uff08FVC\u548cFEV1\uff09\u4e0b\u964d\u4ecb\u5bfc\uff1b\u7259\u5468\u708e\u65e0\u663e\u8457\u56e0\u679c\u6548\u5e94\u3002", "conclusion": "\u9f8b\u9f7f\u4e0e\u80ba\u764c\u98ce\u9669\u5b58\u5728\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u793a\u5e94\u5c06\u53e3\u8154\u62a4\u7406\u548c\u80ba\u529f\u80fd\u76d1\u6d4b\u7eb3\u5165\u764c\u75c7\u9884\u9632\u7b56\u7565\u3002"}}
{"id": "2507.18293", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18293", "abs": "https://arxiv.org/abs/2507.18293", "authors": ["Sjoerd van Straten", "Alessandro Padella", "Marwan Hassani"], "title": "Leveraging Data Augmentation and Siamese Learning for Predictive Process Monitoring", "comment": null, "summary": "Predictive Process Monitoring (PPM) enables forecasting future events or\noutcomes of ongoing business process instances based on event logs. However,\ndeep learning PPM approaches are often limited by the low variability and small\nsize of real-world event logs. To address this, we introduce SiamSA-PPM, a\nnovel self-supervised learning framework that combines Siamese learning with\nStatistical Augmentation for Predictive Process Monitoring. It employs three\nnovel statistically grounded transformation methods that leverage control-flow\nsemantics and frequent behavioral patterns to generate realistic, semantically\nvalid new trace variants. These augmented views are used within a Siamese\nlearning setup to learn generalizable representations of process prefixes\nwithout the need for labeled supervision. Extensive experiments on real-life\nevent logs demonstrate that SiamSA-PPM achieves competitive or superior\nperformance compared to the SOTA in both next activity and final outcome\nprediction tasks. Our results further show that statistical augmentation\nsignificantly outperforms random transformations and improves variability in\nthe data, highlighting SiamSA-PPM as a promising direction for training data\nenrichment in process prediction.", "AI": {"tldr": "SiamSA-PPM\u662f\u4e00\u79cd\u7ed3\u5408Siamese\u5b66\u4e60\u548c\u7edf\u8ba1\u589e\u5f3a\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\uff0c\u901a\u8fc7\u751f\u6210\u8bed\u4e49\u6709\u6548\u7684\u8f68\u8ff9\u53d8\u4f53\u63d0\u5347\u6570\u636e\u591a\u6837\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u4e2d\u56e0\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u6570\u636e\u91cf\u5c0f\u548c\u591a\u6837\u6027\u4f4e\u800c\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8e\u7edf\u8ba1\u7684\u8f6c\u6362\u65b9\u6cd5\uff0c\u7ed3\u5408Siamese\u5b66\u4e60\u6846\u67b6\uff0c\u751f\u6210\u8bed\u4e49\u6709\u6548\u7684\u8f68\u8ff9\u53d8\u4f53\uff0c\u7528\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6570\u636e\u589e\u5f3a\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u968f\u673a\u8f6c\u6362\u3002", "conclusion": "SiamSA-PPM\u4e3a\u6d41\u7a0b\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.18447", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.18447", "abs": "https://arxiv.org/abs/2507.18447", "authors": ["Junda Wu", "Jessica Echterhoff", "Kyungtae Han", "Amr Abdelraouf", "Rohit Gupta", "Julian McAuley"], "title": "PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior", "comment": null, "summary": "Understanding a driver's behavior and intentions is important for potential\nrisk assessment and early accident prevention. Safety and driver assistance\nsystems can be tailored to individual drivers' behavior, significantly\nenhancing their effectiveness. However, existing datasets are limited in\ndescribing and explaining general vehicle movements based on external visual\nevidence. This paper introduces a benchmark, PDB-Eval, for a detailed\nunderstanding of Personalized Driver Behavior, and aligning Large Multimodal\nModels (MLLMs) with driving comprehension and reasoning. Our benchmark consists\nof two main components, PDB-X and PDB-QA. PDB-X can evaluate MLLMs'\nunderstanding of temporal driving scenes. Our dataset is designed to find valid\nvisual evidence from the external view to explain the driver's behavior from\nthe internal view. To align MLLMs' reasoning abilities with driving tasks, we\npropose PDB-QA as a visual explanation question-answering task for MLLM\ninstruction fine-tuning. As a generic learning task for generative models like\nMLLMs, PDB-QA can bridge the domain gap without harming MLLMs'\ngeneralizability. Our evaluation indicates that fine-tuning MLLMs on\nfine-grained descriptions and explanations can effectively bridge the gap\nbetween MLLMs and the driving domain, which improves zero-shot performance on\nquestion-answering tasks by up to 73.2%. We further evaluate the MLLMs\nfine-tuned on PDB-X in Brain4Cars' intention prediction and AIDE's recognition\ntasks. We observe up to 12.5% performance improvements on the turn intention\nprediction task in Brain4Cars, and consistent performance improvements up to\n11.0% on all tasks in AIDE.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aPDB-Eval\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u63d0\u5347\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08MLLMs\uff09\u5728\u9a7e\u9a76\u884c\u4e3a\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u62ec\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1aPDB-X\u548cPDB-QA\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9a7e\u9a76\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u5728\u57fa\u4e8e\u5916\u90e8\u89c6\u89c9\u8bc1\u636e\u63cf\u8ff0\u548c\u89e3\u91ca\u9a7e\u9a76\u5458\u884c\u4e3a\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6765\u63d0\u5347MLLMs\u5728\u9a7e\u9a76\u9886\u57df\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86PDB-Eval\u57fa\u51c6\uff0c\u5305\u62ecPDB-X\uff08\u8bc4\u4f30MLLMs\u5bf9\u9a7e\u9a76\u573a\u666f\u7684\u7406\u89e3\uff09\u548cPDB-QA\uff08\u7528\u4e8eMLLMs\u6307\u4ee4\u5fae\u8c03\u7684\u89c6\u89c9\u89e3\u91ca\u95ee\u7b54\u4efb\u52a1\uff09\u3002\u901a\u8fc7\u5fae\u8c03MLLMs\uff0c\u63d0\u5347\u5176\u5728\u9a7e\u9a76\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5fae\u8c03\u540e\u7684MLLMs\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u96f6\u6837\u672c\u6027\u80fd\u63d0\u5347\u4e8673.2%\uff0c\u5728Brain4Cars\u548cAIDE\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e8612.5%\u548c11.0%\u3002", "conclusion": "PDB-Eval\u57fa\u51c6\u80fd\u591f\u6709\u6548\u7f29\u5c0fMLLMs\u4e0e\u9a7e\u9a76\u9886\u57df\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u9a7e\u9a76\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.18552", "categories": ["cs.CV", "cs.AI", "68T45, 68T50, 68U35,", "I.4.8; I.2.7; I.2.10; H.5.1"], "pdf": "https://arxiv.org/pdf/2507.18552", "abs": "https://arxiv.org/abs/2507.18552", "authors": ["Baoyao Yang", "Wanyun Li", "Dixin Chen", "Junxiang Chen", "Wenbin Yao", "Haifeng Lin"], "title": "VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding", "comment": "7 pages; 14 figures", "summary": "This paper introduces VideoMind, a video-centric omni-modal dataset designed\nfor deep video content cognition and enhanced multi-modal feature\nrepresentation. The dataset comprises 103K video samples (3K reserved for\ntesting), each paired with audio and systematically detailed textual\ndescriptions. Specifically, every video and its audio is described across three\nhierarchical layers (factual, abstract, and intent), progressing from surface\nto depth. It contains over 22 million words, averaging ~225 words per sample.\nVideoMind's key distinction from existing datasets is its provision of intent\nexpressions, which require contextual integration across the entire video and\nare not directly observable. These deep-cognitive expressions are generated\nusing a Chain-of-Thought (COT) approach, prompting the mLLM through\nstep-by-step reasoning. Each description includes annotations for subject,\nplace, time, event, action, and intent, supporting downstream recognition\ntasks. Crucially, we establish a gold-standard benchmark with 3,000 manually\nvalidated samples for evaluating deep-cognitive video understanding. We design\nhybrid-cognitive retrieval experiments, scored by multi-level retrieval\nmetrics, to appropriately assess deep video comprehension. Evaluation results\nfor models (e.g., InternVideo, VAST, UMT-L) are released. VideoMind serves as a\npowerful benchmark for fine-grained cross-modal alignment and advances fields\nrequiring in-depth video understanding, such as emotion and intent recognition.\nThe data is publicly available on GitHub, HuggingFace, and OpenDataLab,\nhttps://github.com/cdx-cindy/VideoMind.", "AI": {"tldr": "VideoMind\u662f\u4e00\u4e2a\u89c6\u9891\u4e3a\u4e2d\u5fc3\u7684\u5168\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6df1\u5ea6\u89c6\u9891\u5185\u5bb9\u8ba4\u77e5\u548c\u591a\u6a21\u6001\u7279\u5f81\u8868\u793a\u589e\u5f3a\u3002\u5b83\u5305\u542b103K\u89c6\u9891\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u914d\u6709\u97f3\u9891\u548c\u8be6\u7ec6\u6587\u672c\u63cf\u8ff0\uff0c\u7279\u522b\u63d0\u4f9b\u610f\u56fe\u8868\u8fbe\uff0c\u5e76\u901a\u8fc7Chain-of-Thought\u65b9\u6cd5\u751f\u6210\u3002\u6570\u636e\u96c6\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u8bc4\u4f30\uff0c\u5e76\u516c\u5f00\u4e86\u6a21\u578b\u8bc4\u6d4b\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u6df1\u5ea6\u8ba4\u77e5\u8868\u8fbe\uff08\u5982\u610f\u56fe\uff09\uff0cVideoMind\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a8\u52a8\u89c6\u9891\u7406\u89e3\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u6570\u636e\u96c6\u5305\u542b103K\u89c6\u9891\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u914d\u6709\u97f3\u9891\u548c\u4e09\u5c42\u6587\u672c\u63cf\u8ff0\uff08\u4e8b\u5b9e\u3001\u62bd\u8c61\u3001\u610f\u56fe\uff09\uff0c\u91c7\u7528Chain-of-Thought\u65b9\u6cd5\u751f\u6210\u6df1\u5ea6\u8ba4\u77e5\u8868\u8fbe\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b3K\u624b\u52a8\u9a8c\u8bc1\u6837\u672c\u7684\u9ec4\u91d1\u6807\u51c6\u57fa\u51c6\uff0c\u652f\u6301\u6df1\u5ea6\u89c6\u9891\u7406\u89e3\u8bc4\u4f30\uff0c\u5e76\u516c\u5f00\u4e86\u6a21\u578b\u8bc4\u6d4b\u7ed3\u679c\u3002", "conclusion": "VideoMind\u4e3a\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5f3a\u5927\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u9700\u8981\u6df1\u5ea6\u89c6\u9891\u7406\u89e3\u7684\u9886\u57df\uff08\u5982\u60c5\u611f\u548c\u610f\u56fe\u8bc6\u522b\uff09\u3002"}}
