<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 16]
- [cs.LG](#cs.LG) [Total: 13]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TESPEC: Temporally-Enhanced Self-Supervised Pretraining for Event Cameras](https://arxiv.org/abs/2508.00913)
*Mohammad Mohammadi,Ziyi Wu,Igor Gilitschenski*

Main category: cs.CV

TL;DR: TESPEC是一个自监督预训练框架，专为学习事件数据的时空信息设计，特别适合循环模型，通过长事件序列预训练提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法忽略事件数据的长期时间信息，而循环模型在从头训练时表现优于前馈模型，但预训练时前馈模型更优。TESPEC旨在解决这一问题。

Method: TESPEC采用掩码图像建模范式，设计新重建目标，将事件累积为伪灰度视频，减少噪声和运动模糊，要求模型推理长期事件历史。

Result: 在目标检测、语义分割和单目深度估计等下游任务中，TESPEC取得了最先进的结果。

Conclusion: TESPEC通过利用长事件序列预训练，显著提升了循环模型在事件感知任务中的性能。

Abstract: Long-term temporal information is crucial for event-based perception tasks,
as raw events only encode pixel brightness changes. Recent works show that when
trained from scratch, recurrent models achieve better results than feedforward
models in these tasks. However, when leveraging self-supervised pre-trained
weights, feedforward models can outperform their recurrent counterparts.
Current self-supervised learning (SSL) methods for event-based pre-training
largely mimic RGB image-based approaches. They pre-train feedforward models on
raw events within a short time interval, ignoring the temporal information of
events. In this work, we introduce TESPEC, a self-supervised pre-training
framework tailored for learning spatio-temporal information. TESPEC is
well-suited for recurrent models, as it is the first framework to leverage long
event sequences during pre-training. TESPEC employs the masked image modeling
paradigm with a new reconstruction target. We design a novel method to
accumulate events into pseudo grayscale videos containing high-level semantic
information about the underlying scene, which is robust to sensor noise and
reduces motion blur. Reconstructing this target thus requires the model to
reason about long-term history of events. Extensive experiments demonstrate our
state-of-the-art results in downstream tasks, including object detection,
semantic segmentation, and monocular depth estimation. Project webpage:
https://mhdmohammadi.github.io/TESPEC_webpage.

</details>


### [2] [Optimizing Vision-Language Consistency via Cross-Layer Regional Attention Alignment](https://arxiv.org/abs/2508.00945)
*Yifan Wang,Hongfeng Ai,Quangao Liu,Maowei Jiang,Ruiyuan Kang,Ruiqi Li,Jiahua Dong,Mengting Xiao,Cheng Jiang,Chenzhong Li*

Main category: cs.CV

TL;DR: 论文提出CCRA方法，通过LPWCA和PAI协调跨模态注意力机制，提升视觉语言模型的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在跨模态嵌入学习中存在注意力不匹配和性能不佳的问题。

Method: 提出CCRA，包括LPWCA（层-块交叉注意力）和PAI（渐进注意力集成），以细粒度协调区域语义关联。

Result: 在十个基准测试中，CCRA增强的LLaVA-v1.5-7B模型表现最优，仅增加3.55M参数。

Conclusion: CCRA通过一致性和渐进性设计，显著提升了模型性能和注意力对齐效果。

Abstract: Vision Language Models (VLMs) face challenges in effectively coordinating
diverse attention mechanisms for cross-modal embedding learning, leading to
mismatched attention and suboptimal performance. We propose Consistent
Cross-layer Regional Alignment (CCRA), which introduces Layer-Patch-wise Cross
Attention (LPWCA) to capture fine-grained regional-semantic correlations by
jointly weighting patch and layer-wise embedding, and Progressive Attention
Integration (PAI) that systematically coordinates LPWCA, layer-wise, and
patch-wise attention mechanisms in sequence. This progressive design ensures
consistency from semantic to regional levels while preventing attention drift
and maximizing individual attention benefits. Experimental results on ten
diverse vision-language benchmarks demonstrate that our CCRA-enhanced
LLaVA-v1.5-7B model achieves state-of-the-art performance, outperforming all
baseline methods with only 3.55M additional parameters, while providing
enhanced interpretability through more regionally focused and semantically
aligned attention patterns.

</details>


### [3] [Evading Data Provenance in Deep Neural Networks](https://arxiv.org/abs/2508.01074)
*Hongyu Zhu,Sichu Liang,Wenwen Wang,Zhuomeng Zhang,Fangqi Li,Shi-Lin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种统一的规避框架，通过教师模型学习版权数据集，并利用OOD数据集转移任务相关知识，成功规避了11种DOV方法，揭示了当前DOV方法的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型高度依赖数据，但许多数据集是专有或敏感的，DOV方法用于保护版权。然而，现有研究对规避攻击的评估过于简化，导致虚假的安全感。

Method: 提出统一规避框架，教师模型学习版权数据后，通过OOD数据集转移任务相关知识，利用视觉语言模型和大语言模型筛选信息子集，选择性转移知识。

Result: 实验表明，该方法能消除所有版权标识符，在泛化性和有效性上显著优于九种现有规避攻击，计算开销适中。

Conclusion: 揭示了当前DOV方法的关键漏洞，强调需要长期发展以提升实用性。

Abstract: Modern over-parameterized deep models are highly data-dependent, with large
scale general-purpose and domain-specific datasets serving as the bedrock for
rapid advancements. However, many datasets are proprietary or contain sensitive
information, making unrestricted model training problematic. In the open world
where data thefts cannot be fully prevented, Dataset Ownership Verification
(DOV) has emerged as a promising method to protect copyright by detecting
unauthorized model training and tracing illicit activities. Due to its
diversity and superior stealth, evading DOV is considered extremely
challenging. However, this paper identifies that previous studies have relied
on oversimplistic evasion attacks for evaluation, leading to a false sense of
security. We introduce a unified evasion framework, in which a teacher model
first learns from the copyright dataset and then transfers task-relevant yet
identifier-independent domain knowledge to a surrogate student using an
out-of-distribution (OOD) dataset as the intermediary. Leveraging
Vision-Language Models and Large Language Models, we curate the most
informative and reliable subsets from the OOD gallery set as the final transfer
set, and propose selectively transferring task-oriented knowledge to achieve a
better trade-off between generalization and evasion effectiveness. Experiments
across diverse datasets covering eleven DOV methods demonstrate our approach
simultaneously eliminates all copyright identifiers and significantly
outperforms nine state-of-the-art evasion attacks in both generalization and
effectiveness, with moderate computational overhead. As a proof of concept, we
reveal key vulnerabilities in current DOV methods, highlighting the need for
long-term development to enhance practicality.

</details>


### [4] [RoadMamba: A Dual Branch Visual State Space Model for Road Surface Classification](https://arxiv.org/abs/2508.01210)
*Tianze Wang,Zhang Zhang,Chao Yue,Nuoran Li,Chao Sun*

Main category: cs.CV

TL;DR: 论文提出了一种名为RoadMamba的方法，结合局部和全局感知技术，用于道路表面分类任务，并在大规模数据集上取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 通过视觉技术提前获取道路表面条件，为自动驾驶车辆的规划与控制系统提供有效信息，从而提高安全性和驾驶舒适性。

Method: 利用双状态空间模型（DualSSM）提取道路表面的全局语义和局部纹理，并通过双注意力融合（DAF）解码和融合双重特征；提出双辅助损失函数以约束网络。

Result: 在包含100万样本的大规模道路表面分类数据集上，RoadMamba达到了最优性能。

Conclusion: RoadMamba方法通过结合局部和全局感知，显著提升了道路表面分类的准确性。

Abstract: Acquiring the road surface conditions in advance based on visual technologies
provides effective information for the planning and control system of
autonomous vehicles, thus improving the safety and driving comfort of the
vehicles. Recently, the Mamba architecture based on state-space models has
shown remarkable performance in visual processing tasks, benefiting from the
efficient global receptive field. However, existing Mamba architectures
struggle to achieve state-of-the-art visual road surface classification due to
their lack of effective extraction of the local texture of the road surface. In
this paper, we explore for the first time the potential of visual Mamba
architectures for road surface classification task and propose a method that
effectively combines local and global perception, called RoadMamba.
Specifically, we utilize the Dual State Space Model (DualSSM) to effectively
extract the global semantics and local texture of the road surface and decode
and fuse the dual features through the Dual Attention Fusion (DAF). In
addition, we propose a dual auxiliary loss to explicitly constrain dual
branches, preventing the network from relying only on global semantic
information from the deep large receptive field and ignoring the local texture.
The proposed RoadMamba achieves the state-of-the-art performance in experiments
on a large-scale road surface classification dataset containing 1 million
samples.

</details>


### [5] [ParaRevSNN: A Parallel Reversible Spiking Neural Network for Efficient Training and Inference](https://arxiv.org/abs/2508.01223)
*Changqing Xu,Guoqing Sun,Yi Liu,Xinfang Liao,Yintang Yang*

Main category: cs.CV

TL;DR: ParaRevSNN是一种并行可逆SNN架构，通过解耦可逆块间的顺序依赖，显著加速训练和推理，同时保持内存效率。


<details>
  <summary>Details</summary>
Motivation: 解决可逆SNN因严格顺序计算导致的高延迟问题。

Method: 提出ParaRevSNN，解耦可逆块间的顺序依赖，实现块间并行。

Result: 在多个数据集上匹配或超越标准RevSNN的准确率，训练时间减少35.2%，推理时间降至18.15%。

Conclusion: ParaRevSNN适合资源受限场景，兼具高效性和准确性。

Abstract: Reversible Spiking Neural Networks (RevSNNs) enable memory-efficient training
by reconstructing forward activations during backpropagation, but suffer from
high latency due to strictly sequential computation. To overcome this
limitation, we propose ParaRevSNN, a parallel reversible SNN architecture that
decouples sequential dependencies between reversible blocks while preserving
reversibility. This design enables inter-block parallelism, significantly
accelerating training and inference while retaining the memory-saving benefits
of reversibility. Experiments on CIFAR10, CIFAR100, CIFAR10-DVS, and DVS128
Gesture demonstrate that ParaRevSNN matches or exceeds the accuracy of standard
RevSNNs, while reducing training time by up to 35.2\% and inference time to
18.15\%, making it well-suited for deployment in resource-constrained
scenarios.

</details>


### [6] [An Event-based Fast Intensity Reconstruction Scheme for UAV Real-time Perception](https://arxiv.org/abs/2508.02238)
*Xin Dong,Yiwei Zhang,Yangjie Cui,Jinwu Xiang,Daochun Li,Zhan Tu*

Main category: cs.CV

TL;DR: 提出了一种基于事件的单积分（ESI）方法，用于实时高帧率强度图像重建，适用于无人机视觉跟踪等场景。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高动态范围和高时间分辨率等优势，但如何从异步事件流中提取有效信息并实现实时处理是关键挑战。

Method: ESI通过单次积分事件流结合增强衰减算法重建强度图像，实现高帧率（100 FPS）和低计算负载。

Result: ESI在运行时效率、重建质量和帧率上优于现有算法，显著提升了无人机在低光照条件下的感知能力。

Conclusion: ESI方法在极端低光照条件下表现出色，适用于无人机机载视觉跟踪，解决了现有算法的不足。

Abstract: Event cameras offer significant advantages, including a wide dynamic range,
high temporal resolution, and immunity to motion blur, making them highly
promising for addressing challenging visual conditions. Extracting and
utilizing effective information from asynchronous event streams is essential
for the onboard implementation of event cameras. In this paper, we propose a
streamlined event-based intensity reconstruction scheme, event-based single
integration (ESI), to address such implementation challenges. This method
guarantees the portability of conventional frame-based vision methods to
event-based scenarios and maintains the intrinsic advantages of event cameras.
The ESI approach reconstructs intensity images by performing a single
integration of the event streams combined with an enhanced decay algorithm.
Such a method enables real-time intensity reconstruction at a high frame rate,
typically 100 FPS. Furthermore, the relatively low computation load of ESI fits
onboard implementation suitably, such as in UAV-based visual tracking
scenarios. Extensive experiments have been conducted to evaluate the
performance comparison of ESI and state-of-the-art algorithms. Compared to
state-of-the-art algorithms, ESI demonstrates remarkable runtime efficiency
improvements, superior reconstruction quality, and a high frame rate. As a
result, ESI enhances UAV onboard perception significantly under visual
adversary surroundings. In-flight tests, ESI demonstrates effective performance
for UAV onboard visual tracking under extremely low illumination
conditions(2-10lux), whereas other comparative algorithms fail due to
insufficient frame rate, poor image quality, or limited real-time performance.

</details>


### [7] [A Spatio-temporal Continuous Network for Stochastic 3D Human Motion Prediction](https://arxiv.org/abs/2508.01585)
*Hua Yu,Yaqing Hou,Xu Gui,Shanshan Feng,Dongsheng Zhou,Qiang Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为STCN的两阶段方法，用于解决随机人类运动预测中的连续时间动态学习和模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成连续时间动态和随机运动序列时面临挑战，且容易忽视复杂人类运动的灵活性并导致模式崩溃。

Method: STCN分为两阶段：第一阶段通过时空连续网络生成更平滑的运动序列，并引入锚点集防止模式崩溃；第二阶段学习观测运动序列的高斯混合分布，并通过多序列采样缓解类内差异。

Result: 在Human3.6M和HumanEva-I数据集上，STCN在多样性和准确性上均表现出竞争力。

Conclusion: STCN通过两阶段设计和锚点集策略，有效提升了随机人类运动预测的性能。

Abstract: Stochastic Human Motion Prediction (HMP) has received increasing attention
due to its wide applications. Despite the rapid progress in generative fields,
existing methods often face challenges in learning continuous temporal dynamics
and predicting stochastic motion sequences. They tend to overlook the
flexibility inherent in complex human motions and are prone to mode collapse.
To alleviate these issues, we propose a novel method called STCN, for
stochastic and continuous human motion prediction, which consists of two
stages. Specifically, in the first stage, we propose a spatio-temporal
continuous network to generate smoother human motion sequences. In addition,
the anchor set is innovatively introduced into the stochastic HMP task to
prevent mode collapse, which refers to the potential human motion patterns. In
the second stage, STCN endeavors to acquire the Gaussian mixture distribution
(GMM) of observed motion sequences with the aid of the anchor set. It also
focuses on the probability associated with each anchor, and employs the
strategy of sampling multiple sequences from each anchor to alleviate
intra-class differences in human motions. Experimental results on two
widely-used datasets (Human3.6M and HumanEva-I) demonstrate that our model
obtains competitive performance on both diversity and accuracy.

</details>


### [8] [TimeExpert: An Expert-Guided Video LLM for Video Temporal Grounding](https://arxiv.org/abs/2508.01699)
*Zuhao Yang,Yingchen Yu,Yunqing Zhao,Shijian Lu,Song Bai*

Main category: cs.CV

TL;DR: TimeExpert是一种基于Mixture-of-Experts的视频大语言模型，通过动态路由任务特定令牌（如时间戳、显著性分数）到专门专家，提升了视频时间定位任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型对所有任务令牌采用相同的静态处理路径，无法区分时间定位、显著性评估和文本生成等不同任务的需求。

Method: 提出TimeExpert，利用Mixture-of-Experts架构，动态路由任务特定令牌到专门专家，提高计算效率。

Result: 在Dense Video Captioning、Moment Retrieval和Video Highlight Detection等任务上达到最先进性能。

Conclusion: TimeExpert通过任务分解和动态路由，显著提升了视频时间定位任务的性能。

Abstract: Video Temporal Grounding (VTG) aims to precisely identify video event
segments in response to textual queries. The outputs of VTG tasks manifest as
sequences of events, each defined by precise timestamps, saliency scores, and
textual descriptions. Despite recent advances, a fundamental limitation
persists in existing Video Large Language Models (Video-LLMs): they process all
task tokens through identical and static pathways, failing to recognize that
temporal localization, saliency assessment, and textual generation represent
fundamentally distinct tasks requiring specialized processing. To address this,
we introduce TimeExpert, a Mixture-of-Experts (MoE)-based Video-LLM that
effectively decomposes VTG tasks by dynamically routing task-specific tokens
(e.g., timestamps, saliency scores) to specialized experts, with increased
computational efficiency. Our design choices enable precise handling of each
subtask, leading to improved event modeling across diverse VTG applications.
Extensive experiments demonstrate that TimeExpert consistently achieves
state-of-the-art performance on various VTG tasks such as Dense Video
Captioning, Moment Retrieval, and Video Highlight Detection.

</details>


### [9] [OmniEvent: Unified Event Representation Learning](https://arxiv.org/abs/2508.01842)
*Weiqi Yan,Chenlu Lin,Youbiao Wang,Zhipeng Cai,Xiuhong Lin,Yangyang Shi,Weiquan Liu,Yu Zang*

Main category: cs.CV

TL;DR: OmniEvent是一个统一的事件表示学习框架，通过解耦-增强-融合范式解决事件数据的不均匀性问题，无需任务特定设计即可在多任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机在计算机视觉中应用广泛，但事件网络依赖任务特定设计，难以复用现有架构。

Method: 提出解耦-增强-融合范式，独立处理时空特征，利用空间填充曲线提升效率，并通过注意力融合特征。

Result: 在3个代表性任务和10个数据集中，性能提升高达68.2%。

Conclusion: OmniEvent为事件数据提供统一处理框架，显著提升性能并简化架构设计。

Abstract: Event cameras have gained increasing popularity in computer vision due to
their ultra-high dynamic range and temporal resolution. However, event networks
heavily rely on task-specific designs due to the unstructured data distribution
and spatial-temporal (S-T) inhomogeneity, making it hard to reuse existing
architectures for new tasks. We propose OmniEvent, the first unified event
representation learning framework that achieves SOTA performance across diverse
tasks, fully removing the need of task-specific designs. Unlike previous
methods that treat event data as 3D point clouds with manually tuned S-T
scaling weights, OmniEvent proposes a decouple-enhance-fuse paradigm, where the
local feature aggregation and enhancement is done independently on the spatial
and temporal domains to avoid inhomogeneity issues. Space-filling curves are
applied to enable large receptive fields while improving memory and compute
efficiency. The features from individual domains are then fused by attention to
learn S-T interactions. The output of OmniEvent is a grid-shaped tensor, which
enables standard vision models to process event data without architecture
change. With a unified framework and similar hyper-parameters, OmniEvent
out-performs (tasks-specific) SOTA by up to 68.2% across 3 representative tasks
and 10 datasets (Fig.1). Code will be ready in
https://github.com/Wickyan/OmniEvent .

</details>


### [10] [StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding](https://arxiv.org/abs/2508.01875)
*Haolin Yang,Feilong Tang,Linxiao Zhao,Xiang An,Ming Hu,Huifa Li,Xinlin Zhuang,Boqian Wang,Yifan Lu,Xiaofeng Zhang,Abdalla Swikir,Junjun He,Zongyuan Ge,Imran Razzak*

Main category: cs.CV

TL;DR: 提出了一种名为StreamAgent的方法，用于实时视频流理解，通过预测未来任务相关信息的时间和空间区域，实现主动决策和响应。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实时视频流处理中缺乏任务驱动的规划和未来预测，限制了响应速度和决策能力。

Method: 结合问题语义和历史观察，通过提示预测关键事件的时间进展，调整感知动作，并设计了一种高效的流式KV缓存机制。

Result: 在流式和长视频理解任务中，该方法在响应准确性和实时效率上优于现有方法。

Conclusion: StreamAgent在实时视频流场景中具有实用价值，能够显著提升主动决策和响应能力。

Abstract: Real-time streaming video understanding in domains such as autonomous driving
and intelligent surveillance poses challenges beyond conventional offline video
processing, requiring continuous perception, proactive decision making, and
responsive interaction based on dynamically evolving visual content. However,
existing methods rely on alternating perception-reaction or asynchronous
triggers, lacking task-driven planning and future anticipation, which limits
their real-time responsiveness and proactive decision making in evolving video
streams. To this end, we propose a StreamAgent that anticipates the temporal
intervals and spatial regions expected to contain future task-relevant
information to enable proactive and goal-driven responses. Specifically, we
integrate question semantics and historical observations through prompting the
anticipatory agent to anticipate the temporal progression of key events, align
current observations with the expected future evidence, and subsequently adjust
the perception action (e.g., attending to task-relevant regions or continuously
tracking in subsequent frames). To enable efficient inference, we design a
streaming KV-cache memory mechanism that constructs a hierarchical memory
structure for selective recall of relevant tokens, enabling efficient semantic
retrieval while reducing the overhead of storing all tokens in the traditional
KV-cache. Extensive experiments on streaming and long video understanding tasks
demonstrate that our method outperforms existing methods in response accuracy
and real-time efficiency, highlighting its practical value for real-world
streaming scenarios.

</details>


### [11] [Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention](https://arxiv.org/abs/2508.02004)
*Kyungmin Jo,Jooyeol Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 本文提出了一种新的自注意力修改方法（Stratified Attention），解决了现有图像提示生成方法中的两个问题：分类器自由引导中的冲突信号以及生成图像真实感与图像提示对齐之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型难以捕捉复杂细节（如纹理），导致用户意图无法完全体现。虽然已有方法通过修改自注意力机制引入图像提示，但仍存在分类器自由引导中的冲突信号和真实感与对齐的权衡问题。

Method: 提出冲突自由引导（conflict-free guidance），仅将图像提示作为期望条件；提出分层注意力（Stratified Attention），联合使用图像提示和生成图像的键值，而非二选一。

Result: 在三种图像生成任务中，所提方法在忠实反映图像提示方面优于现有模型。

Conclusion: 通过冲突自由引导和分层注意力，本文方法显著提升了生成图像对图像提示的忠实度，同时平衡了真实感与对齐。

Abstract: While large-scale text-to-image diffusion models enable the generation of
high-quality, diverse images from text prompts, these prompts struggle to
capture intricate details, such as textures, preventing the user intent from
being reflected. This limitation has led to efforts to generate images
conditioned on user-provided images, referred to as image prompts. Recent work
modifies the self-attention mechanism to impose image conditions in generated
images by replacing or concatenating the keys and values from the image prompt.
This enables the self-attention layer to work like a cross-attention layer,
generally used to incorporate text prompts. In this paper, we identify two
common issues in existing methods of modifying self-attention to generate
images that reflect the details of image prompts. First, existing approaches
neglect the importance of image prompts in classifier-free guidance.
Specifically, current methods use image prompts as both desired and undesired
conditions in classifier-free guidance, causing conflicting signals. To resolve
this, we propose conflict-free guidance by using image prompts only as desired
conditions, ensuring that the generated image faithfully reflects the image
prompt. In addition, we observe that the two most common self-attention
modifications involve a trade-off between the realism of the generated image
and alignment with the image prompt. Specifically, selecting more keys and
values from the image prompt improves alignment, while selecting more from the
generated image enhances realism. To balance both, we propose an new
self-attention modification method, Stratified Attention to jointly use keys
and values from both images rather than selecting between them. Through
extensive experiments across three image generation tasks, we show that the
proposed method outperforms existing image-prompting models in faithfully
reflecting the image prompt.

</details>


### [12] [Beyond RGB and Events: Enhancing Object Detection under Adverse Lighting with Monocular Normal Maps](https://arxiv.org/abs/2508.02127)
*Mingjie Liu,Hanqing Liu,Chuang Zhu*

Main category: cs.CV

TL;DR: 提出了一种多模态检测框架NRE-Net，融合RGB图像、事件流和法线图，显著提升了恶劣光照条件下的物体检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决恶劣光照条件下物体检测的挑战，特别是由反射引起的误检问题，现有RGB或事件数据单独使用效果不佳。

Method: 提出NRE-Net框架，结合RGB图像、事件流和法线图，通过自适应双流融合模块（ADFM）和事件模态感知融合模块（EAFM）优化多模态融合。

Result: 在DSEC-Det-sub和PKU-DAVIS-SOD数据集上，NRE-Net显著优于现有方法，mAP50分别提升7.9%和6.1%。

Conclusion: NRE-Net通过多模态融合有效抑制误检，提升了恶劣光照条件下的检测性能。

Abstract: Accurate object detection under adverse lighting conditions is critical for
real-world applications such as autonomous driving. Although neuromorphic event
cameras have been introduced to handle these scenarios, adverse lighting often
induces distracting reflections from tunnel walls or road surfaces, which
frequently lead to false obstacle detections. However, neither RGB nor event
data alone is robust enough to address these complexities, and mitigating these
issues without additional sensors remains underexplored. To overcome these
challenges, we propose leveraging normal maps, directly predicted from
monocular RGB images, as robust geometric cues to suppress false positives and
enhance detection accuracy. We introduce NRE-Net, a novel multi-modal detection
framework that effectively fuses three complementary modalities: monocularly
predicted surface normal maps, RGB images, and event streams. To optimize the
fusion process, our framework incorporates two key modules: the Adaptive
Dual-stream Fusion Module (ADFM), which integrates RGB and normal map features,
and the Event-modality Aware Fusion Module (EAFM), which adapts to the high
dynamic range characteristics of event data. Extensive evaluations on the
DSEC-Det-sub and PKU-DAVIS-SOD datasets demonstrate that NRE-Net significantly
outperforms state-of-the-art methods. Our approach achieves mAP50 improvements
of 7.9% and 6.1% over frame-based approaches (e.g., YOLOX), while surpassing
the fusion-based SFNet by 2.7% on the DSEC-Det-sub dataset and SODFormer by
7.1% on the PKU-DAVIS-SOD dataset.

</details>


### [13] [Unleashing the Temporal Potential of Stereo Event Cameras for Continuous-Time 3D Object Detection](https://arxiv.org/abs/2508.02288)
*Jae-Young Kang,Hoonhee Cho,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 提出了一种仅依赖事件相机的立体3D物体检测框架，通过双滤波器机制提取语义和几何信息，并在动态环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR和RGB相机在高动态场景中存在感知间隙，而现有结合事件相机的方法依赖同步传感器，难以应对快速运动。

Method: 提出仅使用事件相机的立体3D检测框架，引入双滤波器机制提取语义和几何信息，并通过目标中心信息对齐边界框。

Result: 实验表明，该方法在动态环境中优于现有方法，验证了事件相机在连续时间3D感知中的潜力。

Conclusion: 事件相机可作为独立传感器实现鲁棒的3D物体检测，尤其在高速场景中表现优异。

Abstract: 3D object detection is essential for autonomous systems, enabling precise
localization and dimension estimation. While LiDAR and RGB cameras are widely
used, their fixed frame rates create perception gaps in high-speed scenarios.
Event cameras, with their asynchronous nature and high temporal resolution,
offer a solution by capturing motion continuously. The recent approach, which
integrates event cameras with conventional sensors for continuous-time
detection, struggles in fast-motion scenarios due to its dependency on
synchronized sensors. We propose a novel stereo 3D object detection framework
that relies solely on event cameras, eliminating the need for conventional 3D
sensors. To compensate for the lack of semantic and geometric information in
event data, we introduce a dual filter mechanism that extracts both.
Additionally, we enhance regression by aligning bounding boxes with
object-centric information. Experiments show that our method outperforms prior
approaches in dynamic environments, demonstrating the potential of event
cameras for robust, continuous-time 3D perception. The code is available at
https://github.com/mickeykang16/Ev-Stereo3D.

</details>


### [14] [Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning](https://arxiv.org/abs/2508.02293)
*Muhammad Aqeel,Shakiba Sharifi,Marco Cristani,Francesco Setti*

Main category: cs.CV

TL;DR: 论文提出了一种名为Confident Meta-learning (CoMet)的新训练策略，用于深度异常检测模型，能够在未筛选的数据集上学习，无需显式过滤。


<details>
  <summary>Details</summary>
Motivation: 传统无监督异常检测假设所有训练数据均为正常样本，需人工筛选数据，引入偏差且适应性受限。

Method: CoMet结合Soft Confident Learning（降低低置信度样本权重）和Meta-Learning（通过训练验证损失协方差正则化更新），防止过拟合并增强对噪声数据的鲁棒性。

Result: 在MVTec-AD、VIADUCT和KSDD2数据集上，CoMet显著优于基线方法，对训练集中的异常不敏感，并在所有数据集上达到新SOTA。

Conclusion: CoMet是一种模型无关的方法，适用于任何基于梯度下降的异常检测模型，有效解决了传统方法的局限性。

Abstract: So-called unsupervised anomaly detection is better described as
semi-supervised, as it assumes all training data are nominal. This assumption
simplifies training but requires manual data curation, introducing bias and
limiting adaptability. We propose Confident Meta-learning (CoMet), a novel
training strategy that enables deep anomaly detection models to learn from
uncurated datasets where nominal and anomalous samples coexist, eliminating the
need for explicit filtering. Our approach integrates Soft Confident Learning,
which assigns lower weights to low-confidence samples, and Meta-Learning, which
stabilizes training by regularizing updates based on training validation loss
covariance. This prevents overfitting and enhances robustness to noisy data.
CoMet is model-agnostic and can be applied to any anomaly detection method
trainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2
with two state-of-the-art models demonstrate the effectiveness of our approach,
consistently improving over the baseline methods, remaining insensitive to
anomalies in the training set, and setting a new state-of-the-art across all
datasets.

</details>


### [15] [Whole-body Representation Learning For Competing Preclinical Disease Risk Assessment](https://arxiv.org/abs/2508.02307)
*Dmitrii Seletkov,Sophie Starck,Ayhan Can Erdur,Yundi Zhang,Daniel Rueckert,Rickmer Braren*

Main category: cs.CV

TL;DR: 提出了一种基于全身自监督表示学习的方法，用于多疾病风险预测，优于传统方法，并展示了在临床工作流程中的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的风险预测方法通常仅针对单一疾病且依赖手工特征，限制了其应用范围和准确性。

Method: 采用全身自监督表示学习方法，结合竞争风险模型，进行多疾病风险预测。

Result: 在心血管疾病、糖尿病等多种疾病中表现优于传统方法，并能进一步细化心血管亚组的预测。

Conclusion: 该方法具有作为独立筛查工具或多模态框架一部分的临床转化潜力。

Abstract: Reliable preclinical disease risk assessment is essential to move public
healthcare from reactive treatment to proactive identification and prevention.
However, image-based risk prediction algorithms often consider one condition at
a time and depend on hand-crafted features obtained through segmentation tools.
We propose a whole-body self-supervised representation learning method for the
preclinical disease risk assessment under a competing risk modeling. This
approach outperforms whole-body radiomics in multiple diseases, including
cardiovascular disease (CVD), type 2 diabetes (T2D), chronic obstructive
pulmonary disease (COPD), and chronic kidney disease (CKD). Simulating a
preclinical screening scenario and subsequently combining with cardiac MRI, it
sharpens further the prediction for CVD subgroups: ischemic heart disease
(IHD), hypertensive diseases (HD), and stroke. The results indicate the
translational potential of whole-body representations as a standalone screening
modality and as part of a multi-modal framework within clinical workflows for
early personalized risk stratification. The code is available at
https://github.com/yayapa/WBRLforCR/

</details>


### [16] [HGTS-Former: Hierarchical HyperGraph Transformer for Multivariate Time Series Analysis](https://arxiv.org/abs/2508.02411)
*Xiao Wang,Hao Si,Fan Zhang,Xiaoya Zhou,Dengdi Sun,Wanli Lyu,Qingquan Yang,Jin Tang*

Main category: cs.CV

TL;DR: 论文提出了一种基于超图的时间序列变换器网络（HGTS-Former），用于解决多变量时间序列数据的高维性和复杂交互问题。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列分析因其高维性和动态性而具有挑战性，现有方法难以捕捉变量间的复杂耦合关系。

Method: 通过多头自注意力增强时间表示，构建分层超图以聚合时间模式和变量间细粒度关系，并通过EdgeToNode模块和前馈网络进一步优化特征。

Result: 在多个数据集上的实验验证了HGTS-Former的有效性。

Conclusion: HGTS-Former为解决多变量时间序列分析问题提供了一种新方法，代码将开源。

Abstract: Multivariate time series analysis has long been one of the key research
topics in the field of artificial intelligence. However, analyzing complex time
series data remains a challenging and unresolved problem due to its high
dimensionality, dynamic nature, and complex interactions among variables.
Inspired by the strong structural modeling capability of hypergraphs, this
paper proposes a novel hypergraph-based time series transformer backbone
network, termed HGTS-Former, to address the multivariate coupling in time
series data. Specifically, given the multivariate time series signal, we first
normalize and embed each patch into tokens. Then, we adopt the multi-head
self-attention to enhance the temporal representation of each patch. The
hierarchical hypergraphs are constructed to aggregate the temporal patterns
within each channel and fine-grained relations between different variables.
After that, we convert the hyperedge into node features through the EdgeToNode
module and adopt the feed-forward network to further enhance the output
features. Extensive experiments conducted on two multivariate time series tasks
and eight datasets fully validated the effectiveness of our proposed
HGTS-Former. The source code will be released on
https://github.com/Event-AHU/Time_Series_Analysis.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [17] [A Dynamic, Context-Aware Framework for Risky Driving Prediction Using Naturalistic Data](https://arxiv.org/abs/2508.00888)
*Amir Hossein Kalantari,Eleonora Papadimitriou,Amir Pooyan Afghari*

Main category: cs.LG

TL;DR: 该研究提出了一种动态个性化的框架，用于识别比利时自然驾驶数据中的危险驾驶行为，通过滚动时间窗口和双层优化动态校准风险阈值和模型超参数。


<details>
  <summary>Details</summary>
Motivation: 现有框架依赖固定时间窗口和静态阈值，无法适应真实驾驶的随机性，因此需要动态和个性化的方法来提高风险检测的准确性。

Method: 采用滚动时间窗口和双层优化技术，动态校准风险阈值和模型超参数，评估了三种数据驱动模型（随机森林、XGBoost和深度神经网络）在两种安全指标上的表现。

Result: 深度神经网络在高召回任务中表现优异，XGBoost在平衡性和稳定性上最佳，随机森林对动态阈值调整敏感。速度加权车距比激烈驾驶事件更稳定且上下文敏感。

Conclusion: 自适应和个性化的风险检测方法对实时安全反馈和智能交通系统中的驾驶员支持具有重要价值。

Abstract: Naturalistic driving studies offer a powerful means for observing and
quantifying real-world driving behaviour. One of their prominent applications
in traffic safety is the continuous monitoring and classification of risky
driving behaviour. However, many existing frameworks rely on fixed time windows
and static thresholds for distinguishing between safe and risky behaviour -
limiting their ability to respond to the stochastic nature of real-world
driving. This study proposes a dynamic and individualised framework for
identifying risky driving behaviour using Belgian naturalistic driving data.
The approach leverages a rolling time window and bi-level optimisation to
dynamically calibrate both risk thresholds and model hyperparameters, capturing
subtle behavioural shifts. Two safety indicators, speed-weighted headway and
harsh driving events, were evaluated using three data-driven models: Random
Forest, XGBoost, and Deep Neural Network (DNN). The DNN demonstrated strong
capability in capturing subtle changes in driving behaviour, particularly
excelling in high-recall tasks, making it promising for early-stage risk
detection. XGBoost provided the most balanced and stable performance across
different thresholds and evaluation metrics. While random forest showed more
variability, it responded sensitively to dynamic threshold adjustments, which
may be advantageous during model adaptation or tuning. Speed-weighted headway
emerged as a more stable and context-sensitive risk indicator than harsh
driving events, likely due to its robustness to label sparsity and contextual
variation. Overall, the findings support the value of adaptive, personalised
risk detection approaches for enhancing real-time safety feedback and tailoring
driver support in intelligent transport systems.

</details>


### [18] [Beyond Benchmarks: Dynamic, Automatic And Systematic Red-Teaming Agents For Trustworthy Medical Language Models](https://arxiv.org/abs/2508.00923)
*Jiazhen Pan,Bailiang Jian,Paul Hager,Yundi Zhang,Che Liu,Friedrike Jungmann,Hongwei Bran Li,Chenyu You,Junde Wu,Jiayuan Zhu,Fenglin Liu,Yuyuan Liu,Niklas Bubeck,Christian Wachinger,Chen,Chen,Zhenyu Gong,Cheng Ouyang,Georgios Kaissis,Benedikt Wiestler,Daniel Rueckert*

Main category: cs.LG

TL;DR: 动态、自动、系统化的红队测试框架（DAS）用于持续检测大型语言模型（LLM）在临床实践中的安全性，揭示其在鲁棒性、隐私、偏见/公平性和幻觉方面的显著弱点。


<details>
  <summary>Details</summary>
Motivation: 确保LLM在临床实践中的安全性和可靠性，防止患者受到伤害并促进AI在医疗中的可信应用。

Method: 采用DAS框架，通过对抗性代理动态变异测试用例、识别/演化不安全触发策略并评估响应，实时发现漏洞。

Result: 测试15个LLM发现，静态基准性能与对抗压力下的脆弱性存在显著差异，多个领域失败率高达66%-94%。

Conclusion: DAS框架为医疗AI提供了可进化、可扩展且可靠的安全保障，适用于医院、监管机构和技术供应商。

Abstract: Ensuring the safety and reliability of large language models (LLMs) in
clinical practice is critical to prevent patient harm and promote trustworthy
healthcare applications of AI. However, LLMs are advancing so rapidly that
static safety benchmarks often become obsolete upon publication, yielding only
an incomplete and sometimes misleading picture of model trustworthiness. We
demonstrate that a Dynamic, Automatic, and Systematic (DAS) red-teaming
framework that continuously stress-tests LLMs can reveal significant weaknesses
of current LLMs across four safety-critical domains: robustness, privacy,
bias/fairness, and hallucination. A suite of adversarial agents is applied to
autonomously mutate test cases, identify/evolve unsafe-triggering strategies,
and evaluate responses, uncovering vulnerabilities in real time without human
intervention. Applying DAS to 15 proprietary and open-source LLMs revealed a
stark contrast between static benchmark performance and vulnerability under
adversarial pressure. Despite a median MedQA accuracy exceeding 80\%, 94\% of
previously correct answers failed our dynamic robustness tests. We observed
similarly high failure rates across other domains: privacy leaks were elicited
in 86\% of scenarios, cognitive-bias priming altered clinical recommendations
in 81\% of fairness tests, and we identified hallucination rates exceeding 66\%
in widely used models. Such profound residual risks are incompatible with
routine clinical practice. By converting red-teaming from a static checklist
into a dynamic stress-test audit, DAS red-teaming offers the surveillance that
hospitals/regulators/technology vendors require as LLMs become embedded in
patient chatbots, decision-support dashboards, and broader healthcare
workflows. Our framework delivers an evolvable, scalable, and reliable
safeguard for the next generation of medical AI.

</details>


### [19] [FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph](https://arxiv.org/abs/2508.00961)
*Xiang Li,Penglei Sun,Wanyun Zhou,Zikai Wei,Yongqi Zhang,Xiaowen Chu*

Main category: cs.LG

TL;DR: 论文提出FinKario数据集和FinKario-RAG方法，通过实时整合市场事件和结构化金融知识，提升语言模型在金融分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 个体投资者在金融市场中处于劣势，缺乏专业分析工具。现有知识库更新慢且金融报告非结构化，限制了语言模型的应用效果。

Method: 1. 构建FinKario数据集，包含实时公司基本面和市场事件；2. 提出FinKario-RAG，优化金融知识检索。

Result: FinKario与FinKario-RAG在股票趋势预测中表现优异，分别超越金融语言模型和机构策略18.81%和17.85%。

Conclusion: FinKario和FinKario-RAG有效解决了金融知识更新慢和非结构化问题，显著提升了投资决策能力。

Abstract: Individual investors are significantly outnumbered and disadvantaged in
financial markets, overwhelmed by abundant information and lacking professional
analysis. Equity research reports stand out as crucial resources, offering
valuable insights. By leveraging these reports, large language models (LLMs)
can enhance investors' decision-making capabilities and strengthen financial
analysis. However, two key challenges limit their effectiveness: (1) the rapid
evolution of market events often outpaces the slow update cycles of existing
knowledge bases, (2) the long-form and unstructured nature of financial reports
further hinders timely and context-aware integration by LLMs. To address these
challenges, we tackle both data and methodological aspects. First, we introduce
the Event-Enhanced Automated Construction of Financial Knowledge Graph
(FinKario), a dataset comprising over 305,360 entities, 9,625 relational
triples, and 19 distinct relation types. FinKario automatically integrates
real-time company fundamentals and market events through prompt-driven
extraction guided by professional institutional templates, providing structured
and accessible financial insights for LLMs. Additionally, we propose a
Two-Stage, Graph-Based retrieval strategy (FinKario-RAG), optimizing the
retrieval of evolving, large-scale financial knowledge to ensure efficient and
precise data access. Extensive experiments show that FinKario with FinKario-RAG
achieves superior stock trend prediction accuracy, outperforming financial LLMs
by 18.81% and institutional strategies by 17.85% on average in backtesting.

</details>


### [20] [T2S: Tokenized Skill Scaling for Lifelong Imitation Learning](https://arxiv.org/abs/2508.01167)
*Hongquan Zhang,Jingyu Gong,Zhizhong Zhang,Xin Tan,Yanyun Qu,Yuan Xie*

Main category: cs.LG

TL;DR: 提出了一种名为Tokenized Skill Scaling (T2S)的统一框架，通过参数标记化和语言引导技能扩展，解决了终身模仿学习中灾难性遗忘和新技能学习的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 终身模仿学习的主要挑战在于平衡灾难性遗忘和新技能学习，现有方法通常孤立处理这些问题，忽视了它们的内在关联。

Method: 通过参数标记化将传统Transformer的线性参数映射转换为输入与可学习标记之间的交叉注意力，并引入语言引导技能扩展以实现高效知识迁移。

Result: 实验表明，T2S有效防止灾难性遗忘（平均NBT为1.0%），新技能扩展表现优异（仅需8.0%可训练标记），并实现高效知识迁移（平均FWT为77.7%）。

Conclusion: T2S为终身模仿学习提供了一个有前景的解决方案。

Abstract: The main challenge in lifelong imitation learning lies in the balance between
mitigating catastrophic forgetting of previous skills while maintaining
sufficient capacity for acquiring new ones. However, current approaches
typically address these aspects in isolation, overlooking their internal
correlation in lifelong skill acquisition. We address this limitation with a
unified framework named Tokenized Skill Scaling (T2S). Specifically, by
tokenizing the model parameters, the linear parameter mapping of the
traditional transformer is transformed into cross-attention between input and
learnable tokens, thereby enhancing model scalability through the easy
extension of new tokens. Additionally, we introduce language-guided skill
scaling to transfer knowledge across tasks efficiently and avoid linearly
growing parameters. Extensive experiments across diverse tasks demonstrate that
T2S: 1) effectively prevents catastrophic forgetting (achieving an average NBT
of 1.0% across the three LIBERO task suites), 2) excels in new skill scaling
with minimal increases in trainable parameters (needing only 8.0% trainable
tokens in an average of lifelong tasks), and 3) enables efficient knowledge
transfer between tasks (achieving an average FWT of 77.7% across the three
LIBERO task suites), offering a promising solution for lifelong imitation
learning.

</details>


### [21] [From Taylor Series to Fourier Synthesis: The Periodic Linear Unit](https://arxiv.org/abs/2508.01175)
*Shiko Kudo*

Main category: cs.LG

TL;DR: 论文提出了一种名为PLU的周期性激活函数，通过非单调性和可学习性提升神经网络的表达能力，解决了传统激活函数需要大量参数的问题。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络依赖单调激活函数（如ReLU），需要大规模参数化模型来逼近复杂函数。PLU旨在通过周期性非单调性提升表达能力和参数效率。

Method: 提出周期性线性单元（PLU），结合排斥性重参数化技术，防止激活函数退化为线性函数。

Result: 实验表明，仅含两个PLU神经元的最小MLP能解决螺旋分类任务，而传统激活函数无法完成。

Conclusion: PLU展示了从分段泰勒近似到傅里叶式函数合成的范式转变，显著提升了参数效率。

Abstract: The dominant paradigm in modern neural networks relies on simple,
monotonically-increasing activation functions like ReLU. While effective, this
paradigm necessitates large, massively-parameterized models to approximate
complex functions. In this paper, we introduce the Periodic Linear Unit (PLU),
a learnable sine-wave based activation with periodic non-monotonicity. PLU is
designed for maximum expressive power and numerical stability, achieved through
its formulation and a paired innovation we term Repulsive Reparameterization,
which prevents the activation from collapsing into a non-expressive linear
function. We demonstrate that a minimal MLP with only two PLU neurons can solve
the spiral classification task, a feat impossible for equivalent networks using
standard activations. This suggests a paradigm shift from networks as piecewise
Taylor-like approximators to powerful Fourier-like function synthesizers,
achieving exponential gains in parameter efficiency by placing intelligence in
the neuron itself.

</details>


### [22] [Exploitation Is All You Need... for Exploration](https://arxiv.org/abs/2508.01287)
*Micah Rentschler,Jesse Roberts*

Main category: cs.LG

TL;DR: 研究发现，在满足特定条件下，仅以贪婪目标训练的元强化学习代理也能表现出探索行为。


<details>
  <summary>Details</summary>
Motivation: 解决元强化学习中探索不足的问题，验证贪婪目标是否能自然产生探索行为。

Method: 通过实验验证三个条件（环境结构、代理记忆、长期信用分配）对探索行为的影响。

Result: 在满足环境结构和代理记忆的条件下，贪婪目标训练的代理表现出探索行为。

Conclusion: 探索行为可以在特定条件下自然产生，无需显式激励。

Abstract: Ensuring sufficient exploration is a central challenge when training
meta-reinforcement learning (meta-RL) agents to solve novel environments.
Conventional solutions to the exploration-exploitation dilemma inject explicit
incentives such as randomization, uncertainty bonuses, or intrinsic rewards to
encourage exploration. In this work, we hypothesize that an agent trained
solely to maximize a greedy (exploitation-only) objective can nonetheless
exhibit emergent exploratory behavior, provided three conditions are met: (1)
Recurring Environmental Structure, where the environment features repeatable
regularities that allow past experience to inform future choices; (2) Agent
Memory, enabling the agent to retain and utilize historical interaction data;
and (3) Long-Horizon Credit Assignment, where learning propagates returns over
a time frame sufficient for the delayed benefits of exploration to inform
current decisions. Through experiments in stochastic multi-armed bandits and
temporally extended gridworlds, we observe that, when both structure and memory
are present, a policy trained on a strictly greedy objective exhibits
information-seeking exploratory behavior. We further demonstrate, through
controlled ablations, that emergent exploration vanishes if either
environmental structure or agent memory is absent (Conditions 1 & 2).
Surprisingly, removing long-horizon credit assignment (Condition 3) does not
always prevent emergent exploration-a result we attribute to the
pseudo-Thompson Sampling effect. These findings suggest that, under the right
prerequisites, exploration and exploitation need not be treated as orthogonal
objectives but can emerge from a unified reward-maximization process.

</details>


### [23] [UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting](https://arxiv.org/abs/2508.01426)
*Hang Ni,Weijia Zhang,Hao Liu*

Main category: cs.LG

TL;DR: UniExtreme模型通过自适应频率调制和事件先验增强模块，提升极端天气预测能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在极端天气预测上表现有限，忽视多样极端事件的真实大气模式。

Method: 提出UniExtreme模型，包含自适应频率调制模块（AFM）和事件先验增强模块（EPA）。

Result: 实验显示UniExtreme在极端和一般天气预测中均优于现有方法。

Conclusion: UniExtreme展示了在多样极端场景中的优越适应性。

Abstract: Recent advancements in deep learning have led to the development of
Foundation Models (FMs) for weather forecasting, yet their ability to predict
extreme weather events remains limited. Existing approaches either focus on
general weather conditions or specialize in specific-type extremes, neglecting
the real-world atmospheric patterns of diversified extreme events. In this
work, we identify two key characteristics of extreme events: (1) the spectral
disparity against normal weather regimes, and (2) the hierarchical drivers and
geographic blending of diverse extremes. Along this line, we propose
UniExtreme, a universal extreme weather forecasting foundation model that
integrates (1) an Adaptive Frequency Modulation (AFM) module that captures
region-wise spectral differences between normal and extreme weather, through
learnable Beta-distribution filters and multi-granularity spectral aggregation,
and (2) an Event Prior Augmentation (EPA) module which incorporates
region-specific extreme event priors to resolve hierarchical extreme diversity
and composite extreme schema, via a dual-level memory fusion network. Extensive
experiments demonstrate that UniExtreme outperforms state-of-the-art baselines
in both extreme and general weather forecasting, showcasing superior
adaptability across diverse extreme scenarios.

</details>


### [24] [HT-Transformer: Event Sequences Classification by Accumulating Prefix Information with History Tokens](https://arxiv.org/abs/2508.01474)
*Ivan Karpukhin,Andrey Savchenko*

Main category: cs.LG

TL;DR: Transformers在序列数据建模中表现优异，但在分类任务中常逊于RNNs。研究发现其缺乏单一状态向量表示全局序列，且对比预训练无法捕捉局部上下文。提出历史令牌概念，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索Transformers在分类任务中表现不佳的原因，并提出改进方法。

Method: 引入历史令牌（history tokens）概念，通过预训练积累历史信息。

Result: 在金融、电商和医疗任务中取得显著改进。

Conclusion: 历史令牌有效解决了Transformers的局限性，提升了模型性能。

Abstract: Deep learning has achieved remarkable success in modeling sequential data,
including event sequences, temporal point processes, and irregular time series.
Recently, transformers have largely replaced recurrent networks in these tasks.
However, transformers often underperform RNNs in classification tasks where the
objective is to predict future targets. The reason behind this performance gap
remains largely unexplored. In this paper, we identify a key limitation of
transformers: the absence of a single state vector that provides a compact and
effective representation of the entire sequence. Additionally, we show that
contrastive pretraining of embedding vectors fails to capture local context,
which is crucial for accurate prediction. To address these challenges, we
introduce history tokens, a novel concept that facilitates the accumulation of
historical information during next-token prediction pretraining. Our approach
significantly improves transformer-based models, achieving impressive results
in finance, e-commerce, and healthcare tasks. The code is publicly available on
GitHub.

</details>


### [25] [FlashSVD: Memory-Efficient Inference with Streaming for Low-Rank Models](https://arxiv.org/abs/2508.01506)
*Zishan Shao,Yixiao Wang,Qinsi Wang,Ting Jiang,Zhixu Du,Hancheng Ye,Danyang Zhuo,Yiran Chen,Hai Li*

Main category: cs.LG

TL;DR: FlashSVD是一种新型的端到端流式推理框架，专为SVD压缩的大型语言模型设计，显著减少峰值激活内存和中间临时内存，同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 现有SVD压缩技术在推理时忽略了激活内存的开销，导致无法减少峰值内存，限制了实际部署的可行性。

Method: 通过将低秩投影内核直接融合到自注意力和前馈网络管道中，避免生成全尺寸激活缓冲区，利用SRAM动态处理小片段数据。

Result: 在BERT-Base等基准测试中，FlashSVD将峰值激活内存减少70.2%，中间临时内存减少75%，且无精度损失。

Conclusion: FlashSVD为低秩大型语言模型在内存受限环境中的实际部署提供了可行方案。

Abstract: Singular Value Decomposition (SVD) has recently seen a surge of interest as a
simple yet powerful tool for large language models (LLMs) compression, with a
growing number of works demonstrating 20-80% parameter reductions at minimal
accuracy loss. Previous SVD-based approaches have focused primarily on reducing
the memory footprint of model weights, largely overlooking the additional
activation memory overhead incurred during inference when applying truncated
factors via standard dense CUDA kernels. Our experiments demonstrate that this
activation overhead, scaling with sequence length and hidden dimension,
prevents current SVD compression techniques from achieving any reduction in
peak inference memory, thereby limiting their viability for real-world,
on-device deployments.
  We introduce FlashSVD, a novel, end-to-end rank-aware streaming inference
framework specifically designed for SVD-compressed large language models.
FlashSVD can be seamlessly integrated with any model that employs SVD-based
methods for parameter reduction. By fusing low-rank projection kernels directly
into both the self-attention and feed-forward network (FFN) pipelines, FlashSVD
avoid materializing full-size activation buffers. Instead, small tiles of the
truncated factors are loaded into on-chip SRAM, multiplied and reduced on the
fly, and immediately evicted, preserving high GPU occupancy and adding no extra
latency. On standard encoder benchmarks (e.g., BERT-Base), FlashSVD cuts peak
activation memory by up to 70.2% and intermediate transient memory by 75%, all
while incur no accuracy loss with upstreaming compression methods, offering a
practical path toward memory-constrained deployment of low-rank LLMs.

</details>


### [26] [Drift-aware Collaborative Assistance Mixture of Experts for Heterogeneous Multistream Learning](https://arxiv.org/abs/2508.01598)
*En Yu,Jie Lu,Kun Wang,Xiaoyu Yang,Guangquan Zhang*

Main category: cs.LG

TL;DR: CAMEL框架通过动态协作专家混合学习解决多数据流异质性和概念漂移问题，采用独立系统、动态专家池和协作机制，显著提升泛化能力和适应性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中多数据流的异质性和不可预测的概念漂移使得学习变得困难，现有方法假设流同质且采用静态架构，限制了复杂动态环境中的泛化能力。

Method: CAMEL为每个流分配独立系统，包含专用特征提取器和任务头；动态专家池捕获流特定模式；协作专家通过多头注意力机制整合跨流上下文；AET策略动态管理专家生命周期。

Result: 实验表明CAMEL在多样化多流数据中具有卓越的泛化能力，并能有效应对复杂概念漂移。

Conclusion: CAMEL通过动态协作和专家级可塑性，为多流学习提供了高效且鲁棒的解决方案。

Abstract: Learning from multiple data streams in real-world scenarios is fundamentally
challenging due to intrinsic heterogeneity and unpredictable concept drifts.
Existing methods typically assume homogeneous streams and employ static
architectures with indiscriminate knowledge fusion, limiting generalizability
in complex dynamic environments. To tackle this gap, we propose CAMEL, a
dynamic \textbf{C}ollaborative \textbf{A}ssistance \textbf{M}ixture of
\textbf{E}xperts \textbf{L}earning framework. It addresses heterogeneity by
assigning each stream an independent system with a dedicated feature extractor
and task-specific head. Meanwhile, a dynamic pool of specialized private
experts captures stream-specific idiosyncratic patterns. Crucially,
collaboration across these heterogeneous streams is enabled by a dedicated
assistance expert. This expert employs a multi-head attention mechanism to
distill and integrate relevant context autonomously from all other concurrent
streams. It facilitates targeted knowledge transfer while inherently mitigating
negative transfer from irrelevant sources. Furthermore, we propose an
Autonomous Expert Tuner (AET) strategy, which dynamically manages expert
lifecycles in response to drift. It instantiates new experts for emerging
concepts (freezing prior ones to prevent catastrophic forgetting) and prunes
obsolete ones. This expert-level plasticity provides a robust and efficient
mechanism for online model capacity adaptation. Extensive experiments
demonstrate CAMEL's superior generalizability across diverse multistreams and
exceptional resilience against complex concept drifts.

</details>


### [27] [SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization](https://arxiv.org/abs/2508.01646)
*Minsuk Jang,Changick Kim*

Main category: cs.LG

TL;DR: SPARTA框架利用脉冲时序动态信息，通过竞争门控实现65.4%的稀疏性，将注意力复杂度从O(N^2)降至O(K^2)，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 当前脉冲神经网络（SNNs）主要依赖速率编码，忽视了脉冲时序信息提供的丰富计算线索。

Method: 提出SPARTA框架，利用异质神经元动态和脉冲时序信息实现高效稀疏注意力，通过竞争门控选择最显著的token。

Result: 在DVS-Gesture上达到98.78%的准确率，CIFAR10-DVS和CIFAR-10上分别达到83.06%和95.3%。

Conclusion: 利用脉冲时序动态可显著提升计算效率和准确性。

Abstract: Current Spiking Neural Networks (SNNs) underutilize the temporal dynamics
inherent in spike-based processing, relying primarily on rate coding while
overlooking precise timing information that provides rich computational cues.
We propose SPARTA (Spiking Priority Attention with Resource-Adaptive Temporal
Allocation), a framework that leverages heterogeneous neuron dynamics and
spike-timing information to enable efficient sparse attention. SPARTA
prioritizes tokens based on temporal cues, including firing patterns, spike
timing, and inter-spike intervals, achieving 65.4% sparsity through competitive
gating. By selecting only the most salient tokens, SPARTA reduces attention
complexity from O(N^2) to O(K^2) with k << n, while maintaining high accuracy.
Our method achieves state-of-the-art performance on DVS-Gesture (98.78%) and
competitive results on CIFAR10-DVS (83.06%) and CIFAR-10 (95.3%), demonstrating
that exploiting spike timing dynamics improves both computational efficiency
and accuracy.

</details>


### [28] [The Complexity of Extreme Climate Events on the New Zealand's Kiwifruit Industry](https://arxiv.org/abs/2508.02130)
*Boyuan Zheng,Victor W. Chu,Zhidong Li,Evan Webster,Ashley Rootsey*

Main category: cs.LG

TL;DR: 研究分析了新西兰猕猴桃种植中极端气候事件（霜冻、干旱、极端降雨和热浪）对产量的影响，使用孤立森林算法检测异常，发现不同事件对产量的影响差异显著，并指出当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了极端天气事件，对农业造成挑战，研究旨在量化这些事件对猕猴桃产量的具体影响。

Method: 采用孤立森林算法分析气候历史和极端事件数据，结合猕猴桃产量数据。

Result: 不同极端事件对猕猴桃产量的影响差异显著，当前方法在检测霜冻等事件时存在局限性。

Conclusion: 需整合农场管理策略和气候适应措施，未来研究将采用集成方法以提高检测精度。

Abstract: Climate change has intensified the frequency and severity of extreme weather
events, presenting unprecedented challenges to the agricultural industry
worldwide. In this investigation, we focus on kiwifruit farming in New Zealand.
We propose to examine the impacts of climate-induced extreme events,
specifically frost, drought, extreme rainfall, and heatwave, on kiwifruit
harvest yields. These four events were selected due to their significant
impacts on crop productivity and their prevalence as recorded by climate
monitoring institutions in the country. We employed Isolation Forest, an
unsupervised anomaly detection method, to analyse climate history and recorded
extreme events, alongside with kiwifruit yields. Our analysis reveals
considerable variability in how different types of extreme event affect
kiwifruit yields underscoring notable discrepancies between climatic extremes
and individual farm's yield outcomes. Additionally, our study highlights
critical limitations of current anomaly detection approaches, particularly in
accurately identifying events such as frost. These findings emphasise the need
for integrating supplementary features like farm management strategies with
climate adaptation practices. Our further investigation will employ ensemble
methods that consolidate nearby farms' yield data and regional climate station
features to reduce variance, thereby enhancing the accuracy and reliability of
extreme event detection and the formulation of response strategies.

</details>


### [29] [AutoML-Med: A Framework for Automated Machine Learning in Medical Tabular Data](https://arxiv.org/abs/2508.02625)
*Riccardo Francia,Maurizio Leone,Giorgio Leonardi,Stefania Montani,Marzio Pennisi,Manuel Striani,Sandra D'Alfonso*

Main category: cs.LG

TL;DR: AutoML-Med是一种专为医疗数据集设计的自动化机器学习工具，通过优化预处理和模型选择，解决了数据稀疏和类别不平衡等问题，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 医疗数据集常因缺失值、类别不平衡、特征异质性等问题影响机器学习模型性能，需要一种自动化工具来优化预处理和模型选择。

Method: AutoML-Med结合拉丁超立方采样（LHS）探索预处理方法，利用部分秩相关系数（PRCC）优化关键预处理步骤，并训练模型。

Result: 实验表明，AutoML-Med在两种临床场景中表现优于其他先进工具，平衡准确率和灵敏度更高，尤其适用于稀疏和类别不平衡数据。

Conclusion: AutoML-Med能有效提升医疗数据集的预测性能，简化机器学习在医疗领域的应用。

Abstract: Medical datasets are typically affected by issues such as missing values,
class imbalance, a heterogeneous feature types, and a high number of features
versus a relatively small number of samples, preventing machine learning models
from obtaining proper results in classification and regression tasks. This
paper introduces AutoML-Med, an Automated Machine Learning tool specifically
designed to address these challenges, minimizing user intervention and
identifying the optimal combination of preprocessing techniques and predictive
models. AutoML-Med's architecture incorporates Latin Hypercube Sampling (LHS)
for exploring preprocessing methods, trains models using selected metrics, and
utilizes Partial Rank Correlation Coefficient (PRCC) for fine-tuned
optimization of the most influential preprocessing steps. Experimental results
demonstrate AutoML-Med's effectiveness in two different clinical settings,
achieving higher balanced accuracy and sensitivity, which are crucial for
identifying at-risk patients, compared to other state-of-the-art tools.
AutoML-Med's ability to improve prediction results, especially in medical
datasets with sparse data and class imbalance, highlights its potential to
streamline Machine Learning applications in healthcare.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [30] [How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective](https://arxiv.org/abs/2508.01300)
*Ma'ayan Armony,Albert Meroño-Peñuela,Gerard Canal*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLM）在规划任务中的不可靠性，并提出了一种基于自然语言处理（NLP）的恢复流程，以提高生成计划的质量和成功率。


<details>
  <summary>Details</summary>
Motivation: LLM在规划任务中常生成错误或虚构的动作，现有评估方法主要关注成功率，缺乏对计划质量的全面分析。

Method: 提出一个包含NLP评估和三阶段恢复的流程，结合符号规划器完成计划。

Result: 研究发现LLM生成的计划缺乏底层推理，恢复流程仅将成功率从21.9%提升至27.5%，且平均仅前2.65个动作可执行。

Conclusion: 尽管恢复流程有所改进，LLM在规划任务中的质量和可靠性仍不及传统规划器。

Abstract: The reasoning and planning abilities of Large Language Models (LLMs) have
been a frequent topic of discussion in recent years. Their ability to take
unstructured planning problems as input has made LLMs' integration into AI
planning an area of interest. Nevertheless, LLMs are still not reliable as
planners, with the generated plans often containing mistaken or hallucinated
actions. Existing benchmarking and evaluation methods investigate planning with
LLMs, focusing primarily on success rate as a quality indicator in various
planning tasks, such as validating plans or planning in relaxed conditions. In
this paper, we approach planning with LLMs as a natural language processing
(NLP) task, given that LLMs are NLP models themselves. We propose a recovery
pipeline consisting of an NLP-based evaluation of the generated plans, along
with three stages to recover the plans through NLP manipulation of the
LLM-generated plans, and eventually complete the plan using a symbolic planner.
This pipeline provides a holistic analysis of LLM capabilities in the context
of AI task planning, enabling a broader understanding of the quality of invalid
plans. Our findings reveal no clear evidence of underlying reasoning during
plan generation, and that a pipeline comprising an NLP-based analysis of the
plans, followed by a recovery mechanism, still falls short of the quality and
reliability of classical planners. On average, only the first 2.65 actions of
the plan are executable, with the average length of symbolically generated
plans being 8.4 actions. The pipeline still improves action quality and
increases the overall success rate from 21.9% to 27.5%.

</details>


### [31] [CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics](https://arxiv.org/abs/2508.01476)
*Arindam Khanda,Anurag Satpathy,Amit Jha,Sajal K. Das*

Main category: cs.AI

TL;DR: CARGO框架优化电动车辆配送路线和充电计划，减少充电成本。


<details>
  <summary>Details</summary>
Motivation: 电动车辆因电池容量有限，需优化充电计划以提升城市配送效率。

Method: 提出混合整数线性规划（MILP）精确解和高效启发式方法。

Result: 相比基准策略，充电成本降低39%和22%。

Conclusion: CARGO框架有效解决电动车辆配送问题，显著降低成本。

Abstract: With growing interest in sustainable logistics, electric vehicle (EV)-based
deliveries offer a promising alternative for urban distribution. However, EVs
face challenges due to their limited battery capacity, requiring careful
planning for recharging. This depends on factors such as the charging point
(CP) availability, cost, proximity, and vehicles' state of charge (SoC). We
propose CARGO, a framework addressing the EV-based delivery route planning
problem (EDRP), which jointly optimizes route planning and charging for
deliveries within time windows. After proving the problem's NP-hardness, we
propose a mixed integer linear programming (MILP)-based exact solution and a
computationally efficient heuristic method. Using real-world datasets, we
evaluate our methods by comparing the heuristic to the MILP solution, and
benchmarking it against baseline strategies, Earliest Deadline First (EDF) and
Nearest Delivery First (NDF). The results show up to 39% and 22% reductions in
the charging cost over EDF and NDF, respectively, while completing comparable
deliveries.

</details>


### [32] [WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning](https://arxiv.org/abs/2508.01495)
*Jingtian Yan,Stephen F. Smith,Jiaoyang Li*

Main category: cs.AI

TL;DR: 提出了一种名为kTPG的多智能体速度优化算法，以及其扩展框架WinkTPG，用于将MAPF计划优化为动力学可行的路径，并动态减少不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体路径规划中动力学模型简化导致的计划不可行问题，并减少执行中的不确定性。

Method: 基于kTPG算法，通过窗口机制动态优化MAPF计划，结合执行中的智能体信息。

Result: WinkTPG能在1秒内为1000个智能体生成速度曲线，解决方案质量提升51.7%。

Conclusion: WinkTPG显著提升了多智能体路径规划的效率和可行性。

Abstract: Planning collision-free paths for a large group of agents is a challenging
problem with numerous real-world applications. While recent advances in
Multi-Agent Path Finding (MAPF) have shown promising progress, standard MAPF
algorithms rely on simplified kinodynamic models, preventing agents from
directly following the generated MAPF plan. To bridge this gap, we propose
kinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed
optimization algorithm that efficiently refines a MAPF plan into a
kinodynamically feasible plan while accounting for uncertainties and preserving
collision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a
MAPF execution framework that incrementally refines MAPF plans using a
window-based mechanism, dynamically incorporating agent information during
execution to reduce uncertainty. Experiments show that WinkTPG can generate
speed profiles for up to 1,000 agents in 1 second and improves solution quality
by up to 51.7% over existing MAPF execution methods.

</details>


### [33] [DeepVIS: Bridging Natural Language and Data Visualization Through Step-wise Reasoning](https://arxiv.org/abs/2508.01700)
*Zhihao Shuai,Boyan Li,Siyu Yan,Yuyu Luo,Weikai Yang*

Main category: cs.AI

TL;DR: 论文提出了一种将Chain-of-Thought（CoT）推理引入自然语言到可视化（NL2VIS）流程的方法，以提高透明度和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏透明性，用户无法理解设计逻辑或优化输出，因此需要一种能提供清晰推理过程的方法。

Method: 设计了CoT推理流程，开发了自动标注数据集的方法，并创建了nvBench-CoT数据集和DeepVIS交互界面。

Result: 实验表明，该方法显著提升了NL2VIS的质量，并为用户提供了可理解的推理步骤。

Conclusion: CoT框架有效提升了NL2VIS的透明性和用户参与度，同时保持了高性能。

Abstract: Although data visualization is powerful for revealing patterns and
communicating insights, creating effective visualizations requires familiarity
with authoring tools and often disrupts the analysis flow. While large language
models show promise for automatically converting analysis intent into
visualizations, existing methods function as black boxes without transparent
reasoning processes, which prevents users from understanding design rationales
and refining suboptimal outputs. To bridge this gap, we propose integrating
Chain-of-Thought (CoT) reasoning into the Natural Language to Visualization
(NL2VIS) pipeline. First, we design a comprehensive CoT reasoning process for
NL2VIS and develop an automatic pipeline to equip existing datasets with
structured reasoning steps. Second, we introduce nvBench-CoT, a specialized
dataset capturing detailed step-by-step reasoning from ambiguous natural
language descriptions to finalized visualizations, which enables
state-of-the-art performance when used for model fine-tuning. Third, we develop
DeepVIS, an interactive visual interface that tightly integrates with the CoT
reasoning process, allowing users to inspect reasoning steps, identify errors,
and make targeted adjustments to improve visualization outcomes. Quantitative
benchmark evaluations, two use cases, and a user study collectively demonstrate
that our CoT framework effectively enhances NL2VIS quality while providing
insightful reasoning steps to users.

</details>


### [34] [ReflecSched: Solving Dynamic Flexible Job-Shop Scheduling via LLM-Powered Hierarchical Reflection](https://arxiv.org/abs/2508.01724)
*Shijie Cao,Yuan Yuan*

Main category: cs.AI

TL;DR: ReflecSched框架通过结合LLM的战略分析能力，解决了DFJSP问题中LLM直接应用的不足，显著提升了调度性能。


<details>
  <summary>Details</summary>
Motivation: 传统调度规则效率高但缺乏灵活性，深度学习方法需要复杂特征工程，而LLM直接应用存在长上下文悖论、专家启发式利用不足和短视决策等问题。

Method: 提出ReflecSched框架，通过LLM分析启发式模拟的多规划视野，生成“战略经验”摘要，并集成到最终决策模块中。

Result: ReflecSched显著优于直接LLM基线（71.35%胜率，2.755%相对偏差降低），并超越所有评估的启发式方法。

Conclusion: ReflecSched通过战略分析能力有效解决了LLM在DFJSP中的关键问题，性能与最佳启发式方法相当。

Abstract: Dynamic Flexible Job-Shop Scheduling (DFJSP) is an NP-hard problem challenged
by real-time event adaptation and complex machine routing. While traditional
dispatching rules are efficient but rigid, deep learning approaches are opaque
and require intricate feature engineering. Large Language Models (LLMs) promise
adaptive reasoning without this engineering overhead, yet we find their direct
application is suboptimal. Baseline LLMs suffer from three key pitfalls: the
long-context paradox, where crucial data is underutilized; an underutilization
of expert heuristics; and myopic decision-making. To address this, we propose
ReflecSched, a framework that empowers the LLM beyond a direct scheduler by
equipping it with a strategic analysis capability. ReflecSched tasks the LLM to
analyze heuristic-driven simulations across multiple planning horizons and
distill them into a concise, natural-language summary termed ``Strategic
Experience''. This summary is then integrated into the prompt of a final
decision-making module, guiding it to produce non-myopic actions. Experiments
show that ReflecSched not only statistically significantly outperforms direct
LLM baselines, securing a 71.35\% Win Rate and a 2.755\% Relative Percentage
Deviation reduction, but also surpasses the performance of all individual
heuristics evaluated, all while demonstrably mitigating the three identified
pitfalls. Additionally, ReflecSched performs on par with the best heuristic
tailored to each instance across all problem cases.

</details>


### [35] [CloudAnoAgent: Anomaly Detection for Cloud Sites via LLM Agent with Neuro-Symbolic Mechanism](https://arxiv.org/abs/2508.01844)
*Xinkai Zou,Xuan Jiang,Ruikai Huang,Haoze He,Parv Kapoor,Jiahua Zhao*

Main category: cs.AI

TL;DR: 提出CloudAnoAgent，一种基于神经符号LLM的代理，用于云环境异常检测，结合指标和日志数据，显著提升检测准确率并降低误报率。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖指标数据，误报率高且数据不平衡，导致运维负担重。LLM的进展为结合指标和日志数据提供了新机会。

Method: 提出CloudAnoAgent，联合处理结构化指标和文本日志数据，利用符号验证生成结构化异常报告。

Result: 实验显示，CloudAnoAgent平均提升分类准确率46.36%和36.67%，降低误报率36.67%和33.89%，异常类型检测准确率提升12.8%。

Conclusion: CloudAnoAgent通过提高检测准确性、减少误报和增强可解释性，支持企业云环境的实际部署。

Abstract: Anomaly detection in cloud sites remains a critical yet challenging task.
Existing approaches that rely solely on metric data often suffer from high
false positive rates (FPR) due to data imbalance between normal and anomalous
events, leading to significant operational overhead for system reliance
engineers. Recent advances in large language models (LLMs) offer new
opportunities for integrating metrics with log data, enabling more accurate and
interpretable anomaly detection. In this paper, we propose CloudAnoAgent, the
first neuro-symbolic LLM-based agent for anomaly detection in cloud
environments. CloudAnoAgent jointly processes structured metrics and textual
log data in a unified pipeline, leveraging symbolic verification to validate
detection hypotheses and generate structured anomaly reports. To support
systematic evaluation, we introduce CloudAnoBench, the first benchmark that
provides LLM-generated paired metrics and log data with fine-grained anomaly
behavior annotations, filling a critical gap in existing datasets. Experimental
results demonstrate that CloudAnoAgent improves anomaly classification accuracy
by 46.36% and 36.67% on average and reduces the FPR by 36.67% and 33.89% on
average over traditional baselines and LLM-only baseline, with a boost on
anomaly type detection accuracy by 12.8% compared to vanilla LLM prompting.
These results demonstrate the strengths of our approach in improving detection
accuracy, reducing false positives, and enhancing interpretability, thereby
supporting practical deployment in enterprise cloud environments.

</details>


### [36] [Neuromorphic Computing with Multi-Frequency Oscillations: A Bio-Inspired Approach to Artificial Intelligence](https://arxiv.org/abs/2508.02191)
*Boheng Liu,Ziyu Li,Xia Wu*

Main category: cs.AI

TL;DR: 该论文提出了一种受大脑启发的三部分架构，通过功能专业化和时间动态模拟提升人工认知的灵活性和效率。初步评估显示其在性能和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 人工神经网络在灵活性和通用智能方面存在局限，源于其与生物认知的根本差异，特别是功能专业化和时间动态的忽视。

Method: 提出三部分架构（感知、辅助、执行系统），结合多频神经振荡和突触动态适应机制模拟时间动态。

Result: 在视觉任务中，性能提升2.18%，计算迭代减少48.44%，且与人类置信模式相关性更高。

Conclusion: 该架构为类脑智能提供了理论基础，有望缩小人工与生物智能的差距。

Abstract: Despite remarkable capabilities, artificial neural networks exhibit limited
flexible, generalizable intelligence. This limitation stems from their
fundamental divergence from biological cognition that overlooks both neural
regions' functional specialization and the temporal dynamics critical for
coordinating these specialized systems. We propose a tripartite brain-inspired
architecture comprising functionally specialized perceptual, auxiliary, and
executive systems. Moreover, the integration of temporal dynamics through the
simulation of multi-frequency neural oscillation and synaptic dynamic
adaptation mechanisms enhances the architecture, thereby enabling more flexible
and efficient artificial cognition. Initial evaluations demonstrate superior
performance compared to state-of-the-art temporal processing approaches, with
2.18\% accuracy improvements while reducing required computation iterations by
48.44\%, and achieving higher correlation with human confidence patterns.
Though currently demonstrated on visual processing tasks, this architecture
establishes a theoretical foundation for brain-like intelligence across
cognitive domains, potentially bridging the gap between artificial and
biological intelligence.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [37] [Adaptive Content Restriction for Large Language Models via Suffix Optimization](https://arxiv.org/abs/2508.01198)
*Yige Li,Peihai Jiang,Jun Sun,Peng Shu,Tianming Liu,Zhen Xiang*

Main category: cs.CL

TL;DR: 论文提出了一种轻量级方法（Suffix Optimization, SOP），用于在不微调模型的情况下限制LLM生成特定受限内容，并通过基准测试验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM生成内容的广泛性，针对不同用户群体和快速变化的限制需求，传统的监督微调方法不切实际，因此需要轻量级解决方案。

Method: 提出Suffix Optimization (SOP)方法，通过在提示后添加优化的后缀，防止LLM生成受限内容，同时保持输出质量。

Result: SOP在多个LLM上表现优于基线方法，平均限制率提升6%-17%，并在实际平台POE上验证了实用性。

Conclusion: SOP是一种高效、实用的轻量级方法，适用于动态内容限制需求。

Abstract: Large Language Models (LLMs) have demonstrated significant success across
diverse applications. However, enforcing content restrictions remains a
significant challenge due to their expansive output space. One aspect of
content restriction is preventing LLMs from generating harmful content via
model alignment approaches such as supervised fine-tuning (SFT). Yet, the need
for content restriction may vary significantly across user groups, change
rapidly over time, and not always align with general definitions of
harmfulness. Applying SFT to each of these specific use cases is impractical
due to the high computational, data, and storage demands. Motivated by this
need, we propose a new task called \textit{Adaptive Content Restriction}
(AdaCoRe), which focuses on lightweight strategies -- methods without model
fine-tuning -- to prevent deployed LLMs from generating restricted terms for
specific use cases. We propose the first method for AdaCoRe, named
\textit{Suffix Optimization (SOP)}, which appends a short, optimized suffix to
any prompt to a) prevent a target LLM from generating a set of restricted
terms, while b) preserving the output quality. To evaluate AdaCoRe approaches,
including our SOP, we create a new \textit{Content Restriction Benchmark}
(CoReBench), which contains 400 prompts for 80 restricted terms across 8
carefully selected categories. We demonstrate the effectiveness of SOP on
CoReBench, which outperforms the system-level baselines such as system suffix
by 15\%, 17\%, 10\%, 9\%, and 6\% on average restriction rates for Gemma2-2B,
Mistral-7B, Vicuna-7B, Llama3-8B, and Llama3.1-8B, respectively. We also
demonstrate that SOP is effective on POE, an online platform hosting various
commercial LLMs, highlighting its practicality in real-world scenarios.

</details>


### [38] [Dynaword: From One-shot to Continuously Developed Datasets](https://arxiv.org/abs/2508.02271)
*Kenneth Enevoldsen,Kristian Nørgaard Jensen,Jan Kostkan,Balázs Szabó,Márton Kardos,Kirten Vad,Andrea Blasi Núñez,Gianluca Barmina,Jacob Nielsen,Rasmus Larsen,Peter Vahlstrup,Per Møldrup Dalum,Desmond Elliott,Lukas Galke,Peter Schneider-Kamp,Kristoffer Nielbo*

Main category: cs.CL

TL;DR: 论文提出Dynaword方法和Danish Dynaword数据集，解决大规模数据集在许可、社区贡献和质量保证方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前大规模数据集面临许可模糊、静态发布和质量保证受限的问题，限制了其使用和发展。

Method: 提出Dynaword框架，支持社区协作持续更新数据集；并实现Danish Dynaword作为验证。

Result: Danish Dynaword规模是同类数据集的四倍，完全开源，并吸引了多方贡献。

Conclusion: Dynaword方法为数据集提供了可持续的社区协作框架，展示了其潜力。

Abstract: Large-scale datasets are foundational for research and development in natural
language processing. However, current approaches face three key challenges: (1)
reliance on ambiguously licensed sources restricting use, sharing, and
derivative works; (2) static dataset releases that prevent community
contributions and diminish longevity; and (3) quality assurance processes
restricted to publishing teams rather than leveraging community expertise.
  To address these limitations, we introduce two contributions: the Dynaword
approach and Danish Dynaword. The Dynaword approach is a framework for creating
large-scale, open datasets that can be continuously updated through community
collaboration. Danish Dynaword is a concrete implementation that validates this
approach and demonstrates its potential. Danish Dynaword contains over four
times as many tokens as comparable releases, is exclusively openly licensed,
and has received multiple contributions across industry and research. The
repository includes light-weight tests to ensure data formatting, quality, and
documentation, establishing a sustainable framework for ongoing community
contributions and dataset evolution.

</details>


### [39] [Building and Aligning Comparable Corpora](https://arxiv.org/abs/2508.02555)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 提出了一种从Wikipedia和EURONEWS构建多语言可比语料库的方法，并实验了基于双语词典和潜在语义索引（LSI）的跨语言相似性度量对齐文档。实验表明CL-LSI优于词典方法，并成功应用于BBC和ALJAZEERA新闻文档的对齐。


<details>
  <summary>Details</summary>
Motivation: 可比语料库在多语言自然语言处理中很有用，尤其是在缺乏平行文本的领域或语言中。它们能反映不同语言对同一主题的讨论。

Method: 从Wikipedia和EURONEWS构建英语、法语和阿拉伯语的可比语料库，并实验两种跨语言相似性度量（双语词典和CL-LSI）对齐文档。

Result: CL-LSI在多个语料库上表现优于词典方法，并能实现主题和事件级别的跨语言文档对齐。

Conclusion: CL-LSI是一种有效的跨语言文档对齐方法，适用于构建高质量的可比语料库。

Abstract: Comparable corpus is a set of topic aligned documents in multiple languages,
which are not necessarily translations of each other. These documents are
useful for multilingual natural language processing when there is no parallel
text available in some domains or languages. In addition, comparable documents
are informative because they can tell what is being said about a topic in
different languages. In this paper, we present a method to build comparable
corpora from Wikipedia encyclopedia and EURONEWS website in English, French and
Arabic languages. We further experiment a method to automatically align
comparable documents using cross-lingual similarity measures. We investigate
two cross-lingual similarity measures to align comparable documents. The first
measure is based on bilingual dictionary, and the second measure is based on
Latent Semantic Indexing (LSI). Experiments on several corpora show that the
Cross-Lingual LSI (CL-LSI) measure outperforms the dictionary based measure.
Finally, we collect English and Arabic news documents from the British
Broadcast Corporation (BBC) and from ALJAZEERA (JSC) news website respectively.
Then we use the CL-LSI similarity measure to automatically align comparable
documents of BBC and JSC. The evaluation of the alignment shows that CL-LSI is
not only able to align cross-lingual documents at the topic level, but also it
is able to do this at the event level.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [40] [Improving Drone Racing Performance Through Iterative Learning MPC](https://arxiv.org/abs/2508.01103)
*Haocheng Zhao,Niklas Schlüter,Lukas Brunke,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 论文提出了一种改进的迭代学习模型预测控制（LMPC）方法，通过自适应成本函数、局部安全集和笛卡尔坐标系优化无人机竞速性能。


<details>
  <summary>Details</summary>
Motivation: 无人机竞速需要实时决策和鲁棒控制，但现有LMPC方法在时间最优与安全性之间存在权衡，且实时性不足。

Method: 提出三项创新：自适应成本函数动态平衡时间最优与中心线跟踪，局部安全集防止过度捷径，笛卡尔坐标系避免奇异性。

Result: 仿真和实验显示，算法可将初始轨迹优化至最高60.85%的圈速提升，即使对最优控制器MPCC++仍有6.05%提升。

Conclusion: 改进的LMPC方法显著提升无人机竞速性能，兼顾速度与安全性，适用于实际应用。

Abstract: Autonomous drone racing presents a challenging control problem, requiring
real-time decision-making and robust handling of nonlinear system dynamics.
While iterative learning model predictive control~(LMPC) offers a promising
framework for iterative performance improvement, its direct application to
drone racing faces challenges like real-time compatibility or the trade-off
between time-optimal and safe traversal. In this paper, we enhance LMPC with
three key innovations:~(1) an adaptive cost function that dynamically weights
time-optimal tracking against centerline adherence,~(2)~a shifted local safe
set to prevent excessive shortcutting and enable more robust iterative updates,
and~(3) a Cartesian-based formulation that accommodates safety constraints
without the singularities or integration errors associated with Frenet-frame
transformations. Results from extensive simulation and real-world experiments
demonstrate that our improved algorithm can optimize initial trajectories
generated by a wide range of controllers with varying levels of tuning for a
maximum improvement in lap time by 60.85\%. Even applied to the most
aggressively tuned state-of-the-art model-based controller, MPCC++, on a real
drone, a 6.05\% improvement is still achieved. Overall, the proposed method
pushes the drone toward faster traversal and avoids collisions in simulation
and real-world experiments, making it a practical solution to improve the peak
performance of drone racing.

</details>


### [41] [Adverse Weather-Independent Framework Towards Autonomous Driving Perception through Temporal Correlation and Unfolded Regularization](https://arxiv.org/abs/2508.01583)
*Wei-Bin Kou,Guangxu Zhu,Rongguang Ye,Jingreng Lei,Shuai Wang,Qingfeng Lin,Ming Tang,Yik-Chung Wu*

Main category: cs.RO

TL;DR: 提出了一种无参考且独立于恶劣天气条件的框架Advent，通过利用短时同质性，解决了传统域适应方法依赖清晰图像和单一天气条件的局限性。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气条件（如雾、雨）对自动驾驶感知任务（如语义分割、目标检测）构成挑战，传统域适应方法依赖清晰图像且难以应对多种天气混合情况。

Method: Advent框架包含三个组件：局部序列机制（LSM）利用相邻帧的时间相关性；全局混洗机制（GSM）防止过拟合；展开正则化器（URs）增强跨天气泛化能力。

Result: 实验表明，Advent在语义分割任务中显著优于现有方法。

Conclusion: Advent框架通过无参考和天气无关的设计，有效提升了自动驾驶感知任务在恶劣天气下的性能。

Abstract: Various adverse weather conditions such as fog and rain pose a significant
challenge to autonomous driving (AD) perception tasks like semantic
segmentation, object detection, etc. The common domain adaption strategy is to
minimize the disparity between images captured in clear and adverse weather
conditions. However, domain adaption faces two challenges: (I) it typically
relies on utilizing clear image as a reference, which is challenging to obtain
in practice; (II) it generally targets single adverse weather condition and
performs poorly when confronting the mixture of multiple adverse weather
conditions. To address these issues, we introduce a reference-free and Adverse
weather condition-independent (Advent) framework (rather than a specific model
architecture) that can be implemented by various backbones and heads. This is
achieved by leveraging the homogeneity over short durations, getting rid of
clear reference and being generalizable to arbitrary weather condition.
Specifically, Advent includes three integral components: (I) Locally Sequential
Mechanism (LSM) leverages temporal correlations between adjacent frames to
achieve the weather-condition-agnostic effect thanks to the homogeneity behind
arbitrary weather condition; (II) Globally Shuffled Mechanism (GSM) is proposed
to shuffle segments processed by LSM from different positions of input sequence
to prevent the overfitting to LSM-induced temporal patterns; (III) Unfolded
Regularizers (URs) are the deep unfolding implementation of two proposed
regularizers to penalize the model complexity to enhance across-weather
generalization. We take the semantic segmentation task as an example to assess
the proposed Advent framework. Extensive experiments demonstrate that the
proposed Advent outperforms existing state-of-the-art baselines with large
margins.

</details>


### [42] [Exploring Stiffness Gradient Effects in Magnetically Induced Metamorphic Materials via Continuum Simulation and Validation](https://arxiv.org/abs/2508.01810)
*Wentao Shi,Yang Yang,Yiming Huang,Hongliang Ren*

Main category: cs.RO

TL;DR: 本文研究了基于磁诱导变形材料（MIMMs）的梯度刚度磁软连续体机器人（GMCs），开发了包含四个关键参数的数值模型，并通过实验验证了其弯曲性能。


<details>
  <summary>Details</summary>
Motivation: 现有磁连续体机器人研究多聚焦于单一或两个设计参数，缺乏全面模型，限制了其发展。

Method: 构建梯度刚度GMCs，开发数值模型，并通过实验验证其弯曲性能。

Result: 梯度刚度设计避免了固定端尖锐弯曲，形成更圆滑曲率；训练的高效扩展模型优于模拟过程。

Conclusion: GMCs的梯度刚度设计和高效模型为磁连续体机器人提供了更全面的性能预测和优化方向。

Abstract: Magnetic soft continuum robots are capable of bending with remote control in
confined space environments, and they have been applied in various
bioengineering contexts. As one type of ferromagnetic soft continuums, the
Magnetically Induced Metamorphic Materials (MIMMs)-based continuum (MC)
exhibits similar bending behaviors. Based on the characteristics of its base
material, MC is flexible in modifying unit stiffness and convenient in molding
fabrication. However, recent studies on magnetic continuum robots have
primarily focused on one or two design parameters, limiting the development of
a comprehensive magnetic continuum bending model. In this work, we constructed
graded-stiffness MCs (GMCs) and developed a numerical model for GMCs' bending
performance, incorporating four key parameters that determine their
performance. The simulated bending results were validated with real bending
experiments in four different categories: varying magnetic field,
cross-section, unit stiffness, and unit length. The graded-stiffness design
strategy applied to GMCs prevents sharp bending at the fixed end and results in
a more circular curvature. We also trained an expansion model for GMCs' bending
performance that is highly efficient and accurate compared to the simulation
process. An extensive library of bending prediction for GMCs was built using
the trained model.

</details>


### [43] [HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents](https://arxiv.org/abs/2508.02629)
*Yibin Liu,Zhixuan Liang,Zanxin Chen,Tianxing Chen,Mengkang Hu,Wanxi Dong,Congsheng Xu,Zhaoming Han,Yusen Qin,Yao Mu*

Main category: cs.RO

TL;DR: HyCodePolicy是一种混合语言控制框架，通过结合代码合成、几何基础、感知监控和迭代修复，为具身代理提供闭环编程循环，显著提升机器人操作策略的鲁棒性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统缺乏自适应监控策略执行和修复代码的机制，限制了具身代理的任务完成能力。

Method: HyCodePolicy将自然语言指令分解为子目标，生成基于几何基元的可执行程序，并通过视觉语言模型监控执行失败，结合执行轨迹和感知反馈修复程序。

Result: HyCodePolicy显著提高了机器人操作策略的鲁棒性和样本效率。

Conclusion: HyCodePolicy为将多模态推理集成到自主决策流程中提供了可扩展的策略。

Abstract: Recent advances in multimodal large language models (MLLMs) have enabled
richer perceptual grounding for code policy generation in embodied agents.
However, most existing systems lack effective mechanisms to adaptively monitor
policy execution and repair codes during task completion. In this work, we
introduce HyCodePolicy, a hybrid language-based control framework that
systematically integrates code synthesis, geometric grounding, perceptual
monitoring, and iterative repair into a closed-loop programming cycle for
embodied agents. Technically, given a natural language instruction, our system
first decomposes it into subgoals and generates an initial executable program
grounded in object-centric geometric primitives. The program is then executed
in simulation, while a vision-language model (VLM) observes selected
checkpoints to detect and localize execution failures and infer failure
reasons. By fusing structured execution traces capturing program-level events
with VLM-based perceptual feedback, HyCodePolicy infers failure causes and
repairs programs. This hybrid dual feedback mechanism enables self-correcting
program synthesis with minimal human supervision. Our results demonstrate that
HyCodePolicy significantly improves the robustness and sample efficiency of
robot manipulation policies, offering a scalable strategy for integrating
multimodal reasoning into autonomous decision-making pipelines.

</details>
