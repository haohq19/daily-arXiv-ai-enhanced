<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Asynchronous Event Stream Noise Filtering for High-frequency Structure Deformation Measurement](https://arxiv.org/abs/2512.15055)
*Yifei Bian,Banglei Guan,Zibin Liu,Ang Su,Shiyao Zhu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于事件相机和LED标记的高频变形测量方法，解决传统高速相机在恶劣光照和高成本下的限制


<details>
  <summary>Details</summary>
Motivation: 大型结构在复杂载荷下会产生高频变形，但恶劣光照条件和高昂设备成本限制了传统高速相机的测量方法

Method: 利用事件相机和LED标记：1)基于LED闪烁事件流的时空相关性过滤观测噪声；2)区分运动引起的事件和LED闪烁事件，提取高速移动的LED标记；3)使用单目事件相机测量高频平面变形

Result: 实验结果表明该方法在测量高频平面变形方面具有准确性

Conclusion: 该方法能够有效测量高频平面变形，克服了传统高速相机在恶劣光照和高成本方面的限制

Abstract: Large-scale structures suffer high-frequency deformations due to complex loads. However, harsh lighting conditions and high equipment costs limit measurement methods based on traditional high-speed cameras. This paper proposes a method to measure high-frequency deformations by exploiting an event camera and LED markers. Firstly, observation noise is filtered based on the characteristics of the event stream generated by LED markers blinking and spatiotemporal correlation. Then, LED markers are extracted from the event stream after differentiating between motion-induced events and events from LED blinking, which enables the extraction of high-speed moving LED markers. Ultimately, high-frequency planar deformations are measured by a monocular event camera. Experimental results confirm the accuracy of our method in measuring high-frequency planar deformations.

</details>


### [2] [See It Before You Grab It: Deep Learning-based Action Anticipation in Basketball](https://arxiv.org/abs/2512.15386)
*Arnau Barrera Roy,Albert Clapés Sintes*

Main category: cs.CV

TL;DR: 该论文提出了篮球视频中篮板球预测的新任务，创建了包含10万视频片段和2000+标注篮板事件的数据集，并首次将深度学习应用于篮板预测，展示了在实时广播和赛后分析中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机视觉在体育分析中取得了显著进展，但在体育视频中预测未来动作（如篮板球归属）的研究相对较少。现有技术主要集中在追踪、姿态估计和动作识别上，而动作预测对实时广播和决策支持有重要价值。

Method: 1. 提出了篮球广播视频中篮板球预测的新任务；2. 创建了包含10万个篮球视频片段、300多小时素材和2000多个手动标注篮板事件的数据集；3. 使用最先进的行动预测方法建立基准；4. 探索了篮板分类和篮板识别两个补充任务。

Result: 实验结果表明篮板预测既可行又具有挑战性。这是首次将深度学习技术应用于篮球篮板预测，数据集支持多种篮球视频理解应用，填补了该领域数据集的空白。

Conclusion: 该工作为动态多智能体体育场景的预测建模提供了宝贵见解，通过预测篮板球归属，能够支持实时自动广播和赛后分析工具，促进体育视频理解的发展。

Abstract: Computer vision and video understanding have transformed sports analytics by enabling large-scale, automated analysis of game dynamics from broadcast footage. Despite significant advances in player and ball tracking, pose estimation, action localization, and automatic foul recognition, anticipating actions before they occur in sports videos has received comparatively little attention. This work introduces the task of action anticipation in basketball broadcast videos, focusing on predicting which team will gain possession of the ball following a shot attempt. To benchmark this task, a new self-curated dataset comprising 100,000 basketball video clips, over 300 hours of footage, and more than 2,000 manually annotated rebound events is presented. Comprehensive baseline results are reported using state-of-the-art action anticipation methods, representing the first application of deep learning techniques to basketball rebound prediction. Additionally, two complementary tasks, rebound classification and rebound spotting, are explored, demonstrating that this dataset supports a wide range of video understanding applications in basketball, for which no comparable datasets currently exist. Experimental results highlight both the feasibility and inherent challenges of anticipating rebounds, providing valuable insights into predictive modeling for dynamic multi-agent sports scenarios. By forecasting team possession before rebounds occur, this work enables applications in real-time automated broadcasting and post-game analysis tools to support decision-making.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI](https://arxiv.org/abs/2512.14712)
*Ryan Cartularo*

Main category: cs.LG

TL;DR: 本文比较了两种多模态融合架构用于脓毒症预测，发现轻量级上下文感知混合专家模型（SepsisLateFusion）优于复杂的端到端融合模型（SepsisFusionFormer），在MIMIC-IV数据集上实现了SOTA性能（AUC 0.915），并开发了临床决策支持框架SepsisSuite。


<details>
  <summary>Details</summary>
Motivation: 脓毒症占ICU入院近20%，但传统预测模型难以有效整合异质数据流（生命体征、文本、影像），要么模态孤立，要么依赖脆弱的早期融合。需要更有效的多模态融合方法来提高预测准确性。

Method: 1. 比较两种架构：端到端深度融合（SepsisFusionFormer）和上下文感知堆叠（SepsisLateFusion）。2. SepsisLateFusion采用轻量级混合专家架构，将模态视为正交专家（"历史学家"静态数据、"监视器"时序数据、"阅读器"NLP），通过CatBoost元学习器动态门控。3. 开发SepsisSuite部署框架。

Result: 1. SepsisFusionFormer在小样本抗生素队列（N≈2,100）中因"注意力饥饿"过拟合（AUC 0.66）。2. SepsisLateFusion在临床发作前4小时预测达到SOTA性能（AUC 0.915）。3. 通过校准决策阈值，漏诊率降低48%。4. 四模态集成在多类抗生素选择任务中表现最佳（AUC 0.72）。

Conclusion: 对于脓毒症预测，轻量级上下文感知混合专家架构优于复杂端到端融合模型，能有效整合异质数据流，提供临床可用的预测窗口。开发的SepsisSuite框架为临床决策支持提供了实用工具。

Abstract: Sepsis accounts for nearly 20% of global ICU admissions, yet conventional prediction models often fail to effectively integrate heterogeneous data streams, remaining either siloed by modality or reliant on brittle early fusion. In this work, we present a rigorous architectural comparison between End-to-End Deep Fusion and Context-Aware Stacking for sepsis tasks. We initially hypothesized that a novel Quad-Modal Hierarchical Gated Attention Network -- termed SepsisFusionFormer -- would resolve complex cross-modal interactions between vitals, text, and imaging. However, experiments on MIMIC-IV revealed that SepsisFusionFormer suffered from "attention starvation" in the small antibiotic cohort ($N \approx 2,100$), resulting in overfitting (AUC 0.66). This counterintuitive result informed the design of SepsisLateFusion, a "leaner" Context-Aware Mixture-of-Experts (MoE) architecture. By treating modalities as orthogonal experts -- the "Historian" (Static), the "Monitor" (Temporal), and the "Reader" (NLP) -- and dynamically gating them via a CatBoost meta-learner, we achieved State-of-the-Art (SOTA) performance: 0.915 AUC for prediction 4 hours prior to clinical onset. By calibrating the decision threshold for clinical safety, we reduced missed cases by 48% relative to the default operating point, thus opening a true preventative window for timely intervention over reactive alerts. Furthermore, for the novel prescriptive task of multi-class antibiotic selection, we demonstrate that a Quad-Modal Ensemble achieved the highest performance (0.72 AUC). These models are integrated into SepsisSuite, a deployment-ready Python framework for clinical decision support. SepsisSuite is available for free at: https://github.com/RyanCartularo/SepsisSuite-Info

</details>


### [4] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: 提出一种几何框架，通过球面凸区域表示语义，将政策约束与证据几何分离，实现可证明无幻觉承诺的语义解释。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域（如金融监管）中，传统语义解释方法容易产生幻觉承诺（hallucinated commitments），即系统错误地批准不符合政策约束的请求。需要一种能严格保证政策约束不被违反的语义解释框架。

Method: 1. 将语义表示为单位球面上的方向向量；2. 证据建模为见证向量集合；3. 可接受解释对应球面凸区域；4. 政策约束作为显式先验定义在同一流形上，与证据几何分离；5. 解释简化为在可接受区域上的约束优化；6. 当出现矛盾或政策排除时，拒绝成为拓扑必然结果。

Result: 1. 理论证明：复杂度边界在信息论上是最优的；2. 实证验证：在大规模受监管金融数据上，跨多个政策制度实现零幻觉批准，这是首次在大规模上实现这样的结果。

Conclusion: 该几何框架通过将政策约束与证据几何分离，实现了可证明无幻觉承诺的语义解释，在高风险领域具有重要应用价值，特别是在需要严格政策合规的场景中。

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [5] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: 提出ERBP框架，将自指学习中的模型崩溃统一解释为分布空间中的Bregman投影序列，通过引入熵储层实现稳定化。


<details>
  <summary>Details</summary>
Motivation: 自指学习（模型在自身生成数据上训练）虽然具有无限扩展潜力，但长期面临模型崩溃问题。尽管实践中采用各种临时修复方法，但缺乏统一的理论框架来解释失败模式和修复方法的成功。

Method: 提出熵储层Bregman投影（ERBP）框架，将自指学习建模为分布空间中的随机Bregman投影序列。通过引入熵储层（高熵分布）注入可控的熵通量来稳定动力学。

Result: 理论推导出：1）崩溃的必要条件；2）保证非平凡熵底限的充分条件；3）仅依赖样本量和Bregman生成器常数的闭式速率。在语言模型自训练、强化学习和GAN优化中验证了预测。

Conclusion: ERBP将各种稳定化启发式方法统一为单一量化设计规则：监控和预算熵通量，为自指学习提供了理论基础和设计指导。

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [6] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: SPA是一个确定性框架，用于从股价数据中提取单调价格走势，关联公开事件，并生成事实性解释，旨在提供透明、可审计的历史价格结构分析。


<details>
  <summary>Details</summary>
Motivation: 现有技术指标和预测模型缺乏透明度和可解释性，难以满足需要审计和解释的市场分析需求。需要一种能够提供清晰、可复现价格结构分解的方法。

Method: SPA使用每日OHLCV数据和标准化事件流，通过确定性框架提取单调价格走势，采用对称相关窗口关联公开事件，并生成有约束的事实性历史解释。

Result: 在AAPL、NVDA、SCHW、PGR四只股票上的评估显示，SPA能稳定产生结构性分解和上下文叙事。消融实验验证了确定性分割、事件对齐和约束解释对可解释性的贡献。

Conclusion: SPA不是预测系统，而是提供透明、可复现的历史价格结构视图，可补充分析师工作流程、风险评估和可解释AI管道，填补了市场分析中透明度和可审计性的空白。

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](https://arxiv.org/abs/2512.15231)
*Zhengchao Chen,Haoran Wang,Jing Yao,Pedram Ghamisi,Jun Zhou,Peter M. Atkinson,Bing Zhang*

Main category: cs.AI

TL;DR: CangLing-KnowFlow是一个统一智能代理框架，通过整合过程知识库、动态工作流调整和进化记忆模块，实现遥感数据处理从预处理到高级解释的端到端自动化。


<details>
  <summary>Details</summary>
Motivation: 现有遥感自动化系统通常是任务特定的，缺乏统一框架来管理从数据预处理到高级解释的多样化端到端工作流。需要解决通用智能代理在遥感领域中的幻觉问题，并提供自适应、可验证的解决方案。

Method: 提出CangLing-KnowFlow框架，包含三个核心组件：1) 过程知识库(PKB)，包含1,008个专家验证的工作流案例，覆盖162个实际遥感任务；2) 动态工作流调整，在运行时故障时自主诊断和重新规划恢复策略；3) 进化记忆模块，从事件中持续学习，迭代增强代理知识和性能。

Result: 在KnowFlow-Bench基准测试(324个工作流)上评估，使用13个顶级LLM后端(开源和商业)。在所有复杂任务中，CangLing-KnowFlow比Reflexion基线至少高出4%的任务成功率，展示了作为稳健、高效、可扩展遥感自动化解决方案的潜力。

Conclusion: CangLing-KnowFlow通过将专家知识转化为自适应、可验证的过程，为复杂地球观测挑战提供了首个全面验证的统一智能代理框架，在遥感自动化领域具有重要应用前景。

Abstract: The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [8] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 论文提出Meta-Prompting Protocol框架，通过对抗性三元结构（生成器、审计器、优化器）将LLM交互形式化为可编程系统，解决传统提示工程缺乏确定性保证的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于启发式的"提示工程"方法无法为关键任务应用提供确定性保证，需要重新设计LLM交互范式，使其从随机聊天接口转变为可靠的软件组件。

Method: 提出Meta-Prompting Protocol理论框架，采用对抗性三元拓扑结构：生成器(P)生成内容，审计器(A)评估质量，优化器(O)基于文本批评进行优化。将自然语言指令视为语义计算图中的可微分变量，利用文本批评作为梯度。

Result: 该架构理论上能够缓解幻觉问题并防止模型崩溃，通过声明式编程范式(DSPy)和自动文本微分(TextGrad)验证了方法的理论可行性。

Conclusion: 为概率计算时代的"可观测软件工程"奠定了基础，使LLM能够作为可编程、自优化的系统进行编排。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [9] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 评估LLM在沸石合成实验信息提取中的表现，发现其在事件分类上表现良好（80-90% F1），但在细粒度参数提取上表现一般（50-65% F1），高级提示策略改进有限。


<details>
  <summary>Details</summary>
Motivation: 从沸石合成实验程序中提取结构化信息对材料发现至关重要，但现有方法尚未系统评估LLM在此领域特定任务中的效果，需要研究不同提示策略的有效性。

Method: 聚焦四个子任务：事件类型分类、触发文本识别、论元角色提取和论元文本提取。评估四种提示策略（零样本、少样本、事件特定、反思式）在六个先进LLM上的表现，使用ZSEE数据集（1,530个标注句子）。

Result: 事件类型分类表现良好（80-90% F1），但细粒度提取任务表现一般（50-65% F1）。GPT-5-mini表现出极端提示敏感性（11-79% F1变化）。高级提示策略相比零样本方法改进有限，揭示了架构局限性。

Conclusion: LLM虽能实现高层次理解，但精确提取实验参数需要领域适应模型，为科学信息提取提供了定量基准，揭示了当前LLM在细粒度科学信息提取中的局限性。

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [10] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 该研究首次对孟加拉语在2024年孟加拉国大规模抗议期间进行情感分析，创建了包含2028条新闻标题的标注数据集，使用语言特定模型取得了优于多语言模型和传统机器学习方法的效果。


<details>
  <summary>Details</summary>
Motivation: 情感分析在选举和社交媒体趋势等场景已有研究，但在孟加拉语环境下，特别是在国家危机期间的公民动乱中，对情感动态的理解存在显著空白。本研究旨在填补这一空白。

Method: 收集了主要Facebook新闻门户的2028条标注新闻标题，分为愤怒、希望和绝望三类。使用潜在狄利克雷分配(LDA)识别主题，并比较了语言特定模型、多语言transformer模型（mBERT和XLM-RoBERTa）以及传统机器学习方法（SVM和逻辑回归）的性能。

Result: 语言特定模型表现最佳，准确率达到78%。多语言transformer模型表现较差（mBERT: 67%，XLM-RoBERTa: 71%），传统机器学习方法均为70%。研究还识别了政治腐败、公众抗议等主题，并分析了互联网封锁等事件对情感模式的影响。

Conclusion: 语言特定模型在孟加拉语情感分析中表现优于通用模型，为理解政治动荡期间的公众情感提供了有价值的见解。研究填补了孟加拉语在危机期间情感分析的空白，并展示了事件对公众情感模式的影响。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>
