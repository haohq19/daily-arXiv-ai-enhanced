<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 6]
- [cs.RO](#cs.RO) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MemEvo: Memory-Evolving Incremental Multi-view Clustering](https://arxiv.org/abs/2509.14544)
*Zisen Kong,Bo Zhong,Pengyuan Li,Dongxia Chang,Yiming Wang*

Main category: cs.CV

TL;DR: 提出MemEvo方法解决增量多视图聚类中的稳定性-可塑性困境，通过模拟海马体-前额叶皮层协作记忆机制，实现新视图适应和历史知识保留的平衡


<details>
  <summary>Details</summary>
Motivation: 解决增量多视图聚类中的稳定性-可塑性困境(SPD)，模型需要足够的可塑性来快速适应新数据，同时保持足够的稳定性来巩固长期知识并防止灾难性遗忘

Method: 1) 海马体启发的视图对齐模块：通过对齐连续表示中的结构来捕获新视图的增益信息；2) 认知遗忘机制：模拟人类记忆衰减模式来调节历史知识权重；3) 前额叶皮层启发的知识巩固记忆模块：利用时间张量稳定性逐步巩固历史知识

Result: 大量实验证明MemEvo在视图数量增长场景中展现出强大的知识保留能力，相比现有最先进方法具有显著优势

Conclusion: MemEvo通过神经科学启发的记忆机制成功解决了增量多视图聚类中的稳定性-可塑性平衡问题，为处理动态多视图数据提供了有效解决方案

Abstract: Incremental multi-view clustering aims to achieve stable clustering results
while addressing the stability-plasticity dilemma (SPD) in incremental views.
At the core of SPD is the challenge that the model must have enough plasticity
to quickly adapt to new data, while maintaining sufficient stability to
consolidate long-term knowledge and prevent catastrophic forgetting. Inspired
by the hippocampal-prefrontal cortex collaborative memory mechanism in
neuroscience, we propose a Memory-Evolving Incremental Multi-view Clustering
method (MemEvo) to achieve this balance. First, we propose a
hippocampus-inspired view alignment module that captures the gain information
of new views by aligning structures in continuous representations. Second, we
introduce a cognitive forgetting mechanism that simulates the decay patterns of
human memory to modulate the weights of historical knowledge. Additionally, we
design a prefrontal cortex-inspired knowledge consolidation memory module that
leverages temporal tensor stability to gradually consolidate historical
knowledge. By integrating these modules, MemEvo achieves strong knowledge
retention capabilities in scenarios with a growing number of views. Extensive
experiments demonstrate that MemEvo exhibits remarkable advantages over
existing state-of-the-art methods.

</details>


### [2] [RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching](https://arxiv.org/abs/2509.14966)
*Xingwu Zhang,Guanxuan Li,Zhuocheng Zhang,Zijun Long*

Main category: cs.CV

TL;DR: RoboEye是一个两阶段物体识别框架，结合2D语义特征和3D推理，用于电商仓库自动化包装中的物体识别，在仅使用RGB图像的情况下显著提升了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 电商产品类别快速增长导致仓库自动化包装中的物体识别更加困难，传统仅依赖2D外观特征的方法在类内变异、视觉相似物品、遮挡和视角变化等情况下性能急剧下降。

Method: 两阶段识别框架：第一阶段使用大视觉模型提取2D特征生成候选排名；第二阶段通过轻量级3D特征感知模块判断是否需要3D重排序，使用机器人3D检索变换器进行几何感知特征提取和基于关键点的匹配。

Result: 实验显示RoboEye比之前最先进的方法(RoboLLM)在Recall@1指标上提升了7.1%，且仅使用RGB图像，降低了部署成本。

Conclusion: RoboEye通过动态结合2D语义特征和领域适应的3D推理，有效解决了大规模电商环境下的物体识别挑战，在性能和部署成本之间取得了良好平衡。

Abstract: The rapidly growing number of product categories in large-scale e-commerce
makes accurate object identification for automated packing in warehouses
substantially more difficult. As the catalog grows, intra-class variability and
a long tail of rare or visually similar items increase, and when combined with
diverse packaging, cluttered containers, frequent occlusion, and large
viewpoint changes-these factors amplify discrepancies between query and
reference images, causing sharp performance drops for methods that rely solely
on 2D appearance features. Thus, we propose RoboEye, a two-stage identification
framework that dynamically augments 2D semantic features with domain-adapted 3D
reasoning and lightweight adapters to bridge training deployment gaps. In the
first stage, we train a large vision model to extract 2D features for
generating candidate rankings. A lightweight 3D-feature-awareness module then
estimates 3D feature quality and predicts whether 3D re-ranking is necessary,
preventing performance degradation and avoiding unnecessary computation. When
invoked, the second stage uses our robot 3D retrieval transformer, comprising a
3D feature extractor that produces geometry-aware dense features and a
keypoint-based matcher that computes keypoint-correspondence confidences
between query and reference images instead of conventional cosine-similarity
scoring. Experiments show that RoboEye improves Recall@1 by 7.1% over the prior
state of the art (RoboLLM). Moreover, RoboEye operates using only RGB images,
avoiding reliance on explicit 3D inputs and reducing deployment costs. The code
used in this paper is publicly available at:
https://github.com/longkukuhi/RoboEye.

</details>


### [3] [UCorr: Wire Detection and Depth Estimation for Autonomous Drones](https://arxiv.org/abs/2509.14989)
*Benedikt Kolbeinsson,Krystian Mikolajczyk*

Main category: cs.CV

TL;DR: 提出了一种用于电线分割和深度估计的单目端到端模型，通过时间相关层和合成数据训练，在电线检测和深度估计联合任务上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 全自主无人机需要准确检测障碍物以确保安全导航，电线因其细长轮廓而成为特别具有挑战性的检测目标

Method: 使用单目端到端模型，结合时间相关层并在合成数据上进行训练，实现电线分割和深度估计的联合任务

Result: 在电线检测和深度估计联合任务上表现出优于现有竞争方法的性能

Conclusion: 该模型有潜力提升自主无人机的安全性和精确性，在现实场景中具有广阔的应用前景

Abstract: In the realm of fully autonomous drones, the accurate detection of obstacles
is paramount to ensure safe navigation and prevent collisions. Among these
challenges, the detection of wires stands out due to their slender profile,
which poses a unique and intricate problem. To address this issue, we present
an innovative solution in the form of a monocular end-to-end model for wire
segmentation and depth estimation. Our approach leverages a temporal
correlation layer trained on synthetic data, providing the model with the
ability to effectively tackle the complex joint task of wire detection and
depth estimation. We demonstrate the superiority of our proposed method over
existing competitive approaches in the joint task of wire detection and depth
estimation. Our results underscore the potential of our model to enhance the
safety and precision of autonomous drones, shedding light on its promising
applications in real-world scenarios.

</details>


### [4] [OmniSegmentor: A Flexible Multi-Modal Learning Framework for Semantic Segmentation](https://arxiv.org/abs/2509.15096)
*Bo-Wen Yin,Jiao-Long Cao,Xuying Zhang,Yuming Chen,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: 提出了OmniSegmentor多模态学习框架，包含ImageNeXt大规模多模态预训练数据集和高效预训练方法，在多个语义分割数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有研究证明多模态线索对鲁棒语义分割有益，但缺乏灵活的多视觉模态预训练-微调流程

Method: 1) 基于ImageNet构建包含5种视觉模态的大规模数据集ImageNeXt；2) 设计高效预训练方法使模型能编码不同模态信息

Result: 在NYU Depthv2、EventScape、MFNet、DeLiVER、SUNRGBD、KITTI-360等多个多模态语义分割数据集上达到新的最先进水平

Conclusion: 首次提出了通用的多模态预训练框架，无论涉及模态的任意组合，都能持续增强模型在各种场景下的感知能力

Abstract: Recent research on representation learning has proved the merits of
multi-modal clues for robust semantic segmentation. Nevertheless, a flexible
pretrain-and-finetune pipeline for multiple visual modalities remains
unexplored. In this paper, we propose a novel multi-modal learning framework,
termed OmniSegmentor. It has two key innovations: 1) Based on ImageNet, we
assemble a large-scale dataset for multi-modal pretraining, called ImageNeXt,
which contains five popular visual modalities. 2) We provide an efficient
pretraining manner to endow the model with the capacity to encode different
modality information in the ImageNeXt. For the first time, we introduce a
universal multi-modal pretraining framework that consistently amplifies the
model's perceptual capabilities across various scenarios, regardless of the
arbitrary combination of the involved modalities. Remarkably, our OmniSegmentor
achieves new state-of-the-art records on a wide range of multi-modal semantic
segmentation datasets, including NYU Depthv2, EventScape, MFNet, DeLiVER,
SUNRGBD, and KITTI-360.

</details>


### [5] [Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation](https://arxiv.org/abs/2509.15224)
*Luca Bartolomei,Enrico Mannocci,Fabio Tosi,Matteo Poggi,Stefano Mattoccia*

Main category: cs.CV

TL;DR: 通过跨模态萎取技术，利用视觉基础模型为事件相机生成密集深度代理标签，实现了无需昂贵深度注释的单目深度估计。


<details>
  <summary>Details</summary>
Motivation: 事件相机在高速运动和光照变化环境中优势显著，但缺乏大规模带有密集深度注释的数据集限制了学习基于深度估计的发展。

Method: 提出跨模态萎取范式，利用视觉基础模型生成密集代理标签。采用事件流与RGB帧对齐的简单设置，并提出两种模型：普通Depth Anything v2模型和新的循环网络架构。

Result: 在合成和真实数据集上评估，i)跨模态方法不需昂贵深度注释即可达到与全监督方法竞争的性能；ii)基于VFM的模型达到了状态前沿性能。

Conclusion: 该方法有效解决了事件相机深度估计中注释数据缺乏的问题，通过利用视觉基础模型的稳健性，实现了高性能的无监督深度估计。

Abstract: Event cameras capture sparse, high-temporal-resolution visual information,
making them particularly suitable for challenging environments with high-speed
motion and strongly varying lighting conditions. However, the lack of large
datasets with dense ground-truth depth annotations hinders learning-based
monocular depth estimation from event data. To address this limitation, we
propose a cross-modal distillation paradigm to generate dense proxy labels
leveraging a Vision Foundation Model (VFM). Our strategy requires an event
stream spatially aligned with RGB frames, a simple setup even available
off-the-shelf, and exploits the robustness of large-scale VFMs. Additionally,
we propose to adapt VFMs, either a vanilla one like Depth Anything v2 (DAv2),
or deriving from it a novel recurrent architecture to infer depth from
monocular event cameras. We evaluate our approach with synthetic and real-world
datasets, demonstrating that i) our cross-modal paradigm achieves competitive
performance compared to fully supervised methods without requiring expensive
depth annotations, and ii) our VFM-based models achieve state-of-the-art
performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [FlowCast-ODE: Continuous Hourly Weather Forecasting with Dynamic Flow Matching and ODE Integration](https://arxiv.org/abs/2509.14775)
*Shuangshuang He,Yuanting Zhang,Hongli Liang,Qingye Meng,Xingyuan Yuan*

Main category: cs.LG

TL;DR: FlowCast-ODE是一个基于连续流建模的天气预测框架，通过ODE求解器和粗到细策略解决小时级预测中的误差累积和时间不连续问题，在精度和计算效率上均有提升。


<details>
  <summary>Details</summary>
Motivation: 解决小时级天气预报中由于自回归误差累积和ERA5数据12小时同化周期导致的时间不连续性问题，实现更准确稳定的预测。

Method: 提出FlowCast-ODE框架，将大气状态演化建模为连续流；采用粗到细策略：先在6小时数据上训练动态流匹配，再在小时数据上使用ODE求解器进行精调；引入轻量级低秩AdaLN-Zero调制机制减少模型大小。

Result: 模型在RMSE指标上优于基线，具有更好的能量守恒特性，减少模糊并保留更多空间细节；在台风等极端事件预测上与最先进模型性能相当；有效缓解了同化周期转换带来的时间不连续问题。

Conclusion: FlowCast-ODE通过连续流建模和ODE求解器的结合，成功解决了小时级天气预报的关键挑战，在精度、稳定性和计算效率方面均表现出色，为高时间分辨率天气预测提供了有效解决方案。

Abstract: Accurate hourly weather forecasting is critical for numerous applications.
Recent deep learning models have demonstrated strong capability on 6-hour
intervals, yet achieving accurate and stable hourly predictions remains a
critical challenge. This is primarily due to the rapid accumulation of errors
in autoregressive rollouts and temporal discontinuities within the ERA5 data's
12-hour assimilation cycle. To address these issues, we propose FlowCast-ODE, a
framework that models atmospheric state evolution as a continuous flow.
FlowCast-ODE learns the conditional flow path directly from the previous state,
an approach that aligns more naturally with physical dynamic systems and
enables efficient computation. A coarse-to-fine strategy is introduced to train
the model on 6-hour data using dynamic flow matching and then refined on hourly
data that incorporates an Ordinary Differential Equation (ODE) solver to
achieve temporally coherent forecasts. In addition, a lightweight low-rank
AdaLN-Zero modulation mechanism is proposed and reduces model size by 15%
without compromising accuracy. Experiments demonstrate that FlowCast-ODE
outperforms strong baselines, yielding lower root mean square error (RMSE) and
better energy conservation, which reduces blurring and preserves more
fine-scale spatial details. It also shows comparable performance to the
state-of-the-art model in forecasting extreme events like typhoons.
Furthermore, the model alleviates temporal discontinuities associated with
assimilation cycle transitions.

</details>


### [7] [Pre-training under infinite compute](https://arxiv.org/abs/2509.14786)
*Konwoo Kim,Suhas Kotha,Percy Liang,Tatsunori Hashimoto*

Main category: cs.LG

TL;DR: 在计算资源丰富但训练数据固定的情况下，通过优化正则化、参数缩放、集成学习等简单算法改进，实现了显著的数据效率提升。最佳方案在200M标记数据上获得5.17倍数据节省，并通过矩阵缩放技术在小型模型中保留了83%的集成效果。


<details>
  <summary>Details</summary>
Motivation: 计算资源的增长速度远超语言模型预训练可用的网络文本数据，需要研究在数据固定且计算资源无限制的情况下如何进行最佳预训练。

Method: 1. 识别现有增加训练次数和模型参数的方法会过拟合；2. 通过优化正则化（权重衰减系数调整为标准实践30倍）改进性能；3. 采用独立训练模型的集成学习；4. 结合多次迭代训练、正则化、参数缩放和集成缩放等技术；5. 通过矩阵缩放技术将集成模型知识精炼到小型模型。

Result: 1. 最佳方案在200M标记数据上实现5.17倍数据效率提升；2. 矩阵缩放技术能将集成模型知识精炼到比8倍小的学生模型，保留83%的集成效果；3. 在下游任务上获得9%性能提升，数学任务上获得17.5倍数据效率提升。

Conclusion: 简单的算法改进能够在计算资源丰富的未来实现显著的数据效率提升，为语言模型预训练提供了更有效的方案。

Abstract: Since compute grows much faster than web text available for language model
pre-training, we ask how one should approach pre-training under fixed data and
no compute constraints. We first show that existing data-constrained approaches
of increasing epoch count and parameter count eventually overfit, and we
significantly improve upon such recipes by properly tuning regularization,
finding that the optimal weight decay is $30\times$ larger than standard
practice. Since our regularized recipe monotonically decreases loss following a
simple power law in parameter count, we estimate its best possible performance
via the asymptote of its scaling law rather than the performance at a fixed
compute budget. We then identify that ensembling independently trained models
achieves a significantly lower loss asymptote than the regularized recipe. Our
best intervention combining epoching, regularization, parameter scaling, and
ensemble scaling achieves an asymptote at 200M tokens using $5.17\times$ less
data than our baseline, and our data scaling laws predict that this improvement
persists at higher token budgets. We find that our data efficiency gains can be
realized at much smaller parameter counts as we can distill an ensemble into a
student model that is 8$\times$ smaller and retains $83\%$ of the ensembling
benefit. Finally, our interventions designed for validation loss generalize to
downstream benchmarks, achieving a $9\%$ improvement for pre-training evals and
a $17.5\times$ data efficiency improvement over continued pre-training on math
mid-training data. Our results show that simple algorithmic improvements can
enable significantly more data-efficient pre-training in a compute-rich future.

</details>


### [8] [Exploring the Global-to-Local Attention Scheme in Graph Transformers: An Empirical Study](https://arxiv.org/abs/2509.14863)
*Zhengwei Wang,Gang Wu*

Main category: cs.LG

TL;DR: G2LFormer是一种新型图Transformer，采用全局到局部的注意力机制，浅层用注意力捕获全局信息，深层用GNN学习局部结构信息，通过跨层信息融合策略防止信息丢失，保持线性复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有图Transformer将GNN与全局注意力机制并行或顺序集成，可能导致局部邻域信息在注意力机制中被稀释，造成信息损失。

Method: 提出全局到局部注意力方案：浅层网络使用注意力机制捕获全局信息，深层网络使用GNN模块学习局部结构信息；引入跨层信息融合策略，让局部层保留全局层的有益信息。

Result: 在节点级和图级任务上与最先进的线性图Transformer和GNN进行比较，G2LFormer展现出优异性能，同时保持线性复杂度。

Conclusion: 全局到局部注意力方案是可行的，G2LFormer能够有效防止节点忽略其直接邻居，在性能和可扩展性之间取得良好平衡。

Abstract: Graph Transformers (GTs) show considerable potential in graph representation
learning. The architecture of GTs typically integrates Graph Neural Networks
(GNNs) with global attention mechanisms either in parallel or as a precursor to
attention mechanisms, yielding a local-and-global or local-to-global attention
scheme. However, as the global attention mechanism primarily captures
long-range dependencies between nodes, these integration schemes may suffer
from information loss, where the local neighborhood information learned by GNN
could be diluted by the attention mechanism. Therefore, we propose G2LFormer,
featuring a novel global-to-local attention scheme where the shallow network
layers use attention mechanisms to capture global information, while the deeper
layers employ GNN modules to learn local structural information, thereby
preventing nodes from ignoring their immediate neighbors. An effective
cross-layer information fusion strategy is introduced to allow local layers to
retain beneficial information from global layers and alleviate information
loss, with acceptable trade-offs in scalability. To validate the feasibility of
the global-to-local attention scheme, we compare G2LFormer with
state-of-the-art linear GTs and GNNs on node-level and graph-level tasks. The
results indicate that G2LFormer exhibits excellent performance while keeping
linear complexity.

</details>


### [9] [A Comparative Analysis of Transformer Models in Social Bot Detection](https://arxiv.org/abs/2509.14936)
*Rohan Veit,Michael Lones*

Main category: cs.LG

TL;DR: 比较基于编码器和解码器变换器的机器人检测模型效果，发现编码器模型更准确鲁棒，解码器模型更具适应性和泛化潜力


<details>
  <summary>Details</summary>
Motivation: 社交媒体中人工智能用户（机器人）使用大型语言模型等先进文本生成工具误导他人，需要有效检测方法来保护在线讨论的完整性

Method: 开发评估管道比较编码器和解码器变换器分类器的性能

Result: 编码器分类器表现出更高的准确性和鲁棒性，解码器模型通过任务特定对齐显示更强的适应性和泛化潜力

Conclusion: 研究结果有助于防止数字环境被操纵，保护在线讨论的完整性，为机器人检测模型选择提供指导

Abstract: Social media has become a key medium of communication in today's society.
This realisation has led to many parties employing artificial users (or bots)
to mislead others into believing untruths or acting in a beneficial manner to
such parties. Sophisticated text generation tools, such as large language
models, have further exacerbated this issue. This paper aims to compare the
effectiveness of bot detection models based on encoder and decoder
transformers. Pipelines are developed to evaluate the performance of these
classifiers, revealing that encoder-based classifiers demonstrate greater
accuracy and robustness. However, decoder-based models showed greater
adaptability through task-specific alignment, suggesting more potential for
generalisation across different use cases in addition to superior observa.
These findings contribute to the ongoing effort to prevent digital environments
being manipulated while protecting the integrity of online discussion.

</details>


### [10] [Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers](https://arxiv.org/abs/2509.15113)
*Andrei Chertkov,Artem Basharin,Mikhail Saygin,Evgeny Frolov,Stanislav Straupe,Ivan Oseledets*

Main category: cs.LG

TL;DR: 提出一种结合随机零阶优化和动态低秩代理模型的框架，用于连接非可微物理设备与数字神经网络的端到端训练


<details>
  <summary>Details</summary>
Motivation: 解决物理设备集成到深度学习流水线的挑战，因物理设备往往表达力有限且非可微，导致无法在设备上进行反向传播

Method: 使用随机零阶优化更新物理层参数，通过动态低秩代理模型实现梯度传播，采用隐式投影器分解积分算法最小化硬件查询成本

Result: 在计算机视觉、音频分类和语言建模任务中都达到接近数字基线的准确性，成功训练包含各种非可微物理组件的混合模型

Conclusion: 该工作桥接了硬件感知深度学习与无梯度优化，为集成非可微物理组件到可扩展的端到端可训练AI系统提供了实用途径

Abstract: The growing demand for energy-efficient, high-performance AI systems has led
to increased attention on alternative computing platforms (e.g., photonic,
neuromorphic) due to their potential to accelerate learning and inference.
However, integrating such physical components into deep learning pipelines
remains challenging, as physical devices often offer limited expressiveness,
and their non-differentiable nature renders on-device backpropagation difficult
or infeasible. This motivates the development of hybrid architectures that
combine digital neural networks with reconfigurable physical layers, which
effectively behave as black boxes. In this work, we present a framework for the
end-to-end training of such hybrid networks. This framework integrates
stochastic zeroth-order optimization for updating the physical layer's internal
parameters with a dynamic low-rank surrogate model that enables gradient
propagation through the physical layer. A key component of our approach is the
implicit projector-splitting integrator algorithm, which updates the
lightweight surrogate model after each forward pass with minimal hardware
queries, thereby avoiding costly full matrix reconstruction. We demonstrate our
method across diverse deep learning tasks, including: computer vision, audio
classification, and language modeling. Notably, across all modalities, the
proposed approach achieves near-digital baseline accuracy and consistently
enables effective end-to-end training of hybrid models incorporating various
non-differentiable physical components (spatial light modulators, microring
resonators, and Mach-Zehnder interferometers). This work bridges hardware-aware
deep learning and gradient-free optimization, thereby offering a practical
pathway for integrating non-differentiable physical components into scalable,
end-to-end trainable AI systems.

</details>


### [11] [Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation](https://arxiv.org/abs/2509.15194)
*Yujun Zhou,Zhenwen Liang,Haolin Liu,Wenhao Yu,Kishan Panaganti,Linfeng Song,Dian Yu,Xiangliang Zhang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: EVOL-RL是一种无标签强化学习方法，通过结合多数投票稳定性与语义空间新颖性奖励，防止语言模型在自改进过程中出现熵崩溃，保持探索能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有无标签方法（如置信度最小化、自一致性或多数投票目标）虽然稳定学习，但会逐渐缩小探索范围，导致熵崩溃：生成内容变短、多样性减少且脆弱。需要一种既能实现通用改进又不牺牲模型固有探索能力和泛化能力的方法。

Method: 提出EVOL-RL方法：使用多数投票答案作为稳定锚点（选择），同时添加新颖性感知奖励，在语义空间中偏好与已生成内容不同的响应（变异）。采用GRPO实现，使用非对称裁剪保留强信号和熵正则化维持搜索。

Result: EVOL-RL在无标签AIME24训练中，将Qwen3-4B-Base模型在AIME25上的pass@1从TTRL的4.6%提升至16.4%，pass@16从18.5%提升至37.9%。不仅防止多样性崩溃，还在跨领域（如GPQA）展现更强泛化能力，且在RLVR设置中也提升性能。

Conclusion: EVOL-RL通过选择与变异耦合的设计有效防止崩溃，保持更长、信息更丰富的思维链，提升模型性能，具有广泛适用性。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning from verifiable rewards (RLVR), yet real-world deployment demands
models that can self-improve without labels or external judges. Existing
label-free methods, confidence minimization, self-consistency, or majority-vote
objectives, stabilize learning but steadily shrink exploration, causing an
entropy collapse: generations become shorter, less diverse, and brittle. Unlike
prior approaches such as Test-Time Reinforcement Learning (TTRL), which
primarily adapt models to the immediate unlabeled dataset at hand, our goal is
broader: to enable general improvements without sacrificing the model's
inherent exploration capacity and generalization ability, i.e., evolving. We
formalize this issue and propose EVolution-Oriented and Label-free
Reinforcement Learning (EVOL-RL), a simple rule that couples stability with
variation under a label-free setting. EVOL-RL keeps the majority-voted answer
as a stable anchor (selection) while adding a novelty-aware reward that favors
responses whose reasoning differs from what has already been produced
(variation), measured in semantic space. Implemented with GRPO, EVOL-RL also
uses asymmetric clipping to preserve strong signals and an entropy regularizer
to sustain search. This majority-for-selection + novelty-for-variation design
prevents collapse, maintains longer and more informative chains of thought, and
improves both pass@1 and pass@n. EVOL-RL consistently outperforms the
majority-only TTRL baseline; e.g., training on label-free AIME24 lifts
Qwen3-4B-Base AIME25 pass@1 from TTRL's 4.6% to 16.4%, and pass@16 from 18.5%
to 37.9%. EVOL-RL not only prevents diversity collapse but also unlocks
stronger generalization across domains (e.g., GPQA). Furthermore, we
demonstrate that EVOL-RL also boosts performance in the RLVR setting,
highlighting its broad applicability.

</details>


### [12] [CausalPre: Scalable and Effective Data Pre-processing for Causal Fairness](https://arxiv.org/abs/2509.15199)
*Ying Zheng,Yangfan Jiang,Kian-Lee Tan*

Main category: cs.LG

TL;DR: CausalPre是一个可扩展的因果引导数据预处理框架，无需强因果模型假设即可保证因果公平性


<details>
  <summary>Details</summary>
Motivation: 现有因果公平方法需要已知因果模型或依赖强假设，且往往无法捕捉关键属性关系，影响数据效用

Method: 将复杂的因果公平关系提取问题转化为定制化的分布估计问题，采用低维边际分解近似联合分布，配合启发式算法解决计算挑战

Result: 在基准数据集上的广泛实验表明，CausalPre既有效又可扩展

Conclusion: 挑战了传统观念，证明无需在关系覆盖度和模型假设之间权衡即可实现因果公平

Abstract: Causal fairness in databases is crucial to preventing biased and inaccurate
outcomes in downstream tasks. While most prior work assumes a known causal
model, recent efforts relax this assumption by enforcing additional
constraints. However, these approaches often fail to capture broader attribute
relationships that are critical to maintaining utility. This raises a
fundamental question: Can we harness the benefits of causal reasoning to design
efficient and effective fairness solutions without relying on strong
assumptions about the underlying causal model? In this paper, we seek to answer
this question by introducing CausalPre, a scalable and effective
causality-guided data pre-processing framework that guarantees justifiable
fairness, a strong causal notion of fairness. CausalPre extracts causally fair
relationships by reformulating the originally complex and computationally
infeasible extraction task into a tailored distribution estimation problem. To
ensure scalability, CausalPre adopts a carefully crafted variant of
low-dimensional marginal factorization to approximate the joint distribution,
complemented by a heuristic algorithm that efficiently tackles the associated
computational challenge. Extensive experiments on benchmark datasets
demonstrate that CausalPre is both effective and scalable, challenging the
conventional belief that achieving causal fairness requires trading off
relationship coverage for relaxed model assumptions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition and Patient Outcomes in an Irish Hospital with Transformers](https://arxiv.org/abs/2509.14942)
*Minh-Khoi Pham,Tai Tan Mai,Martin Crane,Rob Brennan,Marie E. Ward,Una Geary,Declan Byrne,Brian O Connell,Colm Bergin,Donncha Creagh,Nick McDonald,Marija Bezbradica*

Main category: cs.AI

TL;DR: 这研究提出了一种可解释的AI框架，使用Transformer模型分析医院电子病历数据，预测股胶霉素韩生物消化菌菌生物消化菌（CPE）相关病人结果，TabTransformer模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 股胶霉素韩生物消化菌菌生物消化菌（CPE）对医院感染控制构成严重威胁，但使用深度学习方法进行风险预测的研究还很少。

Method: 分析爱尔兰急诊医院的住院患者数据，包括诊断代码、病房转换、人口统计学、感染相关变量和接触网络特征。对比了Transformer架构与传统机器学习模型。

Result: TabTransformer模型在多个临床预测任务中表现最佳，特别是在CPE感染预测上（AUROC和敏感度）。感染相关特征、历史住院曝露、接触网络中心性指标等是关键风险因素。

Conclusion: 该研究提供了一种健壮且可解释的AI框架，证明了Transformer模型在医疗数据分析中的优势，并确定了临床和网络特征对预测CPE相关结果的重要性。

Abstract: Carbapenemase-Producing Enterobacteriace poses a critical concern for
infection prevention and control in hospitals. However, predictive modeling of
previously highlighted CPE-associated risks such as readmission, mortality, and
extended length of stay (LOS) remains underexplored, particularly with modern
deep learning approaches. This study introduces an eXplainable AI modeling
framework to investigate CPE impact on patient outcomes from Electronic Medical
Records data of an Irish hospital. We analyzed an inpatient dataset from an
Irish acute hospital, incorporating diagnostic codes, ward transitions, patient
demographics, infection-related variables and contact network features. Several
Transformer-based architectures were benchmarked alongside traditional machine
learning models. Clinical outcomes were predicted, and XAI techniques were
applied to interpret model decisions. Our framework successfully demonstrated
the utility of Transformer-based models, with TabTransformer consistently
outperforming baselines across multiple clinical prediction tasks, especially
for CPE acquisition (AUROC and sensitivity). We found infection-related
features, including historical hospital exposure, admission context, and
network centrality measures, to be highly influential in predicting patient
outcomes and CPE acquisition risk. Explainability analyses revealed that
features like "Area of Residence", "Admission Ward" and prior admissions are
key risk factors. Network variables like "Ward PageRank" also ranked highly,
reflecting the potential value of structural exposure information. This study
presents a robust and explainable AI framework for analyzing complex EMR data
to identify key risk factors and predict CPE-related outcomes. Our findings
underscore the superior performance of the Transformer models and highlight the
importance of diverse clinical and network features.

</details>


### [14] [Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention](https://arxiv.org/abs/2506.11445)
*Xuan Duy Ta,Bang Giang Le,Thanh Ha Le,Viet Cuong Ta*

Main category: cs.AI

TL;DR: 提出基于局部状态注意力模块的MARL方法，用于解决混合交通环境中自动驾驶车辆的冲突协调问题，在高速公路汇入场景中显著提升效率


<details>
  <summary>Details</summary>
Motivation: 混合交通环境中自动驾驶车辆需要适应人类驾驶车辆和异常情况，传统MARL方法难以解决局部冲突和泛化到随机事件

Method: 使用局部状态注意力模块，通过自注意力算子压缩附近车辆的关键信息来解决交通冲突，在高速公路汇入场景中优先处理其他车辆信息

Result: 在高速公路汇入场景中相比主流基线方法显著提升了汇入效率，特别是在高密度交通环境下效果更明显

Conclusion: 局部状态注意力模块能有效提升MARL在混合交通环境中的性能，为解决自动驾驶车辆协调问题提供了有效方案

Abstract: In mixed-traffic environments, autonomous vehicles must adapt to
human-controlled vehicles and other unusual driving situations. This setting
can be framed as a multi-agent reinforcement learning (MARL) environment with
full cooperative reward among the autonomous vehicles. While methods such as
Multi-agent Proximal Policy Optimization can be effective in training MARL
tasks, they often fail to resolve local conflict between agents and are unable
to generalize to stochastic events. In this paper, we propose a Local State
Attention module to assist the input state representation. By relying on the
self-attention operator, the module is expected to compress the essential
information of nearby agents to resolve the conflict in traffic situations.
Utilizing a simulated highway merging scenario with the priority vehicle as the
unexpected event, our approach is able to prioritize other vehicles'
information to manage the merging process. The results demonstrate significant
improvements in merging efficiency compared to popular baselines, especially in
high-density traffic settings.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [Defining, Understanding, and Detecting Online Toxicity: Challenges and Machine Learning Approaches](https://arxiv.org/abs/2509.14264)
*Gautam Kishore Shahi,Tim A. Majchrzak*

Main category: cs.CL

TL;DR: 这是一份关于在线毒性内容检测的综述性研究，综合了140篇相关文献，分析了数据集、机器学习方法和多语言毒性内容检测的挑战与解决方案。


<details>
  <summary>Details</summary>
Motivation: 在线毒性内容在危机时期、选举和社会动荡期间恶化，需要系统性的研究来提高自动检测能力。

Method: 综合分析140篇相关研究文献，包括数据集定义、数据源、挑战分析以及机器学习方法的系统评估。

Result: 研究涵盖32种语言的毒性内容，探讨了跨平台数据在提升分类模型性能中的应用潜力。

Conclusion: 研究提供了新的毒性内容研究指南和内容审查减少建议，为平台毒性内容管理提供了实践指导。

Abstract: Online toxic content has grown into a pervasive phenomenon, intensifying
during times of crisis, elections, and social unrest. A significant amount of
research has been focused on detecting or analyzing toxic content using
machine-learning approaches. The proliferation of toxic content across digital
platforms has spurred extensive research into automated detection mechanisms,
primarily driven by advances in machine learning and natural language
processing. Overall, the present study represents the synthesis of 140
publications on different types of toxic content on digital platforms. We
present a comprehensive overview of the datasets used in previous studies
focusing on definitions, data sources, challenges, and machine learning
approaches employed in detecting online toxicity, such as hate speech,
offensive language, and harmful discourse. The dataset encompasses content in
32 languages, covering topics such as elections, spontaneous events, and
crises. We examine the possibility of using existing cross-platform data to
improve the performance of classification models. We present the
recommendations and guidelines for new research on online toxic consent and the
use of content moderation for mitigation. Finally, we present some practical
guidelines to mitigate toxic content from online platforms.

</details>


### [16] [SparseDoctor: Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models](https://arxiv.org/abs/2509.14269)
*Zhang Jianbin,Yulin Zhu,Wai Lun Lo,Richard Tai-Chiu Hsung,Harris Sik-Ho Tsang,Kai Zhou*

Main category: cs.CL

TL;DR: 提出SparseDoctor，一种基于对比学习增强的LoRA-MoE架构的稀疏医疗大语言模型，通过自动路由机制和专家记忆队列提高效率，在多个医疗基准测试中优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统LLM微调需要更新数十亿参数，训练成本高昂。为提升医疗LLM的效率和效果，探索LLM在医疗领域的表示能力边界，需要更高效的微调策略。

Method: 采用对比学习增强的LoRA-MoE架构，设计自动路由机制科学分配计算资源，引入专家记忆队列机制提升效率并防止训练时内存溢出。

Result: 在CMB、CMExam和CMMLU-Med三个典型医疗基准测试中，所提模型持续优于HuatuoGPT系列等强基线模型。

Conclusion: SparseDoctor通过创新的稀疏架构和优化机制，有效降低了医疗LLM的训练成本，同时提升了模型性能，为医疗领域LLM的高效应用提供了新思路。

Abstract: Large language models (LLMs) have achieved great success in medical question
answering and clinical decision-making, promoting the efficiency and
popularization of the personalized virtual doctor in society. However, the
traditional fine-tuning strategies on LLM require the updates of billions of
parameters, substantially increasing the training cost, including the training
time and utility cost. To enhance the efficiency and effectiveness of the
current medical LLMs and explore the boundary of the representation capability
of the LLMs on the medical domain, apart from the traditional fine-tuning
strategies from the data perspective (i.e., supervised fine-tuning or
reinforcement learning from human feedback), we instead craft a novel sparse
medical LLM named SparseDoctor armed with contrastive learning enhanced
LoRA-MoE (low rank adaptation-mixture of experts) architecture. To this end,
the crafted automatic routing mechanism can scientifically allocate the
computational resources among different LoRA experts supervised by the
contrastive learning. Additionally, we also introduce a novel expert memory
queue mechanism to further boost the efficiency of the overall framework and
prevent the memory overflow during training. We conduct comprehensive
evaluations on three typical medical benchmarks: CMB, CMExam, and CMMLU-Med.
Experimental results demonstrate that the proposed LLM can consistently
outperform the strong baselines such as the HuatuoGPT series.

</details>


### [17] [Position: Thematic Analysis of Unstructured Clinical Transcripts with Large Language Models](https://arxiv.org/abs/2509.14597)
*Seungjun Yi,Joakim Nguyen,Terence Lim,Andrew Well,Joseph Skrovan,Mehak Beri,YongGeon Lee,Kavita Radhakrishnan,Liu Leqi,Mia Markey,Ying Ding*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型在临床转录本主题分析中的应用现状，发现当前方法在分析类型、数据集、提示策略和评估等方面存在碎片化问题，提出了以有效性、可靠性和可解释性为核心的标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 临床转录本的主题分析是资源密集型方法，需要探索LLMs如何支持这一过程以提高效率和分析质量。

Method: 通过系统回顾近期将LLMs应用于主题分析的研究，并辅以临床医生访谈，分析当前方法的碎片化问题。

Result: 发现现有方法在多个维度上存在碎片化，特别是评估方法差异很大（从定性专家评审到自动相似性指标），阻碍了领域进展和跨研究基准测试。

Conclusion: 建立标准化评估实践对推动该领域发展至关重要，提出了以有效性、可靠性和可解释性三个维度为核心的评估框架。

Abstract: This position paper examines how large language models (LLMs) can support
thematic analysis of unstructured clinical transcripts, a widely used but
resource-intensive method for uncovering patterns in patient and provider
narratives. We conducted a systematic review of recent studies applying LLMs to
thematic analysis, complemented by an interview with a practicing clinician.
Our findings reveal that current approaches remain fragmented across multiple
dimensions including types of thematic analysis, datasets, prompting strategies
and models used, most notably in evaluation. Existing evaluation methods vary
widely (from qualitative expert review to automatic similarity metrics),
hindering progress and preventing meaningful benchmarking across studies. We
argue that establishing standardized evaluation practices is critical for
advancing the field. To this end, we propose an evaluation framework centered
on three dimensions: validity, reliability, and interpretability.

</details>


### [18] [MUSE: MCTS-Driven Red Teaming Framework for Enhanced Multi-Turn Dialogue Safety in Large Language Models](https://arxiv.org/abs/2509.14651)
*Siyu Yan,Long Zeng,Xuecheng Wu,Chengcheng Han,Kongcheng Zhang,Chong Peng,Xuezhi Cao,Xunliang Cai,Chenjuan Guo*

Main category: cs.CL

TL;DR: MUSE框架从攻击和防御两个角度解决多轮对话中的越狱问题，MUSE-A利用框架语义和启发式树搜索进行攻击，MUSE-D通过细粒度安全对齐进行早期防御


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛采用，需要确保其与人类价值观对齐以防止越狱攻击。现有防御主要针对单轮攻击，但现实使用中多轮对话容易让攻击者利用对话上下文绕过安全措施

Method: 提出MUSE框架：1）MUSE-A攻击方法：使用框架语义和启发式树搜索探索多样化语义轨迹；2）MUSE-D防御方法：细粒度安全对齐，在对话早期进行干预

Result: 在各种模型上的广泛实验表明，MUSE能有效识别和缓解多轮漏洞

Conclusion: MUSE框架为多轮越狱攻击提供了全面的攻击和防御解决方案，代码已开源

Abstract: As large language models~(LLMs) become widely adopted, ensuring their
alignment with human values is crucial to prevent jailbreaks where adversaries
manipulate models to produce harmful content. While most defenses target
single-turn attacks, real-world usage often involves multi-turn dialogues,
exposing models to attacks that exploit conversational context to bypass safety
measures. We introduce MUSE, a comprehensive framework tackling multi-turn
jailbreaks from both attack and defense angles. For attacks, we propose MUSE-A,
a method that uses frame semantics and heuristic tree search to explore diverse
semantic trajectories. For defense, we present MUSE-D, a fine-grained safety
alignment approach that intervenes early in dialogues to reduce
vulnerabilities. Extensive experiments on various models show that MUSE
effectively identifies and mitigates multi-turn vulnerabilities. Code is
available at
\href{https://github.com/yansiyu02/MUSE}{https://github.com/yansiyu02/MUSE}.

</details>


### [19] [SINAI at eRisk@CLEF 2023: Approaching Early Detection of Gambling with Natural Language Processing](https://arxiv.org/abs/2509.14797)
*Alba Maria Marmol-Romero,Flor Miriam Plaza-del-Arco,Arturo Montejo-Raez*

Main category: cs.CL

TL;DR: SINAI团队在eRisk@CLEF实验室任务2中，使用Transformer预训练模型结合LSTM架构进行病理性赌博早期检测，在49个参赛提交中排名第7，F1分数0.126，但在召回率和早期检测相关指标上表现最佳


<details>
  <summary>Details</summary>
Motivation: 参与eRisk@CLEF实验室的任务2，专注于病理性赌博的早期检测，这是一个重要的心理健康问题

Method: 基于Transformer架构的预训练模型，结合全面的数据预处理和数据平衡技术，并集成LSTM架构与Transformer的automodels

Result: 在49个参赛提交中排名第7位，F1分数为0.126，但在召回率指标和早期检测相关指标上获得了最高值

Conclusion: 虽然整体排名中等，但在关键的早期检测能力方面表现出色，证明了该方法在识别病理性赌博早期迹象方面的有效性

Abstract: This paper describes the participation of the SINAI team in the eRisk@CLEF
lab. Specifically, one of the proposed tasks has been addressed: Task 2 on the
early detection of signs of pathological gambling. The approach presented in
Task 2 is based on pre-trained models from Transformers architecture with
comprehensive preprocessing data and data balancing techniques. Moreover, we
integrate Long-short Term Memory (LSTM) architecture with automodels from
Transformers. In this Task, our team has been ranked in seventh position, with
an F1 score of 0.126, out of 49 participant submissions and achieves the
highest values in recall metrics and metrics related to early detection.

</details>


### [20] [FURINA: Free from Unmergeable Router via LINear Aggregation of mixed experts](https://arxiv.org/abs/2509.14900)
*Jiayi Han,Liang Du,Yinda Chen,Xiao Kang,Weiyang Ding,Donghong Han*

Main category: cs.CL

TL;DR: FURINA是一种无需路由器的MoE-LoRA方法，通过线性聚合专家实现动态路由，可完全合并到主干模型中，零额外推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有MoE-LoRA方法依赖离散路由器，无法将MoE组件集成到主干模型中，限制了实际应用。

Method: 提出自路由机制：1)解耦LoRA适配器的方向和幅度学习；2)共享可学习幅度向量；3)专家选择损失促进专家激活分化；利用输入与适配器方向分量的角度相似性激活专家。

Result: FURINA显著优于标准LoRA，匹配或超越现有MoE-LoRA方法性能，同时消除MoE的额外推理开销。

Conclusion: FURINA是首个可完全合并到主干模型的无路由器MoE增强LoRA方法，实现了零额外推理成本的高性能参数高效微调。

Abstract: The Mixture of Experts (MoE) paradigm has been successfully integrated into
Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning (PEFT),
delivering performance gains with minimal parameter overhead. However, a key
limitation of existing MoE-LoRA methods is their reliance on a discrete router,
which prevents the integration of the MoE components into the backbone model.
To overcome this, we propose FURINA, a novel Free from Unmergeable Router
framework based on the LINear Aggregation of experts. FURINA eliminates the
router by introducing a Self-Routing mechanism. This is achieved through three
core innovations: (1) decoupled learning of the direction and magnitude for
LoRA adapters, (2) a shared learnable magnitude vector for consistent
activation scaling, and (3) expert selection loss that encourages divergent
expert activation. The proposed mechanism leverages the angular similarity
between the input and each adapter's directional component to activate experts,
which are then scaled by the shared magnitude vector. This design allows the
output norm to naturally reflect the importance of each expert, thereby
enabling dynamic, router-free routing. The expert selection loss further
sharpens this behavior by encouraging sparsity and aligning it with standard
MoE activation patterns. We also introduce a shared expert within the MoE-LoRA
block that provides stable, foundational knowledge. To the best of our
knowledge, FURINA is the first router-free, MoE-enhanced LoRA method that can
be fully merged into the backbone model, introducing zero additional
inference-time cost or complexity. Extensive experiments demonstrate that
FURINA not only significantly outperforms standard LoRA but also matches or
surpasses the performance of existing MoE-LoRA methods, while eliminating the
extra inference-time overhead of MoE.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [21] [Event-LAB: Towards Standardized Evaluation of Neuromorphic Localization Methods](https://arxiv.org/abs/2509.14516)
*Adam D. Hines,Alejandro Fontan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Event-LAB是一个统一框架，用于在多个数据集上运行事件相机定位方法，解决了该领域代码依赖和数据格式多样化带来的比较困难问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机定位研究快速发展，但代码依赖和数据格式多样化使得方法比较和实施变得困难，需要一个统一的框架来简化这一过程。

Method: 使用Pixi包管理器实现单命令行安装和调用，支持多种定位方法和数据集组合，实现了VPR和SLAM两种常见事件定位流程。

Result: 框架能够系统可视化分析多方法和数据集结果，发现事件收集计数和帧生成窗口大小等参数对性能有显著影响。

Conclusion: Event-LAB为研究社区提供了公平比较方法的能力，通过简化多条件设置的工作流程，强调了使用一致事件图像生成参数进行公平比较的重要性。

Abstract: Event-based localization research and datasets are a rapidly growing area of
interest, with a tenfold increase in the cumulative total number of published
papers on this topic over the past 10 years. Whilst the rapid expansion in the
field is exciting, it brings with it an associated challenge: a growth in the
variety of required code and package dependencies as well as data formats,
making comparisons difficult and cumbersome for researchers to implement
reliably. To address this challenge, we present Event-LAB: a new and unified
framework for running several event-based localization methodologies across
multiple datasets. Event-LAB is implemented using the Pixi package and
dependency manager, that enables a single command-line installation and
invocation for combinations of localization methods and datasets. To
demonstrate the capabilities of the framework, we implement two common
event-based localization pipelines: Visual Place Recognition (VPR) and
Simultaneous Localization and Mapping (SLAM). We demonstrate the ability of the
framework to systematically visualize and analyze the results of multiple
methods and datasets, revealing key insights such as the association of
parameters that control event collection counts and window sizes for frame
generation to large variations in performance. The results and analysis
demonstrate the importance of fairly comparing methodologies with consistent
event image generation parameters. Our Event-LAB framework provides this
ability for the research community, by contributing a streamlined workflow for
easily setting up multiple conditions.

</details>


### [22] [Dual-Arm Hierarchical Planning for Laboratory Automation: Vibratory Sieve Shaker Operations](https://arxiv.org/abs/2509.14531)
*Haoran Xiao,Xue Wang,Huimin Lu,Zhiwen Zeng,Zirui Guo,Ziqi Ni,Yicong Ye,Wei Dai*

Main category: cs.RO

TL;DR: 提出分层规划框架解决振动筛自动化操作中的狭窄空间双臂操作、双手交接和受限容器递送等挑战，规划时间减少80.4%，路径点减少89.4%，并通过物理实验验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 解决材料实验室振动筛自动化操作中的三个关键挑战：狭窄空间的双臂盖操作、重叠工作空间的双手交接以及有方向约束的受阻粉末容器递送，这些任务存在采样效率低、轨迹不平滑和传统方法路径不佳等问题。

Method: 提出分层规划框架，结合先验引导路径规划和多步轨迹优化。前者使用有限高斯混合模型提高狭窄通道采样效率，后者通过路径缩短、简化、施加关节约束和B样条平滑来优化路径。

Result: 实验结果显示规划时间减少80.4%，路径点数量减少89.4%。系统在物理实验中成功完成了完整的振动筛操作流程，验证了其实用性。

Conclusion: 该分层规划框架有效解决了复杂实验室自动化中的运动规划挑战，显著提高了规划效率和路径质量，具有实际应用价值。

Abstract: This paper addresses the challenges of automating vibratory sieve shaker
operations in a materials laboratory, focusing on three critical tasks: 1)
dual-arm lid manipulation in 3 cm clearance spaces, 2) bimanual handover in
overlapping workspaces, and 3) obstructed powder sample container delivery with
orientation constraints. These tasks present significant challenges, including
inefficient sampling in narrow passages, the need for smooth trajectories to
prevent spillage, and suboptimal paths generated by conventional methods. To
overcome these challenges, we propose a hierarchical planning framework
combining Prior-Guided Path Planning and Multi-Step Trajectory Optimization.
The former uses a finite Gaussian mixture model to improve sampling efficiency
in narrow passages, while the latter refines paths by shortening, simplifying,
imposing joint constraints, and B-spline smoothing. Experimental results
demonstrate the framework's effectiveness: planning time is reduced by up to
80.4%, and waypoints are decreased by 89.4%. Furthermore, the system completes
the full vibratory sieve shaker operation workflow in a physical experiment,
validating its practical applicability for complex laboratory automation.

</details>


### [23] [Exploratory Movement Strategies for Texture Discrimination with a Neuromorphic Tactile Sensor](https://arxiv.org/abs/2509.14954)
*Xingchen Xu,Ao Li,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 提出受人类探索策略启发的神经形态触觉感知框架，通过NeuroTac传感器采集数据，测试多种探索动作，发现滑动+旋转组合动作在复杂条件下达到87.33%准确率且功耗仅8.04mW


<details>
  <summary>Details</summary>
Motivation: 受人类探索策略启发，开发机器人纹理分类的神经形态触觉感知系统，旨在提升机器人与环境的交互能力

Method: 使用NeuroTac传感器采集神经形态触觉数据，测试六种探索动作（滑动、旋转、敲击及其组合），在固定环境和变化条件下评估性能

Result: 滑动+旋转组合动作在变化接触深度和速度条件下达到最高准确率87.33%，功耗极低仅8.04mW

Conclusion: 滑动+旋转是神经形态触觉感知在纹理分类任务中的最优探索策略，对增强机器人环境交互具有重要前景

Abstract: We propose a neuromorphic tactile sensing framework for robotic texture
classification that is inspired by human exploratory strategies. Our system
utilizes the NeuroTac sensor to capture neuromorphic tactile data during a
series of exploratory motions. We first tested six distinct motions for texture
classification under fixed environment: sliding, rotating, tapping, as well as
the combined motions: sliding+rotating, tapping+rotating, and tapping+sliding.
We chose sliding and sliding+rotating as the best motions based on final
accuracy and the sample timing length needed to reach converged accuracy. In
the second experiment designed to simulate complex real-world conditions, these
two motions were further evaluated under varying contact depth and speeds.
Under these conditions, our framework attained the highest accuracy of 87.33\%
with sliding+rotating while maintaining an extremely low power consumption of
only 8.04 mW. These results suggest that the sliding+rotating motion is the
optimal exploratory strategy for neuromorphic tactile sensing deployment in
texture classification tasks and holds significant promise for enhancing
robotic environmental interaction.

</details>


### [24] [AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](https://arxiv.org/abs/2509.15153)
*Yating Lin,Zixuan Huang,Fan Yang,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出基于扩散模型的AnoF-Diff方法，用于从时间序列数据中提取力-扭矩特征并检测异常，在嘈杂数据集上表现优于现有方法，支持在线异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有多变量时间序列异常检测方法难以直接应用于强力工具使用任务，因为真实世界的传感器数据具有噪声大、非平稳且任务间差异大的特点。

Method: 基于扩散模型提取力-扭矩特征，采用并行异常评分评估方法，支持一步扩散的在线异常检测。

Result: 在四个强力工具使用任务上，F1分数和AUROC指标均优于现有最先进方法，对噪声数据集具有更好的鲁棒性。

Conclusion: AnoF-Diff方法有效解决了强力工具使用场景中的异常检测问题，为在线实时监测提供了可行方案。

Abstract: Multivariate time-series anomaly detection, which is critical for identifying
unexpected events, has been explored in the field of machine learning for
several decades. However, directly applying these methods to data from forceful
tool use tasks is challenging because streaming sensor data in the real world
tends to be inherently noisy, exhibits non-stationary behavior, and varies
across different tasks and tools. To address these challenges, we propose a
method, AnoF-Diff, based on the diffusion model to extract force-torque
features from time-series data and use force-torque features to detect
anomalies. We compare our method with other state-of-the-art methods in terms
of F1-score and Area Under the Receiver Operating Characteristic curve (AUROC)
on four forceful tool-use tasks, demonstrating that our method has better
performance and is more robust to a noisy dataset. We also propose the method
of parallel anomaly score evaluation based on one-step diffusion and
demonstrate how our method can be used for online anomaly detection in several
forceful tool use experiments.

</details>
