<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 7]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Density Estimation and Crowd Counting](https://arxiv.org/abs/2511.09723)
*Balachandra Devarangadi Sunil,Rakshith Venkatesh,Shantanu Todmal*

Main category: cs.CV

TL;DR: 将图像人群密度估计算法扩展到视频分析，引入扩散概率模型生成高质量密度图，通过事件驱动采样减少计算负担，在密集和稀疏场景下均能有效捕捉人群动态。


<details>
  <summary>Details</summary>
Motivation: 解决视频分析中特有的时间挑战，为公共安全、灾难响应和事件管理等实时人群监控应用提供可扩展且高效的框架。

Method: 集成去噪概率模型使用扩散过程生成密度图；采用窄高斯核生成多个密度图输出；加入回归分支进行精确特征提取；基于相似度分数合并密度图；引入基于Farneback光流算法的事件驱动采样技术。

Result: 通过定性和定量评估（包括叠加图和平均绝对误差），模型在密集和稀疏场景下都能有效捕捉人群动态；采样方法显著减少帧数同时保持关键人群事件。

Conclusion: 该工作通过解决视频分析的时间挑战，为实时人群监控提供了一个可扩展且高效的解决方案。

Abstract: This study enhances a crowd density estimation algorithm originally designed for image-based analysis by adapting it for video-based scenarios. The proposed method integrates a denoising probabilistic model that utilizes diffusion processes to generate high-quality crowd density maps. To improve accuracy, narrow Gaussian kernels are employed, and multiple density map outputs are generated. A regression branch is incorporated into the model for precise feature extraction, while a consolidation mechanism combines these maps based on similarity scores to produce a robust final result. An event-driven sampling technique, utilizing the Farneback optical flow algorithm, is introduced to selectively capture frames showing significant crowd movements, reducing computational load and storage by focusing on critical crowd dynamics. Through qualitative and quantitative evaluations, including overlay plots and Mean Absolute Error (MAE), the model demonstrates its ability to effectively capture crowd dynamics in both dense and sparse settings. The efficiency of the sampling method is further assessed, showcasing its capability to decrease frame counts while maintaining essential crowd events. By addressing the temporal challenges unique to video analysis, this work offers a scalable and efficient framework for real-time crowd monitoring in applications such as public safety, disaster response, and event management.

</details>


### [2] [Explicit Temporal-Semantic Modeling for Dense Video Captioning via Context-Aware Cross-Modal Interaction](https://arxiv.org/abs/2511.10134)
*Mingda Jia,Weiliang Meng,Zenghuang Fu,Yiheng Li,Qi Zeng,Yifan Zhang,Ju Xin,Rongtao Xu,Jiguang Zhang,Xiaopeng Zhang*

Main category: cs.CV

TL;DR: 提出CACMI框架，通过跨模态帧聚合和上下文感知特征增强，在密集视频描述任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖隐式建模，使用帧级或碎片化视频特征，无法捕捉事件序列的时间连贯性和视觉上下文中的全面语义

Method: CACMI框架包含两个核心组件：跨模态帧聚合通过跨模态检索提取时间连贯的事件对齐文本特征；上下文感知特征增强利用查询引导注意力整合视觉动态与伪事件语义

Result: 在ActivityNet Captions和YouCook2数据集上的广泛实验表明，CACMI在密集视频描述任务中达到了最先进的性能

Conclusion: CACMI通过显式的时间-语义建模，有效提升了密集视频描述的性能

Abstract: Dense video captioning jointly localizes and captions salient events in untrimmed videos. Recent methods primarily focus on leveraging additional prior knowledge and advanced multi-task architectures to achieve competitive performance. However, these pipelines rely on implicit modeling that uses frame-level or fragmented video features, failing to capture the temporal coherence across event sequences and comprehensive semantics within visual contexts. To address this, we propose an explicit temporal-semantic modeling framework called Context-Aware Cross-Modal Interaction (CACMI), which leverages both latent temporal characteristics within videos and linguistic semantics from text corpus. Specifically, our model consists of two core components: Cross-modal Frame Aggregation aggregates relevant frames to extract temporally coherent, event-aligned textual features through cross-modal retrieval; and Context-aware Feature Enhancement utilizes query-guided attention to integrate visual dynamics with pseudo-event semantics. Extensive experiments on the ActivityNet Captions and YouCook2 datasets demonstrate that CACMI achieves the state-of-the-art performance on dense video captioning task.

</details>


### [3] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 评估不同规模的SmolVLM2模型（500M和2.2B参数）在盲人和低视力用户视频描述任务上的性能，重点关注移动设备部署的可行性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视频描述方面表现出色，但其高内存、计算和部署需求阻碍了实际应用，特别是对于依赖详细、上下文感知描述的盲人和低视力用户。

Method: 在两个多样化数据集（AVCaps户外和Charades室内）上评估SmolVLM2变体，引入两个新颖的评估框架：多上下文BLV框架和导航辅助框架，系统评估四种提示设计策略，并在智能手机上部署FP32和INT8精度变体。

Result: 评估了模型规模对可访问性描述质量的影响，并测试了在资源受限移动设备上的实际性能约束。

Conclusion: 通过专门设计的评估框架和移动部署测试，为开发更适合盲人和低视力用户实际需求的视觉语言模型提供了重要见解。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [4] [Learning to Tell Apart: Weakly Supervised Video Anomaly Detection via Disentangled Semantic Alignment](https://arxiv.org/abs/2511.10334)
*Wenti Yin,Huaxin Zhang,Xiang Wang,Yuqing Lu,Yicheng Zhang,Bingquan Gong,Jialong Zuo,Li Yu,Changxin Gao,Nong Sang*

Main category: cs.CV

TL;DR: 提出DSANet网络，通过粗粒度和细粒度分离异常与正常特征，提升弱监督视频异常检测性能


<details>
  <summary>Details</summary>
Motivation: 现有方法倾向于检测最显著响应片段，忽略了挖掘与异常分离的多样正常模式，且易因相似外观导致类别混淆，细粒度分类结果不理想

Method: 1. 粗粒度：自引导正常性建模分支，在学习的正常原型指导下重构输入视频特征；2. 细粒度：解耦对比语义对齐机制，将视频分解为事件中心和背景中心组件，应用视觉语言对比学习

Result: 在XD-Violence和UCF-Crime两个基准测试中，DSANet优于现有最先进方法

Conclusion: DSANet通过显式分离异常和正常特征，有效增强了弱监督视频异常检测的可区分性

Abstract: Recent advancements in weakly-supervised video anomaly detection have achieved remarkable performance by applying the multiple instance learning paradigm based on multimodal foundation models such as CLIP to highlight anomalous instances and classify categories. However, their objectives may tend to detect the most salient response segments, while neglecting to mine diverse normal patterns separated from anomalies, and are prone to category confusion due to similar appearance, leading to unsatisfactory fine-grained classification results. Therefore, we propose a novel Disentangled Semantic Alignment Network (DSANet) to explicitly separate abnormal and normal features from coarse-grained and fine-grained aspects, enhancing the distinguishability. Specifically, at the coarse-grained level, we introduce a self-guided normality modeling branch that reconstructs input video features under the guidance of learned normal prototypes, encouraging the model to exploit normality cues inherent in the video, thereby improving the temporal separation of normal patterns and anomalous events. At the fine-grained level, we present a decoupled contrastive semantic alignment mechanism, which first temporally decomposes each video into event-centric and background-centric components using frame-level anomaly scores and then applies visual-language contrastive learning to enhance class-discriminative representations. Comprehensive experiments on two standard benchmarks, namely XD-Violence and UCF-Crime, demonstrate that DSANet outperforms existing state-of-the-art methods.

</details>


### [5] [Fragile by Design: On the Limits of Adversarial Defenses in Personalized Generation](https://arxiv.org/abs/2511.10382)
*Zhen Chen,Yi Zhang,Xiangyu Yin,Chengxuan Qin,Xingyu Zhao,Xiaowei Huang,Wenjie Ruan*

Main category: cs.CV

TL;DR: 本文分析了现有对抗性防御方法（如Anti-DreamBooth）在保护用户隐私方面的局限性，指出这些方法存在可感知的伪影且易被简单滤波器去除，提出了AntiDB_Purify评估框架来系统评估防御方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 个性化AI应用如DreamBooth虽然能生成定制内容，但也带来面部身份泄露的隐私风险。现有防御方法存在可感知伪影和易被去除的脆弱性，需要更有效的保护机制。

Method: 提出了AntiDB_Purify评估框架，系统评估现有防御方法在传统图像滤波器和对抗性净化威胁下的表现。

Result: 评估结果显示，当前所有防御方法在净化威胁下都无法保持保护效果，表明现有防御仅提供虚假的安全感。

Conclusion: 现有防御方法存在严重漏洞，迫切需要开发更不可感知和鲁棒的保护机制来保障个性化生成中的用户身份安全。

Abstract: Personalized AI applications such as DreamBooth enable the generation of customized content from user images, but also raise significant privacy concerns, particularly the risk of facial identity leakage. Recent defense mechanisms like Anti-DreamBooth attempt to mitigate this risk by injecting adversarial perturbations into user photos to prevent successful personalization. However, we identify two critical yet overlooked limitations of these methods. First, the adversarial examples often exhibit perceptible artifacts such as conspicuous patterns or stripes, making them easily detectable as manipulated content. Second, the perturbations are highly fragile, as even a simple, non-learned filter can effectively remove them, thereby restoring the model's ability to memorize and reproduce user identity. To investigate this vulnerability, we propose a novel evaluation framework, AntiDB_Purify, to systematically evaluate existing defenses under realistic purification threats, including both traditional image filters and adversarial purification. Results reveal that none of the current methods maintains their protective effectiveness under such threats. These findings highlight that current defenses offer a false sense of security and underscore the urgent need for more imperceptible and robust protections to safeguard user identity in personalized generation.

</details>


### [6] [RodEpil: A Video Dataset of Laboratory Rodents for Seizure Detection and Benchmark Evaluation](https://arxiv.org/abs/2511.10431)
*Daniele Perlo,Vladimir Despotovic,Selma Boudissa,Sang-Yoon Kim,Petr Nazarov,Yanrong Zhang,Max Wintermark,Olivier Keunen*

Main category: cs.CV

TL;DR: 介绍了一个用于检测实验室啮齿动物惊厥事件的视频数据集，包含10,101个阴性样本和2,952个阳性样本，使用TimeSformer模型在五折交叉验证中达到97%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 为临床前癫痫研究提供非侵入性、基于视频的监测方法，需要高质量的标注数据集来支持自动惊厥事件检测。

Method: 收集了19只啮齿动物的短时（10秒）俯视和侧视视频片段，采用严格的受试者划分五折交叉验证，使用基于transformer的视频分类器TimeSformer进行实验。

Result: TimeSformer架构能够区分惊厥和正常活动，平均F1分数达到97%，数据集和基准代码已公开发布。

Conclusion: 该数据集和基线方法为临床前癫痫研究中的非侵入性视频监测提供了可重复的研究基础，证明了基于视频的惊厥检测的可行性。

Abstract: We introduce a curated video dataset of laboratory rodents for automatic detection of convulsive events. The dataset contains short (10~s) top-down and side-view video clips of individual rodents, labeled at clip level as normal activity or seizure. It includes 10,101 negative samples and 2,952 positive samples collected from 19 subjects. We describe the data curation, annotation protocol and preprocessing pipeline, and report baseline experiments using a transformer-based video classifier (TimeSformer). Experiments employ five-fold cross-validation with strict subject-wise partitioning to prevent data leakage (no subject appears in more than one fold). Results show that the TimeSformer architecture enables discrimination between seizure and normal activity with an average F1-score of 97%. The dataset and baseline code are publicly released to support reproducible research on non-invasive, video-based monitoring in preclinical epilepsy research. RodEpil Dataset access - DOI: 10.5281/zenodo.17601357

</details>


### [7] [Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes](https://arxiv.org/abs/2511.10484)
*Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T. S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers*

Main category: cs.CV

TL;DR: 开发了一种全自动方法，通过CT成像生物标志物筛查2型糖尿病，发现胰腺表面分叶度(PSL)在糖尿病患者中显著升高，多变量模型预测T2DM的AUC达到0.90。


<details>
  <summary>Details</summary>
Motivation: 2型糖尿病早期检测很重要，但胰腺表面分叶度在T2DM患者中的作用尚未充分研究。

Method: 使用四种深度学习模型在584名患者数据集中分割胰腺，自动检测PSL，并开发多变量模型预测T2DM。

Result: 糖尿病患者PSL显著更高(4.26±8.32 vs 3.19±3.62)，PancAP模型分割效果最好(Dice=0.79)，T2DM预测模型AUC=0.90，敏感性66.7%，特异性91.9%。

Conclusion: PSL可用于T2DM筛查，并可能帮助预测T2DM早期发病。

Abstract: Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that affects millions of people worldwide. Early detection is crucial as it can alter pancreas function through morphological changes and increased deposition of ectopic fat, eventually leading to organ damage. While studies have shown an association between T2DM and pancreas volume and fat content, the role of increased pancreatic surface lobularity (PSL) in patients with T2DM has not been fully investigated. In this pilot work, we propose a fully automated approach to delineate the pancreas and other abdominal structures, derive CT imaging biomarkers, and opportunistically screen for T2DM. Four deep learning-based models were used to segment the pancreas in an internal dataset of 584 patients (297 males, 437 non-diabetic, age: 45$\pm$15 years). PSL was automatically detected and it was higher for diabetic patients (p=0.01) at 4.26 $\pm$ 8.32 compared to 3.19 $\pm$ 3.62 for non-diabetic patients. The PancAP model achieved the highest Dice score of 0.79 $\pm$ 0.17 and lowest ASSD error of 1.94 $\pm$ 2.63 mm (p$<$0.05). For predicting T2DM, a multivariate model trained with CT biomarkers attained 0.90 AUC, 66.7\% sensitivity, and 91.9\% specificity. Our results suggest that PSL is useful for T2DM screening and could potentially help predict the early onset of T2DM.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization](https://arxiv.org/abs/2511.09578)
*Hadi Keramati,Morteza Sadeghi,Rajeev K. Jaiman*

Main category: cs.LG

TL;DR: 提出基于引导去噪扩散概率模型(DDPM)的生成优化框架，利用代理梯度生成散热器设计，在保持表面温度低于阈值的同时最小化压降。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒优化方法(如CMA-ES)在散热器设计优化中存在计算成本高、扩展性差的问题，需要开发更高效、可扩展的生成优化方法。

Method: 使用边界表示法表示多翅片几何结构，采用多保真度方法生成训练数据。训练DDPM生成散热器设计，同时训练两个残差神经网络预测压降和表面温度，利用代理梯度在推理时引导生成过程满足约束条件。

Result: 引导扩散模型生成的样本压降比传统黑盒优化方法低达10%，且在新约束条件下推理计算成本低，无需重新训练。

Conclusion: 该方法为构建电子冷却基础生成模型迈出了重要一步，展示了生成模型在热管理设计优化中的潜力。

Abstract: This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.

</details>


### [9] [History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754)
*Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa*

Main category: cs.LG

TL;DR: 提出了一种基于宏观经济情境检索的金融预测框架，通过检索历史相似宏观经济阶段来增强预测的鲁棒性，解决传统模型在分布外数据上的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 金融市场具有非平稳性，结构性断裂和宏观经济制度转变会导致传统预测模型在分布外部署时失效。现有的多模态方法简单融合数值指标和文本情感，难以适应这种制度转变。

Method: 引入宏观情境检索框架，在共享相似性空间中联合嵌入宏观指标（CPI、失业率、收益率利差、GDP增长等）和金融新闻情感，实现推理时无需重新训练即可因果检索历史相似时期。

Result: 在17年S&P 500数据上训练，并在AAPL和XOM的2024年分布外数据上评估，该方法显著缩小了CV到OOD性能差距，实现了唯一正向的样本外交易结果（AAPL：PF=1.18，夏普比率=0.95；XOM：PF=1.16，夏普比率=0.61）。

Conclusion: 通过实施"金融历史不会重演但会押韵"的原则，证明基于宏观意识的检索能够在分布变化下产生稳健、可解释的预测，检索到的邻居形成可解释的证据链，对应可识别的宏观情境。

Abstract: Financial markets are inherently non-stationary: structural breaks and macroeconomic regime shifts often cause forecasting models to fail when deployed out of distribution (OOD). Conventional multimodal approaches that simply fuse numerical indicators and textual sentiment rarely adapt to such shifts. We introduce macro-contextual retrieval, a retrieval-augmented forecasting framework that grounds each prediction in historically analogous macroeconomic regimes. The method jointly embeds macro indicators (e.g., CPI, unemployment, yield spread, GDP growth) and financial news sentiment in a shared similarity space, enabling causal retrieval of precedent periods during inference without retraining.
  Trained on seventeen years of S&P 500 data (2007-2023) and evaluated OOD on AAPL (2024) and XOM (2024), the framework consistently narrows the CV to OOD performance gap. Macro-conditioned retrieval achieves the only positive out-of-sample trading outcomes (AAPL: PF=1.18, Sharpe=0.95; XOM: PF=1.16, Sharpe=0.61), while static numeric, text-only, and naive multimodal baselines collapse under regime shifts. Beyond metric gains, retrieved neighbors form interpretable evidence chains that correspond to recognizable macro contexts, such as inflationary or yield-curve inversion phases, supporting causal interpretability and transparency. By operationalizing the principle that "financial history may not repeat, but it often rhymes," this work demonstrates that macro-aware retrieval yields robust, explainable forecasts under distributional change.
  All datasets, models, and source code are publicly available.

</details>


### [10] [NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG](https://arxiv.org/abs/2511.09773)
*Mahdi Samaee,Mehran Yazdi,Daniel Massicotte*

Main category: cs.LG

TL;DR: NeuroLingua是一个受语言启发的睡眠分期框架，将睡眠视为结构化生理语言，通过双级Transformer和GCN多模态融合，在Sleep-EDF和ISRUC数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动睡眠分期中缺乏表达性时间层次结构、多模态EEG和EOG融合挑战以及深度学习模型可解释性有限的问题。

Method: 将30秒epoch分解为3秒子窗口作为"token"，使用CNN分词器，通过双级Transformer进行层次时间建模（局部依赖和跨7个epoch的扩展上下文），使用图卷积网络融合EEG和EOG模态嵌入。

Result: 在Sleep-EDF数据集上达到85.3%准确率、0.800宏观F1和0.796 Cohen's kappa；在ISRUC数据集上达到81.9%准确率、0.802宏观F1和0.755 kappa，匹配或超过已发表基线。

Conclusion: 通过将睡眠框架化为组合语言，NeuroLingua统一了层次序列建模和多模态融合，为睡眠研究中的可解释性、可解释性和因果推理提供了原则性基础。

Abstract: Automated sleep stage classification from polysomnography remains limited by the lack of expressive temporal hierarchies, challenges in multimodal EEG and EOG fusion, and the limited interpretability of deep learning models. We propose NeuroLingua, a language-inspired framework that conceptualizes sleep as a structured physiological language. Each 30-second epoch is decomposed into overlapping 3-second subwindows ("tokens") using a CNN-based tokenizer, enabling hierarchical temporal modeling through dual-level Transformers: intra-segment encoding of local dependencies and inter-segment integration across seven consecutive epochs (3.5 minutes) for extended context. Modality-specific embeddings from EEG and EOG channels are fused via a Graph Convolutional Network, facilitating robust multimodal integration. NeuroLingua is evaluated on the Sleep-EDF Expanded and ISRUC-Sleep datasets, achieving state-of-the-art results on Sleep-EDF (85.3% accuracy, 0.800 macro F1, and 0.796 Cohen's kappa) and competitive performance on ISRUC (81.9% accuracy, 0.802 macro F1, and 0.755 kappa), matching or exceeding published baselines in overall and per-class metrics. The architecture's attention mechanisms enhance the detection of clinically relevant sleep microevents, providing a principled foundation for future interpretability, explainability, and causal inference in sleep research. By framing sleep as a compositional language, NeuroLingua unifies hierarchical sequence modeling and multimodal fusion, advancing automated sleep staging toward more transparent and clinically meaningful applications.

</details>


### [11] [Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning](https://arxiv.org/abs/2511.09871)
*Hyung-Jun Moon,Sung-Bae Cho*

Main category: cs.LG

TL;DR: 提出了一种完全可微、无需示例的扩展方法，使用两个互补记忆模块：一个学习跨任务通用特征，另一个组合共享特征学习样本特有特征。通过自适应修剪和最小化扩展来适应新任务，防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中现有方法强制神经网络孤立处理顺序任务的问题，避免重复学习相似特征或过度区分特征，充分利用任务间有用关系。

Method: 使用两个可微记忆模块：共享特征记忆和样本特有特征记忆。通过记忆调整模块自适应修剪关键槽位、最小化扩展容量，并使用正交正则化保持几何分离以防止干扰。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上优于14种最先进方法，分别达到55.13%、37.24%和30.11%的最终准确率。特征提取结果最接近上限。

Conclusion: 通过有效整合和利用知识，该方法能提高顺序任务的平均性能，为持续学习设立了新的里程碑。

Abstract: Continual learning methods used to force neural networks to process sequential tasks in isolation, preventing them from leveraging useful inter-task relationships and causing them to repeatedly relearn similar features or overly differentiate them. To address this problem, we propose a fully differentiable, exemplar-free expandable method composed of two complementary memories: One learns common features that can be used across all tasks, and the other combines the shared features to learn discriminative characteristics unique to each sample. Both memories are differentiable so that the network can autonomously learn latent representations for each sample. For each task, the memory adjustment module adaptively prunes critical slots and minimally expands capacity to accommodate new concepts, and orthogonal regularization enforces geometric separation between preserved and newly learned memory components to prevent interference. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that the proposed method outperforms 14 state-of-the-art methods for class-incremental learning, achieving final accuracies of 55.13\%, 37.24\%, and 30.11\%, respectively. Additional analysis confirms that, through effective integration and utilization of knowledge, the proposed method can increase average performance across sequential tasks, and it produces feature extraction results closest to the upper bound, thus establishing a new milestone in continual learning.

</details>


### [12] [Towards Multiple Missing Values-resistant Unsupervised Graph Anomaly Detection](https://arxiv.org/abs/2511.09917)
*Jiazhen Chen,Xiuqin Liang,Sichao Fu,Zheng Ma,Weihua Ou*

Main category: cs.LG

TL;DR: 提出M²V-UGAD框架，用于处理图结构数据中节点属性和结构同时缺失的无监督异常检测问题，通过双路径编码器防止跨视图干扰，并利用负样本采样缓解插补偏差。


<details>
  <summary>Details</summary>
Motivation: 现实世界图数据常存在节点属性和结构信息同时缺失的问题，传统插补方法会修复异常节点使其看起来正常，导致检测偏差，且缺失视图间的错误会相互传播。

Method: 使用双路径编码器独立重构缺失的节点属性和图结构，在联合潜在空间中融合和正则化，使正常节点占据紧凑内流形，异常节点位于外表面，并通过采样潜在空间外的编码生成硬负样本来锐化决策边界。

Result: 在七个公开基准测试中，M²V-UGAD在不同缺失率下始终优于现有的无监督图异常检测方法。

Conclusion: M²V-UGAD能有效处理图数据中多视图缺失问题，防止跨视图干扰，缓解插补偏差，显著提升异常检测性能。

Abstract: Unsupervised graph anomaly detection (GAD) has received increasing attention in recent years, which aims to identify data anomalous patterns utilizing only unlabeled node information from graph-structured data. However, prevailing unsupervised GAD methods typically presuppose complete node attributes and structure information, a condition hardly satisfied in real-world scenarios owing to privacy, collection errors or dynamic node arrivals. Existing standard imputation schemes risk "repairing" rare anomalous nodes so that they appear normal, thereby introducing imputation bias into the detection process. In addition, when both node attributes and edges are missing simultaneously, estimation errors in one view can contaminate the other, causing cross-view interference that further undermines the detection performance. To overcome these challenges, we propose M$^2$V-UGAD, a multiple missing values-resistant unsupervised GAD framework on incomplete graphs. Specifically, a dual-pathway encoder is first proposed to independently reconstruct missing node attributes and graph structure, thereby preventing errors in one view from propagating to the other. The two pathways are then fused and regularized in a joint latent space so that normals occupy a compact inner manifold while anomalies reside on an outer shell. Lastly, to mitigate imputation bias, we sample latent codes just outside the normal region and decode them into realistic node features and subgraphs, providing hard negative examples that sharpen the decision boundary. Experiments on seven public benchmarks demonstrate that M$^2$V-UGAD consistently outperforms existing unsupervised GAD methods across varying missing rates.

</details>


### [13] [EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models](https://arxiv.org/abs/2511.09947)
*Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan*

Main category: cs.LG

TL;DR: EEGAgent是一个基于大语言模型的通用脑电图分析框架，能够调度多种工具自动完成多任务EEG分析，包括基本信息感知、时空探索、事件检测、用户交互和报告生成。


<details>
  <summary>Details</summary>
Motivation: 现有EEG模型通常针对特定任务设计，难以应对现实场景中多任务和连续推理的需求，限制了其在临床诊断中的实用性。

Method: 利用大语言模型调度和规划多种工具，设计包含EEG预处理、特征提取、事件检测等功能的工具箱。

Result: 在公共数据集上评估显示，EEGAgent支持灵活且可解释的EEG分析，具有实际临床应用潜力。

Conclusion: EEGAgent框架展示了利用LLM实现通用EEG分析的可行性，为脑电图的临床诊断应用提供了新途径。

Abstract: Scalable and generalizable analysis of brain activity is essential for advancing both clinical diagnostics and cognitive research. Electroencephalography (EEG), a non-invasive modality with high temporal resolution, has been widely used for brain states analysis. However, most existing EEG models are usually tailored for individual specific tasks, limiting their utility in realistic scenarios where EEG analysis often involves multi-task and continuous reasoning. In this work, we introduce EEGAgent, a general-purpose framework that leverages large language models (LLMs) to schedule and plan multiple tools to automatically complete EEG-related tasks. EEGAgent is capable of performing the key functions: EEG basic information perception, spatiotemporal EEG exploration, EEG event detection, interaction with users, and EEG report generation. To realize these capabilities, we design a toolbox composed of different tools for EEG preprocessing, feature extraction, event detection, etc. These capabilities were evaluated on public datasets, and our EEGAgent can support flexible and interpretable EEG analysis, highlighting its potential for real-world clinical applications.

</details>


### [14] [BuddyMoE: Exploiting Expert Redundancy to Accelerate Memory-Constrained Mixture-of-Experts Inference](https://arxiv.org/abs/2511.10054)
*Yun Wang,Lingyun Yang,Senhao Yu,Yixiao Wang,Ruixing Li,Zhixiang Wei,James Yen,Zhengwei Qi*

Main category: cs.LG

TL;DR: MoE模型通过仅激活部分专家网络来减少计算量，但大模型参数超出GPU内存容量，需要将非活跃专家卸载到CPU。现有预取方法在预测失败时会严重影响推理速度或模型精度。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型在预取失败时面临的推理延迟和精度下降的矛盾问题，需要在保持高推理速度的同时维持模型准确性。

Method: 论文未明确说明具体方法，但从问题描述看，需要开发新的技术来处理预取失败的情况，避免PCIe传输延迟或专家丢弃带来的问题。

Result: 内容未提供具体实验结果，但指出了现有方法的局限性：预取失败时要么产生10ms的PCIe传输延迟，要么丢弃专家导致精度显著下降。

Conclusion: MoE模型的关键挑战是在预取失败时同时保持高推理速度和模型精度，需要新的解决方案来克服这一瓶颈。

Abstract: Mixture-of-Experts (MoE) architectures scale language models by activating only a subset of specialized expert networks for each input token, thereby reducing the number of floating-point operations. However, the growing size of modern MoE models causes their full parameter sets to exceed GPU memory capacity; for example, Mixtral-8x7B has 45 billion parameters and requires 87 GB of memory even though only 14 billion parameters are used per token. Existing systems alleviate this limitation by offloading inactive experts to CPU memory, but transferring experts across the PCIe interconnect incurs significant latency (about 10 ms). Prefetching heuristics aim to hide this latency by predicting which experts are needed, but prefetch failures introduce significant stalls and amplify inference latency. In the event of a prefetch failure, prior work offers two primary solutions: either fetch the expert on demand, which incurs a long stall due to the PCIe bottleneck, or drop the expert from the computation, which significantly degrades model accuracy. The critical challenge, therefore, is to maintain both high inference speed and model accuracy when prefetching fails.

</details>


### [15] [How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders](https://arxiv.org/abs/2511.10094)
*Yiming Tang,Abhijeet Sinha,Dianbo Liu*

Main category: cs.LG

TL;DR: 提出了Matryoshka Transcoders框架，用于自动发现和解释生成模型中的物理合理性错误，通过分层稀疏特征学习和多模态模型解释，识别物理相关的失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型虽然能产生逼真输出，但仍存在物理合理性错误，且现有评估方法难以检测这些错误，缺乏自动识别和解释物理错误模式的框架。

Method: 扩展Matryoshka表示学习范式到转码器架构，在物理合理性分类器的中间表示上训练，利用多模态模型进行解释，实现多粒度层次稀疏特征学习。

Result: 相比现有方法，实现了更好的特征相关性和准确性，无需手动特征工程即可识别多样化的物理相关失败模式，建立了评估生成模型物理合理性的基准。

Conclusion: 对八个最先进生成模型的分析揭示了它们如何违反物理约束，为模型改进铺平了道路。

Abstract: Although recent generative models are remarkably capable of producing instruction-following and realistic outputs, they remain prone to notable physical plausibility failures. Though critical in applications, these physical plausibility errors often escape detection by existing evaluation methods. Furthermore, no framework exists for automatically identifying and interpreting specific physical error patterns in natural language, preventing targeted model improvements. We introduce Matryoshka Transcoders, a novel framework for the automatic discovery and interpretation of physical plausibility features in generative models. Our approach extends the Matryoshka representation learning paradigm to transcoder architectures, enabling hierarchical sparse feature learning at multiple granularity levels. By training on intermediate representations from a physical plausibility classifier and leveraging large multimodal models for interpretation, our method identifies diverse physics-related failure modes without manual feature engineering, achieving superior feature relevance and feature accuracy compared to existing approaches. We utilize the discovered visual patterns to establish a benchmark for evaluating physical plausibility in generative models. Our analysis of eight state-of-the-art generative models provides valuable insights into how these models fail to follow physical constraints, paving the way for further model improvements.

</details>


### [16] [Holonorm](https://arxiv.org/abs/2511.10504)
*Daryl Noupa Yongueng,Hamidou Tembine*

Main category: cs.LG

TL;DR: 提出Holonorm作为Transformer中替代Tanh的归一化方法，解决Tanh存在的正交性、线性和失真问题，具有残差连接和非线性特性，能防止激活值爆炸并提升深度Transformer模型的稳定性。


<details>
  <summary>Details</summary>
Motivation: Tanh作为层归一化的替代方法存在正交性、线性和失真问题，导致其可靠性不足，需要开发更有效的归一化方法。

Method: 提出Holonorm方法，具有残差连接和非线性特性，保持信号的正交性、方向和可逆性，将向量映射到开放单位球内，防止激活值爆炸。

Result: Holonorm作为softsign函数的广义形式，适合作为归一化函数，在0到1范围内作为百分比使用，便于模型评估。

Conclusion: Holonorm是替代Tanh的有效归一化方法，能解决Tanh的问题并提升Transformer模型的稳定性。

Abstract: Normalization is a key point in transformer training . In Dynamic Tanh (DyT), the author demonstrated that Tanh can be used as an alternative layer normalization (LN) and confirmed the effectiveness of the idea. But Tanh itself faces orthogonality, linearity and distortion problems. Due to that, his proposition cannot be reliable. So we propose a Holonorm (hn) which has residual connections and nonlinearity. Holonorm is suitable for replacing Tanh in the context of normalization. Although the HoloNorm expression could be similar to the softsign function in dimension one, softsign is a componentwise function which is not good for tensors and vectors of great dimension. Holonorm preserves the orthogonality, the direction, the invertibility of the signal. Holonorm is also a suitable metric, maps all vectors into the open unit ball. This prevents exploding activations and improves stability in deep Transformer models. In this work, we have meticulously examined the normalization in transformers and say that Holonorm, a generalized form of softsign function suited as a normalization function first.Second, defined between 0 and 1 hn serves as a percentage, and $1 - \text{Holonorm}$ is its complement, making it better understandable in evaluating a model.

</details>


### [17] [Oya: Deep Learning for Accurate Global Precipitation Estimation](https://arxiv.org/abs/2511.10562)
*Emmanuel Asiedu Brempong,Mohammed Alewi Hassen,MohamedElfatih MohamedKhair,Vusumuzi Dube,Santiago Hincapie Potes,Olivia Graham,Amanie Brik,Amy McGovern,George Huffman,Jason Hickey*

Main category: cs.LG

TL;DR: Oya是一种新型实时降水反演算法，利用地球静止卫星的可见光和红外全光谱观测，采用两阶段深度学习方法，结合两个U-Net模型分别进行降水检测和定量降水估计，在准全球范围内优于现有降水产品。


<details>
  <summary>Details</summary>
Motivation: 全球南方地区地面观测网络稀疏且预报能力有限，现有卫星降水产品仅依赖长波红外通道或使用可能引入显著误差的校准数据，特别是在次日时间尺度上。

Method: 采用两阶段深度学习框架：一个U-Net用于降水检测，另一个U-Net用于定量降水估计，使用GPM CORRA v07数据作为地面真值，并在IMERG-Final上预训练以增强鲁棒性。

Result: Oya通过利用多个地球静止卫星实现准全球覆盖，在性能上优于现有的竞争性区域和全球降水基线产品。

Conclusion: Oya为改进降水监测和预报提供了一条有前景的途径，特别是在地面观测稀疏的地区。

Abstract: Accurate precipitation estimation is critical for hydrological applications, especially in the Global South where ground-based observation networks are sparse and forecasting skill is limited. Existing satellite-based precipitation products often rely on the longwave infrared channel alone or are calibrated with data that can introduce significant errors, particularly at sub-daily timescales. This study introduces Oya, a novel real-time precipitation retrieval algorithm utilizing the full spectrum of visible and infrared (VIS-IR) observations from geostationary (GEO) satellites. Oya employs a two-stage deep learning approach, combining two U-Net models: one for precipitation detection and another for quantitative precipitation estimation (QPE), to address the inherent data imbalance between rain and no-rain events. The models are trained using high-resolution GPM Combined Radar-Radiometer Algorithm (CORRA) v07 data as ground truth and pre-trained on IMERG-Final retrievals to enhance robustness and mitigate overfitting due to the limited temporal sampling of CORRA. By leveraging multiple GEO satellites, Oya achieves quasi-global coverage and demonstrates superior performance compared to existing competitive regional and global precipitation baselines, offering a promising pathway to improved precipitation monitoring and forecasting.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [Temporal Properties of Conditional Independence in Dynamic Bayesian Networks](https://arxiv.org/abs/2511.10266)
*Rajab Aghamov,Christel Baier,Joel Ouaknine,Jakob Piribauer,Mihir Vahanwala,Isa Vialard*

Main category: cs.AI

TL;DR: 本文研究了动态贝叶斯网络中条件独立性命题演化的验证问题，针对随机性和结构性两种CI属性，分别分析了其计算复杂性和可处理性。


<details>
  <summary>Details</summary>
Motivation: 动态贝叶斯网络是建模概率系统的重要工具，但对其条件独立性命题随时间的演化验证问题尚未得到充分研究。需要开发有效的验证方法来确保系统满足时序逻辑规范。

Method: 使用线性时序逻辑和非确定性Büchi自动机作为规范形式化方法，将CI属性验证分为随机性和结构性两种变体，分别分析其计算复杂性。

Result: 随机性CI属性验证至少与线性递推序列的Skolem问题一样困难；结构性CI属性验证属于PSPACE，且是NP-和coNP-困难的；识别了使结构性CI属性验证可处理的图结构限制。

Conclusion: 动态贝叶斯网络中CI命题的验证具有不同的计算复杂性，结构性属性在特定图结构限制下可高效验证，而随机性属性验证面临重大理论挑战。

Abstract: Dynamic Bayesian networks (DBNs) are compact graphical representations used to model probabilistic systems where interdependent random variables and their distributions evolve over time. In this paper, we study the verification of the evolution of conditional-independence (CI) propositions against temporal logic specifications. To this end, we consider two specification formalisms over CI propositions: linear temporal logic (LTL), and non-deterministic Büchi automata (NBAs). This problem has two variants. Stochastic CI properties take the given concrete probability distributions into account, while structural CI properties are viewed purely in terms of the graphical structure of the DBN. We show that deciding if a stochastic CI proposition eventually holds is at least as hard as the Skolem problem for linear recurrence sequences, a long-standing open problem in number theory. On the other hand, we show that verifying the evolution of structural CI propositions against LTL and NBA specifications is in PSPACE, and is NP- and coNP-hard. We also identify natural restrictions on the graphical structure of DBNs that make the verification of structural CI properties tractable.

</details>


### [19] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: FactGuard是一个利用大语言模型提取事件中心内容来提升假新闻检测性能的框架，通过动态可用性机制和知识蒸馏技术解决风格敏感性和LLM可用性问题。


<details>
  <summary>Details</summary>
Motivation: 随着攻击者模仿真实新闻写作风格，基于写作风格的假新闻检测方法效果逐渐下降，而现有LLM方法存在功能探索浅、可用性模糊和推理成本高等问题。

Method: 提出FactGuard框架：1）利用LLM提取事件中心内容减少写作风格影响；2）引入动态可用性机制识别矛盾案例；3）通过知识蒸馏得到FactGuard-D用于冷启动和资源受限场景。

Result: 在两个基准数据集上的实验表明，该方法在鲁棒性和准确性方面均优于现有方法，有效解决了风格敏感性和LLM可用性挑战。

Conclusion: FactGuard框架成功利用LLM提升假新闻检测性能，通过事件内容提取和动态可用性机制解决了传统方法的局限性，并通过知识蒸馏确保实际部署的可行性。

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


### [20] [Regular Games -- an Automata-Based General Game Playing Language](https://arxiv.org/abs/2511.10593)
*Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik*

Main category: cs.AI

TL;DR: 提出了一个名为Regular Games (RG)的新通用游戏博弈系统，旨在实现计算效率和游戏设计便利性的平衡。该系统使用有限自动机定义游戏规则，具有通用性、高效性和完整的开发工具生态。


<details>
  <summary>Details</summary>
Motivation: 现有通用游戏博弈系统在计算效率和游戏设计便利性方面存在不足，RG系统旨在解决这一矛盾，提供既高效又易于使用的游戏开发平台。

Method: 采用分层语言设计：核心是低级的有限自动机语言定义游戏规则，上层提供面向游戏设计的高级语言。系统支持游戏描述的自动转换和优化。

Result: RG系统在生成前向模型方面比现有系统（如Regular Boardgames、Ludii）更快，计算效率显著提升。同时提供了完整的开发工具生态。

Conclusion: RG系统成功实现了计算效率与游戏设计便利性的平衡，为通用游戏博弈提供了高效实用的解决方案，并建立了完整的工具生态系统。

Abstract: We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based games with imperfect information. Higher-level languages are introduced for game design (by humans or Procedural Content Generation), which are eventually translated to a low-level language. RG generates faster forward models than the current state of the art, beating other GGP systems (Regular Boardgames, Ludii) in terms of efficiency. Additionally, RG's ecosystem includes an editor with LSP, automaton visualization, benchmarking tools, and a debugger of game description transformations.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出一种通过因果视角减少事件和领域相关偏差的方法，提升对灾害事件的泛化能力，在三个灾害分类任务中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体已成为灾害事件信息监测的重要工具，但现有系统存在事件相关偏差问题，影响对新兴事件的泛化能力。

Method: 通过因果视角提出偏差缓解方法，减少事件和领域相关偏差。

Result: 方法在三个灾害分类任务中比多个基线方法高出最多+1.9% F1分数，显著提升了基于预训练语言模型的分类器性能。

Conclusion: 因果学习在灾害事件领域的偏差缓解具有重要价值，能够有效提升模型对新兴事件的泛化能力。

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [22] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: LocalBench是首个系统评估LLM在美国县级本地知识能力的基准，包含14,782个验证问答对，涵盖526个县。评估显示现有模型在本地知识方面存在严重局限，最佳模型在叙事类问题准确率仅56.8%，数值推理低于15.5%。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法捕捉超本地知识的复杂性，而现实应用如公民平台和社区新闻需要AI系统能够推理邻里特定动态、文化叙事和本地治理。

Method: 基于本地性概念框架构建LocalBench基准，整合人口普查数据、本地subreddit讨论和区域新闻，涵盖物理、认知和关系维度。评估13个最先进LLM在闭卷和网络增强设置下的表现。

Result: 模型表现严重不足：最佳模型叙事问题准确率56.8%，数值推理低于15.5%。模型规模和网络增强不保证性能提升，搜索使Gemini准确率提升13.6%，但降低GPT系列11.4%。

Conclusion: 迫切需要能够支持公平、位置感知AI系统的语言模型，能够参与不同地理和文化背景下本地社区的多样化、细粒度现实。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [23] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: URaG是一个统一检索与生成的多模态大语言模型框架，通过利用模型早期层进行证据选择，减少计算开销44-56%，同时提升长文档理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在长文档理解上面临两个挑战：无关内容的信息干扰，以及Transformer架构的二次计算成本。现有方法要么牺牲细节精度，要么增加系统复杂度。

Method: 提出URaG框架，引入轻量级跨模态检索模块，将早期Transformer层转换为高效证据选择器，识别并保留相关页面，让深层专注于关键信息。

Result: 实验表明URaG达到最先进性能，同时减少44-56%的计算开销。

Conclusion: URaG证明了MLLMs固有的证据定位能力可以显式用于推理过程中的检索，实现高效的长文档理解。

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2511.09958)
*Xiangyi Wei,Haotian Zhang,Xinyi Cao,Siyu Xie,Weifeng Ge,Yang Li,Changbo Wang*

Main category: cs.RO

TL;DR: Audio-VLA是一个多模态机器人操作策略，利用接触音频感知接触事件和动态过程反馈，克服了纯视觉VLA模型的局限性，并提出了任务完成率(TCR)指标来系统评估动态操作过程。


<details>
  <summary>Details</summary>
Motivation: 纯视觉VLA模型在感知交互和操作动态过程方面存在根本性限制，需要多模态感知来提升机器人操作性能。

Method: 使用预训练的DINOv2和SigLIP作为视觉编码器，AudioCLIP作为音频编码器，Llama2作为大语言模型骨干，通过LoRA微调和多模态投影层实现跨模态理解，并在仿真环境中添加碰撞音频生成。

Result: 在LIBERO、RLBench和两个真实世界任务上的广泛实验表明，Audio-VLA优于纯视觉对比方法，TCR指标能有效量化动态过程感知能力。

Conclusion: Audio-VLA通过整合音频感知显著提升了机器人操作性能，TCR指标为动态操作过程评估提供了系统化方法。

Abstract: The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

</details>


### [25] [Robot Crash Course: Learning Soft and Stylized Falling](https://arxiv.org/abs/2511.10635)
*Pascal Strauch,David Müller,Sammy Christen,Agon Serifi,Ruben Grandia,Espen Knoop,Moritz Bächer*

Main category: cs.RO

TL;DR: 提出了一种机器人无关的奖励函数，通过强化学习实现双足机器人的受控软着陆，平衡期望姿态达成与冲击最小化，保护关键部件。


<details>
  <summary>Details</summary>
Motivation: 双足机器人在现实世界中仍有跌倒风险，现有研究主要关注防止跌倒，本文专注于跌倒现象本身，旨在减少物理损伤并让用户控制机器人最终姿态。

Method: 使用机器人无关的奖励函数，结合强化学习平衡期望姿态达成、冲击最小化和关键部件保护；引入基于仿真的初始姿态和最终姿态采样策略，使策略对广泛初始跌倒条件具有鲁棒性。

Result: 通过仿真和真实世界实验证明，双足机器人能够执行受控的软着陆。

Conclusion: 即使是双足机器人也能实现受控的软着陆，这为减少机器人跌倒时的物理损伤提供了有效方法。

Abstract: Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.

</details>
