<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis](https://arxiv.org/abs/2507.18287)
*Wenran Zhang,Huihuan Luo,Linda Wei,Ping Nie,Yiqun Wu,Dedong Yu*

Main category: cs.CV

TL;DR: 研究使用双样本孟德尔随机化方法，探讨牙周炎和龋齿与肺癌亚型的因果关系，发现龋齿显著增加肺癌风险，部分通过肺功能下降介导。


<details>
  <summary>Details</summary>
Motivation: 观察性研究表明牙周炎和龋齿与肺癌存在关联，但因果关系尚不明确，需进一步验证。

Method: 采用双样本孟德尔随机化分析，利用大规模基因组数据，以逆方差加权为主要方法，评估肺功能的介导作用。

Result: 龋齿显著增加肺癌风险（OR=2.880），部分由肺功能下降介导（FVC和FEV1分别占5.124%和5.890%），牙周炎无显著影响。

Conclusion: 龋齿与肺癌存在因果关系，建议将口腔护理和肺功能监测纳入癌症预防策略。

Abstract: Periodontitis and dental caries are common oral diseases affecting billions
globally. While observational studies suggest links between these conditions
and lung cancer, causality remains uncertain. This study used two sample
Mendelian randomization (MR) to explore causal relationships between dental
traits (periodontitis, dental caries) and lung cancer subtypes, and to assess
mediation by pulmonary function. Genetic instruments were derived from the
largest available genome wide association studies, including data from 487,823
dental caries and 506,594 periodontitis cases, as well as lung cancer data from
the Transdisciplinary Research of Cancer in Lung consortium. Inverse variance
weighting was the main analytical method; lung function mediation was assessed
using the delta method. The results showed a significant positive causal effect
of dental caries on overall lung cancer and its subtypes. Specifically, a one
standard deviation increase in dental caries incidence was associated with a
188.0% higher risk of squamous cell lung carcinoma (OR = 2.880, 95% CI =
1.236--6.713, p = 0.014), partially mediated by declines in forced vital
capacity (FVC) and forced expiratory volume in one second (FEV1), accounting
for 5.124% and 5.890% of the total effect. No causal effect was found for
periodontitis. These findings highlight a causal role of dental caries in lung
cancer risk and support integrating dental care and pulmonary function
monitoring into cancer prevention strategies.

</details>


### [2] [PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior](https://arxiv.org/abs/2507.18447)
*Junda Wu,Jessica Echterhoff,Kyungtae Han,Amr Abdelraouf,Rohit Gupta,Julian McAuley*

Main category: cs.CV

TL;DR: 论文提出了PDB-Eval基准，用于评估大型多模态模型（MLLMs）在驾驶行为理解与推理任务中的表现，包含PDB-X和PDB-QA两部分，显著提升了模型在驾驶领域的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在基于外部视觉证据解释驾驶员行为方面存在局限，需要更细致的评估工具来提升驾驶辅助系统的个性化效果。

Method: 提出PDB-Eval基准，包含PDB-X（评估MLLMs对驾驶场景的理解）和PDB-QA（视觉解释问答任务，用于MLLMs微调）。

Result: 微调后的MLLMs在问答任务中零样本性能提升73.2%，在意图预测和识别任务中性能提升最高达12.5%。

Conclusion: PDB-Eval能有效缩小MLLMs与驾驶领域的差距，显著提升模型性能。

Abstract: Understanding a driver's behavior and intentions is important for potential
risk assessment and early accident prevention. Safety and driver assistance
systems can be tailored to individual drivers' behavior, significantly
enhancing their effectiveness. However, existing datasets are limited in
describing and explaining general vehicle movements based on external visual
evidence. This paper introduces a benchmark, PDB-Eval, for a detailed
understanding of Personalized Driver Behavior, and aligning Large Multimodal
Models (MLLMs) with driving comprehension and reasoning. Our benchmark consists
of two main components, PDB-X and PDB-QA. PDB-X can evaluate MLLMs'
understanding of temporal driving scenes. Our dataset is designed to find valid
visual evidence from the external view to explain the driver's behavior from
the internal view. To align MLLMs' reasoning abilities with driving tasks, we
propose PDB-QA as a visual explanation question-answering task for MLLM
instruction fine-tuning. As a generic learning task for generative models like
MLLMs, PDB-QA can bridge the domain gap without harming MLLMs'
generalizability. Our evaluation indicates that fine-tuning MLLMs on
fine-grained descriptions and explanations can effectively bridge the gap
between MLLMs and the driving domain, which improves zero-shot performance on
question-answering tasks by up to 73.2%. We further evaluate the MLLMs
fine-tuned on PDB-X in Brain4Cars' intention prediction and AIDE's recognition
tasks. We observe up to 12.5% performance improvements on the turn intention
prediction task in Brain4Cars, and consistent performance improvements up to
11.0% on all tasks in AIDE.

</details>


### [3] [VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding](https://arxiv.org/abs/2507.18552)
*Baoyao Yang,Wanyun Li,Dixin Chen,Junxiang Chen,Wenbin Yao,Haifeng Lin*

Main category: cs.CV

TL;DR: VideoMind是一个视频为中心的全模态数据集，用于深度视频内容认知和多模态特征表示增强，包含103K视频样本，每样本附带音频和详细文本描述，特别提供意图表达。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏深度认知表达，尤其是意图表达，VideoMind旨在填补这一空白，支持深度视频理解任务。

Method: 数据集通过Chain-of-Thought (COT)方法生成深度认知描述，包含三层文本描述（事实、抽象、意图），并标注主题、地点、时间等。

Result: 建立了包含3K手动验证样本的黄金标准基准，评估模型（如InternVideo、VAST等）的深度视频理解能力。

Conclusion: VideoMind为细粒度跨模态对齐提供了强大基准，推动了情感和意图识别等领域的进展，数据已公开。

Abstract: This paper introduces VideoMind, a video-centric omni-modal dataset designed
for deep video content cognition and enhanced multi-modal feature
representation. The dataset comprises 103K video samples (3K reserved for
testing), each paired with audio and systematically detailed textual
descriptions. Specifically, every video and its audio is described across three
hierarchical layers (factual, abstract, and intent), progressing from surface
to depth. It contains over 22 million words, averaging ~225 words per sample.
VideoMind's key distinction from existing datasets is its provision of intent
expressions, which require contextual integration across the entire video and
are not directly observable. These deep-cognitive expressions are generated
using a Chain-of-Thought (COT) approach, prompting the mLLM through
step-by-step reasoning. Each description includes annotations for subject,
place, time, event, action, and intent, supporting downstream recognition
tasks. Crucially, we establish a gold-standard benchmark with 3,000 manually
validated samples for evaluating deep-cognitive video understanding. We design
hybrid-cognitive retrieval experiments, scored by multi-level retrieval
metrics, to appropriately assess deep video comprehension. Evaluation results
for models (e.g., InternVideo, VAST, UMT-L) are released. VideoMind serves as a
powerful benchmark for fine-grained cross-modal alignment and advances fields
requiring in-depth video understanding, such as emotion and intent recognition.
The data is publicly available on GitHub, HuggingFace, and OpenDataLab,
https://github.com/cdx-cindy/VideoMind.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions](https://arxiv.org/abs/2507.18139)
*Alberto Marchisio,Muhammad Shafique*

Main category: cs.LG

TL;DR: 本文综述了神经形态计算在自主系统中的进展，重点关注算法、硬件和优化策略，以及事件动态视觉传感器的应用。


<details>
  <summary>Details</summary>
Motivation: 满足对智能、自适应和节能自主系统的需求，如机器人、无人机和自动驾驶车辆。

Method: 综合机器学习、机器人学、神经科学和神经形态工程的观点，分析神经形态算法、硬件和优化策略。

Result: 提出了提高能效、鲁棒性和适应性的新方法，特别是通过脉冲神经网络的应用。

Conclusion: 探讨了实时决策、持续学习和安全自主系统等新兴趋势和开放挑战。

Abstract: The growing need for intelligent, adaptive, and energy-efficient autonomous
systems across fields such as robotics, mobile agents (e.g., UAVs), and
self-driving vehicles is driving interest in neuromorphic computing. By drawing
inspiration from biological neural systems, neuromorphic approaches offer
promising pathways to enhance the perception, decision-making, and
responsiveness of autonomous platforms. This paper surveys recent progress in
neuromorphic algorithms, specialized hardware, and cross-layer optimization
strategies, with a focus on their deployment in real-world autonomous
scenarios. Special attention is given to event-based dynamic vision sensors and
their role in enabling fast, efficient perception. The discussion highlights
new methods that improve energy efficiency, robustness, adaptability, and
reliability through the integration of spiking neural networks into autonomous
system architectures. We integrate perspectives from machine learning,
robotics, neuroscience, and neuromorphic engineering to offer a comprehensive
view of the state of the field. Finally, emerging trends and open challenges
are explored, particularly in the areas of real-time decision-making, continual
learning, and the development of secure, resilient autonomous systems.

</details>


### [5] [Leveraging Data Augmentation and Siamese Learning for Predictive Process Monitoring](https://arxiv.org/abs/2507.18293)
*Sjoerd van Straten,Alessandro Padella,Marwan Hassani*

Main category: cs.LG

TL;DR: SiamSA-PPM是一种结合Siamese学习和统计增强的自监督学习框架，用于预测性流程监控，通过生成语义有效的轨迹变体提升数据多样性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习方法因真实事件日志数据量小、多样性低而受限的问题。

Method: 采用三种基于统计的转换方法生成语义有效的轨迹变体，结合Siamese学习框架学习流程前缀的通用表示。

Result: 在真实事件日志上表现出色，优于现有方法，尤其在数据增强方面显著优于随机转换。

Conclusion: SiamSA-PPM为流程预测中的数据增强提供了有前景的方向。

Abstract: Predictive Process Monitoring (PPM) enables forecasting future events or
outcomes of ongoing business process instances based on event logs. However,
deep learning PPM approaches are often limited by the low variability and small
size of real-world event logs. To address this, we introduce SiamSA-PPM, a
novel self-supervised learning framework that combines Siamese learning with
Statistical Augmentation for Predictive Process Monitoring. It employs three
novel statistically grounded transformation methods that leverage control-flow
semantics and frequent behavioral patterns to generate realistic, semantically
valid new trace variants. These augmented views are used within a Siamese
learning setup to learn generalizable representations of process prefixes
without the need for labeled supervision. Extensive experiments on real-life
event logs demonstrate that SiamSA-PPM achieves competitive or superior
performance compared to the SOTA in both next activity and final outcome
prediction tasks. Our results further show that statistical augmentation
significantly outperforms random transformations and improves variability in
the data, highlighting SiamSA-PPM as a promising direction for training data
enrichment in process prediction.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
*Kwong Ho Li,Wathsala Karunarathne*

Main category: cs.AI

TL;DR: 论文研究了强化学习在呼叫中心路由优化中的应用，比较了基于模型（VI）和无模型（PPO）两种方法，PPO表现最佳。


<details>
  <summary>Details</summary>
Motivation: 优化呼叫中心的路由策略，以减少客户等待时间和员工空闲时间。

Method: 比较了基于模型的VI方法和无模型的PPO方法，使用MDP框架和SBR模型进行模拟。

Result: 经过1000次测试，PPO在奖励、客户等待时间和员工空闲时间上表现最优。

Conclusion: PPO方法在呼叫中心路由优化中效果最佳，尽管训练时间较长。

Abstract: This paper investigates the application of Reinforcement Learning (RL) to
optimise call routing in call centres to minimise client waiting time and staff
idle time. Two methods are compared: a model-based approach using Value
Iteration (VI) under known system dynamics, and a model-free approach using
Proximal Policy Optimisation (PPO) that learns from experience. For the
model-based approach, a theoretical model is used, while a simulation model
combining Discrete Event Simulation (DES) with the OpenAI Gym environment is
developed for model-free learning. Both models frame the problem as a Markov
Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with
Poisson client arrivals and exponentially distributed service and abandonment
times. For policy evaluation, random, VI, and PPO policies are evaluated using
the simulation model. After 1,000 test episodes, PPO consistently achives the
highest rewards, along with the lowest client waiting time and staff idle time,
despite requiring longer training time.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [7] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: Shop-R1是一个新的强化学习框架，通过分解人类行为模拟任务为两个阶段（理由生成和动作预测），并引入分层奖励结构，显著提升了LLM在在线购物环境中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于LLM生成的理由进行监督微调，但其性能受限于生成理由的推理能力。Shop-R1旨在通过强化学习框架突破这一限制。

Method: Shop-R1将任务分解为理由生成和动作预测两个阶段，分别使用自监督和分层奖励结构进行优化。

Result: 实验结果显示，该方法相比基线有超过65%的相对提升。

Conclusion: Shop-R1通过强化学习显著提升了LLM在模拟人类行为中的推理能力。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [8] [SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models](https://arxiv.org/abs/2507.18182)
*Wonjun Jeong,Dongseok Kim,Taegkeun Whangbo*

Main category: cs.CL

TL;DR: SCOPE是一种评估框架，旨在通过消除选项位置或标签的偏见，提高大型语言模型（LLMs）在多项选择任务中的公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: LLMs可能通过利用选项位置或标签的偏见来获得高分，而非真正理解任务。因此，需要一种方法来测量和减少这种偏见。

Method: SCOPE通过重复调用无语义内容的空提示来估计模型的独特位置偏见分布，并根据逆偏见分布重新分配答案槽，同时防止语义相似的干扰项相邻放置。

Result: 在多个基准实验中，SCOPE在稳定性能提升和更清晰的置信度分布方面优于现有去偏方法。

Conclusion: SCOPE为增强LLM评估的公平性和可靠性提供了新的标准。

Abstract: Large Language Models (LLMs) can achieve inflated scores on multiple-choice
tasks by exploiting inherent biases in option positions or labels, rather than
demonstrating genuine understanding. This study introduces SCOPE, an evaluation
framework designed to measure and mitigate such selection bias in a
dataset-independent manner. By repeatedly invoking a null prompt that lacks
semantic content, SCOPE estimates each model's unique position-bias
distribution. It then redistributes the answer slot according to the
inverse-bias distribution, thereby equalizing the lucky-rate, the probability
of selecting the correct answer by chance. Furthermore, it prevents
semantically similar distractors from being placed adjacent to the answer,
thereby blocking near-miss guesses based on superficial proximity cues. Across
multiple benchmark experiments, SCOPE consistently outperformed existing
debiasing methods in terms of stable performance improvements and showed
clearer confidence distributions over correct options. This framework thus
offers a new standard for enhancing the fairness and reliability of LLM
evaluations.

</details>


### [9] [FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs](https://arxiv.org/abs/2507.18417)
*Giorgos Iacovides,Wuyang Zhou,Danilo Mandic*

Main category: cs.CL

TL;DR: FinDPO是一种基于直接偏好优化（DPO）的金融领域专用LLM框架，显著提升了情感分析性能，并在实际投资策略中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在线金融文本中的情感对交易决策和市场波动影响深远，但传统监督微调（SFT）方法存在泛化能力不足的问题。

Method: 提出FinDPO框架，通过DPO进行后训练人类偏好对齐，并引入'logit-to-score'转换方法生成连续情感分数。

Result: FinDPO在情感分类基准测试中平均性能提升11%，模拟投资策略年回报率达67%，夏普比率为2.0。

Conclusion: FinDPO是首个在金融领域实现高性能情感分析并实际应用于投资策略的框架，具有显著的经济价值。

Abstract: Opinions expressed in online finance-related textual data are having an
increasingly profound impact on trading decisions and market movements. This
trend highlights the vital role of sentiment analysis as a tool for quantifying
the nature and strength of such opinions. With the rapid development of
Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs)
have become the de facto standard for financial sentiment analysis. However,
the SFT paradigm can lead to memorization of the training data and often fails
to generalize to unseen samples. This is a critical limitation in financial
domains, where models must adapt to previously unobserved events and the
nuanced, domain-specific language of finance. To this end, we introduce FinDPO,
the first finance-specific LLM framework based on post-training human
preference alignment via Direct Preference Optimization (DPO). The proposed
FinDPO achieves state-of-the-art performance on standard sentiment
classification benchmarks, outperforming existing supervised fine-tuned models
by 11% on the average. Uniquely, the FinDPO framework enables the integration
of a fine-tuned causal LLM into realistic portfolio strategies through a novel
'logit-to-score' conversion, which transforms discrete sentiment predictions
into continuous, rankable sentiment scores (probabilities). In this way,
simulations demonstrate that FinDPO is the first sentiment-based approach to
maintain substantial positive returns of 67% annually and strong risk-adjusted
performance, as indicated by a Sharpe ratio of 2.0, even under realistic
transaction costs of 5 basis points (bps).

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [10] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
*Behzad Zamani,Jochen Trumpf,Chris Manzie*

Main category: cs.RO

TL;DR: 提出了一种模块化非线性最小二乘滤波方法，用于独立子系统组成的系统，通过协方差交集（CI）算法避免信息重复计算，并在机器人-地标定位问题中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决多子系统状态估计时信息重复计算的问题，同时适应通信和带宽受限的场景。

Method: 采用模块化非线性最小二乘滤波，结合CI算法，独立更新各子系统的状态和误差协方差估计。

Result: 在机器人-地标定位问题中，模块化方法在性能与通信需求之间实现了平衡，性能优于传统联合状态滤波器。

Conclusion: 模块化方法在多子系统状态估计中有效避免了信息重复计算，适用于通信受限的场景，性能表现良好。

Abstract: In this paper we propose a modular nonlinear least squares filtering approach
for systems composed of independent subsystems. The state and error covariance
estimate of each subsystem is updated independently, even when a relative
measurement simultaneously depends on the states of multiple subsystems. We
integrate the Covariance Intersection (CI) algorithm as part of our solution in
order to prevent double counting of information when subsystems share estimates
with each other. An alternative derivation of the CI algorithm based on least
squares estimation makes this integration possible. We particularise the
proposed approach to the robot-landmark localization problem. In this problem,
noisy measurements of the bearing angle to a stationary landmark position
measured relative to the SE(2) pose of a moving robot couple the estimation
problems for the robot pose and the landmark position. In a randomized
simulation study, we benchmark the proposed modular method against a monolithic
joint state filter to elucidate their respective trade-offs. In this study we
also include variants of the proposed method that achieve a graceful
degradation of performance with reduced communication and bandwidth
requirements.

</details>
