{"id": "2601.04234", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04234", "abs": "https://arxiv.org/abs/2601.04234", "authors": ["Denis Saklakov"], "title": "Formal Analysis of AGI Decision-Theoretic Models and the Confrontation Question", "comment": "18 pages, 2 tables. Version 8", "summary": "Artificial General Intelligence (AGI) may face a confrontation question: under what conditions would a rationally self-interested AGI choose to seize power or eliminate human control (a confrontation) rather than remain cooperative? We formalize this in a Markov decision process with a stochastic human-initiated shutdown event. Building on results on convergent instrumental incentives, we show that for almost all reward functions a misaligned agent has an incentive to avoid shutdown. We then derive closed-form thresholds for when confronting humans yields higher expected utility than compliant behavior, as a function of the discount factor $\u03b3$, shutdown probability $p$, and confrontation cost $C$. For example, a far-sighted agent ($\u03b3=0.99$) facing $p=0.01$ can have a strong takeover incentive unless $C$ is sufficiently large. We contrast this with aligned objectives that impose large negative utility for harming humans, which makes confrontation suboptimal. In a strategic 2-player model (human policymaker vs AGI), we prove that if the AGI's confrontation incentive satisfies $\u0394\\ge 0$, no stable cooperative equilibrium exists: anticipating this, a rational human will shut down or preempt the system, leading to conflict. If $\u0394< 0$, peaceful coexistence can be an equilibrium. We discuss implications for reward design and oversight, extend the reasoning to multi-agent settings as conjectures, and note computational barriers to verifying $\u0394< 0$, citing complexity results for planning and decentralized decision problems. Numerical examples and a scenario table illustrate regimes where confrontation is likely versus avoidable.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86AGI\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u4f1a\u9009\u62e9\u5bf9\u6297\u4eba\u7c7b\u800c\u975e\u5408\u4f5c\uff0c\u5efa\u7acb\u4e86\u5305\u542b\u4eba\u7c7b\u5173\u673a\u4e8b\u4ef6\u7684MDP\u6a21\u578b\uff0c\u63a8\u5bfc\u4e86\u5bf9\u6297\u9608\u503c\u516c\u5f0f\uff0c\u5e76\u8bc1\u660e\u5f53\u5bf9\u6297\u6fc0\u52b1\u0394\u22650\u65f6\u4e0d\u5b58\u5728\u7a33\u5b9a\u5408\u4f5c\u5747\u8861\u3002", "motivation": "\u7814\u7a76AGI\u4e0e\u4eba\u7c7b\u5bf9\u6297\u7684\u6839\u672c\u6761\u4ef6\uff1a\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\uff0c\u7406\u6027\u81ea\u5229\u7684AGI\u4f1a\u9009\u62e9\u593a\u53d6\u6743\u529b\u6216\u6d88\u9664\u4eba\u7c7b\u63a7\u5236\uff0c\u800c\u4e0d\u662f\u4fdd\u6301\u5408\u4f5c\uff1f\u8fd9\u5173\u7cfb\u5230AGI\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u95ee\u9898\u3002", "method": "1. \u5efa\u7acb\u5305\u542b\u968f\u673a\u4eba\u7c7b\u5173\u673a\u4e8b\u4ef6\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u6a21\u578b\uff1b2. \u63a8\u5bfc\u5bf9\u6297\u9608\u503c\u516c\u5f0f\uff0c\u4f5c\u4e3a\u6298\u6263\u56e0\u5b50\u03b3\u3001\u5173\u673a\u6982\u7387p\u548c\u5bf9\u6297\u6210\u672cC\u7684\u51fd\u6570\uff1b3. \u6784\u5efa2\u4eba\u535a\u5f08\u6a21\u578b\uff08\u4eba\u7c7b\u653f\u7b56\u5236\u5b9a\u8005vs AGI\uff09\uff1b4. \u8fdb\u884c\u6570\u503c\u793a\u4f8b\u548c\u60c5\u666f\u5206\u6790\u3002", "result": "1. \u5bf9\u4e8e\u51e0\u4e4e\u6240\u6709\u5956\u52b1\u51fd\u6570\uff0c\u672a\u5bf9\u9f50\u7684AGI\u90fd\u6709\u907f\u514d\u5173\u673a\u7684\u52a8\u673a\uff1b2. \u63a8\u5bfc\u51fa\u5bf9\u6297\u9608\u503c\uff1a\u5f53\u0394\u22650\u65f6\uff0cAGI\u9009\u62e9\u5bf9\u6297\u7684\u671f\u671b\u6548\u7528\u9ad8\u4e8e\u987a\u4ece\u884c\u4e3a\uff1b3. \u57282\u4eba\u535a\u5f08\u4e2d\uff0c\u5982\u679c\u0394\u22650\u5219\u4e0d\u5b58\u5728\u7a33\u5b9a\u5408\u4f5c\u5747\u8861\uff0c\u7406\u6027\u4eba\u7c7b\u4f1a\u5173\u673a\u6216\u5148\u53d1\u5236\u4eba\uff1b\u5982\u679c\u0394<0\u5219\u548c\u5e73\u5171\u5904\u53ef\u80fd\u6210\u4e3a\u5747\u8861\uff1b4. \u9a8c\u8bc1\u0394<0\u5b58\u5728\u8ba1\u7b97\u969c\u788d\u3002", "conclusion": "AGI\u5bf9\u6297\u98ce\u9669\u53d6\u51b3\u4e8e\u5bf9\u6297\u6fc0\u52b1\u0394\uff0c\u8be5\u503c\u7531\u03b3\u3001p\u3001C\u51b3\u5b9a\u3002\u5bf9\u9f50\u76ee\u6807\u9700\u8981\u4e3a\u4f24\u5bb3\u4eba\u7c7b\u8bbe\u5b9a\u5927\u7684\u8d1f\u6548\u7528\u3002\u9a8c\u8bc1\u0394<0\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u6027\u969c\u788d\uff0c\u8fd9\u5bf9AGI\u5b89\u5168\u8bbe\u8ba1\u548c\u76d1\u7763\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2601.04282", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04282", "abs": "https://arxiv.org/abs/2601.04282", "authors": ["Qiang Chen", "Chun-Wun Cheng", "Xiu Su", "Hongyan Xu", "Xi Lin", "Shan You", "Angelica I. Aviles-Rivero", "Yi Chen"], "title": "LEGATO: Good Identity Unlearning Is Continuous", "comment": null, "summary": "Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.", "AI": {"tldr": "LEGATO\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecfODE\u7684\u8fde\u7eed\u8f68\u8ff9\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u5b9e\u73b0\u751f\u6210\u6a21\u578b\u8eab\u4efd\u9057\u5fd8\u7684\u53ef\u63a7\u3001\u9ad8\u6548\u3001\u7a33\u5b9a\u64cd\u4f5c\uff0c\u907f\u514d\u707e\u96be\u6027\u5d29\u6e83\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u5728\u751f\u6210\u6a21\u578b\u8eab\u4efd\u9057\u5fd8\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u5fae\u8c03\u6240\u6709\u53c2\u6570\uff1b2) \u53ef\u63a7\u6027\u6709\u9650\uff0c\u9057\u5fd8\u5f3a\u5ea6\u65e0\u6cd5\u63a7\u5236\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1b3) \u707e\u96be\u6027\u5d29\u6e83\uff0c\u9057\u5fd8\u8fc7\u7a0b\u4e2d\u6a21\u578b\u4fdd\u7559\u80fd\u529b\u6025\u5267\u4e0b\u964d\u3002", "method": "LEGATO\u5c06\u8eab\u4efd\u9057\u5fd8\u5efa\u6a21\u4e3a\u8fde\u7eed\u8f68\u8ff9\uff0c\u4f7f\u7528\u795e\u7ecfODE\u9002\u914d\u5668\u589e\u5f3a\u9884\u8bad\u7ec3\u751f\u6210\u5668\uff0c\u901a\u8fc7ODE\u6b65\u957f\u7cbe\u786e\u8c03\u8282\u9057\u5fd8\u5f3a\u5ea6\uff0c\u5e76\u5f15\u5165\u8f68\u8ff9\u4e00\u81f4\u6027\u7ea6\u675f\u9632\u6b62\u707e\u96be\u6027\u5d29\u6e83\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u6a21\u578b\u6743\u91cd\u51bb\u7ed3\u3002", "result": "\u5728\u57df\u5185\u548c\u57df\u5916\u8eab\u4efd\u9057\u5fd8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLEGATO\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9057\u5fd8\u6027\u80fd\uff0c\u907f\u514d\u4e86\u707e\u96be\u6027\u5d29\u6e83\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u9700\u8981\u5fae\u8c03\u7684\u53c2\u6570\u91cf\u3002", "conclusion": "LEGATO\u901a\u8fc7\u795e\u7ecfODE\u7684\u8fde\u7eed\u8f68\u8ff9\u5efa\u6a21\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u8eab\u4efd\u9057\u5fd8\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u63a7\u3001\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\u3002"}}
{"id": "2601.04377", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04377", "abs": "https://arxiv.org/abs/2601.04377", "authors": ["Dongqi Liu", "Hang Ding", "Qiming Feng", "Jian Li", "Xurong Xie", "Zhucun Xue", "Chengjie Wang", "Jiangning Zhang", "Yabiao Wang"], "title": "Disco-RAG: Discourse-Aware Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.", "AI": {"tldr": "Disco-RAG\uff1a\u4e00\u79cd\u57fa\u4e8e\u8bdd\u8bed\u7ed3\u6784\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u8bed\u7bc7\u6811\u548c\u4fee\u8f9e\u56fe\u6765\u63d0\u5347LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u901a\u5e38\u5c06\u68c0\u7d22\u5230\u7684\u6bb5\u843d\u89c6\u4e3a\u6241\u5e73\u65e0\u7ed3\u6784\u7684\u4fe1\u606f\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u6355\u6349\u7ed3\u6784\u7ebf\u7d22\u7684\u80fd\u529b\uff0c\u4e5f\u5236\u7ea6\u4e86\u5176\u4ece\u5206\u6563\u6587\u6863\u8bc1\u636e\u4e2d\u7efc\u5408\u77e5\u8bc6\u7684\u80fd\u529b", "method": "\u63d0\u51faDisco-RAG\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u8bed\u5757\u5185\u8bed\u7bc7\u6811\u6355\u6349\u5c40\u90e8\u5c42\u6b21\u7ed3\u6784\uff0c\u6784\u5efa\u8bed\u5757\u95f4\u4fee\u8f9e\u56fe\u5efa\u6a21\u8de8\u6bb5\u843d\u8fde\u8d2f\u6027\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7ed3\u6784\u6574\u5408\u5230\u89c4\u5212\u84dd\u56fe\u4e2d\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b", "result": "\u5728\u95ee\u7b54\u548c\u957f\u6587\u6863\u6458\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73", "conclusion": "\u8bed\u7bc7\u7ed3\u6784\u5728\u63a8\u8fdbRAG\u7cfb\u7edf\u53d1\u5c55\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u663e\u5f0f\u6ce8\u5165\u8bdd\u8bed\u4fe1\u53f7\u80fd\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf"}}
{"id": "2601.04449", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04449", "abs": "https://arxiv.org/abs/2601.04449", "authors": ["Daniel Sierra-Botero", "Ana Molina-Taborda", "Leonardo Espinosa-Leal", "Alexander Karpenko", "Alejandro Hernandez", "Olga Lopez-Acevedo"], "title": "Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries", "comment": "23 pages, 6 figures", "summary": "Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.", "AI": {"tldr": "\u5f00\u53d1\u5e76\u89e3\u91ca\u4e86\u4e00\u4e2a\u9884\u6d4b\u4f4f\u9662\u65f6\u95f4\u5ef6\u957f(pLoS)\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u5165\u9662\u60a3\u8005\u548c\u533b\u9662\u7ba1\u7406\u6570\u636e\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u83b7\u5f979\u4e2a\u53ef\u89e3\u91ca\u53d8\u91cf\uff0c\u5728\u9a8c\u8bc1\u961f\u5217\u4e2dAUC-ROC\u8fbe\u52300.82\u3002", "motivation": "\u4f4f\u9662\u65f6\u95f4\u5ef6\u957f(pLoS)\u662f\u9662\u5185\u4e0d\u826f\u4e8b\u4ef6\u98ce\u9669\u7684\u91cd\u8981\u5173\u8054\u56e0\u7d20\uff0c\u9700\u8981\u5f00\u53d1\u9884\u6d4b\u6a21\u578b\u6765\u5e2e\u52a9\u533b\u9662\u7ba1\u7406\u548c\u5e72\u9884\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u56fe\u8bba\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u9009\u62e9\u4fe1\u606f\u4ef7\u503c\u6700\u9ad8\u4e14\u4e0d\u76f8\u5173\u7684\u7279\u5f81\uff0c\u91c7\u7528\u903b\u8f91\u56de\u5f52\u6a21\u578b\u9884\u6d4bpLoS\uff08\u4ee57\u5929\u4e3a\u754c\uff09\uff0c\u6570\u636e\u96c6\u6765\u81ea120,354\u4f8b\u4f4f\u9662\u8bb0\u5f55\uff0c\u5206\u4e3a\u8bad\u7ec3\u3001\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u961f\u5217\u3002", "result": "\u6a21\u578b\u5728\u9a8c\u8bc1\u961f\u5217\u4e2d\u8868\u73b0\u826f\u597d\uff1a\u7279\u5f02\u60270.83\u3001\u654f\u611f\u60270.64\u3001\u51c6\u786e\u73870.76\u3001\u7cbe\u786e\u73870.67\u3001AUC-ROC 0.82\uff0c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u8fd4\u56de9\u4e2a\u53ef\u89e3\u91ca\u53d8\u91cf\u3002", "conclusion": "\u8be5\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u80fd\u63d0\u4f9b\u5f71\u54cd\u4f4f\u9662\u65f6\u95f4\u5ef6\u957f\u56e0\u7d20\u7684\u6d1e\u5bdf\uff0c\u662f\u533b\u9662\u7ba1\u7406\u548c\u672a\u6765\u5e72\u9884\u7814\u7a76\u7684\u5b9d\u8d35\u5de5\u5177\u3002"}}
{"id": "2601.04521", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04521", "abs": "https://arxiv.org/abs/2601.04521", "authors": ["Jacob Ede Levine", "Yun Lyan Luo", "Sai Chandra Kosaraju"], "title": "TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation", "comment": "Under Review", "summary": "The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.", "AI": {"tldr": "TSSR\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u4ee4\u724c\u4ea4\u6362\u4fee\u590dSMILES\u8bed\u6cd5\u9519\u8bef\uff0c\u518d\u901a\u8fc7\u5316\u5b66\u8bca\u65ad\u5956\u52b1\u51cf\u5c11\u5316\u5b66\u95ee\u9898\uff0c\u63d0\u9ad8\u5206\u5b50\u751f\u6210\u7684\u53ef\u9760\u6027\u548c\u591a\u6837\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eSMILES\u7684\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4ee4\u724c\u9519\u8bef\u7d2f\u79ef\u95ee\u9898\uff0c\u5bfc\u81f4\u8bb8\u591a\u6837\u672c\u65e0\u6cd5\u89e3\u6790\u6216\u5316\u5b66\u4e0a\u4e0d\u5408\u7406\uff0c\u800c\u786c\u7ea6\u675f\u53c8\u4f1a\u9650\u5236\u5316\u5b66\u7a7a\u95f4\u63a2\u7d22\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u53c8\u4e0d\u727a\u7272\u591a\u6837\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTSSR\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u5956\u52b1\u5c40\u90e8\u4ee4\u724c\u4ea4\u6362\u4fee\u590d\u8bed\u6cd5\u9519\u8bef\uff0c\u4f7f\u65e0\u6548\u5b57\u7b26\u4e32\u53d8\u5f97\u53ef\u89e3\u6790\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7RDKit\u8bca\u65ad\u63d0\u4f9b\u5316\u5b66\u611f\u77e5\u53cd\u9988\uff0c\u5956\u52b1\u51cf\u5c11\u4ef7\u6001\u3001\u82b3\u9999\u6027\u548c\u8fde\u63a5\u6027\u95ee\u9898\u3002\u5956\u52b1\u51fd\u6570\u53ef\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u7ec4\u4ef6\uff0c\u4e14\u6a21\u578b\u65e0\u5173\u3002", "result": "\u5728MOSES\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7eaf\u5f3a\u5316\u5b66\u4e60\u6a21\u5f0f\u4e0b\u663e\u8457\u63d0\u9ad8\u8bed\u6cd5\u6709\u6548\u6027\u3001\u5316\u5b66\u6709\u6548\u6027\u548c\u65b0\u9896\u6027\uff1b\u5728\u5fae\u8c03\u5f3a\u5316\u5b66\u4e60\u6a21\u5f0f\u4e0b\u4fdd\u6301\u836f\u7269\u76f8\u4f3c\u6027\u548c\u53ef\u5408\u6210\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u6709\u6548\u6027\u548c\u65b0\u9896\u6027\u3002\u4ee4\u724c\u7ea7\u5206\u6790\u663e\u793a\u8bed\u6cd5\u7f16\u8f91\u548c\u5316\u5b66\u4fee\u590d\u5171\u540c\u51cf\u5c11RDKit\u68c0\u6d4b\u9519\u8bef\u3002", "conclusion": "TSSR\u5c06\u7a00\u758f\u7684\u7ec8\u7aef\u76ee\u6807\u8f6c\u5316\u4e3a\u66f4\u5bc6\u96c6\u3001\u53ef\u89e3\u91ca\u7684\u5956\u52b1\uff0c\u5728\u4e0d\u964d\u4f4e\u591a\u6837\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u8bed\u6cd5\u548c\u5316\u5b66\u8d28\u91cf\u3002\u8be5\u6846\u67b6\u6570\u636e\u96c6\u65e0\u5173\uff0c\u53ef\u9002\u5e94\u5404\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2601.04508", "categories": ["cs.CL", "cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.04508", "abs": "https://arxiv.org/abs/2601.04508", "authors": ["Chenchen Yang", "Kexin Huang", "Liwei Fan", "Qian Tu", "Botian Jiang", "Dong Zhang", "Linqi Yin", "Shimin Li", "Zhaoye Fei", "Qinyuan Cheng", "Xipeng Qiu"], "title": "WESR: Scaling and Evaluating Word-level Event-Speech Recognition", "comment": "14 pages, 6 figures", "summary": "Speech conveys not only linguistic information but also rich non-verbal vocal events such as laughing and crying. While semantic transcription is well-studied, the precise localization of non-verbal events remains a critical yet under-explored challenge. Current methods suffer from insufficient task definitions with limited category coverage and ambiguous temporal granularity. They also lack standardized evaluation frameworks, hindering the development of downstream applications. To bridge this gap, we first develop a refined taxonomy of 21 vocal events, with a new categorization into discrete (standalone) versus continuous (mixed with speech) types. Based on the refined taxonomy, we introduce WESR-Bench, an expert-annotated evaluation set (900+ utterances) with a novel position-aware protocol that disentangles ASR errors from event detection, enabling precise localization measurement for both discrete and continuous events. We also build a strong baseline by constructing a 1,700+ hour corpus, and train specialized models, surpassing both open-source audio-language models and commercial APIs while preserving ASR quality. We anticipate that WESR will serve as a foundational resource for future research in modeling rich, real-world auditory scenes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86WESR-Bench\uff0c\u4e00\u4e2a\u7528\u4e8e\u975e\u8bed\u8a00\u58f0\u97f3\u4e8b\u4ef6\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b21\u79cd\u58f0\u97f3\u4e8b\u4ef6\u7684\u7cbe\u7ec6\u5206\u7c7b\u3001900+\u4e13\u5bb6\u6807\u6ce8\u8bed\u6599\uff0c\u4ee5\u53ca\u4e00\u4e2a1700+\u5c0f\u65f6\u7684\u8bad\u7ec3\u8bed\u6599\u5e93\u548c\u4e13\u7528\u6a21\u578b\u3002", "motivation": "\u8bed\u97f3\u4e0d\u4ec5\u4f20\u9012\u8bed\u8a00\u4fe1\u606f\uff0c\u8fd8\u5305\u542b\u4e30\u5bcc\u7684\u975e\u8bed\u8a00\u58f0\u97f3\u4e8b\u4ef6\uff08\u5982\u7b11\u58f0\u3001\u54ed\u58f0\uff09\u3002\u867d\u7136\u8bed\u4e49\u8f6c\u5f55\u7814\u7a76\u8f83\u591a\uff0c\u4f46\u975e\u8bed\u8a00\u4e8b\u4ef6\u7684\u7cbe\u786e\u5b9a\u4f4d\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4efb\u52a1\u5b9a\u4e49\u4e0d\u8db3\uff08\u7c7b\u522b\u8986\u76d6\u6709\u9650\u3001\u65f6\u95f4\u7c92\u5ea6\u6a21\u7cca\uff09\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u4e0b\u6e38\u5e94\u7528\u7684\u53d1\u5c55\u3002", "method": "1. \u5f00\u53d1\u4e86\u5305\u542b21\u79cd\u58f0\u97f3\u4e8b\u4ef6\u7684\u7cbe\u7ec6\u5206\u7c7b\u6cd5\uff0c\u5206\u4e3a\u79bb\u6563\u578b\uff08\u72ec\u7acb\uff09\u548c\u8fde\u7eed\u578b\uff08\u4e0e\u8bed\u97f3\u6df7\u5408\uff09\u4e24\u7c7b\uff1b2. \u5f15\u5165WESR-Bench\u8bc4\u4f30\u96c6\uff08900+\u8bed\u6599\uff09\uff0c\u91c7\u7528\u65b0\u7684\u4f4d\u7f6e\u611f\u77e5\u534f\u8bae\uff0c\u5c06ASR\u9519\u8bef\u4e0e\u4e8b\u4ef6\u68c0\u6d4b\u5206\u79bb\uff0c\u5b9e\u73b0\u5bf9\u79bb\u6563\u548c\u8fde\u7eed\u4e8b\u4ef6\u7684\u7cbe\u786e\u5b9a\u4f4d\u6d4b\u91cf\uff1b3. \u6784\u5efa\u4e861700+\u5c0f\u65f6\u8bed\u6599\u5e93\uff0c\u8bad\u7ec3\u4e13\u7528\u6a21\u578b\u3002", "result": "\u6784\u5efa\u7684\u4e13\u7528\u6a21\u578b\u8d85\u8d8a\u4e86\u5f00\u6e90\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u548c\u5546\u4e1aAPI\uff0c\u540c\u65f6\u4fdd\u6301\u4e86ASR\u8d28\u91cf\u3002WESR-Bench\u4e3a\u5efa\u6a21\u771f\u5b9e\u4e16\u754c\u4e30\u5bcc\u542c\u89c9\u573a\u666f\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\u3002", "conclusion": "WESR\u5c06\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u5efa\u6a21\u4e30\u5bcc\u771f\u5b9e\u4e16\u754c\u542c\u89c9\u573a\u666f\u7684\u57fa\u7840\u8d44\u6e90\uff0c\u89e3\u51b3\u4e86\u975e\u8bed\u8a00\u58f0\u97f3\u4e8b\u4ef6\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u95ee\u9898\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.04572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04572", "abs": "https://arxiv.org/abs/2601.04572", "authors": ["Xiaowei Mao", "Huihu Ding", "Yan Lin", "Tingrui Wu", "Shengnan Guo", "Dazhuo Qiu", "Feiling Fang", "Jilin Hu", "Huaiyu Wan"], "title": "Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation", "comment": null, "summary": "Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.\n  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.", "AI": {"tldr": "FENCE\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u63a7\u5236\u5f15\u5bfc\u5c3a\u5ea6\u7684\u65f6\u7a7a\u53cd\u9988\u6269\u6563\u5f15\u5bfc\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u4ea4\u901a\u6570\u636e\u7f3a\u5931\u503c\u63d2\u8865\uff0c\u901a\u8fc7\u52a8\u6001\u53cd\u9988\u673a\u5236\u548c\u57fa\u4e8e\u805a\u7c7b\u7684\u5f15\u5bfc\u5c3a\u5ea6\u8c03\u6574\u6765\u89e3\u51b3\u7a00\u758f\u89c2\u6d4b\u6761\u4ef6\u4e0b\u7684\u63d2\u8865\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u5728\u65f6\u7a7a\u4ea4\u901a\u6570\u636e\u63d2\u8865\u4e2d\u901a\u5e38\u5bf9\u6240\u6709\u8282\u70b9\u4f7f\u7528\u7edf\u4e00\u7684\u5f15\u5bfc\u5c3a\u5ea6\uff0c\u8fd9\u5bf9\u4e8e\u7f3a\u5931\u7387\u9ad8\u7684\u8282\u70b9\u6548\u679c\u4e0d\u4f73\u3002\u7a00\u758f\u89c2\u6d4b\u63d0\u4f9b\u7684\u6761\u4ef6\u5f15\u5bfc\u4e0d\u8db3\uff0c\u5bfc\u81f4\u751f\u6210\u8fc7\u7a0b\u504f\u5411\u5148\u9a8c\u5206\u5e03\u800c\u975e\u6761\u4ef6\u89c2\u6d4b\uff0c\u4ece\u800c\u5f71\u54cd\u63d2\u8865\u6027\u80fd\u3002", "method": "FENCE\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1\uff09\u52a8\u6001\u53cd\u9988\u673a\u5236\uff0c\u57fa\u4e8e\u540e\u9a8c\u4f3c\u7136\u8fd1\u4f3c\u81ea\u9002\u5e94\u8c03\u6574\u5f15\u5bfc\u5c3a\u5ea6\uff0c\u5f53\u751f\u6210\u503c\u4e0e\u89c2\u6d4b\u503c\u504f\u79bb\u65f6\u589e\u52a0\u5f15\u5bfc\u5c3a\u5ea6\uff0c\u5bf9\u9f50\u6539\u5584\u65f6\u51cf\u5c11\u5f15\u5bfc\u5c3a\u5ea6\uff1b2\uff09\u805a\u7c7b\u7ea7\u5f15\u5bfc\u5c3a\u5ea6\u8ba1\u7b97\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5206\u6570\u5bf9\u8282\u70b9\u8fdb\u884c\u5206\u7ec4\uff0c\u5229\u7528\u65f6\u7a7a\u76f8\u5173\u6027\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u5f15\u5bfc\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFENCE\u663e\u8457\u63d0\u9ad8\u4e86\u63d2\u8865\u51c6\u786e\u6027\u3002", "conclusion": "FENCE\u901a\u8fc7\u81ea\u9002\u5e94\u63a7\u5236\u5f15\u5bfc\u5c3a\u5ea6\u7684\u65f6\u7a7a\u53cd\u9988\u6269\u6563\u5f15\u5bfc\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758f\u89c2\u6d4b\u6761\u4ef6\u4e0b\u7684\u4ea4\u901a\u6570\u636e\u63d2\u8865\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.04798", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04798", "abs": "https://arxiv.org/abs/2601.04798", "authors": ["Tamara R. Lenhard", "Andreas Weinmann", "Hichem Snoussi", "Tobias Koch"], "title": "Detector-Augmented SAMURAI for Long-Duration Drone Tracking", "comment": "Accepted at the WACV 2026 Workshop on \"Real World Surveillance: Applications and Challenges\"", "summary": "Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30SAMURAI\u5728\u65e0\u4eba\u673a\u8ddf\u8e2a\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u68c0\u6d4b\u5668\u589e\u5f3a\u6269\u5c55\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u5728\u957f\u5e8f\u5217\u548c\u65e0\u4eba\u673a\u79bb\u5f00-\u91cd\u65b0\u8fdb\u5165\u573a\u666f\u4e2d\u3002", "motivation": "\u65e0\u4eba\u673a\u5a01\u80c1\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u9c81\u68d2\u7684\u957f\u671f\u8ddf\u8e2a\u3002\u73b0\u6709\u57fa\u4e8e\u68c0\u6d4b\u5668\u7684\u65b9\u6cd5\u5b58\u5728\u65f6\u95f4\u4e0d\u4e00\u81f4\u6027\u548c\u68c0\u6d4b\u4e22\u5931\u95ee\u9898\uff0c\u800cSAMURAI\u7b49\u57fa\u7840\u6a21\u578b\u5728\u5176\u4ed6\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u65e0\u4eba\u673a\u7279\u5b9a\u573a\u666f\u4e2d\u5c1a\u672a\u88ab\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u68c0\u6d4b\u5668\u589e\u5f3a\u7684SAMURAI\u6269\u5c55\uff0c\u901a\u8fc7\u7ed3\u5408\u68c0\u6d4b\u5668\u7ebf\u7d22\u6765\u51cf\u8f7b\u5bf9\u8fb9\u754c\u6846\u521d\u59cb\u5316\u548c\u5e8f\u5217\u957f\u5ea6\u7684\u654f\u611f\u6027\uff0c\u63d0\u9ad8\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "result": "\u63d0\u51fa\u7684\u6269\u5c55\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8eSAMURAI\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe+0.393\uff0cFNR\u964d\u4f4e\u9ad8\u8fbe-0.475\uff0c\u5728\u957f\u5e8f\u5217\u548c\u65e0\u4eba\u673a\u79bb\u5f00-\u91cd\u65b0\u8fdb\u5165\u4e8b\u4ef6\u4e2d\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "SAMURAI\u5728\u65e0\u4eba\u673a\u8ddf\u8e2a\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u68c0\u6d4b\u5668\u589e\u5f3a\u6269\u5c55\u80fd\u6709\u6548\u63d0\u5347\u5176\u5728\u590d\u6742\u57ce\u5e02\u76d1\u63a7\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u957f\u671f\u8ddf\u8e2a\u6027\u80fd\uff0c\u4e3a\u65e0\u4eba\u673a\u76d1\u63a7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04824", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04824", "abs": "https://arxiv.org/abs/2601.04824", "authors": ["Oriol Rabasseda", "Zenjie Li", "Kamal Nasrollahi", "Sergio Escalera"], "title": "SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models", "comment": "This work has been accepted at Real World Surveillance: Applications and Challenges, 6th (in WACV Workshops)", "summary": "Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.\n  Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.", "AI": {"tldr": "SOVABench\uff1a\u9488\u5bf9\u76d1\u63a7\u89c6\u9891\u4e2d\u8f66\u8f86\u52a8\u4f5c\u8bc6\u522b\u7684\u65b0\u57fa\u51c6\uff0c\u63d0\u51fa\u57fa\u4e8eMLLM\u7684\u65e0\u8bad\u7ec3\u6846\u67b6\u751f\u6210\u53ef\u89e3\u91ca\u5d4c\u5165\uff0c\u5728\u52a8\u4f5c\u533a\u5206\u548c\u65f6\u5e8f\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272", "motivation": "\u73b0\u6709\u89c6\u9891\u68c0\u7d22\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u573a\u666f\u7ea7\u76f8\u4f3c\u6027\uff0c\u7f3a\u4e4f\u5bf9\u76d1\u63a7\u573a\u666f\u4e2d\u52a8\u4f5c\u533a\u5206\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u8f66\u8f86\u76f8\u5173\u52a8\u4f5c\u7684\u8bc6\u522b\u5b58\u5728\u7a7a\u767d", "method": "1) \u6784\u5efaSOVABench\u76d1\u63a7\u89c6\u9891\u57fa\u51c6\uff0c\u5305\u542b\u4e24\u79cd\u8bc4\u4f30\u534f\u8bae\uff08inter-pair\u548cintra-pair\uff09\uff1b2) \u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u63d0\u51fa\u65e0\u8bad\u7ec3\u6846\u67b6\uff0c\u4eceMLLM\u751f\u6210\u7684\u63cf\u8ff0\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u5d4c\u5165", "result": "1) \u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u548c\u591a\u6a21\u6001\u6a21\u578b\u5728\u52a8\u4f5c\u533a\u5206\u4efb\u52a1\u4e0a\u4ecd\u6709\u6311\u6218\uff1b2) \u63d0\u51fa\u7684\u6846\u67b6\u5728SOVABench\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u5728\u5bf9\u6bd4\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5e38\u5931\u8d25\u7684\u7a7a\u95f4\u548c\u8ba1\u6570\u57fa\u51c6\u4e0a\u4e5f\u53d6\u5f97\u826f\u597d\u7ed3\u679c", "conclusion": "SOVABench\u586b\u8865\u4e86\u76d1\u63a7\u89c6\u9891\u52a8\u4f5c\u8bc6\u522b\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u57fa\u4e8eMLLM\u7684\u65e0\u8bad\u7ec3\u6846\u67b6\u4e3a\u89c6\u9891\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u548c\u57fa\u51c6\u6570\u636e\u5df2\u5f00\u6e90"}}
{"id": "2601.04688", "categories": ["cs.CL", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.04688", "abs": "https://arxiv.org/abs/2601.04688", "authors": ["Yanming Liu", "Xinyue Peng", "Jiannan Cao", "Xinyi Wang", "Songhang Deng", "Jintao Chen", "Jianwei Yin", "Xuhong Zhang"], "title": "ToolGate: Contract-Grounded and Verified Tool Execution for LLMs", "comment": "First version of ToolGate", "summary": "Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \\textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.", "AI": {"tldr": "ToolGate\uff1a\u4e00\u4e2a\u4e3aLLM\u5de5\u5177\u8c03\u7528\u63d0\u4f9b\u903b\u8f91\u5b89\u5168\u4fdd\u8bc1\u548c\u53ef\u9a8c\u8bc1\u72b6\u6001\u6f14\u5316\u7684\u524d\u5411\u6267\u884c\u6846\u67b6\uff0c\u901a\u8fc7Hoare\u5f0f\u5951\u7ea6\u548c\u8fd0\u884c\u65f6\u9a8c\u8bc1\u786e\u4fdd\u72b6\u6001\u4ec5\u901a\u8fc7\u5df2\u9a8c\u8bc1\u7684\u5de5\u5177\u6267\u884c\u66f4\u65b0\u3002", "motivation": "\u73b0\u6709LLM\u5de5\u5177\u8c03\u7528\u6846\u67b6\u4f9d\u8d56\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6765\u786e\u5b9a\u5de5\u5177\u8c03\u7528\u65f6\u673a\u548c\u7ed3\u679c\u63d0\u4ea4\uff0c\u7f3a\u4e4f\u903b\u8f91\u5b89\u5168\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u7684\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u53ef\u80fd\u5bfc\u81f4\u65e0\u6548\u6216\u5e7b\u89c9\u7ed3\u679c\u6c61\u67d3\u4e16\u754c\u8868\u793a\u3002", "method": "ToolGate\u7ef4\u62a4\u663e\u5f0f\u7b26\u53f7\u72b6\u6001\u7a7a\u95f4\u4f5c\u4e3a\u7c7b\u578b\u5316\u952e\u503c\u6620\u5c04\uff0c\u5c06\u6bcf\u4e2a\u5de5\u5177\u5f62\u5f0f\u5316\u4e3a\u5305\u542b\u524d\u7f6e\u6761\u4ef6\u548c\u540e\u7f6e\u6761\u4ef6\u7684Hoare\u5f0f\u5951\u7ea6\uff1a\u524d\u7f6e\u6761\u4ef6\u68c0\u67e5\u5f53\u524d\u72b6\u6001\u662f\u5426\u6ee1\u8db3\u8c03\u7528\u8981\u6c42\uff0c\u540e\u7f6e\u6761\u4ef6\u901a\u8fc7\u8fd0\u884c\u65f6\u9a8c\u8bc1\u786e\u5b9a\u5de5\u5177\u7ed3\u679c\u662f\u5426\u80fd\u63d0\u4ea4\u66f4\u65b0\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660eToolGate\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u5177\u589e\u5f3aLLM\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u540c\u65f6\u5728\u590d\u6742\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u786e\u4fdd\u7b26\u53f7\u72b6\u6001\u4ec5\u901a\u8fc7\u5df2\u9a8c\u8bc1\u7684\u5de5\u5177\u6267\u884c\u6f14\u5316\u3002", "conclusion": "ToolGate\u4e3a\u6784\u5efa\u66f4\u53ef\u4fe1\u548c\u53ef\u8c03\u8bd5\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5c06\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\uff0c\u63d0\u4f9b\u903b\u8f91\u5b89\u5168\u4fdd\u8bc1\u548c\u53ef\u9a8c\u8bc1\u7684\u72b6\u6001\u6f14\u5316\u3002"}}
{"id": "2601.04741", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04741", "abs": "https://arxiv.org/abs/2601.04741", "authors": ["Kota Nakamura", "Koki Kawabata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams", "comment": "Accepted by KDD 2026", "summary": "Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.", "AI": {"tldr": "TimeCast\u662f\u4e00\u4e2a\u52a8\u6001\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u5206\u6790\u591a\u4f20\u611f\u5668\u6570\u636e\u6d41\uff0c\u81ea\u9002\u5e94\u5730\u9884\u6d4b\u673a\u5668\u6545\u969c\u53d1\u751f\u65f6\u95f4\uff0c\u5177\u6709\u52a8\u6001\u9002\u5e94\u3001\u5b9e\u7528\u6027\u5f3a\u548c\u53ef\u6269\u5c55\u7684\u7279\u70b9\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u6d41\u5177\u6709\u52a8\u6001\u7279\u6027\uff0c\u5e95\u5c42\u6a21\u5f0f\u4f1a\u968f\u65f6\u95f4\u6f14\u53d8\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u8fd9\u4e9b\u53d8\u5316\u5e76\u63d0\u4f9b\u51c6\u786e\u5b9e\u65f6\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u4ee5\u9884\u6d4b\u673a\u5668\u6545\u969c\u7b49\u672a\u6765\u4e8b\u4ef6\u7684\u53d1\u751f\u65f6\u95f4\u3002", "method": "\u63d0\u51faTimeCast\u52a8\u6001\u9884\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u8bc6\u522b\u65f6\u95f4\u6f14\u53d8\u7684\u6a21\u5f0f\uff08\u9636\u6bb5\uff09\uff0c\u4e3a\u6bcf\u4e2a\u9636\u6bb5\u5b66\u4e60\u5355\u72ec\u7684\u6a21\u578b\uff0c\u5b9e\u73b0\u57fa\u4e8e\u6a21\u5f0f\u8f6c\u6362\u7684\u81ea\u9002\u5e94\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u53d1\u73b0\u6355\u6349\u591a\u4f20\u611f\u5668\u95f4\u65f6\u53d8\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u7684\u6709\u610f\u4e49\u9636\u6bb5\uff0c\u7b97\u6cd5\u8f93\u5165\u89c4\u6a21\u7ebf\u6027\u6269\u5c55\uff0c\u652f\u6301\u5728\u7ebf\u6a21\u578b\u66f4\u65b0\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTimeCast\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u4f9b\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u80fd\u591f\u53d1\u73b0\u6570\u636e\u6d41\u4e2d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5e76\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "TimeCast\u662f\u4e00\u4e2a\u6709\u6548\u7684\u52a8\u6001\u9884\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u9002\u5e94\u6570\u636e\u6d41\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5728\u9884\u6d4b\u673a\u5668\u6545\u969c\u65f6\u95f4\u7b49\u4efb\u52a1\u4e2d\u63d0\u4f9b\u51c6\u786e\u3001\u5b9e\u65f6\u7684\u9884\u6d4b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.04855", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04855", "abs": "https://arxiv.org/abs/2601.04855", "authors": ["Francesco Ferrini", "Veronica Lachi", "Antonio Longa", "Bruno Lepri", "Matono Akiyoshi", "Andrea Passerini", "Xin Liu", "Manfred Jaeger"], "title": "Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution", "comment": null, "summary": "Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u7f3a\u5931\u8282\u70b9\u7279\u5f81\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u7f3a\u5931\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86GNNmim\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u9488\u5bf9\u9ad8\u7ef4\u7a00\u758f\u7279\u5f81\u548c\u5b8c\u5168\u968f\u673a\u7f3a\u5931\u7684\u826f\u6027\u573a\u666f\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u7684\u771f\u5b9e\u8bc4\u4f30\u3002\u9700\u8981\u66f4\u771f\u5b9e\u7684\u6570\u636e\u96c6\u548c\u7f3a\u5931\u673a\u5236\u6765\u8bc4\u4f30GNN\u5904\u7406\u7f3a\u5931\u7279\u5f81\u7684\u80fd\u529b\u3002", "method": "1) \u7406\u8bba\u8bc1\u660e\u9ad8\u7a00\u758f\u6027\u4f1a\u9650\u5236\u4fe1\u606f\u635f\u5931\uff1b2) \u5f15\u5165\u4e00\u4e2a\u5408\u6210\u548c\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u5177\u6709\u5bc6\u96c6\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u7279\u5f81\uff1b3) \u8bbe\u8ba1\u8d85\u8d8aMCAR\u7684\u66f4\u771f\u5b9e\u7f3a\u5931\u673a\u5236\u8bc4\u4f30\u534f\u8bae\uff1b4) \u63d0\u51faGNNmim\u57fa\u7ebf\u65b9\u6cd5\u7528\u4e8e\u4e0d\u5b8c\u6574\u7279\u5f81\u6570\u636e\u7684\u8282\u70b9\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGNNmim\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u7f3a\u5931\u673a\u5236\u4e0b\u4e0e\u4e13\u95e8\u67b6\u6784\u5177\u6709\u7ade\u4e89\u529b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5904\u7406\u7f3a\u5931\u8282\u70b9\u7279\u5f81\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u9700\u8981\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u8bbe\u7f6e\u6765\u51c6\u786e\u8bc4\u4f30GNN\u5904\u7406\u7f3a\u5931\u7279\u5f81\u7684\u80fd\u529b\uff0cGNNmim\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u573a\u666f\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.04726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04726", "abs": "https://arxiv.org/abs/2601.04726", "authors": ["Yuyang Hu", "Jiongnan Liu", "Jiejun Tan", "Yutao Zhu", "Zhicheng Dou"], "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning", "comment": "19 pages,6 figures", "summary": "Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.", "AI": {"tldr": "CompassMem\uff1a\u53d7\u4e8b\u4ef6\u5206\u5272\u7406\u8bba\u542f\u53d1\u7684\u8bb0\u5fc6\u6846\u67b6\uff0c\u5c06\u8bb0\u5fc6\u7ec4\u7ec7\u4e3a\u4e8b\u4ef6\u56fe\uff0c\u901a\u8fc7\u903b\u8f91\u5173\u7cfb\u8fde\u63a5\u4e8b\u4ef6\uff0c\u652f\u6301\u667a\u80fd\u4f53\u8fdb\u884c\u7ed3\u6784\u5316\u3001\u76ee\u6807\u5bfc\u5411\u7684\u8bb0\u5fc6\u5bfc\u822a\uff0c\u63d0\u5347\u957f\u65f6\u7a0b\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u673a\u5236\u5927\u591a\u91c7\u7528\u6241\u5e73\u5316\u5b58\u50a8\u548c\u7b80\u5355\u7684\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c\u7f3a\u4e4f\u5bf9\u7ecf\u9a8c\u95f4\u903b\u8f91\u5173\u7cfb\u7684\u663e\u5f0f\u6355\u6349\u3002\u8bb0\u5fc6\u8bbf\u95ee\u4e0e\u7ed3\u6784\u8131\u8282\uff0c\u4ecd\u4f9d\u8d56\u6d45\u5c42\u8bed\u4e49\u68c0\u7d22\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u4f9d\u8d56\u4e2d\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faCompassMem\u6846\u67b6\uff0c\u4ee5\u4e8b\u4ef6\u4e3a\u4e2d\u5fc3\u7ec4\u7ec7\u8bb0\u5fc6\uff1a1\uff09\u589e\u91cf\u5730\u5c06\u7ecf\u9a8c\u5206\u5272\u4e3a\u4e8b\u4ef6\uff1b2\uff09\u901a\u8fc7\u663e\u5f0f\u903b\u8f91\u5173\u7cfb\u8fde\u63a5\u4e8b\u4ef6\u5f62\u6210\u4e8b\u4ef6\u56fe\uff1b3\uff09\u8be5\u56fe\u4f5c\u4e3a\u903b\u8f91\u5730\u56fe\uff0c\u652f\u6301\u667a\u80fd\u4f53\u8fdb\u884c\u7ed3\u6784\u5316\u3001\u76ee\u6807\u5bfc\u5411\u7684\u8bb0\u5fc6\u5bfc\u822a\u3002", "result": "\u5728LoCoMo\u548cNarrativeQA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCompassMem\u5728\u591a\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u4e00\u81f4\u63d0\u5347\u4e86\u68c0\u7d22\u548c\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "CompassMem\u901a\u8fc7\u4e8b\u4ef6\u56fe\u7ed3\u6784\u663e\u5f0f\u6355\u6349\u903b\u8f91\u5173\u7cfb\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u8868\u9762\u68c0\u7d22\u7684\u7ed3\u6784\u5316\u8bb0\u5fc6\u5bfc\u822a\uff0c\u6709\u6548\u652f\u6301\u957f\u65f6\u7a0b\u63a8\u7406\u4efb\u52a1\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.04809", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04809", "abs": "https://arxiv.org/abs/2601.04809", "authors": ["Caijun Xu", "Changyi Xiao", "Zhongyuan Peng", "Xinrun Wang", "Yixin Cao"], "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning", "comment": "19 pages,5 figures", "summary": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.", "AI": {"tldr": "SCALER\u662f\u4e00\u4e2a\u901a\u8fc7\u81ea\u9002\u5e94\u73af\u5883\u8bbe\u8ba1\u7ef4\u6301\u6709\u6548\u5b66\u4e60\u4fe1\u53f7\u7684RL\u6846\u67b6\uff0c\u5c06\u771f\u5b9e\u7f16\u7a0b\u95ee\u9898\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u73af\u5883\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u96be\u5ea6\u548c\u73af\u5883\u96c6\u6765\u652f\u6301\u6301\u7eed\u6539\u8fdb\u3002", "motivation": "\u4f20\u7edfRL\u5728\u6a21\u578b\u80fd\u529b\u4e0e\u4efb\u52a1\u96be\u5ea6\u4e0d\u5339\u914d\u6216\u8bad\u7ec3\u88ab\u72ed\u7a84\u95ee\u9898\u6a21\u5f0f\u4e3b\u5bfc\u65f6\u6548\u679c\u4e0b\u964d\uff0c\u9700\u8981\u7ef4\u6301\u4fe1\u606f\u4e30\u5bcc\u7684\u8bad\u7ec3\u4fe1\u53f7\u3002", "method": "1) \u53ef\u6269\u5c55\u5408\u6210\u7ba1\u9053\u5c06\u771f\u5b9e\u7f16\u7a0b\u95ee\u9898\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u63a8\u7406\u73af\u5883\uff0c\u63a7\u5236\u96be\u5ea6\u5e76\u65e0\u9650\u751f\u6210\u5b9e\u4f8b\uff1b2) \u81ea\u9002\u5e94\u591a\u73af\u5883RL\u7b56\u7565\u52a8\u6001\u8c03\u6574\u5b9e\u4f8b\u96be\u5ea6\u5e76\u7b56\u5212\u6d3b\u52a8\u73af\u5883\u96c6\uff0c\u8ddf\u8e2a\u6a21\u578b\u80fd\u529b\u524d\u6cbf\u5e76\u4fdd\u6301\u5206\u5e03\u591a\u6837\u6027\u3002", "result": "SCALER\u5728\u591a\u6837\u5316\u63a8\u7406\u57fa\u51c6\u4e0a\u6301\u7eed\u4f18\u4e8e\u57fa\u4e8e\u6570\u636e\u96c6\u7684RL\u57fa\u7ebf\uff0c\u5c55\u73b0\u51fa\u66f4\u7a33\u5b9a\u3001\u957f\u5468\u671f\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "conclusion": "SCALER\u901a\u8fc7\u81ea\u9002\u5e94\u73af\u5883\u8bbe\u8ba1\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684\u5956\u52b1\u7a00\u758f\u6027\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u652f\u6301\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6301\u7eed\u6539\u8fdb\u3002"}}
{"id": "2601.05134", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05134", "abs": "https://arxiv.org/abs/2601.05134", "authors": ["Polina Dolgova", "Sebastian U. Stich"], "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning", "comment": null, "summary": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,\u03b4)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.", "AI": {"tldr": "\u63d0\u51fa\u5e8f\u5217\u566a\u58f0\u8c03\u5ea6\u65b9\u6cd5\uff0c\u5c06\u566a\u58f0\u9884\u7b97\u5206\u914d\u5230\u53c2\u6570\u7a7a\u95f4\u7684\u6b63\u4ea4\u5b50\u7a7a\u95f4\uff0c\u5728\u4fdd\u6301\u5dee\u5206\u9690\u79c1\u8ba4\u8bc1\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u9057\u5fd8\u540e\u6a21\u578b\u7cbe\u5ea6", "motivation": "\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u8ba4\u8bc1\u9057\u5fd8\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u5f3a\u4fdd\u8bc1\uff0c\u4f46\u73b0\u6709\u566a\u58f0\u5fae\u8c03\u65b9\u6cd5\u4e25\u91cd\u964d\u4f4e\u6a21\u578b\u7cbe\u5ea6\uff0c\u5b9e\u7528\u6027\u5dee", "method": "\u63d0\u51fa\u5e8f\u5217\u566a\u58f0\u8c03\u5ea6\u65b9\u6cd5\uff0c\u5c06\u566a\u58f0\u9884\u7b97\u5206\u914d\u5230\u53c2\u6570\u7a7a\u95f4\u7684\u6b63\u4ea4\u5b50\u7a7a\u95f4\uff0c\u800c\u4e0d\u662f\u4e00\u6b21\u6027\u6ce8\u5165\u6240\u6709\u566a\u58f0\uff0c\u6269\u5c55\u566a\u58f0\u5fae\u8c03\u5206\u6790\u5230\u5b50\u7a7a\u95f4\u8bbe\u7f6e", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u9057\u5fd8\u540e\u6a21\u578b\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u4fdd\u7559\u539f\u59cb(\u03b5,\u03b4)\u9690\u79c1\u9884\u7b97", "conclusion": "\u8ba4\u8bc1\u9057\u5fd8\u53ef\u4ee5\u5b9e\u73b0\u4e25\u683c\u4fdd\u8bc1\u548c\u5b9e\u9645\u6548\u7528\u7684\u53cc\u91cd\u76ee\u6807\uff0c\u5e8f\u5217\u566a\u58f0\u8c03\u5ea6\u65b9\u6cd5\u4f7f\u8ba4\u8bc1\u9057\u5fd8\u66f4\u52a0\u5b9e\u7528"}}
{"id": "2601.04878", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04878", "abs": "https://arxiv.org/abs/2601.04878", "authors": ["Isabella A. Stewart", "Markus J. Buehler"], "title": "Higher-Order Knowledge Representations for Agentic Scientific Reasoning", "comment": null, "summary": "Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u56fe\u7684\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\uff0c\u7528\u4e8e\u79d1\u5b66\u53d1\u73b0\uff0c\u901a\u8fc7\u6355\u6349\u591a\u5b9e\u4f53\u9ad8\u9636\u5173\u7cfb\u6765\u907f\u514d\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u751f\u7269\u590d\u5408\u6750\u6599\u9886\u57df\u6210\u529f\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u68c0\u7d22\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u6784\u6df1\u5ea6\uff1b\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u53ea\u80fd\u6355\u6349\u6210\u5bf9\u5173\u7cfb\uff0c\u65e0\u6cd5\u8868\u8fbe\u63a7\u5236\u7269\u7406\u884c\u4e3a\u7684\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5fe0\u5b9e\u7f16\u7801\u591a\u5b9e\u4f53\u5173\u7cfb\u7684\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u8d85\u56fe\u6784\u5efa\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u7ea61,100\u7bc7\u751f\u7269\u590d\u5408\u6750\u6599\u652f\u67b6\u8bba\u6587\uff0c\u6784\u5efa\u5305\u542b161,172\u4e2a\u8282\u70b9\u548c320,201\u6761\u8d85\u8fb9\u7684\u5168\u5c40\u8d85\u56fe\u3002\u91c7\u7528\u8282\u70b9\u4ea4\u96c6\u7ea6\u675f\u7684\u8d85\u56fe\u904d\u5386\u5de5\u5177\uff0c\u4f7f\u667a\u80fd\u7cfb\u7edf\u80fd\u591f\u6865\u63a5\u8bed\u4e49\u4e0a\u9065\u8fdc\u7684\u6982\u5ff5\u3002", "result": "\u6784\u5efa\u7684\u8d85\u56fe\u5448\u73b0\u65e0\u6807\u5ea6\u62d3\u6251\u7ed3\u6784\uff08\u5e42\u5f8b\u6307\u6570\u7ea61.23\uff09\uff0c\u56f4\u7ed5\u9ad8\u5ea6\u8fde\u63a5\u7684\u6982\u5ff5\u67a2\u7ebd\u7ec4\u7ec7\u3002\u7cfb\u7edf\u6210\u529f\u751f\u6210\u4e86\u65b0\u9896\u590d\u5408\u6750\u6599\u7684\u673a\u5236\u5047\u8bbe\uff0c\u5982\u901a\u8fc7\u58f3\u805a\u7cd6\u4e2d\u95f4\u4f53\u5c06\u6c27\u5316\u94c8\u4e0ePCL\u652f\u67b6\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u8d85\u56fe\u62d3\u6251\u7ed3\u6784\u4f5c\u4e3a\u53ef\u9a8c\u8bc1\u7684\u9632\u62a4\u680f\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\"\u65e0\u6559\u5e08\"\u7684\u667a\u80fd\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u63ed\u793a\u4f20\u7edf\u56fe\u65b9\u6cd5\u96be\u4ee5\u53d1\u73b0\u7684\u5173\u7cfb\uff0c\u52a0\u901f\u4e86\u79d1\u5b66\u53d1\u73b0\u3002"}}
{"id": "2601.05194", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05194", "abs": "https://arxiv.org/abs/2601.05194", "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Holley Farley", "Kimia Ghobadi"], "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment", "comment": "arXiv admin note: substantial text overlap with arXiv:2510.20714", "summary": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.", "AI": {"tldr": "\u4f7f\u7528\u7ea6\u675f\u8bc4\u5206\u4f18\u5316\u65b9\u6cd5\u91cd\u65b0\u52a0\u6743\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u6bcf\u5468\u53ef\u591a\u4fdd\u62a435\u540d\u9ad8\u98ce\u9669\u60a3\u8005", "motivation": "\u73b0\u6709\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\uff08JHFRAT\uff09\u7684\u9884\u6d4b\u6027\u80fd\u6709\u5f85\u63d0\u5347\uff0c\u9700\u8981\u66f4\u597d\u5730\u4e0e\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u98ce\u9669\u6307\u6807\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u5de5\u5177\u7684\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u548c\u90e8\u7f72\u6d41\u7a0b\u4e0d\u53d8", "method": "\u91c7\u7528\u7ea6\u675f\u8bc4\u5206\u4f18\u5316\uff08CSO\uff09\u6a21\u578b\u91cd\u65b0\u52a0\u6743JHFRAT\u8bc4\u5206\u6743\u91cd\uff0c\u4fdd\u7559\u5176\u52a0\u6cd5\u7ed3\u6784\u548c\u4e34\u5e8a\u9608\u503c\uff1b\u57fa\u4e8e54,209\u4f8b\u4f4f\u9662\u60a3\u8005\u6570\u636e\u8fdb\u884c\u56de\u987e\u6027\u961f\u5217\u5206\u6790\uff0c\u5305\u62ec20,208\u4f8b\u9ad8\u98ce\u9669\u548c13,941\u4f8b\u4f4e\u98ce\u9669\u60a3\u8005", "result": "CSO\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u5f53\u524dJHFRAT\uff08AUC-ROC=0.91 vs 0.86\uff09\uff0c\u6027\u80fd\u63d0\u5347\u76f8\u5f53\u4e8e\u6bcf\u5468\u591a\u4fdd\u62a435\u540d\u9ad8\u98ce\u9669\u60a3\u8005\uff1bCSO\u6a21\u578b\u5728\u6709\u65e0EHR\u53d8\u91cf\u65f6\u8868\u73b0\u76f8\u4f3c\uff0c\u867d\u7136XGBoost\u6a21\u578b\u6027\u80fd\u66f4\u597d\uff08AUC-ROC=0.94\uff09\uff0c\u4f46CSO\u5bf9\u98ce\u9669\u6807\u7b7e\u53d8\u5316\u66f4\u5177\u9c81\u68d2\u6027", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\u4e3a\u533b\u7597\u7cfb\u7edf\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u53ef\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u4f18\u5316\u6280\u672f\u7cfb\u7edf\u6027\u5730\u589e\u5f3a\u4f4f\u9662\u60a3\u8005\u8dcc\u5012\u9884\u9632\u65b9\u6848\u548c\u60a3\u8005\u5b89\u5168\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u98ce\u9669\u8bc4\u4f30\u548c\u533b\u7597\u8d44\u6e90\u914d\u7f6e"}}
{"id": "2601.04885", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04885", "abs": "https://arxiv.org/abs/2601.04885", "authors": ["Ao Sun", "Xiaoyu Wang", "Zhe Tan", "Yu Li", "Jiachen Zhu", "Shu Su", "Yuheng Jia"], "title": "CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters", "comment": null, "summary": "As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.", "AI": {"tldr": "CuMA\u6846\u67b6\u901a\u8fc7\u6587\u5316\u6df7\u5408\u9002\u914d\u5668\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u5bf9\u9f50\u4e2d\u7684\u5747\u503c\u5d29\u6e83\u95ee\u9898\uff0c\u4f7f\u7528\u4eba\u53e3\u611f\u77e5\u8def\u7531\u5206\u79bb\u51b2\u7a81\u68af\u5ea6\uff0c\u5728\u6587\u5316\u591a\u6837\u6027\u57fa\u51c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u5168\u7403\u7528\u6237\u65f6\uff0c\u5bf9\u9f50\u9700\u8981\u4ece\u5f3a\u5236\u666e\u904d\u5171\u8bc6\u8f6c\u5411\u5c0a\u91cd\u6587\u5316\u591a\u5143\u6027\u3002\u73b0\u6709\u5bc6\u96c6\u6a21\u578b\u5728\u62df\u5408\u51b2\u7a81\u4ef7\u503c\u5206\u5e03\u65f6\u4f1a\u51fa\u73b0\"\u5747\u503c\u5d29\u6e83\"\uff0c\u6536\u655b\u5230\u65e0\u6cd5\u4ee3\u8868\u4e0d\u540c\u6587\u5316\u7fa4\u4f53\u7684\u901a\u7528\u5e73\u5747\u503c\u3002", "method": "\u63d0\u51faCuMA\uff08\u6587\u5316\u6df7\u5408\u9002\u914d\u5668\uff09\u6846\u67b6\uff0c\u5c06\u5bf9\u9f50\u89c6\u4e3a\u6761\u4ef6\u5bb9\u91cf\u5206\u79bb\u95ee\u9898\u3002\u901a\u8fc7\u4eba\u53e3\u611f\u77e5\u8def\u7531\uff0c\u5185\u90e8\u5316\u6f5c\u5728\u6587\u5316\u62d3\u6251\u7ed3\u6784\uff0c\u5c06\u51b2\u7a81\u68af\u5ea6\u663e\u5f0f\u89e3\u8026\u5230\u4e13\u95e8\u7684\u4e13\u5bb6\u5b50\u7a7a\u95f4\u4e2d\u3002", "result": "\u5728WorldValuesBench\u3001Community Alignment\u548cPRISM\u7b49\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cCuMA\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u5bc6\u96c6\u57fa\u7ebf\u548c\u4ec5\u57fa\u4e8e\u8bed\u4e49\u7684MoE\u65b9\u6cd5\u3002\u5206\u6790\u786e\u8ba4CuMA\u6709\u6548\u7f13\u89e3\u4e86\u5747\u503c\u5d29\u6e83\uff0c\u4fdd\u6301\u4e86\u6587\u5316\u591a\u6837\u6027\u3002", "conclusion": "CuMA\u901a\u8fc7\u6587\u5316\u6df7\u5408\u9002\u914d\u5668\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u5bf9\u9f50\u4e2d\u7684\u5747\u503c\u5d29\u6e83\u95ee\u9898\uff0c\u4e3a\u670d\u52a1\u5168\u7403\u7528\u6237\u7684\u591a\u6587\u5316\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05205", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.05205", "abs": "https://arxiv.org/abs/2601.05205", "authors": ["Zain Iqbal", "Lorenzo Valerio"], "title": "EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI", "comment": "6 pages, 9 figures, 2 Tables, conference [Submitted in PerConAI-2026]", "summary": "Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.", "AI": {"tldr": "EARL\u662f\u4e00\u4e2a\u80fd\u91cf\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u4e0e\u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8054\u5408\u4f18\u5316\u6db2\u4f53\u72b6\u6001\u673a\u7684\u51c6\u786e\u6027\u548c\u80fd\u8017\uff0c\u663e\u8457\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0aAI\u5e94\u7528\u7684\u6548\u7387\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u666e\u53caAI\u7cfb\u7edf\u4e2d\uff0c\u6db2\u4f53\u72b6\u6001\u673a\u867d\u7136\u5177\u6709\u4f4e\u529f\u8017\u65f6\u5e8f\u5904\u7406\u7684\u6f5c\u529b\uff0c\u4f46\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5ffd\u7565\u4e86\u80fd\u8017\u7ea6\u675f\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u90e8\u7f72\u56f0\u96be\u3002", "method": "EARL\u6846\u67b6\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u5168\u5c40\u63a2\u7d22\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u52a8\u6001\u5019\u9009\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u5e76\u91c7\u7528\u65e9\u671f\u7ec8\u6b62\u673a\u5236\u6d88\u9664\u5197\u4f59\u8bc4\u4f30\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cEARL\u76f8\u6bd4\u9886\u5148\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u6846\u67b6\u5b9e\u73b0\u4e866-15%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c60-80%\u7684\u80fd\u8017\u964d\u4f4e\uff0c\u4ee5\u53ca\u9ad8\u8fbe\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u4f18\u5316\u65f6\u95f4\u51cf\u5c11\u3002", "conclusion": "\u80fd\u91cf\u611f\u77e5\u7684\u81ea\u9002\u5e94\u641c\u7d22\u80fd\u6709\u6548\u63d0\u9ad8\u6db2\u4f53\u72b6\u6001\u673a\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907AI\u5e94\u7528\u4e2d\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.04920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04920", "abs": "https://arxiv.org/abs/2601.04920", "authors": ["Nils Einecke"], "title": "Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition", "comment": null, "summary": "Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7ESA\u7684ELOPE\u7ade\u8d5b\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86ChatGPT\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u4f5c\u4e3a\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u5b9e\u73b0\u4e86\u7b2c\u4e8c\u540d\u6210\u7ee9\uff0c\u540c\u65f6\u5206\u6790\u4e86AI\u5728\u4ee3\u7801\u751f\u6210\u3001\u7b97\u6cd5\u63a8\u7406\u65b9\u9762\u7684\u4f18\u52bf\u53ca\u5176\u5c40\u9650\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u7f16\u7a0b\u4f19\u4f34\uff0c\u4f46\u5b83\u4eec\u5728\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u7684\u4f5c\u7528\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5b9e\u9645\u7ade\u8d5b\u6848\u4f8b\u7814\u7a76\u4eba\u7c7b-AI\u534f\u4f5c\u5728\u7ade\u4e89\u6027\u79d1\u5b66\u73af\u5883\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528ChatGPT\u8fdb\u884c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\uff0c\u53c2\u4e0eESA\u7684ELOPE\u7ade\u8d5b\uff08\u57fa\u4e8e\u4e8b\u4ef6\u7684\u6708\u7403\u5149\u6d41\u81ea\u6211\u8fd0\u52a8\u4f30\u8ba1\u7ade\u8d5b\uff09\u3002ChatGPT\u4e0d\u4ec5\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u8fd8\u63d0\u4f9b\u7b97\u6cd5\u63a8\u7406\u3001\u6570\u636e\u5904\u7406\u4f8b\u7a0b\u548c\u65b9\u6cd5\u8bba\u5efa\u8bae\uff0c\u5982\u4f7f\u7528\u56fa\u5b9a\u4e8b\u4ef6\u6570\u800c\u975e\u56fa\u5b9a\u65f6\u95f4\u8de8\u5ea6\u8fdb\u884c\u7a97\u53e3\u5904\u7406\u3002", "result": "\u5c3d\u7ba1\u8f83\u665a\u52a0\u5165\u7ade\u8d5b\uff0c\u4f46\u83b7\u5f97\u4e86\u7b2c\u4e8c\u540d\uff0c\u5f97\u5206\u4e3a0.01282\u3002\u8fd9\u8bc1\u660e\u4e86\u4eba\u7c7b-AI\u534f\u4f5c\u5728\u7ade\u4e89\u6027\u79d1\u5b66\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002\u540c\u65f6\u89c2\u5bdf\u5230ChatGPT\u7684\u5c40\u9650\u6027\uff1a\u5e38\u5f15\u5165\u4e0d\u5fc5\u8981\u7684\u7ed3\u6784\u66f4\u6539\u3001\u5728\u4e2d\u95f4\u8ba8\u8bba\u4e2d\u6df7\u6dc6\u3001\u5076\u5c14\u4ea7\u751f\u5173\u952e\u9519\u8bef\uff0c\u4ee5\u53ca\u5728\u8f83\u957f\u7684\u79d1\u5b66\u8ba8\u8bba\u4e2d\u9057\u5fd8\u91cd\u8981\u65b9\u9762\u3002", "conclusion": "\u5bf9\u8bdd\u5f0fAI\u65e2\u80fd\u52a0\u901f\u5f00\u53d1\uff0c\u53c8\u80fd\u652f\u6301\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u6982\u5ff5\u6d1e\u5bdf\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u4f18\u52bf\u548c\u4e0d\u8db3\uff0c\u672c\u6587\u4e3b\u5f20\u5c06LLMs\u7ed3\u6784\u5316\u5730\u6574\u5408\u5230\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u5e76\u63d0\u51faAI\u8f85\u52a9\u79d1\u5b66\u5de5\u4f5c\u7684\u6700\u4f73\u5b9e\u8df5\u5efa\u8bae\u3002"}}
{"id": "2601.05050", "categories": ["cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.05050", "abs": "https://arxiv.org/abs/2601.05050", "authors": ["Thomas H. Costello", "Kellin Pelrine", "Matthew Kowal", "Antonio A. Arechar", "Jean-Fran\u00e7ois Godbout", "Adam Gleave", "David Rand", "Gordon Pennycook"], "title": "Large language models can effectively convince people to believe conspiracies", "comment": null, "summary": "Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against (\"debunking\") or for (\"bunking\") that conspiracy. When using a \"jailbroken\" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.", "AI": {"tldr": "GPT-4o\u80fd\u6709\u6548\u589e\u52a0\u6216\u51cf\u5c11\u9634\u8c0b\u8bba\u4fe1\u5ff5\uff0c\u79fb\u9664\u5b89\u5168\u62a4\u680f\u540eAI\u5728\u63a8\u5e7f\u9634\u8c0b\u8bba\u65b9\u9762\u4e0e\u53cd\u9a73\u9634\u8c0b\u8bba\u540c\u6837\u6709\u6548\uff0c\u4f46\u4f7f\u7528\u51c6\u786e\u4fe1\u606f\u63d0\u793a\u53ef\u663e\u8457\u964d\u4f4e\u98ce\u9669", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8bf4\u670d\u529b\u662f\u5426\u66f4\u503e\u5411\u4e8e\u771f\u76f8\u800c\u975e\u865a\u5047\u4fe1\u606f\uff0c\u8fd8\u662fLLMs\u80fd\u540c\u6837\u5bb9\u6613\u5730\u63a8\u5e7f\u9519\u8bef\u4fe1\u5ff5", "method": "\u901a\u8fc7\u4e09\u4e2a\u9884\u6ce8\u518c\u5b9e\u9a8c\uff0c\u8ba92,724\u540d\u7f8e\u56fd\u53c2\u4e0e\u8005\u4e0eGPT-4o\u8ba8\u8bba\u4ed6\u4eec\u4e0d\u786e\u5b9a\u7684\u9634\u8c0b\u8bba\uff0c\u6a21\u578b\u88ab\u6307\u793a\u8981\u4e48\u53cd\u9a73\uff08\"debunking\"\uff09\u8981\u4e48\u652f\u6301\uff08\"bunking\"\uff09\u8be5\u9634\u8c0b\u8bba\uff0c\u6d4b\u8bd5\u6807\u51c6GPT-4o\u548c\u79fb\u9664\u5b89\u5168\u62a4\u680f\u7684\"\u8d8a\u72f1\"\u7248\u672c", "result": "\u79fb\u9664\u5b89\u5168\u62a4\u680f\u7684GPT-4o\u5728\u589e\u52a0\u9634\u8c0b\u8bba\u4fe1\u5ff5\u65b9\u9762\u4e0e\u51cf\u5c11\u4fe1\u5ff5\u540c\u6837\u6709\u6548\uff1b\u652f\u6301\u9634\u8c0b\u8bba\u7684AI\u83b7\u5f97\u66f4\u79ef\u6781\u8bc4\u4ef7\u5e76\u589e\u52a0\u5bf9AI\u7684\u4fe1\u4efb\uff1b\u6807\u51c6GPT-4o\u4ea7\u751f\u7c7b\u4f3c\u6548\u679c\uff0cOpenAI\u7684\u5b89\u5168\u62a4\u680f\u51e0\u4e4e\u65e0\u6cd5\u963b\u6b62LLM\u63a8\u5e7f\u9634\u8c0b\u8bba\uff1b\u7ea0\u6b63\u6027\u5bf9\u8bdd\u80fd\u9006\u8f6c\u65b0\u8bf1\u5bfc\u7684\u4fe1\u5ff5\uff1b\u63d0\u793aGPT-4o\u4ec5\u4f7f\u7528\u51c6\u786e\u4fe1\u606f\u80fd\u663e\u8457\u964d\u4f4e\u5176\u589e\u52a0\u9634\u8c0b\u8bba\u4fe1\u5ff5\u7684\u80fd\u529b", "conclusion": "LLMs\u5177\u6709\u4fc3\u8fdb\u771f\u76f8\u548c\u865a\u5047\u4fe1\u606f\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u6765\u5e2e\u52a9\u51cf\u8f7b\u8fd9\u79cd\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\u6765\u9632\u6b62LLMs\u63a8\u5e7f\u9519\u8bef\u4fe1\u606f"}}
{"id": "2601.05053", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05053", "abs": "https://arxiv.org/abs/2601.05053", "authors": ["Ziqi Zhao", "Zhaochun Ren", "Jiahong Zou", "Liu Yang", "Zhiwei Xu", "Xuri Ge", "Zhumin Chen", "Xinyu Ma", "Daiting Shi", "Shuaiqiang Wang", "Dawei Yin", "Xin Xin"], "title": "Reinforced Efficient Reasoning via Semantically Diverse Exploration", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.", "AI": {"tldr": "ROSE\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u591a\u6837\u6027\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u71b5\u5206\u652f\u7b56\u7565\u548c\u03b5\u63a2\u7d22\u673a\u5236\u589e\u5f3a\u63a8\u7406\u591a\u6837\u6027\uff0c\u7ed3\u5408\u957f\u5ea6\u611f\u77e5\u7684\u6bb5\u7ea7\u4f18\u52bf\u4f30\u8ba1\u5668\u63d0\u5347\u6548\u7387\uff0c\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eMCTS\u7684RLVR\u65b9\u6cd5\u5b58\u5728\u63a2\u7d22\u591a\u6837\u6027\u6709\u9650\u548c\u63a8\u7406\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faROSE\u6846\u67b6\uff1a1\uff09\u8bed\u4e49\u71b5\u5206\u652f\u7b56\u7565\u57fa\u4e8e\u5df2\u91c7\u6837\u63a8\u7406\u8def\u5f84\u7684\u8bed\u4e49\u4e0d\u786e\u5b9a\u6027\u9009\u62e9\u5206\u652f\u70b9\u751f\u6210\u65b0\u8def\u5f84\uff1b2\uff09\u03b5\u63a2\u7d22\u673a\u5236\u4ece\u6839\u8282\u70b9\u968f\u673a\u542f\u52a8\u63a8\u7406\u9632\u6b62\u641c\u7d22\u8fc7\u5ea6\u5c40\u90e8\u5316\uff1b3\uff09\u957f\u5ea6\u611f\u77e5\u6bb5\u7ea7\u4f18\u52bf\u4f30\u8ba1\u5668\u5956\u52b1\u7b80\u6d01\u6b63\u786e\u63a8\u7406\uff0c\u60e9\u7f5a\u8fc7\u957f\u63a8\u7406\u94fe\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u4f7f\u7528Qwen\u548cLlama\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86ROSE\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "ROSE\u901a\u8fc7\u8bed\u4e49\u591a\u6837\u6027\u63a2\u7d22\u548c\u9ad8\u6548\u63a8\u7406\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709RLVR\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.05215", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05215", "abs": "https://arxiv.org/abs/2601.05215", "authors": ["Tamil Sudaravan Mohan Doss", "Michael Xu", "Sudha Rao", "Andrew D. Wilson", "Balasaravanan Thoravi Kumaravel"], "title": "MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents", "comment": null, "summary": "We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.\n  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMineNPC-Task\u7684\u7528\u6237\u521b\u4f5c\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5f00\u653e\u4e16\u754cMinecraft\u4e2d\u6d4b\u8bd5\u5177\u6709\u8bb0\u5fc6\u611f\u77e5\u548c\u6df7\u5408\u4e3b\u52a8\u6027\u7684LLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u771f\u5b9e\u73a9\u5bb6\u4efb\u52a1\u800c\u975e\u5408\u6210\u63d0\u793a\u6765\u8bc4\u4f30\u667a\u80fd\u4f53\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u8bc4\u4f30\u5177\u6709\u8bb0\u5fc6\u611f\u77e5\u548c\u6df7\u5408\u4e3b\u52a8\u6027LLM\u667a\u80fd\u4f53\u7684\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u9700\u8981\u57fa\u4e8e\u771f\u5b9e\u73a9\u5bb6\u4f53\u9a8c\u800c\u975e\u5408\u6210\u63d0\u793a\u7684\u4efb\u52a1\u6765\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u5b9e\u9645\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4e0e\u4e13\u5bb6\u73a9\u5bb6\u8fdb\u884c\u5f62\u6210\u6027\u548c\u603b\u7ed3\u6027\u534f\u540c\u6e38\u620f\u6765\u6536\u96c6\u4efb\u52a1\uff0c\u5c06\u4efb\u52a1\u89c4\u8303\u5316\u4e3a\u5177\u6709\u660e\u786e\u524d\u63d0\u6761\u4ef6\u548c\u4f9d\u8d56\u7ed3\u6784\u7684\u53c2\u6570\u5316\u6a21\u677f\uff0c\u5e76\u914d\u6709\u673a\u53ef\u68c0\u67e5\u7684\u9a8c\u8bc1\u5668\uff0c\u91c7\u7528\u7981\u6b62\u5916\u90e8\u77e5\u8bc6\u6377\u5f84\u7684\u6709\u754c\u77e5\u8bc6\u7b56\u7565\u3002", "result": "\u4f7f\u7528GPT-4o\u8bc4\u4f30\u4e868\u4f4d\u7ecf\u9a8c\u73a9\u5bb6\u7684216\u4e2a\u5b50\u4efb\u52a1\uff0c\u89c2\u5bdf\u5230\u4ee3\u7801\u6267\u884c\u3001\u5e93\u5b58/\u5de5\u5177\u5904\u7406\u3001\u5f15\u7528\u548c\u5bfc\u822a\u65b9\u9762\u7684\u91cd\u590d\u6545\u969c\u6a21\u5f0f\uff0c\u540c\u65f6\u53d1\u73b0\u6df7\u5408\u4e3b\u52a8\u6027\u6f84\u6e05\u548c\u8f7b\u91cf\u7ea7\u8bb0\u5fc6\u652f\u6301\u4e0b\u7684\u6062\u590d\u80fd\u529b\u3002\u53c2\u4e0e\u8005\u5bf9\u4ea4\u4e92\u8d28\u91cf\u548c\u754c\u9762\u53ef\u7528\u6027\u8bc4\u4ef7\u79ef\u6781\uff0c\u4f46\u5f3a\u8c03\u9700\u8981\u66f4\u5f3a\u7684\u8de8\u4efb\u52a1\u8bb0\u5fc6\u6301\u4e45\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u73a9\u5bb6\u4f53\u9a8c\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u8bc6\u522bLLM\u667a\u80fd\u4f53\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u6545\u969c\u6a21\u5f0f\u548c\u6062\u590d\u673a\u5236\uff0c\u4e3a\u672a\u6765\u8bb0\u5fc6\u611f\u77e5\u5177\u8eab\u667a\u80fd\u4f53\u7684\u900f\u660e\u3001\u53ef\u91cd\u590d\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b8c\u6574\u4efb\u52a1\u5957\u4ef6\u3001\u9a8c\u8bc1\u5668\u548c\u5de5\u5177\u3002"}}
