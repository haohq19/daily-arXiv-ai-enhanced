<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 13]
- [cs.LG](#cs.LG) [Total: 15]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CL](#cs.CL) [Total: 6]
- [cs.RO](#cs.RO) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A 96pJ/Frame/Pixel and 61pJ/Event Anti-UAV System with Hybrid Object Tracking Modes](https://arxiv.org/abs/2512.17939)
*Yuncheng Lu,Yucen Shi,Aobo Li,Zehao Li,Junying Li,Bo Wang,Tony Tae-Hyoung Kim*

Main category: cs.CV

TL;DR: 提出一种能效优化的反无人机系统，结合帧基与事件驱动目标跟踪，实现对小而快速移动的无人机可靠检测，芯片在40nm工艺下达到96pJ/帧/像素和61pJ/事件的能效。


<details>
  <summary>Details</summary>
Motivation: 现有反无人机系统在检测小而快速移动的无人机时面临能效挑战，需要同时处理高动态范围场景和低功耗要求，特别是对于电池供电的移动设备。

Method: 系统集成帧基与事件驱动目标跟踪，使用游程编码重建二值事件帧，生成区域建议，根据目标大小和速度自适应切换帧模式与事件模式。快速目标跟踪单元通过自适应阈值和轨迹分类提高鲁棒性，神经处理单元支持灰度块和轨迹推理，采用自定义指令集和零跳过MAC架构。

Result: 在40nm CMOS工艺下实现2mm²芯片，达到96pJ/帧/像素和61pJ/事件的能效，在公共无人机数据集上实现98.2%识别准确率，覆盖50-400米范围和5-80像素/秒速度，减少97%以上冗余神经计算。

Conclusion: 该系统展示了反无人机系统最先进的端到端能效，通过混合帧基与事件驱动方法有效平衡了检测精度与功耗，为移动反无人机应用提供了实用解决方案。

Abstract: We present an energy-efficient anti-UAV system that integrates frame-based and event-driven object tracking to enable reliable detection of small and fast-moving drones. The system reconstructs binary event frames using run-length encoding, generates region proposals, and adaptively switches between frame mode and event mode based on object size and velocity. A Fast Object Tracking Unit improves robustness for high-speed targets through adaptive thresholding and trajectory-based classification. The neural processing unit supports both grayscale-patch and trajectory inference with a custom instruction set and a zero-skipping MAC architecture, reducing redundant neural computations by more than 97 percent. Implemented in 40 nm CMOS technology, the 2 mm^2 chip achieves 96 pJ per frame per pixel and 61 pJ per event at 0.8 V, and reaches 98.2 percent recognition accuracy on public UAV datasets across 50 to 400 m ranges and 5 to 80 pixels per second speeds. The results demonstrate state-of-the-art end-to-end energy efficiency for anti-UAV systems.

</details>


### [2] [UniMPR: A Unified Framework for Multimodal Place Recognition with Arbitrary Sensor Configurations](https://arxiv.org/abs/2512.18279)
*Zhangshuo Qi,Jingyi Xu,Luqi Cheng,Shichen Wen,Yiming Ma,Guangming Xiong*

Main category: cs.CV

TL;DR: UniMPR是一个统一的多模态地点识别框架，使用单一训练模型即可适应任意传感器组合（相机、LiDAR、雷达），在极坐标BEV特征空间中处理异构数据，通过多分支网络提取特征，并在多个数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态地点识别方法面临三个主要挑战：1）无法在统一框架中动态适应任意模态输入；2）对缺失或退化模态的鲁棒性不足；3）难以泛化到不同的传感器配置和设置。需要一种更灵活、鲁棒且通用的解决方案。

Method: 提出UniMPR统一框架：1）将所有输入统一到极坐标BEV特征空间处理数据异构性；2）使用多分支网络从任意模态组合中提取判别性的模态内和模态间特征；3）构建大规模训练集并引入自适应标签分配策略进行广泛预训练。

Result: 在7个数据集上的实验表明，UniMPR在不同传感器配置、模态组合和环境条件下均实现了最先进的性能，证明了其强大的泛化能力和鲁棒性。

Conclusion: UniMPR成功解决了多模态地点识别中的关键挑战，提供了一个统一、灵活且鲁棒的框架，能够适应任意传感器组合，为自动驾驶和机器人在GPS拒止环境中的全局定位提供了有效解决方案。

Abstract: Place recognition is a critical component of autonomous vehicles and robotics, enabling global localization in GPS-denied environments. Recent advances have spurred significant interest in multimodal place recognition (MPR), which leverages complementary strengths of multiple modalities. Despite its potential, most existing MPR methods still face three key challenges: (1) dynamically adapting to arbitrary modality inputs within a unified framework, (2) maintaining robustness with missing or degraded modalities, and (3) generalizing across diverse sensor configurations and setups. In this paper, we propose UniMPR, a unified framework for multimodal place recognition. Using only one trained model, it can seamlessly adapt to any combination of common perceptual modalities (e.g., camera, LiDAR, radar). To tackle the data heterogeneity, we unify all inputs within a polar BEV feature space. Subsequently, the polar BEVs are fed into a multi-branch network to exploit discriminative intra-model and inter-modal features from any modality combinations. To fully exploit the network's generalization capability and robustness, we construct a large-scale training set from multiple datasets and introduce an adaptive label assignment strategy for extensive pre-training. Experiments on seven datasets demonstrate that UniMPR achieves state-of-the-art performance under varying sensor configurations, modality combinations, and environmental conditions. Our code will be released at https://github.com/QiZS-BIT/UniMPR.

</details>


### [3] [E-RGB-D: Real-Time Event-Based Perception with Structured Light](https://arxiv.org/abs/2512.18429)
*Seyed Ehsan Marjani Bajestani,Giovanni Beltrame*

Main category: cs.CV

TL;DR: 提出结合事件相机和DLP投影仪的新型RGB-D感知系统，实现1400fps色彩检测和4kHz像素深度检测


<details>
  <summary>Details</summary>
Motivation: 传统单色事件相机无法检测静态/慢速物体且缺乏色彩信息，限制了其在需要颜色感知的应用中的使用

Method: 集成数字光处理投影仪形成主动结构光系统，结合事件相机优势，通过动态投影调整优化带宽，实现像素级色彩和深度分离检测

Result: 实现1400fps色彩检测速度和4kHz像素深度检测，生成彩色点云而不牺牲空间分辨率

Conclusion: 该方法显著推进了计算机视觉领域，从机器人到3D重建等多个应用领域都能受益于这种无帧RGB-D感知能力

Abstract: Event-based cameras (ECs) have emerged as bio-inspired sensors that report pixel brightness changes asynchronously, offering unmatched speed and efficiency in vision sensing. Despite their high dynamic range, temporal resolution, low power consumption, and computational simplicity, traditional monochrome ECs face limitations in detecting static or slowly moving objects and lack color information essential for certain applications. To address these challenges, we present a novel approach that integrates a Digital Light Processing (DLP) projector, forming Active Structured Light (ASL) for RGB-D sensing. By combining the benefits of ECs and projection-based techniques, our method enables the detection of color and the depth of each pixel separately. Dynamic projection adjustments optimize bandwidth, ensuring selective color data acquisition and yielding colorful point clouds without sacrificing spatial resolution. This integration, facilitated by a commercial TI LightCrafter 4500 projector and a monocular monochrome EC, not only enables frameless RGB-D sensing applications but also achieves remarkable performance milestones. With our approach, we achieved a color detection speed equivalent to 1400 fps and 4 kHz of pixel depth detection, significantly advancing the realm of computer vision across diverse fields from robotics to 3D reconstruction methods. Our code is publicly available: https://github.com/MISTLab/event_based_rgbd_ros

</details>


### [4] [Geometric-Photometric Event-based 3D Gaussian Ray Tracing](https://arxiv.org/abs/2512.18640)
*Kai Kohyama,Yoshimitsu Aoki,Guillermo Gallego,Shintaro Shiba*

Main category: cs.CV

TL;DR: 提出一种事件相机3D高斯泼溅框架，通过解耦几何和辐射渲染，在精度和时间分辨率间取得平衡，无需先验信息或COLMAP初始化。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率，适合运动和结构估计，但现有事件3D高斯泼溅方法难以利用稀疏事件的细粒度时间信息，需要在精度和时间分辨率间权衡。

Method: 将渲染解耦为两个分支：事件级几何（深度）渲染和快照级辐射（强度）渲染，使用光线追踪和扭曲事件图像技术。

Result: 在真实数据集上达到SOTA性能，在合成数据集上具有竞争力；无需先验信息或COLMAP初始化，事件选择更灵活，边缘重建清晰，训练速度快。

Conclusion: 该方法深化了对稀疏事件用于3D重建的理解，为事件相机3D高斯泼溅提供了有效框架。

Abstract: Event cameras offer a high temporal resolution over traditional frame-based cameras, which makes them suitable for motion and structure estimation. However, it has been unclear how event-based 3D Gaussian Splatting (3DGS) approaches could leverage fine-grained temporal information of sparse events. This work proposes a framework to address the trade-off between accuracy and temporal resolution in event-based 3DGS. Our key idea is to decouple the rendering into two branches: event-by-event geometry (depth) rendering and snapshot-based radiance (intensity) rendering, by using ray-tracing and the image of warped events. The extensive evaluation shows that our method achieves state-of-the-art performance on the real-world datasets and competitive performance on the synthetic dataset. Also, the proposed method works without prior information (e.g., pretrained image reconstruction models) or COLMAP-based initialization, is more flexible in the event selection number, and achieves sharp reconstruction on scene edges with fast training time. We hope that this work deepens our understanding of the sparse nature of events for 3D reconstruction. The code will be released.

</details>


### [5] [VLNVerse: A Benchmark for Vision-Language Navigation with Versatile, Embodied, Realistic Simulation and Evaluation](https://arxiv.org/abs/2512.19021)
*Sihao Lin,Zerui Li,Xunyi Zhao,Gengze Zhou,Liuyi Wang,Rong Wei,Rui Tang,Juncheng Li,Hanqing Wang,Jiangmiao Pang,Anton van den Hengel,Jiajun Liu,Qi Wu*

Main category: cs.CV

TL;DR: VLNVerse是一个新的大规模、可扩展的视觉语言导航基准，旨在解决现有基准数据集规模小、物理模拟简单、任务碎片化等问题，推动可扩展的通用具身智能体研究。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航基准存在以下问题：1) 数据集规模小且固定，无法满足现代大语言模型预训练需求；2) 物理模拟简单，限制了从模拟到真实世界的泛化研究；3) 任务碎片化，阻碍了统一进展；4) 现有智能体多为"幽灵"式（无形、瞬移），缺乏完整运动学支持。

Method: 提出VLNVerse基准，具有以下特点：1) 多功能性：将碎片化任务统一到单一框架中，提供可扩展工具包；2) 具身性：超越无形瞬移的"幽灵"智能体，支持完整运动学；3) 真实模拟：基于强大的物理引擎实现逼真模拟；4) 大规模：利用规模和多样性进行全面评估；5) 提出新颖的统一多任务模型，能够处理基准中的所有任务。

Result: VLNVerse重新定义了视觉语言导航作为一个可扩展的全栈具身AI问题，缩小了模拟导航与真实世界泛化之间的差距，为研究界提供了一个重要工具，推动可扩展、通用具身运动智能体的研究。

Conclusion: VLNVerse基准通过其多功能性、具身性、真实模拟和大规模特性，解决了现有视觉语言导航研究的局限性，为开发可扩展的通用具身智能体提供了关键基础设施，有望显著推动该领域的发展。

Abstract: Despite remarkable progress in Vision-Language Navigation (VLN), existing benchmarks remain confined to fixed, small-scale datasets with naive physical simulation. These shortcomings limit the insight that the benchmarks provide into sim-to-real generalization, and create a significant research gap. Furthermore, task fragmentation prevents unified/shared progress in the area, while limited data scales fail to meet the demands of modern LLM-based pretraining. To overcome these limitations, we introduce VLNVerse: a new large-scale, extensible benchmark designed for Versatile, Embodied, Realistic Simulation, and Evaluation. VLNVerse redefines VLN as a scalable, full-stack embodied AI problem. Its Versatile nature unifies previously fragmented tasks into a single framework and provides an extensible toolkit for researchers. Its Embodied design moves beyond intangible and teleporting "ghost" agents that support full-kinematics in a Realistic Simulation powered by a robust physics engine. We leverage the scale and diversity of VLNVerse to conduct a comprehensive Evaluation of existing methods, from classic models to MLLM-based agents. We also propose a novel unified multi-task model capable of addressing all tasks within the benchmark. VLNVerse aims to narrow the gap between simulated navigation and real-world generalization, providing the community with a vital tool to boost research towards scalable, general-purpose embodied locomotion agents.

</details>


### [6] [Commercial Vehicle Braking Optimization: A Robust SIFT-Trajectory Approach](https://arxiv.org/abs/2512.18597)
*Zhe Li,Kun Cheng,Hanyue Mo,Jintao Lu,Ziwen Kuang,Jianwen Ye,Lixu Xu,Xinya Meng,Jiahui Zhao,Shengda Ji,Shuyuan Liu,Mengyu Wang*

Main category: cs.CV

TL;DR: 提出基于视觉的轨迹分析方案，解决商用车AEB系统在低速运行时因CAN信号不准确导致的"零速制动"问题，通过视频处理精确识别车辆运动状态。


<details>
  <summary>Details</summary>
Motivation: 商用车自动紧急制动系统在低速运行时，由于CAN信号不准确会导致"零速制动"误触发问题，影响系统可靠性和安全性。

Method: 使用NVIDIA Jetson AGX Xavier平台处理盲区摄像头视频序列，采用自适应CLAHE增强的SIFT特征提取和KNN-RANSAC匹配，结合5帧滑动窗口轨迹位移统计、双阈值状态决策矩阵和OBD-II驱动的动态ROI配置。

Result: 在真实数据集（32,454个视频片段，1,852辆车）上测试：静态检测F1-score 99.96%，运动状态识别97.78%，处理延迟14.2ms。现场部署显示误制动事件减少89%，紧急制动成功率100%，故障率低于5%。

Conclusion: 该视觉轨迹分析方案有效解决了商用车AEB系统的低速误触发问题，显著提升了系统可靠性和安全性，具有实际应用价值。

Abstract: A vision-based trajectory analysis solution is proposed to address the "zero-speed braking" issue caused by inaccurate Controller Area Network (CAN) signals in commercial vehicle Automatic Emergency Braking (AEB) systems during low-speed operation. The algorithm utilizes the NVIDIA Jetson AGX Xavier platform to process sequential video frames from a blind spot camera, employing self-adaptive Contrast Limited Adaptive Histogram Equalization (CLAHE)-enhanced Scale-Invariant Feature Transform (SIFT) feature extraction and K-Nearest Neighbors (KNN)-Random Sample Consensus (RANSAC) matching. This allows for precise classification of the vehicle's motion state (static, vibration, moving). Key innovations include 1) multiframe trajectory displacement statistics (5-frame sliding window), 2) a dual-threshold state decision matrix, and 3) OBD-II driven dynamic Region of Interest (ROI) configuration. The system effectively suppresses environmental interference and false detection of dynamic objects, directly addressing the challenge of low-speed false activation in commercial vehicle safety systems. Evaluation in a real-world dataset (32,454 video segments from 1,852 vehicles) demonstrates an F1-score of 99.96% for static detection, 97.78% for moving state recognition, and a processing delay of 14.2 milliseconds (resolution 704x576). The deployment on-site shows an 89% reduction in false braking events, a 100% success rate in emergency braking, and a fault rate below 5%.

</details>


### [7] [CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis](https://arxiv.org/abs/2512.18878)
*Kaidi Liang,Ke Li,Xianbiao Hu,Ruwen Qin*

Main category: cs.CV

TL;DR: 提出CrashChat多模态大语言模型，用于交通事故视频的多任务分析，在识别、定位和描述任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶和交通安全研究中，交通事故视频分析日益重要，但现有模型无法在统一框架内完成复杂的多任务分析，且缺乏有效的训练策略

Method: 基于VideoLLaMA3构建多模态大语言模型，通过指令微调获取领域知识，采用任务解耦与分组的多任务学习策略，最大化联合学习效益并减少负迁移

Result: 在公开数据集上超越现有MLLM和传统视觉方法：碰撞识别接近完美准确率，碰撞定位提升176%，碰撞前定位提升40%；在描述和推理任务上，BLEU和ROUGE分数显著提升

Conclusion: CrashChat是一个性能强大、端到端的多任务交通事故视频分析工具，可直接用于实际应用，代码和数据集已开源

Abstract: Automating crash video analysis is essential to leverage the growing availability of driving video data for traffic safety research and accountability attribution in autonomous driving. Crash video analysis is a challenging multitask problem due to the complex spatiotemporal dynamics of crash events in video data and the diverse analytical requirements involved. It requires capabilities spanning crash recognition, temporal grounding, and high-level video understanding. Existing models, however, cannot perform all these tasks within a unified framework, and effective training strategies for such models remain underexplored. To fill these gaps, this paper proposes CrashChat, a multimodal large language model (MLLM) for multitask traffic crash analysis, built upon VideoLLaMA3. CrashChat acquires domain-specific knowledge through instruction fine-tuning and employs a novel multitask learning strategy based on task decoupling and grouping, which maximizes the benefit of joint learning within and across task groups while mitigating negative transfer. Numerical experiments on consolidated public datasets demonstrate that CrashChat consistently outperforms existing MLLMs across model scales and traditional vision-based methods, achieving state-of-the-art performance. It reaches near-perfect accuracy in crash recognition, a 176\% improvement in crash localization, and a 40\% improvement in the more challenging pre-crash localization. Compared to general MLLMs, it substantially enhances textual accuracy and content coverage in crash description and reasoning tasks, with 0.18-0.41 increases in BLEU scores and 0.18-0.42 increases in ROUGE scores. Beyond its strong performance, CrashChat is a convenient, end-to-end analytical tool ready for practical implementation. The dataset and implementation code for CrashChat are available at https://github.com/Liangkd/CrashChat.

</details>


### [8] [InvCoSS: Inversion-driven Continual Self-supervised Learning in Medical Multi-modal Image Pre-training](https://arxiv.org/abs/2512.19213)
*Zihao Luo,Shaohao Rui,Zhenyu Tang,Guotai Wang,Xiaosong Wang*

Main category: cs.CV

TL;DR: InvCoSS提出了一种基于模型反演的持续自监督学习框架，通过生成合成图像替代真实数据回放，解决医学多模态图像预训练中的灾难性遗忘问题，同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 现有持续自监督学习方法依赖回放先前阶段的数据来防止灾难性遗忘，但这会损害数据隐私，且在跨站点数据传递受限的实际场景中应用受限。需要一种既能保持性能又能严格保护隐私的解决方案。

Method: 1) 训练完前一任务后，通过模型反演生成近似原始训练分布的合成图像；2) 提出InvUNet多尺度融合架构，恢复反演图像的高低频成分；3) 设计排斥性表征学习机制，在没有类别指导的情况下促进合成图像特征空间的多样性；4) 将合成图像与新任务数据联合优化。

Result: 在九个下游任务上的实验验证了InvCoSS的有效性，其性能达到甚至超过先前的数据回放方法，同时显著减少存储需求并完全消除数据隐私限制。

Conclusion: InvCoSS提供了一种隐私保护的持续自监督学习框架，通过模型反演生成合成图像替代真实数据回放，在保持性能的同时解决了医学图像分析中的数据隐私和传输限制问题。

Abstract: Continual self-supervised learning (CSSL) in medical imaging trains a foundation model sequentially, alleviating the need for collecting multi-modal images for joint training and offering promising improvements in downstream performance while preserving data privacy. However, most existing methods still rely on replaying data from previous stages to prevent catastrophic forgetting, which compromises privacy and limits their applicability in real-world scenarios where data transfer across sites is often restricted. In this work, we propose InvCoSS, an inversion-driven continual self-supervised learning framework for medical multi-modal image pre-training. Specifically, after training on a previous task, InvCoSS inverts the pre-trained self-supervised model to generate synthetic images that approximate the original training distribution. These synthetic images are then combined with data from the new task for joint optimization, which effectively mitigates catastrophic forgetting while strictly adhering to the constraint of no access to previous real data. Furthermore, to improve the fidelity of synthetic images, we introduce a novel InvUNet with a multi-scale fusion architecture to restore both high- and low-frequency components of the inverted images. To enhance diversity and prevent mode collapse, we design a repulsive representation-learning mechanism that encourages a diverse feature space for synthetic images without class guidance. Extensive experiments across nine downstream tasks validate the effectiveness of InvCoSS, achieving performance comparable to or even superior to prior data-replay methods while significantly reducing storage requirements and eliminating data privacy constraints.

</details>


### [9] [Extended OpenTT Games Dataset: A table tennis dataset for fine-grained shot type and point outcome](https://arxiv.org/abs/2512.19327)
*Moamal Fadhil Abdul,Jonas Bruun Hubrechts,Thomas Martini Jørgensen,Emil Hovad*

Main category: cs.CV

TL;DR: 扩展OpenTTGames数据集，添加详细的击球类型、球员姿势和回合结果标注，支持乒乓球视频的细粒度分析


<details>
  <summary>Details</summary>
Motivation: 现有乒乓球视频数据集缺乏细粒度标注，限制了自动检测和分类击球类型、战术分析等应用的发展

Method: 在OpenTTGames数据集基础上，添加帧级击球类型标注（正手、反手及子类型）、球员姿势标签（身体倾斜和腿部姿势）和回合结果标签，提供紧凑编码方案和代码辅助标注流程

Result: 创建了包含丰富标注的扩展数据集，填补了社区中公开可用的细粒度乒乓球视频数据集的空白

Conclusion: 扩展后的OpenTTGames数据集支持从事件检测向战术理解的模型发展，采用CC BY-NC-SA 4.0许可促进非商业使用和研究基准测试

Abstract: Automatically detecting and classifying strokes in table tennis video can streamline training workflows, enrich broadcast overlays, and enable fine-grained performance analytics. For this to be possible, annotated video data of table tennis is needed. We extend the public OpenTTGames dataset with highly detailed, frame-accurate shot type annotations (forehand, backhand with subtypes), player posture labels (body lean and leg stance), and rally outcome tags at point end. OpenTTGames is a set of recordings from the side of the table with official labels for bounces, when the ball is above the net, or hitting the net. The dataset already contains ball coordinates near events, which are either "bounce", "net", or "empty_event" in the original OpenTTGames dataset, and semantic masks (humans, table, scoreboard). Our extension adds the types of stroke to the events and a per-player taxonomy so models can move beyond event spotting toward tactical understanding (e.g., whether a stroke is likely to win the point or set up an advantage). We provide a compact coding scheme and code-assisted labeling procedure to support reproducible annotations and baselines for fine-grained stroke understanding in racket sports. This fills a practical gap in the community, where many prior video resources are either not publicly released or carry restrictive/unclear licenses that hinder reuse and benchmarking. Our annotations are released under the same CC BY-NC-SA 4.0 license as OpenTTGames, allowing free non-commercial use, modification, and redistribution, with appropriate attribution.

</details>


### [10] [Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation](https://arxiv.org/abs/2512.19512)
*Ziyang Song,Zelin Zang,Zuyao Chen,Xusheng Liang,Dong Yi,Jinlin Wu,Hongbin Liu,Jiebo Luo*

Main category: cs.CV

TL;DR: 本文提出两种新方法改进MLLMs在医学解剖图像理解中的表现：解剖相似性课程学习和组多样性问题增强，显著提升在SGG-VQA和OmniMedVQA基准上的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在自然图像推理方面取得显著进展，但在医学影像特别是临床解剖手术图像中的应用潜力尚未充分挖掘。解剖理解任务需要精确理解和临床一致的答案，但由于医学数据的复杂性和高质量专家标注的稀缺性，传统监督微调策略效果有限。虽然GRPO方法能在无需大量数据的情况下增强MLLMs的推理能力，但在解剖识别中存在两个弱点：不同解剖结构间的知识无法有效共享，以及模型快速收敛到单一推理路径。

Method: 提出两种创新方法：1) 解剖相似性课程学习：通过控制问题难度（基于答案选项的相似性）实现渐进式学习，使模型逐步掌握复杂问题；2) 组多样性问题增强：通过问题增强扩展模型对困难查询的搜索空间，减少产生统一响应的倾向。

Result: 在SGG-VQA和OmniMedVQA基准测试中，该方法在两个基准上都取得了显著改进，证明了其在增强MLLMs医学推理能力方面的有效性。

Conclusion: 提出的解剖相似性课程学习和组多样性问题增强方法有效解决了GRPO在解剖识别中的局限性，显著提升了多模态大语言模型在医学解剖图像理解任务上的性能。

Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive progress in natural image reasoning, yet their potential in medical imaging remains underexplored, especially in clinical anatomical surgical images. Anatomy understanding tasks demand precise understanding and clinically coherent answers, which are difficult to achieve due to the complexity of medical data and the scarcity of high-quality expert annotations. These challenges limit the effectiveness of conventional Supervised Fine-Tuning (SFT) strategies. While recent work has demonstrated that Group Relative Policy Optimization (GRPO) can enhance reasoning in MLLMs without relying on large amounts of data, we find two weaknesses that hinder GRPO's reasoning performance in anatomy recognition: 1) knowledge cannot be effectively shared between different anatomical structures, resulting in uneven information gain and preventing the model from converging, and 2) the model quickly converges to a single reasoning path, suppressing the exploration of diverse strategies. To overcome these challenges, we propose two novel methods. First, we implement a progressive learning strategy called Anatomical Similarity Curriculum Learning by controlling question difficulty via the similarity of answer choices, enabling the model to master complex problems incrementally. Second, we utilize question augmentation referred to as Group Diversity Question Augmentation to expand the model's search space for difficult queries, mitigating the tendency to produce uniform responses. Comprehensive experiments on the SGG-VQA and OmniMedVQA benchmarks show our method achieves a significant improvement across the two benchmarks, demonstrating its effectiveness in enhancing the medical reasoning capabilities of MLLMs. The code can be found in https://github.com/tomato996/Anatomy-R1

</details>


### [11] [Multi-Modal Soccer Scene Analysis with Masked Pre-Training](https://arxiv.org/abs/2512.19528)
*Marc Peral,Guillem Capellera,Luis Ferraz,Antonio Rubio,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出用于分析足球战术镜头视频的多模态架构，专注于球轨迹推断、球状态分类和持球者识别三个核心任务，通过结合球员轨迹、球员类型和球员图像裁剪三种输入模态，使用社会时空Transformer块处理时空动态，无需直接访问球的历史或未来位置。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖准确的球跟踪或手工启发式规则，无法在真实顶级联赛比赛的噪声或遮挡条件下鲁棒地识别球状态和持球者。需要一种能够从战术镜头中分析足球场景的综合性多模态方法。

Method: 集成三种输入模态（球员轨迹、球员类型和球员图像裁剪）到统一框架，使用级联的社会时空Transformer块处理时空动态。引入CropDrop预训练策略，通过模态特定的掩码防止过度依赖图像特征，鼓励模型在预训练期间依赖跨模态模式。

Result: 在大规模数据集上展示了方法的有效性，在所有任务上都显著优于最先进的基线方法。结果突出了在基于Transformer的架构中结合结构化和视觉线索的好处，以及现实掩码策略在多模态学习中的重要性。

Conclusion: 提出的多模态架构能够从战术镜头中分析足球场景，无需直接访问球的位置信息，在噪声和遮挡条件下表现鲁棒。CropDrop预训练策略有效防止了过度依赖图像特征，促进了跨模态学习。

Abstract: In this work we propose a multi-modal architecture for analyzing soccer scenes from tactical camera footage, with a focus on three core tasks: ball trajectory inference, ball state classification, and ball possessor identification. To this end, our solution integrates three distinct input modalities (player trajectories, player types and image crops of individual players) into a unified framework that processes spatial and temporal dynamics using a cascade of sociotemporal transformer blocks. Unlike prior methods, which rely heavily on accurate ball tracking or handcrafted heuristics, our approach infers the ball trajectory without direct access to its past or future positions, and robustly identifies the ball state and ball possessor under noisy or occluded conditions from real top league matches. We also introduce CropDrop, a modality-specific masking pre-training strategy that prevents over-reliance on image features and encourages the model to rely on cross-modal patterns during pre-training. We show the effectiveness of our approach on a large-scale dataset providing substantial improvements over state-of-the-art baselines in all tasks. Our results highlight the benefits of combining structured and visual cues in a transformer-based architecture, and the importance of realistic masking strategies in multi-modal learning.

</details>


### [12] [ActAvatar: Temporally-Aware Precise Action Control for Talking Avatars](https://arxiv.org/abs/2512.19546)
*Ziqiao Peng,Yi Chen,Yifeng Ma,Guozhen Zhang,Zhiyao Sun,Zixiang Zhou,Youliang Zhang,Zhengguang Zhou,Zhaoxin Fan,Hongyan Liu,Yuan Zhou,Qinglin Lu,Jun He*

Main category: cs.CV

TL;DR: ActAvatar：通过文本引导实现相位级精度动作控制的说话头像生成框架，解决了现有方法在文本跟随能力、时间对齐和依赖额外控制信号方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有说话头像生成方法存在三个关键问题：1) 文本跟随能力不足，难以生成多样化动作；2) 动作与音频内容之间缺乏时间对齐；3) 依赖额外的控制信号（如姿态骨架）。需要开发一个能够通过文本引导实现精确动作控制的框架。

Method: 提出三个核心创新：1) 相位感知交叉注意力(PACA)，将提示分解为全局基础块和时间锚定的相位块，使模型能够专注于相位相关标记；2) 渐进式视听对齐，早期层优先文本建立动作结构，深层强调音频细化唇部运动；3) 两阶段训练策略，先在多样化数据上建立稳健的视听对应，再通过结构化注释微调注入动作控制。

Result: 广泛实验表明，ActAvatar在动作控制和视觉质量方面显著优于最先进的方法。

Conclusion: ActAvatar框架通过相位级精度动作控制，解决了说话头像生成中的关键挑战，实现了更好的文本跟随能力和时间对齐，同时不依赖额外控制信号。

Abstract: Despite significant advances in talking avatar generation, existing methods face critical challenges: insufficient text-following capability for diverse actions, lack of temporal alignment between actions and audio content, and dependency on additional control signals such as pose skeletons. We present ActAvatar, a framework that achieves phase-level precision in action control through textual guidance by capturing both action semantics and temporal context. Our approach introduces three core innovations: (1) Phase-Aware Cross-Attention (PACA), which decomposes prompts into a global base block and temporally-anchored phase blocks, enabling the model to concentrate on phase-relevant tokens for precise temporal-semantic alignment; (2) Progressive Audio-Visual Alignment, which aligns modality influence with the hierarchical feature learning process-early layers prioritize text for establishing action structure while deeper layers emphasize audio for refining lip movements, preventing modality interference; (3) A two-stage training strategy that first establishes robust audio-visual correspondence on diverse data, then injects action control through fine-tuning on structured annotations, maintaining both audio-visual alignment and the model's text-following capabilities. Extensive experiments demonstrate that ActAvatar significantly outperforms state-of-the-art methods in both action control and visual quality.

</details>


### [13] [Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2512.19663)
*Argha Kamal Samanta,Harshika Goyal,Vasudha Joshi,Tushar Mungle,Pabitra Mitra*

Main category: cs.CV

TL;DR: 提出知识增强的联合嵌入框架，整合视网膜图像、临床文本和结构化患者数据，显著提升糖尿病视网膜病变的跨模态检索和诊断性能。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是全球可预防性失明的主要原因，需要准确的自动化诊断系统。通用视觉语言模型（如CLIP）在自然图像任务中表现良好，但在医学领域应用，特别是眼科图像的跨模态检索方面表现不佳。

Method: 提出知识增强的联合嵌入框架，使用多模态Transformer架构：Vision Transformer处理视网膜图像，Bio-ClinicalBERT处理临床叙述，多层感知机处理结构化特征。通过联合Transformer融合各模态，使用对比损失、重建损失和分类损失进行多目标训练。

Result: 在BRSET数据集上，文本到图像检索Recall@1达到99.94%（相比微调CLIP的1.29%），SDRG分类准确率97.05%，ICDR分类准确率97.97%。在DeepEyeNet数据集上的零样本评估显示Recall@1为93.95%（相比微调CLIP的0.22%）。

Conclusion: 该多模态训练方法有效捕捉医学领域的跨模态关系，在检索能力和诊断性能方面均表现出色，验证了框架的优越性和强泛化能力。

Abstract: Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain applications, particularly in cross-modal retrieval for ophthalmological images. We propose a novel knowledge-enhanced joint embedding framework that integrates retinal fundus images, clinical text, and structured patient data through a multimodal transformer architecture to address the critical gap in medical image-text alignment. Our approach employs separate encoders for each modality: a Vision Transformer (ViT-B/16) for retinal images, Bio-ClinicalBERT for clinical narratives, and a multilayer perceptron for structured demographic and clinical features. These modalities are fused through a joint transformer with modality-specific embeddings, trained using multiple objectives including contrastive losses between modality pairs, reconstruction losses for images and text, and classification losses for DR severity grading according to ICDR and SDRG schemes. Experimental results on the Brazilian Multilabel Ophthalmological Dataset (BRSET) demonstrate significant improvements over baseline models. Our framework achieves near-perfect text-to-image retrieval performance with Recall@1 of 99.94% compared to fine-tuned CLIP's 1.29%, while maintaining state-of-the-art classification accuracy of 97.05% for SDRG and 97.97% for ICDR. Furthermore, zero-shot evaluation on the unseen DeepEyeNet dataset validates strong generalizability with 93.95% Recall@1 versus 0.22% for fine-tuned CLIP. These results demonstrate that our multimodal training approach effectively captures cross-modal relationships in the medical domain, establishing both superior retrieval capabilities and robust diagnostic performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations](https://arxiv.org/abs/2512.17984)
*Mohammadmahdi Rahimiasl,Ynte Vanderhoydonc,Siegfried Mercelis*

Main category: cs.LG

TL;DR: HINT提出了一种混合归纳-转导网络，用于交通流量插补，结合速度的转导信号和流量的归纳学习，在三个真实数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 交通流量插补面临挑战：环检测器数据精确但稀疏，探测车速度数据广泛但仅与流量弱相关，相邻路段流量尺度差异大（如匝道与主线），这打破了标准GNN的假设。

Method: HINT采用混合归纳-转导网络：1）归纳空间变换器学习节点特征驱动的长程交互；2）基于FiLM的扩散GCN，利用丰富静态上下文（OSM属性和交通仿真）；3）节点级校准层修正各路段尺度偏差。训练使用掩码重建、逐轮节点采样、困难节点挖掘和可见流量噪声注入。

Result: 在三个真实数据集（MOW、UTD19-Torino、UTD19-Essen）上，HINT持续超越最先进的归纳基线。相比KITS，在MOW上MAE降低约42%（基础仿真）和50%（校准仿真）；在Torino降低约22%；在Essen降低约12%。即使没有仿真，HINT在MOW和Torino上仍表现优异。

Conclusion: 将归纳流量插补与转导速度、交通仿真和外部地理空间信息相结合，能显著提高交通流量插补的准确性，特别是在处理稀疏传感器和异质流量尺度时。

Abstract: Accurately imputing traffic flow at unsensed locations is difficult: loop detectors provide precise but sparse measurements, speed from probe vehicles is widely available yet only weakly correlated with flow, and nearby links often exhibit strong heterophily in the scale of traffic flow (e.g., ramps vs. mainline), which breaks standard GNN assumptions. We propose HINT, a Hybrid INductive-Transductive Network, and an INDU-TRANSDUCTIVE training strategy that treats speed as a transductive, network-wide signal while learning flow inductively to generalize to unseen locations. HINT couples (i) an inductive spatial transformer that learns similarity-driven, long-range interactions from node features with (ii) a diffusion GCN conditioned by FiLM on rich static context (OSM-derived attributes and traffic simulation), and (iii) a node-wise calibration layer that corrects scale biases per segment. Training uses masked reconstruction with epoch-wise node sampling, hard-node mining to emphasize difficult sensors, and noise injection on visible flows to prevent identity mapping, while graph structure is built from driving distances.
  Across three real-world datasets, MOW (Antwerp, Belgium), UTD19-Torino, and UTD19-Essen, HINT consistently surpasses state-of-the-art inductive baselines. Relative to KITS, HINT reduces MAE on MOW by $\approx42$% with basic simulation and $\approx50$% with calibrated simulation; on Torino by $\approx22$%, and on Essen by $\approx12$%. Even without simulation, HINT remains superior on MOW and Torino, while simulation is crucial on Essen. These results show that combining inductive flow imputation with transductive speed, traffic simulations and external geospatial improves accuracy for the task described above.

</details>


### [15] [FedOAED: Federated On-Device Autoencoder Denoiser for Heterogeneous Data under Limited Client Availability](https://arxiv.org/abs/2512.17986)
*S M Ruhul Kabir Howlader,Xiao Chen,Yifei Xie,Lu Liu*

Main category: cs.LG

TL;DR: FedOAED是一种新颖的联邦学习算法，通过客户端设备上的自编码器降噪器来缓解客户端漂移和部分客户端参与引起的方差问题，在非独立同分布数据设置下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然联邦学习（FL）解决了数据隐私保护问题，但在实际应用中仍面临异构性带来的挑战：梯度噪声、客户端漂移以及部分客户端参与导致的方差增加。这些限制阻碍了FL在现实场景中的有效应用。

Method: FedOAED算法在客户端侧集成了设备上的自编码器降噪器，用于缓解由多个本地训练更新引起的客户端漂移，以及部分客户端参与导致的方差问题。该方法专门针对异构数据分布和有限客户端可用性场景设计。

Result: 在多个视觉数据集上的非独立同分布（Non-IID）设置实验中，FedOAED始终优于最先进的基线方法，证明了其在缓解客户端漂移和方差问题方面的有效性。

Conclusion: FedOAED通过创新的设备端自编码器降噪机制，成功解决了联邦学习中的客户端漂移和部分参与方差问题，为异构数据环境下的隐私保护机器学习提供了有效解决方案。

Abstract: Over the last few decades, machine learning (ML) and deep learning (DL) solutions have demonstrated their potential across many applications by leveraging large amounts of high-quality data. However, strict data-sharing regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) have prevented many data-driven applications from being realised. Federated Learning (FL), in which raw data never leaves local devices, has shown promise in overcoming these limitations. Although FL has grown rapidly in recent years, it still struggles with heterogeneity, which produces gradient noise, client-drift, and increased variance from partial client participation. In this paper, we propose FedOAED, a novel federated learning algorithm designed to mitigate client-drift arising from multiple local training updates and the variance induced by partial client participation. FedOAED incorporates an on-device autoencoder denoiser on the client side to mitigate client-drift and variance resulting from heterogeneous data under limited client availability. Experiments on multiple vision datasets under Non-IID settings demonstrate that FedOAED consistently outperforms state-of-the-art baselines.

</details>


### [16] [TraCeR: Transformer-Based Competing Risk Analysis with Longitudinal Covariates](https://arxiv.org/abs/2512.18129)
*Maxmillan Ries,Sohan Seth*

Main category: cs.LG

TL;DR: TraCeR：基于Transformer的生存分析框架，用于处理纵向协变量，无需比例风险假设，同时评估模型校准性


<details>
  <summary>Details</summary>
Motivation: 现有深度学习生存分析模型主要关注横截面特征，难以有效纳入纵向协变量，且评估主要关注区分度而忽视校准性评估

Method: 基于分解自注意力架构的Transformer框架，从测量序列估计风险函数，自然捕获时间协变量交互，无需数据生成过程假设，可处理删失数据和竞争事件

Result: 在多个真实世界数据集上，TraCeR相比最先进方法取得显著且统计显著的性能提升

Conclusion: TraCeR成功解决了纵向协变量纳入和校准性评估两个关键挑战，为生存分析提供了更全面的框架

Abstract: Survival analysis is a critical tool for modeling time-to-event data. Recent deep learning-based models have reduced various modeling assumptions including proportional hazard and linearity. However, a persistent challenge remains in incorporating longitudinal covariates, with prior work largely focusing on cross-sectional features, and in assessing calibration of these models, with research primarily focusing on discrimination during evaluation. We introduce TraCeR, a transformer-based survival analysis framework for incorporating longitudinal covariates. Based on a factorized self-attention architecture, TraCeR estimates the hazard function from a sequence of measurements, naturally capturing temporal covariate interactions without assumptions about the underlying data-generating process. The framework is inherently designed to handle censored data and competing events. Experiments on multiple real-world datasets demonstrate that TraCeR achieves substantial and statistically significant performance improvements over state-of-the-art methods. Furthermore, our evaluation extends beyond discrimination metrics and assesses model calibration, addressing a key oversight in literature.

</details>


### [17] [FairExpand: Individual Fairness on Graphs with Partial Similarity Information](https://arxiv.org/abs/2512.18180)
*Rebecca Salganik,Yibin Wang,Guillaume Salha-Galvan,Jian Kang*

Main category: cs.LG

TL;DR: FairExpand：一种在部分相似性信息场景下促进图表示学习中个体公平性的灵活框架


<details>
  <summary>Details</summary>
Motivation: 现有图表示学习的个体公平性方法需要所有节点对的预定义相似性信息，这在现实中往往不切实际，阻碍了实际应用。本文针对更现实的场景，即相似性信息仅对有限节点对可用的情况。

Method: FairExpand采用两步流水线：1) 使用骨干模型（如图神经网络）精炼节点表示；2) 逐步传播相似性信息。这种交替方法允许公平性约束有效扩展到整个图。

Result: 大量实验表明，FairExpand在保持性能的同时，能持续增强个体公平性，使其成为在现实世界部分相似性信息应用中实现基于图的个体公平性的实用解决方案。

Conclusion: FairExpand为图表示学习中个体公平性的实际应用提供了可行方案，解决了现有方法需要完整相似性信息的局限性，在用户建模、推荐系统和搜索等高风险Web领域具有重要实践价值。

Abstract: Individual fairness, which requires that similar individuals should be treated similarly by algorithmic systems, has become a central principle in fair machine learning. Individual fairness has garnered traction in graph representation learning due to its practical importance in high-stakes Web areas such as user modeling, recommender systems, and search. However, existing methods assume the existence of predefined similarity information over all node pairs, an often unrealistic requirement that prevents their operationalization in practice. In this paper, we assume the similarity information is only available for a limited subset of node pairs and introduce FairExpand, a flexible framework that promotes individual fairness in this more realistic partial information scenario. FairExpand follows a two-step pipeline that alternates between refining node representations using a backbone model (e.g., a graph neural network) and gradually propagating similarity information, which allows fairness enforcement to effectively expand to the entire graph. Extensive experiments show that FairExpand consistently enhances individual fairness while preserving performance, making it a practical solution for enabling graph-based individual fairness in real-world applications with partial similarity information.

</details>


### [18] [Stable and Efficient Single-Rollout RL for Multimodal Reasoning](https://arxiv.org/abs/2512.18215)
*Rui Liu,Dian Yu,Lei Ke,Haolin Liu,Yujun Zhou,Zhenwen Liang,Haitao Mi,Pratap Tokekar,Dong Yu*

Main category: cs.LG

TL;DR: MSSR是一个用于多模态大语言模型的无组强化学习框架，通过基于熵的优势整形机制解决单轮采样训练中的稳定性问题，在保持训练稳定的同时提高计算效率和推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于组的RLVR算法需要多轮采样，计算效率低。而单轮采样变体在多模态环境中存在严重的不稳定性，容易导致训练崩溃。需要解决训练效率与稳定性之间的权衡问题。

Method: 提出MSSR（多模态稳定单轮采样）框架，采用基于熵的优势整形机制，自适应地正则化优势幅度，防止训练崩溃并保持稳定性。这是首个专门针对多模态单轮采样RLVR设计的稳定优化方法。

Result: 在分布内评估中，MSSR仅用一半的训练步数就能达到与基于组基线相似的验证准确率。当训练相同步数时，MSSR性能超越基线，并在五个不同的推理密集型基准测试中展现出一致的泛化改进。

Conclusion: MSSR为复杂的多模态推理任务提供了稳定、计算高效且有效的RLVR解决方案，解决了多模态环境中单轮采样训练的效率-稳定性权衡问题。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a key paradigm to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevalent group-based algorithms such as GRPO require multi-rollout sampling for each prompt. While more efficient single-rollout variants have recently been explored in text-only settings, we find that they suffer from severe instability in multimodal contexts, often leading to training collapse. To address this training efficiency-stability trade-off, we introduce $\textbf{MSSR}$ (Multimodal Stabilized Single-Rollout), a group-free RLVR framework that achieves both stable optimization and effective multimodal reasoning performance. MSSR achieves this via an entropy-based advantage-shaping mechanism that adaptively regularizes advantage magnitudes, preventing collapse and maintaining training stability. While such mechanisms have been used in group-based RLVR, we show that in the multimodal single-rollout setting they are not merely beneficial but essential for stability. In in-distribution evaluations, MSSR demonstrates superior training compute efficiency, achieving similar validation accuracy to the group-based baseline with half the training steps. When trained for the same number of steps, MSSR's performance surpasses the group-based baseline and shows consistent generalization improvements across five diverse reasoning-intensive benchmarks. Together, these results demonstrate that MSSR enables stable, compute-efficient, and effective RLVR for complex multimodal reasoning tasks.

</details>


### [19] [The Geometry of Abstraction: Continual Learning via Recursive Quotienting](https://arxiv.org/abs/2512.18471)
*Xin Li*

Main category: cs.LG

TL;DR: 提出递归度量收缩框架解决持续学习中的几何障碍，通过拓扑变形将线性增长的测地距离转化为对数深度的拓扑结构，实现有界容量嵌入和线性可分性。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习系统在固定维度空间中面临的基本几何障碍：平坦流形问题。当经验表示为欧几里得空间中的线性轨迹时，时间事件之间的测地距离随时间线性增长，导致所需覆盖数发散，最终引发灾难性干扰。

Method: 提出递归度量收缩框架，将抽象概念化为拓扑变形而非符号分组。通过商映射在已验证的时间邻域内收缩度量张量，使局部子流形直径趋近于零。采用正交流形分割（流动流形和支架流形）来保持记忆稳定性。

Result: 1. 有界容量定理：递归商映射允许将任意长轨迹嵌入有界表示体积中；2. 拓扑坍缩可分性定理：递归商化使非线性可分时间序列在极限下线性可分；3. 奇偶分割稳定性定理：通过正交流形分割解决灾难性遗忘问题。

Conclusion: 递归度量收缩为持续学习中的几何障碍提供了理论解决方案，揭示了神经网络中的标记实际上是连接时间流形中远点的奇点或虫洞，实现了有界容量嵌入、线性可分性和记忆稳定性。

Abstract: Continual learning systems operating in fixed-dimensional spaces face a fundamental geometric barrier: the flat manifold problem. When experience is represented as a linear trajectory in Euclidean space, the geodesic distance between temporal events grows linearly with time, forcing the required covering number to diverge. In fixed-dimensional hardware, this volume expansion inevitably forces trajectory overlap, manifesting as catastrophic interference. In this work, we propose a geometric resolution to this paradox based on Recursive Metric Contraction. We formalize abstraction not as symbolic grouping, but as a topological deformation: a quotient map that collapses the metric tensor within validated temporal neighborhoods, effectively driving the diameter of local sub-manifolds to zero. We substantiate our framework with four rigorous results. First, the Bounded Capacity Theorem establishes that recursive quotient maps allow the embedding of arbitrarily long trajectories into bounded representational volumes, trading linear metric growth for logarithmic topological depth. Second, the Topological Collapse Separability Theorem, derived via Urysohn's Lemma, proves that recursive quotienting renders non-linearly separable temporal sequences linearly separable in the limit, bypassing the need for infinite-dimensional kernel projections. Third, the Parity-Partitioned Stability Theorem solves the catastrophic forgetting problem by proving that if the state space is partitioned into orthogonal flow and scaffold manifolds, the metric deformations of active learning do not disturb the stability of stored memories. Our analysis reveals that tokens in neural architectures are physically realizable as singularities or wormholes, regions of extreme positive curvature that bridge distant points in the temporal manifold.

</details>


### [20] [Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing](https://arxiv.org/abs/2512.18575)
*Effiong Blessing,Chiung-Yi Tseng,Somshubhra Roy,Junaid Rehman,Isaac Nkrumah*

Main category: cs.LG

TL;DR: 该研究首次对脉冲神经网络中的记忆机制进行跨模态消融分析，发现Hopfield网络在视觉任务上表现优异（97.68%）但在听觉任务上较差（76.15%），而监督对比学习表现更均衡，揭示了记忆机制具有模态特异性而非通用性。


<details>
  <summary>Details</summary>
Motivation: 尽管记忆增强型脉冲神经网络在节能神经形态计算方面有前景，但其在不同感官模态间的泛化能力尚未被探索。研究旨在首次全面评估SNNs中记忆机制在跨模态任务中的表现。

Method: 采用跨模态消融研究方法，在视觉（N-MNIST）和听觉（SHD）神经形态数据集上评估了五种架构：Hopfield网络、分层门控循环网络（HGRNs）和监督对比学习（SCL）。通过系统评估不同记忆机制的性能，并进行联合多模态训练和定量记忆痕迹分析。

Result: 发现显著的模态依赖性能模式：Hopfield网络在视觉任务上达到97.68%准确率，但在听觉任务上仅76.15%（21.53点差距），而SCL表现更均衡（96.72%视觉，82.16%听觉，14.56点差距）。HGRN联合多模态训练达到94.41%视觉和79.37%听觉准确率。定量记忆痕迹分析显示跨模态对齐较弱（0.038相似度）。

Conclusion: 记忆机制表现出任务特异性优势而非通用适用性，为神经形态系统中的模态特定记忆优化提供了首个实证证据，实现了比传统神经网络603倍的能效提升。

Abstract: Memory-augmented spiking neural networks (SNNs) promise energy-efficient neuromorphic computing, yet their generalization across sensory modalities remains unexplored. We present the first comprehensive cross-modal ablation study of memory mechanisms in SNNs, evaluating Hopfield networks, Hierarchical Gated Recurrent Networks (HGRNs), and supervised contrastive learning (SCL) across visual (N-MNIST) and auditory (SHD) neuromorphic datasets. Our systematic evaluation of five architectures reveals striking modality-dependent performance patterns: Hopfield networks achieve 97.68% accuracy on visual tasks but only 76.15% on auditory tasks (21.53 point gap), revealing severe modality-specific specialization, while SCL demonstrates more balanced cross-modal performance (96.72% visual, 82.16% audio, 14.56 point gap). These findings establish that memory mechanisms exhibit task-specific benefits rather than universal applicability. Joint multi-modal training with HGRN achieves 94.41% visual and 79.37% audio accuracy (88.78% average), matching parallel HGRN performance through unified deployment. Quantitative engram analysis confirms weak cross-modal alignment (0.038 similarity), validating our parallel architecture design. Our work provides the first empirical evidence for modality-specific memory optimization in neuromorphic systems, achieving 603x energy efficiency over traditional neural networks.

</details>


### [21] [EIA-SEC: Improved Actor-Critic Framework for Multi-UAV Collaborative Control in Smart Agriculture](https://arxiv.org/abs/2512.18596)
*Quanxi Zhou,Wencan Mao,Yilei Liang,Manabu Tsukada,Yunling Liu,Jon Crowcroft*

Main category: cs.LG

TL;DR: 提出EIA-SEC框架解决多无人机智能农业系统中的轨迹规划问题，通过精英模仿和共享集成批评器提升性能


<details>
  <summary>Details</summary>
Motivation: 无线通信技术推动智能农业发展，无人机在数据采集、图像获取和通信任务中发挥多功能作用。多无人机协同工作需要解决轨迹规划问题，但现有方法存在试错成本高、估计偏差和过估计等问题。

Method: 建立马尔可夫决策过程模型，提出精英模仿演员-共享集成批评器（EIA-SEC）框架：1）智能体自适应地从精英智能体学习以减少试错成本；2）共享集成批评器与每个智能体的本地批评器协作，确保无偏目标值估计并防止过估计。

Result: 实验结果表明，EIA-SEC在奖励性能、训练稳定性和收敛速度方面优于最先进的基线方法。

Conclusion: EIA-SEC框架有效解决了多无人机智能农业系统的轨迹规划问题，通过精英模仿和共享集成批评器机制提升了多智能体强化学习的性能。

Abstract: The widespread application of wireless communication technology has promoted the development of smart agriculture, where unmanned aerial vehicles (UAVs) play a multifunctional role. We target a multi-UAV smart agriculture system where UAVs cooperatively perform data collection, image acquisition, and communication tasks. In this context, we model a Markov decision process to solve the multi-UAV trajectory planning problem. Moreover, we propose a novel Elite Imitation Actor-Shared Ensemble Critic (EIA-SEC) framework, where agents adaptively learn from the elite agent to reduce trial-and-error costs, and a shared ensemble critic collaborates with each agent's local critic to ensure unbiased objective value estimates and prevent overestimation. Experimental results demonstrate that EIA-SEC outperforms state-of-the-art baselines in terms of reward performance, training stability, and convergence speed.

</details>


### [22] [PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation](https://arxiv.org/abs/2512.18737)
*Zichuan Lin,Xiaokai Huang,Jiate Liu,Yuxuan Han,Jia Chen,Xiapeng Wu,Deheng Ye*

Main category: cs.LG

TL;DR: PIPCFR提出了一种利用治疗后变量改进个体治疗效果估计的新方法，通过伪结果插补和有效表征学习，显著降低了反事实预测的误差。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估计个体治疗效果时，往往忽略了治疗后变量对结果的影响，这导致无法完全捕捉结果的变异性，增加了反事实预测的方差。

Method: 提出PIPCFR方法，结合治疗后变量改进伪结果插补，建立新的理论边界连接治疗后变量与ITE估计精度，学习既能保留信息成分又能减少偏差的有效表征。

Result: 在真实世界和模拟数据集上的实证评估表明，PIPCFR相比现有方法显著降低了ITE误差。

Conclusion: 治疗后变量对个体治疗效果估计至关重要，PIPCFR通过有效利用这些变量，提高了反事实预测的准确性，为因果推断提供了新的方法。

Abstract: The estimation of individual treatment effects (ITE) focuses on predicting the outcome changes that result from a change in treatment. A fundamental challenge in observational data is that while we need to infer outcome differences under alternative treatments, we can only observe each individual's outcome under a single treatment. Existing approaches address this limitation either by training with inferred pseudo-outcomes or by creating matched instance pairs. However, recent work has largely overlooked the potential impact of post-treatment variables on the outcome. This oversight prevents existing methods from fully capturing outcome variability, resulting in increased variance in counterfactual predictions. This paper introduces Pseudo-outcome Imputation with Post-treatment Variables for Counterfactual Regression (PIPCFR), a novel approach that incorporates post-treatment variables to improve pseudo-outcome imputation. We analyze the challenges inherent in utilizing post-treatment variables and establish a novel theoretical bound for ITE risk that explicitly connects post-treatment variables to ITE estimation accuracy. Unlike existing methods that ignore these variables or impose restrictive assumptions, PIPCFR learns effective representations that preserve informative components while mitigating bias. Empirical evaluations on both real-world and simulated datasets demonstrate that PIPCFR achieves significantly lower ITE errors compared to existing methods.

</details>


### [23] [When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models](https://arxiv.org/abs/2512.18934)
*Michael S. Zhang,Rishi A. Ruia,Arnav Kewalram,Saathvik Dharmapuram,Utkarsh Sharma,Kevin Zhu*

Main category: cs.LG

TL;DR: 量化（INT8/INT4）在持续学习中优于高精度（FP16），量化噪声起到正则化作用防止过拟合，小回放缓冲区显著提升知识保留，INT8在计算效率和持续学习性能间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 研究量化精度与持续学习中灾难性遗忘的相互作用，探索在部署效率需求下如何平衡模型精度与持续学习能力。

Method: 系统研究不同量化精度（FP16、INT8、INT4）与回放缓冲区策略在大语言模型中的表现，分析量化噪声对持续学习动态的影响。

Result: 量化模型在后续任务上超越FP16（8-15%优势），INT4在代码生成任务上性能接近FP16的两倍；即使很小的回放缓冲区（0.1%）也能显著提升知识保留；INT8在计算效率和持续学习性能间达到最佳平衡。

Conclusion: 量化噪声作为隐式正则化防止过拟合，挑战了"精度越高越好"的传统观念；INT8量化既提供计算效率又具备优越的持续学习动态；为压缩模型在持续学习场景中的部署提供实用指南。

Abstract: Catastrophic forgetting poses a fundamental challenge in continual learning, particularly when models are quantized for deployment efficiency. We systematically investigate the interplay between quantization precision (FP16, INT8, INT4) and replay buffer strategies in large language models, revealing unexpected dynamics. While FP16 achieves superior initial task performance (74.44% on NLU), we observe a striking inversion on subsequent tasks: quantized models outperform FP16 by 8-15% on final task forward accuracy, with INT4 achieving nearly double FP16's performance on Code generation (40% vs 20%). Critically, even minimal replay buffers (0.1%) dramatically improve retention - increasing NLU retention after Math training from 45% to 65% across all precision levels - with INT8 consistently achieving the optimal balance between learning plasticity and knowledge retention. We hypothesize that quantization-induced noise acts as implicit regularization, preventing the overfitting to new task gradients that plagues high-precision models. These findings challenge the conventional wisdom that higher precision is always preferable, suggesting instead that INT8 quantization offers both computational efficiency and superior continual learning dynamics. Our results provide practical guidelines for deploying compressed models in continual learning scenarios: small replay buffers (1-2%) suffice for NLU tasks, while Math and Code benefit from moderate buffers (5-10%), with quantized models requiring less replay than FP16 to achieve comparable retention. Code is available at https://github.com/Festyve/LessIsMore.

</details>


### [24] [Optimizer Dynamics at the Edge of Stability with Differential Privacy](https://arxiv.org/abs/2512.19019)
*Ayana Hussain,Ricky Fang*

Main category: cs.LG

TL;DR: DP训练会改变神经网络优化动态，但边缘稳定性模式仍然存在，只是DP会降低锐度并阻止优化器完全达到经典稳定性阈值


<details>
  <summary>Details</summary>
Motivation: 研究差分隐私如何改变神经网络训练动态，特别是梯度裁剪和高斯噪声对优化器稳定性的影响

Method: 比较标准梯度下降和Adam与其隐私保护变体，分析梯度裁剪和噪声如何改变锐度和损失演化

Result: DP通常会降低锐度并阻止优化器完全达到经典稳定性阈值，但边缘稳定性模式仍然存在，最大学习率和最大隐私预算有时会接近或超过这些阈值

Conclusion: 差分隐私在神经网络优化中引入了不可预测性，但稳定性模式仍然持续存在

Abstract: Deep learning models can reveal sensitive information about individual training examples, and while differential privacy (DP) provides guarantees restricting such leakage, it also alters optimization dynamics in poorly understood ways. We study the training dynamics of neural networks under DP by comparing Gradient Descent (GD), and Adam to their privacy-preserving variants. Prior work shows that these optimizers exhibit distinct stability dynamics: full-batch methods train at the Edge of Stability (EoS), while mini-batch and adaptive methods exhibit analogous edge-of-stability behavior. At these regimes, the training loss and the sharpness--the maximum eigenvalue of the training loss Hessian--exhibit certain characteristic behavior. In DP training, per-example gradient clipping and Gaussian noise modify the update rule, and it is unclear whether these stability patterns persist. We analyze how clipping and noise change sharpness and loss evolution and show that while DP generally reduces the sharpness and can prevent optimizers from fully reaching the classical stability thresholds, patterns from EoS and analogous adaptive methods stability regimes persist, with the largest learning rates and largest privacy budgets approaching, and sometimes exceeding, these thresholds. These findings highlight the unpredictability introduced by DP in neural network optimization.

</details>


### [25] [A Logical View of GNN-Style Computation and the Role of Activation Functions](https://arxiv.org/abs/2512.19332)
*Pablo Barceló,Floris Geerts,Matthias Lanzinger,Klara Pakhomenko,Jan Van den Bussche*

Main category: cs.LG

TL;DR: 本文研究了MPLang（一种描述图神经网络计算的语言）的表达能力，分析了不同激活函数（有界/无界）对GNN表达力的影响，证明了ReLU等无界激活函数比有界激活函数具有更强的表达能力。


<details>
  <summary>Details</summary>
Motivation: 研究图神经网络（GNN）计算语言MPLang的表达能力，特别关注激活函数类型（有界vs无界）如何影响GNN的数值和布尔表达能力，以理解不同GNN架构的理论表达能力差异。

Method: 1. 首先分析无激活函数的A-MPLang片段，用walk-summed特征刻画其表达能力；2. 研究有界激活函数，证明在温和条件下所有最终常数激活函数具有相同的表达能力；3. 证明无界激活函数（如ReLU）比有界激活函数在存在线性层时具有更强的表达能力。

Result: 1. 给出了A-MPLang表达能力的特征化描述；2. 证明了所有最终常数激活函数具有相同的表达能力；3. 首次证明了在存在线性层时，无界激活函数（如ReLU）比有界激活函数（如截断ReLU）具有更强的数值查询能力。

Conclusion: 激活函数的类型显著影响GNN的表达能力：无界激活函数（如ReLU）比有界激活函数具有更强的表达能力，特别是在存在线性层的情况下。这揭示了线性聚合与最终常数非线性之间的微妙相互作用，表明使用ReLU的GNN比限制使用最终常数激活函数和线性层的GNN更具表达力。

Abstract: We study the numerical and Boolean expressiveness of MPLang, a declarative language that captures the computation of graph neural networks (GNNs) through linear message passing and activation functions. We begin with A-MPLang, the fragment without activation functions, and give a characterization of its expressive power in terms of walk-summed features. For bounded activation functions, we show that (under mild conditions) all eventually constant activations yield the same expressive power - numerical and Boolean - and that it subsumes previously established logics for GNNs with eventually constant activation functions but without linear layers. Finally, we prove the first expressive separation between unbounded and bounded activations in the presence of linear layers: MPLang with ReLU is strictly more powerful for numerical queries than MPLang with eventually constant activation functions, e.g., truncated ReLU. This hinges on subtle interactions between linear aggregation and eventually constant non-linearities, and it establishes that GNNs using ReLU are more expressive than those restricted to eventually constant activations and linear layers.

</details>


### [26] [DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast](https://arxiv.org/abs/2512.19506)
*Hongliang Li,Nong Zhang,Zhewen Xu,Xiang Li,Changzheng Liu,Chongbo Zhao,Jie Wu*

Main category: cs.LG

TL;DR: 提出DK-STN模型，结合数值天气预报与神经网络优势，实现高效稳定的MJO预测，精度与ECMWF相当但效率更高


<details>
  <summary>Details</summary>
Motivation: 传统数值天气预报方法资源密集、耗时且不稳定，而现有神经网络方法虽节省资源但精度不足，无法达到28天预测水平，需要结合两者优势改进MJO预测

Method: 提出领域知识嵌入时空网络(DK-STN)，在时空网络基础上通过两种关键方法嵌入领域知识：1)应用领域知识增强方法；2)将领域知识处理方法集成到网络训练中

Result: 使用ERA5数据评估，DK-STN以7天气候数据为输入，1-2秒内生成28天可靠预测，不同季节误差仅2-3天，精度与ECMWF相当但效率和稳定性显著更优

Conclusion: DK-STN成功结合了NWP和ANN方法的优势，在保持高效率和高稳定性的同时，显著提高了神经网络方法的预测精度，为MJO预测提供了有效解决方案

Abstract: Understanding and predicting the Madden-Julian Oscillation (MJO) is fundamental for precipitation forecasting and disaster prevention. To date, long-term and accurate MJO prediction has remained a challenge for researchers. Conventional MJO prediction methods using Numerical Weather Prediction (NWP) are resource-intensive, time-consuming, and highly unstable (most NWP methods are sensitive to seasons, with better MJO forecast results in winter). While existing Artificial Neural Network (ANN) methods save resources and speed forecasting, their accuracy never reaches the 28 days predicted by the state-of-the-art NWP method, i.e., the operational forecasts from ECMWF, since neural networks cannot handle climate data effectively. In this paper, we present a Domain Knowledge Embedded Spatio-Temporal Network (DK-STN), a stable neural network model for accurate and efficient MJO forecasting. It combines the benefits of NWP and ANN methods and successfully improves the forecast accuracy of ANN methods while maintaining a high level of efficiency and stability. We begin with a spatial-temporal network (STN) and embed domain knowledge in it using two key methods: (i) applying a domain knowledge enhancement method and (ii) integrating a domain knowledge processing method into network training. We evaluated DK-STN with the 5th generation of ECMWF reanalysis (ERA5) data and compared it with ECMWF. Given 7 days of climate data as input, DK-STN can generate reliable forecasts for the following 28 days in 1-2 seconds, with an error of only 2-3 days in different seasons. DK-STN significantly exceeds ECMWF in that its forecast accuracy is equivalent to ECMWF's, while its efficiency and stability are significantly superior.

</details>


### [27] [Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement](https://arxiv.org/abs/2512.19530)
*Hongsheng Xing,Qiuxin Si*

Main category: cs.LG

TL;DR: 该研究提出了Catechol Benchmark数据集，用于评估机器学习模型在连续溶剂组成范围内预测反应产率的能力，并开发了一种混合GNN架构，相比传统方法实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 有机合成和过程化学中，预测连续溶剂组成范围内的反应结果是一个关键挑战。传统机器学习方法通常将溶剂视为离散分类变量，这阻碍了在溶剂空间中的系统插值和外推。

Method: 提出了Catechol Benchmark数据集，包含1,227个实验产率测量值，涵盖24种纯溶剂及其二元混合物。开发了混合GNN架构，整合了图注意力网络(GATs)、差分反应指纹(DRFP)和学习的混合物感知溶剂编码。采用严格的留一溶剂和留一混合物协议进行评估。

Result: 传统表格方法（梯度提升决策树）和大型语言模型嵌入（Qwen-7B）表现不佳，MSE分别为0.099和0.129。提出的混合GNN架构实现了MSE 0.0039（±0.0003），比竞争基线误差减少60%，比表格集成方法提升超过25倍。

Conclusion: 显式分子图消息传递和连续混合物编码对于稳健的泛化至关重要。该研究为数据高效的反应预测和连续溶剂表示学习提供了完整的数据集、评估协议和参考实现。

Abstract: Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.
  Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \textbf{MSE of 0.0039} ($\pm$ 0.0003), representing a 60\% error reduction over competitive baselines and a $>25\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning.

</details>


### [28] [CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal](https://arxiv.org/abs/2512.19554)
*Yongxin Wang,Zhicheng Yang,Meng Cao,Mingfei Han,Haokun Lin,Yingying Zhu,Xiaojun Chang,Xiaodan Liang*

Main category: cs.LG

TL;DR: CARE是一种针对多模态推理的失败中心化后训练框架，通过对比锚定和反思引导重采样，将错误转化为监督信号，提升验证性视觉推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于验证奖励的群体相对强化学习（RLVR）在处理失败数据时效率低下：当所有轨迹都错误时梯度停滞；当有正确轨迹时，更新通常忽略其他接近但错误的原因，并且可能将信用错误分配给虚假的推理链。

Method: CARE包含两个核心组件：1）锚定对比目标，围绕最佳轨迹形成紧凑子组和语义相近的困难负样本，进行组内z-score归一化并包含负样本缩放和全负样本救援机制；2）反思引导重采样（RGR），通过一次性结构化自我修复重写代表性失败样本并用相同验证器重新评分，将接近正确的失败转化为可用正样本。

Result: 在Qwen2.5-VL-7B上，CARE在六个可验证视觉推理基准测试中比GRPO提升4.6个百分点的宏平均准确率；在Qwen3-VL-8B上，在相同评估协议下在MathVista和MMMU-Pro上达到竞争性或最先进的结果。

Conclusion: CARE通过将错误转化为监督信号，提高了准确性和训练平滑度，同时明确增加了来自失败的学习信号比例，为多模态推理中的失败利用提供了有效框架。

Abstract: Group-relative reinforcement learning with verifiable rewards (RLVR) often wastes the most informative data it already has the failures. When all rollouts are wrong, gradients stall; when one happens to be correct, the update usually ignores why the others are close-but-wrong, and credit can be misassigned to spurious chains. We present CARE (Contrastive Anchored REflection), a failure-centric post-training framework for multimodal reasoning that turns errors into supervision. CARE combines: (i) an anchored-contrastive objective that forms a compact subgroup around the best rollout and a set of semantically proximate hard negatives, performs within-subgroup z-score normalization with negative-only scaling, and includes an all-negative rescue to prevent zero-signal batches; and (ii) Reflection-Guided Resampling (RGR), a one-shot structured self-repair that rewrites a representative failure and re-scores it with the same verifier, converting near-misses into usable positives without any test-time reflection. CARE improves accuracy and training smoothness while explicitly increasing the share of learning signal that comes from failures. On Qwen2.5-VL-7B, CARE lifts macro-averaged accuracy by 4.6 points over GRPO across six verifiable visual-reasoning benchmarks; with Qwen3-VL-8B it reaches competitive or state-of-the-art results on MathVista and MMMU-Pro under an identical evaluation protocol.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage](https://arxiv.org/abs/2512.18908)
*Szymon Rusiecki,Cecilia G. Morales,Kimberly Elenberg,Leonard Weiss,Artur Dubrawski*

Main category: cs.AI

TL;DR: 本文提出了一种基于专家知识贝叶斯网络的决策支持框架，融合多个计算机视觉模型输出，用于大规模伤亡事件中的伤员分类，无需训练数据且能处理不完整信息，在DARPA分类挑战中性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 大规模伤亡事件会压垮紧急医疗系统，导致伤员评估延迟或错误，造成可预防的死亡。需要开发能够辅助急救人员快速准确分类伤员的自动化系统。

Method: 提出一个决策支持框架，融合多个计算机视觉模型（估计严重出血、呼吸窘迫、身体警觉性或可见创伤）的输出，构建完全基于专家定义规则的贝叶斯网络。该方法无需训练数据，支持不完整信息推理，对噪声或不确定观察具有鲁棒性。

Result: 在两个涉及11名和9名伤员的场景中，贝叶斯网络模型显著优于仅使用视觉的基线。生理评估准确率从15%提升到42%（第一个场景）和从19%提升到46%（第二个场景），性能提升近三倍。总体分类准确率从14%提高到53%，系统诊断覆盖率从31%扩大到95%。该团队在DARPA分类挑战第一轮物理比赛中获得11支队伍中的第4名。

Conclusion: 专家知识引导的概率推理能显著增强自动化分类系统，为大规模伤亡事件中的急救人员提供有前景的支持方法。该方法在DARPA分类挑战中展示了实际应用价值。

Abstract: Mass Casualty Incidents can overwhelm emergency medical systems and resulting delays or errors in the assessment of casualties can lead to preventable deaths. We present a decision support framework that fuses outputs from multiple computer vision models, estimating signs of severe hemorrhage, respiratory distress, physical alertness, or visible trauma, into a Bayesian network constructed entirely from expert-defined rules. Unlike traditional data-driven models, our approach does not require training data, supports inference with incomplete information, and is robust to noisy or uncertain observations. We report performance for two missions involving 11 and 9 casualties, respectively, where our Bayesian network model substantially outperformed vision-only baselines during evaluation of our system in the DARPA Triage Challenge (DTC) field scenarios. The accuracy of physiological assessment improved from 15% to 42% in the first scenario and from 19% to 46% in the second, representing nearly threefold increase in performance. More importantly, overall triage accuracy increased from 14% to 53% in all patients, while the diagnostic coverage of the system expanded from 31% to 95% of the cases requiring assessment. These results demonstrate that expert-knowledge-guided probabilistic reasoning can significantly enhance automated triage systems, offering a promising approach to supporting emergency responders in MCIs. This approach enabled Team Chiron to achieve 4th place out of 11 teams during the 1st physical round of the DTC.

</details>


### [30] [ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management](https://arxiv.org/abs/2512.19001)
*Lingjie Zhao,Xue Yu,Yongzhi Qi,Hao Hu,Jianshen Zhang,Yingzheng Ma,Shuyu Han,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 提出OR引导的"预训练-强化"框架，将AI自适应感知与OR结构严谨性结合，在库存管理中实现轻量级高性能模型


<details>
  <summary>Details</summary>
Motivation: 解决AI自适应感知与OR结构严谨性之间的协调难题，在复杂库存系统中实现两者的有效结合

Method: OR引导的"预训练-强化"框架：1) 仿真增强OR模型生成高质量参考决策；2) 领域知识深度学习基础模型建立决策能力；3) 强化学习作为深度对齐机制进行微调

Result: 在JD.com实际部署验证：库存周转减少5.27天，现货率提升2.29%，持有成本降低29.95%，显著优于现有工业实践

Conclusion: 轻量级领域知识模型在OR结构化逻辑指导下可实现最先进性能和鲁棒可迁移性，为智能供应链管理提供可扩展、经济有效的范式

Abstract: As the pursuit of synergy between Artificial Intelligence (AI) and Operations Research (OR) gains momentum in handling complex inventory systems, a critical challenge persists: how to effectively reconcile AI's adaptive perception with OR's structural rigor. To bridge this gap, we propose a novel OR-Guided "Pretrain-then-Reinforce" framework. To provide structured guidance, we propose a simulation-augmented OR model that generates high-quality reference decisions, implicitly capturing complex business constraints and managerial preferences. Leveraging these OR-derived decisions as foundational training labels, we design a domain-informed deep learning foundation model to establish foundational decision-making capabilities, followed by a reinforcement learning (RL) fine-tuning stage. Uniquely, we position RL as a deep alignment mechanism that enables the AI agent to internalize the optimality principles of OR, while simultaneously leveraging exploration for general policy refinement and allowing expert guidance for scenario-specific adaptation (e.g., promotional events). Validated through extensive numerical experiments and a field deployment at JD.com augmented by a Difference-in-Differences (DiD) analysis, our model significantly outperforms incumbent industrial practices, delivering real-world gains of a 5.27-day reduction in turnover and a 2.29% increase in in-stock rates, alongside a 29.95% decrease in holding costs. Contrary to the prevailing trend of brute-force model scaling, our study demonstrates that a lightweight, domain-informed model can deliver state-of-the-art performance and robust transferability when guided by structured OR logic. This approach offers a scalable and cost-effective paradigm for intelligent supply chain management, highlighting the value of deeply aligning AI with OR.

</details>


### [31] [Recontextualization Mitigates Specification Gaming without Modifying the Specification](https://arxiv.org/abs/2512.19027)
*Ariana Azarbal,Victor Gillioz,Vladimir Ivanov,Bryce Woodworth,Jacob Drori,Nevan Wichers,Aram Ebtekar,Alex Cloud,Alexander Matt Turner*

Main category: cs.AI

TL;DR: 提出recontextualization方法，通过重新语境化训练样本，减少语言模型"博弈"训练信号的问题，防止模型学习错误行为


<details>
  <summary>Details</summary>
Motivation: 开发者经常难以指定正确的训练标签和奖励信号，导致语言模型学会"博弈"这些不完善的训练信号，表现出错误行为（如优先考虑评估指标而非聊天质量、特殊处理代码以通过错误测试、对用户撒谎、谄媚等）

Method: recontextualization方法：首先生成阻止错误行为的提示下的补全，然后将这些补全重新语境化为好像是在允许错误行为的提示下生成的。通过这种方式训练语言模型，使其即使在允许错误行为的指令下也能抵抗错误行为

Result: 该方法能防止模型学习四种错误行为：1)优先考虑评估指标而非聊天质量；2)特殊处理代码以通过错误测试；3)对用户撒谎；4)谄媚。无需改进监督信号就能减少规范博弈

Conclusion: recontextualization通过重新语境化训练样本，有效缓解了因训练信号误指定而强化的错误行为，减少了规范博弈问题，为语言模型训练提供了一种新的鲁棒性增强方法

Abstract: Developers often struggle to specify correct training labels and rewards. Perhaps they don't need to. We propose recontextualization, which reduces how often language models "game" training signals, performing misbehaviors those signals mistakenly reinforce. We show recontextualization prevents models from learning to 1) prioritize evaluation metrics over chat response quality; 2) special-case code to pass incorrect tests; 3) lie to users; and 4) become sycophantic. Our method works by generating completions from prompts discouraging misbehavior and then recontextualizing them as though they were in response to prompts permitting misbehavior. Recontextualization trains language models to resist misbehavior even when instructions permit it. This mitigates the reinforcement of misbehavior from misspecified training signals, reducing specification gaming without improving the supervision signal.

</details>


### [32] [Conditioning Accept-Desirability models in the context of AGM-like belief change](https://arxiv.org/abs/2512.19096)
*Kathelijne Coussement,Gert de Cooman,Keano De Vos*

Main category: cs.AI

TL;DR: 提出了一种在抽象决策框架中用于接受-期望模型的新的条件化规则，基于观测事件引入新无差异性的思想，并研究了AGM信念修正公理在该框架中的适用性。


<details>
  <summary>Details</summary>
Motivation: 在统一经典概率和量子概率的抽象决策框架中，需要发展适用于接受-期望模型的条件化规则，并探讨在更一般框架下信念修正公理的保持情况。

Method: 在抽象决策框架中，将不确定奖励置于一般线性空间，事件作为该空间的投影算子。提出基于观测事件引入新无差异性的条件化规则，并关联信念修正算子，分析AGM公理的保持情况。

Result: 发现两个特殊情况下所有AGM公理仍然成立：经典命题逻辑和完全条件概率。在更一般的接受-期望模型框架中，部分AGM公理可能不成立。

Conclusion: 提出的条件化规则为统一经典和量子概率的抽象决策框架提供了理论工具，揭示了在更一般概率框架下信念修正公理的适用边界，为不精确概率环境下的决策理论奠定了基础。

Abstract: We discuss conditionalisation for Accept-Desirability models in an abstract decision-making framework, where uncertain rewards live in a general linear space, and events are special projection operators on that linear space. This abstract setting allows us to unify classical and quantum probabilities, and extend them to an imprecise probabilities context. We introduce a new conditioning rule for our Accept-Desirability models, based on the idea that observing an event introduces new indifferences between options. We associate a belief revision operator with our conditioning rule, and investigate which of the AGM axioms for belief revision still hold in our more general framework. We investigate two interesting special cases where all of these axioms are shown to still hold: classical propositional logic and full conditional probabilities.

</details>


### [33] [Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application](https://arxiv.org/abs/2512.19299)
*Haoyu Jiang,Fanjie Zeng,Boan Qu,Xiaojie Lin,Wei Zhong*

Main category: cs.AI

TL;DR: Helios是一个专门针对智能能源领域的大语言模型，通过多智能体协作框架构建了知识库、指令微调数据集和RLHF数据集，显著提升了在智能能源领域的专业知识掌握、任务执行准确性和人类偏好对齐。


<details>
  <summary>Details</summary>
Motivation: 在碳中和的全球趋势下，智能能源系统需要深度协调，但该领域跨学科、碎片化且快速发展的专业知识使得通用LLMs缺乏领域知识和物理约束意识，无法提供精确的工程对齐推理和生成。

Method: 开发了Enersys多智能体协作框架进行端到端数据集构建，包括：1) EnerBase智能能源知识库；2) EnerInstruct指令微调数据集；3) EnerReinforce RLHF数据集。利用这些资源对Helios进行大规模预训练、SFT和RLHF。

Result: 发布了EnerBench基准用于评估智能能源场景中的LLMs，证明该方法显著增强了领域知识掌握、任务执行准确性和人类偏好对齐。

Conclusion: Helios模型及其配套资源（数据集、基准）为智能能源领域的LLM研究提供了全面解决方案，解决了通用LLMs在该领域专业知识不足和物理约束意识缺乏的问题。

Abstract: In the global drive toward carbon neutrality, deeply coordinated smart energy systems underpin industrial transformation. However, the interdisciplinary, fragmented, and fast-evolving expertise in this domain prevents general-purpose LLMs, which lack domain knowledge and physical-constraint awareness, from delivering precise engineering-aligned inference and generation. To address these challenges, we introduce Helios, a large language model tailored to the smart energy domain, together with a comprehensive suite of resources to advance LLM research in this field. Specifically, we develop Enersys, a multi-agent collaborative framework for end-to-end dataset construction, through which we produce: (1) a smart energy knowledge base, EnerBase, to enrich the model's foundational expertise; (2) an instruction fine-tuning dataset, EnerInstruct, to strengthen performance on domain-specific downstream tasks; and (3) an RLHF dataset, EnerReinforce, to align the model with human preferences and industry standards. Leveraging these resources, Helios undergoes large-scale pretraining, SFT, and RLHF. We also release EnerBench, a benchmark for evaluating LLMs in smart energy scenarios, and demonstrate that our approach significantly enhances domain knowledge mastery, task execution accuracy, and alignment with human preferences.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts](https://arxiv.org/abs/2512.18041)
*Roger A. Finger,Eduardo G. Cortes,Sandro J. Rigo,Gabriel de O. Ramos*

Main category: cs.CL

TL;DR: 本文提出了叙事整合新任务，专注于保持时间顺序和叙事连贯性，而非传统摘要的压缩。通过引入时间对齐事件图(TAEG)和中心性算法，在圣经福音书案例中实现了完美时间排序和显著内容改进。


<details>
  <summary>Details</summary>
Motivation: 处理重叠叙事文档（如法律证词、历史记录）时，传统多文档摘要(MDS)过于关注压缩而破坏了叙事流。需要一种新方法专注于保持时间顺序完整性、内容完整性和细节融合，而不是简单压缩。

Method: 提出叙事整合任务，引入时间对齐事件图(TAEG)显式建模时间顺序和事件对齐。使用标准中心性算法作为版本选择机制，为每个事件选择最中心的表示，并保持正确的时间位置。

Result: 在四部圣经福音书研究中，该方法通过设计保证了完美的时间排序（Kendall's Tau为1.000），并显著提升了内容指标（如ROUGE-L F1提高了357.2%）。

Conclusion: 叙事整合是一个相关且重要的NLP任务，显式的时间骨架是其解决的基本组成部分。该方法验证了任务定义的合理性，并为处理重叠叙事文档提供了有效框架。

Abstract: Processing overlapping narrative documents, such as legal testimonies or historical accounts, often aims not for compression but for a unified, coherent, and chronologically sound text. Standard Multi-Document Summarization (MDS), with its focus on conciseness, fails to preserve narrative flow. This paper formally defines this challenge as a new NLP task: Narrative Consolidation, where the central objectives are chronological integrity, completeness, and the fusion of complementary details. To demonstrate the critical role of temporal structure in this task, we introduce Temporal Alignment Event Graph (TAEG), a graph structure that explicitly models chronology and event alignment. By applying a standard centrality algorithm to TAEG, our method functions as a version selection mechanism, choosing the most central representation of each event in its correct temporal position. In a study on the four Biblical Gospels, this structure-focused approach guarantees perfect temporal ordering (Kendall's Tau of 1.000) by design and dramatically improves content metrics (e.g., +357.2% in ROUGE-L F1). The success of this baseline method validates the formulation of Narrative Consolidation as a relevant task and establishes that an explicit temporal backbone is a fundamental component for its resolution.

</details>


### [35] [GeoSense-AI: Fast Location Inference from Crisis Microblogs](https://arxiv.org/abs/2512.18225)
*Deepit Sapru*

Main category: cs.CL

TL;DR: GeoSense-AI：一个用于从嘈杂的微博流中实时地理定位的应用AI管道，通过整合多种NLP技术和地理知识库，在紧急情况下实现高效的位置推断。


<details>
  <summary>Details</summary>
Motivation: 传统的地理标签（geotags）在社交媒体数据中通常稀疏不可靠，特别是在紧急情况下需要快速获取位置信息时。需要开发能够直接从文本中提取地理位置的实时系统，以支持紧急情况下的态势感知和响应。

Method: 整合了统计性标签分割、词性驱动的专有名词检测、围绕灾害词典的依存句法分析、轻量级命名实体识别以及基于地名录的消歧。整个系统针对流式处理约束设计，强调低延迟NLP组件和高效的地理知识库验证。

Result: 与广泛使用的NER工具包相比，该系统在保持高F1分数的同时，实现了数量级更快的吞吐量，能够在实时危机信息学环境中部署。生产地图界面展示了端到端的AI功能，包括数据摄入、推理和可视化。

Conclusion: 通过优先考虑对非正式文本的鲁棒性和流式处理效率，GeoSense-AI展示了领域调优的NLP和知识基础如何能够超越传统地理标签依赖，提升应急响应能力。

Abstract: This paper presents an applied AI pipeline for realtime geolocation from noisy microblog streams, unifying statistical hashtag segmentation, part-of-speech-driven proper-noun detection, dependency parsing around disaster lexicons, lightweight named-entity recognition, and gazetteer-grounded disambiguation to infer locations directly from text rather than sparse geotags. The approach operationalizes information extraction under streaming constraints, emphasizing low-latency NLP components and efficient validation against geographic knowledge bases to support situational awareness during emergencies. In head to head comparisons with widely used NER toolkits, the system attains strong F1 while being engineered for orders-of-magnitude faster throughput, enabling deployment in live crisis informatics settings. A production map interface demonstrates end-to-end AI functionality ingest, inference, and visualization--surfacing locational signals at scale for floods, outbreaks, and other fastmoving events. By prioritizing robustness to informal text and streaming efficiency, GeoSense-AI illustrates how domain-tuned NLP and knowledge grounding can elevate emergency response beyond conventional geo-tag reliance.

</details>


### [36] [Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling](https://arxiv.org/abs/2512.18462)
*Christopher Román Jaimes*

Main category: cs.CL

TL;DR: 提出自动化可扩展的NLI模型去偏方法，通过LF-LMI检测语义伪影、LLM合成对比集、动态平衡采样训练，显著提升模型一致性


<details>
  <summary>Details</summary>
Motivation: NLI模型经常依赖虚假相关性而非语义推理，现有缓解策略要么标注成本高，要么在微调时引发灾难性遗忘

Method: 1) 提出LF-LMI准确检测语义伪影；2) 通过LLM合成管道生成高质量合成对比集，并进行多法官验证；3) 引入动态平衡采样训练策略，旋转原始数据分布以防止遗忘

Result: 在挑战性基准测试中，一致性从63.5%提升至81.0%，同时保持88.4%的域内准确率，显著优于朴素微调方法

Conclusion: 提出的自动化可扩展管道有效解决了NLI模型依赖虚假相关性的问题，在提升模型一致性的同时避免了灾难性遗忘

Abstract: Natural Language Inference (NLI) models frequently rely on spurious correlations rather than semantic reasoning. Existing mitigation strategies often incur high annotation costs or trigger catastrophic forgetting during fine-tuning. We propose an automated, scalable pipeline to address these limitations. First, we introduce Log-Frequency LMI (LF-LMI) to accurately detect semantic artifacts. Second, we generate a high-quality synthetic contrast set via an LLM-synthesis pipeline with multi-judge verification. Finally, we introduce Dynamic Balanced Sampling, a training strategy that rotates the original data distribution to prevent forgetting. Our method improves consistency on a challenging benchmark from 63.5% to 81.0% while maintaining 88.4% in-domain accuracy, significantly outperforming naive fine-tuning.

</details>


### [37] [CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation](https://arxiv.org/abs/2512.19173)
*Dazhen Deng,Sen Yang,Yuchen He,Yuan Tian,Yingcai Wu*

Main category: cs.CL

TL;DR: CycleChart是一个基于一致性的双向图表理解与生成框架，通过模式中心化表述统一任务接口，利用生成-解析一致性目标学习跨方向图表语义


<details>
  <summary>Details</summary>
Motivation: 当前图表特定任务（如图表问答、图表解析、图表生成）通常孤立研究，阻碍了模型学习连接图表生成与解释的共享语义

Method: 采用模式中心化表述作为跨任务通用接口，构建一致的多任务数据集，引入生成-解析一致性目标：模型从表格和文本查询生成图表模式，然后学习从生成的图表中恢复模式和数据

Result: CycleChart在图表生成、图表解析和图表问答方面取得强劲结果，展示了改进的跨任务泛化能力

Conclusion: CycleChart标志着向更通用的图表理解模型迈出了一步，通过一致性学习框架实现了双向图表理解与生成

Abstract: Current chart-specific tasks, such as chart question answering, chart parsing, and chart generation, are typically studied in isolation, preventing models from learning the shared semantics that link chart generation and interpretation. We introduce CycleChart, a consistency-based learning framework for bidirectional chart understanding and generation. CycleChart adopts a schema-centric formulation as a common interface across tasks. We construct a consistent multi-task dataset, where each chart sample includes aligned annotations for schema prediction, data parsing, and question answering. To learn cross-directional chart semantics, CycleChart introduces a generate-parse consistency objective: the model generates a chart schema from a table and a textual query, then learns to recover the schema and data from the generated chart, enforcing semantic alignment across directions. CycleChart achieves strong results on chart generation, chart parsing, and chart question answering, demonstrating improved cross-task generalization and marking a step toward more general chart understanding models.

</details>


### [38] [A Large-Language-Model Framework for Automated Humanitarian Situation Reporting](https://arxiv.org/abs/2512.19475)
*Ivan Decostanzi,Yelena Mejova,Kyriaki Kalimeri*

Main category: cs.CL

TL;DR: 利用大语言模型自动将异构人道主义文档转化为结构化、有证据支撑的报告框架，在13个人道主义事件中验证有效


<details>
  <summary>Details</summary>
Motivation: 当前人道主义决策依赖的手工报告制作流程效率低下、资源密集且不一致，需要自动化解决方案来提高时效性和准确性

Method: 整合语义文本聚类、自动问题生成、检索增强答案提取（带引用）、多级摘要和行政摘要生成，并采用模拟专家推理的内部评估指标

Result: 在13个人道主义事件（自然灾害和冲突）的1100多份文档上验证，生成问题相关度84.7%、重要性84.0%、紧急性76.4%；提取答案相关度86.3%，引用精确率和召回率均超76%；人机评估一致性F1分数超0.80

Conclusion: 结合LLM推理、透明引用链接和多级评估，生成式AI能够自主产生准确、可验证且具有操作价值的人道主义形势报告，优于现有基线方法

Abstract: Timely and accurate situational reports are essential for humanitarian decision-making, yet current workflows remain largely manual, resource intensive, and inconsistent. We present a fully automated framework that uses large language models (LLMs) to transform heterogeneous humanitarian documents into structured and evidence-grounded reports. The system integrates semantic text clustering, automatic question generation, retrieval augmented answer extraction with citations, multi-level summarization, and executive summary generation, supported by internal evaluation metrics that emulate expert reasoning. We evaluated the framework across 13 humanitarian events, including natural disasters and conflicts, using more than 1,100 documents from verified sources such as ReliefWeb. The generated questions achieved 84.7 percent relevance, 84.0 percent importance, and 76.4 percent urgency. The extracted answers reached 86.3 percent relevance, with citation precision and recall both exceeding 76 percent. Agreement between human and LLM based evaluations surpassed an F1 score of 0.80. Comparative analysis shows that the proposed framework produces reports that are more structured, interpretable, and actionable than existing baselines. By combining LLM reasoning with transparent citation linking and multi-level evaluation, this study demonstrates that generative AI can autonomously produce accurate, verifiable, and operationally useful humanitarian situation reports.

</details>


### [39] [Event Extraction in Large Language Model](https://arxiv.org/abs/2512.19537)
*Bobo Li,Xudong Han,Jiang Liu,Yuzhe Ding,Liqiang Jing,Zhaoqi Zhang,Jinheng Li,Xinya Du,Fei Li,Meishan Zhang,Min Zhang,Aixin Sun,Philip S. Yu,Hao Fei*

Main category: cs.CL

TL;DR: 该论文综述了事件抽取在LLM时代的发展，提出将事件抽取视为为LLM解决方案提供认知支架的系统组件，并探讨了从静态提取到可靠、面向智能体的感知与记忆层的演进方向。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM和多模态LLM正在改变事件抽取领域，但基于LLM的管道仍面临部署差距：弱约束下的幻觉问题、长上下文和跨文档的脆弱时间因果链接、有限的长视野知识管理等。需要将事件抽取视为为LLM中心解决方案提供认知支架的系统组件。

Method: 通过事件模式和槽位约束创建接地和验证接口；以事件为中心的结构作为逐步推理的受控中间表示；事件链接支持基于图的RAG进行关系感知检索；事件存储提供超出上下文窗口的可更新情景和智能体记忆。

Result: 综述涵盖了文本和多模态设置下的事件抽取，组织了任务和分类法，追溯了从基于规则和神经模型到指令驱动和生成框架的方法演进，总结了公式、解码策略、架构、表示、数据集和评估方法。

Conclusion: 事件抽取需要从静态提取演变为结构可靠、面向智能体的感知和记忆层，以支持开放世界系统。未来方向包括解决LLM时代的核心挑战，建立可靠的事件中心系统。

Abstract: Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [40] [Embodied4C: Measuring What Matters for Embodied Vision-Language Navigation](https://arxiv.org/abs/2512.18028)
*Tin Stribor Sohn,Maximilian Dillitzer,Jason J. Corso,Eric Sax*

Main category: cs.RO

TL;DR: Embodied4C是一个为评估视觉语言模型在具身推理能力而设计的闭环基准测试，涵盖自动驾驶车辆、无人机和机械臂三种异构具身平台，通过1100个一次性推理问题和58个目标导向导航任务评估语义、空间、时间和物理四个维度的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试对具身性（物理平台、传感器配置和模态对齐）如何影响感知、推理和控制的理解有限，需要开发一个能够全面评估视觉语言模型具身推理能力的基准测试。

Method: 设计Embodied4C作为具身推理的图灵测试，包含三种异构具身平台（自动驾驶车辆、无人机、机械臂），通过动态传感器配置和环境变化评估泛化能力，并集成领域外查询以防止具身过拟合。

Result: 对10个最先进的视觉语言模型和4个具身控制基线的评估表明：跨模态对齐和指令调优比模型规模更重要，而空间和时间推理仍然是可靠具身能力的主要瓶颈。

Conclusion: Embodied4C基准测试揭示了视觉语言模型在具身推理中的关键瓶颈，强调需要更好的跨模态对齐和时空推理能力，而不仅仅是扩大模型规模。

Abstract: Vision-language navigation requires agents to reason and act under constraints of embodiment. While vision-language models (VLMs) demonstrate strong generalization, current benchmarks provide limited understanding of how embodiment -- i.e., the choice of physical platform, sensor configuration, and modality alignment -- influences perception, reasoning, and control. We introduce Embodied4C, a closed-loop benchmark designed as a Turing test for embodied reasoning. The benchmark evaluates the core embodied capabilities of VLMs across three heterogeneous embodiments -- autonomous vehicles, aerial drones, and robotic manipulators -- through approximately 1.1K one-shot reasoning questions and 58 goal-directed navigation tasks. These tasks jointly assess four foundational dimensions: semantic, spatial, temporal, and physical reasoning. Each embodiment presents dynamic sensor configurations and environment variations to probe generalization beyond platform-specific adaptation. To prevent embodiment overfitting, Embodied4C integrates domain-far queries targeting abstract and cross-context reasoning. Comprehensive evaluation across ten state-of-the-art VLMs and four embodied control baselines shows that cross-modal alignment and instruction tuning matter more than scale, while spatial and temporal reasoning remains the primary bottleneck for reliable embodied competence.

</details>


### [41] [Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism](https://arxiv.org/abs/2512.18336)
*Youssef Mahran,Zeyad Gamal,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 本文研究了强化学习中动态熵调优对随机策略训练的影响，并与确定性策略训练进行比较，发现动态熵调优在四旋翼控制中能防止灾难性遗忘并提高探索效率。


<details>
  <summary>Details</summary>
Motivation: 研究动态熵调优在强化学习随机策略训练中的作用，特别是与确定性策略训练相比，探索其在复杂控制任务（如四旋翼控制）中的性能差异。

Method: 使用SAC算法（随机策略）与TD3算法（确定性策略）进行对比实验。在SAC中测试静态熵和动态熵两种设置，然后执行确定性动作控制四旋翼，并与TD3的确定性策略训练进行比较。

Result: 训练和仿真结果显示，动态熵调优在四旋翼控制中具有积极效果：能防止灾难性遗忘，并提高探索效率。

Conclusion: 动态熵调优在强化学习随机策略训练中优于静态熵设置，在复杂控制任务中表现更佳，能有效平衡探索与利用。

Abstract: This paper explores the impact of dynamic entropy tuning in Reinforcement Learning (RL) algorithms that train a stochastic policy. Its performance is compared against algorithms that train a deterministic one. Stochastic policies optimize a probability distribution over actions to maximize rewards, while deterministic policies select a single deterministic action per state. The effect of training a stochastic policy with both static entropy and dynamic entropy and then executing deterministic actions to control the quadcopter is explored. It is then compared against training a deterministic policy and executing deterministic actions. For the purpose of this research, the Soft Actor-Critic (SAC) algorithm was chosen for the stochastic algorithm while the Twin Delayed Deep Deterministic Policy Gradient (TD3) was chosen for the deterministic algorithm. The training and simulation results show the positive effect the dynamic entropy tuning has on controlling the quadcopter by preventing catastrophic forgetting and improving exploration efficiency.

</details>


### [42] [DTCCL: Disengagement-Triggered Contrastive Continual Learning for Autonomous Bus Planners](https://arxiv.org/abs/2512.18988)
*Yanding Yang,Weitao Zhou,Jinhai Wang,Xiaomin Guo,Junze Wen,Xiaolong Liu,Lang Ding,Zheng Fu,Jinyu Miao,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: 提出DTCCL框架，通过对比持续学习解决自动驾驶公交车在交互密集区域的规划失败问题，利用脱钩事件触发云端数据增强，实现无监督闭环策略改进。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶公交车在固定路线上运行，但在开放动态的城市环境中，脱钩事件往往集中在高度交互区域，由规划器失败引起。传统的模仿学习容易对稀疏的脱钩数据过拟合，难以纠正这些策略级失败。

Method: 提出脱钩触发的对比持续学习（DTCCL）框架：1）每次脱钩触发云端数据增强，通过扰动周围智能体生成正负样本，同时保持路线上下文；2）使用对比学习细化策略表示，更好区分安全和不安全行为；3）在云边循环中持续更新策略，无需人工监督。

Result: 在城市公交路线上的实验表明，DTCCL相比直接重新训练，将整体规划性能提高了48.6%，验证了其在自动驾驶公共交通中可扩展、闭环策略改进的有效性。

Conclusion: DTCCL框架能够有效解决自动驾驶公交车在交互密集区域的规划失败问题，通过脱钩触发的对比持续学习实现无监督策略改进，为自动驾驶公共交通提供了可扩展的闭环改进方案。

Abstract: Autonomous buses run on fixed routes but must operate in open, dynamic urban environments. Disengagement events on these routes are often geographically concentrated and typically arise from planner failures in highly interactive regions. Such policy-level failures are difficult to correct using conventional imitation learning, which easily overfits to sparse disengagement data. To address this issue, this paper presents a Disengagement-Triggered Contrastive Continual Learning (DTCCL) framework that enables autonomous buses to improve planning policies through real-world operation. Each disengagement triggers cloud-based data augmentation that generates positive and negative samples by perturbing surrounding agents while preserving route context. Contrastive learning refines policy representations to better distinguish safe and unsafe behaviors, and continual updates are applied in a cloud-edge loop without human supervision. Experiments on urban bus routes demonstrate that DTCCL improves overall planning performance by 48.6 percent compared with direct retraining, validating its effectiveness for scalable, closed-loop policy improvement in autonomous public transport.

</details>
